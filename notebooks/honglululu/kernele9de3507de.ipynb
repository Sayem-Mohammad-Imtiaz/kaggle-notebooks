{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport keras\n\nprint(\"tensorflow version \",tf.__version__)\nprint(\"keras version \",keras.__version__)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# import tensorflow as tf\nimport cv2\nfrom PIL import Image\nimport os\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\nprint(\"done\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pathlib import Path\nx_train = []\ny_train = []\n\nheight = 30\nwidth = 30\nchannels = 3\nclasses = 43\nn_inputs = height * width * channels\n\ncwd = os.getcwd()\nprint(\"currect directory \",os.getcwd())\n# for x in os.listdir('../'):\n#     print(x)\n\n# \"/input/gtsrb-german-traffic-sign/train\"\n# for x in os.listdir(\"../input/gtsrb-german-traffic-sign/train/0\"):\n#     print(x)\n\nprint(\"read all the training data to x_train and y_train\")\nfor i in range(classes) :\n    path = \"../input/gtsrb-german-traffic-sign/train/{0}/\".format(i)\n    print(path)\n    Class=os.listdir(path)\n    for a in Class:\n        try:\n            image=cv2.imread(path+a)\n            image_from_array = Image.fromarray(image, 'RGB')\n            size_image = image_from_array.resize((height, width))\n            x_train.append(np.array(size_image))\n            y_train.append(i)\n        except AttributeError:\n            print(\" \")\n            \nx_train = np.array(x_train)\ny_train = np.array(y_train)\nx_train = x_train.astype('float32')/255 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert the image to grayscale and apply histogram equalization\nprint(x_train[0].shape)\nplt.figure(figsize=(2,2))\nplt.imshow(x_train[0])\n# plt.imshow(cv2.cvtColor(x_train[0], cv2.COLOR_GRAY2RGB))\n\n# def gray(img):\n#     gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY )\n#     equ  = cv2.equalizeHist(gray_img)\n#     return equ\n\n# x_train = np.array([gray(img) for img in x_train])\n# x_train = x_train[...,np.newaxis]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# shuffle and split the data to training set and validation set\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nimport sys\nprint(sys.version)\nprint(\"import lib successfully\")\n\n# x_train, y_train = shuffle(x_train, y_train)\nprint(\"total number of data\",len(x_train))\nx_train,x_validation,y_train,y_validation = train_test_split(x_train,y_train,test_size=0.2,random_state=42)\nprint(\"number of train data\",len(x_train))\nprint(\"number of validation data\",len(x_validation))\n\n# print(x_train[10].shape)\n# plt.figure(figsize=(2,2))\n# plt.imshow(x_train[10])\n\n# print(x_validation[10].shape)\n# plt.figure(figsize=(2,2))\n# plt.imshow(x_validation[10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# build the conv net\nfrom keras.layers import Dense, Input\nfrom keras.layers import Conv2D, MaxPool2D, Dropout, Flatten\ndef convNet(img):\n    net = Conv2D(filters=6, kernel_size=(5,5), activation='relu')(img)\n    net = Conv2D(filters=16, kernel_size=(5,5), activation='relu')(net)\n    net = MaxPool2D(pool_size=(2, 2))(net)\n#     net  = Dropout(rate=0.25)(net)\n    net = Conv2D(filters=400, kernel_size=(3, 3), activation='relu')(net)\n#     net = Dropout(rate=0.25)(net)\n    net = Flatten()(net)\n    net = Dropout(rate=0.5)(net)\n    logits = Dense(43)(net)\n    return logits\nprint(\"model defined!!!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow.compat.v1 as tf\nfrom tensorflow.compat.v1.math import subtract\nfrom keras import backend as K\ntf.disable_v2_behavior()\n\nprint(\"0 is testing mode and 1 is the training mode\")\nprint(K.learning_phase())\n\nrate = 0.001\nEPOCHS = 20\nBATCH_SIZE = 128\n\nx = tf.placeholder(tf.float32, (None, 30, 30, 3))\ny = tf.placeholder(tf.int32, (None))\none_hot_y = tf.one_hot(y, classes)\n\n# one = tf.constant(value = 1.0, dtype = tf.float32)\n# drop_out_prob = subtract(one,keep_prob)\n\nlogits = convNet(x)\ncross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = one_hot_y)\ntotal_loss = tf.reduce_mean(cross_entropy)\noptimizer = tf.train.AdamOptimizer(learning_rate = rate)\ntraining_operation = optimizer.minimize(total_loss)\n\n\ncorrect_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\naccuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\nsaver = tf.train.Saver()\n\ndef evaluate(X_data,y_data):\n    num_examples = len(X_data)\n    total_accuracy = 0\n    sess = tf.get_default_session()\n    for offset in range(0, num_examples, BATCH_SIZE):\n        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n        accuracy = sess.run(accuracy_operation, \n                            feed_dict={x: batch_x, y: batch_y, K.learning_phase():0})\n        total_accuracy += (accuracy * len(batch_x))\n    return total_accuracy / num_examples\n\n\n\n\nprint(\"done!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# training start\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    num_examples = len(x_train)\n    print(\"training....\")\n    print()\n    for i in range(EPOCHS):\n        x_train,y_train = shuffle(x_train,y_train)\n        for offset in range(0,num_examples,BATCH_SIZE):\n            batch_x,batch_y = x_train[offset:offset+BATCH_SIZE],y_train[offset:offset+BATCH_SIZE]\n            sess.run(training_operation,feed_dict={x: batch_x, y: batch_y,K.learning_phase(): 1})\n            \n        validation_accuracy = evaluate(x_validation, y_validation)\n        print(\"EPOCH {} ...\".format(i+1))\n        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n        print()\n        \n    saver.save(sess, 'convnet')\n    print(\"Model saved\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}