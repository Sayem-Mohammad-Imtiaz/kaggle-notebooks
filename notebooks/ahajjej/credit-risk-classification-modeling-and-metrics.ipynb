{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n!pip install plotly\nimport plotly.offline as py \nimport plotly.graph_objs as go\nimport plotly.express as px\nfrom collections import Counter  \nfrom subprocess import call\nfrom IPython.display import Image\n############################################################################################\n%matplotlib inline \nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, auc, accuracy_score\n\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Ingestion :**\n\nIn the beginning , I start by loading data and checking it","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"credit=pd.read_csv(\"../input/german-credit-data-with-risk/german_credit_data.csv\")\nprint(\"The dataset is {} credit record\".format(len(credit)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"credit.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"According to the data dictionnary provided to detail each of the columns:\n* Age (numeric)\n* Sex (text: male, female)\n* Job (numeric: 0 — unskilled and non-resident, 1 — unskilled and resident, 2 — skilled, 3 — highly skilled)\n* Housing (text: own, rent, or free)\n* Saving accounts (text — little, moderate, quite rich, rich)\n* Checking account (numeric, in DM — Deutsch Mark)\n* Credit amount (numeric, in DM)\n* Duration (numeric, in month)\n* Purpose (text: car, furniture/equipment, radio/TV, domestic appliances, repairs, education, business, vacation/others)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Data checks:**\n\nThe function info() helps to get a concise summary of a DataFrame by providning data types per column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"credit=credit.iloc[:, 1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"credit.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data sanity shows that two columns contains NaN values which will be handled later.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"credit.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Descriptive analysis:**\n\nExploratory data analysis in a data science project is a mandatory step in order to understand the way some of the attributes are distributed. In this chapter, I focus on drawing some charts in order to find out and demonstrate insights. To this end, I use the Plotly’s Python graphing library to create graphs which makes interactive, publication-quality graphs. For further detail please check plotly website.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"*** Sex Vs Age Cross tabulation:**\n\nA box plot is a statistical representation of numerical data through their quartiles. The ends of the box represent the lower and upper quartiles, while the median (second quartile) is marked by a line inside the box.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"credit['Sex'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SA = credit.loc[:,['Sex','Age']]\nfig = px.box(SA, x=\"Sex\", y=\"Age\", points=\"all\",color=\"Sex\")\nfig.update_layout(\n    title={\n          'text':\"Sex Vs Age Cross tabulation\",\n        'y':.95,\n        'x':.5,\n        'xanchor': 'center',\n        'yanchor': 'top'\n    },\n    xaxis_title=\"Sex\",\n    yaxis_title=\"Age\",\n   \n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SC =credit.loc[:,['Sex','Credit amount']]\nfig = px.box(SC, x=\"Sex\", y=\"Credit amount\", points=\"all\", color=\"Sex\")\nfig.update_traces(quartilemethod=\"exclusive\") # or \"inclusive\", or \"linear\" by default\nfig.update_layout(\n    title={\n          'text':\"Sex Vs Credit Amount Cross tabulation\",\n        'y':.95,\n        'x':.5,\n        'xanchor': 'center',\n        'yanchor': 'top'\n    },\n    xaxis_title=\"Sex\",\n    yaxis_title=\"Age\",\n   \n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Purpose distribution:**\n\nA histogram is a representation of the distribution of numerical data, where the data are binned and the count for each bin is represented.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Purpose = credit['Purpose']\nfig = px.histogram(credit, x=\"Purpose\", color=\"Purpose\")\nfig.update_layout(\n    title={\n          'text':\"Purpose breakdown\",\n        'y':.95,\n        'x':.5,\n        'xanchor': 'center',\n        'yanchor': 'top'\n    }\n   \n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The histogram chart shows that most of credit purpose is related to car prurchase , followed by radio/TV one.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"*** Purpose Vs Credit Amount Cross tabulation**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"SC =credit.loc[:,['Purpose','Credit amount']]\nfig = px.box(SC, x=\"Purpose\", y=\"Credit amount\", color=\"Purpose\")\nfig.update_traces(quartilemethod=\"exclusive\") # or \"inclusive\", or \"linear\" by default\nfig.update_layout(\n    title={\n          'text':\"Purpose Vs Credit Amount Cross tabulation\",\n        'y':.95,\n        'x':.5,\n        'xanchor': 'center',\n        'yanchor': 'top'\n    },\n    xaxis_title=\"Purpose\",\n    yaxis_title=\"Credit amount\",\n   \n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Transformations and feature engineering:**\n\nPart of the data cleansing step involves:\n* hypothesizing about the features I think I need\n* preparing to integrate them in my model\n\nA machine learning model unfortunately cannot deal with categorical variables (except for some models ). Therefore, I have to find a way to encode these variables as numbers before handling them within the model. There are two main ways to carry out this process:\n\n* Label Encoding: is the concept of assigning each unique category in a categorical variable with an integer. No new columns are created.\n\n=> It is only recommended for two unique categories since it gives the categories an arbitrary ordering\n\n* One-Hot Encoding: is the concept of creating a new column for each unique category in a categorical variable. Each observation receives a value of “1” in the column for its corresponding category and a value “0” in all other new columns.\n\nThe Risk is what I would like to predict: either a 0 for the loan presenting no risk and will be repaid on time, or a 1 indicating that the loan presents a risk and the client will have some payment difficulties.\nTo this end, I have two unique categories that’s why I use the map function for Label encoding.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"credit['Risk'] = credit['Risk'].map({'bad':1, 'good':0})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When the time comes to build the machine learning model, I have to fill in these missing values (known as imputation) identified during the data checks phase.\nIn my case I have at my disposal a small dataset which oblige me to keep all my rows that’s why I have introduced a new category value called “Others” for both Saving account and Checking account columns.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"credit['Saving accounts'] = credit['Saving accounts'].fillna('Others')\ncredit['Checking account'] = credit['Checking account'].fillna('Others')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I create then a checkpoint:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"credit_clean=credit.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Second step consists of transforming the data into dummy variable which is a part of One-hot encoding:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_features = ['Sex','Housing', 'Saving accounts', 'Checking account','Purpose']\nnum_features=['Age', 'Job', 'Credit amount', 'Duration','Risk']\nfor variable in cat_features:\n    dummies = pd.get_dummies(credit_clean[cat_features])\n    df1= pd.concat([credit_clean[num_features], dummies],axis=1)\n\nRisk= df1['Risk']          \ndf2=df1.drop(['Risk'],axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since the data is ready to be integrated and fit into the model, I can start by splitting it into training and testing sets.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,Y_train,Y_test = train_test_split(df2,Risk,test_size=0.20,random_state = 30)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Model building process:**\n\nThe risk prediction is a standard supervised classification task:\n* Supervised: The labels are included in the training data and the goal is to train a model to learn to predict the labels from the features\n* Classification: The label is a binary variable, 0 (no risk and loan will be on time), 1 (risky loan will have difficulty repaying loan)\nI use RandomForestClassifier from scikit-learn with the familiar Scikit-Learn modeling syntax: I first create the baseline model which will be tuned in order to seek the best hyperparameters.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"random_forest = RandomForestClassifier( random_state = 100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Model Optimization:**\n\nHyperparameters are model-specific parameters whose values are set before the learning process begins. In my case, I am using random forest classifier, hyperparameters include for example the number of trees in the forest (n_estimators) and the maximum depth of the tree (max_depth) as described within the model specifications.\nHyperparameters Tuning is a measure of how much performance can be gained by tuning them and searching for the right set of hyperparameter to achieve high precision and accuracy.\nThere are several parameter tuning techniques, but two of the most widely-used parameter optimizing techniques are :\n\n* Grid Search : The concept behavior is similar to the grid, where all the values are placed in the form of a matrix. Each combination of parameters is taken into consideration.\n\n* Random Search : The concept tries random combinations of the hyperparameters to find the best solution for the built model based on the defined scoring.\n\n\nI try to adjust the following RF set of hyperparameters using Random search:\n* n_estimators = number of trees in the forest\n* max_features = max number of features considered for splitting a node\n* max_depth = max number of levels in each decision tree\n* min_samples_split = min number of data points placed in a node before the node is split\n* min_samples_leaf = min number of data points allowed in a leaf node\n* bootstrap = method for sampling data points (with or without replacement)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Standardization\nsc=StandardScaler()\nX_train_std=sc.fit_transform(X_train)\nX_test_std=sc.transform(X_test)\n\nn_estimators = [int(x) for x in np.linspace(start = 100, stop = 2000, num = 10)]# Number of trees in random forest\nmax_features = ['auto', 'sqrt']# Number of features to consider at every split\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\nmin_samples_split = [2, 5, 10]# Minimum number of samples required to split a node\nmin_samples_leaf = [1, 2, 4]# Minimum number of samples required at each leaf node\nbootstrap = [True, False]# Method of selecting samples for training each tree\n\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\n\nrandom_forest = RandomForestClassifier(random_state = 100)\nrf_random = RandomizedSearchCV(estimator = random_forest, param_distributions = random_grid, n_iter = 50, cv = 5, verbose=4, scoring='recall', random_state=42, n_jobs = -1)\nrf_random.fit(X_train_std, Y_train)\nrf_random.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_test_pred = rf_random.predict(X_test_std)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model metrics:**\n\n*** Confusion matrix:**\n\nIt is a performance metric widely-used for machine learning classification tasks where output can be two or more classes. It is an array with 4 different combinations of predicted and actual values as shown below:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix= confusion_matrix(Y_test, Y_test_pred)\nconfusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_true = [\"bad\", \"good\"]\ny_pred = [\"bad\", \"good\"]\ndf_cm = pd.DataFrame(confusion_matrix, columns=np.unique(y_true), index = np.unique(y_true))\ndf_cm.index.name = 'Actual'\ndf_cm.columns.name = 'Predicted'\ndf_cm.dtypes\n\nplt.figure(figsize = (8,5))\nplt.title('Confusion Matrix')\nsns.set(font_scale=1.4)#for label size\nsns.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 16})# font size","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To summarize the confusion matrix :\n\n* TRUE POSITIVES (TP)= 122,\n* TRUE NEGATIVES (TN)= 18,\n* FALSE POSITIVES (FP)= 14,\n* FALSE NEGATIVES (FN)= 46.\n\nThe confusion matrix is extremely useful for measuring:\n* Recall(Sensitivity): also called the True Positive Rate is defined as the proportion of loan with an associated risk which will have a positive result. In other words, a highly sensitive test is one that correctly identifies credit with risk.\n* Specificity: also called the True Negative Rate is defined as the proportion of loans without an associated risk which will have a negative result. In other words, a highly sensitive test is one that correctly identifies credit without risk.\n* Accuracy: is the number of correctly predicted risks out of all the data points.\n* Precision: is the number of loans with risk which were actually correct","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The formulae for the evaluation metrics are as follows :","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"total=sum(sum(confusion_matrix))\n\nsensitivity_recall = confusion_matrix[0,0]/(confusion_matrix[0,0]+confusion_matrix[1,0])\nprint('Sensitivity_recall : ',sensitivity_recall )\n\nSpecificity = confusion_matrix[1,1]/(confusion_matrix[1,1]+confusion_matrix[0,1])\nprint('Specificity: ', Specificity)\n\nprecision = confusion_matrix[0,0]/(confusion_matrix[0,0]+confusion_matrix[0,1])\nprint('Precision: ', precision)\n\naccuracy =(confusion_matrix[0,0]+confusion_matrix[1,1])/(confusion_matrix[0,0]+confusion_matrix[0,1]+\n                                                         confusion_matrix[1,0]+confusion_matrix[1,1])\nprint('Accuracy: ', accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The roc curve:**\nAn ROC curve (receiver operating characteristic curve) is a graph showing the performance of a classification model at all classification thresholds. This curve plots two parameters:\n\n* True Positive Rate\n* False Positive Rate\n\n\nThe area covered by the curve is the area between the blue line (ROC) and the axis. This area covered is AUC. The bigger the area covered, the better the machine learning model is at distinguishing the given classes.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fpr, tpr, thresholds = roc_curve(Y_test, Y_test_pred)\n\nfig, ax = plt.subplots()\nax.plot(fpr, tpr)\nax.plot([0, 1], [0, 1], transform=ax.transAxes, ls=\"--\", c=\".3\")\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.rcParams['font.size'] = 12\n\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\nplt.grid(True)\n\nprint(\"\\n\")\nprint (\"Area Under Curve: %.2f\" %auc(fpr, tpr))\nprint(\"\\n\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}