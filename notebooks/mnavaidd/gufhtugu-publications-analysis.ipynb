{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport holoviews as hv\nfrom holoviews import opts\nhv.extension('bokeh')\nimport altair as alt\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n\n\nfrom fuzzywuzzy import fuzz \nfrom fuzzywuzzy import process \n\n#Apriori libraries \nfrom mlxtend.frequent_patterns import apriori\nfrom mlxtend.frequent_patterns import association_rules\n\nimport nltk\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import Dataset and check the rows and columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/gufhtugu-publications-dataset-challenge/GP Orders - 5.csv\", delimiter=',')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Shape of dataset <br/>\nWe have 19187 rows and 5 columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Rename the column of dataset for easy"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.rename(columns={'Order Number': 'order_number',\"Order Status\":\"order_status\", \"Book Name\":\"book_name\",\"Order Date & Time\":\"order_date\",\"City\":\"billing_city\", \"Payment Method\":\"payment_method\", \"Total items\":\"total_books\", \"Total weight (grams)\":\"grams\"})\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Check missing value in dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum().sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Check NaN in book_name**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['book_name'].isna()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Check NaN in billing_city**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['billing_city'].isna()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Delete all NaN from dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, We have no NaN values."},{"metadata":{},"cell_type":"markdown","source":"**We have 3 order status**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.order_status.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.order_status.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.order_status.hist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning"},{"metadata":{},"cell_type":"markdown","source":"**Split the book_name column with '/'and make a new row**"},{"metadata":{"trusted":true},"cell_type":"code","source":"split_col = df['book_name'].str.split('/', expand=True).stack()\n\n# Melting dataframe so that we have one book in each row\nsplit_col.index = split_col.index.droplevel(-1) # to line up with df's index\nsplit_col.name = 'book_name' # needs a name to join\n\ndf = df.drop(columns='book_name').join(split_col)\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Make book_name and billing_city to lowercase**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['book_name'] = df['book_name'].str.lower()\ndf['billing_city'] = df['billing_city'].str.lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pd.set_option('display.max_rows', df.shape[0]+1)\ndf['billing_city'].head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We have 3518  total cities**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['billing_city'].nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Try to clean the cities column**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# df['billing_city'] = df['billing_city'].replace({'KHI':'KARACHI', 'KHI':'KARACHI'})\n# df['billing_city'] = df['billing_city'].replace({'GAGOO MANDI TEHSIL BUREWALA DISTRICT VEHARI':'VEHARI'})\n# df['billing_city'] = df['billing_city'].replace({'ZILA TOBA TAK SING TAHSEEL GOJJRA':'GOJRA'})\n# df['billing_city'] = df['billing_city'].replace({'WAH CANTT, TAXILA, RAWALPINDI':'RAWALPINDI'})\n# df['billing_city'] = df['billing_city'].replace({'MIDEL TOWN LAHORE':'LAHORE'})\n# df['billing_city'] = df['billing_city'].replace({'TEHSIL BARNALA, DUST. BHIMBER':'BHIMBER'})\n# df['billing_city'] = df['billing_city'].replace({'ADDA ZAKHEERA(DUNYA PUR)':'DUNYAPUR'})\n# df['billing_city'] = df['billing_city'].replace({'JAUHARABAD , DISTT KHUSHAB':'KHUSHAB'})\n# df['billing_city'] = df['billing_city'].replace({'ADIYALA ROAD, RAWALPINDI':'RAWALPINDI'})\n# df['billing_city'] = df['billing_city'].replace({'UPPER CHITRAL':'CHITRAL'})\n# df['billing_city'] = df['billing_city'].replace({'MUSTUFA TOWN, WAHDAT ROAD, LAHORE.':'LAHORE'})\n# df['billing_city'] = df['billing_city'].replace({'AHMED PUR SIAL JHANG':'JHANG'})\n# df['billing_city'] = df['billing_city'].replace({'KALLAR SYEDAN DIST RAWALPINDI':'RAWALPINDI'})\n# df['billing_city'] = df['billing_city'].replace({'BAHWALNAGAR':'BAHAWALNAGAR'})\n# df['billing_city'] = df['billing_city'].replace({'LAHORE, PAKISTAN':'LAHORE'})\n# df['billing_city'] = df['billing_city'].replace({'MADINA TOWN, FAISALABAD':'FAISALABAD'})\n# df['billing_city'] = df['billing_city'].replace({'ALI RAZA ABAD 5KM RAIWIND ROAD LAHORE':'LAHORE'})\n# df['billing_city'] = df['billing_city'].replace({'MUZAFFARABAD AZAD KASHMIR':'MUZAFFARABAD'})\n# df['billing_city'] = df['billing_city'].replace({'TALUKA HALA DISTRICT MATIARI':'MATIARI'})\n# df['billing_city'] = df['billing_city'].replace({'AGRICS TOWN, RAIWAND ROAD LAHORE':'LAHORE'})\n# df['billing_city'] = df['billing_city'].replace({'LYARI, KARACHI':'KARACHI'})\n# df['billing_city'] = df['billing_city'].replace({'NORTH NAZIMABAD KARACHI':'KARACHI'})\n# df['billing_city'] = df['billing_city'].replace({'SAADI TOWN/KARACHI':'KARACHI'})\n# df['billing_city'] = df['billing_city'].replace({'KORANGI, KARACHI':'KARACHI'})\n# df['billing_city'] = df['billing_city'].replace({'RAWALPINDI CANT':'RAWALPINDI'})\n# df['billing_city'] = df['billing_city'].replace({'GULSHAN E IQBAL BLOCK 10 A, KARACHI':'KARACHI'})\n# df['billing_city'] = df['billing_city'].replace({'MALIR, KARACHI':'KARACHI'})\n# df['billing_city'] = df['billing_city'].replace({'SABZAZAR, MULTAN ROAD,LAHORE':'LAHORE'})\n# df['billing_city'] = df['billing_city'].replace({'TOWNSHIP LAHORE':'LAHORE'})\n# df['billing_city'] = df['billing_city'].replace({'CHAKLALA RAWALPINDI':'RAWALPINDI'})\n# df['billing_city'] = df['billing_city'].replace({'TEHSIL PHALIA DISTRICT MANDI BHUDDIN':'MANDI BAHAUDDIN'})\n# df['billing_city'] = df['billing_city'].replace({'VILLAGE SHUKHDARA TEHSIL MATTA DISTRICT SWAT':'SWAT'})\n# df['billing_city'] = df['billing_city'].replace({'DHA,EME SOCIETY MULTAN ROAD LAHORE PAKISTAN.':'LAHORE'})\n# df['billing_city'] = df['billing_city'].replace({'PAHAR PUR D I KHAN':'D I KHAN'})\n# df['billing_city'] = df['billing_city'].replace({'MANDI BAHAHUDIN':'MANDI BAHAUDDIN'})\n# df['billing_city'] = df['billing_city'].replace({'FAZAL COLONY NEAR EMCO FACTORY SHEIKHUPURA ROA':'SHEIKHUPURA'})\n# df['billing_city'] = df['billing_city'].replace({'SADIQ ABAD DISTRICT RAHIM YAR KHAN':'RAHIM YAR KHAN'})\n# df['billing_city'] = df['billing_city'].replace({'CHOUPERHATTA KABIRWALA KHANEWAL':'KHANEWAL'})\n# df['billing_city'] = df['billing_city'].replace({'ACADEMY TOWN, PESHAWAR':'PESHAWAR'})\n# df['billing_city'] = df['billing_city'].replace({'LATIFABAD, HYDERABAD':'HYDERABAD'})\n# df['billing_city'] = df['billing_city'].replace({'G-8/1, ISLAMABAD':'ISLAMABAD'})\n# df['billing_city'] = df['billing_city'].replace({'ORANGI TOWN KARACHI':'KARACHI'})\n# df['billing_city'] = df['billing_city'].replace({'CHASHMA, KUNDIAN, DISTRICT, MIANWALI':'MIANWALI'})\n# df['billing_city'] = df['billing_city'].replace({'MALAKWAL DISTRICT MANDI BAHAUDDIN':'MANDI BAHAUDDIN'})\n# df['billing_city'] = df['billing_city'].replace({'GULISTAN E JAUHAR KARACHI':'KARACHI'})\n# df['billing_city'] = df['billing_city'].replace({'JABOKA OKARA':'OKARA'})\n# df['billing_city'] = df['billing_city'].replace({'GHOURI TOWN, ISLAMABAD':'ISLAMABAD'})\n# df['billing_city'] = df['billing_city'].replace({'GULZAR E HIJRI':'KARACHI'})\n# df['billing_city'] = df['billing_city'].replace({'GULBERG TOWN KARACHI CENTRAL':'KARACHI'})\n# df['billing_city'] = df['billing_city'].replace({'KAHNA NAU LAHORE':'LAHORE'})\n# df['billing_city'] = df['billing_city'].replace({'FAZAL COLONY NEAR EMCO FACTORY SHEIKHUPURA ROAD LAHORE':'LAHORE'})\n# df['billing_city'] = df['billing_city'].replace({'ISLAAM ABAD':'ISLAMABAD'})\n# df['billing_city'] = df['billing_city'].replace({'TEHSIL ALLAI DISST BATTAGRAM':'BATTAGRAM'})\n# df['billing_city'] = df['billing_city'].replace({'SWABI PESHAWAR':'SWABI'})\n# df['billing_city'] = df['billing_city'].replace({'FEROZ PUR ROAD LAHORE':'LAHORE'})\n# df['billing_city'] = df['billing_city'].replace({'SAKRAND DIST:NAWABSHAH':'NAWABSHAH'})\n# df['billing_city'] = df['billing_city'].replace({'SARGODHA SILANWALI ROAD HAMEED TOWN':'SARGODHA'})\n# df['billing_city'] = df['billing_city'].replace({'BAGH AZAD KASHMIR':'BAGH'})\n# df['billing_city'] = df['billing_city'].replace({'KAMEER DARBAR HAZRAT BABA MUHAMMAD PANHA DISTRICT SAHIWAL':'SAHIWAL'})\n# df['billing_city'] = df['billing_city'].replace({'RAWAL PINDI':'RAWALPINDI'})\n# df['billing_city'] = df['billing_city'].replace({'FAISAL ABAD':'FAISALABAD'})\n# df['billing_city'] = df['billing_city'].replace({'SIALKOT PASRUR':'SIALKOT'})\n# df['billing_city'] = df['billing_city'].replace({'PESHAWAR GULBAHAR NO.1':'PESHAWAR'})\n# df['billing_city'] = df['billing_city'].replace({'TAXILA, RAWALPINDI':'RAWALPINDI'})\n# df['billing_city'] = df['billing_city'].replace({'NAWAB SHAH':'NAWABSHAH'})\n# df['billing_city'] = df['billing_city'].replace({'CHAKDARA LOWER DIR':'DIR'})\n# df['billing_city'] = df['billing_city'].replace({'LALIAN DISTRICT CHINIOT':'CHINIOT'})\n# df['billing_city'] = df['billing_city'].replace({'BAHWALPUR':'BAHAWALPUR'})\n# df['billing_city'] = df['billing_city'].replace({'DASKA, SIALKOT':'SIALKOT'})\n# df['billing_city'] = df['billing_city'].replace({'UPPER DIR':'DIR'})\n# df['billing_city'] = df['billing_city'].replace({'MAKHAI TIMERGATA':'TIMERGATA'})\n# df['billing_city'] = df['billing_city'].replace({'HAZARA TOWN QUETTA':'QUETTA'})\n# df['billing_city'] = df['billing_city'].replace({'QILA DIDAR SINGH, GUJRANWALA':'GUJRANWALA'})\n# df['billing_city'] = df['billing_city'].replace({'F-17/2 ISLAMABAD':'ISLAMABAD'})\n# df['billing_city'] = df['billing_city'].replace({'ALKHIDMAT RAAZI HOSPITAL CBR TOWN':'ISLAMABAD'})\n# df['billing_city'] = df['billing_city'].replace({'ZAFARWAL ZILLA NAROWAL':'NAROWAL'})\n# df['billing_city'] = df['billing_city'].replace({'DINGA, TEHSIL KHARIAN,DISTRICT GUJRAT.':'GUJRAT'})\n# df['billing_city'] = df['billing_city'].replace({'BALDIA TOWN':'KARACHI'})\n# df['billing_city'] = df['billing_city'].replace({'TEH: DASKA/ DISTT: SIALKOT':'SIALKOT'})\n# df['billing_city'] = df['billing_city'].replace({'MUZAFFARGARH PAKISTAN':'MUZAFFARGARH'})\n# df['billing_city'] = df['billing_city'].replace({'JOHAR TOWN, LAHORE':'LAHORE'})\n# df['billing_city'] = df['billing_city'].replace({'B?GH AZAD KASHMIR':'BAGH'})\n# df['billing_city'] = df['billing_city'].replace({'ARIFWALA DISTRICT PAKPATTAN':'ARIFWALA'})\n# df['billing_city'] = df['billing_city'].replace({'LYYAH':'LAYYAH'})\n# df['billing_city'] = df['billing_city'].replace({'M. B DIN':'MANDI BAHAUDDIN'})\n# df['billing_city'] = df['billing_city'].replace({'MULTAN/LODHRAN':'MULTAN'})\n# df['billing_city'] = df['billing_city'].replace({'MIRPUR AZAD KASHMIR':'MIRPUR'})\n# df['billing_city'] = df['billing_city'].replace({'FATEH PUR DISTRICT LAYYAH':'LAYYAH'})\n# df['billing_city'] = df['billing_city'].replace({'PESHAWAR RAHATABAD':'PESHAWAR'})\n# df['billing_city'] = df['billing_city'].replace({'USTA MUHAMMAD DISTRICT JAFFERABAD':'USTA MUHAMMAD'})\n# df['billing_city'] = df['billing_city'].replace({'BERON YAKATOOT ZARGAR ABAD PESHAWAR CITY':'PESHAWAR'})\n# df['billing_city'] = df['billing_city'].replace({'KOTLA JAM DISTRICT BHAKKAR':'BHAKKAR'})\n# df['billing_city'] = df['billing_city'].replace({'USMAN WALA DISTRICT KASUR PUNJAB PAKISTAN':'KASUR'})\n# df['billing_city'] = df['billing_city'].replace({'BALAKOT DISTRICT MANSEHRA':'MANSEHRA'})\n# df['billing_city'] = df['billing_city'].replace({'AHMAD PUR SIAL/JHANG':'JHANG'})\n# df['billing_city'] = df['billing_city'].replace({'KARACHI/MALIR/QUAIDABAD':'KARACHI'})\n# df['billing_city'] = df['billing_city'].replace({'USLAMABAF':'ISLAMABAD'})\n# df['billing_city'] = df['billing_city'].replace({'BHIMBER AZAD KASHMIR':'BHIMBER'})\n# df['billing_city'] = df['billing_city'].replace({'SITA ROAD RAHMANI NAGHAR DISTRICT DADU':'DADU'})\n# df['billing_city'] = df['billing_city'].replace({'MANGAT MANDI BAHA UD DIN':'MANDI BAHAUDDIN'})\n# df['billing_city'] = df['billing_city'].replace({'TEH:DASKA/ DISTT: SIALKOT':'SIALKOT'})\n# df['billing_city'] = df['billing_city'].replace({'PINDI GHEB DISTRICT ATTOCK':'ATTOCK'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# @arindam et al.\n\n# Source: https://simplemaps.com/data/pk-cities\n\npakistan_top_cities = ['karachi', 'lahore', 'sialkot', 'faisalabad', 'rawalpindi',\n       'peshawar', 'saidu sharif', 'multan', 'gujranwala', 'islamabad',\n       'quetta', 'bahawalpur', 'sargodha', 'new mirpur', 'chiniot',\n       'sukkur', 'larkana', 'shekhupura', 'jhang', 'rahimyar khan',\n       'gujrat', 'kasur', 'mardan', 'mingaora', 'dera ghazi khan',\"dgk\"\n       'nawabshah', 'sahiwal', 'mirpur khas', 'okara', 'burewala',\n       'jacobabad', 'saddiqabad', 'kohat', 'muridke', 'muzaffargarh',\n       'khanpur', 'gojra', 'bahauddin', 'abbottabad', 'dadu',\n       'khuzdar', 'pakpattan', 'tando allahyar', 'vihari', 'jaranwala',\n       'kamalia', 'kot addu', 'nowshera', 'swabi', 'dera ismail khan',\n       'chaman', 'charsadda', 'kandhkot', 'hasilpur', 'muzaffarabad',\n       'mianwali', 'jalalpur\",\"jattan', 'bhakkar', 'zhob', 'kharian',\n       'mian channun', 'jamshoro', 'pattoki', 'harunabad',\n       'toba tek singh', 'shakargarh', 'hujra\", \"shah\", \"muqim', 'kabirwala',\n       'mansehra', 'lala musa', 'nankana sahib', 'bannu', 'timargara',\n       'parachinar', 'gwadar', 'abdul hakim', 'hassan\", \"abdal', 'tank',\n       'hangu', 'risalpur cantonment', 'karak', 'kundian', 'umarkot',\n       'chitral', 'dainyor', 'kulachi', 'kotli', 'gilgit',\n       'hyderabad', 'narowal', 'khairpur', \"mir’s\", 'khanewal', 'jhelum',\n       'haripur', 'shikarpur', 'rawala kot', 'hafizabad', 'lodhran',\n       'malakand', 'attock', 'batgram', 'matiari', 'ghotki',\n       'firoz','naushahro', 'alpurai', 'bagh', 'daggar', 'bahawalnagar',\n       'leiah', 'tando muhammad khan', 'chakwal', 'khushab', 'badin',\n       'lakki', 'rajanpur', 'dera allahyar', 'shahdad kot', 'pishin',\n       'sanghar', 'upper dir', 'thatta', 'dera murad jamali', 'kohlu',\n       'mastung', 'dasu', 'athmuqam', 'loralai', 'barkhan',\n       'musa khel bazar', 'ziarat', 'gandava', 'sibi', 'dera bugti',\n       'eidgah', 'turbat', 'uthal', 'chilas', 'kalat', 'panjgur', 'gakuch',\n       'qila', 'saifullah', 'kharan', 'aliabad', 'awaran', 'dalbandin']\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"single_word_cities = df[df[\"billing_city\"].str.split().apply(len) == 2][\"billing_city\"].unique()\nsingle_word_cities[:20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def clean_city(row):\n    address = row.billing_city.split()\n    add = set()\n    for a in address:\n        a = a.strip()\n        if a:\n            add.add(a)\n    for city in pakistan_top_cities:\n        if row.billing_city.__contains__(city):\n            return city\n        \n    for a in add:\n        for c in pakistan_top_cities:\n            if nltk.edit_distance(a, c) <= 5: # considering spelling mistakes upto 5 letters\n                return c\n    return row.billing_city","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of cities before cleaning\ndf[\"billing_city\"].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"billing_city\"] = df.apply(clean_city, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['billing_city'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['billing_city'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Convert the 'order_date' column to datetime format"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# df['order_date']= pd.to_datetime(df['order_date'])\n \n# #Extracting year,month and day\n# df['year'] = df['order_date'].apply(lambda x : x.year)\n# df['month'] = df['order_date'].apply(lambda x : x.month_name)\n# df['day'] = df['order_date'].apply(lambda x : x.day)\n# df['weekday'] = df['order_date'].apply(lambda x : x.weekday())\n\n# #Rearranging the columns\n# df_new=df[['order_number', 'order_status', 'book_name', 'order_date', 'billing_city', 'year', 'month', 'day','weekday']]\n# df_new.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Convert the 'day' column to day_name"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"\ndf['order_date']= pd.to_datetime(df['order_date'])\n \n#Extracting year,month and day\ndf['year'] = df['order_date'].apply(lambda x : x.year)\ndf['month'] = df['order_date'].apply(lambda x : x.month)\ndf['day'] = df['order_date'].apply(lambda x : x.day_name())\ndf['weekday'] = df['order_date'].apply(lambda x : x.weekday())\n\n#Rearranging the columns\ndf_new=df[['order_number', 'order_status', 'book_name', 'order_date', 'billing_city', 'year', 'month', 'day','weekday']]\ndf_new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new.year.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# find out how much bought is total on which day"},{"metadata":{"trusted":true},"cell_type":"code","source":"# \ndaily_sales = df.groupby([\"day\"])[\"book_name\"].agg([\"count\"]).reset_index()\ndaily_sales.sort_values(\"day\",ascending = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12,8))\nsns.barplot(x =daily_sales[\"day\"], y =daily_sales[\"count\"],color = \"Blue\",label = \"count\")\nplt.xlabel(\"Days\")\nplt.ylabel(\"item\")\nplt.title(\"Sales by Days\")\nplt.xticks(rotation = 60)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# find out how much bought is total on which month"},{"metadata":{"trusted":true},"cell_type":"code","source":"# \nmonth_sales = df.groupby([\"month\"])[\"book_name\"].agg([\"count\"]).reset_index()\nmonth_sales.sort_values(\"month\",ascending = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12,8))\nsns.barplot(x =month_sales[\"month\"], y =month_sales[\"count\"],color = \"Blue\",label = \"count\")\nplt.xlabel(\"month\")\nplt.ylabel(\"Total Number of Books Buy\")\nplt.title(\"Sales by Month\")\nplt.xticks(rotation = 60)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sales by month and year"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import holoviews as hv\nfrom holoviews import opts\nhv.extension('bokeh')\n\ndf1=df_new.groupby(['year']).filter(lambda x: (x['year'] == 2020).any())\ndf2=df_new.groupby(['year']).filter(lambda x: (x['year'] == 2021).any())\ndf3=df_new.groupby(['year']).filter(lambda x: (x['year'] == 2019).any())\n\n#Plotting monthly data of number of quantity purchased in 2020 and 2021 \nsales_2019=hv.Bars(df3.groupby(['month'])['book_name'].count()).opts(ylabel=\"# of items\", title='# of items sold in 2019')\nsales_2020=hv.Bars(df1.groupby(['month'])['book_name'].count()).opts(ylabel=\"# of items\", title='# of items sold in 2020')\nsales_2021=hv.Bars(df2.groupby(['month'])['book_name'].count()).opts(ylabel=\"# of items\", title='# of items sold in 2021')\n\n#Merging both plots\n(sales_2019 + sales_2020 + sales_2021).opts(opts.Bars(width=380, height=300,tools=['hover'],show_grid=True))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Week Days Sale"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import altair as alt\n\n#Converting weekday variable to category\ntemp=df_new.copy()\ntemp['qty_purchased']=df_new['order_number'].map(df_new['order_number'].value_counts())\n\n#Slicing first 5000 rows as altair library can't plot any data which has record beyond that\ntemp1=temp[:5000]\ntemp1.columns\ntemp1.weekday = temp1.weekday.astype('category') \n\n#Creating a new dataframe which has the frequency of weekdays\nweekday_bin=temp1['weekday'].value_counts().to_frame().reset_index().rename(columns={'index':'weekday','weekday':'count'})\n\n#Plotting bar chart\nbars = alt.Chart(weekday_bin).mark_bar(color=\"darkorange\").encode(\n    x='weekday',\n    y=alt.Y(\"count\",title='Number of purchases')\n)\n\n#Adding data labels\ntext = bars.mark_text(\n    align='center',\n    baseline='middle',\n    dy=-7 ,\n    size=15,\n).encode(\n    text='count',\n    tooltip=[alt.Tooltip('weekday'),\n            alt.Tooltip('count')]\n)\n\n#Combining both\n(bars + text).properties(\n    width=800,\n    height=400,\n    title=\"Number of quantity purchases across weekdays\"\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Top 10 book sales"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n\n#Setting plot style\nplt.figure(figsize = (15, 8))\nplt.style.use('seaborn-white')\n\n#Top 10 fast moving products\nplt.subplot(1,2,1)\nax=sns.countplot(y=\"book_name\", hue=\"year\", data=df_new, palette=\"pastel\",\n              order=df_new.book_name.value_counts().iloc[:10].index)\n\nax.set_xticklabels(ax.get_xticklabels(),fontsize=11,rotation=40, ha=\"right\")\nax.set_title('Top 10 book sales',fontsize= 22)\nax.set_xlabel('Total # of items purchased',fontsize = 20) \nax.set_ylabel('Top 10 items', fontsize = 20)\nplt.tight_layout()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 10 Books sale by bottom"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Bottom 10 fast moving products\nplt.subplot(1,2,2)\nax=sns.countplot(y=\"book_name\", hue=\"year\", data=df_new, palette=\"pastel\",\n              order=df_new.book_name.value_counts().iloc[-10:].index)\nax.set_xticklabels(ax.get_xticklabels(),fontsize=11,rotation=40, ha=\"right\")\nax.set_title('10 Books sale by bottom',fontsize= 22)\nax.set_xlabel('Total # of books purchased',fontsize = 20) \nax.set_ylabel('Bottom 10 book', fontsize = 20)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_new.assign(Book=df_new.book_name.str.split(\"/\")).explode('book_name')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Which words used mostly "},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud,STOPWORDS\n\n#Wordcloud\nwordcloud = WordCloud(\n    width = 3000,\n    height = 2000,\n    background_color = 'white').generate(\"\".join(str(df_new['book_name'])))\nfig = plt.figure(\n    figsize = (50, 30),\n    facecolor = 'k',\n    edgecolor = 'k')\n\n#Display plot\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Seperate Book with \"/\""},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_new.assign(book_name_seperate=df_new.book_name.str.split(\"/\")).explode('book_name')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Top 10 City"},{"metadata":{"trusted":true},"cell_type":"code","source":"city_sales1 = df_new['billing_city'].value_counts()[:10].index.tolist()\ncity_sales2 = df_new['billing_city'].value_counts().unique()\ncity_sales = list(zip(city_sales1, city_sales2)) \ncity_sales = pd.DataFrame(city_sales, \n                  columns = ['billig_city', 'counts']) \ncity_sales","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12,8))\nsns.barplot(x =city_sales[\"billig_city\"], y =city_sales[\"counts\"],color = \"Blue\",label = \"count\")\nplt.xlabel(\"City\")\nplt.ylabel(\"Total numbers of sales\")\nplt.title(\"Sales by City\")\nplt.xticks(rotation = 60)\nplt.legend()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# import plotly.express as px\n\n# fig = px.sunburst(df_new, path=['year', 'month', 'day', 'book_name'],title=\"Dont Forget to Click Chart to Examine Deeply \")\n# fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# targets = list(dict(df_new['book_name'].value_counts()).keys())\n# values = list(dict(df_new['book_name'].value_counts()).values())\n\n# fig = px.pie(\n#     values=values, \n#     names=targets,\n#     title='Book Name',\n#     color_discrete_sequence=['darkcyan', 'lawngreen']\n# )\n# fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# import squarify\n\n# plt.figure(figsize = (50, 30))\n# squarify.plot(sizes = df_new.book_name.value_counts().values, alpha = 0.8,\n#               label = df_new.book_name.unique(), text_kwargs={'fontsize':18})\n# plt.title('Book Name', fontsize = 30)\n# plt.axis('off')\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Apriori Algorithm"},{"metadata":{},"cell_type":"markdown","source":"**Now, we need to run apriori algorithm to get insight that if a customer buys one item which item he/she buys next.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"hot_encoded_df = df_new.groupby(['order_number', 'book_name'])['book_name'].count().unstack().reset_index().fillna(0).set_index('order_number')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hot_encoded_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Above lineAbove line of code is transfrom data to make items as columns and each transaction as a row and count same Items bought in one transaction but fill other cloumns of the row with 0 to represent item which are not bought.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def encode_units(x):\n    if x <= 0:\n        return 0\n    if x >= 1:\n        return 1\nhot_encoded_df = hot_encoded_df.applymap(encode_units)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"frequent_itemsets = apriori(hot_encoded_df, min_support=0.01, use_colnames=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Support is an indication of how frequently the itemset appears in the dataset.\n* Confidence is an indication of how often the rule has been found to be true.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"rules = association_rules(frequent_itemsets, metric='lift', min_threshold=1)\nrules.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We only want to see the rules where confidence is greater than or equal to 50% so:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"rules[ (rules['lift'] >= 1) & (rules['confidence'] >= 0.5)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For instance from the last rule we can see that (مشین لرننگ, ARTIFICIAL INTELLIGENCE) and (ڈیٹا سائنس) are commonly bought together. This makes sense since people who purchase (مشین لرننگ, ARTIFICIAL INTELLIGENCE) would like to have (ڈیٹا سائنس) with it.\n\nThe support value for the this rule is 0.016109. This number is calculated by dividing the number of transactions containing toast divided by total number of transactions. The confidence level for the rule is 0.04995 which shows that out of all the transactions that contain toast , 76.69% of the transactions also contain (ڈیٹا سائنس). Finally, the lift of 15.34 tells us that (مشین لرننگ, ARTIFICIAL INTELLIGENCE) is 15.34 times more likely to be bought by the customers who buy (مشین لرننگ, ARTIFICIAL INTELLIGENCE) compared to the default likelihood of the sale of (ڈیٹا سائنس).\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"support = rules['support'] #rules.to_numpy(columns=['support']) #as_matrix\nconfidence = rules['confidence'] #rules.to_numpy(columns=['confidence']) \nimport seaborn as sns\n\nfor i in range (len(support)):\n    support[i] = support[i]\n    confidence[i] = confidence[i]\n    \nplt.title('Assonciation Rules')\nplt.xlabel('support')\nplt.ylabel('confidance')\nsns.regplot(x=support, y=confidence, fit_reg=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# What's Next?"},{"metadata":{},"cell_type":"markdown","source":"* Try to clean city column with fuzzywuzzy\n* Predict next hour order\n* Predict next day order"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}