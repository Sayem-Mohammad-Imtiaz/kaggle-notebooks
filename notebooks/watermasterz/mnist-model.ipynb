{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Training a Machine Learning model for the MNIST Handwritten digits dataset","metadata":{}},{"cell_type":"markdown","source":"## 1. Introduction\n\nMNIST (\"Modified National Institute of Standards and Technology\") Handwritten Digit recogition is often regarded as the \"Hello World\" of Machine Learning. This project involvs creating a Machine Learning model using a simple Convolutional Neural Network to further enhance the capabilities of the model in recognising the Handwritten Digits. We then run and test the model on user inputs.\n\nWe begin by: \n**Importing the required libraries**\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\nfrom keras.models import Sequential, Model\nfrom keras.layers import Conv2D, Lambda, MaxPooling2D # convolution layers\nfrom keras.layers import Dense, Dropout, Flatten # core layers\n\nfrom keras.layers.normalization import BatchNormalization\n\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom keras.utils.np_utils import to_categorical","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-09-03T06:10:48.191761Z","iopub.execute_input":"2021-09-03T06:10:48.192207Z","iopub.status.idle":"2021-09-03T06:10:48.201103Z","shell.execute_reply.started":"2021-09-03T06:10:48.192169Z","shell.execute_reply":"2021-09-03T06:10:48.199786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Data Preprocessing\n\n### 2.1 Importing the datasets\n\nI found a dataset that was already split into training set and testing set, both are subsets of the MNIST Handwritten digits dataset","metadata":{}},{"cell_type":"code","source":"import os\ntrain = pd.read_csv('../input/mnist-in-csv/mnist_train.csv')\ntest = pd.read_csv('../input/mnist-in-csv/mnist_test.csv')\nprint(\"Data Ready\")","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:11:32.171039Z","iopub.execute_input":"2021-09-03T06:11:32.171376Z","iopub.status.idle":"2021-09-03T06:11:37.561108Z","shell.execute_reply.started":"2021-09-03T06:11:32.171345Z","shell.execute_reply":"2021-09-03T06:11:37.560292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Training data size is {train.shape}\\nTesting data size is {test.shape}\")","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:11:39.56106Z","iopub.execute_input":"2021-09-03T06:11:39.561372Z","iopub.status.idle":"2021-09-03T06:11:39.565796Z","shell.execute_reply.started":"2021-09-03T06:11:39.561343Z","shell.execute_reply":"2021-09-03T06:11:39.564949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Set data features and labels**\n","metadata":{}},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:12:23.754715Z","iopub.execute_input":"2021-09-03T06:12:23.755072Z","iopub.status.idle":"2021-09-03T06:12:23.783707Z","shell.execute_reply.started":"2021-09-03T06:12:23.755042Z","shell.execute_reply":"2021-09-03T06:12:23.782883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train.drop(['label'], 1).values\ny = train['label'].values\ntest_x = test.drop(['label'],1).values","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:12:44.411456Z","iopub.execute_input":"2021-09-03T06:12:44.411805Z","iopub.status.idle":"2021-09-03T06:12:44.540669Z","shell.execute_reply.started":"2021-09-03T06:12:44.411774Z","shell.execute_reply":"2021-09-03T06:12:44.539665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.2 Normalization\nWe perform a grayscale normalization which reduces the time as well as avoids looking for useless details in the image","metadata":{}},{"cell_type":"code","source":"X = X / 255.0\ntest_x = test_x / 255.0","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:12:46.122791Z","iopub.execute_input":"2021-09-03T06:12:46.123164Z","iopub.status.idle":"2021-09-03T06:12:46.282669Z","shell.execute_reply.started":"2021-09-03T06:12:46.123133Z","shell.execute_reply":"2021-09-03T06:12:46.28191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.3 Reshaping\nReshape image in 3 dimensions (height = 28px, width = 28px , canal = 1) \n\ncanal = 1:  For gray scale","metadata":{}},{"cell_type":"code","source":"X = X.reshape(-1,28,28,1)\ntest_x = test_x.reshape(-1,28,28,1)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:12:47.448667Z","iopub.execute_input":"2021-09-03T06:12:47.449147Z","iopub.status.idle":"2021-09-03T06:12:47.453635Z","shell.execute_reply.started":"2021-09-03T06:12:47.449108Z","shell.execute_reply":"2021-09-03T06:12:47.452788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.4 Label Encoding\n**Encode labels to one-hot-vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])**","metadata":{}},{"cell_type":"code","source":"y = to_categorical(y)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:12:49.93433Z","iopub.execute_input":"2021-09-03T06:12:49.934661Z","iopub.status.idle":"2021-09-03T06:12:49.940297Z","shell.execute_reply.started":"2021-09-03T06:12:49.934631Z","shell.execute_reply":"2021-09-03T06:12:49.939424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n### 2.5 Split training and valdiation set\nThe validation set is to evaluate the performance of the model\n","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:12:52.807085Z","iopub.execute_input":"2021-09-03T06:12:52.807416Z","iopub.status.idle":"2021-09-03T06:12:53.352959Z","shell.execute_reply.started":"2021-09-03T06:12:52.807386Z","shell.execute_reply":"2021-09-03T06:12:53.352116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Visualizing the Data**","metadata":{}},{"cell_type":"code","source":"X_train__ = X_train.reshape(X_train.shape[0], 28, 28)\n\nfig, axis = plt.subplots(1, 4, figsize=(20, 10))\nfor i, ax in enumerate(axis.flat):\n    ax.imshow(X_train__[i], cmap='binary')\n    digit = y_train[i].argmax()\n    ax.set(title = f\"Real Number is {digit}\");","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:12:57.150335Z","iopub.execute_input":"2021-09-03T06:12:57.150667Z","iopub.status.idle":"2021-09-03T06:12:57.642504Z","shell.execute_reply.started":"2021-09-03T06:12:57.150636Z","shell.execute_reply":"2021-09-03T06:12:57.641729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Normalization**\n","metadata":{}},{"cell_type":"code","source":"mean = np.mean(X_train)\nstd = np.std(X_train)\n\ndef standardize(x):\n    return (x-mean)/std","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:13:07.584126Z","iopub.execute_input":"2021-09-03T06:13:07.584483Z","iopub.status.idle":"2021-09-03T06:13:07.815041Z","shell.execute_reply.started":"2021-09-03T06:13:07.58445Z","shell.execute_reply":"2021-09-03T06:13:07.813964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 50\nbatch_size = 64","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:13:10.69448Z","iopub.execute_input":"2021-09-03T06:13:10.694798Z","iopub.status.idle":"2021-09-03T06:13:10.698843Z","shell.execute_reply.started":"2021-09-03T06:13:10.694767Z","shell.execute_reply":"2021-09-03T06:13:10.69798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Convolutional Neural Network\n\n## 3.1 Defining the model\n\nThis uses a Keras Sequential API to create a CNN, we start from the input and add the layers one by one.\n\nThe first layer is the convolutional (Conv2D) layer. We choose 32 filters for the first-two conv2D layers and 64 filters for the second-two layers and 128 filters for third-two layers and 256 for the last one. Each filter transforms a part of the image as defined by the kernel size using the kernel filter. The kernel filter matrix is applied on the whole image. Filters can be seen as a transformation of the image.\n\nThe CNN can isolate features that are useful everywhere from these transformed images (feature maps).\n\nThe second important layer in CNN is the pooling (MaxPool2D) layer. This layer simply acts as a downsampling filter. It looks at the 2 neighboring pixels and picks the maximal value. These are used to reduce computational cost, and to some extent also reduce overfitting.\n\nCombining convolutional and pooling layers, CNN is able to combine local features and learn more global features of the image.\n\n'relu' is the rectifier (activation function max(0,x)). The rectifier activation function is used to add non linearity to the network.\n\nThe Flatten layer is used to convert the final feature maps into a single 1D vector. This flattening step is needed so that we can make use of fully connected layers after some convolutional/maxpool layers. It combines all the found local features of the previous convolutional layers.\n\nIn the end we use the features in two fully-connected (Dense) layers which is just an artificial neural networks (ANN) classifier. In the last layer(Dense(10,activation=\"softmax\")) the net outputs distribution of probability of each class i.e. [0,0,0.98,0,0,0,0,0,0,0]","metadata":{}},{"cell_type":"markdown","source":"**Model Definition**","metadata":{}},{"cell_type":"code","source":"model=Sequential()\n\n \nmodel.add(Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\", input_shape=(28,28,1)))\nmodel.add(Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\"))\n\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\nmodel.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\n\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())    \nmodel.add(Conv2D(filters=256, kernel_size = (3,3), activation=\"relu\"))\n\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Flatten())\nmodel.add(BatchNormalization())\nmodel.add(Dense(512,activation=\"relu\"))\n\nmodel.add(Dense(10,activation=\"softmax\"))\n\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:35:19.051173Z","iopub.execute_input":"2021-09-03T06:35:19.051495Z","iopub.status.idle":"2021-09-03T06:35:19.17019Z","shell.execute_reply.started":"2021-09-03T06:35:19.051465Z","shell.execute_reply":"2021-09-03T06:35:19.169296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Summary","metadata":{}},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:35:25.002938Z","iopub.execute_input":"2021-09-03T06:35:25.003278Z","iopub.status.idle":"2021-09-03T06:35:25.016331Z","shell.execute_reply.started":"2021-09-03T06:35:25.003248Z","shell.execute_reply":"2021-09-03T06:35:25.015428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.2 Augmenting the data\n\nThis step was necessary because we are dealing with the user input, the user is free to draw anything he wants, so the drawing of the digits might not always be in perfect orientation. Hence we need to train the model for handiling such situations\n\nI found out the following data augmentation techniques that are frequently used by people for further improving the accurary of their models.\n\nThe improvement:\n - Without data augmentation, Accuracy:  98.114%\n - With data augmentation, Accuracy:  99.67% \n","metadata":{}},{"cell_type":"code","source":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\ntrain_gen = datagen.flow(X_train, y_train, batch_size=batch_size)\ntest_gen = datagen.flow(X_test, y_test, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:35:29.90833Z","iopub.execute_input":"2021-09-03T06:35:29.908649Z","iopub.status.idle":"2021-09-03T06:35:29.989597Z","shell.execute_reply.started":"2021-09-03T06:35:29.908617Z","shell.execute_reply":"2021-09-03T06:35:29.988813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.3 Model Training","metadata":{}},{"cell_type":"code","source":"# Fit the model\nhistory = model.fit_generator(train_gen, \n                              epochs = 2, \n                              steps_per_epoch = X_train.shape[0] // batch_size,\n                              validation_data = test_gen,\n                              validation_steps = X_test.shape[0] // batch_size)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:35:32.778323Z","iopub.execute_input":"2021-09-03T06:35:32.77864Z","iopub.status.idle":"2021-09-03T06:36:10.460143Z","shell.execute_reply.started":"2021-09-03T06:35:32.778609Z","shell.execute_reply":"2021-09-03T06:36:10.459423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras.backend as K\n\ninputs = model.input\noutputs = K.function([inputs], [layer.output for layer in model.layers])\n\n","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:39:02.038903Z","iopub.execute_input":"2021-09-03T06:39:02.039252Z","iopub.status.idle":"2021-09-03T06:39:02.055774Z","shell.execute_reply.started":"2021-09-03T06:39:02.039221Z","shell.execute_reply":"2021-09-03T06:39:02.055089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Call this function for getting the outputs for each layer\nlen(outputs([X_train[0:1]]))","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:41:41.897818Z","iopub.execute_input":"2021-09-03T06:41:41.898177Z","iopub.status.idle":"2021-09-03T06:41:41.915084Z","shell.execute_reply.started":"2021-09-03T06:41:41.898146Z","shell.execute_reply":"2021-09-03T06:41:41.914234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_test)\nX_test__ = X_test.reshape(X_test.shape[0], 28, 28)\n\nfig, axis = plt.subplots(4, 4, figsize=(12, 14))\nfor i, ax in enumerate(axis.flat):\n    ax.imshow(X_test__[i], cmap='binary')\n    ax.set(title = f\"Real Number is {y_test[i].argmax()}\\nPredict Number is {y_pred[i].argmax()}\");","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:40:21.134172Z","iopub.execute_input":"2021-09-03T06:40:21.134489Z","iopub.status.idle":"2021-09-03T06:40:23.475464Z","shell.execute_reply.started":"2021-09-03T06:40:21.13446Z","shell.execute_reply":"2021-09-03T06:40:23.47459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Saving the trained Model","metadata":{}},{"cell_type":"code","source":"model.save(\"mnist_trained_99.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:40:54.372459Z","iopub.execute_input":"2021-09-03T06:40:54.372796Z","iopub.status.idle":"2021-09-03T06:40:54.452288Z","shell.execute_reply.started":"2021-09-03T06:40:54.372764Z","shell.execute_reply":"2021-09-03T06:40:54.451479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Part 1 finishes here(Model Training)","metadata":{}},{"cell_type":"markdown","source":"`___________________________________________________________________________________________________________`","metadata":{}},{"cell_type":"markdown","source":"# Part 2 \n\n### Using the model to predict the digits","metadata":{}},{"cell_type":"markdown","source":"### Loading the model from the file\n","metadata":{}},{"cell_type":"code","source":"from keras.models import load_model\nmodel = load_model(\"./mnist_trained_99.h5\") # Path where the model is saved.\nprint(\"Model loaded successfully\")","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:41:06.129193Z","iopub.execute_input":"2021-09-03T06:41:06.129501Z","iopub.status.idle":"2021-09-03T06:41:06.346129Z","shell.execute_reply.started":"2021-09-03T06:41:06.12947Z","shell.execute_reply":"2021-09-03T06:41:06.345223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from skimage import color, io\nfrom skimage.transform import resize","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:41:07.255225Z","iopub.execute_input":"2021-09-03T06:41:07.255548Z","iopub.status.idle":"2021-09-03T06:41:07.493624Z","shell.execute_reply.started":"2021-09-03T06:41:07.255518Z","shell.execute_reply":"2021-09-03T06:41:07.492904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using the model to predict our custom handwritten digits","metadata":{}},{"cell_type":"code","source":"digits_folder = \"../input/handwritten-digits-images\"  # Folder containing the images of handwritten digits\nimages = os.listdir(digits_folder)  # Custom image list\n\n\nfig, axis = plt.subplots(4, 4, figsize=(12, 14))\nfor i, ax in enumerate(axis.flat):\n    image = io.imread(digits_folder + \"/\" + images[i])\n    ax.imshow(image, cmap='binary')\n    image = color.rgb2gray(image)\n    image_resized = resize(image, (28, 28, 1))\n    final = 1 - np.array(image_resized)\n    final = np.expand_dims(final, axis=0)\n    answer = model.predict(final)\n    ret_val = answer.argmax()\n    ax.set(title = f\"Predicted number: {ret_val}\");\n","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:41:08.795608Z","iopub.execute_input":"2021-09-03T06:41:08.795969Z","iopub.status.idle":"2021-09-03T06:41:11.278692Z","shell.execute_reply.started":"2021-09-03T06:41:08.795933Z","shell.execute_reply":"2021-09-03T06:41:11.277995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}