{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# Analysis and Prediction:\n## Indian Liver Patients -  records collected from North East of Andhra Pradesh, India"},{"metadata":{"_uuid":"3e73c704fecda2b1b45356bb4ddf6884107e0cd2"},"cell_type":"markdown","source":"__About the dataset__\n> This data set contains 416 liver patient records and 167 non liver patient records collected from North East of Andhra Pradesh, India. The \"Dataset\" column is a class label used to divide groups into liver patient (liver disease) or not (no disease). This data set contains 441 male patient records and 142 female patient records. Any patient whose age exceeded 89 is listed as being of age \"90\".\n\n> Based on chemical compounds(bilrubin,albumin,protiens,alkaline phosphatase) present in human body <br> \nand tests like SGOT , SGPT the outcome mentioned whether person is patient ie __needs to be diagnosed or not__."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Importing basic packages for data preprocessing\nimport numpy as np\nimport pandas as pd\nimport os\n# Importing packages for plotting\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce835b92420d03cb74ec9781cd5594b7ee0df990"},"cell_type":"code","source":"print(os.listdir(\"../input\"))\ndataset=pd.read_csv(\"../input/indian_liver_patient.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df90cefb29e8ded26c14b845a991dace42bdd03d"},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68e76b3ba466e7e09bd960361faf958e77a2c987"},"cell_type":"code","source":"dataset.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"00f408bd0074fd4d8c18d81f47663f7d63d74382"},"cell_type":"code","source":"dataset.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ce18a5498ae660a92611dde557a0d6ca2c66c9ed"},"cell_type":"markdown","source":"*Remove rows with missing values*\n> As I do not have expert knowledge on the values in the Albumin_and_Globulin_Ratio column, <br>\nI prefer to remove the 4 rows with missing values. \nThis is considering the fact that the total missing values are only 4."},{"metadata":{"trusted":true,"_uuid":"5a3648d68c0cdf853ca04f1639f38585bdbc6940"},"cell_type":"code","source":"dataset[dataset['Albumin_and_Globulin_Ratio'].isnull()].index.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"39f5a092f91317cf86946ef1f27338ec9ea3785b"},"cell_type":"code","source":"# Using the above row indexes, removing rows with missing values in Albumin_and_Globulin_Ratio column\ndataset.drop(dataset.index[[209,241,253,312]], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"079b5fcec47dc8f378bf6dcdebc61565d91803b0"},"cell_type":"code","source":"# Creating copy of the dataset\ndataset_orig = dataset.copy()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a070b1d03d49bb13e0dc40ed7b09af6d3b3ccec4"},"cell_type":"markdown","source":"----"},{"metadata":{"_uuid":"a68d290d0a890688ff616b690ad737e7cbdf1e01"},"cell_type":"markdown","source":"Label Encoder <br> \nTransforming character values to numerics"},{"metadata":{"trusted":true,"_uuid":"f3b2b8f7bd8a6d4e94295ad8d5dc1d933f406569"},"cell_type":"code","source":"# Transforming Gender column (indepedent variable) to numerics (0s and 1s)\n# Importing required package\nfrom sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8f5107e6ceeb382589598af311da67963367ddec"},"cell_type":"code","source":"labelencoder_x = LabelEncoder()\ndataset['Gender'] = labelencoder_x.fit_transform(dataset['Gender'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"a4baef9613b0c5ed549564ba9af59f4a42c144b3"},"cell_type":"code","source":"dataset['Gender'].head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c2500012591c32ad64a3b9fc58fa6fb13491250e"},"cell_type":"markdown","source":"#### 2. Finding out the Correlation of dependent data to the independent data"},{"metadata":{"trusted":true,"_uuid":"bf8438cfbed5ab6141a55c0fd9c58315db29aefc"},"cell_type":"code","source":"# Finding the correlation of independent data with the dependent data Income column \ncorrmat = dataset.corr()\ncorrmat","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7d5f4a1ac33e26c94b040712330bcdac47ca9c33"},"cell_type":"markdown","source":"*Visualization of the correlation*"},{"metadata":{"trusted":true,"_uuid":"7fcd23dc254092ea3edc600175af0a9e5e578ac5"},"cell_type":"code","source":"import seaborn as sns\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=1, cmap=\"YlGnBu\", square=True,linewidths=.5, annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"329f62ff6156bffd6696c24b38d3bdbb72fc1ca1"},"cell_type":"code","source":"# Obtaining top K columns which affects the Income the most\nk= 10\ncorrmat.nlargest(k, 'Dataset')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"14613b52a8f92a25881aa4d7e7ff1ad725a4230b"},"cell_type":"code","source":"# Replotting the heatmap with the above data\ncols = corrmat.nlargest(k, 'Dataset')['Dataset'].index\ncm = np.corrcoef(dataset[cols].values.T)\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(cm, cmap=\"YlGnBu\", cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6e37e533df3a52c7db1ba66832b5c6e0868a92f3"},"cell_type":"markdown","source":"#### Observation:\n> Visualization from the above chart indicate that the major contributors for whether the patient __needs to be diagnosed__ are the columns with *correlation value* greater than 0. <br>\nConsidering the fact that I have no domain expertise in the field of liver disease, I want to complete the analysis and arrive at a decent classification model, the results of which can be reviewed by the domain experts when the insights are projected. <br> \nThis being the case,  I am considering only __3 independent variables__ Albumin_and_Globulin_Ratio, Albumin and Total_Protiens will be considered"},{"metadata":{"_uuid":"65a2af1be669ef29f1ae17160216dc3648638cd2"},"cell_type":"markdown","source":"#### 3. Additional Visualization "},{"metadata":{"trusted":true,"_uuid":"710e8549162f4d5c385ed441dea3216f94c3de3e"},"cell_type":"code","source":"sns.catplot(x=\"Gender\", y=\"Age\", hue=\"Dataset\", data=dataset_orig)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"83ca2bcb6c682223c8e194218a88187363edcc69"},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(8, 6))\nsns.scatterplot(x=\"Albumin\", y=\"Albumin_and_Globulin_Ratio\", hue=\"Dataset\", style=\"Dataset\", data=dataset_orig);\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"113dbf6c5a4a30ed6ee0918061fc800f49795833"},"cell_type":"markdown","source":"## 4. Machine Learning\n> Based on the correlation matrix, considering only __3 independent variables__ Albumin_and_Globulin_Ratio, Albumin and Total_Protiens"},{"metadata":{"_uuid":"e350cceceed7b8cea8caece6f1f1fe2ced40cd8a"},"cell_type":"markdown","source":"*Splitting Independent (X) and dependent (y) variables*"},{"metadata":{"trusted":true,"_uuid":"993c079aa5f3d0143cf116ffc4cd4df7517fe38c"},"cell_type":"code","source":"# Splitting Independent (X) and dependent (y) variables from the dataset\nX = dataset[['Albumin_and_Globulin_Ratio', 'Albumin','Total_Protiens']]\ny = dataset [['Dataset']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"55b5770622da48d14fb24988f6195103d40f8eb7"},"cell_type":"code","source":"X[0:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"21705414c3c8f31ee23ab445c409af53997cf95b"},"cell_type":"code","source":"y[0:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"72179bb0a7ece5794abae2a7a095fb1f5deb3195"},"cell_type":"code","source":"# Splitting the data into Training and Test set with 80-20 ratio\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1378d363e064c42151943e4ee406447b776e8ff1"},"cell_type":"code","source":"print(\"X_train: \" , X_train.shape)\nprint(\"X_test: \", X_test.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7a79775845ee56a777e2ecdca079c60161ca5d30"},"cell_type":"markdown","source":"*Applying feature scale on training and test datasets* <br>\nFeature scaling is not applied on dependent variable 'Dataset' as it has values with only 1s and 2s"},{"metadata":{"trusted":true,"_uuid":"3cf5cce6875ca916761403d3f81b81acf08300db"},"cell_type":"code","source":"# Import required package\nfrom sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"919d55a492e5fb7cca9154dbcba0947d9595e992"},"cell_type":"code","source":"sc_X = StandardScaler()\nX_train = sc_X.fit_transform(X_train)\nX_test = sc_X.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fb41f93c67eb48b903d73e806e12c714017fa35a"},"cell_type":"code","source":"X_train[0:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"41b88b22e47424dba880c6f132a8f31d32914430"},"cell_type":"code","source":"X_test[0:5]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d0bb70230cbaaa8c2430f5e0baf50e13a74c4388"},"cell_type":"markdown","source":"### 4.a Logistic Regression"},{"metadata":{"trusted":true,"_uuid":"0d394c67266018a03f38cb6f5ae12e9e5aa4081d"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nclassifier_lr = LogisticRegression(random_state=0, solver='lbfgs')\nclassifier_lr.fit(X_train,y_train.values.reshape(-1,))\n# predict the test set result\ny_predLR = classifier_lr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cdf7578ebb51fcee52ed72ef12de3d99b16b2747"},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix \ncm = confusion_matrix(y_test, y_predLR)\ncm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"985b8307729a84af1b7b7836a26f038582fa5e84"},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test,y_predLR)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"83779a875f18faf87eae9731063be5c8273e3611"},"cell_type":"markdown","source":"### 4.b K-NN Regression\n*Fitting K Nearest Neighbors (KNN)* Classifier to the training set"},{"metadata":{"trusted":true,"_uuid":"5fadcefccb4c4ec6bf042bf20c6e1644a5b87a5e"},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nclassifierKNN = KNeighborsClassifier(n_neighbors=5,p=2, metric='minkowski')\nclassifierKNN.fit(X_train, y_train.values.reshape(-1,))\n\n# predict the test set result\ny_predKNN = classifierKNN.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d6c8057612c1e0996436b1af1da3b558b536b821"},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix \ncm = confusion_matrix(y_test, y_predKNN)\ncm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2f4d1864f36bd6255beda456f60c6e217fca0ad1"},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test,y_predKNN)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ae85a0230f76c5a4f59d53c121891e931556615f"},"cell_type":"markdown","source":"### 4.c SVM Regression\n*Fitting Support Vector Machine (SVM)* Classifier to the training set"},{"metadata":{"trusted":true,"_uuid":"7aff2e56f3701833b68467d6865dcb003dc23d18"},"cell_type":"code","source":"# Importing the required package \nfrom sklearn.svm import SVC\nclassifier_svm = SVC(kernel='linear', random_state=0)\nclassifier_svm.fit(X_train, y_train.values.reshape(-1,))\n# predict the test set result\ny_predSVM = classifier_svm.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"da87d285fa99078bb89bf26fb5fc29c7d65b5c8f"},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix \ncm = confusion_matrix(y_test, y_predSVM)\ncm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a8ac3014f8172e15370f4e1099792ecb5f02cf29"},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test,y_predSVM)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cc854016be2a15b071b83ef46cd54889e18dd4a4"},"cell_type":"markdown","source":"### 4.d Kernel SVM Regression\n*Fitting Naive Bayes* Classifier to the training set"},{"metadata":{"trusted":true,"_uuid":"8d46a07c24867b5a504837618ccc94a4132aacdd"},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nclassifierNB = GaussianNB()\nclassifierNB.fit(X_train, y_train.values.reshape(-1,))\n\n# predict the test set result\ny_predNB = classifierNB.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c6bbf77d0c2ee64b57a123f973a4493d2fc5662"},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix \ncm = confusion_matrix(y_test, y_predNB)\ncm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a54c45111fd4710f62c369b952764a89eb42acb3"},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test,y_predNB)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2a654ca01f877f2314dbdd167d96b85ebb768cc3"},"cell_type":"markdown","source":"## Conclusion\n> From the above classification models - Logistic, SVM and K-SVM classification models yeilded almsot the same accuracy of 70.12%<br>\nHowever, the __Naive Bayes regression model__ was the hieghest with 71.26% accuracy, compared to other 3 models tried above,"},{"metadata":{"trusted":true,"_uuid":"2ffdb4ddd3e1d8cf8c0288c637270befb43cc725"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}