{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"warnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/dataset-of-songs-in-spotify/genres_v2.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Only the columns song_name, unnamed: 0 and title are having missing values."},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['type','id','uri','track_href','analysis_url','song_name','Unnamed: 0', 'title']].head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The columns type,id,uri,track_href,analysis_url,song_name,Unnamed: 0,title has no significance. So dropping those columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['type','id','uri','track_href','analysis_url','song_name','Unnamed: 0', 'title'], axis = 1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Genre"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(df['genre'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = pd.DataFrame(df['genre'].value_counts()).plot(kind='bar',figsize=(8,5))\nax.set_title('Songs per Each Genre')\nax.set_xlabel('Genre')\nax.set_ylabel('Count')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Genre Pop has very less number of songs while the Underground Rap has nearly 6K songs"},{"metadata":{},"cell_type":"markdown","source":"## Danceability"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['danceability'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Energy"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['energy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## key"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['key'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig_dims = (8, 8)\nfig, ax = plt.subplots(figsize=fig_dims)\nsns.boxplot(x='key',y='genre',data=df, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loudness"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['loudness'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Mode"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['mode'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='mode',data=df, hue='genre', palette='bright')\nplt.legend(bbox_to_anchor=(1.01, 1),borderaxespad=0)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Speechiness"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['speechiness'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Acousticness"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['acousticness'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Instrumentalness"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['instrumentalness'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Liveness"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['liveness'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Valence"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['valence'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tempo"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['tempo'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## duration_ms"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['duration_ms'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## time signature"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['time_signature'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig_dims = (8, 4)\nfig, ax = plt.subplots(figsize=fig_dims)\nsns.countplot(x='time_signature',data=df, hue='genre', palette='bright', ax= ax)\nplt.legend(bbox_to_anchor=(1.01, 1),borderaxespad=0)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. There is no significance for the columns time_signature, mode and key since there is no proper insight from those data. So dropping those columns\n2. Danceability distribution looks like gaussian but not exactly gaussian distribution\n3. No conclusion can be drawn from the distribution of energy\n4. The distribution of loudness looks like gaussian distribution\n5. The distribution of speechiness and Acousticness resembles like chi-square-esque distribution\n6. Instrumentalness has more zero values\n7. valence - valence in music descibes the musical positiveness conveyed by the song. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry). (Source: https://towardsdatascience.com/what-makes-a-song-likeable-dbfdb7abe404#:~:text=Valence%3A%20Describes%20the%20musical%20positiveness,measure%20of%20intensity%20and%20activity)\n8. Tempo follows a normal distribution (almost)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['time_signature','mode','key'], axis = 1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Label Encoding the Genre column"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder,StandardScaler\ndf['genre_encoded'] = LabelEncoder().fit_transform(df['genre'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Label Encoder Mapping Reference\nle = LabelEncoder()\nle.fit(df['genre'])\nle_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\nprint(le_name_mapping)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig_dims = (10, 8)\nfig, ax = plt.subplots(figsize=fig_dims)\nsns.heatmap(df.corr(), annot=True, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()['genre_encoded']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Instrumentalness, duration_ms, energy are positively correlated while acousticness and tempo are negatively correlated"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop(['genre_encoded','genre'], axis = 1)\ny = df['genre_encoded']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.describe() ## Before Standardization","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tempo and duration_ms should be standardized"},{"metadata":{"trusted":true},"cell_type":"code","source":"std = StandardScaler().fit(X_train[['tempo']])\nX_train['tempo'] = std.transform(X_train[['tempo']])\nX_test['tempo'] = std.transform(X_test[['tempo']])\n\nstd = StandardScaler().fit(X_train[['duration_ms']])\nX_train['duration_ms'] = std.transform(X_train[['duration_ms']])\nX_test['duration_ms'] = std.transform(X_test[['duration_ms']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.describe() ## After Standardization","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Building"},{"metadata":{},"cell_type":"markdown","source":"### The metric should be Confusion Matrix and F1 score since it is a multi class classification. Accuracy can't be used for a multi class classification since interpretability is low"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import confusion_matrix,f1_score, accuracy_score\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_confusion_matrix(test_y, predict_y, plot_title):\n    C = confusion_matrix(test_y, predict_y)\n    labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n    cmap=sns.light_palette(\"green\")\n    # representing A in heatmap format\n    print(\"-\"*50, \"Confusion matrix\", \"-\"*50)\n    plt.figure(figsize=(15,12))\n    sns.heatmap(C, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n    plt.xlabel('Predicted Class')\n    plt.ylabel('Original Class')\n    plt.title(plot_title)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The confusion matrix function plots the confusion matrix for the given inputs"},{"metadata":{},"cell_type":"markdown","source":"## Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = {\"max_depth\":np.array([1, 2, 5, 10, 50, 100]), \"min_samples_split\":np.array([1, 5, 10, 50, 100, 500])}\ndt_clf = DecisionTreeClassifier(random_state=42)\nclf = GridSearchCV(dt_clf, parameters, cv=5, scoring='f1_micro', n_jobs=-1, verbose=10)\nclf.fit(X_train, y_train)\nprint(clf.best_estimator_)\nprint(clf.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = DecisionTreeClassifier(max_depth=10, min_samples_split=10, random_state=42)\nclf.fit(X_train,y_train)\ny_train_pred = clf.predict(X_train)\ny_pred = clf.predict(X_test)\n# Train Confusion Matrix\nplot_confusion_matrix(y_train,y_train_pred, 'Train Confusion Matrix')\n# Test Confusion Matrix\nplot_confusion_matrix(y_test,y_pred, 'Test Confusion Matrix')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Train F1 Score is {0}'.format(f1_score(y_train,y_train_pred,average='micro')))\nprint('Test F1 Score is {0}'.format(f1_score(y_test,y_pred,average='micro')))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = {\"n_estimators\":np.array([10,50,100,250,350,500,750,1000,2000,3000]) ,\"max_depth\":np.array([1,5,8,10,50,70,100]),\n              \"min_samples_split\":np.array([2,5,10,100,500])}\nrf_clf = RandomForestClassifier(random_state=42, n_jobs=-1)\nclf = RandomizedSearchCV(rf_clf, parameters, cv=5, scoring='f1_micro', n_jobs=-1, verbose=10)\nclf.fit(X_train, y_train)\nprint(clf.best_estimator_)\nprint(clf.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = RandomForestClassifier(max_depth=10, min_samples_split=10, n_estimators=750, n_jobs=-1, random_state=42)\nclf.fit(X_train,y_train)\ny_train_pred = clf.predict(X_train)\ny_pred = clf.predict(X_test)\n# Train Confusion Matrix\nplot_confusion_matrix(y_train,y_train_pred, 'Train Confusion Matrix')\n# Test Confusion Matrix\nplot_confusion_matrix(y_test,y_pred, 'Test Confusion Matrix')\nprint('Train F1 Score is {0}'.format(f1_score(y_train,y_train_pred,average='micro')))\nprint('Test F1 Score is {0}'.format(f1_score(y_test,y_pred,average='micro')))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## XGBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    'learning_rate':[0.01,0.03,0.05,0.1,0.15,0.2],\n     'n_estimators':[100,200,350,500,1000,2000],\n     'max_depth':[2,3,5,8,10],\n    'colsample_bytree':[0.1,0.3,0.5,1],\n    'colsample_bylevel':[0.1,0.3,0.5,1],\n    'reg_alpha' : [0.001,0.01,0.1,1,10],\n    'reg_lambda' : [0.001,0.01,0.1,1,10],\n    'subsample':[0.1,0.3,0.5,1]\n    }\nxgb = XGBClassifier(n_jobs = -1)\nclf = RandomizedSearchCV(xgb, params, cv=5, scoring='f1_micro', n_jobs=-1, verbose=10)\nclf.fit(X_train, y_train)\nprint(clf.best_estimator_)\nprint(clf.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.5, gamma=0, gpu_id=-1,\n              importance_type='gain', interaction_constraints='',\n              learning_rate=0.15, max_delta_step=0, max_depth=2,\n              min_child_weight=1, monotone_constraints='()',\n              n_estimators=500, n_jobs=-1, num_parallel_tree=1,\n              objective='multi:softprob', random_state=0, reg_alpha=1,\n              reg_lambda=0.001, scale_pos_weight=None, subsample=1,\n              tree_method='exact', validate_parameters=1, verbosity=None)\nclf.fit(X_train,y_train)\ny_train_pred = clf.predict(X_train)\ny_pred = clf.predict(X_test)\n# Train Confusion Matrix\nplot_confusion_matrix(y_train,y_train_pred, 'Train Confusion Matrix')\n# Test Confusion Matrix\nplot_confusion_matrix(y_test,y_pred, 'Test Confusion Matrix')\nprint('Train F1 Score is {0}'.format(f1_score(y_train,y_train_pred,average='micro')))\nprint('Test F1 Score is {0}'.format(f1_score(y_test,y_pred,average='micro')))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The model is getting confused in classifying certain data points belonging to some genre's like Dark Trap, Hiphop and RnB "},{"metadata":{},"cell_type":"markdown","source":"# Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"from prettytable import PrettyTable\nresults = []\n\n# add the results in a list\nresults.append(['Model','Train F1','Test F1'])\nresults.append(['Decision Tree',0.679,0.631])\nresults.append(['Random Forest',0.727,0.683])\nresults.append(['XGBoost',0.741,0.697])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"table = PrettyTable()\ntable.field_names = results[0]\nfor i in range(len(results)):\n    if i!=0:\n        table.add_row(results[i])\nprint(table)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion"},{"metadata":{},"cell_type":"markdown","source":"### 1. The best F1 score obtained is 69.7 with XGBoost model. The features are not having a specific pattern to achieve good F1 score. They are falling under different distributions which is complex for the machine learning model to learn from them\n\n### 2. If more further more feature engineering techniques may help to get better prediction results"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}