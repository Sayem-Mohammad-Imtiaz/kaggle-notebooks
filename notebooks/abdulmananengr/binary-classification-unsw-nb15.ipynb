{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Read Directories"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Import Liberaries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import SGDClassifier,RidgeClassifier\nfrom sklearn.metrics import (precision_score, recall_score,f1_score)\nfrom sklearn.metrics import average_precision_score","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"######## Base\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\npd.set_option('display.max_columns', None)\n\n######### Warning ##############\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n\n########## Sklearn #############\n# Pre-processing\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import train_test_split\n# Metrics\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom sklearn.metrics import roc_auc_score, roc_curve\n# Models\nfrom sklearn.linear_model import LogisticRegression     # Logistic Regression\nfrom sklearn.naive_bayes import GaussianNB              # Naive Bayes\nfrom sklearn.neighbors import KNeighborsClassifier      # KNN \nfrom sklearn.svm import SVC                             # SVC \nfrom sklearn import tree                                # CART - Sınıflandırma ve Regresyon Ağaçları\nfrom sklearn.tree import DecisionTreeClassifier         # CART - Sınıflandırma ve Regresyon Ağaçları\nfrom sklearn.ensemble import BaggingClassifier          # Bagging\nfrom sklearn.ensemble import VotingClassifier           # Voting \nfrom sklearn.ensemble import RandomForestClassifier     # Random Forest\nfrom sklearn.ensemble import AdaBoostClassifier         # Ada Boost\nfrom sklearn.ensemble import GradientBoostingClassifier # GBM - Gradient Boosting Machine\nfrom xgboost import XGBClassifier                       # XGBoost | !pip install xgboost\nfrom lightgbm import LGBMClassifier                     # LightGBM | !conda install -c conda-forge lightgbm\nfrom catboost import CatBoostClassifier                 # CatBoost | !pip install catboost\n!pip install --upgrade nboost                           # NGBoost\n!pip install --upgrade git+https://github.com/stanfordmlgroup/ngboost.git\nfrom ngboost import NGBClassifier\nfrom ngboost.distns import k_categorical, Bernoulli","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Loading Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/unsw-nb15/UNSW_NB15_training-set.csv')\ntest=pd.read_csv('/kaggle/input/unsw-nb15/UNSW_NB15_testing-set.csv')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Data Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print the number of train / test samples\nprint(f\"Train data length: {len(train)}\")\nprint(f\"Test data length: {len(test)}\")\n\n# Visualise the distribution of attacks and normal traffic\n\nf, axes = plt.subplots(2, 2, figsize=(12, 10))\n\n# Create the plots\nsns.countplot(x=\"label\", data=train, ax=axes[0,0])\nsns.countplot(x=\"label\", data=test, ax=axes[0,1])\nsns.countplot(x=\"attack_cat\", data=train, ax=axes[1,0], order = train['attack_cat'].value_counts().index)\nsns.countplot(x=\"attack_cat\", data=test, ax=axes[1,1], order = test['attack_cat'].value_counts().index)\n\n# Set the plot titles\naxes[0,0].set_title(\"Training data distribution\")\naxes[1,0].set_title(\"Training data distribution\")\naxes[0,1].set_title(\"Testing data distribution\")\naxes[1,1].set_title(\"Testing data distribution\")\n\n# Rotate xticks for readability\naxes[1,0].tick_params('x', labelrotation=45)\naxes[1,1].tick_params('x', labelrotation=45)\n\n# Change the xtick labels for attack / normal\naxes[0,0].set_xticklabels([\"Normal\", \"Attack\"])\naxes[0,1].set_xticklabels([\"Normal\", \"Attack\"])\n\n# Remove xlabels\naxes[0,0].set_xlabel(\"\")\naxes[0,1].set_xlabel(\"\")\naxes[1,0].set_xlabel(\"\")\naxes[1,1].set_xlabel(\"\")\n\n# Add some space between the plots for y labels\nplt.subplots_adjust(wspace=0.25)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Dataset Observation"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape,test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Data Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"## Null Value check"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Categorical variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"mask = (train.dtypes == np.object)\nprint(train.loc[:,mask].head())\nlist_cat = train.loc[:,mask].columns.tolist()\nprint(list_cat)\nprint(train.loc[:,mask].values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Numeric variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"mask = (train.dtypes != np.object)\nprint(train.loc[:,mask].head())\nlist_cat = train.loc[:,mask].columns.tolist()\nprint(list_cat)\ntrain.loc[:,mask].describe()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluation of the training dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Check whether the positive label (1) match attack categories, and whether attack categories match labelled data.\n\n# all(iterable) returns True if all elements of the iterable are considered as true values\nprint(all(((train.label == 1) & (train.attack_cat != 'Normal')) == (train.attack_cat != 'Normal')))\nprint(all(((train.attack_cat != 'Normal') & (train.label == 1)) == (train.label == 1)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## number of occurrences for each attack category"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.attack_cat.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Which protocols and services appear in the positively labelled entries?"},{"metadata":{"trusted":true},"cell_type":"code","source":"mask = (train.label == 1)\nprint(train.loc[mask,:].service.value_counts())\nprint(train.loc[mask,:].proto.value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## In the negatively labelled ones?"},{"metadata":{"trusted":true},"cell_type":"code","source":"mask = (train.label == 0)\nprint(train.loc[mask,:].service.value_counts())\nprint(train.loc[mask,:].proto.value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.columns.values)\nprint(test.columns.values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Scaling the Data before doing anomoly detection\n* As anomoly detection methods works better with scaled data, but there is no compulsory need to do so.\n* Scale only continious data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([train, test], ignore_index=True)\n\n# Remove unwanted columns\ndf.drop(['id', 'attack_cat'], inplace=True, axis=1)\n\n# Perform one-hot encoding on categorical columns and join back to main train_data\none_hot = pd.get_dummies(df[[\"proto\", \"state\", \"service\"]])\ndf = df.join(one_hot)\n\n# Remove the original categorical columns\ndf.drop([\"proto\", \"state\", \"service\"], inplace=True, axis=1)\n\n# Re split the data back into train / test\ntrain_data = df.iloc[0:175341, 0:]\ntest_data = df.iloc[175341:, 0:]\n\n# Create y_train and then drop the label from the training data\ny_train = np.array(train_data[\"label\"])\ntrain_data.drop(['label'], inplace=True, axis=1)\n\ny_test = np.array(test_data[\"label\"])\ntest_data.drop(['label'], inplace=True, axis=1)\n\n# Use min-max scaler to scale the features to 0-1 range\n# Only fit the scaler on the train data!!\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(train_data)\n\n# Scale the testing data\nX_test = scaler.transform(test_data)\n\n# Ensure our dataset splits are still correct\nprint(f\"Train data shape: {X_train.shape} Train label shape: {y_train.shape}\")\nprint(f\"Test data shape: {X_test.shape} Test label shape: {y_test.shape}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Machine Learning Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic Regression\nlog = LogisticRegression(solver = \"liblinear\")\ny_pred_log_fit = log.fit(X_train, y_train)\ny_pred_log = y_pred_log_fit.predict(X_test)\nlog_accuracy = accuracy_score(y_test, y_pred_log)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"Accuracy: \" + str(accuracy_score(y_pred_log, y_test)))\nprint (\"Precision: \" + str(precision_score(y_pred_log, y_test)))\nprint (\"Recall: \" + str(recall_score(y_pred_log, y_test)))\nprint (\"F1: \" + str(f1_score(y_pred_log, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test, y_pred_log)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred_log))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## AUROC Score"},{"metadata":{"trusted":true},"cell_type":"code","source":"log_roc_auc_score = roc_auc_score(y_test, y_pred_log)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nfrom sklearn.metrics import (confusion_matrix, precision_recall_curve, auc, roc_curve, recall_score, \n                             classification_report, f1_score, average_precision_score, precision_recall_fscore_support)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fpr_lr, tpr_lr, thresholds_lr = roc_curve(y_test, y_pred_log)\nroc_auc_lr = auc(fpr_lr, tpr_lr)\nprecision_lr, recall_lr, th_lr = precision_recall_curve(y_test, y_pred_log)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## AUPRC Score"},{"metadata":{"trusted":true},"cell_type":"code","source":"log_auprc_score=average_precision_score(y_test,y_pred_log)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_auprc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ridge Classifier\nrc = RidgeClassifier()\nrc_fit = rc.fit(X_train, y_train)\ny_pred_rc = rc_fit.predict(X_test)\nrc_accuracy = accuracy_score(y_test, y_pred_rc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rc_accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"Accuracy: \" + str(accuracy_score(y_pred_rc, y_test)))\nprint (\"Precision: \" + str(precision_score(y_pred_rc, y_test)))\nprint (\"Recall: \" + str(recall_score(y_pred_rc, y_test)))\nprint (\"F1: \" + str(f1_score(y_pred_rc, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test, y_pred_rc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred_rc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## AUROC Score"},{"metadata":{"trusted":true},"cell_type":"code","source":"rc_roc_auc_score = roc_auc_score(y_test, y_pred_rc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rc_roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fpr_rc, tpr_rc, thresholds_rc = roc_curve(y_test, y_pred_rc)\nroc_auc_rc = auc(fpr_rc, tpr_rc)\nprecision_rc, recall_rc, th_rc = precision_recall_curve(y_test, y_pred_rc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## AUPRC Score"},{"metadata":{"trusted":true},"cell_type":"code","source":"rc_auprc_score = average_precision_score(y_test,y_pred_rc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rc_auprc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SGD Classifier\nsgd = SGDClassifier()\nsgd_fit = sgd.fit(X_train, y_train)\ny_pred_sgd = sgd_fit.predict(X_test)\nsgd_accuracy = accuracy_score(y_test, y_pred_sgd)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sgd_accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"Accuracy: \" + str(accuracy_score(y_pred_sgd, y_test)))\nprint (\"Precision: \" + str(precision_score(y_pred_sgd, y_test)))\nprint (\"Recall: \" + str(recall_score(y_pred_sgd, y_test)))\nprint (\"F1: \" + str(f1_score(y_pred_sgd, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test, y_pred_sgd)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred_sgd))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## AUROC Score"},{"metadata":{"trusted":true},"cell_type":"code","source":"sgd_roc_auc_score = roc_auc_score(y_test, y_pred_sgd)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sgd_roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fpr_sgd, tpr_sgd, thresholds_sgd = roc_curve(y_test, y_pred_sgd)\nroc_auc_sgd = auc(fpr_sgd, tpr_sgd)\nprecision_sgd, recall_sgd, th_sgd = precision_recall_curve(y_test, y_pred_sgd)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## AUPRC Score"},{"metadata":{"trusted":true},"cell_type":"code","source":"sgd_auprc_score = average_precision_score(y_test,y_pred_sgd)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sgd_auprc_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" Ensanmble Learning"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ensanmble Learning\nimport statistics\nfinal_pred = np.array([])\nfor i in range(0,len(X_test)):\n    final_pred = np.append(final_pred, statistics.mode( [y_pred_log[i],y_pred_rc[i], y_pred_sgd[i]]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn\nimport matplotlib.pyplot as plt\n \ndef plot_confusion_matrix(cm,\n                          target_names,\n                          title,\n                          cmap=None,\n                          normalize=True):\n    \n    \n    data = cm\n    labels = target_names\n    \n    \"\"\"Plot confusion matrix using heatmap.\n \n    Args:\n        data (list of list): List of lists with confusion matrix data.\n        labels (list): Labels which will be plotted across x and y axis.\n        output_filename (str): Path to output file.\n \n    \"\"\"\n    seaborn.set(color_codes=True)\n    plt.figure(1, figsize=(9, 6))\n \n    plt.title(title)\n \n    seaborn.set(font_scale=1.4)\n    ax = seaborn.heatmap(data, annot=True, cmap=\"YlGnBu\", cbar_kws={'label': 'Scale'}, fmt=\".5g\")\n    ax.set_xticklabels(labels)\n    ax.set_yticklabels(labels)\n \n    accuracy = np.trace(cm) / float(np.sum(cm))\n    misclass = 1 - accuracy\n\n    ax.set(ylabel=\"True Label\", xlabel='Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n#     plt.savefig(output_filename, bbox_inches='tight', dpi=300)\n    plt.show()\n    plt.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ensamble_accuracy = accuracy_score(final_pred, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ensamble_accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"Accuracy: \" + str(accuracy_score(final_pred, y_test)))\nprint (\"Precision: \" + str(precision_score(final_pred, y_test)))\nprint (\"Recall: \" + str(recall_score(final_pred, y_test)))\nprint (\"F1: \" + str(f1_score(final_pred, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fpr_en, tpr_en, thresholds_en = roc_curve(y_test, final_pred)\nroc_auc_en = auc(fpr_en, tpr_en)\nprecision_en, recall_en, th_en = precision_recall_curve(y_test, final_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_auc_en","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(cm = confusion_matrix(y_test, final_pred, labels=[0,1]), \n                      normalize    = False,\n                      target_names = [0,1],\n                      title        = \"Binary Classification\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot ROC curve\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr_lr, tpr_lr, label='Log Reg (area = %0.3f)' % roc_auc_lr)\nplt.plot(fpr_rc, tpr_rc, label='Ridge Classifier (area = %0.3f)' % roc_auc_rc)\nplt.plot(fpr_sgd, tpr_sgd, label='SGD (area = %0.3f)' % roc_auc_sgd)\nplt.plot(fpr_en, tpr_en, label='Ensemble (area = %0.3f)' % roc_auc_en)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC curves from the investigated models')\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot([1, 0], [0, 1], 'k--')\nplt.plot(recall_lr, precision_lr, label='Log Reg')\nplt.plot(recall_rc, precision_rc, label='Ridge Classifier')\nplt.plot(recall_sgd, precision_sgd, label='SGD')\nplt.plot(recall_en, precision_en, label='Ensemble')\nplt.title('Precision vs. Recall')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\ndef plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, scoring=None, obj_line=None,\n                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n    \"\"\"\n    Generate a simple plot of the test and training learning curve.\n\n    Parameters\n    ----------\n    estimator : object type that implements the \"fit\" and \"predict\" methods\n        An object of that type which is cloned for each validation.\n\n    title : string\n        Title for the chart.\n\n    X : array-like, shape (n_samples, n_features)\n        Training vector, where n_samples is the number of samples and\n        n_features is the number of features.\n\n    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n        Target relative to X for classification or regression;\n        None for unsupervised learning.\n\n    ylim : tuple, shape (ymin, ymax), optional\n        Defines minimum and maximum yvalues plotted.\n\n    cv : int, cross-validation generator or an iterable, optional\n        Determines the cross-validation splitting strategy.\n        Possible inputs for cv are:\n          - None, to use the default 3-fold cross-validation,\n          - integer, to specify the number of folds.\n          - An object to be used as a cross-validation generator.\n          - An iterable yielding train/test splits.\n\n        For integer/None inputs, if ``y`` is binary or multiclass,\n        :class:`StratifiedKFold` used. If the estimator is not a classifier\n        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n\n        Refer :ref:`User Guide <cross_validation>` for the various\n        cross-validators that can be used here.\n\n    scoring : string, callable or None, optional, default: None\n              A string (see model evaluation documentation)\n              or a scorer callable object / function with signature scorer(estimator, X, y)\n              For Python 3.5 the documentation is here:\n              http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n              For example, Log Loss is specified as 'neg_log_loss'\n\n    obj_line : numeric or None (default: None)\n               draw a horizontal line\n\n\n    n_jobs : integer, optional\n        Number of jobs to run in parallel (default 1).\n\n\n    Citation\n    --------\n        http://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html\n\n    Usage\n    -----\n        plot_learning_curve(estimator = best_estimator,\n                            title     = best_estimator_title,\n                            X         = X_train,\n                            y         = y_train,\n                            ylim      = (-1.1, 0.1), # neg_log_loss is negative\n                            cv        = StatifiedCV, # CV generator\n                            scoring   = scoring,     # eg., 'neg_log_loss'\n                            obj_line  = obj_line,    # horizontal line\n                            n_jobs    = n_jobs)      # how many CPUs\n\n         plt.show()\n    \"\"\"\n    from sklearn.model_selection import learning_curve\n    import numpy as np\n    from matplotlib import pyplot as plt\n\n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, scoring=scoring, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Cross-validation score\")\n\n    if obj_line:\n        plt.axhline(y=obj_line, color='blue')\n\n    plt.legend(loc=\"best\")\n    return plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import StratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X, y = X_train, y_train\n\nestimator = LogisticRegression(solver = \"liblinear\")\nplot_learning_curve(estimator = estimator,\n                    title     = \"Learning Curves (Log Regression)\",\n                    X         = X,\n                    y         = y,\n                    ylim      = (0.5, 1.1),\n                    cv        = StratifiedKFold(),\n                    scoring   = 'accuracy',     \n                    obj_line  = 0.90,    \n                    n_jobs    = -1)  \nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"estimator = SGDClassifier()\nplot_learning_curve(estimator = estimator,\n                    title     = \"Learning Curves (SGD)\",\n                    X         = X,\n                    y         = y,\n                    ylim      = (0.5, 1.1),\n                    cv        = StratifiedKFold(),\n                    scoring   = 'accuracy',     \n                    obj_line  = 0.90,    \n                    n_jobs    = -1)  \nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"estimator = RidgeClassifier()\nplot_learning_curve(estimator = estimator,\n                    title     = \"Learning Curves (Ridge classifier)\",\n                    X         = X,\n                    y         = y,\n                    ylim      = (0.5, 1.1),\n                    cv        = StratifiedKFold(),\n                    scoring   = 'accuracy',     \n                    obj_line  = 0.90,    \n                    n_jobs    = -1)  \nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}