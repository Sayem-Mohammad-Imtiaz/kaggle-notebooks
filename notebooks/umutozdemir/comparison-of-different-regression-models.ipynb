{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"version":"3.6.3","nbconvert_exporter":"python","file_extension":".py","pygments_lexer":"ipython3","name":"python","mimetype":"text/x-python"}},"nbformat_minor":1,"nbformat":4,"cells":[{"cell_type":"markdown","metadata":{"_uuid":"4e24654b940a07a1139235170967de56455fda90","_cell_guid":"687850f6-f867-4ab3-a360-acbbf716193c"},"source":"The wine data set was choosen on purpose since it requires none data cleansing. Furthermore we will not do any feature extraction. This time the focus will be just on a comparison of different Regression Algorithms (regularized and unregularized). I do not expect hughe differences between the Normal Equations and SGD. But for the sake of completeness i added both.<br>\n\n- Linear Regression\n    - Normal Equation (Plain)\n    - Regularization\n        - Ridge\n        - Lasso\n        - Ealstic Net\n- Stochastic Gradient Descent (SGD)\n    - Plain\n    - Regularization\n        - Ridge \n        - Lasso \n        - Elastic Net\n- Polynomial Regression\n    - Normal Equation\n- Support Vector Regression\n    - Linear\n    - Polynomial\n    - RBF\n        - Defaults\n        - Randomized Search\n\n\nI will play a little bit with some hyperparameters, visualize and have a look onto the results.\n\nMy thoughts will be commented within the cells.\n    "},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"4250a80b0dfbc864ff10cda3e96b73a23fa5861a","_cell_guid":"b13f9c30-cac3-4cbc-b69a-7caa1d16c98c"},"execution_count":null,"source":"import pandas as pd\nimport numpy as np\nimport os\n%matplotlib inline\nimport matplotlib\nimport matplotlib.pyplot as plt","outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"593c6e1dc7d01e03aae3f8ea3c3c5d52ff50321f","_cell_guid":"59ea150c-0fbe-407f-8c34-1c476e34b56a"},"execution_count":null,"source":"file = (\"../input/winequality-red.csv\")\n\nwine = pd.read_csv(file, delimiter = \";\")\n","outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"02573a39ed9a5f0d527e254883c926b154d6be90","_cell_guid":"96efd47a-ab08-4fd8-98a6-5ecf711a66d1"},"source":"# 0. Loading and little preprocessing of the data"},{"cell_type":"code","metadata":{"_uuid":"2c0afcb80a207230c4ff4012aa31917e66bd2435","_cell_guid":"3e21a201-a3ac-4750-8154-e06eacd8ed4c"},"execution_count":null,"source":"wine.head()","outputs":[]},{"cell_type":"code","metadata":{"_uuid":"e9014452686ab8846b772caff6279c2c35ac8c69","_cell_guid":"119bfd1a-cab8-4bca-8f75-b86fdf07b7ae"},"execution_count":null,"source":"wine.columns","outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"3700684ef612a719ba3f5063ba78945c3b3bc2c5","_cell_guid":"d1932e97-18fb-44ec-9729-49e1014232bb"},"execution_count":null,"source":"# Split into Features and Labels\n\nX = wine.drop(['alcohol'], axis = 1)\n\ny = wine[['alcohol']]","outputs":[]},{"cell_type":"code","metadata":{"_uuid":"30efaba2b1c9a60a0f33816466effd1a05d8bfe1","_cell_guid":"7ffa7fb0-7f0f-4fda-a3b7-fbf9eecfc19e"},"execution_count":null,"source":"# Split into train and test data\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, train_size = 0.8, shuffle = True, random_state = 42)\n","outputs":[]},{"cell_type":"code","metadata":{"_uuid":"fb3b980ee12734da1fb4ac5ccf9f126899b07c5a","_cell_guid":"f4fb44ad-05c0-4407-bbaa-63a8a8d67d2e"},"execution_count":null,"source":"X_train.head()","outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"634e193802612f2d3f4070b77ac09c541f989cbc","_cell_guid":"1812ffbe-10a5-4203-810f-54674819acd9"},"execution_count":null,"source":"# Definition of categorical and numerical attributes\n\ncat_attribs = ['quality']\nnum_attribs = list(X_train.drop(cat_attribs, axis=1))","outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"73edc340e8bb4e9865449c628e006c7820e70f1b","_cell_guid":"fcfb54d4-c05c-4401-9892-abf36d160ed7"},"execution_count":null,"source":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.linear_model import LinearRegression\n\n# Since Scikit-Learn doesn't hanldes DataFrame, we build a class for it\n\nclass DFSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, attribute_names):\n        self.attribute_names = attribute_names\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X):\n        return X[self.attribute_names].values\n\nnum_pipe = Pipeline([\n    ('DFSelector', DFSelector(num_attribs)),\n    ('scaler', StandardScaler()) # Feature Scaling\n\n])\n\ncat_pipe = Pipeline([\n    ('DFSelector', DFSelector(cat_attribs)),\n    ('OneHot', OneHotEncoder(sparse = False)) #OneHotEncoding of Categorical Attributes\n])\n\n\nfull_pipeline = FeatureUnion(transformer_list =[\n    (\"num_pipeline\", num_pipe),\n    (\"cat_pipeline\", cat_pipe)\n])","outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"60d2d41baab755a0e7b65b7bcbd698f59a273ad2","_cell_guid":"628bb693-77cc-44d3-bbd2-3a041553daa2"},"execution_count":null,"source":"# Preprocessing of the training set\n\nX_train_prepared = full_pipeline.fit_transform(X_train)","outputs":[]},{"cell_type":"code","metadata":{"_uuid":"f95cb3fdb203aac39f533b6b2ed4d49ae1b73727","_cell_guid":"96760ca2-dd09-486b-95e4-0e54e2bcace2"},"execution_count":null,"source":"# Proof that Feature Scaling and OneHotEncoding worked\n\npd.DataFrame(X_train_prepared).head()","outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"66430d775b0b2fc7854b4cc45bbffed70b5914df","_cell_guid":"939d70e4-9be5-4c3c-8f83-8b8936d63218"},"source":"# 1. Linear Regression \n## 1.1 Normal Equation"},{"cell_type":"code","metadata":{"_uuid":"a6b75019522a39724a2a5725c283e9de645dfe88","_cell_guid":"8ef3319d-ee4d-486a-8d6e-91ecc9ebc76b"},"execution_count":null,"source":"from sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(X_train_prepared, y_train)","outputs":[]},{"cell_type":"code","metadata":{"_uuid":"5115168e4c24dd359356221336ee7f6362722bac","_cell_guid":"f9653264-1b8c-4bf8-b8a3-e8001d8452a1"},"execution_count":null,"source":"lin_reg.score(X_train_prepared, y_train)\n\n# Thats a promising score, best score is 1","outputs":[]},{"cell_type":"code","metadata":{"_uuid":"139572b7ca28d4c6a9ee06c91f7c10a4e4186e7c","_cell_guid":"01a12817-e667-4a7d-abb6-e72a0a1eabed"},"execution_count":null,"source":"# Calculating the MSE\n\nfrom sklearn.metrics import mean_squared_error\n\ny_predict = lin_reg.predict(X_train_prepared)\n\nlin_mse = mean_squared_error(y_train, y_predict)\nlin_rmse = np.sqrt(lin_mse)\nlin_rmse\n\n# Thats a promising RMSE","outputs":[]},{"cell_type":"code","metadata":{"_uuid":"56d9444c4a583f7b7dd56e581702bec6cb1c20ba","_cell_guid":"1b947087-d89c-4a1e-a886-671328423f25"},"execution_count":null,"source":"# Cross Validation\n\nfrom sklearn.model_selection import cross_val_score\n\n\nscores = cross_val_score(lin_reg, X_train_prepared, y_train, cv=5, n_jobs=-1, scoring = \"neg_mean_squared_error\")\n\nlin_rmse_scores = np.sqrt(-scores)\n\nlin_rmse_scores.mean()\n\n# Thats still a promising RMSE, especially for Validation","outputs":[]},{"cell_type":"code","metadata":{"_uuid":"a4c52951676deb8e17d12d7b77c27b7cb88db2d2","_cell_guid":"90df5c29-69f3-499d-8475-4c113c006e5a"},"execution_count":null,"source":"# Plotting each feature except quality against y_predict to see if there is any obvious linearity.\n\nf, axarr = plt.subplots(3, 3, sharex='col', sharey='row', figsize = [15,8])\n\naxarr[0, 0].scatter(X_train_prepared[:,0], y_predict, alpha = 0.05)\naxarr[0, 0].set_title('fixed acidity')\n\naxarr[0, 1].scatter(X_train_prepared[:,1], y_predict, alpha = 0.05)\naxarr[0, 1].set_title('volatile acidity')\naxarr[0, 2].scatter(X_train_prepared[:,2], y_predict, alpha = 0.05)\naxarr[0, 2].set_title('citric acid')\n\naxarr[1, 0].scatter(X_train_prepared[:,3], y_predict, alpha = 0.05)\naxarr[1, 0].set_title('residual sugar')\naxarr[1, 1].scatter(X_train_prepared[:,4], y_predict, alpha = 0.05)\naxarr[1, 1].set_title('chlorides')\naxarr[1, 2].scatter(X_train_prepared[:,5], y_predict, alpha = 0.05)\naxarr[1, 2].set_title('free sulfur dioxide')\n\naxarr[2, 0].scatter(X_train_prepared[:,6], y_predict, alpha = 0.05)\naxarr[2, 0].set_title('total sulfur dioxide')\naxarr[2, 1].scatter(X_train_prepared[:,7], y_predict, alpha = 0.05)\naxarr[2, 1].set_title('density')\naxarr[2, 2].scatter(X_train_prepared[:,8], y_predict, alpha = 0.05)\naxarr[2, 2].set_title('pH')\n\n\nplt.show()","outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"46a17635e2c921612e565fc38023b90244546a0f","_cell_guid":"eea097a8-5308-41ac-a684-bcff95f447bc"},"source":"It seems like there is a higher correlation between denisty and alcohol"},{"cell_type":"code","metadata":{"scrolled":true,"_uuid":"35c3161e0760a699f20d956c63d0bdfdd0fe6ab2","_cell_guid":"d830f687-6782-4f79-8971-7718af27391b"},"execution_count":null,"source":"# Just to proof the graphs\n\ncorr_matrix = wine.corr()\n\ncorr_matrix[\"alcohol\"].sort_values(ascending=False)","outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"9456675f25de672bf04bb299a68abae8e22970da","_cell_guid":"6083465d-6b57-453f-8fc6-2ce3453ae2f4"},"source":"## 1.2 Regularization\n### 1.2.1 Ridge"},{"cell_type":"code","metadata":{"_uuid":"e76438499306949b667e7983d6a93fa73d4f6bec","_cell_guid":"068dc62d-27c0-4c36-9f42-62bb93ec1606"},"execution_count":null,"source":"from sklearn.linear_model import Ridge\n\nridge_reg = Ridge(alpha=0.05, solver=\"cholesky\")\nridge_reg.fit(X_train_prepared, y_train)\n\nridge_reg.score(X_train_prepared, y_train)","outputs":[]},{"cell_type":"code","metadata":{"_uuid":"503f5b51e30a4973e6fd9eb57a75638755cbdc13","_cell_guid":"d1222446-d499-40ef-b676-02e160bee4dc"},"execution_count":null,"source":"# Calculating the MSE\n\nfrom sklearn.metrics import mean_squared_error\n\ny_predict_ridge = ridge_reg.predict(X_train_prepared)\n\nridge_mse = mean_squared_error(y_train, y_predict_ridge)\nridge_rmse = np.sqrt(ridge_mse)\nridge_rmse","outputs":[]},{"cell_type":"code","metadata":{"_uuid":"94e195891970abff29f2c5b59c15e97d45e1fd8c","_cell_guid":"304038b9-2722-4109-97f0-2aad10f2481d"},"execution_count":null,"source":"# Cross Validation\n\nfrom sklearn.model_selection import cross_val_score\n\n\nscores_ridge = cross_val_score(ridge_reg, X_train_prepared, y_train, cv=5, n_jobs=-1, scoring = \"neg_mean_squared_error\")\n\nridge_rmse_scores = np.sqrt(-scores_ridge)\nridge_rmse_scores.mean()","outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"aae06579f99242e853a77bd61f3aa5b7bc5b5d3c","_cell_guid":"fc279042-349b-43e3-b426-1fa01de4d4d0"},"source":"### 1.2.2 Lasso"},{"cell_type":"code","metadata":{"_uuid":"260daf17319a572b5d359d9464a3334aeb065ca9","_cell_guid":"eb31baf1-bc21-4abd-8477-14a8f1837915"},"execution_count":null,"source":"from sklearn.linear_model import Lasso\n\nlasso_reg = Lasso(alpha=0.05, random_state = 42)\nlasso_reg.fit(X_train_prepared, y_train)\n\nlasso_reg.score(X_train_prepared, y_train)","outputs":[]},{"cell_type":"code","metadata":{"_uuid":"690af145b2333c3c98c331ccab9d8badc2644a7a","_cell_guid":"af146f8b-5d18-4616-a803-0f586004970f"},"execution_count":null,"source":"# Calculating the MSE\n\nfrom sklearn.metrics import mean_squared_error\n\ny_predict_lasso = lasso_reg.predict(X_train_prepared)\n\nlasso_mse = mean_squared_error(y_train, y_predict_lasso)\nlasso_rmse = np.sqrt(lasso_mse)\nlasso_rmse","outputs":[]},{"cell_type":"code","metadata":{"_uuid":"8e60d4d27dd4941b5027e218ad5620816d5b1a3f","_cell_guid":"0d834ce0-1dfd-4008-94b6-0be44b152c24"},"execution_count":null,"source":"# Cross Validation\n\nfrom sklearn.model_selection import cross_val_score\n\n\nscores_lasso = cross_val_score(lasso_reg, X_train_prepared, y_train, cv=5, n_jobs=-1, scoring = \"neg_mean_squared_error\")\n\nlasso_rmse_scores = np.sqrt(-scores_lasso)\nlasso_rmse_scores.mean()","outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"85da77ad67923e264d6d0a3a97fd2848769592e9","_cell_guid":"892d319d-95f4-47c4-8937-2d2e1798afb4"},"source":"### 1.2.3 Elastic Net"},{"cell_type":"code","metadata":{"_uuid":"d85c115153eb748eaf65dbad5a51e049bf95ce6b","_cell_guid":"b2bb80a7-3372-4bc9-89d8-99396471e5c1"},"execution_count":null,"source":"from sklearn.linear_model import ElasticNet\n\n# l1_ratio = 0 = penalty = l2 (Ridge)\n# l1_ratio = 1 = panalty = l1 (Lasso)\n\nelastic_reg = ElasticNet(alpha=0.005, l1_ratio = 0.5, random_state = 42)\nelastic_reg.fit(X_train_prepared, y_train)\n\nelastic_reg.score(X_train_prepared, y_train)","outputs":[]},{"cell_type":"code","metadata":{"_uuid":"b5a8f211f2b627bc83146d627c2cb2767aefaf64","_cell_guid":"7c4c920b-6010-4ab1-bcba-871d06ca6564"},"execution_count":null,"source":"# Calculating the MSE\n\nfrom sklearn.metrics import mean_squared_error\n\ny_predict_elastic = elastic_reg.predict(X_train_prepared)\n\nelastic_mse = mean_squared_error(y_train, y_predict_elastic)\nelastic_rmse = np.sqrt(elastic_mse)\nelastic_rmse","outputs":[]},{"cell_type":"code","metadata":{"_uuid":"9cb786e078ae80e601c9b0f25e36fe2a6a24bcf7","_cell_guid":"130d74ab-496f-40c2-951c-67e8fc12c3eb"},"execution_count":null,"source":"# Cross Validation\n\nfrom sklearn.model_selection import cross_val_score\n\n\nscores_elastic = cross_val_score(elastic_reg, X_train_prepared, y_train, cv=5, n_jobs=-1, scoring = \"neg_mean_squared_error\")\n\nelastic_rmse_scores = np.sqrt(-scores_elastic)\nelastic_rmse_scores.mean()","outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"1045cee5acc1e027697438fd7a4f5a141f161ac7","_cell_guid":"17c15b02-152f-4b83-8c53-01fb6fb7475b"},"source":"# 2 Stochastic Gradient Descent\n## 2.1 Plain"},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"6de5046dc9b98083c51dc22a9f3c52be9d504c1b","_cell_guid":"7f9bb22c-3696-4992-83bc-15fc4535647e"},"execution_count":null,"source":"# Transform y_train for cross val score. It works witout, but an error occurs\n\ny_train_rs = y_train.as_matrix()","outputs":[]},{"cell_type":"code","metadata":{"_uuid":"cea3c39905a8efd18099687f9fd64e824bdcbd12","_cell_guid":"f7e0789a-2af7-4d12-8196-fa0a41f545a2"},"execution_count":null,"source":"from sklearn.linear_model import SGDRegressor\n\nsgd_reg = SGDRegressor(penalty=None, max_iter = 1000, random_state = 42)\nsgd_reg.fit(X_train_prepared, y_train_rs.ravel())\n\nsgd_reg.score(X_train_prepared, y_train_rs.ravel())","outputs":[]},{"cell_type":"code","metadata":{"_uuid":"b1ea5fdfa645d4a4c1fc2d88c91e243e09b5b326","_cell_guid":"d790a23e-508d-4728-ace4-1dc363571d76"},"execution_count":null,"source":"# Calculating the MSE\n\nfrom sklearn.metrics import mean_squared_error\n\ny_predict_sgd = sgd_reg.predict(X_train_prepared)\n\nsgd_mse = mean_squared_error(y_train, y_predict_sgd)\nsgd_rmse = np.sqrt(sgd_mse)\nsgd_rmse","outputs":[]},{"cell_type":"code","metadata":{"_uuid":"914d5bc359fc7f7505fbac4efca8c9892797bc83","_cell_guid":"e9520c72-a78c-4927-8f2b-bd8145a24135"},"execution_count":null,"source":"# Cross Validation\n\nfrom sklearn.model_selection import cross_val_score\n\n\nscores_sgd = cross_val_score(sgd_reg, X_train_prepared, y_train_rs.ravel(), cv=5, n_jobs=-1, scoring = \"neg_mean_squared_error\")\n\nsgd_rmse_scores = np.sqrt(-scores_sgd)\nsgd_rmse_scores.mean()","outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"245a07879bba1a70d61aca94fe6104adec4bb719","_cell_guid":"6bd7423e-6811-4ce9-b859-6c9197b2539c"},"source":"## 2.2 Regularization"},{"cell_type":"markdown","metadata":{"_uuid":"7c548e49c3c48b4940a80b1431446f46d862a0fe","_cell_guid":"28ad3fb7-68f1-428f-a76f-0155f92e1295"},"source":"### 2.2.1 Ridge"},{"cell_type":"code","metadata":{"_uuid":"99b1a28286c20104fe23a110a4253e56e4b8a114","_cell_guid":"2be76314-d213-454c-b2c3-d40221d77ad5"},"execution_count":null,"source":"from sklearn.linear_model import SGDRegressor\n\nsgd_reg_ridge = SGDRegressor(penalty=\"l2\", max_iter = 1000, random_state = 42)\nsgd_reg_ridge.fit(X_train_prepared, y_train_rs.ravel())\n\nsgd_reg_ridge.score(X_train_prepared, y_train_rs.ravel())","outputs":[]},{"cell_type":"code","metadata":{"_uuid":"f5862f56d7559c6a02954e5a8a99ec6ce7706540","_cell_guid":"8b7711ea-904f-4060-a66d-9d78f08b4c19"},"execution_count":null,"source":"# Calculating the MSE\n\nfrom sklearn.metrics import mean_squared_error\n\ny_predict_sgd_ridge = sgd_reg_ridge.predict(X_train_prepared)\n\nsgd_ridge_mse = mean_squared_error(y_train, y_predict_sgd_ridge)\nsgd_ridge_rmse = np.sqrt(sgd_mse)\nsgd_ridge_rmse","outputs":[]},{"cell_type":"code","metadata":{"_uuid":"a9a67fc6c3666d77460803fc5647955bc3a16d32","_cell_guid":"d5f2331f-ab1a-4812-b1ab-95de374fe329"},"execution_count":null,"source":"# Cross Validation\n\nfrom sklearn.model_selection import cross_val_score\n\n\nscores_sgd_ridge = cross_val_score(sgd_reg_ridge, X_train_prepared, y_train_rs.ravel(), cv=5, n_jobs=-1, scoring = \"neg_mean_squared_error\")\n\nsgd_ridge_rmse_scores = np.sqrt(-scores_sgd_ridge)\nsgd_ridge_rmse_scores.mean()","outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"997ed9cc7f8b671540902ff5a56893d659bbe5c0","_cell_guid":"9620a066-0f96-4392-9d2f-3768d483493b"},"source":"### 2.2.2 Lasso"},{"cell_type":"code","metadata":{"_uuid":"30f0e1688485ea8a57f1a8ec0a04bf787688a3f8","_cell_guid":"fd22e312-703e-43dc-8fdf-715c88c95c91"},"execution_count":null,"source":"from sklearn.linear_model import SGDRegressor\n\nsgd_reg_lasso = SGDRegressor(penalty=\"l1\", max_iter = 1000, random_state = 42)\nsgd_reg_lasso.fit(X_train_prepared, y_train_rs.ravel())\n\nsgd_reg_lasso.score(X_train_prepared, y_train_rs.ravel())","outputs":[]},{"cell_type":"code","metadata":{"_uuid":"9755723ab0a9f8f555f74a5d485ed6309f18aa8b","_cell_guid":"5663502d-91ee-4934-8395-4340ae1c39d6"},"execution_count":null,"source":"# Calculating the MSE\n\nfrom sklearn.metrics import mean_squared_error\n\ny_predict_sgd_lasso = sgd_reg_lasso.predict(X_train_prepared)\n\nsgd_lasso_mse = mean_squared_error(y_train, y_predict_sgd_lasso)\nsgd_lasso_rmse = np.sqrt(sgd_mse)\nsgd_lasso_rmse","outputs":[]},{"cell_type":"code","metadata":{"_uuid":"b7028e1108ad26a2a26a7b2d36651c099fd8f402","_cell_guid":"e0725500-b4f7-432f-b542-0327a7c57d90"},"execution_count":null,"source":"# Cross Validation\n\nfrom sklearn.model_selection import cross_val_score\n\n\nscores_sgd_lasso = cross_val_score(sgd_reg_lasso, X_train_prepared, y_train_rs.ravel(), cv=5, n_jobs=-1, scoring = \"neg_mean_squared_error\")\n\nsgd_ridge_lasso_scores = np.sqrt(-scores_sgd_ridge)\nsgd_ridge_lasso_scores.mean()","outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"c7e462c8d368a3fba967ba4d92160eef98cc752b","_cell_guid":"c5290aff-49ae-4c1e-9ce7-6ed3c86bea07"},"source":"### 2.2.3 Elastic Net"},{"cell_type":"code","metadata":{"_uuid":"9914c0bc7c92e6b924b0700ed3977377933ac31a","_cell_guid":"c1fc090d-1773-42bd-b5af-d771f6710a31"},"execution_count":null,"source":"from sklearn.linear_model import SGDRegressor\n\nsgd_reg_elastic = SGDRegressor(penalty=\"elasticnet\", alpha = 0.005, l1_ratio = 0.5, max_iter = 1000, random_state = 42)\nsgd_reg_elastic.fit(X_train_prepared, y_train_rs.ravel())\n\nsgd_reg_elastic.score(X_train_prepared, y_train_rs.ravel())","outputs":[]},{"cell_type":"code","metadata":{"_uuid":"5cb60bf15aba04c45112b608b17a6abd4416b091","_cell_guid":"becee490-7be7-4fa3-a394-b40e85b6d8b2"},"execution_count":null,"source":"# Calculating the MSE\n\nfrom sklearn.metrics import mean_squared_error\n\ny_predict_sgd_lasso = sgd_reg_lasso.predict(X_train_prepared)\n\nsgd_lasso_mse = mean_squared_error(y_train, y_predict_sgd_lasso)\nsgd_lasso_rmse = np.sqrt(sgd_mse)\nsgd_lasso_rmse","outputs":[]},{"cell_type":"code","metadata":{"_uuid":"db415208f1037d1dbadaae8ff714b4759d26005d","_cell_guid":"ca4dfb22-e583-4d59-8554-f48c8d29da3a"},"execution_count":null,"source":"# Cross Validation\n\nfrom sklearn.model_selection import cross_val_score\n\n\nscores_sgd_lasso = cross_val_score(sgd_reg_lasso, X_train_prepared, y_train_rs.ravel(), cv=5, n_jobs=-1, scoring = \"neg_mean_squared_error\")\n\nsgd_ridge_lasso_scores = np.sqrt(-scores_sgd_ridge)\nsgd_ridge_lasso_scores.mean()","outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"aade4bed4b1f33b168df513091963051b440b3ee","_cell_guid":"740567fc-7206-4cc0-a2f8-943b5394b3e5"},"source":"# 3. Polynomial Regression"},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"733b8efc6dfa0ca246c120f338b522df397417ba","_cell_guid":"ab323d51-be03-4084-92a6-98aa28265acf"},"execution_count":null,"source":"from sklearn.preprocessing import PolynomialFeatures\npoly_features = PolynomialFeatures(degree=4, include_bias=False)\n\nX_poly = poly_features.fit_transform(X_train_prepared)","outputs":[]},{"cell_type":"code","metadata":{"_uuid":"883e38d7962a1a4b39b5df8278168a9c1281a408","_cell_guid":"4a34eb3b-acfe-448e-b54a-b380d34541ae"},"execution_count":null,"source":"poly_reg = LinearRegression()\npoly_reg.fit(X_poly, y_train)","outputs":[]},{"cell_type":"code","metadata":{"_uuid":"57fa68ee7847bc0ce7a5c881c49d523da7900c83","_cell_guid":"23202b36-2fb7-4882-ad65-d67b27662197"},"execution_count":null,"source":"poly_reg.score(X_poly, y_train)","outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"679ec8693cdf26842d1a95531623eea8b0e43e8f","_cell_guid":"a848ee3e-068e-4dc2-bb2e-d637cf93acb9"},"source":"At the first glance thats a perfect score. But me we must validate that this to be very sure."},{"cell_type":"code","metadata":{"_uuid":"c03e60900a85c175e945f0ef41d293cd3a31a275","_cell_guid":"70d42600-9a7c-47ce-8c6e-8a16b8032d79"},"execution_count":null,"source":"# Before we had 16 Features (n) and 1279 Samples (m)\n\nX_train_prepared.shape","outputs":[]},{"cell_type":"code","metadata":{"_uuid":"c993c5a3445dc1bcd3a4dde2edebb54cae0ecea8","_cell_guid":"9a24f0d7-06ea-46b3-8d8c-c4f87fec68a4"},"execution_count":null,"source":"# After adding the Polynomial-Features (degree = 4) we end up with 4844 Features!\n\nX_poly.shape","outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"d3665481c0eebb77eefd66ed7fb7c16da672035a","_cell_guid":"dacae6aa-0f84-461d-a092-777398474ba2"},"source":"This might be a problem. A rule of thumb is <b> m > n^2 </b> and  <b>m/f > n^2 </b> for cross validation. Lets see."},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"74903b254439a50b786b56830743863d76408c44","_cell_guid":"a1d75553-078d-4d9d-a81c-9c915b5dd8ba"},"execution_count":null,"source":"y_poly_predicted = poly_reg.predict(X_poly)","outputs":[]},{"cell_type":"code","metadata":{"_uuid":"51e904129bd004df7b8c91ba5ebed3e84e3c6221","_cell_guid":"4872a721-c4d8-4fe2-97e4-fec4ff3e6d38"},"execution_count":null,"source":"from sklearn.metrics import mean_squared_error\n\npoly_mse = mean_squared_error(y_train, y_poly_predicted)\npoly_rmse = np.sqrt(poly_mse)\npoly_rmse","outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"e160a8a535da235080df3f50997c8909f525bfef","_cell_guid":"d163842f-694a-45f2-abf7-0886d7a79560"},"source":"Regarding the training thats a very good score, maybe too good ;). Lets cross validate"},{"cell_type":"code","metadata":{"_uuid":"68441af9ecb48dc3a4dee15ad095693abe3b3c2e","_cell_guid":"9582c1e7-e669-4b57-888d-39035ee6823d"},"execution_count":null,"source":"# Try reducing the number of features, increasing the number samples, and decreasing the number of folds \n# (if you are using cross_validation).\n\n# m/f > n^2: 255 > 23464336, which is clearly not given\n\nfrom sklearn.model_selection import cross_val_score\n\nscores_poly = cross_val_score(poly_reg, X_poly, y_train, cv=5, n_jobs=-1, scoring = \"neg_mean_squared_error\")\n\npoly_rmse_scores = np.sqrt(-scores_poly)","outputs":[]},{"cell_type":"code","metadata":{"_uuid":"35cf87d69a1a1e75f54b16eda1e8a4f0bca0c5de","_cell_guid":"fa18a884-9319-4ee1-96da-5db8a1c0d17a"},"execution_count":null,"source":"poly_rmse_scores.mean()","outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"373480ad1b7d832eff361b90c5134f1b3e99177a","_cell_guid":"13d49789-2165-4dc1-9c16-4ea5c1837934"},"source":"Thats an absurd score since \"m/f > n^2\" is violated: <br>\n- m = 1279\n- f = 5\n- m/f = 255,8\n- n^2 = 4844^2 = 23464336\n\nWhat could work out is a polynom with a degree of 2:\n- m/f = 255,8\n- n^2 = 16^2 = 256\n\nNotice, that m/f is still smaler than n^2. We will give it just a try."},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"8b4ef570b7946c5c8f1b47098e248f894d3bf0dc","_cell_guid":"9135f0e7-0551-4a37-a4d6-07a22dc5a3f1"},"execution_count":null,"source":"poly_features = PolynomialFeatures(degree=2, include_bias=False)\n\nX_poly_2 = poly_features.fit_transform(X_train_prepared)","outputs":[]},{"cell_type":"code","metadata":{"_uuid":"90b2046f55c3e4dbb2b3c2b0c650166b87e6235c","_cell_guid":"403be52a-676e-42ae-8f75-08501db19260"},"execution_count":null,"source":"poly_2_reg = LinearRegression()\npoly_2_reg.fit(X_poly_2, y_train)","outputs":[]},{"cell_type":"code","metadata":{"_uuid":"1fc0c8006567822b88b1a30ec36f6e998abfecd5","_cell_guid":"f0311c26-c843-4cee-b47f-c840ee17cda3"},"execution_count":null,"source":"poly_2_reg.score(X_poly_2, y_train)","outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"678c5839b9b5d648de4878226c19576334a8b44b","_cell_guid":"d25137e4-1cd9-411c-a27c-08ff66eb5da7"},"source":"Way worse, than 0.99 but at least it seems to be more regularized now."},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"5d9695a65b41c75e3544450228aed223375c88ac","_cell_guid":"34b08514-de84-433b-be5c-0c10749cb267"},"execution_count":null,"source":"y_poly_2_predicted = poly_2_reg.predict(X_poly_2)","outputs":[]},{"cell_type":"code","metadata":{"_uuid":"11f90691d346c09dcf530b0162dd8076e9965c1a","_cell_guid":"c7d3fa07-460b-4ada-a68a-8cb2cf9c5f0b"},"execution_count":null,"source":"from sklearn.metrics import mean_squared_error\n\npoly_2_mse = mean_squared_error(y_train, y_poly_2_predicted)\npoly_2_rmse = np.sqrt(poly_2_mse)\npoly_2_rmse","outputs":[]},{"cell_type":"code","metadata":{"_uuid":"0db742564ef0f335f003e89b37d9a37e1f1ebb72","_cell_guid":"d34900e0-0c82-4434-9a74-6c2e8b0377af"},"execution_count":null,"source":"from sklearn.model_selection import cross_val_score\n\nscores_poly_2 = cross_val_score(poly_2_reg, X_poly_2, y_train, cv=2, n_jobs=-1, scoring = \"neg_mean_squared_error\")\n\npoly_2_rmse_scores = np.sqrt(-scores_poly_2)\npoly_2_rmse_scores.mean()","outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"db8bae5c49afd18c44c133ea9b290952f4681f1a","_cell_guid":"dc0c29a1-3424-481d-bd6e-34efbe222adf"},"source":"The number of samples seems still to be small for a degree of 2"},{"cell_type":"markdown","metadata":{},"source":"# 4. Support Vector Regession"},{"cell_type":"markdown","metadata":{},"source":"## 4.1 Linear"},{"cell_type":"code","metadata":{},"execution_count":null,"source":"from sklearn.svm import LinearSVR # I could have also used SVR with kernel=\"linear\", but LinearSVR is faster\n\nsvm_reg_linear = LinearSVR(epsilon = 1, C = 1)\n\nsvm_reg_linear.fit(X_train_prepared, y_train_rs.ravel())\n\nsvm_reg_linear.score(X_train_prepared, y_train_rs.ravel())","outputs":[]},{"cell_type":"code","metadata":{},"execution_count":null,"source":"# Calculating the MSE\n\nfrom sklearn.metrics import mean_squared_error\n\ny_predict_svm_linear = svm_reg_linear.predict(X_train_prepared)\n\nsvm_linear_mse = mean_squared_error(y_train_rs.ravel(), y_predict_svm_linear)\nsvm_linear_rmse = np.sqrt(svm_linear_mse)\nsvm_linear_rmse","outputs":[]},{"cell_type":"code","metadata":{},"execution_count":null,"source":"# Cross Validation\n\nfrom sklearn.model_selection import cross_val_score\n\nscores_svm_linear = cross_val_score(svm_reg_linear, X_train_prepared, y_train_rs.ravel(), cv=5, n_jobs=-1, scoring = \"neg_mean_squared_error\")\n\nsvm_reg_linear_scores = np.sqrt(-scores_svm_linear)\nsvm_reg_linear_scores.mean()","outputs":[]},{"cell_type":"markdown","metadata":{},"source":"## 4.2 Polynomial"},{"cell_type":"code","metadata":{},"execution_count":null,"source":"from sklearn.svm import SVR\n\nsvm_reg_poly = SVR(kernel = \"poly\", degree = 2, C=1, epsilon = 0)\n\nsvm_reg_poly.fit(X_train_prepared, y_train_rs.ravel())\n\nsvm_reg_poly.score(X_train_prepared, y_train_rs.ravel())","outputs":[]},{"cell_type":"code","metadata":{},"execution_count":null,"source":"# Calculating the MSE\n\nfrom sklearn.metrics import mean_squared_error\n\ny_predict_svm_poly = svm_reg_poly.predict(X_train_prepared)\n\nsvm_poly_mse = mean_squared_error(y_train_rs.ravel(), y_predict_svm_poly)\nsvm_poly_rmse = np.sqrt(svm_poly_mse)\nsvm_poly_rmse","outputs":[]},{"cell_type":"code","metadata":{},"execution_count":null,"source":"# Cross Validation\n\nfrom sklearn.model_selection import cross_val_score\n\nscores_svm_poly = cross_val_score(svm_reg_poly, X_train_prepared, y_train_rs.ravel(), cv=5, n_jobs=-1, scoring = \"neg_mean_squared_error\")\n\nsvm_reg_poly_scores = np.sqrt(-scores_svm_poly)\nsvm_reg_poly_scores.mean()","outputs":[]},{"cell_type":"markdown","metadata":{},"source":"## 4.3 RBF Kernel"},{"cell_type":"markdown","metadata":{},"source":"### 4.3.1 Defaults"},{"cell_type":"code","metadata":{},"execution_count":null,"source":"from sklearn.svm import SVR\n\nsvm_reg_rbf = SVR(kernel = \"rbf\", C=1)\n\nsvm_reg_rbf.fit(X_train_prepared, y_train_rs.ravel())\n\nsvm_reg_rbf.score(X_train_prepared, y_train_rs.ravel())","outputs":[]},{"cell_type":"code","metadata":{},"execution_count":null,"source":"# Calculating the MSE\n\nfrom sklearn.metrics import mean_squared_error\n\ny_predict_svm_rbf = svm_reg_rbf.predict(X_train_prepared)\n\nsvm_rbf_mse = mean_squared_error(y_train_rs.ravel(), y_predict_svm_rbf)\nsvm_rbf_rmse = np.sqrt(svm_rbf_mse)\nsvm_rbf_rmse","outputs":[]},{"cell_type":"code","metadata":{},"execution_count":null,"source":"# Cross Validation\n\nfrom sklearn.model_selection import cross_val_score\n\nscores_svm_rbf = cross_val_score(svm_reg_rbf, X_train_prepared, y_train_rs.ravel(), cv=5, n_jobs=-1, scoring = \"neg_mean_squared_error\")\n\nsvm_reg_rbf_scores = np.sqrt(-scores_svm_rbf)\nsvm_reg_rbf_scores.mean()","outputs":[]},{"cell_type":"markdown","metadata":{},"source":"### 4.3.2 Randomized Search"},{"cell_type":"code","metadata":{},"execution_count":null,"source":"# Due to the promising scores we will do a randomizes search on the RBF Kernel\n\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import expon, reciprocal\n\nparams = {\n        'kernel': ['rbf'],\n        'C': reciprocal(1, 200000),\n        'gamma': expon(scale=1.0),\n    }\n\nsvm_reg = SVR()\nrnd_search = RandomizedSearchCV(svm_reg, param_distributions= params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, random_state=42)\nrnd_search.fit(X_train_prepared, y_train_rs.ravel())\n","outputs":[]},{"cell_type":"code","metadata":{},"execution_count":null,"source":"rnd_search.best_params_","outputs":[]},{"cell_type":"code","metadata":{},"execution_count":null,"source":"rnd_search.best_score_","outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"3fa620ef6d4459ef6e81c9d9047b3be3d5d9803c","_cell_guid":"13081d56-70de-4cbd-b552-2fcd4aac3251"},"source":" # X. Final Prediction"},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"579fc2b497298ec53266d5e8f24fb299c5e59bc2","_cell_guid":"f6b5389b-875c-4e2b-afbe-0a3bef3a4270"},"execution_count":null,"source":"final_model = rnd_search\n\n\nX_test_prepared = full_pipeline.transform(X_test) ## call transform NOT fit_transform\n\nfinal_predictions = final_model.predict(X_test_prepared)\n\nfinal_mse = mean_squared_error(y_test, final_predictions)\n\nfinal_rmse = np.sqrt(final_mse)","outputs":[]},{"cell_type":"code","metadata":{"_uuid":"74958bb491b65c1e472bfd03b6505b992f9f3c65","_cell_guid":"69b45fb5-1ee6-4cbf-b5aa-15d29cf37e19"},"execution_count":null,"source":"final_rmse","outputs":[]},{"cell_type":"code","metadata":{"_uuid":"ebd7416a0c6f3d1733d974a6936470473f61248a","_cell_guid":"a75dbb9b-59ad-4a88-9b86-90d1a99ceb11"},"execution_count":null,"source":"Results = pd.DataFrame(y_test)\nResults[\"Final_Predictions\"] = final_predictions\nResults.head(10)","outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"_uuid":"f6447aebcd478198e53501c446ca3c4552a5d577","_cell_guid":"9a89ac7e-922e-4bcb-a540-7ed70553a064"},"execution_count":null,"source":"","outputs":[]}]}