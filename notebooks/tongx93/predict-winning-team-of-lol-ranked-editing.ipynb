{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\nfrom sklearn.model_selection import train_test_split # Import train_test_split function\nfrom sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# read and skim the data\ndata = pd.read_csv('../input/league-of-legends-diamond-ranked-games-10-min/high_diamond_ranked_10min.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# No missing value check is required\n# Find the table size:\nprint(\"(row, column): \", data.shape)\n# See if there is repeated record:\nprint(\"\\nThe dataset has duplicated game record: \", data.duplicated().any())\n# See the variables available:\nprint(\"\\nThe column names: \")\nprint(data.columns.values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Take a close look at the columns, we can see that there is some repeated information:\n1. 'blueGoldDiff'='blueTotalGold'-'redTotalGold'= -'redGoldDiff'\n2. 'blueGoldPerMin'='blueTotalGold'/10(min)\n3. 'redGoldPerMin'='redTotalGold'/10(min)\n4. 'blueExperienceDiff'= -'redExperienceDiff'\n5. 'blueCSPerMin'='blueTotalMinionsKilled'/10(min)\n6. 'redCSPerMin'='redTotalMinionsKilled'/10(min)\n7. 'blueEliteMonsters'='blueDragons'+'blueHeralds'\n8. 'redEliteMonsters'='redDragons'+'redHeralds'\n9. 'blueFirstBlood'= Â¬'redFirstBlood'\n\nFor simplification, we can reduce the dimension of the table by removing some columns:\n* 'blueGoldPerMin'/'redGoldPerMin'\n* 'blueCSPerMin'/'redCSPerMin'\n* 'blueEliteMonsters'/'redEliteMonsters'\n* 'blueTotalGold'/'redTotalGold'\n* 'blueTotalMinionsKilled'/'redTotalMinionsKilled'\n* 'blueTotalJungleMinionsKilled'/'redTotalJungleMinionsKilled'\n* 'blueWardsPlaced'/'redWardsPlaced' \n* 'blueWardsDestroyed'/'redWardsDestroyed'\n* 'blueKills'/'redKills'\n* 'blueDeaths'/'redDeaths'\n* 'blueAssists'/'redAssists' \n* 'blueDragons'/'redDragons'\n* 'blueHeralds'/'redHeralds'\n* 'blueTowersDestroyed'/'redTowersDestroyed'\n* 'blueAvgLevel'/'redAvgLevel'\n* 'blueTotalExperience'/'redTotalExperience'\n* 'redGoldDiff'\n* 'redExperienceDiff'\n* 'redFirstBlood'\n\n(based on that the rules of getting gold and experience, the amount of minions spawned are the same for both side, and the elite monsters, dragon and herald, give different bonus to the killing team);\n\nand adding columns for the differences instead:\n* 'blueWardsPlacedDiff'= 'blueWardsPlaced'-'redWardsPlaced'\n* 'blueWardsDestroyedDiff'='blueWardsDestroyed'-'redWardsDestroyed'\n* 'blueCSDiff'= 'blueTotalMinionsKilled'-'redTotalMinionsKilled'\n* 'blueTotalJungleMinionsKilledDiff'= 'blueTotalJungleMinionsKilled'-'redTotalJungleMinionsKilled'\n* 'blueKillsDiff'= 'blueKills'-'redKills'\n* 'blueDeathsDiff'= 'blueDeaths'-'redDeaths'\n* 'blueAssistsDiff'= 'blueAssists'-'redAssists' \n* 'blueDragonsDiff'= 'blueDragons'-'redDragons'\n* 'blueHeraldsDiff'= 'blueHeralds'-'redHeralds'\n* 'blueTowersDestroyedDiff'= 'blueTowersDestroyed'-'redTowersDestroyed'\n* 'blueAvgLevelDiff'= 'blueAvgLevel'-'redAvgLevel'\n\nAfter the simplication, the independent variable number reduces from 38 to 14.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# After adjusting the columns:\ndata['blueWardsPlacedDiff'] = data.apply(lambda row: int(row['blueWardsPlaced']-row['redWardsPlaced']),axis=1)\ndata['blueWardsDestoryedDiff'] = data.apply(lambda row: int(row['blueWardsDestroyed']-row['redWardsDestroyed']),axis=1)\ndata['blueCSDiff'] = data.apply(lambda row: int(row['blueTotalMinionsKilled']-row['redTotalMinionsKilled']),axis=1)\ndata['blueTotalJungleMinionsKilledDiff'] = data.apply(lambda row: int(row['blueTotalJungleMinionsKilled']-row['redTotalJungleMinionsKilled']),axis=1)\ndata['blueKillsDiff'] = data.apply(lambda row: int(row['blueKills']-row['redKills']),axis=1)\ndata['blueDeathsDiff'] = data.apply(lambda row: int(row['blueDeaths']-row['redDeaths']),axis=1)\ndata['blueAssistsDiff'] = data.apply(lambda row: int(row['blueAssists']-row['redAssists']),axis=1)\ndata['blueDragonsDiff'] = data.apply(lambda row: int(row['blueDragons']-row['redDragons']),axis=1)\ndata['blueHeraldsDiff'] = data.apply(lambda row: int(row['blueHeralds']-row['redHeralds']),axis=1)\ndata['blueTowersDestroyedDiff'] = data.apply(lambda row: int(row['blueTowersDestroyed']-row['redTowersDestroyed']),axis=1)\ndata['blueAvgLevelDiff'] = data.apply(lambda row: row['blueAvgLevel']-row['redAvgLevel'],axis=1)\n\ndata_1 = data.drop(['blueGoldPerMin','redGoldPerMin','blueCSPerMin','redCSPerMin','blueEliteMonsters',\n                   'redEliteMonsters','blueTotalGold','redTotalGold','blueTotalMinionsKilled',\n                   'redTotalMinionsKilled','redGoldDiff','redExperienceDiff', 'blueTotalJungleMinionsKilled', \n                   'redTotalJungleMinionsKilled','blueWardsPlaced','redWardsPlaced','blueWardsDestroyed',\n                   'redWardsDestroyed','redFirstBlood','blueKills','blueDeaths','blueAssists','blueDragons',\n                   'blueHeralds','blueTowersDestroyed','blueAvgLevel','blueTotalExperience','redKills','redDeaths',\n                   'redAssists','redDragons','redHeralds','redTowersDestroyed','redAvgLevel','redTotalExperience'],axis=1)\nprint(data_1.columns.values)\ndata_1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# General discription of the table\ndata_1[data_1.columns[1:]].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize and compare the ratio of blueWins: redWins and blueFirstBlood: redFirstBlood\nblueWins = pd.DataFrame({'Side':['red','blue'], 'Winning':data_1['blueWins'].value_counts(),'FirstBlood':data_1['blueFirstBlood'].value_counts()})\nblueWins.plot(y='Winning',kind='pie',colors=['tomato','lightskyblue'], figsize=(5,5),labels=['red','blue'],autopct='%1.2f%%')\nblueWins.plot(y='FirstBlood',kind='pie',colors=['tomato','lightskyblue'], figsize=(5,5),labels=['red','blue'],autopct='%1.2f%%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The number of red and blue wins/first blood can be seemed as identical.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# find the correlation between variables\ncorr = data_1[data_1.columns[1:]].corr()\nax = sns.heatmap(\n    corr, \n    vmin=-1, vmax=1, center=0,\n    cmap=sns.diverging_palette(220, 10, n=20),\n    square=True)\nax.set_xticklabels(\n    ax.get_xticklabels(),\n    rotation=45,\n    horizontalalignment='right')\nprint(corr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the correlation matrix, we don't see a single variable that is strongly correlated to winning('blueWins'). The two highest correlation coefficient variables are gold('blueGoldDiff') and experience('blueExperienceDiff'), which are also the two main KPIs of the early game. They are associated with wards destroyed, lane/jungle minions killed, KDA, dragons/heralds killed. Tower destroyed provide gold but not experience, and the average level results from experience. Also extra gold could be gained by equipping certain items, which is not accounted by the variables mentioned.\n\nWith respect to the gold and experience gain, of all the contributive factors, kills('blueKillsDiff'), assists('blueAssistsDiff') have strong positive correlation, and death has strong negative correlation, which indicates the main gold gain strategy is through kills. Lane minion kills('blueCSDiff') also have a close to 0.7 correlation coefficient, which could be the second most important source of gold and experience. \n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"To predict winning team, which is essentially a binary classification problem, we initially consider the following models:\n* Decision tree/Ramdom forest\n* Logistic regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use gold and experience diff to predict winning team\nx = data_1[['blueGoldDiff','blueExperienceDiff']]\ny = data_1[['blueWins']]\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1) # 80% training and 20% test\n# Create Decision Tree classifer object\nclf = DecisionTreeClassifier(criterion=\"entropy\")\n# Train Decision Tree Classifer\nclf = clf.fit(x_train,y_train)\n#Predict the response for test dataset\ny_pred = clf.predict(x_test)\n# Model Accuracy\nprint(\"Accuracy of DT using gold and xp diff to predict winning team:\\n\",metrics.accuracy_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use all variables other than gold and experience difference to predict winning team\nx = data_1[data_1.columns.difference(['blueGoldDiff','blueExperienceDiff','blueWins','gameId'])]\ny = data_1[['blueWins']]\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1) # 80% training and 20% test\n# Create Decision Tree classifer object\nclf = DecisionTreeClassifier(criterion=\"entropy\")\n# Train Decision Tree Classifer\nclf = clf.fit(x_train,y_train)\n#Predict the response for test dataset\ny_pred = clf.predict(x_test)\n# Model Accuracy\nprint(\"Accuracy of DT using gold and xp diff to predict winning team:\\n\",metrics.accuracy_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}