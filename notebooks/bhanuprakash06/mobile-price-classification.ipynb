{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# read the files\ndf_train = pd.read_csv('../input/mobile-price-classification/train.csv')\ndf_test = pd.read_csv('../input/mobile-price-classification/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Concatenate both files\ndf_tot = pd.concat([df_train, df_test], axis = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Analyze the data\ndf_tot.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ID column is not required. Drop the column\ndf_tot.drop('id', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the skew of the target variable i.e price_range\nprint(df_tot['price_range'].skew())\nsns.distplot(df_tot['price_range'], kde=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tot.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split into train and test data\ntrain = df_tot.iloc[:2000, :]\ntest = df_tot.iloc[2000:,:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split into X and Y\nX_train = train.iloc[:,:20]\nX_test = test.iloc[:,:20]\nY_train = pd.DataFrame(train.iloc[:, -1])\nY_test = pd.DataFrame(test.iloc[:, -1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature selection\nfrom sklearn.feature_selection import RFECV\nfrom xgboost import XGBRegressor\nboost = XGBRegressor()\nrfecv = RFECV(boost, cv = 3, n_jobs = -1)\nrfecv = rfecv.fit(X_train, Y_train)\nprint(f\"No. of highly important features: {rfecv.n_features_}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imp_features = X_train.columns.values[rfecv.support_]\nX_imp = X_train[imp_features]\nX_test_imp = X_test[imp_features]\nX_test_imp.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import mean_absolute_error as MAE\nfrom sklearn.metrics import mean_squared_error as MSE\nfrom sklearn.metrics import r2_score as R2\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import RobustScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"robust = RobustScaler()\nX_imp_scaled = robust.fit_transform(X_imp)\nrandom = RandomForestClassifier(max_depth=2, random_state=0)\nrandom.fit(X_imp_scaled, Y_train)\nres = random.predict(X_imp_scaled)\nprint(classification_report(Y_train, res))\nprint(confusion_matrix(Y_train, res))\n# print('MAE ',MAE(Y_test, Y_pred))\n# print('MSE ',MSE(Y_test, Y_pred))\n# print('R2 ',R2(Y_test, Y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=10)\nknn.fit(X_imp_scaled, Y_train)\nres = knn.predict(X_imp_scaled)\nprint(classification_report(Y_train, res))\nprint(confusion_matrix(Y_train, res))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=10)\nknn.fit(X_imp, Y_train)\nres = knn.predict(X_imp)\nprint(classification_report(Y_train, res))\nprint(confusion_matrix(Y_train, res))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=10)\nknn.fit(X_train, Y_train)\nres = knn.predict(X_train)\nprint(classification_report(Y_train, res))\nprint(confusion_matrix(Y_train, res))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}