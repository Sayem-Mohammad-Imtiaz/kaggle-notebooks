{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime as dt\nimport time\nfrom statsmodels.tsa.holtwinters import Holt\nfrom statsmodels.tsa.arima_model import ARIMA\n# Simple Exponential Smoothing\nfrom statsmodels.tsa.holtwinters import ExponentialSmoothing\nfrom sklearn import metrics\n#pd.set_option('display.max_columns',None)\n#pd.set_option('display.max_rows',None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/sunspots/Sunspots.csv',index_col=0,#parse_dates=['Date'],\n                   names=['Date','Total_Sunspots'],header=0)\ndata.tail(100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's do the analysis on data from 1751 to 2000. That's 250 years.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.loc[(data['Date']>='1751') & (data['Date']<='2001'),['Date','Total_Sunspots']]\ndata.reset_index(inplace=True)\ndata.drop('index',axis=1,inplace=True)\ndata","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating a new column called nth_year where each value in the column is an integer which represents 1 if it is 1st year of the decade or 2 if it is 2nd year of the decade and so on. This column is created to analyze if any seasonality exists in the data for 25 decades.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['nth_year'] = [str(d)[3] for d in data.Date]\ndata['nth_year']=data['nth_year'].replace('0','10')\ndata","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Converting date column to datetime object and nth_year to float type.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Date'] = pd.to_datetime(data['Date'])\ndata['nth_year'] = data['nth_year'].astype(float)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the below plot you will see that there is some seasonality. By looking closer we can observe that after every 8-9 years the pattern is repeating. Also we can observe that after a specific period of time the number of sunspots start to decrease and then start to increase.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(data['Total_Sunspots'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Extracting year and month from the date column.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['year'] = pd.DatetimeIndex(data['Date']).year\ndata['month'] = [d.strftime('%b') for d in data.Date]\ndata","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we have to observe the trend and seasonality clearly. For that we use boxlots.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(3, 1, figsize=(20,15), dpi= 80)\nsns.boxplot(x='year', y='Total_Sunspots', data=data, ax=axes[0])\nsns.boxplot(x='nth_year', y='Total_Sunspots', data=data,ax = axes[1])\nsns.boxplot(x='month', y='Total_Sunspots', data=data,ax = axes[2])\n\n# Set Title\naxes[0].set_title('Year-wise Box Plot\\n(The Trend)', fontsize=18); \n\naxes[1].set_title('Nth_year-wise Box Plot\\n(The Seasonality)', fontsize=18)\n\naxes[2].set_title('Month-wise Box Plot\\n(The Seasonality)', fontsize=18)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.set_index('Date',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.seasonal import seasonal_decompose\nfrom dateutil.parser import parse\n\n# Import Data\n# Multiplicative Decomposition \n#result_mul = seasonal_decompose(data['Total_Sunspots'], model='multiplicative', extrapolate_trend='freq')\n\n# Additive Decomposition\nresult_add = seasonal_decompose(data['Total_Sunspots'], model='additive', extrapolate_trend='freq',freq=96)\n\n# Plot\nplt.rcParams.update({'figure.figsize': (5,5)})\n#result_mul.plot().suptitle('Multiplicative Decompose', fontsize=22)\nresult_add.plot().suptitle('Additive Decompose', fontsize=22)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Detrending Manually","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['rolling_mean'] = data['Total_Sunspots'].rolling(12).mean()\ndata['Detrend'] = data['Total_Sunspots'] - data['rolling_mean']\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(data['Detrend'])\nplt.title('Detrended',fontsize=16)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Detrending using seasonal_decompose","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using statmodels: Subtracting the Trend Component.\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nresult_add = seasonal_decompose(data['Total_Sunspots'], model='add', extrapolate_trend='freq',freq=96)\ndetrended = data.Total_Sunspots.values -result_add.trend\nplt.plot(detrended)\nplt.title('Drug Sales detrended by subtracting the trend component', fontsize=16)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Deseasonalizing using seasonal decompose","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.seasonal import seasonal_decompose\nresult_add = seasonal_decompose(data['Total_Sunspots'], model='add', extrapolate_trend='freq',freq=96)\ndeseasonalized = data.Total_Sunspots.values -result_add.seasonal\nplt.plot(deseasonalized)\nplt.title('Drug Sales deseasonalized by subtracting the seasonal component', fontsize=16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Autocorrelation plot\n\nThis helps us to find if current value depends on previous values. In the plot you can observe that current value is dependent on previous 110-125 values. This can be around 8-10 years as it is monthly data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas.plotting import autocorrelation_plot\n\n\n# Draw Plot\nplt.rcParams.update({'figure.figsize':(9,5), 'figure.dpi':120})\nautocorrelation_plot(data['Total_Sunspots'].tolist())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"acf plot helps us understand whether the data in additive or multiplicatve in some way. By looking at the plot we can improvise our understanding from above plot and say that present value depends on previous 25-27 values.\n\npacf plot further says that present value depends only on previous 6 values. All these plots help us narrow down thinking and make our model efficient.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.stattools import acf, pacf\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n\n# Draw Plot\nfig, axes = plt.subplots(1,2,figsize=(16,3), dpi= 100)\nplot_acf(data['Total_Sunspots'].tolist(), lags=100, ax=axes[0])\nplot_pacf(data['Total_Sunspots'].tolist(), lags=50, ax=axes[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Holt Winter's Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"count = int(data.shape[0]*0.8)\nTrain = data[:count]\nTest = data[count:]\n\ny_hat_avg = Test.copy()\nfit1 = Holt(np.asarray(Train['Total_Sunspots'])).fit()\ny_hat_avg['Holt_Winter'] = fit1.predict(start=count+1,end=data.shape[0])\nplt.figure(figsize=(16,8))\nplt.plot(Train.index, Train['Total_Sunspots'], label='Train')\nplt.plot(Test.index,Test['Total_Sunspots'], label='Test')\nplt.plot(y_hat_avg.index,y_hat_avg['Holt_Winter'], label='Holt_Winter')\nplt.legend(loc='best')\n# plt.savefig('Holt_Winters.jpg')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Holt Winter's using exponential smoothing\n\nEven with exponential smoothing we did not get good predictions.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"new = data[['Total_Sunspots']]\nnew","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new.index.freq = 'M' # Start of the month\nTrain, Test = new.iloc[:count, 0], data.iloc[count:, 0]\n\nmodel = ExponentialSmoothing(Train, trend='add', seasonal='add', seasonal_periods=12, damped=True)\nhw_model = model.fit(optimized=True, use_boxcox=False, remove_bias=False)\npred = hw_model.predict(start=Test.index[0], end=Test.index[-1])\n\nplt.plot(Train.index, Train, label='Train')\nplt.plot(Test.index, Test, label='Test')\nplt.plot(pred.index, pred, label='Holt-Winters')\nplt.legend(loc='best');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ARMA Model\n\nremoving the differencing parameter","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"history = [x for x in Train]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We make a list for training data and we will be predicting next day's closing price with this data. Later the predicted value is appended to training data and next day's value is predicted again. This is repeated for all the test data.\n\nARIMA's forecast function gives 4 outputs.\n\npredicted value\n\nstandard error\n\nlower and upper confidance values which are very important when predicting on time series data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = []\nlower_list = []\nupper_list = []\nfor t in range(len(Test)):\n    model = ARIMA(history, order=(5,0,1))\n    model_fit = model.fit(disp=0)\n    output = model_fit.forecast()\n    yhat = output[0]\n    lower = output[2][0][0]\n    upper = output[2][0][1]\n    predictions.append(yhat)\n    lower_list.append(lower)\n    upper_list.append(upper)\n    obs = Test[t]\n    history.append(obs)\n    print('predicted=%f, expected=%f' % (yhat, obs))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"error = metrics.mean_squared_error(Test, predictions)\nprint('Test MSE: %.3f' % error)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below is the plot for orginal test data values, predicted values and confidance interval.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot\nplt.plot(Test.values,color='black')\nplt.plot(lower_list,color='red')\nplt.plot(upper_list,color='green')\nplt.plot(predictions)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}