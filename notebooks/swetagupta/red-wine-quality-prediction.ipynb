{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-21T12:45:36.937525Z","iopub.execute_input":"2021-09-21T12:45:36.938041Z","iopub.status.idle":"2021-09-21T12:45:36.959232Z","shell.execute_reply.started":"2021-09-21T12:45:36.937923Z","shell.execute_reply":"2021-09-21T12:45:36.957773Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"color:powderblue;\"> The Red Wine Quality Prediction </h1>\n<h3 style=\"color:pink;\"> Step by step explanation </h3>","metadata":{}},{"cell_type":"code","source":"#Importing all the necessary libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n%matplotlib inline\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import confusion_matrix\nfrom collections import Counter\nfrom IPython.core.display import display, HTML\nsns.set_style('darkgrid')","metadata":{"execution":{"iopub.status.busy":"2021-09-21T12:45:36.961347Z","iopub.execute_input":"2021-09-21T12:45:36.961897Z","iopub.status.idle":"2021-09-21T12:45:38.51513Z","shell.execute_reply.started":"2021-09-21T12:45:36.961856Z","shell.execute_reply":"2021-09-21T12:45:38.513928Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"color:powderblue;\"> EDA </h2>","metadata":{}},{"cell_type":"code","source":"#loading dataset\nrwine = pd.read_csv('/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')\n\n#Shape\nprint(rwine.shape)\nprint(\"----------------------------\")\nprint(rwine.head(5))\nprint(\"----------------------------\")\nprint(rwine.info())\nprint(\"----------------------------\")\nprint(rwine.describe())","metadata":{"execution":{"iopub.status.busy":"2021-09-21T12:45:38.517172Z","iopub.execute_input":"2021-09-21T12:45:38.517479Z","iopub.status.idle":"2021-09-21T12:45:38.625545Z","shell.execute_reply.started":"2021-09-21T12:45:38.517446Z","shell.execute_reply":"2021-09-21T12:45:38.624485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 style=\"color:pink;\"> Data is clean no null values present </h3>","metadata":{}},{"cell_type":"raw","source":"rwine.isnull().mean()","metadata":{"execution":{"iopub.status.busy":"2021-08-21T13:02:48.548048Z","iopub.execute_input":"2021-08-21T13:02:48.548628Z","iopub.status.idle":"2021-08-21T13:02:48.560177Z","shell.execute_reply.started":"2021-08-21T13:02:48.548581Z","shell.execute_reply":"2021-08-21T13:02:48.559159Z"}}},{"cell_type":"code","source":"rwine[\"quality\"].unique","metadata":{"execution":{"iopub.status.busy":"2021-09-21T12:45:38.627296Z","iopub.execute_input":"2021-09-21T12:45:38.627632Z","iopub.status.idle":"2021-09-21T12:45:38.638108Z","shell.execute_reply.started":"2021-09-21T12:45:38.627596Z","shell.execute_reply":"2021-09-21T12:45:38.637265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"color:powderblue;\"> Plotting Charts and Observing them </h1>","metadata":{}},{"cell_type":"code","source":"#Here we see that fixed acidity does not give any specification to classify the quality.\nfig = plt.figure(figsize = (10,6))\nsns.barplot(x = 'quality', y = 'fixed acidity', data = rwine)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-21T12:45:38.639377Z","iopub.execute_input":"2021-09-21T12:45:38.639927Z","iopub.status.idle":"2021-09-21T12:45:39.115944Z","shell.execute_reply.started":"2021-09-21T12:45:38.639882Z","shell.execute_reply":"2021-09-21T12:45:39.114849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfig = plt.figure(figsize = (10,6))\nsns.barplot(x = 'quality', y = 'volatile acidity', data = rwine)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-21T12:45:39.117559Z","iopub.execute_input":"2021-09-21T12:45:39.117982Z","iopub.status.idle":"2021-09-21T12:45:39.52674Z","shell.execute_reply.started":"2021-09-21T12:45:39.117935Z","shell.execute_reply":"2021-09-21T12:45:39.525597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x = 'quality', y = 'citric acid', data = rwine)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T12:45:39.528165Z","iopub.execute_input":"2021-09-21T12:45:39.528509Z","iopub.status.idle":"2021-09-21T12:45:39.954698Z","shell.execute_reply.started":"2021-09-21T12:45:39.528474Z","shell.execute_reply":"2021-09-21T12:45:39.953415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize = (20,20))\nsns.lineplot(x = 'alcohol', y = 'citric acid', data = rwine)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T12:45:39.956655Z","iopub.execute_input":"2021-09-21T12:45:39.957031Z","iopub.status.idle":"2021-09-21T12:45:41.912655Z","shell.execute_reply.started":"2021-09-21T12:45:39.956994Z","shell.execute_reply":"2021-09-21T12:45:41.911464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x = 'quality', y = 'residual sugar', data = rwine)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T12:45:41.916529Z","iopub.execute_input":"2021-09-21T12:45:41.917167Z","iopub.status.idle":"2021-09-21T12:45:42.530028Z","shell.execute_reply.started":"2021-09-21T12:45:41.917101Z","shell.execute_reply":"2021-09-21T12:45:42.528663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x = 'quality', y = 'chlorides', data = rwine)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T12:45:42.532176Z","iopub.execute_input":"2021-09-21T12:45:42.532505Z","iopub.status.idle":"2021-09-21T12:45:42.97477Z","shell.execute_reply.started":"2021-09-21T12:45:42.532469Z","shell.execute_reply":"2021-09-21T12:45:42.973599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x = 'quality', y = 'total sulfur dioxide', data = rwine)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T12:45:42.976323Z","iopub.execute_input":"2021-09-21T12:45:42.97667Z","iopub.status.idle":"2021-09-21T12:45:43.407355Z","shell.execute_reply.started":"2021-09-21T12:45:42.976634Z","shell.execute_reply":"2021-09-21T12:45:43.406127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set_style(\"whitegrid\");\nsns.pairplot(rwine, hue=\"quality\",height=3);\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-21T12:48:33.419372Z","iopub.execute_input":"2021-09-21T12:48:33.420021Z","iopub.status.idle":"2021-09-21T12:49:18.986898Z","shell.execute_reply.started":"2021-09-21T12:48:33.419972Z","shell.execute_reply":"2021-09-21T12:49:18.985729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"color:pink;\"> Encoding our target variable </h1>","metadata":{"execution":{"iopub.status.busy":"2021-09-08T13:45:14.618513Z","iopub.execute_input":"2021-09-08T13:45:14.618915Z","iopub.status.idle":"2021-09-08T13:45:14.626528Z","shell.execute_reply.started":"2021-09-08T13:45:14.618883Z","shell.execute_reply":"2021-09-08T13:45:14.624793Z"}}},{"cell_type":"markdown","source":"Why Encoding is Important?\nWe want to classify our data. And it only make sense if our data is catagorical.\nSo, we are splitting the data in Good or Bad.","metadata":{}},{"cell_type":"code","source":"rwine['quality'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-21T12:45:43.409046Z","iopub.execute_input":"2021-09-21T12:45:43.409483Z","iopub.status.idle":"2021-09-21T12:45:43.420773Z","shell.execute_reply.started":"2021-09-21T12:45:43.409433Z","shell.execute_reply":"2021-09-21T12:45:43.418569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 style","metadata":{}},{"cell_type":"code","source":"bins = (2, 6, 8)\nlabels = ['bad', 'good']\nrwine['quality'] = pd.cut(x = rwine['quality'], bins = bins, labels = labels)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T12:45:43.422964Z","iopub.execute_input":"2021-09-21T12:45:43.423632Z","iopub.status.idle":"2021-09-21T12:45:43.437226Z","shell.execute_reply.started":"2021-09-21T12:45:43.423558Z","shell.execute_reply":"2021-09-21T12:45:43.435423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rwine[\"quality\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-21T12:45:43.439626Z","iopub.execute_input":"2021-09-21T12:45:43.440278Z","iopub.status.idle":"2021-09-21T12:45:43.458153Z","shell.execute_reply.started":"2021-09-21T12:45:43.44022Z","shell.execute_reply":"2021-09-21T12:45:43.456088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabelencoder_y = LabelEncoder()\nrwine['quality'] = labelencoder_y.fit_transform(rwine['quality'])\nrwine['quality'] ","metadata":{"execution":{"iopub.status.busy":"2021-09-21T12:45:43.460446Z","iopub.execute_input":"2021-09-21T12:45:43.460932Z","iopub.status.idle":"2021-09-21T12:45:43.483987Z","shell.execute_reply.started":"2021-09-21T12:45:43.46088Z","shell.execute_reply":"2021-09-21T12:45:43.482729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"color:powderblue;\"> Dividing the columns into input and target variable.</h1>","metadata":{}},{"cell_type":"code","source":"X = rwine.drop('quality', axis = 1).values\ny = rwine['quality'].values.reshape(-1,1)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T12:45:43.485382Z","iopub.execute_input":"2021-09-21T12:45:43.485778Z","iopub.status.idle":"2021-09-21T12:45:43.502087Z","shell.execute_reply.started":"2021-09-21T12:45:43.485739Z","shell.execute_reply":"2021-09-21T12:45:43.500381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3>The Data is divided using basic 80% of traning and 20% test set </h3>","metadata":{}},{"cell_type":"code","source":"# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T12:45:43.505182Z","iopub.execute_input":"2021-09-21T12:45:43.506638Z","iopub.status.idle":"2021-09-21T12:45:43.514493Z","shell.execute_reply.started":"2021-09-21T12:45:43.506583Z","shell.execute_reply":"2021-09-21T12:45:43.513733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 style=\"color:pink;\"> Feature Scaling:  It is the process of standerizing the data. We do this to our data so that while building a machine learning model, our model is not biased towards a particular feature of the dataset. </h3>","metadata":{}},{"cell_type":"code","source":"# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train_scaled = sc.fit_transform(X_train)\nX_test_scaled = sc.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T12:45:43.515797Z","iopub.execute_input":"2021-09-21T12:45:43.516333Z","iopub.status.idle":"2021-09-21T12:45:43.529303Z","shell.execute_reply.started":"2021-09-21T12:45:43.516281Z","shell.execute_reply":"2021-09-21T12:45:43.528377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_scaled","metadata":{"execution":{"iopub.status.busy":"2021-09-21T12:45:43.530685Z","iopub.execute_input":"2021-09-21T12:45:43.53133Z","iopub.status.idle":"2021-09-21T12:45:43.543435Z","shell.execute_reply.started":"2021-09-21T12:45:43.531285Z","shell.execute_reply":"2021-09-21T12:45:43.5423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"color:powderblue;\"> Logistic Regression (Sigmoid/S shaped) </h2>","metadata":{}},{"cell_type":"code","source":"# Fitting Logistic Regression to the Training set\n#Taken the maximum iteration possible, assigned default penality,alowed constant adding\nfrom sklearn.linear_model import LogisticRegression\nclassifier_lr = LogisticRegression(C=1, fit_intercept=True, max_iter=1000, penalty = 'l2', solver='liblinear')\n#The numpy.ravel() functions returns contiguous flattened array.\nclassifier_lr.fit(X_train_scaled, y_train.ravel())","metadata":{"execution":{"iopub.status.busy":"2021-09-21T12:45:43.545108Z","iopub.execute_input":"2021-09-21T12:45:43.545558Z","iopub.status.idle":"2021-09-21T12:45:43.747819Z","shell.execute_reply.started":"2021-09-21T12:45:43.545509Z","shell.execute_reply":"2021-09-21T12:45:43.74655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"color:pink;\"> Cross Validation: It is a resampling procedure used to evaluate machine learning models on a limited data sample. </h1>","metadata":{}},{"cell_type":"code","source":"# Predicting Cross Validation Score\n#taking 10 fold cross-validation\ncv_lr = cross_val_score(estimator = classifier_lr, X = X_train_scaled, y = y_train.ravel(), cv = 10)\nprint(\"CV: \", cv_lr.mean())\n\ny_pred_lr_train = classifier_lr.predict(X_train_scaled)\naccuracy_lr_train = accuracy_score(y_train, y_pred_lr_train)\nprint(\"Training set: \", accuracy_lr_train)\n\ny_pred_lr_test = classifier_lr.predict(X_test_scaled)\naccuracy_lr_test = accuracy_score(y_test, y_pred_lr_test)\nprint(\"Test set: \", accuracy_lr_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T12:45:43.749577Z","iopub.execute_input":"2021-09-21T12:45:43.750033Z","iopub.status.idle":"2021-09-21T12:45:43.827685Z","shell.execute_reply.started":"2021-09-21T12:45:43.749987Z","shell.execute_reply":"2021-09-21T12:45:43.826466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 style=\"color:lightgreen;\">Logistic Regressor gave us 88% Accuracy which is good but we will try to find better if possible.</h3>","metadata":{}},{"cell_type":"markdown","source":"<h3 style=\"color:powderblue;\"> Decison Tree: It is a supervised learning algorithm used for classification. <h3>","metadata":{}},{"cell_type":"markdown","source":"**Gini Coefficient: It shows the information gain and help to split the tree in more efficient way.**","metadata":{}},{"cell_type":"code","source":"# Fitting classifier to the Training set\n#gini coefficient\nfrom sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier(criterion = 'gini', max_features=6, max_leaf_nodes=400, random_state = 33)\ndt.fit(X_train_scaled, y_train.ravel())","metadata":{"execution":{"iopub.status.busy":"2021-09-21T12:45:43.829409Z","iopub.execute_input":"2021-09-21T12:45:43.829851Z","iopub.status.idle":"2021-09-21T12:45:43.958334Z","shell.execute_reply.started":"2021-09-21T12:45:43.829807Z","shell.execute_reply":"2021-09-21T12:45:43.957092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predicting Cross Validation Score\ncv_dt = cross_val_score(estimator = dt, X = X_train_scaled, y = y_train.ravel(), cv = 10)\nprint(\"CV: \", cv_dt.mean())\n\ny_pred_train = dt.predict(X_train_scaled)\naccuracy_dt_train = accuracy_score(y_train, y_pred_train)\nprint(\"Training set: \", accuracy_dt_train)\n\ny_pred_dt_test = dt.predict(X_test_scaled)\naccuracy_dt_test = accuracy_score(y_test, y_pred_dt_test)\nprint(\"Test set: \", accuracy_dt_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T12:45:43.96005Z","iopub.execute_input":"2021-09-21T12:45:43.960499Z","iopub.status.idle":"2021-09-21T12:45:44.028986Z","shell.execute_reply.started":"2021-09-21T12:45:43.960451Z","shell.execute_reply":"2021-09-21T12:45:44.027872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 style=\"color:pink;\"> Random Forest :   It consists of a large number of individual decision trees that operate as an ensemble. Each tree in the random forest spits out a class prediction and the class with the most votes becomes our model’s prediction. It also remove the problem created by over fitting of data</h3>","metadata":{}},{"cell_type":"code","source":"# Import the model we are using\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(criterion = 'entropy', max_features = 4, n_estimators = 800, random_state=33)\nrf.fit(X_train_scaled, y_train.ravel())","metadata":{"execution":{"iopub.status.busy":"2021-09-21T12:45:44.030584Z","iopub.execute_input":"2021-09-21T12:45:44.031223Z","iopub.status.idle":"2021-09-21T12:45:47.411936Z","shell.execute_reply.started":"2021-09-21T12:45:44.031172Z","shell.execute_reply":"2021-09-21T12:45:47.410845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" #Use the forest's predict method on the test data\npredictions = rf.predict(X_test_scaled)\n# Calculate the absolute errors\nerrors = abs(predictions - y_test)\n# Print out the mean absolute error (mae)\nprint('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')","metadata":{"execution":{"iopub.status.busy":"2021-09-21T12:45:47.413452Z","iopub.execute_input":"2021-09-21T12:45:47.41383Z","iopub.status.idle":"2021-09-21T12:45:47.540198Z","shell.execute_reply.started":"2021-09-21T12:45:47.413772Z","shell.execute_reply":"2021-09-21T12:45:47.53917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predicting Cross Validation Score\ncv_rf = cross_val_score(estimator = rf, X = X_train_scaled, y = y_train.ravel(), cv = 10)\nprint(\"CV: \", cv_rf.mean())\n\ny_pred_rf_train = rf.predict(X_train_scaled)\naccuracy_rf_train = accuracy_score(y_train, y_pred_rf_train)\nprint(\"Training set: \", accuracy_rf_train)\n\ny_pred_rf_test = rf.predict(X_test_scaled)\naccuracy_rf_test = accuracy_score(y_test, y_pred_rf_test)\nprint(\"Test set: \", accuracy_rf_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T12:45:47.541498Z","iopub.execute_input":"2021-09-21T12:45:47.54204Z","iopub.status.idle":"2021-09-21T12:46:19.603927Z","shell.execute_reply.started":"2021-09-21T12:45:47.542002Z","shell.execute_reply":"2021-09-21T12:46:19.602791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 style=\"color:pink;\">Support Vector Machine: Support Vector Machine” (SVM) is a supervised machine learning algorithm that can be used for both classification or regression challenges </h3>","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC","metadata":{"execution":{"iopub.status.busy":"2021-09-21T12:46:19.607977Z","iopub.execute_input":"2021-09-21T12:46:19.608341Z","iopub.status.idle":"2021-09-21T12:46:19.612758Z","shell.execute_reply.started":"2021-09-21T12:46:19.608301Z","shell.execute_reply":"2021-09-21T12:46:19.611835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 style=\"color:powder Blue;\">Linear </h3>","metadata":{}},{"cell_type":"code","source":"svc = SVC(kernel = 'linear')\nsvc.fit(X_train_scaled, y_train.ravel())\npred_svc = svc.predict(X_test_scaled)\nprint(classification_report(y_test, pred_svc))","metadata":{"execution":{"iopub.status.busy":"2021-09-21T12:46:19.614534Z","iopub.execute_input":"2021-09-21T12:46:19.614887Z","iopub.status.idle":"2021-09-21T12:46:19.660353Z","shell.execute_reply.started":"2021-09-21T12:46:19.614853Z","shell.execute_reply":"2021-09-21T12:46:19.659222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predicting Cross Validation Score\ncv_svm_linear = cross_val_score(estimator = svc, X = X_train_scaled, y = y_train.ravel(), cv = 10)\nprint(\"CV: \", cv_svm_linear.mean())\n\ny_pred_svm_linear_train = svc.predict(X_train_scaled)\naccuracy_svm_linear_train = accuracy_score(y_train, y_pred_svm_linear_train)\nprint(\"Training set: \", accuracy_svm_linear_train)\n\ny_pred_svm_linear_test = svc.predict(X_test_scaled)\naccuracy_svm_linear_test = accuracy_score(y_test, y_pred_svm_linear_test)\nprint(\"Test set: \", accuracy_svm_linear_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T12:46:19.663076Z","iopub.execute_input":"2021-09-21T12:46:19.663556Z","iopub.status.idle":"2021-09-21T12:46:19.844596Z","shell.execute_reply.started":"2021-09-21T12:46:19.663504Z","shell.execute_reply":"2021-09-21T12:46:19.843431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 style=\"color:pink;\"> Radial Basis Function </h3>","metadata":{}},{"cell_type":"code","source":"# Fitting classifier to the Training set\nsvm_kernel = SVC(kernel = 'rbf', C = 10, tol = 0.001, gamma = 'scale')\nsvm_kernel.fit(X_train_scaled, y_train.ravel())\n","metadata":{"execution":{"iopub.status.busy":"2021-09-21T12:46:19.846353Z","iopub.execute_input":"2021-09-21T12:46:19.846716Z","iopub.status.idle":"2021-09-21T12:46:19.895901Z","shell.execute_reply.started":"2021-09-21T12:46:19.84668Z","shell.execute_reply":"2021-09-21T12:46:19.894837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predicting Cross Validation Score\ncv_svm_kernel = cross_val_score(estimator = svm_kernel, X = X_train_scaled, y = y_train.ravel(), cv = 10)\nprint(\"CV: \", cv_svm_kernel.mean())\n\ny_pred_svm_kernel_train = svm_kernel.predict(X_train_scaled)\naccuracy_svm_kernel_train = accuracy_score(y_train, y_pred_svm_kernel_train)\nprint(\"Training set: \", accuracy_svm_kernel_train)\n\ny_pred_svm_kernel_test = svm_kernel.predict(X_test_scaled)\naccuracy_svm_kernel_test = accuracy_score(y_test, y_pred_svm_kernel_test)\nprint(\"Test set: \", accuracy_svm_kernel_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T12:46:19.897429Z","iopub.execute_input":"2021-09-21T12:46:19.897757Z","iopub.status.idle":"2021-09-21T12:46:20.275717Z","shell.execute_reply.started":"2021-09-21T12:46:19.897722Z","shell.execute_reply":"2021-09-21T12:46:20.274496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svc = SVC(kernel = 'rbf')\nsvc.fit(X_train_scaled, y_train.ravel())\npred_svc = svc.predict(X_test_scaled)\nprint(classification_report(y_test, y_pred_svm_kernel_test))","metadata":{"execution":{"iopub.status.busy":"2021-09-21T12:46:20.277189Z","iopub.execute_input":"2021-09-21T12:46:20.27753Z","iopub.status.idle":"2021-09-21T12:46:20.325796Z","shell.execute_reply.started":"2021-09-21T12:46:20.277491Z","shell.execute_reply":"2021-09-21T12:46:20.324353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h4 style=\"color:lightgreen;\">We can see that we have everything better in RBC than we had in linear. Model accuracy, precision everything improved</h4>","metadata":{}},{"cell_type":"markdown","source":"**Also, The model which gives the best result is Rndom Forest Classifier**","metadata":{}},{"cell_type":"markdown","source":"At the very end, I would just like to mention I have take help of several notebooks to understand and write my own.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}