{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"text-align:center;color:blue\">Don't forget to Upvote if you like it.ðŸ˜Š</h1>"},{"metadata":{},"cell_type":"markdown","source":"# **Introduction**\n\n\nIn this kernal we will going through the whole process of creating a Machine Learning on the Heart Disease dataset. It predicts the patients which can survive by considering various features."},{"metadata":{},"cell_type":"markdown","source":"<h4 style='color:red'>There are many risk factors for heart diseases: age, sex, tobacco use, physical inactivity, excessive alcohol consumption, unhealthy diet, obesity, genetic predisposition and family history of cardiovascular disease, raised blood pressure (hypertension), raised blood sugar,etc. We will predict heart disease in this model by considering various such factors</h4>"},{"metadata":{},"cell_type":"markdown","source":"![](https://www.health.harvard.edu/media/content/images/p2_QA_MLJuly19_gi484761271.jpg)"},{"metadata":{},"cell_type":"markdown","source":"<h1>Importing Libraries</h1>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Importing Dataset</h1>"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/heart-disease-uci/heart.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Data Preprocessing</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Data Visualization</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.pairplot(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,10))\nsns.heatmap(df.corr(),annot=True,cmap=plt.cm.plasma)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,15))\nfor i in range(len(df.columns)-1):\n    plt.subplot(5,3,i+1)\n    sns.scatterplot(df['target'],df[df.columns[i]],hue=df['target'])\n    plt.xticks([0,1])\nplt.tight_layout(pad=4.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df['target'],data=df)\nplt.grid()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Building and Training the Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nX=df.drop('target',axis=1)\nY=df['target']\ndf=sc.fit(X).transform(X)\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.25,random_state=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>We will train model function in which we will train the data for 6 Different Algorithms</h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def model(X_train,y_train):\n    models=[]\n    \n    lr=LogisticRegression(max_iter=1000)\n    lr.fit(X_train,y_train)\n    models.append(lr)\n    \n    tree=DecisionTreeClassifier(random_state=42)\n    tree.fit(X_train,y_train)\n    models.append(tree)\n    \n    svm=SVC(kernel='rbf', gamma=0.1, C=1.0)\n    svm.fit(X_train,y_train)\n    models.append(svm)\n    \n    knn=KNeighborsClassifier(n_neighbors=5)\n    knn.fit(X_train,y_train)\n    models.append(knn)\n    \n    rfc=RandomForestClassifier()\n    rfc.fit(X_train,y_train)\n    models.append(rfc)\n    \n    nb=GaussianNB()\n    nb.fit(X_train,y_train)\n    models.append(nb)\n    \n    return models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models=model(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\ntrain_accuracy=[]\ntest_accuracy=[]\n\nfor i in range(6):\n    yhat=models[i].predict(X_test)\n    yhat_t=models[i].predict(X_train)\n    train_accuracy.append(accuracy_score(yhat_t,y_train))\n    test_accuracy.append(accuracy_score(yhat,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Model=['LogisticRegression','DecisionTreeClassifier','SVC','KNeighborsClassifier','RandomForestClassifier','GaussianNB']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Accuracy_score=pd.DataFrame({ \n    'Model':Model,\n    'Train_Accuracy':train_accuracy,\n    'Test_Accuracy':test_accuracy\n})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Finding Best Model</h1>"},{"metadata":{},"cell_type":"markdown","source":"<h4>Below is the accuracy score for testing and training data for various Models</h4>"},{"metadata":{"trusted":true},"cell_type":"code","source":"Accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score=dict(zip(Model, Accuracy_score['Test_Accuracy'].values)) \nscore={k: v for k, v in sorted(score.items(), key=lambda item: item[1])}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nplt.plot(list(score.keys()),list(score.values()),marker='x',color='red')\nplt.xlabel('Model')\nplt.ylabel('Accuracy')\nplt.title('Model Vs Accuracy')\nplt.grid()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}