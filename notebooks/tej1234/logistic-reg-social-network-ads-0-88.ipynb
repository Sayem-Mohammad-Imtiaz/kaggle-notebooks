{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Logistic Regression on Social Network Ads","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"## 1: Importing libraries and reading the dataset","metadata":{}},{"cell_type":"code","source":"# Importing the libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder, normalize, StandardScaler\n\nfrom sklearn.linear_model import LogisticRegression\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reading the dataset\ndf = pd.read_csv(\"../input/logistic-regression/Social_Network_Ads.csv\")\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df.drop([\"User ID\", \"Purchased\"], axis=1)\ny = df[[\"Purchased\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2: EDA\n\nPlotting pairplot to visualize the distribution of data","metadata":{}},{"cell_type":"code","source":"sns.pairplot(df.drop([\"User ID\"], axis=1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3: Feature Engineering","metadata":{}},{"cell_type":"code","source":"features_num = [\"Age\", \"EstimatedSalary\"]\nfeatures_cat = [\"Gender\"]\n\npreprocessor = ColumnTransformer([(\"OneHotEncoder\", OneHotEncoder(), features_cat),\n                                 (\"Normalization\", StandardScaler(), features_num)], remainder=\"passthrough\")\n\nX = preprocessor.fit_transform(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4: Training and Fitting the model","metadata":{}},{"cell_type":"code","source":"model = LogisticRegression()\nmodel.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5: Hyperparameter Tuning\n\n\nHyperparameter tuning is an important step in model building, it defines the parameters of an estimator till a max accuracy is reached. We will be performing 2 hyperparameter tuning operations one after the other\n- RandomizedSearchCV - To arrive at a paramter combination that will be likely close to the best combination, this process will occur quickly and help us difine our GridSearchCV parameters\n- GridSearchCV - This is run once the RandomizedSearchCV is complete, this will be an extensive search to find the best paramters\n","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### RandomizedSearchCV","metadata":{}},{"cell_type":"code","source":"# 1. Defining the param gird\nparam_grid = {\n    \"penalty\": [\"l1\", \"l2\", \"elasticnet\", \"none\"],\n    \"C\": np.logspace(-3, 3, 7)\n}\n# 2. Defining the RandomizedSearchCV class\nmodel_rscv = RandomizedSearchCV(model, param_grid, cv=10)\nmodel_rscv.fit(X_train, y_train)\n\n# 3. Getting the best params and score\nprint(model_rscv.best_params_)\nprint(model_rscv.best_score_)\n\n# 4. Getting the prediciting for testing data\ny_pred = model_rscv.best_estimator_.fit(X_train, y_train).predict(X_test)\n\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))\nprint(accuracy_score(y_test, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Even after performing RandomizedGridSearchCV, we don't see improvement in the model (~88%). We will stick with these parameters.","metadata":{}}]}