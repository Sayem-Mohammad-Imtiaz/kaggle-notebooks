{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vengono importati i dati che verrannno utilizzati per testare i metodi."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"Mall_Customers=pd.read_csv('../input/mall-customers/Mall_Customers.csv')\nIris = pd.read_csv(\"../input/iris/Iris.csv\")\nSeed_Data = pd.read_csv(\"../input/seed-from-uci/Seed_Data.csv\")\nX_C1=[]\nwith open('/kaggle/input/uefclusters2/s1.txt') as f:\n    for line in f:\n        x, y = line.split()\n        X_C1.append([int(x),int(y)])\nX_C2=[]\nwith open('/kaggle/input/uefclusters2/s2.txt') as f:\n    for line in f:\n        x, y = line.split()\n        X_C2.append([int(x),int(y)])\nX_C3=[]\nwith open('/kaggle/input/uefclusters2/s3.txt') as f:\n    for line in f:\n        x, y = line.split()\n        X_C3.append([int(x),int(y)])\nX_C4=[]\nwith open('/kaggle/input/uefclusters2/s4.txt') as f:\n    for line in f:\n        x, y = line.split()\n        X_C4.append([int(x),int(y)])\n\nX_M=Mall_Customers.values[:,(3,4)]\nX_I=Iris.values[:,(1,2,3,4)]\nX_S=Seed_Data.values[:,range(0,7)]\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Verranno utilizzate due metriche per valutare il numero di cluster da utilizzare: l'inerzia (iner), che è la somma del quadrato delle distanze dal centroide più vicino, e la silhouette, che è data da (b - a)/max(a, b), dove a è la distanza media all'interno di un cluster e b è la distanza media tra cluster. Si calcola il valore di queste due metriche tramite la funzione metricGenerator."},{"metadata":{"trusted":true},"cell_type":"code","source":"def metricGenerator(X):\n    sil=[0,0]\n    iner=[]\n    N=30\n    for k in range(1, N):\n            km = KMeans(init=\"k-means++\", n_clusters=k, n_init=20)\n            km.fit(X)\n            iner.append(km.inertia_)\n            if (k>1): \n                sil.append(silhouette_score(X,km.labels_))\n    n=iner[0]\n    for k in range(0,N-1):\n        iner[k] = iner[k]/n\n    return ([iner,sil])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Si possono osservare quindi i grafici di queste metriche applicati al dateset Mall_Customers:"},{"metadata":{"trusted":true},"cell_type":"code","source":"mall=metricGenerator(X_M)\nimport pylab as pl\npl.plot(mall[0])\npl.xlabel(\"numero di cluster\")\npl.ylabel(\"inerzia\")\npl.grid()\npl.show()\n\npl.plot(mall[1])\npl.grid()\npl.xlabel(\"numero di cluster\")\npl.ylabel(\"silhouette score\")\npl.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mentre per il grafico della silhouette è sufficente identificare il massimo per trovare il numero ottimale di cluster, l'inerzia è un valore che diminuisce con il numero di cluster usati, e si utilizza il metodo del gomito, spiegato in [questo blog](https://www.developersmaggioli.it/blog/apprendimento-non-supervisionato-clustering-k-means/). Bisogna quindi identificare il punto di gomito. Se si assume che dopo il punto di gomito il comportamento dell'inerzia è approssimativamente lineare, lo si può trovare usando la versione discreta della derivata seconda (che sarà nulla per una funzione lineare) ossia il rapporto incrementale del rapporto incrementale:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def dDer(lis):\n    ret=[]\n    for k in range (0,len(lis)-1):\n        ret.append(lis[k]-lis[k+1])\n    return(ret)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Il grafico seguente mostra la derivata dell'inerzia del dataset utilizzato."},{"metadata":{"trusted":true},"cell_type":"code","source":"pl.plot(dDer(dDer(mall[0])))\npl.xlabel(\"numero di cluster\")\npl.ylabel(\"derivata seconda\")\npl.grid()\npl.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Il gomito sarà il punto dove la derivata seconda diventa (approssimativamente) nulla, quindi un gomito sarà identificato quando la media dei quadrati di tre valori successivi sarà minore di una solgia data. Si usa la media di tre valori per evitare che un singolo punto, dove la derivata seconda è nulla, venga erroenamente identificato come punto di gomito, come avviene nel grafico soprastante per 2. La soglia verrà impostata d'ora in poi come 10^-4. Si può usare questo valore costante in quanto la funzione metricGenerator normalizza l'inerzia. Ci si aspetta, quindi, una soglia ad un valore simile, ma si potrebbe cercare un criterio migliore per la scelta di questo iperparametro. Non sarà però necessario in quanto verrà mostrato successivamente un metodo migliore."},{"metadata":{"trusted":true},"cell_type":"code","source":"def findElbow(lis,slg):\n        dd=dDer(dDer(lis))\n        for k in range(0,len(dd)-1):\n            if (dd[k]**2+dd[k+1]**2+dd[k+2]**2)/3<slg: \n                return(k)\n        return(len(dd)-1)\n            ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vengono applicati questi metodi al dataset dato, tenendo conto del fatto che il gomito trovato è più piccolo di 1 del valore cercato in quanto l'indice dell'array inizia a 0 ma l'inerzia viene calcolata per un numero di cluster maggiore uguale a 1. "},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"silhouette:\",mall[1].index(max(mall[1])),\" gomito:\",findElbow(mall[0],10**(-4))+1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I due metodi concordano su 5 come numero di cluster. Segue il grafico dei dati divisi in 5 cluster:"},{"metadata":{"trusted":true},"cell_type":"code","source":"pl.scatter(X_M[:,0],X_M[:,1],c=KMeans(init=\"k-means++\", n_clusters=5, n_init=20).fit(X_M).labels_)\npl.xlabel(\"annual income\")\npl.ylabel(\"spending score\")\npl.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Si può quindi vedere che i metodi hanno entrambi identificato il numero corretto di cluster.\nApplicando però questo metodo ad altri dataset si possono mettere in evidenza dei problemi. Viene studiato il dataset s1 preso da http://cs.joensuu.fi/sipu/datasets/ di cui è noto il numero di cluster da cui è composto (15)."},{"metadata":{"trusted":true},"cell_type":"code","source":"S1=metricGenerator(X_C1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pl.plot(S1[0])\npl.xlabel(\"numero di cluster\")\npl.ylabel(\"inerzia\")\npl.grid()\npl.show()\npl.plot(dDer(dDer(S1[0])))\npl.xlabel(\"numero di cluster\")\npl.ylabel(\"derivata seconda dell'inerzia\")\npl.grid()\npl.show()\nprint(\" gomito:\",findElbow(S1[0],10**(-4))+1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Si può vedere dal grafico della derivata seconda che ci sono due gomiti (due sezioni diverse dove la fuznione è lineare), e che l'algoritmo identifica il gomito errato. Questo problema potrebbe essere risolto modificando la soglia, ma in questo modo fallirebbe su altri dataset.\nLa soluzione proposta richiede una funzione che identifica più gomiti presenti, e seleziona il \"migliore\". Come gomito migliore viene selezionato quello dove il rapporto tra i valori della derivata seconda prima e dopo il gomito è maggiore, in questo modo la performance migliora sensibilmente."},{"metadata":{"trusted":true},"cell_type":"code","source":"def findElbowCandidates(lis,slg,slg2):\n    dd=dDer(dDer(lis))\n    el=[]\n    f=slg2\n    for k in range(0,len(dd)-2):\n        if f<slg2:\n            f=(dd[k]**2+dd[k+1]**2+dd[k+2]**2)/3\n        else:\n            if (dd[k]**2+dd[k+1]**2+dd[k+2]**2)/3<slg: \n                el.append([k,(dd[k]**2+dd[k+1]**2+dd[k+2]**2)/3,f])\n            f=(dd[k]**2+dd[k+1]**2+dd[k+2]**2)/3\n    return(el)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def findBestElbow(lis,slg,slg2):\n    el=findElbowCandidates(lis,slg,slg2)\n    el_v=[]\n    for k in range(0,len(el)):\n        el_v.append(el[k][2]/el[k][1])\n    return(el[el_v.index(max(el_v))][0])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Applicando i metodi fin'ora elencati al dataset S1 si ottengono quindi i seguenti risultati:\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"silhouette:\",S1[1].index(max(S1[1])),\" gomito semplice:\",findElbow(S1[0],10**(-4))+1,  \"gomito migliorato:\", findBestElbow(S1[0],10**(-3),10**(-6))+1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Verificato che il nuovo metodo trovato ci restituisce il valore voluto si può procedere a testare su altri dataset.\nLa funzione creata di seguito bestClusterNumber restituisce sotto forma di array il numero di cluster predetto da findBestElbow, dalla silhouette, dalla prima versione del metodo del gomito, dal valore massimo degli ultimi due metodi e dal valore massimo di tutti e tre i metodi. Tramite questa operazione di \"pooling\" delle varie predizioni si ottiene una predizione migliore delle singole predizioni. Si sceglie il valore maggiore in quanto, come vedremo successivamente, i metodi selezionati approssimano quasi esclusivamente per difetto il numero di cluster.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def bestClusterNumber(lis):\n    be = findBestElbow(lis[0],10**(-3),10**(-6))+1\n    si = lis[1].index(max(lis[1]))\n    se = findElbow(lis[0],10**(-4))+1\n    return([be,si,se,max(se,si),max(se,si,be)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bestClusterNumber(S1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def printBCN(name,target,res):\n    print(\"dataset\",name,\"formato da\",target,\"clusters:      gomito migliorato:\", res[0],\" silhouette:\",res[1],\" gomito semplice:\",res[2], \" pool2:\",res[3],\" pool3:\",res[4] )\ndef findBCN(name,target,data):\n    printBCN(name,target,bestClusterNumber(metricGenerator(data)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Applicando i metodi ai 3 dataset reali e ai 4 dataset generati si ottiengono i seguenti risultati:"},{"metadata":{"trusted":true},"cell_type":"code","source":"findBCN(\"Mall_Customers\",5, X_M)\nfindBCN(\"Iris Species\",3, X_I)\nfindBCN(\"Seed_from_UCI\",3, X_S)\nfindBCN(\"S1\",15, X_C1)\nfindBCN(\"S2\",15, X_C2)\nfindBCN(\"S3\",15, X_C3)\nfindBCN(\"S4\",15, X_C4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Si possono ulteriormente testare i metodi usati su una serie di dataset generati artificialmente tramite la funzione di sklearn make_blobs, che genererà dataset simili al seguente, avente come parametri 4 cluster e deviazione standard pari a 0.8:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.datasets import make_blobs\nX, Y= make_blobs(n_samples=500, centers=4, cluster_std=0.8, random_state=0)\npl.scatter(X[:,0],X[:,1],c=Y)\npl.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Il test verrà fatto su un numero di cluster che va da 3 a 8, questi generati con deviazione stardand da 0.4 a 1.2 con incrementi di 0.2. Per ogni configurazione verranno generati 4 dataset diversi."},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"\nrand_counter=0\nind=[]\nper=[]\nfor cl_n in range(3,9):\n    ind2=[]\n    per2=[]\n    for std in range (2,7):\n        ind1=[]\n        per1=[]\n        for rand in range(1,5):\n            \n            X, Y= make_blobs(n_samples=500, centers=cl_n, cluster_std=std/5, random_state=rand_counter)\n            Z=bestClusterNumber(metricGenerator(X))\n            ind1.append(Z)\n            per1.append(list(map(lambda x:x-cl_n, Z)))\n            #print(rand,std,cl_n,\" -> \", Z)\n            rand_counter+=1\n        ind2.append(ind1)\n        per2.append(per1)\n    ind.append(ind2)\n    per.append(per2)\nind=np.asarray(ind)\nper=np.asarray(per)\nprint(per)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I risultati del test sono organizzati in due matrici 6x5x4x5, che corrisponde a numero di cluster x deviazione standard x iterazione x metodo usato. In ind ogni elemento della matrice indica la predizione di numero di cluster per un dato dataset tramite un dato metodo, mentre la matrice per indica la differenza tra questo valore e la predizione corretta. Si userà quest'ultimo valore per valutare la performance dei metodi usati tramite due metriche: errore medio, che indica la differenza in media tra numero di cluster predetto e numero di cluster corretto, e hit rate, ossia il rapporto tra il numero di predizioni corrette e numero di predizioni totali. Viene calcolata anche quante volte la stima è avvenuta per eccesso, per confermare la validità del pooling tramite scelta del valore massimo."},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"def avErr (lis):\n    return(sum(map(abs,lis))/len(lis))\ndef avMissErr(lis):\n    return(sum(map(abs,lis))/sum(map(lambda x:x!=0,lis)))\ndef avHitR (lis):\n    return(sum(map(lambda x:x==0,lis))/len(lis))\ndef totOv (lis):\n    return(sum(map(lambda x:x>0,lis))/len(lis))\ndef flt(lis):\n    return([y for x in lis for y in x])\ndef flt2(lis):\n    return(flt(flt(lis)))\ndef printscore(name,lis):\n    print(\"Performance\",name,\": Errore medio:\",avErr(lis),\"Predizioni corrette:\", avHitR(lis),\"Errore medio sulle predizoni errate:\",avMissErr(lis) , \"Stime per ecesso:\", totOv(lis) )\ndef score(lis):\n    printscore(\"gomito migliorato\",flt2(lis[:,:,:,0]))\n    printscore(\"silhouette\",flt2(lis[:,:,:,1]))\n    printscore(\"gomito semplice\",flt2(lis[:,:,:,2]))\n    printscore(\"pooling di 2\",flt2(lis[:,:,:,3]))\n    printscore(\"pooling di 3\",flt2(lis[:,:,:,4]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score(per)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In conclusione, si può quindi vedere come il metodo del gomito migliorato performa meglio sia degli altri due metodi sia del loro pooling, e come in ogni caso il pooling di più metodi migliora la peformance globale."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}