{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Credit Card Dataset for Clustering\n## Table of Contents\n<ul>\n<li><a href=\"#Dictionary\">Data Dictionary</a></li>\n<li><a href=\"#intro\">Introduction</a></li>\n<li><a href=\"#wrangling\"> Data wrangling</a></li>\n<li><a href=\"#eda\">Exploratory Data Analysis</a></li>\n<li><a href=\"#cluster\">clustering </a></li>\n</ul> ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import matplotlib.pyplot as plt  # for visualization \n%matplotlib inline\nimport seaborn as sns           # for visualization ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# read the data\ndf = pd.read_csv('/kaggle/input/ccdata/CC GENERAL.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='Dictionary'></a>\n## Data Dictionary","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Following is the Data Dictionary for Credit Card dataset :-**\n\n- **CUSTID** : Identification of Credit Card holder (Categorical)\n- **BALANCE**: Balance amount left in their account to make purchases (\n- **BALANCEFREQUENCY** : How frequently the Balance is updated, score between 0 and 1 (1 = frequently updated, 0 = not frequently updated)\n- **PURCHASES** : Amount of purchases made from account\n- **ONEOFFPURCHASES**: Maximum purchase amount done in one-go\n- **INSTALLMENTSPURCHASES** : Amount of purchase done in installment\n- **CASHADVANCE**: Cash in advance given by the user\n- **PURCHASESFREQUENCY** : How frequently the Purchases are being made, score between 0 and 1 (1 = frequently purchased, 0 = not frequently purchased)\n- **ONEOFFPURCHASESFREQUENCY**: How frequently Purchases are happening in one-go (1 = frequently purchased, 0 = not frequently purchased)\n- **PURCHASESINSTALLMENTSFREQUENCY** : How frequently purchases in installments are being done (1 = frequently done, 0 = not frequently done)\n- **CASHADVANCEFREQUENCY** : How frequently the cash in advance being paid\n- **CASHADVANCETRX** : Number of Transactions made with \"Cash in Advanced\"\n- **PURCHASESTRX**: Numbe of purchase transactions made\n- **CREDITLIMIT**: Limit of Credit Card for user\n- **PAYMENTS** : Amount of Payment done by user\n- **MINIMUM_PAYMENTS** : Minimum amount of payments made by user\n- **PRCFULLPAYMENT** : Percent of full payment paid by user\n- **TENURE** : Tenure of credit card service for user","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id='intro'></a>\n## Introduction\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**This case requires to develop a customer segmentation to define marketing strategy. The\nsample Dataset summarizes the usage behavior of about 9000 active credit card holders during the last 6 months. The file is at a customer level with 18 behavioral variables.**\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id='wrangling'></a>\n## Data wrangling","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Missing Values","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"def missing_percentage(df):\n\n    total = df.isnull().sum().sort_values(\n        ascending=False)[df.isnull().sum().sort_values(ascending=False) != 0]\n    percent = (df.isnull().sum().sort_values(ascending=False) / len(df) *\n               100)[(df.isnull().sum().sort_values(ascending=False) / len(df) *\n                     100) != 0]\n    return pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n\n\nmissing_data = missing_percentage(df)\n\nfig, ax = plt.subplots( figsize=(16, 6))\n\nsns.barplot(x=missing_data.index,\n            y='Percent',\n            data=missing_data)\n\n\nax.set_title('Missing Values')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Checking Variables Before Imputing","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Just wanted to check variable distribution before we impute the missing ones","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nplt.subplot(1,2,1)\nsns.distplot(df.MINIMUM_PAYMENTS, color='#fdc029')\nplt.subplot(1,2,2)\nsns.distplot(df.CREDIT_LIMIT, color='#fdc029')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**After discovered the data with missing value and knowing its distribution, the best way to fill missing values is median**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## filling missing values ","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"df.MINIMUM_PAYMENTS.fillna(df.MINIMUM_PAYMENTS.median(),inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print('MINIMUM_PAYMENTS FEATURE HAS',df.MINIMUM_PAYMENTS.isna().sum(),'MISSING VALUE')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.CREDIT_LIMIT.fillna(df.CREDIT_LIMIT.median(),inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print('CREDIT_LIMIT FEATURE HAS',df.CREDIT_LIMIT.isna().sum(),'MISSING VALUE')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='eda'></a>\n## EDA","execution_count":null},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"g = sns.PairGrid(df)\ng.map(plt.scatter)\nplt.title('relations between features')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def scatter_purchases(x):\n    sns.scatterplot(y='PURCHASES',x=x,data = df,color='#171820',alpha=0.7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"scatter_purchases('BALANCE')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(16,5))\n\nplt.subplot(1,2,1)\nsns.lineplot(x='TENURE',y='PURCHASES',data=df)\nplt.title('The Purchases based on Tenure of credit card service for use')\nplt.subplot(1,2,2)\nscatter_purchases('TENURE')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Now we can confirm that with the increase in the period of use of the card, the purchase price increases, especially for a year, because there is a big difference between it and the rest**","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.hist(df.CREDIT_LIMIT)\nplt.title('credit limit distribution')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"col = list(df.drop('CUST_ID',axis=1).columns)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(30,30))\nfor idx,val in enumerate(col):\n    plt.subplot(6,3,idx+1)\n    sns.boxplot(x=val,data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## We can see that the data contains a lot of outliers which we have to deal with","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**But! What if we divide them into clusters; Outliers will be in Private cluster**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id='cluster'></a>\n\n# Clustering","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Kmeans","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscale = StandardScaler()\nX = scale.fit_transform(df.drop('CUST_ID',axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.cluster import KMeans\nn_clusters=30\ncost=[]\nfor i in range(1,n_clusters):\n    kmean= KMeans(i)\n    kmean.fit(X)\n    cost.append(kmean.inertia_)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.plot(cost, 'bx-')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"n_clusters=10\ncost=[]\nfor i in range(1,n_clusters):\n    kmean= KMeans(i)\n    kmean.fit(X)\n    cost.append(kmean.inertia_)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.plot(cost, 'gx-')\nplt.title('Elbow Criterion')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6 clusters are good","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"kmean= KMeans(6)\nkmean.fit(X)\nlabels=kmean.labels_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"clusters=pd.concat([df, pd.DataFrame({'cluster':labels})], axis=1)\nclusters.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"clusters.info()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"for c in clusters.iloc[:,1:]:\n    grid= sns.FacetGrid(clusters.iloc[:,1:], col='cluster')\n    grid.map(plt.hist, c)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- **Cluster0** People with average to high credit limit who make all type of purchases\n- \n- **Cluster1** This group has more people with due payments who take advance cash more often\n- \n- **Cluster2** Less money spenders with average to high credit limits who purchases mostly in installments\n- \n- **Cluster3** People with high credit limit who take more cash in advance\n- \n- **Cluster4** High spenders with high credit limit who make expensive purchases\n- \n- **Cluster5** People who don't spend much money and who have average to high credit limit","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Visualization of Clusters","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.decomposition import PCA\ndist = 1 - cosine_similarity(X)\n\npca = PCA(2)\npca.fit(dist)\nX_PCA = pca.transform(dist)\nX_PCA.shape","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"x, y = X_PCA[:, 0], X_PCA[:, 1]\n\ncolors = {0: 'red',\n          1: 'blue',\n          2: 'green', \n          3: 'yellow', \n          4: 'orange',  \n          5:'purple'}\n\nnames = {0: 'who make all type of purchases', \n         1: 'more people with due payments', \n         2: 'who purchases mostly in installments', \n         3: 'who take more cash in advance', \n         4: 'who make expensive purchases',\n         5:'who don\\'t spend much money'}\n  \ndf = pd.DataFrame({'x': x, 'y':y, 'label':labels}) \ngroups = df.groupby('label')\n\nfig, ax = plt.subplots(figsize=(20, 13)) \n\nfor name, group in groups:\n    ax.plot(group.x, group.y, marker='o', linestyle='', ms=5,\n            color=colors[name],label=names[name], mec='none')\n    ax.set_aspect('auto')\n    ax.tick_params(axis='x',which='both',bottom='off',top='off',labelbottom='off')\n    ax.tick_params(axis= 'y',which='both',left='off',top='off',labelleft='off')\n    \nax.legend()\nax.set_title(\"Customers Segmentation based on their Credit Card usage bhaviour.\")\nplt.show()\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}