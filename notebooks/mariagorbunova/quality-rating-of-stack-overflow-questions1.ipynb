{"cells":[{"metadata":{},"cell_type":"markdown","source":"# CIS09 Intro to Data Science Final Project"},{"metadata":{},"cell_type":"markdown","source":"*Name: Maria Gorbunova, Yueqi Wang *"},{"metadata":{},"cell_type":"markdown","source":"# **1. Project Description**"},{"metadata":{},"cell_type":"markdown","source":"Learn from 60,000 questions collected at Stack Overflow from 2016 to 2020, create models to label the quality of questions into three categories. \n\n    1.\tHQ: High-quality posts with a total of 30+ score and without a single edit.\n    2.\tLQ_EDIT: Low-quality posts with a negative score, and multiple community edits. However, they still remain open after those changes.\n    3.\tLQ_CLOSE: Low-quality posts that were closed by the community without a single edit.\n\nStudy the characteristics of good questions on Stack Overflow and pick the features that have the strongest correlation with the categories. Train several models to predict the category of the post. Choose the best model.\n"},{"metadata":{},"cell_type":"markdown","source":"# 2. Import main packages and data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import confusion_matrix\n\nimport nltk\nfrom nltk.tokenize import RegexpTokenizer\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/60k-stack-overflow-questions-with-quality-rate/train.csv\")\nvalid = pd.read_csv(\"../input/60k-stack-overflow-questions-with-quality-rate/valid.csv\")\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# 3. Preprocessing data and generate additional features "},{"metadata":{},"cell_type":"markdown","source":"a.\tGet number of words in body"},{"metadata":{"trusted":true},"cell_type":"code","source":"# change column names to lower:\ntrain.columns = train.columns.str.lower()\n\n# remove <p> from Body apply to train DataFrame \ntrain.body = train.body.str.replace('<p>','')\n# count words by splitting the string by space\nnum_words_in_body = pd.Series([len(row.split(' ')) for row in train.body])\n# add the count to train dataFrame\ntrain[\"num_words_in_body\"] = num_words_in_body\n#show the data\ntrain[\"num_words_in_body\"].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"b.\tGet number of words in title"},{"metadata":{"trusted":true},"cell_type":"code","source":"# count words by splitting the string by space\nnum_words_in_title = pd.Series([len(row.split(' ')) for row in train.title])\n# add the count to train dataFrame\ntrain[\"num_words_in_title\"] = num_words_in_title\ntrain[\"num_words_in_title\"].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"c.\tGet number of tags per question"},{"metadata":{"trusted":true},"cell_type":"code","source":"# extract words from tags\nnum_of_tags = pd.Series([len(re.findall('<(\\w+)>', row)) for row in train.tags])\n# add the count to train DataFrame\ntrain[\"num_of_tags\"] = num_of_tags\ntrain[\"num_of_tags\"].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"d.\tExtract tags for coding language associated with the question"},{"metadata":{"trusted":true},"cell_type":"code","source":"# get a list of tags from the dataFrame Tags column\ntags_list = []\nfor row in train.tags:\n    #print(row)\n    for tag in re.findall('<(.*?)>', row):   # if this is python-2.7 or python-3.x in the tag, it will be counted as different tags\n        tags_list.append(tag)\n        #print(tag)\n        \n# store unique tags into a tags_set\ntags_set = set(tags_list)\n\n# use the nltk package to count the frequency of each tag\ntags_freqD = nltk.FreqDist(tags_list)\n\n# sort the dictionary by the count, in descending order\nsorted_tagsD = sorted(tags_freqD.items(), key=lambda item:item[1], reverse=True)\n\n'''\n# evaluate the result, use \"python\" to test out\nfor k,v in sorted_tagsD:\n    if \"c\" in k:    \n        print(k, v)'''\nprint()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# top10_tags are the most used tags in the dataset\ntop10_tags = [tag[0] for tag in sorted_tagsD[:10]]\ntop10_tags","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"e.\tExtract year of the question"},{"metadata":{"trusted":true},"cell_type":"code","source":"# extract year from CreationDate\nCreationYear = pd.Series([date[:4] for date in train.creationdate])\n# add CreationYear to train DataFrame\ntrain[\"creation_year\"] = CreationYear\ntrain[\"creation_year\"].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"f. replace <> from Tags columns with space"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.tags = train.tags.str.replace('<|>',' ')\n#train.Tags = train.tags.str.replace('>',' ') # used | - or operator\ntrain.tags.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"g. print the layout of train dataFrame after preprosessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Data Visualization "},{"metadata":{},"cell_type":"markdown","source":"a.\tVisualize data by “y”, the question quality label, verify if data is balanced between each quality category"},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = train.y.unique()\ntrain.groupby('y').size()\nplt.bar(labels, train.groupby('y').size())\nplt.xlabel(\"Quality Labels\")\nplt.ylabel(\"Total questions in Train dataset\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"from the bar chart above, we can see the train data is well balanced with equal amount of each qaulity questions in the dataset"},{"metadata":{},"cell_type":"markdown","source":"b.\tPlot total questions per year (Plot total questions by label by year? )"},{"metadata":{"trusted":true},"cell_type":"code","source":"years = train.creation_year.unique()\nplt.bar(years, train.groupby('creation_year').size())\nplt.xlabel(\"Year\")\nplt.ylabel(\"Total questions in year\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As shown above, there are less questions comparing to previous years. \nIt would be interesting to check out the qaulity of questions among each year in the train dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"years  # unique years in dataset\nlabels # unique labels in dataset\nyear_label_df = pd.DataFrame(columns=labels, index=years, data= [[sum((train.y == label)&(train.creation_year== year)) for label in labels] for year in years ])\nprint(year_label_df)\nyear_label_df.plot.barh()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- There are fewer HQ (high quality) questions as the total quesion number goes down\n- Meanwhile, the decrease of LQ (low qaulity) questions are not dropping as dramatically as the HQ questions. "},{"metadata":{},"cell_type":"markdown","source":"c.\tPlot frequency of top 10 used tags in Stack Overflow"},{"metadata":{"trusted":true},"cell_type":"code","source":"tags_freqD.plot(10)\n### i think we should use bar plot here","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"d.Plot number of HQ, LQ posts for top 10 tags"},{"metadata":{"trusted":true},"cell_type":"code","source":"labels     # unique labels in dataset\ntop10_tags # top 10 tags used in the dataset\n# train[train['Tags'].str.contains('\\\\b(c)\\\\b', regex=True)].Tags\n\n\ntag_label_df = pd.DataFrame(columns=labels, index=top10_tags, data= [[sum((train.y == label)&(train['tags'].str.contains(tag, regex=True))) for label in labels] for tag in top10_tags ])\nprint(tag_label_df)\ntag_label_df.plot.bar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"e.\tPlot correlation between features and quality label\n    -\tlength of title vs quality\n    -\tlength of body text vs quality\n    -\tnumber of tags vs quality\n    -\tyear vs quality"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data=train, y_vars=[\"y\"], x_vars=[\"num_words_in_title\", \"num_words_in_body\", \"num_of_tags\", \"creation_year\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# 5. Build Classification Models With Features"},{"metadata":{},"cell_type":"markdown","source":"a.\tDecisionTreeClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"b.\tKNN classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"c.\tnaïve_bayes: GaussianNB"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. Build NLP Model"},{"metadata":{},"cell_type":"markdown","source":"a.\tTokenize the words (combine tag and text )"},{"metadata":{},"cell_type":"markdown","source":"b.\tRemoves stop words"},{"metadata":{},"cell_type":"markdown","source":"c.\tGet frequency distribution and find out: * (may have to limit to certain years due to capacity) \n    - What are the commonly used words in high rating posts?\n    - What are the commonly used words in low rating posts? "},{"metadata":{},"cell_type":"markdown","source":"d.\tStemming words"},{"metadata":{},"cell_type":"markdown","source":"e.\tTransform words into document vector by CountVectorizer"},{"metadata":{},"cell_type":"markdown","source":"f.\tUse multinomialNB to create model"},{"metadata":{},"cell_type":"markdown","source":"# 7. Models Evaluation and Final Conclusion"},{"metadata":{},"cell_type":"markdown","source":"a.\tWhich model is better for the prediction? Why do we think it performs better than the other one?"},{"metadata":{},"cell_type":"markdown","source":"b.\tWhat are the common characteristics of “good” questions?"},{"metadata":{},"cell_type":"markdown","source":"c.\tRoom of improvement?"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}