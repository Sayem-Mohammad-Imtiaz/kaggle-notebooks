{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#installing the needed packages\n\n!pip install openpyxl\n!pip install contractions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#reading your file into the dataframe\n\nimport pandas as pd\n\ndf = pd.read_excel('../input/example2/Example1.xlsx')\n#df = pd.read_excel('../input/example1/Example1.xlsx') <- this is my file path. Yours should be sth similar","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#take a look at your dataframe\n\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We're -> Were ","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#We define the functions for text preprocessing\nimport contractions\nimport re\nimport nltk\nnltk.download('stopwords')\nnltk.download('wordnet')\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\n\nstop = stopwords.words('english')\nlemmatizer = WordNetLemmatizer()\n\ndef remove_special_characters(text, remove_digits=False):\n    pattern = r'[^a-zA-Z0-9\\s]' if not remove_digits else r'[^a-zA-Z\\s]'\n    text = re.sub(pattern, '', text)\n    return text\n\nprint('Functions have been successfully defined!')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_col = []\nfor item in df['Text']:\n    new_abs = contractions.fix(item)\n    new_abs = remove_special_characters(new_abs, remove_digits=True)\n    new_abs_words = new_abs.split()\n    new_abs_words = [lemmatizer.lemmatize(w).lower() for w in new_abs_words if w.lower() not in stop]\n    new_col.append(new_abs_words)\ndf['Words'] = new_col","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#finding all unique words\nall_words = []\nfor item in df['Words']:\n    new_abs_words =item\n    all_words += new_abs_words\nall_words_unique = list(set(all_words))\n\nprint('There are ' + str(len(all_words_unique)) + ' unique words in our dataset.')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#making document term matrix\nword_matrix = {}\nfor word in all_words_unique:\n    word_vec = []\n    for item in df['Words']:\n        if word in item:\n            word_vec += [1]\n        else:\n            word_vec += [0]\n    word_matrix[word] = word_vec\n\ndc_df = pd.DataFrame(word_matrix)\ndc_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Calculating Cosine Similarity\n\nfrom sklearn.metrics.pairwise import cosine_similarity\n\ncos_matrix = cosine_similarity(dc_df)\n\npd.DataFrame(cos_matrix)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Calculating Euclidean Distance\n\nfrom sklearn.metrics.pairwise import euclidean_distances\n\neuc_matrix = euclidean_distances(dc_df)\n\npd.DataFrame(euc_matrix)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking the most similar document \n\n#specify the index of your chosen document\nchosen_doc = 4\nscores = sorted(cos_matrix[chosen_doc],reverse=True) \nscore = scores[1]                                     \nresult_doc = list(cos_matrix[chosen_doc]).index(score)\n# note: you may want to change cos_matrix to euc_matrix and set reverse=False when you are using \n#       Euclidean distance since the smaller the Euclidean distance is, the similar the two documents are.\n       \nprint('The document that is the most similar with document ' + str(chosen_doc) + ' is ' + 'document ' + str(result_doc) + '.')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#tf -- Term Frequency\ntf_matrix = {}\ntf_ranking ={}\nfor word in all_words_unique:\n    word_vec = []\n    for item in df['Words']:\n        if word in item:\n            word_vec += [item.count(word)/len(item)]\n        else:\n            word_vec += [0]\n    tf_matrix[word] = word_vec\n\npd.DataFrame(tf_matrix)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Top frequenty terms\n\ndef top_terms(matrix_df, n=10): #input should be a pandas dataframe\n    output_dict = {}\n    for index, series in matrix_df.iterrows():\n        doc_num = 'doc' + str(index)\n        scores = dict(series)\n        scores_sorted = {k: v for k, v in sorted(scores.items(), key=lambda item: item[1], reverse=True)}\n        terms = scores_sorted.keys()\n        terms_topn = list(terms)[:n]\n        output_dict[doc_num] = terms_topn\n    output_df = pd.DataFrame(output_dict)\n    return output_df.transpose()\n\nmatrix_df = pd.DataFrame(tf_matrix)\ntf_ranking = top_terms(matrix_df, 10)\ntf_ranking","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\n\n#idf -- Inverse document frequency\nidf_matrix = {}\nfor word in word_matrix:\n    idf_matrix[word] = math.log(len(df['Words'])/sum(word_matrix[word]))\n\nprint(\"Inverse Document Frequency Matrix successfully computed!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Ranking of the Inverse document frequency\n\nidf_ranking = {k: v for k, v in sorted(idf_matrix.items(), key=lambda item: item[1], reverse=True)}\nidf_ranking","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Computing tfidf\n\ntfidf = {}\nfor word in idf_matrix:\n    idf = idf_matrix[word]\n    tfidf_vec = tf_matrix[word]\n    tfidf[word] = [i * idf for i in tfidf_vec]\n\npd.DataFrame(tfidf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Ranking according to tfidf\n\ntfidf_df = pd.DataFrame(tfidf)\ntop_tfidf_terms = top_terms(tfidf_df)\n\ntop_tfidf_terms","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Calculating Cosine Similarity using tfidf\n\ndc_df = pd.DataFrame(tfidf)\ncos_matrix = cosine_similarity(dc_df)\n\npd.DataFrame(cos_matrix)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking the similarity between two documents using tfidf\n\nchosen_doc = 2\nscores = sorted(cos_matrix[chosen_doc],reverse=True)\nscore = scores[1]\nresult_doc = list(cos_matrix[chosen_doc]).index(score)\n\nprint('The document that is the most similar with document ' + str(chosen_doc) + ' is ' + 'document ' + str(result_doc) + '.')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Take a look at your text\n\nprint(df.Text[4])\nprint(df.Text[3])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Your may also locate your data using the title of it\ndf.loc[df['Title']=='Cancer Progress and Priorities: Lung Cancer', ['Text']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}