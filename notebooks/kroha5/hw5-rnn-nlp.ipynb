{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-25T12:16:29.233622Z","iopub.execute_input":"2021-05-25T12:16:29.233945Z","iopub.status.idle":"2021-05-25T12:16:29.242243Z","shell.execute_reply.started":"2021-05-25T12:16:29.233914Z","shell.execute_reply":"2021-05-25T12:16:29.241253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:16:29.243909Z","iopub.execute_input":"2021-05-25T12:16:29.244512Z","iopub.status.idle":"2021-05-25T12:16:29.253324Z","shell.execute_reply.started":"2021-05-25T12:16:29.244475Z","shell.execute_reply":"2021-05-25T12:16:29.252383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Загрузим данные","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/twitter-airline-sentiment/Tweets.csv\")\ndata.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:16:29.255704Z","iopub.execute_input":"2021-05-25T12:16:29.25619Z","iopub.status.idle":"2021-05-25T12:16:29.328099Z","shell.execute_reply.started":"2021-05-25T12:16:29.256157Z","shell.execute_reply":"2021-05-25T12:16:29.327174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = data[\"text\"]\ny = data[\"airline_sentiment\"]","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:16:29.329758Z","iopub.execute_input":"2021-05-25T12:16:29.330114Z","iopub.status.idle":"2021-05-25T12:16:29.335276Z","shell.execute_reply.started":"2021-05-25T12:16:29.330078Z","shell.execute_reply":"2021-05-25T12:16:29.333919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Мелкая предобработка","metadata":{}},{"cell_type":"code","source":"import re\n\nX = X.apply(lambda s:s.lower())\nX = X.apply(lambda s:s.replace(\"i\\'m\", \"i am\"))\nX = X.apply(lambda s:s.replace(\"\\'re\",\" are\"))\nX = X.apply(lambda s:s.replace(\"\\'ll\", \" will\"))\nX = X.apply(lambda s:s.replace(\"\\'ve\",\" have\"))\nX = X.apply(lambda s:s.replace(\"\\'s\", \" is\"))\nX = X.apply(lambda s:s.replace(\"#\",\"\"))\nX = X.apply(lambda s:re.sub(\"@[a-zA-Z]*\",\"\",s))\n\nsentiment_to_num=dict()\nsentiment_to_num['negative']=0\nsentiment_to_num['neutral']=1\nsentiment_to_num['positive']=2\n\nnum_to_sentiment=['negative','neutral','positive']","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:16:29.336901Z","iopub.execute_input":"2021-05-25T12:16:29.337364Z","iopub.status.idle":"2021-05-25T12:16:29.419042Z","shell.execute_reply.started":"2021-05-25T12:16:29.337305Z","shell.execute_reply":"2021-05-25T12:16:29.418322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.1, stratify=y)\nX_train, X_val, y_train, y_val = train_test_split(X_train,y_train, test_size=0.1, stratify=y_train)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:16:29.420119Z","iopub.execute_input":"2021-05-25T12:16:29.420465Z","iopub.status.idle":"2021-05-25T12:16:29.46334Z","shell.execute_reply.started":"2021-05-25T12:16:29.42043Z","shell.execute_reply":"2021-05-25T12:16:29.462676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Построение словаря","metadata":{}},{"cell_type":"code","source":"from torchtext.data.utils import get_tokenizer\nfrom collections import Counter\nfrom torchtext.vocab import Vocab\n\ntokenizer = get_tokenizer('basic_english')\ncounter = Counter()\nfor line in X_train:\n    counter.update(tokenizer(line))\nvocab = Vocab(counter, min_freq=1,max_size=20000)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:16:29.464467Z","iopub.execute_input":"2021-05-25T12:16:29.464788Z","iopub.status.idle":"2021-05-25T12:16:29.705746Z","shell.execute_reply.started":"2021-05-25T12:16:29.464756Z","shell.execute_reply":"2021-05-25T12:16:29.704965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Построение списка токенов по тексту","metadata":{}},{"cell_type":"code","source":"text_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]\nlabel_pipeline = lambda x: sentiment_to_num[x]","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:16:29.708075Z","iopub.execute_input":"2021-05-25T12:16:29.708471Z","iopub.status.idle":"2021-05-25T12:16:29.712897Z","shell.execute_reply.started":"2021-05-25T12:16:29.708437Z","shell.execute_reply":"2021-05-25T12:16:29.711803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Вот тут проблема. Списки токенов в датасете неодинаковой длины","metadata":{}},{"cell_type":"code","source":"max_len=200 # хочу чтобы было максимально 200 токенов\nfrom torch.utils.data import Dataset\n\nclass SentimentDataset(Dataset):\n    def __init__(self, X,y):\n        super().__init__()\n        self.X = np.array(X)\n        self.y = np.array(y)\n    def __len__(self):\n        return len(self.X)\n    def __getitem__(self,idx):\n        return (text_pipeline(self.X[idx]),label_pipeline(self.y[idx]))","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:16:29.714699Z","iopub.execute_input":"2021-05-25T12:16:29.715075Z","iopub.status.idle":"2021-05-25T12:16:29.724092Z","shell.execute_reply.started":"2021-05-25T12:16:29.715041Z","shell.execute_reply":"2021-05-25T12:16:29.72321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch import nn\nfrom torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\nfrom tqdm import tqdm\n\nclass LSTMClassifier(nn.Module):\n    def __init__(self,dimension=128):\n        super().__init__()\n        self.embedding = nn.EmbeddingBag(num_embeddings = len(vocab),embedding_dim=300,sparse=True)\n        self.lstm = nn.LSTM(input_size=300,\n                            hidden_size=dimension,\n                            num_layers=1,\n                            batch_first=True,\n                            bidirectional=True)\n        self.drop = nn.Dropout(p=0.3)\n        self.fc1 = nn.Linear(2*dimension, 2*dimension)\n        self.act1 = nn.ReLU()\n        self.fc2 = nn.Linear(2*dimension,3)\n\n    def forward(self, text, text_len):\n        text_emb = self.embedding(text)\n\n        packed_input = pack_padded_sequence(text_emb, text_len, batch_first=True, enforce_sorted=False)\n        packed_output, _ = self.lstm(packed_input)\n        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n\n        out_forward = output[range(len(output)), text_len - 1, :self.dimension]\n        out_reverse = output[:, 0, self.dimension:]\n        out_reduced = torch.cat((out_forward, out_reverse), 1)\n        \n        text_fea = self.drop(out_reduced)\n        text_fea = self.act1(self.fc1(text_fea))\n        text_fea = self.fc2(text_fea)\n\n        return text_fea","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:16:29.725391Z","iopub.execute_input":"2021-05-25T12:16:29.725728Z","iopub.status.idle":"2021-05-25T12:16:29.736901Z","shell.execute_reply.started":"2021-05-25T12:16:29.725695Z","shell.execute_reply":"2021-05-25T12:16:29.735671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\ndevice = torch.device('cuda')","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:16:29.738095Z","iopub.execute_input":"2021-05-25T12:16:29.738671Z","iopub.status.idle":"2021-05-25T12:16:29.748593Z","shell.execute_reply.started":"2021-05-25T12:16:29.73863Z","shell.execute_reply":"2021-05-25T12:16:29.747737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = LSTMClassifier()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:16:29.750995Z","iopub.execute_input":"2021-05-25T12:16:29.75152Z","iopub.status.idle":"2021-05-25T12:16:29.807022Z","shell.execute_reply.started":"2021-05-25T12:16:29.751483Z","shell.execute_reply":"2021-05-25T12:16:29.806266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = SentimentDataset(X_train, y_train)\nval_dataset = SentimentDataset(X_val, y_val)\ntest_dataset = SentimentDataset(X_test, y_test)\n\nfrom torch.utils.data import DataLoader\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_dataset,batch_size=16, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:16:29.808242Z","iopub.execute_input":"2021-05-25T12:16:29.808552Z","iopub.status.idle":"2021-05-25T12:16:29.815103Z","shell.execute_reply.started":"2021-05-25T12:16:29.80852Z","shell.execute_reply":"2021-05-25T12:16:29.814073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch import optim\noptimizer = torch.optim.Adam(params = clf.parameters(), lr=1e-4)\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:16:29.816645Z","iopub.execute_input":"2021-05-25T12:16:29.817055Z","iopub.status.idle":"2021-05-25T12:16:29.824146Z","shell.execute_reply.started":"2021-05-25T12:16:29.817019Z","shell.execute_reply":"2021-05-25T12:16:29.823409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_epoch(model,epoch):\n    dataset_size=len(train_dataset)\n    print(f\"Epoch#{epoch}. Train\")\n    \n    start_time=time.time()\n    model.train()\n    \n    running_loss=0.0   #накопление лосса\n    running_corrects=0 #накопление для accuracy\n    \n    epoch_loss=0.0\n    epoch_acc=0.0\n    for inputs,labels in tqdm( train_loader):\n        inputs=inputs.to(device)\n        \n        labels=labels.to(device) #передаем батч на GPU(cuda)\n        optimizer.zero_grad()\n        \n        outputs=model(inputs,len(inputs))\n        _,preds=torch.max(outputs,dim=1)\n        loss=criterion(outputs,labels)\n        loss.backward() # обратное распостранение градиента\n        optimizer.step() # шаг оптимизатора\n        #scheduler.step(loss) #планировщик learning rate\n        running_loss+=loss.item()*inputs.size(0)\n        running_corrects += torch.sum(preds == labels.data)\n    \n    epoch_loss = running_loss / dataset_size\n    epoch_acc = running_corrects / dataset_size\n    \n    print(f'Loss: { epoch_loss } Acc: { epoch_acc }')\n    print(f\"Epoch#{epoch} (Train) completed. {round(time.time()-start_time,3)}s \")\n    return model, epoch_loss, epoch_acc","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:16:29.825186Z","iopub.execute_input":"2021-05-25T12:16:29.825476Z","iopub.status.idle":"2021-05-25T12:16:29.835422Z","shell.execute_reply.started":"2021-05-25T12:16:29.82545Z","shell.execute_reply":"2021-05-25T12:16:29.834598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def valid_epoch(model,epoch):\n    dataset_size=len(val_dataset)\n    print(f\"Epoch#{epoch}. Validation\")\n    start_time=time.time()\n    model.eval()\n    running_loss=0.0 # накопление лосса\n    running_corrects=0\n    \n    epoch_loss=0.0\n    epoch_acc=0.0\n    with torch.no_grad():\n        for inputs,labels in tqdm( val_loader):\n            inputs=inputs.to(device)\n            labels=labels.to(device) #передаем батч на GPU(cuda)\n        \n            outputs=model(inputs, len(inputs))\n            _,preds=torch.max(outputs,dim=1)\n            loss=criterion(outputs,labels)\n        \n            running_loss+=loss.item()*inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data)\n    \n    epoch_loss = running_loss / dataset_size\n    epoch_acc = running_corrects / dataset_size\n    \n    print(f'Loss: { epoch_loss } Acc: { epoch_acc }')\n    print(f\"Epoch#{epoch} (Validation) completed. {round(time.time()-start_time,3)}s \")\n    return model, epoch_loss, epoch_acc","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:16:29.836626Z","iopub.execute_input":"2021-05-25T12:16:29.837143Z","iopub.status.idle":"2021-05-25T12:16:29.848681Z","shell.execute_reply.started":"2021-05-25T12:16:29.837103Z","shell.execute_reply":"2021-05-25T12:16:29.847915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_model=clf\nbest_acc=0.0\nbest_epoch=1\n\n\ntrain_acc_history=[]\nval_acc_history=[]\n\nnum_epochs = 10\n\nfor epoch in range(1,num_epochs+1):\n    #тренировка\n    clf, train_loss, train_acc=train_epoch(clf,epoch)\n    train_loss_history.append(train_loss)\n    train_acc_history.append(train_acc)\n    #валидация\n    clf, val_loss, val_acc=valid_epoch(clf,epoch)\n    val_loss_history.append(val_loss)\n    val_acc_history.append(val_acc)\n    \n    if(val_acc>best_acc):\n        best_acc=val_acc\n        best_model=model_ft\n        best_epoch=epoch\n","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:16:29.850381Z","iopub.execute_input":"2021-05-25T12:16:29.850606Z","iopub.status.idle":"2021-05-25T12:16:29.89486Z","shell.execute_reply.started":"2021-05-25T12:16:29.850585Z","shell.execute_reply":"2021-05-25T12:16:29.892595Z"},"trusted":true},"execution_count":null,"outputs":[]}]}