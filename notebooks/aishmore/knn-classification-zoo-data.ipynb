{"cells":[{"metadata":{},"cell_type":"markdown","source":"# K Nearest Neighbours (KNN)\nThe KNN algorithm works by storing all known classified values and makes predictions for new cases based on similarity measure.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Importing Libraries for ML model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Importing subpackages from scikit-learn library","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import additional required libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\nfrom sklearn.model_selection import *\nfrom sklearn.metrics import confusion_matrix,classification_report, accuracy_score\nfrom sklearn.model_selection import cross_val_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Importing and Modifying the Data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Reading the data using `pandas.read_csv()`.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Importing dataset\nzoo_df = pd.read_csv('../input/zoo-animal-classification/zoo.csv')\nclass_df = pd.read_csv('../input/zoo-animal-classification/class.csv')\nzoo_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since we want to use the information in both of these datasets, we can merge them along a common column, the `class_type` and `Class_Number` columns.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Joining datasets along the class number column present in both datasets\nanimal_df = zoo_df.merge(class_df,how='left',left_on='class_type',right_on='Class_Number')\nanimal_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we can remove the column `class_type` which was originally from `zoo_df` as it is now a duplicate of `Class_Number`, and also because it shares a name with `Class_Type` originally from `class_df`.\n\nWe can also remove the columns `Animal_Names` and `Number_Of_Animal_Species_In_Class` as they does not provide us with any classification insights.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping unwanted columns\n## I am renaming the dataframe as zoo_df because it is shorter to use\nzoo_df = animal_df.drop(['class_type','Animal_Names', 'Number_Of_Animal_Species_In_Class'], axis=1)\nzoo_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before doing anything else with the data let's see if there are any null values (missing data) in any of the columns.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"zoo_df.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have no missing data so all the entries are valid for use.\n\nNow we can check the column names to get a better understanding of what features we will be basing our classification on.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Initial Evaluation","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Review data prior to implementing model using basic stats and visualizations.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get names of columns in zoo_df\nzoo_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"zoo_df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From this we can see that all of the animal characteristics or feature values are given as binary values (1- present / 0-absent) except for the legs where it is given as a count of legs.\n\nWe need to keep this in mind going forward while using the data.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Next let's get the distribution of animal data across the types of classes.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set default plot grid\nsns.set_style('whitegrid')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot histogram of classes\nplt.rcParams['figure.figsize'] = (7,7)\nsns.countplot(zoo_df['Class_Type'], palette='YlGnBu')\nax = plt.gca()\nax.set_title(\"Histogram of Classes\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can also see if there are any trends or correlations in the data using a heatmap.\n\nAs mentioned previously, we will want to treat the `legs` columns differently as it does not present data the same way as the remaining columns. So, we will create a column `has_legs` that checks if an animal has legs (1) or not (0).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"zoo_df['has_legs'] = np.where(zoo_df['legs']>0,1,0)\nzoo_df = zoo_df[['animal_name','hair','feathers','eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous','fins','legs','has_legs','tail','domestic','catsize','Class_Number','Class_Type']]\nzoo_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"zoo_df_temp = zoo_df.drop(['has_legs','Class_Number'], axis=1)\nzoo_df_temp = zoo_df_temp.groupby(by='animal_name').mean()\nplt.rcParams['figure.figsize'] = (16,10) \nsns.heatmap(zoo_df_temp, cmap=\"inferno\")\nax = plt.gca()\nax.set_title(\"Features for the Animals\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"zoo_df_temp = zoo_df.drop(['has_legs','Class_Number'], axis=1)\nzoo_df_temp = zoo_df_temp.groupby(by='Class_Type').mean()\nplt.rcParams['figure.figsize'] = (16,10) \nsns.heatmap(zoo_df_temp, annot=True, cmap=\"inferno\")\nax = plt.gca()\nax.set_title(\"HeatMap of Features for the Classes\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we can see how `legs` having a larger range of values [0-8] than the rest of the features skews the data.\n\nNow, let's try that again but using `has_legs` instead.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"zoo_df_temp = zoo_df.drop(['legs','Class_Number'], axis=1)\nzoo_df_temp = zoo_df_temp.groupby(by='animal_name').mean()\nplt.rcParams['figure.figsize'] = (16,10) \nsns.heatmap(zoo_df_temp, cmap=\"inferno\")\nax = plt.gca()\nax.set_title(\"Features for the Animals\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"zoo_df_temp = zoo_df.drop(['legs','Class_Number'], axis=1)\nzoo_df_temp = zoo_df_temp.groupby(by='Class_Type').mean()\nplt.rcParams['figure.figsize'] = (16,10) \nsns.heatmap(zoo_df_temp, annot=True, cmap=\"inferno\")\nax = plt.gca()\nax.set_title(\"HeatMap of Features for the Classes\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This gives us a much clearer idea of what features play a more or less important role in identifying certain animals.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Prepraring Data for Models\nWe will be removing column `animal_name` as it does not help us in classification. We will also remove `has_legs` since it is not part of the original data, and is not as insightful as it's parent feature `legs`.\n\nAfter that, we can assign the remaining relevant columns to the X and y sets.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"zoo_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select columns to add to X and y sets\nfeatures = list(zoo_df.columns.values)\nfeatures.remove('has_legs')\nfeatures.remove('Class_Type')\nfeatures.remove('Class_Number')\nfeatures.remove('animal_name')\nX = zoo_df[features]\ny = zoo_df['Class_Number']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Split X, y data into training set and testing set.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split X and y into train and test\nX_train, X_test, y_train, y_test = train_test_split(X,y,random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train model\nCreate and train knn classifier to use on zoo data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit k-nearest neighbors classifier with training sets for n = 5\nknn = KNeighborsClassifier(n_neighbors = 5)\nknn.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Test and Evaluate model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Run predicitions on the test data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Run prediction\ny_pred = knn.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get the confusion matrix and classification report for model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (9,9) \n_, ax = plt.subplots()\nax.hist(y_test, color = 'm', alpha = 0.5, label = 'actual', bins=7)\nax.hist(y_pred, color = 'c', alpha = 0.5, label = 'prediction', bins=7)\nax.yaxis.set_ticks(np.arange(0,11))\nax.legend(loc = 'best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What this figure tells us is the total number of animals in each class according to the test data and predicted data. <br>\nWe can see that the predictions matches almost all the actual animal classifications (indicated by color overlap) except for one case where the model failed to identify an animal as belonging to class 3 (Reptile), and marked it as being in class 4 (Fish).\n\nSo we can see the level of accuracy for this particular classifier.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Now that we know what the model can do at n=5, we should run the model for multiple values of n to find optimal value of n with respect to this dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get score for different values of n\nk_list = np.arange(1, 50, 2)\nmean_scores = []\naccuracy_list = []\nerror_rate = []\n\nfor i in k_list:\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train,y_train)\n    pred_i = knn.predict(X_test)\n    score = cross_val_score(knn,X_train, y_train,cv=10)\n    mean_scores.append(np.mean(score))\n    error_rate.append(np.mean(pred_i != y_test))\n\nprint(\"Mean Scores:\")\nprint(mean_scores)\nprint(\"Error Rate:\")\nprint(error_rate)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualization of Model Performance of Different n-Values\nCreate a plot of the average accuracy of the prediction model for different values of k between 1 to 50.\n\nThis is to help us better see which value of k works best with this model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot n values and average accuracy scores\nplt.plot(k_list,mean_scores, marker='o')\n\n# Added titles and adjust dimensions\nplt.title('Accuracy of Model for Varying Values of K')\nplt.xlabel(\"Values of K\")\nplt.ylabel(\"Mean Accuracy Score\")\nplt.xticks(k_list)\nplt.rcParams['figure.figsize'] = (12,12) \n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot n values and average accuracy scores\nplt.plot(k_list,error_rate, color='r', marker = 'o')\n\n# Added titles and adjust dimensions\nplt.title('Error Rate for Model for Varying Values of K')\nplt.xlabel(\"Values of K\")\nplt.ylabel(\"Error Rate\")\nplt.xticks(k_list)\nplt.rcParams['figure.figsize'] = (12,12) \n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Out of Curiosity...","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"So, we've seen how this works when we use all the features values as given. <br>\nJust for fun, let's see how this changes if we don't use the values for `legs` and use `has_legs` instead as we did when plotting our heatmap.\n\nI'll run the exact same code as before changing nothing but using `has_legs` and not `legs`. <br>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select columns to add to X and y sets\nfeatures = list(zoo_df.columns.values)\nfeatures.remove('legs')\nfeatures.remove('Class_Type')\nfeatures.remove('Class_Number')\nfeatures.remove('animal_name')\nX2 = zoo_df[features]\ny2 = zoo_df['Class_Type']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split X and y into train and test\nX2_train, X2_test, y2_train, y2_test = train_test_split(X2,y2,random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit k-nearest neighbors classifier with training sets for n = 5\nknn2 = KNeighborsClassifier(n_neighbors = 5)\nknn2.fit(X2_train, y2_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Run prediction\ny2_pred = knn2.predict(X2_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y2_test,y2_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y2_test,y2_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (9,9) \n_, ax = plt.subplots()\nax.hist(y2_test, color = 'm', alpha = 0.5, label = 'actual', bins=7)\nax.hist(y2_pred, color = 'c', alpha = 0.5, label = 'prediction', bins=7)\nax.yaxis.set_ticks(np.arange(0,11))\nax.legend(loc = 'best')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"# Get score for different values of n\nk_list = np.arange(1, 50, 2)\nmean_scores2 = []\naccuracy_list2 = []\nerror_rate2 = []\n\nfor i in k_list:\n    knn2 = KNeighborsClassifier(n_neighbors=i)\n    knn2.fit(X2_train,y2_train)\n    pred_i = knn2.predict(X2_test)\n    score = cross_val_score(knn2,X2_train, y2_train,cv=10)\n    mean_scores2.append(np.mean(score))\n    error_rate2.append(np.mean(pred_i != y2_test))\n\nprint(\"Mean Scores:\")\nprint(mean_scores)\nprint(\"Error Rate:\")\nprint(error_rate)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here I'll plot the original and new curves together so we can see and compare any differences.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot n values and average accuracy scores\nplt.plot(k_list,mean_scores, color='b',marker='o', label='Model using Number of Legs')\nplt.plot(k_list,mean_scores2, color='m',marker='x', label='Model using Presence of Legs')\n\n# Added titles and adjust dimensions\nplt.title('Accuracy of Model for Varying Values of K')\nplt.xlabel(\"Values of K\")\nplt.ylabel(\"Mean Accuracy Score\")\nplt.xticks(k_list)\nplt.legend()\nplt.rcParams['figure.figsize'] = (12,12) \n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot n values and average accuracy scores\nplt.plot(k_list,error_rate, color='r', marker = 'o', label='Model using Number of Legs')\nplt.plot(k_list,error_rate2, color='c', marker = 'x', label='Model using Presence of Legs')\n\n# Added titles and adjust dimensions\nplt.title('Error Rate for Model for Varying Values of K')\nplt.xlabel(\"Values of K\")\nplt.ylabel(\"Error Rate\")\nplt.xticks(k_list)\nplt.legend()\nplt.rcParams['figure.figsize'] = (12,12) \n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Inference\n\nSo interestingly, <br>\nReplacing the feature `legs` with `has_legs` improved the accuracy of KNN models at every value where n >3 <br>\nThis may be due to the model taking the number of legs as a continuous, numeric data point rather than as an enumerate. <br>","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}