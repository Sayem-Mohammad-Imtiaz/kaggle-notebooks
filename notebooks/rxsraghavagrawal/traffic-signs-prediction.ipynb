{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**In this Notebook we aim to build a Traffic sign Classification project using Image Processing and Image Classification**\n\nTheir are four phases to accomplish the requirements\n- Explore the dataset\n- Train the CNN\n- Evaluate the CNN","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n #   for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-07T16:55:33.765618Z","iopub.execute_input":"2021-06-07T16:55:33.766049Z","iopub.status.idle":"2021-06-07T16:55:33.775278Z","shell.execute_reply.started":"2021-06-07T16:55:33.765939Z","shell.execute_reply":"2021-06-07T16:55:33.774579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import libraries\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nimport tensorflow as tf\nfrom keras.utils import to_categorical\nfrom keras.layers import Conv2D, Dense, Flatten, MaxPool2D, Dropout\n","metadata":{"execution":{"iopub.status.busy":"2021-06-07T16:55:35.151123Z","iopub.execute_input":"2021-06-07T16:55:35.151644Z","iopub.status.idle":"2021-06-07T16:55:41.246544Z","shell.execute_reply.started":"2021-06-07T16:55:35.151595Z","shell.execute_reply":"2021-06-07T16:55:41.245304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Explore The Dataset","metadata":{}},{"cell_type":"code","source":"#how many classes we have in train\nfiles = []\npath = \"../input/gtsrb-german-traffic-sign/Train\"\nfor file in os.listdir(path):\n    files.append(file)\n    \nprint(len(files))","metadata":{"execution":{"iopub.status.busy":"2021-06-07T16:55:41.248214Z","iopub.execute_input":"2021-06-07T16:55:41.24863Z","iopub.status.idle":"2021-06-07T16:55:41.26634Z","shell.execute_reply.started":"2021-06-07T16:55:41.248581Z","shell.execute_reply":"2021-06-07T16:55:41.265383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train folder contains 43 folder of each class. And in each class it contains various images of that particular class. The range of folder is 0 to 42. With the help of os module, we iterate over all the classes and append images and and their respective labels in data and labels list.\n\nThe PIL library is used to open image content into an array.","metadata":{}},{"cell_type":"code","source":"from PIL import Image","metadata":{"execution":{"iopub.status.busy":"2021-06-07T16:55:41.268132Z","iopub.execute_input":"2021-06-07T16:55:41.268487Z","iopub.status.idle":"2021-06-07T16:55:41.272678Z","shell.execute_reply.started":"2021-06-07T16:55:41.268454Z","shell.execute_reply":"2021-06-07T16:55:41.271676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nimgs_path = \"../input/gtsrb-german-traffic-sign/Train\"\ndata = []\nlabels = []\nclasses = 43\n\nfor i in range(43):\n    p = os.path.join(imgs_path, str(i)) #0-42\n    #print(p)\n    for img in os.listdir(p):\n        im = Image.open(p + '/' + img)\n        im = im.resize((30,30))\n        im = np.array(im)\n        data.append(im)\n        labels.append(i)\n        \ndata = np.array(data)\nlabels = np.array(labels)\nprint(\"success\")","metadata":{"execution":{"iopub.status.busy":"2021-06-07T16:55:41.273933Z","iopub.execute_input":"2021-06-07T16:55:41.274205Z","iopub.status.idle":"2021-06-07T16:58:28.381062Z","shell.execute_reply.started":"2021-06-07T16:55:41.274178Z","shell.execute_reply":"2021-06-07T16:58:28.380049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#what we done, see an sample example\ni0 = \"../input/gtsrb-german-traffic-sign/Train/0/00000_00004_00029.png\"\ni = Image.open(i0)\ni = i.resize((30, 30))\nsr = np.array(i)  #it is a matrix of shape (30,30,3)\nplt.imshow(i)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T16:58:28.382686Z","iopub.execute_input":"2021-06-07T16:58:28.383006Z","iopub.status.idle":"2021-06-07T16:58:28.534723Z","shell.execute_reply.started":"2021-06-07T16:58:28.382973Z","shell.execute_reply":"2021-06-07T16:58:28.533985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data.shape)\nprint(labels.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T16:58:28.536048Z","iopub.execute_input":"2021-06-07T16:58:28.536534Z","iopub.status.idle":"2021-06-07T16:58:28.542754Z","shell.execute_reply.started":"2021-06-07T16:58:28.536499Z","shell.execute_reply":"2021-06-07T16:58:28.541809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Hence we got our data ready, Data is a matrix containing each image of shape 30*30*3 and labels is nothing but a class name from 0 to 42.","metadata":{}},{"cell_type":"code","source":"#see any random image\nipath = \"../input/gtsrb-german-traffic-sign/Train/7\"\nimgs = os.listdir(ipath)\nfor ip in imgs[5:8]:\n    im = Image.open(ipath +'/'+ip)\n    plt.imshow(im)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T16:58:28.544155Z","iopub.execute_input":"2021-06-07T16:58:28.544523Z","iopub.status.idle":"2021-06-07T16:58:28.930335Z","shell.execute_reply.started":"2021-06-07T16:58:28.544494Z","shell.execute_reply":"2021-06-07T16:58:28.92923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally we have sorted all the images and labels into list(data and label). Now we need to convert list into numpy arrays for feeding to the model. The shape of data is (39209, 30, 30, 3) which means we hvae total 39209 images of shape 30*30. And the 3 means data contains colored imgs(RGB)\n","metadata":{}},{"cell_type":"markdown","source":"**Train Test split**\n\n now we will split the data into train test split. we will one hot encode the labels with to_categorical method imported from keras utils.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n\nprint(\"training shape: \",x_train.shape, y_train.shape)\nprint(\"testing shape: \",x_test.shape, y_test.shape)\n\ny_train = to_categorical(y_train, 43)\ny_test = to_categorical(y_test, 43)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T16:58:28.932678Z","iopub.execute_input":"2021-06-07T16:58:28.93297Z","iopub.status.idle":"2021-06-07T16:58:29.821003Z","shell.execute_reply.started":"2021-06-07T16:58:28.932942Z","shell.execute_reply":"2021-06-07T16:58:29.819814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#after onehot encoding we can see the shape of output labels.\nprint(y_train.shape, y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T16:58:29.822698Z","iopub.execute_input":"2021-06-07T16:58:29.823057Z","iopub.status.idle":"2021-06-07T16:58:29.831075Z","shell.execute_reply.started":"2021-06-07T16:58:29.823021Z","shell.execute_reply":"2021-06-07T16:58:29.829122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build CNN Model\n\nIt's time for modelling, Concolutional Neural Network is best for Image Classification Task and we will build CNN using Keras Sequential Model.\n\n**The architecture of CNN**\n\n- 1st is Input Convolutional(Conv2D) layer with 32 filters of 5*5 size\n- 2nd layer is also conv2d of 32 filters of 5*5\n- Next is Max Pooling(MaxPool2D) with 2*2 shape\n- Dropout layer(rate=0.25)\n- 2 Convolutional Layer of 64 filters of 3*3 size\n- MaxPool2D(pool_size=(2,2))\n- Dropout layer, rate = 0.25\n- Flatter Layer to squeeze the layers in 1-D\n- Dense Fully connected layers(256 nodes, activation=\"relu\")\n- Dropout(rate=0.5)\n- Dense Layer(43 nodes, activation=\"softmax\"), softmax activation for multiclass classification\n\n","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPool2D, Activation, Flatten, Dropout\nfrom keras.layers import Dense","metadata":{"execution":{"iopub.status.busy":"2021-06-07T16:58:29.833597Z","iopub.execute_input":"2021-06-07T16:58:29.834058Z","iopub.status.idle":"2021-06-07T16:58:29.840395Z","shell.execute_reply.started":"2021-06-07T16:58:29.834024Z","shell.execute_reply":"2021-06-07T16:58:29.839438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(filters=32, kernel_size=(5,5), activation=\"relu\", input_shape=x_train.shape[1:]))\nmodel.add(Conv2D(filters=32, kernel_size=(5,5), activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(rate=0.25))\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\"))\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(rate=0.25))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation=\"relu\"))\nmodel.add(Dropout(rate=0.5))\nmodel.add(Dense(43, activation=\"softmax\"))","metadata":{"execution":{"iopub.status.busy":"2021-06-07T16:58:29.84359Z","iopub.execute_input":"2021-06-07T16:58:29.844031Z","iopub.status.idle":"2021-06-07T16:58:30.023998Z","shell.execute_reply.started":"2021-06-07T16:58:29.84399Z","shell.execute_reply":"2021-06-07T16:58:30.023005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* We compile the model using ADAM Optimizer which performs well and loss is \"Categorical_crossentropy\" because we have multiple classes","metadata":{}},{"cell_type":"code","source":"model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2021-06-07T16:58:30.025575Z","iopub.execute_input":"2021-06-07T16:58:30.025948Z","iopub.status.idle":"2021-06-07T16:58:30.043913Z","shell.execute_reply.started":"2021-06-07T16:58:30.025907Z","shell.execute_reply":"2021-06-07T16:58:30.042962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training and Evaluating the model\n\nabhi toh raghav pdna hai, ghar ke bahar car khadi krna hai in an any how condition. I can and I will win.","metadata":{}},{"cell_type":"code","source":"epochs = 15\nhistory = model.fit(x_train, y_train, epochs=epochs, batch_size=64, validation_data=(x_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2021-06-07T16:58:30.045379Z","iopub.execute_input":"2021-06-07T16:58:30.045776Z","iopub.status.idle":"2021-06-07T17:17:35.477914Z","shell.execute_reply.started":"2021-06-07T16:58:30.045732Z","shell.execute_reply":"2021-06-07T17:17:35.476703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Let's Plot a graph for accuracy and loss**","metadata":{}},{"cell_type":"code","source":"plt.figure(0)\nplt.plot(history.history['accuracy'], label=\"Training accuracy\")\nplt.plot(history.history['val_accuracy'], label=\"val accuracy\")\nplt.title(\"Accuracy\")\nplt.xlabel(\"epochs\")\nplt.ylabel(\"accuracy\")\nplt.legend()\n\nplt.figure(1)\nplt.plot(history.history['loss'], label=\"training loss\")\nplt.plot(history.history['val_loss'], label=\"val loss\")\nplt.title(\"Loss\")\nplt.xlabel(\"epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T17:17:35.47969Z","iopub.execute_input":"2021-06-07T17:17:35.480031Z","iopub.status.idle":"2021-06-07T17:17:35.853458Z","shell.execute_reply.started":"2021-06-07T17:17:35.479999Z","shell.execute_reply":"2021-06-07T17:17:35.852376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Testing the Model\n\nwe have test folder which contains different set of images and we also have the respective set of labels. Again we will load all the images and resize them to shape of 30*30*3 And create a Numpy array containing all image data. We will use sklearn accuracy score to check that our model predict or not actual label with 95% accuracy.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nimport pandas as pd\ntest = pd.read_csv(\"../input/gtsrb-german-traffic-sign/Test.csv\")\nprint(test.shape)\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_labels = test['ClassId'].values\ntest_img_path = \"../input/gtsrb-german-traffic-sign\"\ntest_imgs = test['Path'].values\n\ntest_data = []\ntest_labels = []\n\nfor img in test_imgs:\n    im = Image.open(test_img_path + '/' + img)\n    im = im.resize((30,30))\n    im = np.array(im)\n    test_data.append(im)\n\ntest_data = np.array(test_data)\nprint(test_data.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\ntest_labels = test['ClassId'].values\ntest_labels","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:50:30.762198Z","iopub.execute_input":"2021-05-31T18:50:30.762783Z","iopub.status.idle":"2021-05-31T18:50:30.770123Z","shell.execute_reply.started":"2021-05-31T18:50:30.762735Z","shell.execute_reply":"2021-05-31T18:50:30.769164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predict the output on test data\npredictions = model.predict_classes(test_data)\nprint(\"accuracy: \", accuracy_score(test_labels, predictions))","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:50:37.758464Z","iopub.execute_input":"2021-05-31T18:50:37.758908Z","iopub.status.idle":"2021-05-31T18:50:43.776803Z","shell.execute_reply.started":"2021-05-31T18:50:37.758875Z","shell.execute_reply":"2021-05-31T18:50:43.775748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('traffic_classifier.h5')","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:51:09.688561Z","iopub.execute_input":"2021-05-31T18:51:09.688946Z","iopub.status.idle":"2021-05-31T18:51:09.733461Z","shell.execute_reply.started":"2021-05-31T18:51:09.688912Z","shell.execute_reply":"2021-05-31T18:51:09.732725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}