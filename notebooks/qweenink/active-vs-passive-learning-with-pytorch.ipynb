{"cells":[{"metadata":{"scrolled":true,"trusted":true,"_uuid":"078693a0f2b75505cc4e2db6c235c5919ac5ad10"},"cell_type":"code","source":"import pandas as pd\n\nsdss_df = pd.read_csv('../input/Skyserver_SQL2_27_2018 6_51_39 PM.csv')\nsdss_df.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"6faf9bf74427fbc77a4563e4225ec43ec795da9f"},"cell_type":"code","source":"sdss_df.drop(['objid', 'run', 'rerun', 'camcol', 'field', 'specobjid'], axis=1, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b0dc8c20f488860d47cca6eee76944188cf93d6d"},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder, MinMaxScaler, OneHotEncoder\n\nle = LabelEncoder()\ny_encoded = le.fit_transform(sdss_df['class'])\nsdss_df.drop(['class'], axis=1, inplace=True)\n\ny_encoded = y_encoded.reshape(-1, 1)\n\nenc = OneHotEncoder()\nenc.fit(y_encoded)\ny_encoded = enc.transform(y_encoded)\ny_encoded = y_encoded.toarray().tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ee637b6e756f4e741096347cfbb070dea0063da"},"cell_type":"code","source":"scaler = MinMaxScaler(feature_range=(-1, 1))\nsdss = scaler.fit_transform(sdss_df).tolist()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"b13bf973bda0089164bca47f6783b85eea8a3199"},"cell_type":"code","source":"import numpy as np\n\ndef stitch(inputs, target):\n    series_inputs = pd.Series(inputs)\n    series_target = pd.Series(target)\n    df = pd.DataFrame({'inputs': series_inputs, 'target': series_target})\n    return df.values.tolist()\n\ndef unstitch(data):\n    df = pd.DataFrame(data)\n    return df[0].values.tolist(), df[1].values.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f148746d3ef7f7ccf43af24daeba55eb1a0236b3"},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\n\nclass Net(nn.Module):\n    def __init__(self, dropout=False, weightDecay=0):\n        super(Net, self).__init__()\n        self.fc1 = nn.Linear(11, 11) # 2 Input noses, 50 in middle layers\n        self.do1 = nn.Dropout(p=0.2)\n        self.rl1 = nn.Sigmoid()\n        self.fc2 = nn.Linear(11, 3)\n        self.do2 = nn.Dropout(p=0.2)\n        self.smout = nn.Softmax(dim=1)      \n        \n        self.criterion = nn.CrossEntropyLoss()\n        self.optimizer = optim.Adam(self.parameters(), lr=0.01, weight_decay=0)\n        self.dropout=dropout\n        \n        self.cuda()\n        \n        self.trainOverTimeAccuracy = []\n        self.trainOverTimeLoss = []\n        self.testOverTimeAccuracy = []\n        self.testOverTimeLoss = []\n    \n    def forward(self, x):\n        x = self.fc1(x)\n        if self.dropout:\n            x = self.do1(x)\n        x = self.rl1(x)\n        x = self.fc2(x)\n        if self.dropout:\n            x = self.do1(x)\n        x = self.smout(x)\n        return x\n    \n    def log(self, epoch, train, test):\n        if epoch % REPORT_RATE == 0:\n            self.trainOverTimeAccuracy.append(self.accuracy(train))\n            #self.trainOverTimeLoss.append(self.loss(train))\n            self.testOverTimeAccuracy.append(self.accuracy(test))\n            #self.testOverTimeLoss.append(self.loss(test))\n            \n    def epochTrain(self, inputs, labels):\n        self.optimizer.zero_grad()\n        outputs = self(inputs)\n        self.loss = self.criterion(outputs, torch.max(labels, 1)[1])\n        self.loss.backward()    \n        self.optimizer.step()\n\n        \n    def train(self, numEpochs, train_set, train, test):\n        inputs, labels = unstitch(train_set)\n        \n        inputs = Variable(torch.FloatTensor(inputs).cuda())\n        labels = Variable(torch.FloatTensor(labels).cuda())\n\n        for epoch in range(numEpochs):\n            self.epochTrain(inputs, labels)\n            self.log(epoch, train, test)\n                \n    def activetrain(self, activeUpdateRate, batchSize, numEpochs, train, test):\n        trainings = int(numEpochs/activeUpdateRate)\n        currentEpoch = 0\n\n        for i in range(trainings):\n            activecriterion = nn.CrossEntropyLoss(reduction='none')\n            \n            inputs, labels = unstitch(train)\n            \n            inputs = Variable(torch.FloatTensor(inputs).cuda())\n            labels = Variable(torch.FloatTensor(labels).cuda())\n            \n            outputs = self(inputs)\n\n            loss = activecriterion(outputs, torch.max(labels, 1)[1]).detach().cpu().numpy()\n            sortIndexs = np.argsort(loss)[::-1]\n            dynamicTrainSet = np.array(np.copy(train))[sortIndexs]\n            dynamicTrainSet = dynamicTrainSet[0:batchSize]\n\n            inputs, labels = unstitch(dynamicTrainSet)\n        \n            inputs = Variable(torch.FloatTensor(inputs).cuda())\n            labels = Variable(torch.FloatTensor(labels).cuda())\n            \n            for epoch in range(activeUpdateRate):\n                currentEpoch += 1\n                self.epochTrain(inputs, labels)\n                self.log(currentEpoch, train, test)\n            \n    def randomtrain(self, batchSize, numEpochs, train, test):\n        shuffledTrainSet = np.array(np.copy(train))\n        for epoch in range(numEpochs):\n            np.random.shuffle(shuffledTrainSet)\n\n            inputs, labels = unstitch(shuffledTrainSet[0:batchSize])\n\n            inputs = Variable(torch.FloatTensor(inputs).cuda())\n            labels = Variable(torch.FloatTensor(labels).cuda())\n            \n            self.epochTrain(inputs, labels)\n            self.log(epoch, train, test)\n\n            \n    def loss(self, test_set):\n        inputs, labels = unstitch(test_set)\n        inputs = Variable(torch.FloatTensor(inputs).cuda())\n        labels = Variable(torch.FloatTensor(labels).cuda())\n        result = self(inputs)\n        loss = self.criterion(result, torch.max(labels, 1)[1])\n\n        return loss.item()\n\n    def accuracy(self, test_set):\n        inputs, labels = unstitch(test_set)\n        result = self(Variable(torch.FloatTensor(inputs)).cuda())\n        inputs_max = np.argmax(result.detach().cpu().numpy(), axis=1)\n        labels_max = np.argmax(np.array(labels), axis=1)\n        correct = np.sum(inputs_max == labels_max)\n\n        return correct/len(test_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a4282307bdf9ca85b8182e228b8f200eac0bfdd2"},"cell_type":"code","source":"print(len(sdss), len(y_encoded))\ndata = stitch(sdss, y_encoded)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"35d6527f1897ccde8423189e2843695ed37add36"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, ShuffleSplit\n\ntestSize = 0.2\nvalSize = 0.2\ntrainSize = 1.0 - (testSize + valSize)\nsubPercentage = 0.25\n\nSAMPLES = 30\nNUM_EPOCHS = 2000\nBATCH_SIZE = 200\nACTIVE_UPDATE_RATE = 1\nREPORT_RATE = 10\n\nprint(subPercentage)\n\ntrain, test = train_test_split(data, test_size=testSize, shuffle=True)\ntrain, val = train_test_split(train, test_size=subPercentage , shuffle=True)\n\nprint(len(data))\nprint(len(train), len(test), len(val))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"56d5bb12852720a3036c0be4981d28bf0cf9eb9e"},"cell_type":"code","source":"%%time\nregularisationBatchNets = []\nregularisationMiniBatchNets = []\nregularisationActiveNets = []\n\nregularisationSchemes = [[False, 0, 'no regularisation'], [True, 0, 'dropout'], [False, 0.01, 'weight decay'], [False, 0.01, 'dropout & weight decay']]\n\nfor scheme in regularisationSchemes:\n    print(scheme[2])\n    batchNets = []\n    miniBatchNets = []\n    activeNets = []\n    for i in range(SAMPLES):\n        batchNet = Net(scheme[0], scheme[1])\n        batchNet.train(NUM_EPOCHS, train, train, test)\n        batchNets.append(batchNet)\n\n        miniBatchNet = Net(scheme[0], scheme[1])\n        miniBatchNet.randomtrain(BATCH_SIZE, NUM_EPOCHS, train, test)\n        miniBatchNets.append(miniBatchNet)\n\n        activeNet = Net(scheme[0], scheme[1])\n        activeNet.activetrain(ACTIVE_UPDATE_RATE, BATCH_SIZE, NUM_EPOCHS, train, test)\n        activeNets.append(activeNet)\n        \n    regularisationBatchNets.append([batchNets, scheme[2]])\n    regularisationMiniBatchNets.append([miniBatchNets, scheme[2]])\n    regularisationActiveNets.append([activeNets, scheme[2]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc70a91e8ff11eec69f98526e7a485b0d86fd74c"},"cell_type":"code","source":"def buildDataFrame():\n    meanTrainAccList = []\n    meanTestAccList = []\n    meanValAccList = []\n    descriptionList = []\n    \n    padding = ['', '', '', '', '', '', '']\n        \n    typeList = []\n    typeList.extend(['batch'])\n    typeList.extend(padding)\n    typeList.extend(['random mini batch'])\n    typeList.extend(padding)\n    typeList.extend(['selective learning'])\n    typeList.extend(padding)\n    for scheme in regularisationBatchNets:\n        trainAccuracys = np.array(list(map(lambda x: x.accuracy(train), scheme[0])))\n        meanTrainAccList.append(1.0 - np.mean(trainAccuracys))\n        meanTrainAccList.append(np.std(trainAccuracys))\n        \n        testAccuracys = np.array(list(map(lambda x: x.accuracy(test), scheme[0])))\n        meanTestAccList.append(1.0 - np.mean(testAccuracys))\n        meanTestAccList.append(np.std(testAccuracys))\n        \n        valAccuracys = np.array(list(map(lambda x: x.accuracy(val), scheme[0])))\n        meanValAccList.append(np.mean(testAccuracys / trainAccuracys))\n        meanValAccList.append(np.std(testAccuracys / trainAccuracys))\n        \n        \n        descriptionList.append(scheme[1])\n        descriptionList.append('')\n        \n    for scheme in regularisationMiniBatchNets:\n        trainAccuracys = np.array(list(map(lambda x: x.accuracy(train), scheme[0])))\n        meanTrainAccList.append(1.0 - np.mean(trainAccuracys))\n        meanTrainAccList.append(np.std(trainAccuracys))\n        \n        testAccuracys = np.array(list(map(lambda x: x.accuracy(test), scheme[0])))\n        meanTestAccList.append(1.0 - np.mean(testAccuracys))\n        meanTestAccList.append(np.std(testAccuracys))\n        \n        valAccuracys = np.array(list(map(lambda x: x.accuracy(val), scheme[0])))\n        meanValAccList.append(np.mean(testAccuracys / trainAccuracys))\n        meanValAccList.append(np.std(testAccuracys / trainAccuracys))\n        \n        \n        descriptionList.append(scheme[1])\n        descriptionList.append('')\n        \n    for scheme in regularisationActiveNets:\n        trainAccuracys = np.array(list(map(lambda x: x.accuracy(train), scheme[0])))\n        meanTrainAccList.append(1.0 - np.mean(trainAccuracys))\n        meanTrainAccList.append(np.std(trainAccuracys))\n        \n        testAccuracys = np.array(list(map(lambda x: x.accuracy(test), scheme[0])))\n        meanTestAccList.append(1.0 - np.mean(testAccuracys))\n        meanTestAccList.append(np.std(testAccuracys))\n        \n        valAccuracys = np.array(list(map(lambda x: x.accuracy(val), scheme[0])))\n        meanValAccList.append(np.mean(testAccuracys / trainAccuracys))\n        meanValAccList.append(np.std(testAccuracys / trainAccuracys))\n        \n        \n        descriptionList.append(scheme[1])\n        descriptionList.append('')\n        \n    df = pd.DataFrame({'training': typeList, 'regularisation': descriptionList, '$trainError$': meanTrainAccList, '$testError$': meanTestAccList, '$genFactor$': meanValAccList})\n    \n    return df\n\ntable = buildDataFrame()\ntable_result = table[['training', 'regularisation', '$trainError$', '$testError$', '$genFactor$']]\ntable_result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dddd0c043590d713011b472b90b0889f5290cdac"},"cell_type":"code","source":"#print(table_result.to_latex(index=False, bold_rows=True, na_rep=''))\nwith open('./resulttable.txt', 'w') as f:\n    print(table_result.to_latex(index=False, bold_rows=True, na_rep=''), file=f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1fd1a82cc61d5c20e74ae834573e2a5b2d925bc7"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# SMALL_SIZE = 10\n# MEDIUM_SIZE = 12\n\n# plt.rc('font', size=SMALL_SIZE)\n# plt.rc('axes', titlesize=MEDIUM_SIZE)\n# plt.rc('axes', labelsize=MEDIUM_SIZE)\n# plt.rcParams['figure.dpi']=150\n\ngenerations = np.arange(0, NUM_EPOCHS, REPORT_RATE)\n\nplotColors = [\n    'b--',\n    'r--',\n    'g--',\n    'k--',\n    'g^',\n    'k'\n]\n\n\ngraphs = [[regularisationBatchNets, 'batch'], [regularisationMiniBatchNets, 'miniBatch'], [regularisationActiveNets, 'active']]\nfor graph in graphs:\n    fig = plt.figure()\n    plt.grid(1)\n    plt.xlim([0, NUM_EPOCHS])\n    plt.ion()\n    plt.xlabel('Generations')\n    plt.ylabel('Fitness')\n    plots = []\n    descriptions = []\n    for x, result in enumerate(graph[0]):\n        overTimeAccuracy = np.array(list(map(lambda x: x.trainOverTimeAccuracy, result[0])))\n        meanOverTimeAccuracy = 1 - np.mean(overTimeAccuracy, axis=0)\n        plots.append(plt.plot(generations, meanOverTimeAccuracy, plotColors[x%len(plotColors)] , linewidth=1, markersize=1)[0])\n        descriptions.append(result[1])\n\n    plt.legend(plots, descriptions)\n    fig.savefig('./' + graph[1] + 'Traning.png')\n    plt.show(5)\n\n    plt.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"edc747bd6dca3ef4ef59d4e9cfa8235f9336b6e0"},"cell_type":"code","source":"fig = plt.figure()\nplt.grid(1)\nplt.xlim([0, NUM_EPOCHS])\nplt.ion()\nplt.xlabel('Generations')\nplt.ylabel('Fitness')\nplots = []\ndescriptions = []\n\nthings = [[regularisationBatchNets, 'batch'], [regularisationMiniBatchNets, 'miniBatch'], [regularisationActiveNets, 'active']]\nfor x, graph in enumerate(things):\n    \n    overTimeAccuracy = np.array(list(map(lambda x: x.trainOverTimeAccuracy, graph[0][0][0])))\n    meanOverTimeAccuracy = 1 - np.mean(overTimeAccuracy, axis=0)\n    plots.append(plt.plot(generations, meanOverTimeAccuracy, plotColors[x%len(plotColors)] , linewidth=1, markersize=3)[0])\n    descriptions.append(graph[1])\n\nplt.legend(plots, descriptions)\nfig.savefig('./none.png')\nplt.show(5)\n\nplt.close()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}