{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Importing other necessary libraries.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, cross_val_score\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn import metrics   #Additional scklearn functions\nfrom sklearn.model_selection import GridSearchCV \nfrom sklearn.metrics import classification_report\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.preprocessing import MinMaxScaler\nimport seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading the datasets."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/health-insurance-cross-sell-prediction/train.csv')\ntest = pd.read_csv('../input/health-insurance-cross-sell-prediction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now lets take a look at the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before we go further and perform EDA, data wrangling lets make a copy of the original data and then look at the stats of the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = train.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now lets check if there are missing values."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA and Feature Engineering.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_style('whitegrid')\nplt.figure(figsize=(12,8))\nsns.countplot(x = 'Gender', hue = 'Vehicle_Damage', data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Interesting, looks like vehicles owned by `Male`, tend to have more damage, compared to `Female`."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.countplot(x = 'Vehicle_Age', hue = 'Vehicle_Damage', data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1-2 years old vehicles are prone to damage more than vehicles that are <1 year and >2 years old."},{"metadata":{},"cell_type":"markdown","source":"Now lets take a look at the `Age` column."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nprint(df['Age'].value_counts()[:5])\nsns.distplot(df.Age, color='darkred')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It looks like most common age is 24, with around 25,960 customers lying in that age.\n\nLets also look at the age range."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Youngest Customer's age : {df['Age'].min()}\")\nprint(f\"Oldest Customer's age : {df['Age'].max()}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets see how many customers are the oldest (85 years old) and youngest(20 years old)"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_rows', None)\nage_range = pd.DataFrame(df['Age'].value_counts())\nage_range","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 6232 customers, who are 20 years old, whereas there 11 customers who are 85 years old.\n\nLets now create a new column which is binned version of the `Age` column, which helps us understand the data more."},{"metadata":{"trusted":true},"cell_type":"code","source":"bins = [18, 30, 40, 50, 60, 70, 120]\nlabels = ['18-29', '30-39', '40-49', '50-59', '60-69', '70+']\ndf['Age_Range'] = pd.cut(df.Age, bins, labels = labels,include_lowest = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now lets compare `Age_Range` and `Vehicle_Damage` and see how they correlate."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.countplot(x = 'Age_Range', hue = 'Vehicle_Damage', data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Interesting, looks like the probability of `Vehicle_Damage` was more with the customers of 40-49 age group."},{"metadata":{},"cell_type":"markdown","source":"Now lets compare `Gender` and `Response` variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.countplot(x = 'Gender', hue = 'Response', data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems like males are more interested in insurance than females."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.countplot(x = 'Gender', hue = 'Previously_Insured', data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It looks like more men don't have insurance."},{"metadata":{},"cell_type":"markdown","source":"Lets now take a look at `Driving_License` column"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Driving_License'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"While 380297 customers have driving license, 812 don't."},{"metadata":{},"cell_type":"markdown","source":"Looking at the `Region_Code`..."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(24,8))\nsns.countplot(x = 'Region_Code', hue = 'Vehicle_Damage', data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It looks like area with region code 28.0 has the most vehicle damage cases.\n\nNow lets compare `Region_Code` with `Response`."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(24,8))\nsns.countplot(x = 'Region_Code', hue = 'Response', data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And obviously, that is the region where the most customers are interested in getting the insurance."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.countplot(x = 'Previously_Insured', hue = 'Response', data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If you look carefully, some customers who are not insured, are still not interested in getting the insurance."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.countplot(x = 'Age_Range', hue = 'Response', data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems that, customers in the age group 40-49 are the ones that are most interested in getting the insurance."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df['Annual_Premium'].value_counts().head(15))\nplt.figure(figsize=(12,8))\nsns.distplot(df['Annual_Premium'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems that most common annual premium is 2630.0 with 64877 customers opting out for it."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.countplot(x = 'Vehicle_Age',data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most vehicles are 1-2 years old."},{"metadata":{},"cell_type":"markdown","source":"Lets now look at correlation of features."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.heatmap(df.corr(), annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It doesn't seem like any features are highly correlated.\n\nLets look for columns that correlated to the target variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()['Response']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`Age` is somewhat correlated to the target feature, but the correlation is not much."},{"metadata":{},"cell_type":"markdown","source":"Now lets look at different data types we're dealing with in this case.."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Vehicle_Age'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are about 3 `objects`, which have to converted into numerical format. \nSo lets do that.\nBut before that lets take a look at those 3 features.\n\n`Gender` - Has 2 classes, `Male, Female`. Here we can use `pd.get_dummies()`.\n\n`Vehicle_Age` - Has 3 classes, `1-2 Year, < 1 Year, > 2 Years`. Now this is ordinal data, so the best way to convert this feature into number would be to use `Label Encoding'.\n\n`Vehicle_Damage` - Has 2 classes, `Yes, No`. Similar to `Gender`, we can use `pd.get_dummies()`.\n\nLets do that.\n\nNote - We only use `Label Encoding` when the feature is ordinal. We can also use Label Encoder. But in case the feature isn't ordinal and is instead nominal, go ahead and use either `pd.get_dummies()` or `OneHotEncoder`."},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.concat([df,pd.get_dummies(df['Vehicle_Damage'],prefix='Vehicle_Damage')],axis=1).drop(['Vehicle_Damage'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that we've created dummy variable for `Vehicle_Damage` feature, lets do the same for `Gender` feature."},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.concat([df,pd.get_dummies(df['Gender'],prefix='Gender')],axis=1).drop(['Gender'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Can you notice what's wrong here?.\n\nYes!, while creating dummy variables, we created extra features which represent the same thing. This is called dummy variable trap.\n\nSo lets drop any 2 of the 4 dummy variables created. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['Vehicle_Damage_No','Gender_Female'], axis=1, inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we still have to convert feature `Vehicle_Age`, and since it's a ordinal feature,lets use `pd.categorical()`."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Vehicle_Age'] = pd.Categorical(df['Vehicle_Age'].values).codes\ndf['Age_Range'] = pd.Categorical(df['Age_Range'].values).codes\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modelling\n\nNow that all the features are numerical, lets build some ML models."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop(['Response','id', 'Age_Range'], axis=1)\ny = df['Response']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before we build models, lets first normalize the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler()\nscaled_X = scaler.fit_transform(X)\nscaled_X = pd.DataFrame(scaled_X)\nscaled_X.columns = X.columns\nscaled_X.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before start building models, lets check if the target variable is balanced."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y.value_counts())\ny.value_counts().plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Target variable is highly imbalanced. This will definitely result in poor results in the class with lower value counts.\nLets balance it using `SMOTE`."},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\nfrom imblearn.over_sampling import SMOTE\nprint('Original dataset shape %s' % Counter(y))\nsm = SMOTE(random_state=42)\nX_res, y_res = sm.fit_resample(scaled_X, y)\nprint('Resampled dataset shape %s' % Counter(y_res))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now implementing SMOTE results in significant increase in the data points.\nLets check the shape of the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_res = pd.DataFrame(X_res)\ny_res = pd.Series(y_res)\nX_res.columns = scaled_X.columns\nX_res.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_res.value_counts())\ny_res.value_counts().plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our target variable is now balanced."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_res.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see that now the datapoints are 668798, almost double the size of our original number of datapoints.\n\nAnyway, lets now build models on this data.\n\nWe also don't need the feature `Age_Range`, as it gives the same information as `Age`, so lets drop it."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size = 0.3, random_state = 42)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(42)\nxgb1 = XGBClassifier(learning_rate =0.1, n_estimators=1000, max_depth=5, min_child_weight=1,\ngamma=0,subsample=0.8, colsample_bytree=0.8, objective= 'binary:logistic',nthread=4,\nscale_pos_weight=1,seed=27)\nxgb1.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(42)\netc = ExtraTreesClassifier(n_estimators=200).fit(X_train, y_train)\nprint(etc.score(X_test, y_test))\netc_pred = etc.predict(X_test)\nprint(classification_report(etc_pred, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(42)\nrf = RandomForestClassifier(n_estimators=200).fit(X_train, y_train)\nprint(rf.score(X_test, y_test))\nrf_pred = rf.predict(X_test)\nprint(classification_report(rf_pred, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You can play around with different parameters, or tune them as you wish.\nI've used them because they seemed to work for me."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"ROC_AUC Score of XGBoost Classifier is : {metrics.roc_auc_score(xgb1.predict(X_test), y_test)}\")\nprint(f\"ROC_AUC Score of RandomForestClassifier is : {metrics.roc_auc_score(rf.predict(X_test), y_test)}\")\nprint(f\"ROC_AUC Score of ExtraTreesClassifier is : {metrics.roc_auc_score(etc.predict(X_test), y_test)}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Of all the models, ExtraTreesClassifier has better `roc_auc_score`. So lets consider that as our final model.\n\nBut before making predictions on the test set, we must remember that we created an additional feature called `Age_Range` using `Age` column.\n\nWe have to drop one of them, so that the model is more robust.\n\nThis may result in the drop of ROC_AUC_score, but it makes our model robust."},{"metadata":{},"cell_type":"markdown","source":"## Predictions\nNow lets make predictions on the test data."},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets first deal with the categorical data.."},{"metadata":{"trusted":true},"cell_type":"code","source":"t_copy = test.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t_copy.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating dummy variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"t_copy=pd.concat([t_copy,pd.get_dummies(t_copy['Gender'],prefix='Gender')],axis=1).drop(['Gender'],axis=1)\nt_copy=pd.concat([t_copy,pd.get_dummies(t_copy['Vehicle_Damage'],prefix='Vehicle_Damage')],axis=1).drop(['Vehicle_Damage'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t_copy.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t_copy['Vehicle_Age'] = pd.Categorical(t_copy['Vehicle_Age'].values).codes\nt_copy.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t_copy.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dropping `id,Vehicle_Damage_No,Gender_Female`, to avoid dummy variable trap."},{"metadata":{"trusted":true},"cell_type":"code","source":"t_copy.drop(['id','Vehicle_Damage_No','Gender_Female'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Scaling the test data.."},{"metadata":{"trusted":true},"cell_type":"code","source":"scaled_test = scaler.transform(t_copy)\nscaled_test = pd.DataFrame(scaled_test)\nscaled_test.columns = t_copy.columns\nscaled_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = etc.predict(scaled_test)\nf_pred = pd.concat([pd.DataFrame(test['id']),pd.DataFrame(pred)], axis=1)\nf_pred.columns = ['id','Response'] \nf_pred.head()\nf_pred.to_csv('Submission.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}