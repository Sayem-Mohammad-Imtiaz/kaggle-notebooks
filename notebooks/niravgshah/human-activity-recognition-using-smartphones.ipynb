{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pylab as pl\nimport pandas as pd\nimport matplotlib.pyplot as plt \n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.utils import shuffle\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix,classification_report\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\ntrain = shuffle(pd.read_csv(\"../input/train.csv\"))\ntest = shuffle(pd.read_csv(\"../input/test.csv\"))\ntrain_outcome = pd.crosstab(index=train[\"Activity\"], columns=\"count\")\ntrain_outcome\ntemp = train[\"Activity\"].value_counts()\ndf = pd.DataFrame({'labels': temp.index,\n                   'values': temp.values\n                  })\n\n#df.plot(kind='pie',labels='labels',values='values', title='Activity Ditribution',subplots= \"True\")\n\nlabels = df['labels']\nsizes = df['values']\ncolors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral','cyan','lightpink']\npatches, texts = plt.pie(sizes, colors=colors, shadow=True, startangle=90, pctdistance=1.1, labeldistance=1.2)\nplt.legend(patches, labels, loc=\"best\")\nplt.axis('equal')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Seperating Predictors and Outcome values from train and test sets\nX_train = pd.DataFrame(train.drop(['Activity','subject'],axis=1))\nY_train_label = train.Activity.values.astype(object)\nX_test = pd.DataFrame(test.drop(['Activity','subject'],axis=1))\nY_test_label = test.Activity.values.astype(object)\n\n# Dimension of Train and Test set \n#print(\"Dimension of Train set\",X_train.shape)\n#print(\"Dimension of Test set\",X_test.shape,\"\\n\")\n\n# Transforming non numerical labels into numerical labels\nfrom sklearn import preprocessing\nencoder = preprocessing.LabelEncoder()\n\n# encoding train labels \nencoder.fit(Y_train_label)\nY_train = encoder.transform(Y_train_label)\n\n# encoding test labels \nencoder.fit(Y_test_label)\nY_test = encoder.transform(Y_test_label)\n\n#Total Number of Continous and Categorical features in the training set\nnum_cols = X_train._get_numeric_data().columns\nprint(\"Number of numeric features:\",num_cols.size)\n#list(set(X_train.columns) - set(num_cols))\n\n\nnames_of_predictors = list(X_train.columns.values)\n\n# Scaling the Train and Test feature set \nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Libraries to Build Ensemble Model : Random Forest Classifier \n# Create the parameter grid based on the results of random search \nparams_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n                     'C': [1, 10, 100, 1000]},\n                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n# Performing CV to tune parameters for best SVM fit \nsvm_model = GridSearchCV(SVC(), params_grid, cv=5)\nsvm_model.fit(X_train_scaled, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_model = svm_model.best_estimator_\nY_pred = final_model.predict(X_test_scaled)\nY_pred_label = list(encoder.inverse_transform(Y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Training set score for SVM: %f\" % final_model.score(X_train_scaled , Y_train))\nprint(\"Testing  set score for SVM: %f\" % final_model.score(X_test_scaled  , Y_test ))\n\nsvm_model.score","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}