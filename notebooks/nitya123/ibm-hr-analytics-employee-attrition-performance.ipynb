{"cells":[{"metadata":{"_uuid":"8365dfc9837bce70eddb8496274889d00d22bb95"},"cell_type":"markdown","source":"# Business Problem"},{"metadata":{"_uuid":"569008a0bc2d559192cb1fd8083cd46114b6bffc"},"cell_type":"markdown","source":"IBM is an American multinational technology company and they wants to know why employees are leaving the company(Fictional dataset)"},{"metadata":{"_uuid":"a67710b7d7eca9edf97842e913bb8c46bbd145be"},"cell_type":"markdown","source":"# Objective"},{"metadata":{"_uuid":"cf3f84586703f2f41e2fb002b24f18460203ea19"},"cell_type":"markdown","source":"The company wants to understand what factors contributed most to employee turnover and to create a model that can predict if a certain employee will leave the company or not. The goal is to create or improve different retention strategies on targeted employees. Overall, the implementation of this model will allow management to create better decision-making actions."},{"metadata":{"_uuid":"dbca411c0eac7bac5cdd03a2aceedc39137801b3"},"cell_type":"markdown","source":"Parameters and their score range"},{"metadata":{"_uuid":"61d32fa2c1e60bec26fbc18747238c7836c07755"},"cell_type":"markdown","source":"Education 1 'Below College' 2 'College' 3 'Bachelor' 4 'Master' 5 'Doctor'\n\nEnvironmentSatisfaction 1 'Low' 2 'Medium' 3 'High' 4 'Very High'\n\nJobInvolvement \n1 'Low' 2 'Medium' 3 'High' 4 'Very High'\n\nJobSatisfaction 1 'Low' 2 'Medium' 3 'High' 4 'Very High'\n\nPerformanceRating \n1 'Low' 2 'Good' 3 'Excellent' 4 'Outstanding'\n\nRelationshipSatisfaction \n1 'Low' 2 'Medium' 3 'High' 4 'Very High'\n\nWorkLifeBalance 1 'Bad' 2 'Good' 3 'Better' 4 'Best'\n\nStandardHours=80"},{"metadata":{"_uuid":"da0a81e467f52c19472a93d66b6e68c377b40297"},"cell_type":"markdown","source":"### Part 1: Obtaining the Data"},{"metadata":{"trusted":false,"_uuid":"ef27211f0e73a52ec2d2144aa3829066c08bbf5e"},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"1987812cb3d9deba333d85e3df3422e226e3a7cd"},"cell_type":"code","source":"df=pd.read_csv('../input/WA_Fn-UseC_-HR-Employee-Attrition.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"14425bbc374056bb706b3455df1bc26d071dd194"},"cell_type":"markdown","source":"### 1.a Know the Datatypes\n"},{"metadata":{"trusted":false,"_uuid":"1c1e61a5273287bbbeeaf84b80d9501f9b3d70fd"},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5bcd9941f7494aec0b832a627eec417d4391a373"},"cell_type":"markdown","source":"### Part 2: Scrubbing the Data"},{"metadata":{"trusted":false,"_uuid":"57dc955549c5abbcc13957d9d4bb569d70e14cd2"},"cell_type":"code","source":"df.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"3b1c6a8737be47be3ffa4a23d88ba930b90de0b6"},"cell_type":"code","source":"front=df['Attrition']\ndf.drop(labels=['Attrition'],axis=1,inplace=True)\ndf.insert(0,'Attrition',front)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"415d11f374d7e8cb5f4ab367cdfd4db7f9daf95c"},"cell_type":"code","source":"#Delete Unwanted Records\ndf.drop(labels=['EmployeeCount','EmployeeNumber','StockOptionLevel','StandardHours'],axis=1,inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"b7c115f8cd831f27ec8134033944b6b27c27e90e"},"cell_type":"code","source":"#df['Gender']=df['Gender'].map({'Male':0,'Female':1}) Map doesnt work\nAttrition={'Yes':1,'No':0}\ndf.Attrition=[Attrition[item] for item in df.Attrition]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"57d1bee0d83a879ed212b1a024084660c4e465e5"},"cell_type":"code","source":"#Get categorical values of column \ndf.EducationField.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"cafdc2035c09c4ec85f7c8dcc7f6b4ab8ff7c5e5"},"cell_type":"code","source":"# creating a dict file \nGender={'Male':1,'Female':0}\n# traversing through dataframe Gender column and writing values where key matches\ndf.Gender=[Gender[item] for item in df.Gender]\n\nField={'Life Sciences':2,'Medical':1,'Other':0,'Marketing':3,'Technical Degree':4,'Human Resources':5}\ndf.EducationField=[Field[item] for item in df.EducationField]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"504ffab5716f8796e3c5ab518e4997d308fcf9a6"},"cell_type":"markdown","source":"### Part 3: Exploring the Data"},{"metadata":{"trusted":false,"_uuid":"f31da753c05b7b182c8f15cbf849135241c9cf8a"},"cell_type":"code","source":"#Summary based on Attrition\ndf1=df.groupby('Attrition')\ndf1.mean()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0afad00ab56d686d3de5c8e87693e4268f16aeb3"},"cell_type":"markdown","source":"### 3.1 Correlation between parameters"},{"metadata":{"trusted":false,"_uuid":"5f4877692a5a8c742a0d5c60b12c180838eec471"},"cell_type":"code","source":"corr=df.corr()\ncorr=(corr)\nplt.figure(figsize=(10, 10))\nsns.heatmap(corr,\n           xticklabels=corr.columns.values,\n           yticklabels=corr.columns.values,cmap='Blues')\ncorr\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6ded579d4ae30488f625adb842c3279a87cd180d"},"cell_type":"markdown","source":"### Conclusion:\n\n### Monthly income,Job level is highly correlated with TotalWorkingYears\n### PerformanceRating is highly correlated with PercentSalaryhike"},{"metadata":{"trusted":false,"_uuid":"baf76034a8c5a03a6c146cb52f790dec9254d1fb"},"cell_type":"code","source":"Attrition_Rate=df.Attrition.value_counts()/len(df)\nAttrition_Rate","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b109b371f85eaff4cde27d370f097071f468251c"},"cell_type":"markdown","source":"### Looks like about 83% of employees stayed and 16% of employees left\n"},{"metadata":{"_uuid":"2335942357ba8d41de1bbb30579612e4037d1193"},"cell_type":"markdown","source":"### 3.2  Employee income & Gender vs Attrition"},{"metadata":{"trusted":false,"_uuid":"534581e3722549e8816edc1246f2c6096eef1f6a"},"cell_type":"code","source":"sns.barplot(x='Attrition',y='MonthlyIncome',hue='Gender',data=df,color='green').set_title('Employee Income Gender Distribution')\nplt.figure(figsize=(10, 10))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1bd9104c262a1a085a7e862dea85706d78f6a4e5"},"cell_type":"markdown","source":"### 3.3 DistanceFromHome  & Gender vs Attrition"},{"metadata":{"trusted":false,"_uuid":"a22ea28fef69dd3d14a4a2687777ad4acab0d77c"},"cell_type":"code","source":"sns.barplot(x='Attrition',y='DistanceFromHome',hue='Gender',data=df,color='blue').set_title('Employee Distance Gender Distribution')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"23188838c83d37d6be6e8a0a9655e4ff0b78ef95"},"cell_type":"markdown","source":"### 3.4  Employee Salary vs Attrition"},{"metadata":{"_uuid":"29707c79afc26269d632a99be368a3edb3bab77d"},"cell_type":"markdown","source":"Converting Monthly income into 5 income range"},{"metadata":{"trusted":false,"_uuid":"4c219a411e0cce54172b3df10472d871c6eddac8"},"cell_type":"code","source":"df['Income_Range']=pd.cut(df['MonthlyIncome'],[1000,5000,10000,15000,20000])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"cf8d7e548ef88179f9acfe114f7e18b1ab69e05b"},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(15, 4))\nsns.countplot(y='Income_Range',hue='Attrition',data=df).set_title('Employee Salary Attrition Distribution')\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f68bb10993255fde67d1da9a06e9c17211e6cb51"},"cell_type":"markdown","source":"### 3.5 Employee Job Satisfaction Rating vs Attrition"},{"metadata":{"trusted":false,"_uuid":"a022add7d65494e7107d5b2df391ad4de4ce2411"},"cell_type":"code","source":"fig=plt.figure(figsize=(15,4))\nax=sns.kdeplot(df.loc[(df['Attrition']==0),'JobSatisfaction'],color='g',shade=False,label='No Attrition')\nax=sns.kdeplot(df.loc[(df['Attrition']==1),'JobSatisfaction'],color='r',shade=True,label='Attrition')\nax.set(xlabel='Employee Job Satisfaction Rating',ylabel='Frequency')\nplt.title('Employee Job Satisfaction Rating - Attrition vs No Attrition')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"858d9309c421513e6b50f82da54ed4444611df95"},"cell_type":"markdown","source":"### 3.6 Employee WorkLifeBalance Rating vs Attrition"},{"metadata":{"trusted":false,"_uuid":"e328f39195be663ce82f5418b8dd023ee942ecae"},"cell_type":"code","source":"fig=plt.figure(figsize=(15,4))\nax=sns.kdeplot(df.loc[(df['Attrition']==0),'WorkLifeBalance'],color='g',shade=False,label='No Attrition')\nax=sns.kdeplot(df.loc[(df['Attrition']==1),'WorkLifeBalance'],color='r',shade=True,label='Attrition')\nax.set(xlabel='Employee WorkLifeBalance Rating',ylabel='Frequency')\nplt.title('Employee WorkLifeBalance Rating - Attrition vs No Attrition')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"61eb2438126e5cb2390124427d5106ef552ad44c"},"cell_type":"markdown","source":"### 3.7 Employee Relationship Satisfaction vs Attrition"},{"metadata":{"trusted":false,"_uuid":"43498f2f005e8ca9a80c8b5955621e0ba76adc37"},"cell_type":"code","source":"fig=plt.figure(figsize=(15,4))\nax=sns.kdeplot(df.loc[(df['Attrition']==0),'RelationshipSatisfaction'],color='g',shade=False,label='No Attrition')\nax=sns.kdeplot(df.loc[(df['Attrition']==1),'RelationshipSatisfaction'],color='r',shade=True,label='Attrition')\nax.set(xlabel='Employee RelationshipSatisfaction Rating',ylabel='Frequency')\nplt.title('Employee Relationship Satisfaction Rating - Attrition vs No Attrition')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a70b92b2870221087b0bb0f35ce28bdb313685a9"},"cell_type":"markdown","source":"### 3.8  Employee YearsAtCompany vs Attrition"},{"metadata":{"trusted":false,"_uuid":"39651d1002404c3af7beae96469bb3d4c3207eee"},"cell_type":"code","source":"fig=plt.figure(figsize=(15,4))\nax=sns.kdeplot(df.loc[(df['Attrition']==0),'YearsAtCompany'],color='g',shade=False,label='No Attrition')\nax=sns.kdeplot(df.loc[(df['Attrition']==1),'YearsAtCompany'],color='r',shade=True,label='Attrition')\nax.set(xlabel='Employee YearsAtCompany ',ylabel='Frequency')\nplt.title('Employee YearsAtCompany - Attrition vs No Attrition')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"327243788dc9d2930efbcd6ed8a7715b5e123375"},"cell_type":"code","source":"fig=plt.figure(figsize=(15,8))\nvalue=df['YearsAtCompany']<11\ndf3=df[value]\nsns.countplot(x='YearsAtCompany',hue='Attrition',data=df3)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ff6829e16a9531cc5e1c2d8197a3e611418b0a7f"},"cell_type":"markdown","source":"### Conclusion:\n\n### Employee leaving the company at initial stage"},{"metadata":{"_uuid":"7a04cb08040123dffb8b9a41338076269addcd52"},"cell_type":"markdown","source":"### 3.9  Employee YearswithCurrentManager  vs Attrition\n"},{"metadata":{"trusted":false,"_uuid":"eaf1edcedef8283708737d67f6d6d80cf9d84d61"},"cell_type":"code","source":"fig=plt.figure(figsize=(10,6))\nsns.countplot(x='YearsWithCurrManager',hue='Attrition',data=df,color='black')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d5da0428a8c4b9a81dc073f540a2413dc8afe47e"},"cell_type":"markdown","source":"### 3.9  Employee YearsSinceLastPromotion  vs Attrition\n"},{"metadata":{"trusted":false,"_uuid":"dcb4027e3263713616982cf549997369aa28e842"},"cell_type":"code","source":"fig=plt.figure(figsize=(10,6))\nsns.countplot(x='YearsSinceLastPromotion',hue='Attrition',data=df,color='green')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"753d4131621b18efb2386d30207fcc3a1782a24f"},"cell_type":"markdown","source":"### 3.10  Analysis of parameter vs Attrition"},{"metadata":{"trusted":false,"_uuid":"2666561cf470d69c013d13681bbcf8661cc37227"},"cell_type":"code","source":"total_records= len(df)\ncolumns = [\"Gender\",\"MaritalStatus\",\"WorkLifeBalance\",\"EnvironmentSatisfaction\",\"JobSatisfaction\",\n           \"JobLevel\",'NumCompaniesWorked',\"JobInvolvement\",\"BusinessTravel\",'Department']\n\nj=0\nfor i in columns:\n    j +=1\n    plt.subplot(5,2,j)\n    ax1 = sns.countplot(data=df,x= i,hue=\"Attrition\")\n    if(j==9 or j== 10):\n        plt.xticks( rotation=90)\n    for p in ax1.patches:\n        height = p.get_height()\n        #ax1.text(p.get_x()+p.get_width()/2.,\n               # height + 3,\n                #'{:1.2f}'.format(height/total_records,0),\n                #ha=\"center\",rotation=0) \n\n# Custom the subplot layout\nplt.subplots_adjust(bottom=0.1, top=4)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d5aa3f8e087a9feac3850a4585218c0656572590"},"cell_type":"markdown","source":"### 4 . Modeling the Data: Logistic Regression Analysis"},{"metadata":{"_uuid":"04d72c0c590c9d59f243141420f734f4a373338a"},"cell_type":"markdown","source":"### 4.1 Feature Engineering\n"},{"metadata":{"trusted":false,"_uuid":"4973d21fc55b4eb9b8be86704407c4f20babe558"},"cell_type":"code","source":"#Selecting numeric paremeters for Feature Engineering\ndf3=df[['JobLevel','EnvironmentSatisfaction','JobInvolvement','JobSatisfaction','PerformanceRating','RelationshipSatisfaction','WorkLifeBalance','Attrition']]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a81f499ed0d3f8571163c94f9cabd16679588bc"},"cell_type":"markdown","source":"Summary :\n\nBy using a decision tree classifier, it could rank the features used for the prediction. The top three features were JobLevel, JobInvolvment, and EnviornmentSatisfaction. This is helpful in creating our model for logistic regression because it’ll be more interpretable to understand what goes into our model when we utilize less features."},{"metadata":{"trusted":false,"_uuid":"f1622c0cd77354b05e9d43c3657adbe410d7cb75"},"cell_type":"code","source":"from sklearn import tree\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nplt.style.use('fivethirtyeight')\nplt.rcParams['figure.figsize'] = (12,6)\n\n# Create train and test splits\ntarget_name = 'Attrition'\nX = df3.drop('Attrition', axis=1)\n\ny=df3[target_name]\nX_train,X_test,y_train,t_test=train_test_split(X,y,test_size=0.15, random_state=123, stratify=y)\n\ndtree = tree.DecisionTreeClassifier(\n    #max_depth=3,\n    class_weight=\"balanced\",\n    min_weight_fraction_leaf=0.01\n    )\ndtree = dtree.fit(X_train,y_train)\n\n## plot the importances ##\nimportances = dtree.feature_importances_\nfeat_names = df3.drop(['Attrition'],axis=1).columns\n\nindices = np.argsort(importances)[::-1]\nplt.figure(figsize=(12,6))\nplt.title(\"Feature importances by DecisionTreeClassifier\")\nplt.bar(range(len(indices)), importances[indices], color='lightblue',  align=\"center\")\nplt.step(range(len(indices)), np.cumsum(importances[indices]), where='mid', label='Cumulative')\nplt.xticks(range(len(indices)), feat_names[indices], rotation='vertical',fontsize=14)\nplt.xlim([-1, len(indices)])\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cf4aee76e6c4e0b8a58c199da1134c991dc8f7fb"},"cell_type":"markdown","source":"Modeling the Data: Logistic Regression Analysis"},{"metadata":{"_uuid":"7bd0effda13b8b0d4f86571505eb9b632c5054d2"},"cell_type":"markdown","source":"Logistic Regression commonly deals with the issue of how likely an observation is to belong to each group. This model is commonly used to predict the likelihood of an event occurring. In contrast to linear regression, the output of logistic regression is transformed with a logit function. This makes the output either 0 or 1. This is a useful model to take advantage of for this problem because we are interested in predicting whether an employee will leave (0) or stay (1).\n\nAnother reason for why logistic regression is the preferred model of choice is because of its interpretability. Logistic regression predicts the outcome of the response variable (turnover) through a set of other explanatory variables, also called predictors. In context of this domain, the value of our response variable is categorized into two forms: 0 (zero) or 1 (one). The value of 0 (zero) represents the probability of an employee not leaving the company and the value of 1 (one) represents the probability of an employee leaving the company.\n"},{"metadata":{"trusted":false,"_uuid":"1a7ee3289633c6913b8689a145941e4c35325d1a"},"cell_type":"code","source":"# Create an intercept term for the logistic regression equation\ndf['value'] = 1\nindep_var = ['JobLevel','JobInvolvement','EnvironmentSatisfaction','value', 'Attrition']\ndf = df[indep_var]\n\n# Create train and test splits\ntarget_name = 'Attrition'\nX = df.drop('Attrition', axis=1)\n\ny=df[target_name]\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.15, random_state=123, stratify=y)\n\nX_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0ac44958ebdea475e52e1b425536acb95ac90d98"},"cell_type":"markdown","source":"### 4.2  Using Logistic Regression Coefficients"},{"metadata":{"trusted":false,"_uuid":"acd34e732f7622491bd48833ccb462c77d041a7d"},"cell_type":"code","source":"import statsmodels.api as sm\niv = ['JobLevel','JobInvolvement','EnvironmentSatisfaction', 'value']\nlogReg = sm.Logit(y_train, X_train[iv])\nanswer = logReg.fit()\n\nanswer.summary\nanswer.params","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"15a07d56b0351b00e84f7274e14335d1060e9700"},"cell_type":"markdown","source":"### 4.3  Function to compute coefficients"},{"metadata":{"trusted":false,"_uuid":"ec57cc86d78660ce64fbfc9d75d1fc2ca76cbc43"},"cell_type":"code","source":"# Create function to compute coefficients\ncoef = answer.params\ndef y (coef,JobLevel,JobInvolvement , EnvironmentSatisfaction) : \n    return coef[3] + coef[0]*JobLevel + coef[1]*JobInvolvement + coef[2]*EnvironmentSatisfaction\n\nimport numpy as np\n\n# An Employee Having at level 1 and rating 1 for EnvironmentSatisfaction and 1 for JobInvolvement a 54% chance of attrition\ny1 = y(coef, 1, 1, 1)\np = np.exp(y1) / (1+np.exp(y1))\np","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e99da2eb9907a11d9fe4bbb46adc0c75d8c9b072"},"cell_type":"markdown","source":"###  Compare Logistic Regression Model V.S. Decision Tree Model V.S. Random Forest Model"},{"metadata":{"trusted":false,"_uuid":"dfefd4716a4c69a717662e5fe89ac40d56da8be7"},"cell_type":"code","source":"# Compare the Logistic Regression Model V.S. Decision Tree Model V.S. Random Forest Model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn import tree\nfrom sklearn.tree import DecisionTreeClassifier\nfrom numpy.core.umath_tests import inner1d\n\n\n#Logistic Regression Model\nmodel1 = LogisticRegression(class_weight=\"balanced\",)\nmodel1.fit(X_train, y_train)\nprint (\"\\n\\n ---Logistic Model---\")\nlogit_roc_auc = roc_auc_score(y_test, model1.predict(X_test))\nprint (\"Logistic AUC = %2.2f\" % logit_roc_auc)\nprint(classification_report(y_test, model1.predict(X_test)))\n\n#Decision Tree Model\nmodel2=DecisionTreeClassifier(min_weight_fraction_leaf=0.01,class_weight=\"balanced\",)\nmodel2.fit(X_train,y_train)\nprint(\"\\n\\n ---Decision Tree Model ---\")\ndtree_roc_auc=roc_auc_score(y_test,model2.predict(X_test))\nprint(\"Decision Tree AUC = %2.2f\" % dtree_roc_auc)\nprint(classification_report(y_test,model2.predict(X_test)))\n\n#Random Forest Model\nmodel3=RandomForestClassifier( n_estimators=1000,max_depth=None,min_samples_split=10,class_weight=\"balanced\")\nmodel3.fit(X_train,y_train)\nprint(\"\\n\\n --- Random Forest Model ----\")\nrforest_roc_auc=roc_auc_score(y_test,model2.predict(X_test))\nprint(\"Random forest AUC = %2.2f\" % rforest_roc_auc)\nprint(classification_report(y_test,model3.predict(X_test)))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"ecc38ed9c2adddbb0ea7bdd6ed020f74d5f2de37"},"cell_type":"code","source":"# Using 10 fold Cross-Validation to train Logistic Regression Model\nfrom sklearn import model_selection\nfrom sklearn.linear_model import LogisticRegression\nkfold = model_selection.KFold(n_splits=10, random_state=7)\nmodelCV = LogisticRegression(class_weight = \"balanced\")\nscoring = 'roc_auc'\nresults = model_selection.cross_val_score(modelCV, X_train, y_train, cv=kfold, scoring=scoring)\nprint(\"AUC: %.3f (%.3f)\" % (results.mean(), results.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"485e13725704f5825f2c28ee742fb91a0b41adf9"},"cell_type":"code","source":"# Using 10 fold Cross-Validation to train Decision Tree Model\nfrom sklearn import model_selection\nfrom sklearn.tree import DecisionTreeClassifier\nkfold = model_selection.KFold(n_splits=10, random_state=7)\nmodelCV = DecisionTreeClassifier(class_weight = \"balanced\",min_weight_fraction_leaf=0.01)\nscoring = 'roc_auc'\nresults = model_selection.cross_val_score(modelCV, X_train, y_train, cv=kfold, scoring=scoring)\nprint(\"AUC: %.3f (%.3f)\" % (results.mean(), results.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"ec22215ef046db47267a33c2cc8cf73d859482a9"},"cell_type":"code","source":"# Using 10 fold Cross-Validation to train Random Forest Model\nfrom sklearn import model_selection\nfrom sklearn.ensemble import RandomForestClassifier\nkfold = model_selection.KFold(n_splits=10, random_state=7)\nmodelCV = RandomForestClassifier(n_estimators=1000,max_depth=None,min_samples_split=10,class_weight=\"balanced\")\nscoring = 'roc_auc'\nresults = model_selection.cross_val_score(modelCV, X_train, y_train, cv=kfold, scoring=scoring)\nprint(\"AUC: %.3f (%.3f)\" % (results.mean(), results.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"7e55fe0d36d4a06bdc03db77d233ae9706288fb9"},"cell_type":"code","source":"# Create ROC Graph\nfrom sklearn.metrics import roc_curve\nfpr, tpr, thresholds = roc_curve(y_test, model1.predict_proba(X_test)[:,1])\n#The first column is the probability that the entry has the -1 label \n#and the second column is the probability that the entry has the +1 label.\nrf_fpr, rf_tpr, rf_thresholds = roc_curve(y_test, model3.predict_proba(X_test)[:,1])\ndt_fpr, dt_tpr, dt_thresholds = roc_curve(y_test, model2.predict_proba(X_test)[:,1])\n\n\nplt.figure()\n\n# Plot Logistic Regression ROC\nplt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n\n# Plot Random Forest ROC\nplt.plot(rf_fpr, rf_tpr, label='Random Forest (area = %0.2f)' % rforest_roc_auc)\n\n# Plot Decision Tree ROC\nplt.plot(dt_fpr, dt_tpr, label='Decision Tree (area = %0.2f)' % dtree_roc_auc)\n\n# Plot Base Rate ROC\nplt.plot([0,1], [0,1],label='Base Rate')\n\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Graph')\nplt.legend(loc=\"lower right\")\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"5bdc90bcc8cf81f9aa25707e6c7bce8b7ae72297"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}