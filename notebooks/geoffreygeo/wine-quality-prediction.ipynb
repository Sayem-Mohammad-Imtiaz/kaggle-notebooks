{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n#scikit learn library \nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n\nfrom sklearn.externals.six import StringIO  \nfrom IPython.display import Image  \nfrom sklearn.tree import export_graphviz\nimport pydotplus\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/winequality-red.csv')\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b69cd30b10aeeb52faf7ad3fb6d690566e0571d"},"cell_type":"code","source":"#checking for null values\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0a8f1e37238a4d24c831d8282751c72e4805606"},"cell_type":"code","source":"df.quality.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2d70fb701ad1d475854ecc0ae6a89db238cb5ce"},"cell_type":"code","source":"df_label = df['quality'].values\ndf_data=df.drop('quality',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"012b2fe63ab38b351c9b9168cf09197014733935"},"cell_type":"code","source":"#splitting the test data and the train data\nfrom sklearn.model_selection import train_test_split\n\nxtrain, xtest, ytrain, ytest = train_test_split(df_data,df_label,test_size=1/3, random_state=0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"83c16d74aab16734d4653969ff31e28b0235f4b2"},"cell_type":"code","source":"clf = GaussianNB()\nclf1= MultinomialNB()\nclf2=BernoulliNB()\nclf.fit(xtrain,ytrain)\nclf1.fit(xtrain,ytrain)\nclf2.fit(xtrain,ytrain)\naccuracy = dict()\npredicted_values_GB=clf.predict(xtest)\npredicted_values_NB=clf1.predict(xtest)\npredicted_values_BB=clf2.predict(xtest)\naccuracy['Gaussian'] = accuracy_score(predicted_values_GB,ytest)*100\naccuracy['MultinomialNB'] = accuracy_score(predicted_values_NB,ytest)*100\naccuracy['BernoulliNB'] = accuracy_score(predicted_values_BB,ytest)*100\naccuracy['Max_accuracy'] = 100\naccuracy=pd.DataFrame(list(accuracy.items()),columns=['Algorithm','Accuracy'])\ndisplay(accuracy)\nsns.lineplot(x='Algorithm',y='Accuracy',data=accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"20cbb016d084ee35689f71b99064ed80ec9c916b"},"cell_type":"code","source":"display(df['quality'].unique())\nfig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True,figsize=(11,11))\n# we will create a new feature called label. This column will contain the values bad,average,excellant. \n#This will be split in the following way. \n#1,2,3 --> Bad\n#4,5,6,7 --> Average\n#8,9,10 --> Excellent\ndef label_quality(quality):\n    if(quality >=1 and quality<=3):\n        return 'Bad'\n    elif(quality>=4 and quality<=7):\n        return 'Average'\n    elif(quality>=8 and quality<=10):\n        return 'Excellent'\ndf['label']=df['quality'].apply(label_quality)\nsns.countplot(x='quality',data=df,ax=ax1)\nsns.countplot(x='label',data=df,ax=ax2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f9680ccc9af4908ae749d4a87be0e9ceafd87bf"},"cell_type":"code","source":"df_label = df['label'].values\ndf_data=df.drop(['quality','label'],axis=1)\nfrom sklearn.model_selection import train_test_split\n\nxtrain, xtest, ytrain, ytest = train_test_split(df_data,df_label,test_size=1/3, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aff41a35848bc2a278176b53fe9c01678f48d43b"},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nDT=DecisionTreeClassifier()\nDT.fit(xtrain,ytrain)\npredicted_result_dt= DT.predict(xtest)\nprint(\"The accuracy score of DT is {}\".format(accuracy_score(predicted_result_dt,ytest)*100))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4455ce82e8838f011802b2920662c27dd1736be3"},"cell_type":"code","source":"import graphviz\nfrom sklearn import tree\n\ndata = export_graphviz(DT,out_file=None,   \n                         filled=True, rounded=True,  \n                         special_characters=True)\ngraph = graphviz.Source(data)\ndisplay(graph)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b6bcc49c5ec5ba8cc5eaa18f81430fdad027835"},"cell_type":"code","source":"dot_data = StringIO()\nexport_graphviz(DT, out_file=dot_data,  \n                filled=True, rounded=True,\n                special_characters=True)\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \nImage(graph.create_png())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}