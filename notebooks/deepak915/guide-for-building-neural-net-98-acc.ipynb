{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.feature_selection import mutual_info_classif\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2021-09-14T20:48:58.03932Z","iopub.status.idle":"2021-09-14T20:48:58.039739Z","shell.execute_reply.started":"2021-09-14T20:48:58.039507Z","shell.execute_reply":"2021-09-14T20:48:58.039529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The approach for solving this type of problem constitutes of below steps:\n### 1. Explore the dataset *Check shape* of dataset\n### 2. Look for the object/cat datatype among the columns\n### 3. Fill in all of the Null Values\n### 4. Select the best features for model-building\n### 5. Normalize the features\n### 6. Split the datasets\n### 7. Build the Neural-Net(use 'softmax' activation for last layer when doing multi-class classification)\n### 8. Compile the model\n### 9. Fit the model\n### 10. Evaluate!","metadata":{}},{"cell_type":"markdown","source":"# Importing and Exploring dataset","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv('../input/eeg-brainwave-dataset-feeling-emotions/emotions.csv')","metadata":{"execution":{"iopub.status.busy":"2021-09-14T20:48:58.040993Z","iopub.status.idle":"2021-09-14T20:48:58.041394Z","shell.execute_reply.started":"2021-09-14T20:48:58.041177Z","shell.execute_reply":"2021-09-14T20:48:58.041198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-14T20:48:58.042794Z","iopub.status.idle":"2021-09-14T20:48:58.043203Z","shell.execute_reply.started":"2021-09-14T20:48:58.042987Z","shell.execute_reply":"2021-09-14T20:48:58.043009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2021-09-14T20:48:58.044446Z","iopub.status.idle":"2021-09-14T20:48:58.044858Z","shell.execute_reply.started":"2021-09-14T20:48:58.044634Z","shell.execute_reply":"2021-09-14T20:48:58.044669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# These checks help in identifying imbalanced datasets\ndf['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T20:48:58.046068Z","iopub.status.idle":"2021-09-14T20:48:58.046463Z","shell.execute_reply.started":"2021-09-14T20:48:58.04625Z","shell.execute_reply":"2021-09-14T20:48:58.046271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dataset is balanced!","metadata":{}},{"cell_type":"markdown","source":"### Checking the dataset for *missing* values","metadata":{}},{"cell_type":"code","source":"for col in df.columns:\n    if(df[col].isnull().sum()>0):\n        print(col)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T20:48:58.047681Z","iopub.status.idle":"2021-09-14T20:48:58.048093Z","shell.execute_reply.started":"2021-09-14T20:48:58.047866Z","shell.execute_reply":"2021-09-14T20:48:58.047887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### No missing value in dataset","metadata":{}},{"cell_type":"markdown","source":"### Checking the total number of Categorical features in dataset","metadata":{}},{"cell_type":"code","source":"for col in df.columns:\n    if(df[col].dtype=='object'):\n        print(col)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T20:48:58.049297Z","iopub.status.idle":"2021-09-14T20:48:58.049709Z","shell.execute_reply.started":"2021-09-14T20:48:58.049481Z","shell.execute_reply":"2021-09-14T20:48:58.049501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## All of the feature-columns are numeric","metadata":{}},{"cell_type":"markdown","source":"# Identifying the top-features related to our dataset","metadata":{}},{"cell_type":"code","source":"#Separating features and columns\ndf_fea=df.drop('label',axis=1)\ny=df['label']","metadata":{"execution":{"iopub.status.busy":"2021-09-14T20:48:58.050962Z","iopub.status.idle":"2021-09-14T20:48:58.051373Z","shell.execute_reply.started":"2021-09-14T20:48:58.051159Z","shell.execute_reply":"2021-09-14T20:48:58.05118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#mutual_info_classif helps in defining the % of dependence between features and target variables\nmi_score=mutual_info_classif(df_fea,y)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T20:48:58.052719Z","iopub.status.idle":"2021-09-14T20:48:58.053126Z","shell.execute_reply.started":"2021-09-14T20:48:58.052902Z","shell.execute_reply":"2021-09-14T20:48:58.052923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Converting the labels to [0,1] format\ny=pd.get_dummies(df['label'])","metadata":{"execution":{"iopub.status.busy":"2021-09-14T20:48:58.054573Z","iopub.status.idle":"2021-09-14T20:48:58.055008Z","shell.execute_reply.started":"2021-09-14T20:48:58.054783Z","shell.execute_reply":"2021-09-14T20:48:58.054804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Converting the scores to pandas-series and choosing the columns as the index of respected score\nmi_score=pd.Series(mi_score,index=df_fea.columns)\nmi_score=(mi_score*100).sort_values(ascending=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T20:48:58.056549Z","iopub.status.idle":"2021-09-14T20:48:58.056978Z","shell.execute_reply.started":"2021-09-14T20:48:58.05675Z","shell.execute_reply":"2021-09-14T20:48:58.056772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Selecting features with more than 10% MI-score","metadata":{}},{"cell_type":"code","source":"#Using the index values(column names of original dataset) to drop the columns which can interfere with the overall model\ntop_fea=mi_score[:-367].index # last 367 columns were dropped because they were only a liability for our computation power","metadata":{"execution":{"iopub.status.busy":"2021-09-14T20:48:58.058323Z","iopub.status.idle":"2021-09-14T20:48:58.058754Z","shell.execute_reply.started":"2021-09-14T20:48:58.058515Z","shell.execute_reply":"2021-09-14T20:48:58.058537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Scaling the dataset","metadata":{}},{"cell_type":"code","source":"df_sc=StandardScaler().fit_transform(df_fea[top_fea])","metadata":{"execution":{"iopub.status.busy":"2021-09-14T20:48:58.059986Z","iopub.status.idle":"2021-09-14T20:48:58.060402Z","shell.execute_reply.started":"2021-09-14T20:48:58.060184Z","shell.execute_reply":"2021-09-14T20:48:58.060205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Splitting the dataset into\n### * X_train, Y_train\n### * X_test, Y_test\n### * X_val, Y_val","metadata":{}},{"cell_type":"code","source":"Xtr,xte,Ytr,yte=train_test_split(df_sc,y,random_state=108,test_size=0.27)\nxtr,xval,ytr,yval=train_test_split(Xtr,Ytr,random_state=108,test_size=0.27)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T20:48:58.06157Z","iopub.status.idle":"2021-09-14T20:48:58.062001Z","shell.execute_reply.started":"2021-09-14T20:48:58.061773Z","shell.execute_reply":"2021-09-14T20:48:58.061794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building/Compiling/Fitting the Neural-Net to identify the emotion","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import callbacks,layers","metadata":{"execution":{"iopub.status.busy":"2021-09-14T20:48:58.063237Z","iopub.status.idle":"2021-09-14T20:48:58.063644Z","shell.execute_reply.started":"2021-09-14T20:48:58.063427Z","shell.execute_reply":"2021-09-14T20:48:58.063449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Building the model\nmodel=keras.Sequential([\n    layers.Dense(units=2181,input_shape=(2181,),activation='relu'), #using the relu activation because it is great for hidden layers\n    layers.BatchNormalization(), #BatchNormalization layer scales the dataset even further\n    layers.Dropout(0.27), #Dropping-out the nodes to make our model more general\n    layers.Dense(units=3181,activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),  \n    layers.Dense(units=4181,activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.32),  \n    layers.Dense(units=2581,activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.27),  \n    layers.Dense(units=2381,activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.32),  \n    layers.Dense(units=2181,activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.27),  \n    layers.Dense(units=3,activation='softmax') #Softmax activation helps in multiclass-identification\n])\n\n# Compiling the model\nadam=keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\nadamax=keras.optimizers.Adamax(learning_rate=0.00085, beta_1=0.9, beta_2=0.999, epsilon=1e-07) #These are just general code. you can find them easily in tensorflow API guide\n#Categorical_crossentropy will make sure if all the categories are getting identified\n#Accuracy will help in identifying if correct labels are getting picked-up\nmodel.compile(optimizer=adamax,loss='categorical_crossentropy',metrics=['accuracy'])\n\n# Fitting the model\ncall=callbacks.EarlyStopping(patience=10,min_delta=0.0001,restore_best_weights=True)\n# Defining earlystopping callback to save time.\nhistory=model.fit(xtr,ytr,validation_data=(xval,yval),batch_size=28,epochs=50,callbacks=[call])","metadata":{"execution":{"iopub.status.busy":"2021-09-14T20:48:58.06506Z","iopub.status.idle":"2021-09-14T20:48:58.065461Z","shell.execute_reply.started":"2021-09-14T20:48:58.065245Z","shell.execute_reply":"2021-09-14T20:48:58.065266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Time to *Evaluate*!","metadata":{}},{"cell_type":"code","source":"model.evaluate(xte,yte)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T20:48:58.066714Z","iopub.status.idle":"2021-09-14T20:48:58.067122Z","shell.execute_reply.started":"2021-09-14T20:48:58.066898Z","shell.execute_reply":"2021-09-14T20:48:58.066919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# More than **98%** accuracy!","metadata":{}}]}