{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b0903923e9e3a98715ee15fcfce3c69469ae3938"},"cell_type":"markdown","source":"3.CLEANING DATA\n\n\nDIAGNOSE DATA for CLEANING\n\nWe need to diagnose and clean data before exploring.\nUnclean data:\n\n   - Column name inconsistency like upper-lower case letter or space between words\n    -missing data\n    -different language\n\n\nWe will use head, tail, columns, shape and info methods to diagnose data\n"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/anime.csv\")\ndata.head() # head show first 5 row","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f302a14ebbf16f0a8d7d7cac2c4ff3f6e1187be4"},"cell_type":"code","source":"data.tail() # tail show last 5 row","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e8271c3986707e8f52ed57053dd935a3bda92864"},"cell_type":"code","source":"# columns gives column names of features\ndata.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c8f61f7e36700b13063149d61948b364580a344"},"cell_type":"code","source":"# shape gives number of rows and columns in a tuble\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"912134fb7d80f1197cb8cccefc7410ceb9b1bf0d"},"cell_type":"code","source":"# info gives data type like dataframe, number of sample or row, number of feature or column, feature types and memory usage\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cee60633917faaa11a7560ef048d5a5fd96e49d6"},"cell_type":"markdown","source":"EXPLORATORY DATA ANALYSIS\n\nvalue_counts(): Frequency counts\noutliers: the value that is considerably higher or lower from rest of the data\n\n   - Lets say value at 75% is Q3 and value at 25% is Q1.\n    -Outlier are smaller than Q1 - 1.5(Q3-Q1) and bigger than Q3 + 1.5(Q3-Q1). (Q3-Q1) = IQR\n    -We will use describe() method. Describe method includes:\n    -count: number of entries\n    -mean: average of entries\n    -std: standart deviation\n    -min: minimum entry\n    -25%: first quantile\n    -50%: median or second quantile\n    -75%: third quantile\n    -max: maximum entry\n\n\nWhat is quantile?\n\n*     1,4,5,6,8,9,11,12,13,14,15,16,17\n* \n*     The median is the number that is in middle of the sequence. In this case it would be 11.\n* \n*     The lower quartile is the median in between the smallest number and the median i.e. in between 1 and 11, which is 6.\n*     The upper quartile, you find the median between the median and the largest number i.e. between 11 and 17, which will be 14 according to the question above.\n"},{"metadata":{"trusted":true,"_uuid":"05e3f87230c1301d81fba1c039711e1e3d3f712b"},"cell_type":"code","source":"# For example lets look frequency of anime genre\ndata.genre.value_counts(dropna=False) # if there are nan values that also be counted","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d76e31413990ca483a1b411b5597ed6af3c76e3"},"cell_type":"code","source":"data.describe() #ignore null entries","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"61c68ca22fea3d68fd20c33c339bf70c24e3d2f9"},"cell_type":"markdown","source":"**CONCATENATING DATA**\n\nWe can concatenate two dataframe"},{"metadata":{"trusted":true,"_uuid":"a0620c53fe9df3d50a2a32d7a3b53fd8ab56ea17"},"cell_type":"code","source":"# This codes skipping\nfilter1 = data.type == \"Movie\"\nfilter2 = data.type == \"TV\"\ndata1 = data[filter1]\ndata2 = data [filter2]\nver_concatdata =pd.concat([data1,data2],axis=0,ignore_index=True) # axis = 0 vertial concatenating\nver_concatdata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ded548d583930dc7fbe1e6a9581601b55c66ddf3"},"cell_type":"code","source":"hor_concatdata = pd.concat([data1,data2],axis = 1) # axis = 1 horizontal concatenating\nhor_concatdata","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"08189b5787c24dcf825d5674458c618b9bf2eafd"},"cell_type":"markdown","source":"VISUAL EXPLORATORY DATA ANALYSIS\n\n    Box plots: visualize basic statistics like outliers, min/max or quantiles"},{"metadata":{"trusted":true,"_uuid":"8ab3689eacfe454ea5e2b14827945ccb85e51427"},"cell_type":"code","source":"# For example: compare attack of pokemons that are legendary  or not\n# Black line at top is max\n# Blue line at top is 75%\n# Red line is median (50%)\n# Blue line at bottom is 25%\n# Black line at bottom is min\n# There are no outliers\ncdata.boxplot(column='members',by =\"type\",figsize = (24,12))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"74112449e5d4445822629ca4396b9ae38e5fb794"},"cell_type":"markdown","source":"\n**TIDY DATA**\n\nWe tidy data with melt(). Describing melt is confusing. Therefore lets make example to understand it.\n"},{"metadata":{"trusted":true,"_uuid":"c00d787b7dd95d563f463be6d625a72c11aabd0e"},"cell_type":"code","source":"# Firstly I create new data from anime data to explain melt nore easily.\ndata_new = data.head(10)   # I only take 10 rows into new data\ndata_new","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4721107763bdf5f2c696bab7a61b81dad39ab1b2"},"cell_type":"code","source":"# lets melt\n# id_vars = what we do not wish to melt\n# value_vars = what we want to melt\nmelted = pd.melt(frame=data_new,id_vars = 'name', value_vars= ['type','episodes'])\nmelted","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4e3b1aa35c9f32e822e9d7acb515732185b8068a"},"cell_type":"markdown","source":"PIVOTING DATA\n\nReverse of melting."},{"metadata":{"trusted":true,"_uuid":"932ba779e3ba96205f8bcb35ba4768555cdb031b"},"cell_type":"code","source":"melted.pivot(index = \"name\",columns=\"variable\",values=\"value\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"83f52198612b77406652183a69e5a0ec2d2e911b"},"cell_type":"markdown","source":"DATA TYPES\n\nThere are 5 basic data types: object(string),booleab, integer, float and categorical.\nWe can make conversion data types like from str to categorical or from int to float\nWhy is category important:\n\n*     make dataframe smaller in memory\n*     can be utilized for anlaysis especially for sklear(we will learn later)\n"},{"metadata":{"trusted":true,"_uuid":"9a103a34517723367659375cd8a5ca13ddf0df59"},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec8378ec32d9352890e8a69e4d9142369dbebae7"},"cell_type":"code","source":"\n\n# lets convert object(str) to categorical and int to float.\ndata.type = data.type.astype('category')\ndata.members = data.members.astype(\"float\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af142fdc8b41e641c9d47683b4d2185957a0cbfb"},"cell_type":"code","source":"# As you can see Type 1 is converted from object to categorical\n# And Speed ,s converted from int to float\ndata.dtypes","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e497e10165cdb531f3ea798ba8db07ebf7fff2c9"},"cell_type":"markdown","source":"MISSING DATA and TESTING WITH ASSERT\n\nIf we encounter with missing data, what we can do:\n* \n*     leave as is\n*     drop them with dropna()\n*     fill missing value with fillna()\n*     fill missing values with test statistics like mean\n*     Assert statement: check that you can turn on or turn off when you are done with your testing of the program\n"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"48790f1d2ee14e985050b319b00bcf82b6afc980"},"cell_type":"code","source":"\n\n# Lets look at does pokemon data have nan value\n# As you can see there are 800 entries. However Type 2 has 414 non-null object so it has 386 null object.\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"24e0218e77745e38876fcd6d4bf11a916878cddf"},"cell_type":"code","source":"\n\n# Lets chech Type 2\ndata.genre.value_counts(dropna =False)\n# As you can see, there are 62 NAN value\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c6a6848683b08ef5eb0925008986d66824d180f2"},"cell_type":"code","source":"# Lets drop nan values\ndatax=data   # also we will use data to fill missing value so I assign it to data1 variable\ndatax.genre.dropna(inplace = True)  # inplace = True means we do not assign it to new variable. Changes automatically assigned to data\n# So does it work ?","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a13ed32029509db21653454e86db312ff1ab75a7"},"cell_type":"code","source":"#  Lets check with assert statement\n# Assert statement:\nassert 1==1 # return nothing because it is true","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b7b6db076b602a344febd23f63f39802dfdc749"},"cell_type":"code","source":"assert  datax.genre.notnull().all() # returns nothing because we drop nan values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a07d16d98f88fa9b1e5c7eebc7b9660698690994"},"cell_type":"code","source":"\n\ndatax.genre.fillna('empty',inplace = True)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"123c57b6850679a41415612b4888c7919d633428"},"cell_type":"code","source":"data.type.value_counts(dropna=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"98f77eb2fd1416365e1d8d935986a2cf310db08a"},"cell_type":"code","source":"#data.type.fillna(\"empty\",inplace = True)# give error. Because category feature is not working this metod\ndata.type = data.type.astype(\"object\")# well we convert category to object\ndata.type.fillna('empty',inplace = True)# ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b95bd067cd56b81c053b18e4ab005ccf482f660"},"cell_type":"code","source":"data.type.value_counts(dropna=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d1f5b9c609cd43b7e245092b33ca40bf0d076136"},"cell_type":"code","source":"assert  data.type.notnull().all()# returns nothing because we do not have nan values","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fdc85918092c41ad14ea7dde7a9e57a6da4a4888"},"cell_type":"markdown","source":"\nIn this part, you learn:\n\n*     Diagnose data for cleaning\n*     Exploratory data analysis\n*     Visual exploratory data analysis\n*     Tidy data\n*     Pivoting data\n*     Concatenating data\n*     Data types\n*     Missing data and testing with assert"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}