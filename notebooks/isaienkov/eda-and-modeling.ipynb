{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1><center>The Estonia Disaster Passenger List. Data analysis and modeling</center></h1>\n\n<center><img src=\"https://bb.lv/engine/client/content/articles/mega/15696046575278a5ba6e8c931c110c6cfc9923cbeb04b.jpg\"></center>\n\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport plotly.express as px\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score, recall_score, precision_score, plot_confusion_matrix, accuracy_score\n\nfrom lightgbm import LGBMClassifier\n\nimport matplotlib.pyplot as plt\n\nimport optuna\nfrom optuna.samplers import TPESampler","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data overview"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/passenger-list-for-the-estonia-ferry-disaster/estonia-passenger-list.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"NaNs percent for every column"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"for col in df.columns:\n    print(col, str(round(100* df[col].isnull().sum() / len(df), 2)) + '%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data = df['Country'].value_counts().reset_index()\n\ndata.columns = [\n    'Country', \n    'Passengers'\n]\n\nfig = px.bar(\n    data, \n    x='Country', \n    y='Passengers', \n    orientation='v', \n    title='Number of Passengers by country', \n    width=800,\n    height=600\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data = df['Sex'].value_counts().reset_index()\ndata.columns = [\n    'Sex', \n    'Passengers'\n]\n\nfig = px.pie(\n    data, \n    values='Passengers', \n    names='Sex', \n    title='Number of Passengers by gender', \n    width=500, \n    height=500\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data = df['Category'].value_counts().reset_index()\n\ndata.columns = [\n    'Category', \n    'Passengers'\n]\n\nfig = px.pie(\n    data, \n    values='Passengers', \n    names='Category', \n    title='Number of Passengers by category', \n    width=500, \n    height=500\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data = df['Survived'].value_counts().reset_index()\ndata.columns = [\n    'Survived', \n    'Passengers'\n]\n\nfig = px.pie(\n    data, \n    values='Passengers', \n    names='Survived', \n    title='Survival distribution', \n    width=500, \n    height=500\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = px.histogram(\n    df, \n    \"Age\", \n    nbins=20, \n    title='Age distribution', \n    width=800\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = px.box(\n    df, \n    x=\"Survived\", \n    y=\"Age\", \n    points='all',\n    height=600,\n    width=800,\n    title='Age & Survived box plot'\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Baseline modeling"},{"metadata":{},"cell_type":"markdown","source":"Let's build simple logistic regression model to get baseline score"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df[['Country', 'Sex', 'Age', 'Category', 'Survived']]\n\ncategorical = [\n    'Country', \n    'Sex', \n    'Category'\n]\n\nfor cat in categorical:\n    X = pd.concat([X, pd.get_dummies(X[cat], prefix=cat)], axis=1)\n    X = X.drop([cat], axis=1)\nX = X.drop(['Sex_F', 'Category_C'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"f = plt.figure(figsize=(19, 15))\nplt.matshow(X.corr(), fignum=f.number)\nplt.xticks(range(X.shape[1]), X.columns, fontsize=14, rotation=45)\nplt.yticks(range(X.shape[1]), X.columns, fontsize=14)\ncb = plt.colorbar()\ncb.ax.tick_params(labelsize=14)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in X.columns:\n    if abs(X[col].corr(X['Survived'])) < 0.1:\n        X = X.drop([col], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"y = X['Survived']\nX = X.drop(['Survived'], axis=1)\n\nX, X_test, y, y_test = train_test_split(X, y, random_state=0, test_size=0.2, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LogisticRegression(random_state=0)\nmodel.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model.predict(X_test)\n\nprint('Logistic Regression ', accuracy_score(y_test, preds))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's check a confusion matrix."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(model, X_test, y_test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that we have enough high accuracy, but model didn't classify any item from class 1. So lets use f1-score, precision and recall."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Logistic Regression f1-score', f1_score(y_test, preds))\nprint('Logistic Regression precision', precision_score(y_test, preds))\nprint('Logistic Regression recall', recall_score(y_test, preds))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's try Random Forest model with default parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = RandomForestClassifier(random_state=666)\nmodel.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"preds = model.predict(X_test)\n\nprint('Random Forest', accuracy_score(y_test, preds))\nprint('Random Forest f1-score', f1_score(y_test, preds))\nprint('Random Forest precision', precision_score(y_test, preds))\nprint('Random Forest recall', recall_score(y_test, preds))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(model, X_test, y_test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next we need to try optimize hyperparameters for models."},{"metadata":{"trusted":true},"cell_type":"code","source":"sampler = TPESampler(\n    seed=0\n)\n\ndef create_model(trial):\n    max_depth = trial.suggest_int(\"max_depth\", 2, 5)\n    n_estimators = trial.suggest_int(\"n_estimators\", 2, 200)\n    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n    model = RandomForestClassifier(\n        min_samples_leaf=min_samples_leaf, \n        n_estimators=n_estimators, \n        max_depth=max_depth, \n        random_state=0\n    )\n    return model\n\ndef objective(trial):\n    model = create_model(trial)\n    model.fit(X, y)\n    preds = model.predict(X_test)\n    score = f1_score(y_test, preds)\n    return score\n\nstudy = optuna.create_study(direction=\"maximize\", sampler=sampler)\nstudy.optimize(objective, n_trials=50)\n\nrf_params = study.best_params\nrf_params['random_state'] = 0\nrf = RandomForestClassifier(\n    **rf_params\n)\nrf.fit(X, y)\npreds = rf.predict(X_test)\n\nprint('Optimized Random Forest: ', accuracy_score(y_test, preds))\nprint('Optimized Random Forest f1-score: ', f1_score(y_test, preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(rf, X_test, y_test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}