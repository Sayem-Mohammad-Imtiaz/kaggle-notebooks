{"cells":[{"metadata":{},"cell_type":"markdown","source":"\n<h1><center>Insurance Prediction. Data analysis and modeling.</center></h1>\n\n<center><img src=\"https://www.outlookindia.com/outlookmoney/public/uploads/article/gallery/9f5518fc9b70672aaba65aa3af600c32.jpg\"></center>\n"},{"metadata":{},"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:blue; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Quick navigation</center></h2>\n\n* [1. Basic Data Analysis](#1)\n* [2. Feature engineering (In progress)](#2)\n* [3. Modeling (In progress)](#3)"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"1\"></a>\n<h2 style='background:blue; border:0; color:white'><center>1. Basic Data Analysis</center><h2>"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"!pip install pyod","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objs as go\n\nimport matplotlib.pyplot as plt\n\nimport seaborn as sns\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.cluster import KMeans\nfrom sklearn.manifold import TSNE\nfrom sklearn.model_selection import KFold, train_test_split\n\nimport optuna\nfrom optuna.samplers import TPESampler\n\nfrom pyod.models.copod import COPOD\n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.layers import Input, Dense\nfrom tensorflow.keras.utils import to_categorical\n\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/health-insurance-cross-sell-prediction/train.csv')\ntest = pd.read_csv('/kaggle/input/health-insurance-cross-sell-prediction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop(['id'], axis=1)\ntest = test.drop(['id'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = make_subplots(rows=1, cols=2)\n\ntraces = [\n    go.Bar(\n        x=['Male', 'Female'], \n        y=[\n            len(train[train['Gender']=='Male']),\n            len(train[train['Gender']=='Female'])\n        ], \n        name='Train Gender',\n        text = [\n            str(round(100 * len(train[train['Gender']=='Male']) / len(train), 2)) + '%',\n            str(round(100 * len(train[train['Gender']=='Female']) / len(train), 2)) + '%'\n        ],\n        textposition='auto'\n    ),\n    go.Bar(\n        x=['Male', 'Female'], \n        y=[\n            len(test[test['Gender']=='Male']),\n            len(test[test['Gender']=='Female'])\n        ], \n        name='Test Gender',\n        text=[\n            str(round(100 * len(test[test['Gender']=='Male']) / len(test), 2)) + '%',\n            str(round(100 * len(test[test['Gender']=='Female']) / len(test), 2)) + '%'\n        ],\n        textposition='auto'\n    ),\n\n]\n\nfor i in range(len(traces)):\n    fig.append_trace(\n        traces[i], \n        (i // 2) + 1, \n        (i % 2)  +1\n    )\n\nfig.update_layout(\n    title_text='Train/test gender column',\n    height=400,\n    width=700\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = make_subplots(rows=1, cols=2)\n\ntraces = [\n    go.Bar(\n        x=['Yes', 'No'], \n        y=[\n            len(train[train['Driving_License']==1]),\n            len(train[train['Driving_License']==0])\n        ], \n        name='Train Driving_License',\n        text = [\n            str(round(100 * len(train[train['Driving_License']==1]) / len(train), 2)) + '%',\n            str(round(100 * len(train[train['Driving_License']==0]) / len(train), 2)) + '%'\n        ],\n        textposition='auto'\n    ),\n    go.Bar(\n        x=['Yes', 'No'], \n        y=[\n            len(test[test['Driving_License']==1]),\n            len(test[test['Driving_License']==0])\n        ], \n        name='Test Driving_License',\n        text=[\n            str(round(100 * len(test[test['Driving_License']==1]) / len(test), 2)) + '%',\n            str(round(100 * len(test[test['Driving_License']==0]) / len(test), 2)) + '%'\n        ],\n        textposition='auto'\n    ),\n\n]\n\nfor i in range(len(traces)):\n    fig.append_trace(\n        traces[i], \n        (i // 2) + 1, \n        (i % 2)  + 1\n    )\n\nfig.update_layout(\n    title_text='Train/test Driving_License column',\n    height=400,\n    width=700\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = make_subplots(rows=1, cols=2)\n\ntraces = [\n    go.Bar(\n        x=['Yes', 'No'], \n        y=[\n            len(train[train['Previously_Insured']==1]),\n            len(train[train['Previously_Insured']==0])\n        ], \n        name='Train Previously_Insured',\n        text = [\n            str(round(100 * len(train[train['Previously_Insured']==1]) / len(train), 2)) + '%',\n            str(round(100 * len(train[train['Previously_Insured']==0]) / len(train), 2)) + '%'\n        ],\n        textposition='auto'\n    ),\n    go.Bar(\n        x=['Yes', 'No'], \n        y=[\n            len(test[test['Previously_Insured']==1]),\n            len(test[test['Previously_Insured']==0])\n        ], \n        name='Test Previously_Insured',\n        text = [\n            str(round(100 * len(test[test['Previously_Insured']==1]) / len(test), 2)) + '%',\n            str(round(100 * len(test[test['Previously_Insured']==0]) / len(test), 2)) + '%'\n        ],\n        textposition='auto'\n    ),\n\n]\n\nfor i in range(len(traces)):\n    fig.append_trace(\n        traces[i], \n        (i // 2) + 1, \n        (i % 2)  + 1\n    )\n\nfig.update_layout(\n    title_text='Train/test Previously_Insured column',\n    height=400,\n    width=700\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = make_subplots(rows=1, cols=2)\n\ntraces = [\n    go.Bar(\n        x=['Yes', 'No'], \n        y=[\n            len(train[train['Vehicle_Damage']=='Yes']),\n            len(train[train['Vehicle_Damage']=='No'])\n        ], \n        name='Train Vehicle_Damage',\n        text = [\n            str(round(100 * len(train[train['Vehicle_Damage']=='Yes']) / len(train), 2)) + '%',\n            str(round(100 * len(train[train['Vehicle_Damage']=='No']) / len(train), 2)) + '%'\n        ],\n        textposition='auto'\n    ),\n    go.Bar(\n        x=['Yes', 'No'], \n        y=[\n            len(test[test['Vehicle_Damage']=='Yes']),\n            len(test[test['Vehicle_Damage']=='No'])\n        ], \n        name='Test Vehicle_Damage',\n        text = [\n            str(round(100 * len(test[test['Vehicle_Damage']=='Yes']) / len(test), 2)) + '%',\n            str(round(100 * len(test[test['Vehicle_Damage']=='No']) / len(test), 2)) + '%'\n        ],\n        textposition='auto'\n    ),\n\n]\n\nfor i in range(len(traces)):\n    fig.append_trace(\n        traces[i], \n        (i // 2) + 1, \n        (i % 2)  + 1\n    )\n\nfig.update_layout(\n    title_text='Train/test Vehicle_Damage column',\n    height=400,\n    width=700\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = make_subplots(rows=1, cols=2)\n\ntraces = [\n    go.Bar(\n        x=['> 2 Years', '1-2 Year', '< 1 Year'], \n        y=[\n            len(train[train['Vehicle_Age']=='> 2 Years']),\n            len(train[train['Vehicle_Age']=='1-2 Year']),\n            len(train[train['Vehicle_Age']=='< 1 Year'])\n        ], \n        name='Train Vehicle_Age',\n        text = [\n            str(round(100 * len(train[train['Vehicle_Age']=='> 2 Years']) / len(train), 2)) + '%',\n            str(round(100 * len(train[train['Vehicle_Age']=='1-2 Year']) / len(train), 2)) + '%',\n            str(round(100 * len(train[train['Vehicle_Age']=='< 1 Year']) / len(train), 2)) + '%'\n        ],\n        textposition='auto'\n    ),\n    go.Bar(\n        x=['> 2 Years', '1-2 Year', '< 1 Year'], \n        y=[\n            len(test[test['Vehicle_Age']=='> 2 Years']),\n            len(test[test['Vehicle_Age']=='1-2 Year']),\n            len(test[test['Vehicle_Age']=='< 1 Year'])\n        ], \n        name='Test Vehicle_Age',\n        text = [\n            str(round(100 * len(test[test['Vehicle_Age']=='> 2 Years']) / len(test), 2)) + '%',\n            str(round(100 * len(test[test['Vehicle_Age']=='1-2 Year']) / len(test), 2)) + '%',\n            str(round(100 * len(test[test['Vehicle_Age']=='< 1 Year']) / len(test), 2)) + '%'\n        ],\n        textposition='auto'\n    ),\n\n]\n\nfor i in range(len(traces)):\n    fig.append_trace(\n        traces[i], \n        (i // 2) + 1, \n        (i % 2)  + 1\n    )\n\nfig.update_layout(\n    title_text='Train/test Vehicle_Age column',\n    height=400,\n    width=700\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = make_subplots(rows=1, cols=2)\n\ntraces = [\n    go.Histogram(\n        x=train['Age'], \n        name='Train Age'\n    ),\n    go.Histogram(\n        x=test['Age'], \n        name='Test Age'\n    ),\n\n]\n\nfor i in range(len(traces)):\n    fig.append_trace(\n        traces[i], \n        (i // 2) + 1, \n        (i % 2)  + 1\n    )\n\nfig.update_layout(\n    title_text='Train/test Age column distribution',\n    height=500,\n    width=900\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = make_subplots(rows=1, cols=2)\n\ntraces = [\n    go.Histogram(\n        x=train['Annual_Premium'], \n        name='Train Annual_Premium'\n    ),\n    go.Histogram(\n        x=test['Annual_Premium'], \n        name='Test Annual_Premium'\n    ),\n\n]\n\nfor i in range(len(traces)):\n    fig.append_trace(\n        traces[i], \n        (i // 2) + 1, \n        (i % 2)  + 1\n    )\n\nfig.update_layout(\n    title_text='Train/test Annual_Premium column distribution',\n    height=500,\n    width=800\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = make_subplots(rows=1, cols=2)\n\ntraces = [\n    go.Histogram(\n        x=train['Policy_Sales_Channel'], \n        name='Train Policy_Sales_Channel'\n    ),\n    go.Histogram(\n        x=test['Policy_Sales_Channel'], \n        name='Test Policy_Sales_Channel'\n    ),\n\n]\n\nfor i in range(len(traces)):\n    fig.append_trace(\n        traces[i], \n        (i // 2) + 1, \n        (i % 2)  +1\n    )\n\nfig.update_layout(\n    title_text='Train/test Policy_Sales_Channel column distribution',\n    height=500,\n    width=800\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = make_subplots(rows=1, cols=2)\n\ntraces = [\n    go.Histogram(\n        x=train['Vintage'], \n        name='Train Vintage'\n    ),\n    go.Histogram(\n        x=test['Vintage'], \n        name='Test Vintage'\n    ),\n\n]\n\nfor i in range(len(traces)):\n    fig.append_trace(\n        traces[i], \n        (i // 2) + 1, \n        (i % 2)  + 1\n    )\n\nfig.update_layout(\n    title_text='Train/test Vintage column distribution',\n    height=500,\n    width=800\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"tr = train['Region_Code'].value_counts().reset_index()\nx_tr = tr['index'].tolist()\ny_tr = tr['Region_Code'].tolist()\nte = test['Region_Code'].value_counts().reset_index()\nx_te = te['index'].tolist()\ny_te = te['Region_Code'].tolist()\n\nfig = make_subplots(rows=2, cols=1)\n\ntraces = [\n    go.Bar(\n        x=x_tr, \n        y=y_tr, \n        name='Train Region_Code'\n    ),\n    go.Bar(\n        x=x_te, \n        y=y_te, \n        name='Test Region_Code'\n    )\n]\n\nfor i in range(len(traces)):\n    fig.append_trace(\n        traces[i], \n        (i // 1) + 1, \n        (i % 1)  + 1\n    )\n\nfig.update_layout(\n    title_text='Train / test Region_Code',\n    height=900,\n    width=800\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = make_subplots(rows=1, cols=1)\n\ntraces = [\n    go.Bar(\n        x=['Yes', 'No'], \n        y=[\n            len(train[train['Response']==1]),\n            len(train[train['Response']==0])\n        ], \n        name='Train Response'\n    ),\n]\n\nfor i in range(len(traces)):\n    fig.append_trace(\n        traces[i], \n        (i // 2) + 1, \n        (i % 2)  + 1\n    )\n\nfig.update_layout(\n    title_text='Train Response column',\n    height=400,\n    width=400\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see from initial analysis all columns presented in dataset have exactly the same ditribution. Let's do feature engineering and modeling next."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = px.histogram(\n    train, \n    \"Age\", \n    color='Response',\n    nbins=100, \n    title='Age & Response ditribution', \n    width=700,\n    height=500\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = px.histogram(\n    train[train['Response'] == 1], \n    \"Age\", \n    nbins=100, \n    title='Age distribution for positive response', \n    width=700,\n    height=500\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = make_subplots(\n    rows=1, \n    cols=2\n)\n\ntraces = [\n    go.Bar(\n        x=['Declined', 'Accepted'], \n        y=[\n            len(train[(train['Gender']=='Male') & (train['Response']==0)]),\n            len(train[(train['Gender']=='Male') & (train['Response']==1)])\n        ], \n        name='Gender: Male'\n    ),\n    go.Bar(\n        x=['Declined', 'Accepted'],  \n        y=[\n            len(train[(train['Gender']=='Female') & (train['Response']==0)]),\n            len(train[(train['Gender']=='Female') & (train['Response']==1)])\n        ], \n        name='Gender: Female'\n    ),\n\n]\n\nfor i in range(len(traces)):\n    fig.append_trace(\n        traces[i], \n        (i // 2) + 1, \n        (i % 2)  + 1\n    )\n\nfig.update_layout(\n    title_text='Train gender/response dependencies',\n    height=400,\n    width=700\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = make_subplots(\n    rows=1, \n    cols=2\n)\n\ntraces = [\n    go.Bar(\n        x=['Declined', 'Accepted'], \n        y=[\n            len(train[(train['Previously_Insured']==0) & (train['Response']==0)]),\n            len(train[(train['Previously_Insured']==0) & (train['Response']==1)])\n        ], \n        name='Previously_Insured: Previously Not Insured'\n    ),\n    go.Bar(\n        x=['Declined', 'Accepted'],  \n        y=[\n            len(train[(train['Previously_Insured']==1) & (train['Response']==0)]),\n            len(train[(train['Previously_Insured']==1) & (train['Response']==1)])\n        ], \n        name='Previously_Insured: Previously Insured'\n    ),\n\n]\n\nfor i in range(len(traces)):\n    fig.append_trace(\n        traces[i], \n        (i // 2) + 1, \n        (i % 2)  + 1\n    )\n\nfig.update_layout(\n    title_text='Train previously_insured/response dependencies',\n    height=400,\n    width=700\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = make_subplots(\n    rows=1, \n    cols=2\n)\n\ntraces = [\n    go.Bar(\n        x=['Declined', 'Accepted'], \n        y=[\n            len(train[(train['Vehicle_Damage']=='No') & (train['Response']==0)]),\n            len(train[(train['Vehicle_Damage']=='No') & (train['Response']==1)])\n        ], \n        name='Vehicle_Damage: No'\n    ),\n    go.Bar(\n        x=['Declined', 'Accepted'],  \n        y=[\n            len(train[(train['Vehicle_Damage']=='Yes') & (train['Response']==0)]),\n            len(train[(train['Vehicle_Damage']=='Yes') & (train['Response']==1)])\n        ], \n        name='Vehicle_Damage: Yes'\n    ),\n\n]\n\nfor i in range(len(traces)):\n    fig.append_trace(\n        traces[i], \n        (i // 2) + 1, \n        (i % 2)  + 1\n    )\n\nfig.update_layout(\n    title_text='Train vehicle_damage/response dependencies',\n    height=400,\n    width=700\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = make_subplots(\n    rows=1, \n    cols=3\n)\n\ntraces = [\n    go.Bar(\n        x=['Declined', 'Accepted'], \n        y=[\n            len(train[(train['Vehicle_Age']=='> 2 Years') & (train['Response']==0)]),\n            len(train[(train['Vehicle_Age']=='> 2 Years') & (train['Response']==1)])\n        ], \n        name='Vehicle_Age: > 2 Years'\n    ),\n    go.Bar(\n        x=['Declined', 'Accepted'], \n        y=[\n            len(train[(train['Vehicle_Age']=='1-2 Year') & (train['Response']==0)]),\n            len(train[(train['Vehicle_Age']=='1-2 Year') & (train['Response']==1)])\n        ], \n        name='Vehicle_Age: 1-2 Year'\n    ),\n    go.Bar(\n        x=['Declined', 'Accepted'], \n        y=[\n            len(train[(train['Vehicle_Age']=='< 1 Year') & (train['Response']==0)]),\n            len(train[(train['Vehicle_Age']=='< 1 Year') & (train['Response']==1)])\n        ], \n        name='Vehicle_Age: < 1 Year'\n    ),\n\n]\n\nfor i in range(len(traces)):\n    fig.append_trace(traces[i], (i // 3) + 1, (i % 3)  +1)\n\nfig.update_layout(\n    title_text='Train/test Vehicle_Age/Response dependencies',\n    height=400,\n    width=800\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = px.histogram(\n    train, \n    \"Annual_Premium\", \n    color='Response',\n    nbins=100, \n    title='Annual_Premium & Response ditribution', \n    width=700,\n    height=500\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = px.histogram(\n    train[train['Response'] == 1], \n    \"Annual_Premium\", \n    nbins=100, \n    title='Annual_Premium distribution for positive response', \n    width=700,\n    height=500\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = px.histogram(\n    train, \n    \"Vintage\", \n    color='Response',\n    nbins=100, \n    title='Vintage & Response ditribution', \n    width=700,\n    height=500\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = px.histogram(\n    train[train['Response'] == 1], \n    \"Vintage\", \n    nbins=100, \n    title='Vintage distribution for positive response', \n    width=700,\n    height=500\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"2\"></a>\n<h2 style='background:blue; border:0; color:white'><center>2. Feature Engineering</center><h2>"},{"metadata":{},"cell_type":"markdown","source":"1) Convert columns with text values"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[train['Gender'] == 'Male', 'Gender'] = 1\ntrain.loc[train['Gender'] == 'Female', 'Gender'] = 0\ntest.loc[test['Gender'] == 'Male', 'Gender'] = 1\ntest.loc[test['Gender'] == 'Female', 'Gender'] = 0\n\ntrain.loc[train['Vehicle_Age'] == '> 2 Years', 'Vehicle_Age'] = 2\ntrain.loc[train['Vehicle_Age'] == '1-2 Year', 'Vehicle_Age'] = 1\ntrain.loc[train['Vehicle_Age'] == '< 1 Year', 'Vehicle_Age'] = 0\ntest.loc[test['Vehicle_Age'] == '> 2 Years', 'Vehicle_Age'] = 2\ntest.loc[test['Vehicle_Age'] == '1-2 Year', 'Vehicle_Age'] = 1\ntest.loc[test['Vehicle_Age'] == '< 1 Year', 'Vehicle_Age'] = 0\n\ntrain.loc[train['Vehicle_Damage'] == 'Yes', 'Vehicle_Damage'] = 1\ntrain.loc[train['Vehicle_Damage'] == 'No', 'Vehicle_Damage'] = 0\ntest.loc[test['Vehicle_Damage'] == 'Yes', 'Vehicle_Damage'] = 1\ntest.loc[test['Vehicle_Damage'] == 'No', 'Vehicle_Damage'] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in train.columns:\n    train[col] = train[col].astype(np.int32)\n\ntrain","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"f = plt.figure(\n    figsize=(13, 11)\n)\n\nplt.matshow(\n    train.corr(), \n    fignum=f.number\n)\n\nplt.xticks(\n    range(train.shape[1]), \n    train.columns, \n    fontsize=14, \n    rotation=75\n)\n\nplt.yticks(\n    range(train.shape[1]), \n    train.columns, \n    fontsize=14\n)\n\ncb = plt.colorbar()\n\ncb.ax.tick_params(\n    labelsize=14\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Correlation for every feature with target"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in train.columns:\n    if col == 'Response':\n        continue\n    print(col, train[col].corr(train['Response']))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = px.scatter(\n    train, \n    x=\"Annual_Premium\", \n    y=\"Age\", \n    color=\"Response\",\n    width=600,\n    height=600,\n    title='Annual_premium vs Age scatter'\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"3\"></a>\n<h2 style='background:blue; border:0; color:white'><center>3. Modeling</center><h2>"},{"metadata":{},"cell_type":"markdown","source":"Let's try unsupervised learning first. We will us kmeans clustering algorithm to check scores."},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.drop(['Response'], axis=1)\ny = train['Response']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans = KMeans(\n    n_clusters=2, \n    random_state=666\n).fit(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['cluster'] = kmeans.labels_\ntrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['cluster'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Kmeans accuracy: ', accuracy_score(train['Response'], train['cluster']))\nprint('Kmeans f1_score: ', f1_score(train['Response'], train['cluster']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's try to use COPOD anomaly detection model and check results"},{"metadata":{"trusted":true},"cell_type":"code","source":"response = train['Response']\ntrain = train.drop(['Response', 'cluster'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = COPOD(\n    contamination=0.15\n)\nclf.fit(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cluster = clf.predict(train)\ntrain['cluster'] = cluster\ntrain['Response'] = response\ntrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['cluster'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('COPOD accuracy: ', accuracy_score(train['Response'], train['cluster']))\nprint('COPOD f1_score: ', f1_score(train['Response'], train['cluster']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's build our first version of classifier and use Logistic Regression"},{"metadata":{},"cell_type":"markdown","source":"Now we will create validation set"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=666)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Positive cases % in validation set: ', round(100 * len(y_test[y_test == 1]) / len(y_test), 3), '%')\nprint('Positive cases % in train set: ', round(100 * len(y_train[y_train == 1]) / len(y_train), 3), '%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So we can see that our sets are well balanced by target column and we can use our validation set for testing."},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"model = LogisticRegression(random_state=666)\nmodel.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model.predict(X_test)\nprint('Simple Logistic Regression accuracy: ', accuracy_score(y_test, preds))\nprint('Simple Logistic Regression f1_score: ', f1_score(y_test, preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_confusion_matrix(y_real, y_pred):\n    cm = confusion_matrix(y_real, y_pred)\n\n    ax= plt.subplot()\n    sns.heatmap(cm, annot=True, ax = ax, fmt='g')\n\n    ax.set_xlabel('Predicted labels')\n    ax.set_ylabel('True labels')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(y_test, preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train.drop(['Region_Code', 'Vintage', 'Driving_License'], axis=1)\nX_test = X_test.drop(['Region_Code', 'Vintage', 'Driving_License'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LogisticRegression(random_state=666)\nmodel.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model.predict(X_test)\nprint('Simple Logistic Regression accuracy: ', accuracy_score(y_test, preds))\nprint('Simple Logistic Regression f1_score: ', f1_score(y_test, preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(y_test, preds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### After removing some columns predictions become better but still not good."},{"metadata":{},"cell_type":"markdown","source":"#### Let's build LightGBM with default parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LGBMClassifier(random_state=666)\nmodel.fit(X_train, y_train)\n\npreds = model.predict(X_test)\nprint('Simple LGBM accuracy: ', accuracy_score(y_test, preds))\nprint('Simple LGBM Regression f1_score: ', f1_score(y_test, preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(666)\nsampler = TPESampler(seed=0)\n\ndef create_model(trial):\n    max_depth = trial.suggest_int(\"max_depth\", 2, 20)\n    n_estimators = trial.suggest_int(\"n_estimators\", 1, 400)\n    learning_rate = trial.suggest_uniform('learning_rate', 0.0000001, 1)\n    gamma = trial.suggest_uniform('gamma', 0.0000001, 1)\n    scale_pos_weight = trial.suggest_int(\"scale_pos_weight\", 1, 20)\n    model = XGBClassifier(\n        learning_rate=learning_rate, \n        n_estimators=n_estimators, \n        max_depth=max_depth, \n        gamma=gamma, \n        scale_pos_weight=scale_pos_weight, \n        random_state=0\n    )\n    return model\n\ndef objective(trial):\n    model = create_model(trial)\n    model.fit(X_train, y_train)\n    preds = model.predict(X_test)\n    score = f1_score(y_test, preds)\n    return score\n\n#study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n#study.optimize(objective, n_trials=500)\n\n#xgb_params = study.best_params\nxgb_params = {\n    'max_depth': 4, \n    'n_estimators': 372, \n    'learning_rate': 0.09345905554110154, \n    'gamma': 0.6641238000625036, \n    'scale_pos_weight': 4\n}\nxgb_params['random_state'] = 0\nxgb = XGBClassifier(**xgb_params)\nxgb.fit(X_train, y_train)\npreds = xgb.predict(X_test)\nprint('Optimized XGBClassifier accuracy: ', accuracy_score(y_test, preds))\nprint('Optimized XGBClassifier f1-score', f1_score(y_test, preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(y_test, preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model(trial):\n    max_depth = trial.suggest_int(\"max_depth\", 2, 7)\n    n_estimators = trial.suggest_int(\"n_estimators\", 2, 200)\n    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n    model = RandomForestClassifier(\n        min_samples_leaf=min_samples_leaf, \n        n_estimators=n_estimators, \n        max_depth=max_depth, \n        random_state=0\n    )\n    return model\n\ndef objective(trial):\n    model = create_model(trial)\n    model.fit(X_train, y_train)\n    preds = model.predict(X_test)\n    score = f1_score(y_test, preds)\n    return score\n\nstudy = optuna.create_study(direction=\"maximize\", sampler=sampler)\nstudy.optimize(objective, n_trials=100)\nrf_params = study.best_params\nrf = RandomForestClassifier(**rf_params)\nrf.fit(X_train, y_train)\npreds = rf.predict(X_test)\nprint('Optimized RF accuracy: ', accuracy_score(y_test, preds))\nprint('Optimized RF f1-score:', f1_score(y_test, preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(y_test, preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def recall_score(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives / (possible_positives + K.epsilon())\n    return recall\n\ndef precision_score(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    return precision\n\ndef keras_f1_score(y_true, y_pred):\n    precision = precision_score(y_true, y_pred)\n    recall = recall_score(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model():\n    model = tf.keras.Sequential([\n        tf.keras.layers.Input(7),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dense(30, activation=\"relu\"),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.3),\n        tf.keras.layers.Dense(2, activation='softmax')\n    ])\n    model.compile(\n        loss=tf.keras.losses.binary_crossentropy, \n        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n        metrics=[keras_f1_score]\n    )\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_nn_train = to_categorical(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_weight = {\n    0: 1.,\n    1: 8.\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = create_model()\nmodel.fit(X_train, y_nn_train, validation_split=0.2, epochs=35, batch_size=256, verbose=2, class_weight=class_weight)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model.predict(X_test)\npreds = np.argmax(preds, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('NN accuracy: ', accuracy_score(y_test, preds))\nprint('NN f1-score', f1_score(y_test, preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(y_test, preds)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}