{"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python","mimetype":"text/x-python","pygments_lexer":"ipython3","name":"python","file_extension":".py","version":"3.6.1"},"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"}},"nbformat":4,"nbformat_minor":0,"cells":[{"metadata":{"_uuid":"e3d80b7ef2340a24ca667c8e6024fb1d7a5c3c08","trusted":false,"_cell_guid":"b5660c22-fa0d-4950-9bcb-be0adc81172c","_execution_state":"idle"},"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom keras.utils.np_utils import to_categorical\nfrom keras.callbacks import Callback\nfrom keras.callbacks import EarlyStopping\n\nimport pandas as pd\nimport os\nimport numpy as np\nimport pdb\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","outputs":[],"cell_type":"code","execution_count":1},{"metadata":{"_uuid":"8a53310aa811f473c3090c3aa87c3fd7190ec7a9","collapsed":false,"_execution_state":"idle"},"source":"INBOUND_DATA_FOLDER = \"../input\"\nDATASET_FILENAME = \"adult-training.csv\"","outputs":[],"execution_count":null,"cell_type":"code"},{"metadata":{"_uuid":"6d620066bee9f829be57c751b71af6d3608206b1","collapsed":false,"_execution_state":"idle"},"source":"df_train = pd.read_csv(os.path.join(INBOUND_DATA_FOLDER, DATASET_FILENAME), header=None)\ndf_test = pd.read_csv(os.path.join(INBOUND_DATA_FOLDER, \"adult-test.csv\"), header=None, skiprows=[0])\n\ncols = [\n    'age',\n    'workclass',\n    'fnlwgt',\n    'education',\n    'education-num',\n    'marital-status',\n    'occupation',\n    'relationship',\n    'race',\n    'sex',\n    'capital-gain',\n    'capital-loss',\n    'hours-per-week',\n    'native-country',\n    'label']\n\ndf_train.columns = cols\ndf_test.columns = cols\n\n\nreplacer = {\" <=50K\": 0, \" >50K\" : 1, \" <=50K.\": 0, \" >50K.\" : 1}\ndf_train.label = df_train.label.replace(replacer)\ndf_test.label = df_test.label.replace(replacer)\n\ntrain_labels = df_train.label.fillna(df_train.label.mode()[0])\ntest_labels = df_test.label.fillna(train_labels.mode()[0])\n\ndf_train = df_train.drop(\"label\", axis=1)\ndf_test = df_test.drop(\"label\", axis=1)\n\n\n\ntrain_rows = df_train.shape[0]\n\n# merge dataframes\ndf = pd.concat([df_train, df_test], axis=0)\n\n# drop redundant columns\ndf = df.drop(\"education\", axis=1)\ndf = df.drop(\"fnlwgt\", axis=1)\n\n# replace ? with NaN\ndf = df.replace(\"?\", value=np.nan)\n\n# Impute columns by using fillna\nmode_columns = [\"workclass\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native-country\"]\nmedian_columns = [\"age\", \"education-num\", \"capital-gain\", \"capital-loss\"]\nmean_columns = [\"hours-per-week\"]\n\nfor mode_column in mode_columns:\n    df[mode_column] = df[mode_column].fillna(df[mode_column].mode()[0])\nfor median_column in median_columns:\n    df[median_column] = df[median_column].fillna(df[median_column].median())\nfor mean_column in mean_columns:\n    df[mean_column] = df[mean_column].fillna(df[mean_column].mean())\n\n# One hot encode\nencoded = pd.get_dummies(df)\n\n# unmerge train and test dataframes\ndf_train = encoded.iloc[:train_rows, :]\ndf_test = encoded.iloc[train_rows:, :]\n\n# reappend label column to train\ndf_train = pd.concat([train_labels, df_train], axis=1)\ndf_test = pd.concat([test_labels, df_test], axis=1)\n\n\n# Extract values\ntrain = df_train.values\ntest = df_test.values","outputs":[],"execution_count":null,"cell_type":"code"},{"metadata":{"_uuid":"2269808e32732aa874188896b62b2104f61a0edd","collapsed":false,"_execution_state":"idle"},"source":"X_train = train[:, 1:]\ny_train = train[:, 0]\n\nX_test = test[:, 1:]\ny_test = test[:, 0]\n\n# scaling features\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)","outputs":[],"execution_count":null,"cell_type":"code"},{"metadata":{"_uuid":"814c8ced356deeeba665d259e9c89a0c0c394265","collapsed":false,"_execution_state":"idle"},"source":"# Deep neural net\ndef create_model():\n    model = Sequential()\n    model.add(Dense(200,\n                    input_dim=X_train.shape[1],\n                    activation=\"relu\"))\n    model.add(Dense(100,\n                    activation=\"relu\"))\n    model.add(Dense(2, activation=\"softmax\"))\n\n    # Compile model\n    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n    return model\n","outputs":[],"execution_count":null,"cell_type":"code"},{"metadata":{"_uuid":"f825e4816429cc7f378e635f80580a0eff0c1b00","collapsed":false,"_execution_state":"idle"},"source":"estimator = KerasClassifier(create_model, epochs=10, batch_size=40, verbose=False)\n\nY_train = to_categorical(y_train)\nY_test = to_categorical(y_test)\n\nresults = estimator.fit(X_train, Y_train, validation_data=(X_test, Y_test))\nprint(\"Score: {}\".format(estimator.score(X_test, Y_test)))","outputs":[],"execution_count":null,"cell_type":"code"},{"metadata":{"_uuid":"c13e2c5315f1438a85c1d8bfe0174142ef5c298b","collapsed":false,"_execution_state":"idle"},"source":"","outputs":[],"execution_count":null,"cell_type":"code"}]}