{"cells":[{"metadata":{},"cell_type":"markdown","source":"This will be one of my first projects, in this project, I aim to create a model that will detect whether mushrooms are poisonous or not.\n\nI will use accuracy scoring,grid search, cross-validation and most of the classification models, and create an ensembled model.\n\nSince I am a newbie in this field, I will have mistakes and shortcomings, so I ask you to indicate the places that you see incorrect or missing in the comments :)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load and Check Data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"../input/mushroom-classification/mushrooms.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All variables are categorical variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"class\"].replace([\"p\",\"e\"],[1,0],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I marked poisonous ones as 1 in order to make achieve my goal by using recall scoring."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is no missing value so it's good for us. We don't have to spend effort on this and since all of them categorical we don't have any outliers."},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Categorical Data Analysis with Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(\"class\",data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The number of both classes is about the same, but edible ones are slightly more."},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in [ 'cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor',\n       'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color',\n       'stalk-shape', 'stalk-root', 'stalk-surface-above-ring',\n       'stalk-surface-below-ring', 'stalk-color-above-ring',\n       'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number',\n       'ring-type', 'spore-print-color', 'population', 'habitat']:\n    \n    plt.subplots()\n    sns.countplot(x=i,hue=\"class\",data=df,order = df[i].value_counts().index,palette=['green',\"red\"])\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see some variables are similar and some of are not correlated much with target like gill-attachment and veil-type. these two variables does not give information about target so we can drop them."},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Check and Drop Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\nsns.countplot(x=\"class\",data=df)\nplt.figure()\nsns.countplot(x=\"veil-type\",hue=\"class\",data=df,order = df[\"veil-type\"].value_counts().index,palette=['green',\"red\"])\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see veil-type's behavior does not give information about class so we can drop it."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop([\"veil-type\"],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\nsns.countplot(x=\"class\",data=df)\nplt.figure()\nsns.countplot(x=\"gill-attachment\",hue=\"class\",data=df,order = df[\"gill-attachment\"].value_counts().index,palette=['green',\"red\"])\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And gill-attachment's behavior is similar to veil-type's one and it does not give information so we can drop it too."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop([\"gill-attachment\"],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\nsns.countplot(x=\"odor\",hue=\"class\",data=df,order = df[\"odor\"].value_counts().index,palette=['green',\"red\"])\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see odor variable is highly correlated with class so it can cause data leakage. Maybe odor name named after class name so it will be better if we drop that variable in order to prevent data leakage."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop([\"odor\"],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=pd.get_dummies(df,columns=['cap-shape', 'cap-surface', 'cap-color', 'bruises',\n       'gill-spacing', 'gill-size', 'gill-color', 'stalk-shape', 'stalk-root',\n       'stalk-surface-above-ring', 'stalk-surface-below-ring',\n       'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-color',\n       'ring-number', 'ring-type', 'spore-print-color', 'population',\n       'habitat']).drop(\"class\",axis=1)\ny=df[\"class\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since all of my variables are categorical I changed every x variable to make suitable for my model."},{"metadata":{},"cell_type":"markdown","source":"# Train Test Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.25,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelling"},{"metadata":{},"cell_type":"markdown","source":"-I will use DecisionTreeClassifier,SVC,RandomForestClassifier, LogisticRegression,KNeighborsClassifier\n\n-I want to create a model that detects all poisonous mushrooms since no one would eat them.  I will use \"Recall Scoring\" because  I labelled poisonous mushrooms \"1\" and I want my model to detect all of the positive labels. That's why I will use \"Recall Scoring\".\n\n-I will use GridSearch to find the best parameters for all of the classifiers.\n\n-I will score them by using cross-validation.\n\n-I will find the best 3 or 4 models and I will create an ensembled model then I will finish."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler,StandardScaler,QuantileTransformer\nfrom sklearn.model_selection import GridSearchCV, cross_val_score,StratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score, recall_score,f1_score\nfrom sklearn.metrics import confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Confusion_Matrices=[]\nClassifiers=[]\nScores=[]\nBest_Parameters=[]\nCross_Val_Test_Scores=[]\nrandom_state=42","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt_param_grid = {\"min_samples_split\" : range(20,400,20),\n                \"max_depth\": range(2,18,2)}\n\n\nclf=GridSearchCV(DecisionTreeClassifier(random_state = random_state),param_grid=dt_param_grid,cv=StratifiedKFold(n_splits = 5),scoring=\"accuracy\")\nclf.fit(x_train,y_train)\nScores.append(clf.best_score_)\nConfusion_Matrices.append(confusion_matrix(y_test, clf.predict(x_test)))\nClassifiers.append(\"Decision Tree\")\nCross_Val_Test_Scores.append(cross_val_score(clf, x_test, y_test,scoring=\"accuracy\", cv=5).mean())\nBest_Parameters.append(clf.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svc_param_grid = {\"kernel\" : [\"rbf\"],\n                 \"gamma\": [0.001, 0.01, 0.1, 1],\n                 \"C\": [1,10,50,100,200,1000]}\n\n\n\nclf=GridSearchCV(SVC(random_state = random_state),param_grid=svc_param_grid,cv=StratifiedKFold(n_splits = 5),scoring=\"accuracy\")\nclf.fit(x_train,y_train)\nScores.append(clf.best_score_)\nConfusion_Matrices.append(confusion_matrix(y_test, clf.predict(x_test)))\nClassifiers.append(\"SVC\")\nCross_Val_Test_Scores.append(cross_val_score(clf, x_test, y_test,scoring=\"accuracy\", cv=5).mean())\nBest_Parameters.append(clf.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_param_grid = {\"max_features\": [1,3,10],\n                \"min_samples_split\":[2,3,10],\n                \"min_samples_leaf\":[1,3,10],\n                \"bootstrap\":[False],\n                \"n_estimators\":[100,300],\n                \"criterion\":[\"gini\"]}\n\n\n\nclf=GridSearchCV(RandomForestClassifier(random_state = random_state),param_grid=rf_param_grid,cv=StratifiedKFold(n_splits = 5),scoring=\"accuracy\")\nclf.fit(x_train,y_train)\nScores.append(clf.best_score_)\nConfusion_Matrices.append(confusion_matrix(y_test, clf.predict(x_test)))\nClassifiers.append(\"Random Forest\")\nCross_Val_Test_Scores.append(cross_val_score(clf, x_test, y_test,scoring=\"accuracy\", cv=5).mean())\nBest_Parameters.append(clf.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg_param_grid = {\"C\":np.logspace(-3,3,7)}\nclf=GridSearchCV(LogisticRegression(random_state = random_state),param_grid=logreg_param_grid,cv=StratifiedKFold(n_splits = 5),scoring=\"accuracy\")\nclf.fit(x_train,y_train)\nScores.append(clf.best_score_)\nConfusion_Matrices.append(confusion_matrix(y_test, clf.predict(x_test)))\nClassifiers.append(\"Logistic Regression\")\nCross_Val_Test_Scores.append(cross_val_score(clf, x_test, y_test,scoring=\"accuracy\", cv=5).mean())\nBest_Parameters.append(clf.best_estimator_)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_param_grid = {\"n_neighbors\": np.linspace(1,19,10, dtype = int).tolist(),\n                 \"weights\": [\"uniform\",\"distance\"],\n                 \"metric\":[\"euclidean\",\"manhattan\"]}\n\nclf=GridSearchCV(KNeighborsClassifier(),param_grid=knn_param_grid,cv=StratifiedKFold(n_splits = 5),scoring=\"accuracy\")\nclf.fit(x_train,y_train)\nScores.append(clf.best_score_)\nConfusion_Matrices.append(confusion_matrix(y_test, clf.predict(x_test)))\nClassifiers.append(\"KNN\")\nCross_Val_Test_Scores.append(cross_val_score(clf, x_test, y_test,scoring=\"accuracy\", cv=5).mean())\nBest_Parameters.append(clf.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"graph_data= pd.DataFrame(list(zip(Classifiers,Cross_Val_Test_Scores)),columns =['Classifiers', 'Cross_Val_Test_Scores']) \ngraph_data=graph_data.sort_values(\"Cross_Val_Test_Scores\",ascending=False)\nstandartscaler=QuantileTransformer()\ngraph_data[\"Scaled Scores\"]=standartscaler.fit_transform(graph_data[\"Cross_Val_Test_Scores\"].values.reshape(-1,1))\nplt.figure(figsize=(16,8))\nsns.barplot(x=graph_data[\"Classifiers\"],y=graph_data[\"Scaled Scores\"])\nplt.title(\"Scores with scaled data\")\nplt.figure(figsize=(16,8))\nsns.barplot(x=graph_data[\"Classifiers\"],y=graph_data['Cross_Val_Test_Scores'])\nplt.title(\"Scores with real data\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"graph_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All of models that I used with their best parameters gave more than 99% accuracy. But still I will use an ensemble model for both creating a better model and avoid overfitting as much as possible."},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(Cross_Val_Test_Scores)):\n    plt.subplots()\n    sns.heatmap(Confusion_Matrices[i],annot=True,fmt='d')\n    plt.title(\"Confusion Matrix of {}\".format(Classifiers[i]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Still I cannot see any problem from any of the models."},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Ensemble Modelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"votingC = VotingClassifier(estimators = [(\"knn\",Best_Parameters[4]),\n                                        (\"lr\",Best_Parameters[3]),\n                                        (\"rf\",Best_Parameters[2])],\n                                        voting = \"soft\", n_jobs = -1)\nvotingC = votingC.fit(x_train, y_train)\nprint(accuracy_score(votingC.predict(x_test),y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"At the end we created a model that has 100% accuracy."},{"metadata":{},"cell_type":"markdown","source":"I hope you liked it, please do not forget to mention the wrong and missing places in the comments."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}