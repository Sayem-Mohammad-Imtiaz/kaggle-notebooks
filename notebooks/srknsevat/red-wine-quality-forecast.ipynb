{"cells":[{"metadata":{},"cell_type":"markdown","source":"<font size=12 color=\"black\" face=\"verdana\"><center> **Red Wine Quality Forecast**"},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://storage.googleapis.com/kaggle-datasets-images/4458/6836/30587db9a40233164f65a4a3f148f40d/dataset-cover.jpg?t=2017-11-12-14-28-34\" alt=\"Girl in a jacket\" style=\"width:1448px;height:200px;\">\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"0.\"></a>\n<font size=10  color=\"black\" face=\"verdana\"  ><center> **Contents** </center>\n    <h2>\n        <h2>\n<font size=6 color=\"black\" face=\"verdana\"  >[1. Summary of Work](#1.)\n    <h2>\n        <h2>\n<font size=6 color=\"black\" face=\"verdana\" >[1.1. Inclusion of Required Libraries in Development Environment](#1.1.)\n    <h2>\n        <h2>\n<font size=6 color=\"black\" face=\"verdana\" >[2. Importing to the Data Set](# 2.)\n    <h2>\n        <h2>\n<font size=6 color=\"black\" face=\"verdana\"  >[3. Technical Evaluation About the Data Set](#3.)\n    <h2>\n        <h2>\n<font size=6 color=\"black\" face=\"verdana\"  >[4. Visualization of the Data Set](#4.)\n    <h2>\n        <h2>\n<font size=6 color=\"black\" face=\"verdana\"  >[5. Applying Machine Learning Algorithms](#5.)\n    <h2>\n        <h2>\n<font size=6 color=\"black\" face=\"verdana\"  >[6. Model Selection](#6.)\n    <h2>\n        <h2>\n<font size=6 color=\"black\" face=\"verdana\" >[7. Implementing Clustering Algorithms](#7.)\n    <h2>\n        <h2>"},{"metadata":{},"cell_type":"markdown","source":"[Contents](#0.)\n\n# <a class=\"anchor\" id=\"1.\"></a>**1. Summary of Work**"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"<font size = 5 color = \"black\" face = \"verdana\"> Prepared for the data set of the study using the Red Wine Quality dataset from kaggle.com.\n\n<font size = 5 color = \"black\" face = \"verdana\"> This data set was arranged as shown below, chemicals affecting the quality of the wine were analyzed and the quality value was estimated. In this estimate, the models with the highest ratio were selected by trying various models.\n\n<font size = 5 color = \"black\" face = \"verdana\"> The data set was first analyzed using the numpy and pandas libraries, data distributions were examined, and the changes in features were observed with the group by method. Later, data visualizations were made using Seaborn and Matplotlib Libraries and the correlations between the variables were visually examined.\n\n<font size = 5 color = \"black\" face = \"verdana\"> In order to use Machine Learning algorithms, the quality variable dependent variable, which is among the data variables, has been accepted and a model has been created to estimate this value. By choosing the model with the highest accuracy among the created models, it was tried to reach higher accuracy on this model.\n\n<font size = 5 color = \"black\" face = \"verdana\"> In order to use the Logistic Regression Classification model, we tried to estimate the status of our data as 1 or 0 by accepting our dependent variable as 1 for values ​​above 5 and 0 for others.\n\n<font size = 5 color = \"black\" face = \"verdana\"> We applied Clustering models to observe how our data is distributed in order to observe how our data is distributed after these model applications."},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"1.1.\"></a>**1.1. Inclusion of Required Libraries in Development Environment**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Veri tanımlama\nimport numpy as np \nimport pandas as pd \n\n# Veri Görselleştirme\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom plotly.offline import init_notebook_mode, iplot, plot\nimport plotly as py\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\n#Sistem kütüphaneleri\nimport os\nimport warnings\n\n# Çıktılarda karmaşıklığa sebep olduğu için uyarılırı iptal ediyoruz\nwarnings.filterwarnings(\"ignore\")\nprint(\"Warnings Ignore\")\n\nprint(os.listdir(\"../\"))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir(\"../input/red-wine-quality-cortez-et-al-2009\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[Contents](#0.)\n# <a class=\"anchor\" id=\"2.\"></a>**2. Importing to the Data Set**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/red-wine-quality-cortez-et-al-2009/winequality-red.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[Contents](#0.)\n\n* # <a class=\"anchor\" id=\"3.\"></a>**3. Technical Evaluation About the Data Set** "},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.quality.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.quality.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby([\"quality\"], as_index = True).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndata[\"status\"] = data.quality.apply(lambda x: \"Good\" if x > 5 else \"Bad\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[Contents](#0.)\n\n# <a class=\"anchor\" id=\"4.\"></a>**4. Visualization of the Data Set**  "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (8,8))\nlabels = data.status.value_counts().index\nplt.pie(data.status.value_counts(), autopct='%1.1f%%', pctdistance=0.8, textprops={'size':\"30\", 'color':\"w\"},\n        shadow=True, startangle=360)\nplt.legend(labels, title=\"Status\", loc=\"center left\", bbox_to_anchor=(1, 0, 0.5, 1), fontsize=16)\nplt.axis('equal')\nplt.title('QUALİTY', fontsize=32)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = list(data.columns)\nfor i in x:\n    data.plot(kind='scatter', x=i, y='quality',alpha = 0.5,color =\"red\" )   \n    plt.title('Scatter Plot')          \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#correlation matrix\nplt.figure(figsize=(10,5))\nheatmap = sns.heatmap(data.corr(), annot=True, fmt=\".1f\")\nheatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\nheatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_sns = ['residual sugar', 'chlorides', 'density', 'pH', 'alcohol', 'quality']\nsns.set(style=\"ticks\")\nsns.pairplot(data[cols_sns], hue='quality')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='quality', data=data)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[Contents](#0.)\n\n# <a class=\"anchor\" id=\"5.\" ></a>**5. Applying Machine Learning Algorithms**"},{"metadata":{},"cell_type":"markdown","source":"1. Decision Tree\n2. Random Forest\n3. KNeighbors\n4. GaussianNB\n5. SVC"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = data.drop(['quality','status'], axis =1)\ny = data['quality'] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()  \n\nx = scaler.fit_transform(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\"></a>**Decision Tree Classification**"},{"metadata":{"trusted":true},"cell_type":"code","source":"decision_tree = DecisionTreeClassifier()\ndecision_tree.fit(x_train,y_train)\ntree_pred = decision_tree.predict(x_test)\nprint('Decision Tree:', accuracy_score(y_test, tree_pred)*100,'%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\"></a>**Random Forest Classification**"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier()\nrf.fit(x_train,y_train)\nrf_pred = rf.predict(x_test)\nprint('Random Forest:', accuracy_score(y_test, rf_pred)*100,'%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\"></a>**K-Nearest Neighbour (KNN) Classification**"},{"metadata":{"trusted":true},"cell_type":"code","source":"KN = KNeighborsClassifier()\nKN.fit(x_train,y_train)\nKN_pred = KN.predict(x_test)\nprint('KNeighbors:',accuracy_score(y_test, KN_pred)*100,'%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\"></a>**Gaussian Classification**"},{"metadata":{"trusted":true},"cell_type":"code","source":"Gaussian = GaussianNB()\nGaussian.fit(x_train,y_train)\nGaussian_pred = Gaussian.predict(x_test)\nprint('GaussianNB:',accuracy_score(y_test, Gaussian_pred)*100,'%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\"></a>**SVC Classification**"},{"metadata":{"trusted":true},"cell_type":"code","source":"svc = SVC()\nsvc.fit(x_train,y_train)\nsvc_pred = svc.predict(x_test)\nprint('SVC:',accuracy_score(y_test, svc_pred)*100,'%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[Contents](#0.)\n\n# <a class=\"anchor\" id=\"6.\"></a>**6. Model Selection**"},{"metadata":{},"cell_type":"markdown","source":"The Highest Accuracy Random Forest model was selection."},{"metadata":{"trusted":true},"cell_type":"code","source":"k = []\nl = []\nfor i in range(1,250):\n    rf_tune = RandomForestClassifier(n_estimators=i)\n    rf_tune.fit(x_train,y_train)\n    y_pred = rf_tune.predict(x_test)\n    k.append(float(accuracy_score(y_test, y_pred)*100))\n    l.append(i)\n    \nk = pd.DataFrame(k , columns=['Accuracy']) \nl = pd.DataFrame(l , columns=['n_estimator'])\ndf = pd.concat([k, l], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.sort_values(by='Accuracy', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\"></a>**Principal Component Analysis (PCA)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\npca = PCA(n_components = 3, whiten= True )  # whitten = normalize\npca.fit(x)\n\nx_pca = pca.transform(x)\n\nprint(\"variance ratio: \", pca.explained_variance_ratio_)\n\nprint(\"sum: \",sum(pca.explained_variance_ratio_))\n\n#%%","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x_pca, y, test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k = []\nl = []\nfor i in range(1,250):\n    rf_tune = RandomForestClassifier(n_estimators=i)\n    rf_tune.fit(x_train,y_train)\n    y_pred = rf_tune.predict(x_test)\n    k.append(float(accuracy_score(y_test, y_pred)*100))\n    l.append(i)\n    \nk = pd.DataFrame(k , columns=['Accuracy']) \nl = pd.DataFrame(l , columns=['n_estimator'])\ndf = pd.concat([k, l], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.sort_values(by='Accuracy', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = data.drop(['fixed acidity','citric acid','free sulfur dioxide','total sulfur dioxide','pH','quality', 'status'], axis =1)\ny = data['quality'] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k = []\nl = []\nfor i in range(1,250):\n    rf_tune = RandomForestClassifier(n_estimators=i)\n    rf_tune.fit(x_train,y_train)\n    y_pred = rf_tune.predict(x_test)\n    k.append(float(accuracy_score(y_test, y_pred)*100))\n    l.append(i)\n    \nk = pd.DataFrame(k , columns=['Accuracy']) \nl = pd.DataFrame(l , columns=['n_estimator'])\ndf = pd.concat([k, l], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.sort_values(by='Accuracy', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\"></a>**Logistic Regression Classification**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"status\"] = data.quality.apply(lambda x: 1 if x > 5 else 0)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = data.drop(['quality','status' ,'fixed acidity','residual sugar','free sulfur dioxide','pH'], axis =1)\ny = data['status']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nlr.fit(x_train,y_train)\nprint(\"test accuracy {}\".format(lr.score(x_test,y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#%%\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\n\ny_tahmin = lr.predict(x_test)\nresults = confusion_matrix(y_tahmin, y_test)\nprint(\"Confusion Matrix : \")\nprint(results)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[Contents](#0.)\n\n# <a class=\"anchor\" id=\"7.\"></a>**7.  Implementing Clustering Algorithms**"},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\"></a>**K-Means Clustering**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_cls = data.drop(['quality','status'], axis =1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\nwcss = []\n\nfor k in range(1,15):\n    kmeans = KMeans(n_clusters=k)\n    kmeans.fit(data_cls)\n    wcss.append(kmeans.inertia_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nplt.plot(range(1,15),wcss)\nplt.xlabel(\"number of k (cluster) value\" , fontsize=26)\nplt.ylabel(\"Within Cluster Sum of Squares\" , fontsize=26)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans2 = KMeans(n_clusters=3)\nclusters= kmeans2.fit_predict(data_cls)\ndata_cls[\"label\"] = clusters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_cls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\npca = PCA(n_components =2 , whiten= True )  # whitten = normalize\npca.fit(data_cls)\n\nscatter =pd.DataFrame(pca.transform(data_cls))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scatter[\"label\"] = clusters\n\nplt.scatter(scatter[0][scatter.label == 0 ],scatter[1][scatter.label == 0],color = \"red\")\nplt.scatter(scatter[0][scatter.label == 1 ],scatter[1][scatter.label == 1],color = \"green\")\nplt.scatter(scatter[0][scatter.label == 2 ],scatter[1][scatter.label == 2],color = \"blue\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}