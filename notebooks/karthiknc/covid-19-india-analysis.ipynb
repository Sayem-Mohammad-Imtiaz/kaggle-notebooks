{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline \n\nfrom scipy import stats\nfrom math import sqrt\nimport statsmodels.api as sm\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LogisticRegression,LinearRegression\nfrom random import sample\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error,confusion_matrix,classification_report,roc_curve,auc\nfrom sklearn import svm\nfrom sklearn.svm import SVC,SVR\n\nimport wordcloud\nfrom wordcloud import WordCloud, ImageColorGenerator\n\nfrom pandas.plotting import autocorrelation_plot\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.arima_model import ARIMA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/covid19-in-india/covid_19_india.csv\")\ndata.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Understand the data\ndata = pd.DataFrame(data)\ndata.shape\ndata.columns\nlen(data.ConfirmedIndianNational)\nlen(data.Deaths)\nlen(data.Cured)\nlen(data.Date)\ndata.info()\ndata.describe()\ndata['ConfirmedIndianNational'].describe()\ndata.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#If needed we can also replace the name of column\ndata = data.rename(columns = {\"State/UnionTerritory\":\"State\",\n                              \"ConfirmedIndianNational\":\"Confirmed_Indian\",\n                              \"ConfirmedForeignNational\":\"Confirmed_Foreginer\",\n                              \"Cured\":\"Recovered\"})\ndata.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Drop the SNo or column\n#ab = data.ix[:,1:]  Another method for droppping column\ndf = data.drop(['Sno','Time'],1)\ndf.columns\ndf['Date'] = pd.to_datetime(df['Date'], dayfirst = True)\ndf['Date'] = pd.to_datetime(df['Date'])\n#df['Confirmed_Total'] = df['Confirmed_Indian']+df['Confirmed_Foreginer']\ndf.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#missing values check\ndf.isna().sum()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['Recovered'].isna()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['Deaths'].isna()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_per_day=df.groupby('Date')['Confirmed_Indian','Confirmed_Foreginer','Confirmed',\n          'Deaths', 'Recovered'].sum()\ndf_per_day1=df.groupby('Date')['Confirmed_Indian','Confirmed_Foreginer','Confirmed',\n          'Deaths', 'Recovered'].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#maximum number of cases\ndf_per_day['Confirmed'].max() \ndf_per_day1['Confirmed'].max()\n\n#minimum number of cases\ndf_per_day['Confirmed'].min()\n\n#which day has max cases\ndf_per_day['Confirmed'].idxmax()\n\n#which day has minimum cases\ndf_per_day['Confirmed'].idxmin()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#No of cases per country State\n\ndf.groupby(['State'])['Confirmed_Indian','Confirmed_Foreginer','Confirmed',\n          'Deaths', 'Recovered'].max()\n#no of cases per country by descending order\na=df.groupby(['State'])['Confirmed_Indian','Confirmed_Foreginer','Confirmed','Deaths', 'Recovered'].max().sort_values(by = 'Confirmed', ascending= False)\n\n#how many countried affected\nStates = df['State'].unique()\nlen(df['State'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# WordCloud for Confirmed cases in Country\nState = str(a.Confirmed)\ncloud = WordCloud(max_words=70,background_color=\"white\").generate(State)\nplt.figure(figsize = (10,10))\nplt.imshow(cloud, interpolation='Bilinear')\nplt.axis(\"off\")\nplt.show()\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## COVID-19 # Symptoms\n\nsymptoms={'symptom':['Fever','Dry cough','Fatigue','Sputum production',\n                     'Loss of smell','Shortness of breath','Muscle pain or Joint pain',\n                     'Sore throat','Headache','Chills','Nausea or vomiting',\n                     'Nasal congestion','Diarrhoea','Haemoptysis','Conjunctival congestion']\n,'percentage':[87.9,67.7,38.1,33.4,15,18.6,14.8,13.9,13.6,11.4,5.0,4.8,3.7,0.9,0.8]}\n\ncon_symptoms=pd.DataFrame(data=symptoms)\ncon_symptoms\n\n# Graph for Symptoms and Percentage\nplt.figure(figsize=(10,5))\nplt.bar(con_symptoms['symptom'],con_symptoms['percentage'], color = 'm')\nplt.legend()\nplt.title('Conditions of Covid-19')\nplt.xlabel('Symptoms')\nplt.xticks(rotation=90)\n\n# Pie plot for symptoms\nplt.figure(figsize=(15,10))\nplt.title('Symptoms of Coronavirus',fontsize=20) \nplt.pie(con_symptoms['percentage'],autopct='%1.1f%%')\nplt.legend(symptoms['symptom'],loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Graph for Cases observed per day\n\nb = df.groupby(['Date'])['Recovered','Deaths','Confirmed',].sum().sort_values(by = 'Date', ascending = True)\n\nimport matplotlib.pyplot as plt\nplt.figure(figsize = (10,10))\nplt.plot(b['Confirmed'],'bo', label = 'Confirmed_Total', linewidth = 2, linestyle = ':')\nplt.plot(b['Deaths'],'ro', label = 'Deaths',linewidth = 2, linestyle = '--',)\nplt.plot(b['Recovered'],'go', label = 'Recovered',linewidth = 2,linestyle = '-.')\nplt.title('Cases per day')\nplt.xlabel('Dates')\n#plt.xticks([0,9,19,29])\nplt.ylabel('Cases')\nplt.legend()\nplt.show","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cases observed per state\nimport seaborn as sns\nc=df.groupby(['State'])['Confirmed','Deaths', 'Recovered'].max().sort_values(by = 'Confirmed', ascending= False)\n\nc.head(45).plot.barh(color = ('m','r','g'), figsize = (10,10), width = 0.9)\nplt.title('Cases per State')\nplt.xlabel('States in India')\nplt.ylabel('Cases', labelpad = 20)\nplt.legend()\nplt.show\n\n#Cases in State in Stacked form\nc.head(45).plot.barh(stacked = True, color = ('m','r','g'), figsize = (20,10))\nplt.title('Cases per State')\nplt.xlabel('State')\nplt.ylabel('Cases')\nplt.legend()\nplt.show","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#make another group for adding calculated columns\nc = df.groupby(['State'])['Confirmed','Deaths', 'Recovered'].max().sort_values(by = 'Confirmed', ascending= False)\n\n# percent Death Rate\nc['Percent_Deaths'] = c['Deaths']/c['Confirmed']*100\nc['Percent_Deaths']= round(c['Percent_Deaths'], 2)\n\n#Death rate state wise\nc['Percent_Deaths'].sort_values().head(55).plot.barh(figsize = (10,10), color = 'r')\nplt.title('Death Rate')\nplt.xlabel('State')\nplt.ylabel('Percent Death Rate')\nplt.legend()\nplt.show","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# percent Recoverey rate\nc['Percent_Recovery']=c['Recovered']/c['Confirmed']*100\nc['Percent_Recovery'] = round(c['Percent_Recovery'], 2)\n\n# Percent recovery rate Country wise\nc['Percent_Recovery'].sort_values().tail(55).plot.barh(figsize = (10,10), color = 'g')\nplt.title('Recovery Rate')\nplt.xlabel('State')\nplt.ylabel('Percent Recovery Rate')\nplt.legend()\nplt.show","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stacked plot for Recovery rate and Death rate\nc[['Percent_Deaths', 'Percent_Recovery']].sort_values(by = 'Percent_Recovery', ascending = False).plot.barh(stacked = True, figsize = (10,10), color = ('r','g'))\n\nc[['Percent_Deaths', 'Percent_Recovery']].sort_values(by = 'Percent_Deaths', ascending = False).plot.barh(stacked = True, figsize = (10,10), color = ('r','g'))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Percent recovery and Percent Death rate Date wise in scatter plot\nd = df.groupby(['Date'])['Confirmed','Deaths', 'Recovered'].sum().sort_values(by  ='Date',ascending= True)\n# Active Cases in India Date Wise\nd['Active'] = d['Confirmed']-d['Deaths']-d['Recovered']\n\nd['Percent_Deaths'] = d['Deaths']/d['Confirmed']*100\nd['Percent_Deaths']= round(d['Percent_Deaths'], 2)\nd['Percent_Recovery']=d['Recovered']/d['Confirmed']*100\nd['Percent_Recovery'] = round(d['Percent_Recovery'], 2)\nd['Percent_Active']=d['Active']/d['Confirmed']*100\nd['Percent_Active'] = round(d['Percent_Active'], 2)\n\nplt.figure(figsize = (10,10))\nplt.plot(d['Percent_Recovery'], 'b', label = 'Percent_Recovery')\nplt.plot(d['Percent_Deaths'], 'r', label = 'Percent_Deaths')\nplt.plot(d['Percent_Active'],'y',label = 'Percent_Active')\nplt.title('Recovery Rate Vs Death Rate Vs Active Rate')\nplt.xlabel('Date')\nplt.ylabel('Percencent Rate')\nplt.legend()\nplt.show\n\n# Datewise growth Rate\ng = df.groupby(['Date'])['Confirmed','Deaths', 'Recovered'].sum().sort_values(by = 'Date', ascending = True)\nprint(g.iloc[-1])\n\nincreased_Confirmed=[]\nincreased_Recovered=[]\nincreased_Deaths=[]\nz = 0\nfor z in range(g.shape[0]-1):\n    increased_Confirmed.append(((g['Confirmed'].iloc[z+1])/g['Confirmed'].iloc[z]))\n    increased_Recovered.append(((g['Recovered'].iloc[z+1])/g['Recovered'].iloc[z]))\n    increased_Deaths.append(((g['Deaths'].iloc[z+1])/g['Deaths'].iloc[z]))\nincreased_Confirmed.insert(0,1)\nincreased_Recovered.insert(0,1)\nincreased_Deaths.insert(0,1)\n\nplt.figure(figsize=(10,5))\nplt.plot(g.index,increased_Confirmed,'bo',label=\"Growth Rate of Confirmed Cases\",linestyle = ':')\nplt.plot(g.index,increased_Recovered,'go',label=\"Growth Rate of Recovered Cases\",linestyle = '-.')\nplt.plot(g.index,increased_Deaths,'ro',label=\"Growth Rate of Death Cases\",linestyle = '--')\nplt.xticks(rotation=90)\nplt.title(\"Datewise Growth Rate of different Types of Cases\")\nplt.ylabel(\"Growth Rate\")\nplt.xlabel(\"Date\")\nplt.legend()\n\n# Daily increase in Case\ng = df.groupby(['Date'])['Confirmed','Deaths', 'Recovered'].sum().sort_values(by = 'Date', ascending = True)\n\nts=g.reset_index().sort_values('Date')\nConfirmed=ts.Confirmed\nDeaths=ts.Deaths\nRecovered=ts.Recovered\nNew_Confirmed=[Confirmed[0]]\nNew_Deaths=[Deaths[0]]\nNew_Recovered=[Recovered[0]]\nfor i in range(1,len(Confirmed)):\n    New_Confirmed.append(Confirmed[i]-Confirmed[i-1])\n    New_Deaths.append(Deaths[i]-Deaths[i-1])\n    New_Recovered.append(Recovered[i]-Recovered[i-1])\nts['New_Confirmed']=New_Confirmed\nts['New_Deaths']=New_Deaths\nts['New_Recovered']=New_Recovered\nts.head()\n\nplt.figure(figsize=(10,5))\nplt.plot(ts['Date'],ts['New_Confirmed'],'bo',label=\"New Confirmed Cases\", linestyle = ':')\nplt.plot(ts['Date'],ts['New_Recovered'],'go',label=\"New Recovered Cases\",linestyle = '-.')\nplt.plot(ts['Date'],ts['New_Deaths'],'ro',label=\"New Death Cases\",linestyle = '--')\nplt.xticks(rotation=90)\nplt.title(\"New Cases added each day\")\nplt.ylabel(\"Cases\")\nplt.xlabel(\"Date\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Date Time\nfrom datetime import date\ne = df.copy()\ne = e.drop(['State','Confirmed_Indian','Confirmed_Foreginer'],1)\ne =e.groupby('Date').sum().reset_index()\ni = 0\ne['Days'] = 1\n#####RUN THIS ONLY ONE TIME #################\nfor ind in e.index: \n    e['Days'][ind] = i\n    i=i+1\n#############################################\n\n# Select only required variables and make new data frame\nf = e.ix[:,(3,4)]\nf.head(3)\n\n#taking value into two variables X and y\nX = f.ix[:,1] # Predictor # No of Days\nX.head(3)\nX_matrix = X.values.reshape(-1,1)\ny = f.ix[:,0] # Response Variable # Total Confirmed Cases\ny.head(3)\n\n\n# splitting of training and testing data\nX_matrix_train,X_matrix_test,y_train,y_test = train_test_split(X_matrix,y, test_size = 0.15,shuffle=False)\nlen(X_matrix_train)\nlen(X_matrix_test)\nlen(y_train)\nlen(y_test)\n\nX_matrix_train.shape\nX_matrix_test.shape\ny_train.shape\ny_test.shape\n\n# New data created for prediction\nnew_data=pd.DataFrame(data=[0,60,70,80,90,100,110,120,130,140,150],columns=['Days'])\nnew_data\nnew_data_matrix = new_data.values.reshape(-1,1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LINEAR REGRESSION #\n\n# Actual Model with Confirmed cases and no of Days\nlinear_model = LinearRegression(normalize=True, fit_intercept=True)\nlinear_model.fit(X_matrix_train, y_train)\nlinear_model.score(X_matrix_train,y_train)\nprint(linear_model.intercept_)\nprint(linear_model.coef_)\n\n#--Training Accuracy ---#\npred_y=linear_model.predict(X_matrix_train)\npred_y\n\nprint('MAE Training set:', mean_absolute_error(pred_y, y_train))\nprint('MSE Training set:',mean_squared_error(pred_y, y_train))\nMSE_tlr = mean_squared_error(pred_y, y_train)\nprint('RMSE Training set:',np.sqrt(MSE_tlr)) \n\n# Testing Accuaracy#\ny_pred = linear_model.predict(X_matrix_test)\ny_pred\n\nprint('MAE Testing set:', mean_absolute_error(y_pred, y_test))\nprint('MSE Testing set:',mean_squared_error(y_pred, y_test)) \nMSE_lr = mean_squared_error(y_pred, y_test)\nprint('RMSE Testing set:',np.sqrt(MSE_lr))\n\n# Prediction for unknow of future data created with new data matrix\nlinear_pred = linear_model.predict(new_data_matrix) #prediction of future days 60,70,80,90,100\nlinear_pred\n\n# Plot for Linear Regression\nplt.figure(figsize=(10,5))\nplt.plot(f['Days'], f['Confirmed'])\nplt.plot(new_data_matrix, linear_pred, linestyle='dashed', color='orange')\nplt.title('# of Coronavirus Cases Over Time')\nplt.xlabel('Days')\nplt.ylabel('# of Cases', size=30)\nplt.legend(['Confirmed Cases', 'Linear Regression Predictions'])\nplt.xticks([0,9,19,29,39,49,59,69,79,89,99,109,119,129,139,149])\nplt.show()\n#Linear Regrssion is not good fit for the data \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SUPPORT VECTOR MACHINE #\n\nsvCT = SVR(shrinking=True, kernel='poly',gamma=0.01, epsilon=1,degree=6, C=0.1).fit(X_matrix_train, y_train)\nprint(svCT)\n\n\n#--Training Accuracy ---#\npred_svm_y=svCT.predict(X_matrix_train)\npred_svm_y\n\nprint('MAE training set:', mean_absolute_error(pred_svm_y, y_train))\nprint('MSE training set:',mean_squared_error(pred_svm_y, y_train))\nMSE_tsvm = mean_squared_error(pred_svm_y, y_train)\nprint('RMSE training set:',np.sqrt(MSE_tsvm)) \n\n# Testing Accuaracy#\nsvm_y_pred = svCT.predict(X_matrix_test)\nsvm_y_pred\n\nprint('MAE testing set:', mean_absolute_error(svm_y_pred, y_test))\nprint('MSE testing set:',mean_squared_error(svm_y_pred, y_test)) \nMSE_svm = mean_squared_error(svm_y_pred, y_test)\nprint('RMSE testing set:',np.sqrt(MSE_svm))\n\nplt.plot(svm_y_pred)\nplt.plot(y_test)\n\nsvm_new_data_pred = svCT.predict(new_data_matrix) #prediction of future days 60,70,80,90,100\n# Plot for SVM predictions\n\nplt.figure(figsize=(10,5))\nplt.plot(f['Days'], f['Confirmed'])\nplt.plot(new_data_matrix, svm_new_data_pred,'mo', linestyle='dashed')\nplt.title('Coronavirus Cases Over Time')\nplt.xlabel('Days')\nplt.ylabel('Cases', size=30)\nplt.legend(['Confirmed Cases', 'SVM Predictions'])\nplt.xticks([0,9,19,29,39,49,59,69,79,89,99,109,119,129,139,149])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Polynomial Regression #\nfrom sklearn.preprocessing import PolynomialFeatures\npoly = PolynomialFeatures(degree=5)\npoly_X_matrix_train = poly.fit_transform(X_matrix_train)\npoly_X_matrix_test = poly.fit_transform(X_matrix_test)\npoly_new_data_matrix = poly.fit_transform(new_data_matrix)\n\npoly_linear_model = LinearRegression(normalize=True, fit_intercept=False)\npoly_linear_model.fit(poly_X_matrix_train, y_train)\n\n#--Training Accuracy ---#\npred_poly_y=poly_linear_model.predict(poly_X_matrix_train)\npred_poly_y\n\nprint('MAE training set:', mean_absolute_error(pred_poly_y, y_train))\nprint('MSE training set:',mean_squared_error(pred_poly_y, y_train))\nMSE_tpr = mean_squared_error(pred_poly_y, y_train)\nprint('RMSE training set:',np.sqrt(MSE_tpr))\n\n# Testing Accuaracy#\npoly_y_pred = poly_linear_model.predict(poly_X_matrix_test)\npoly_y_pred\n\nprint('MAE testing set:', mean_absolute_error(poly_y_pred, y_test))\nprint('MSE testing set:',mean_squared_error(poly_y_pred, y_test))\nMSE_pr = mean_squared_error(poly_y_pred, y_test)\nprint('RMSE testing set:',np.sqrt(MSE_pr))\n\nplt.plot(poly_y_pred)\nplt.plot(y_test)\n\npoly_new_data_pred = poly_linear_model.predict(poly_new_data_matrix) #prediction of future days 60,70,80,90,100\n\n#Plot for polynomial regression\nplt.figure(figsize=(10,5))\nplt.plot(f['Days'], f['Confirmed'])\nplt.plot(new_data_matrix, poly_new_data_pred, 'mo',linestyle='dashed')\nplt.title('# of Coronavirus Cases Over Time')\nplt.xlabel('Days')\nplt.ylabel('# of Cases', size=30)\nplt.legend(['Confirmed Cases', 'Poly Rgression Predictions'])\nplt.xticks([0,9,19,29,39,49,59,69,79,89,99,109,119,129,139,149])\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Time Series Forecasts #\ng = df.groupby(['Date'])['Confirmed','Deaths', 'Recovered'].sum().sort_values(by = 'Date', ascending = True)\nX_TS_train, y_TS_test = train_test_split(g, test_size = 0.20,shuffle=False)\ny_pred_TS = y_TS_test.copy()\nmodel_scores=[]\n\n\nfrom pandas.plotting import autocorrelation_plot\nplt.figure(figsize=(10, 5))\nautocorrelation_plot(g[\"Confirmed\"])\n\n# Define Function #\ndef get_stationarity(timeseries):\n# rolling statistics\n    rolling_mean = timeseries.rolling(window=7).mean()\n    rolling_std = timeseries.rolling(window=7).std()\n    \n    # rolling statistics plot\n    original = plt.plot(timeseries, color='blue', label='Original')\n    mean = plt.plot(rolling_mean, color='red', label='Rolling Mean')\n    std = plt.plot(rolling_std, color='black', label='Rolling Std')\n    plt.legend(loc='best')\n    plt.title('Rolling Mean & Standard Deviation')\n    plt.show(block=False)\n    \n    # Dickey–Fuller test:\n    result = adfuller(timeseries)\n    print('ADF Statistic: {}'.format(result[0]))\n    print('p-value: {}'.format(result[1]))\n    print('Critical Values:')\n    for key, value in result[4].items():\n        print('\\t{}: {}'.format(key, value))\n\nget_stationarity(X_TS_train[\"Confirmed\"])\n\nfig, (ax1,ax2,ax3) = plt.subplots(3, 1,figsize=(15,7))\nimport statsmodels.api as sm\nresults=sm.tsa.seasonal_decompose(X_TS_train[\"Confirmed\"])\nax1.plot(results.trend)\nax2.plot(results.seasonal)\nax3.plot(results.resid)\n\nlog_series=np.log(X_TS_train[\"Confirmed\"])\nget_stationarity(log_series)\n\n    \nfig, (ax1,ax2,ax3) = plt.subplots(3, 1,figsize=(15,7))\nimport statsmodels.api as sm\nresults=sm.tsa.seasonal_decompose(log_series)\nax1.plot(results.trend)\nax2.plot(results.seasonal)\nax3.plot(results.resid)\n\nmovingavg = log_series.rolling(window = 2).mean()\nlogscaleminusmovingavg = log_series-movingavg\nlogscaleminusmovingavg=logscaleminusmovingavg.dropna()\nget_stationarity(logscaleminusmovingavg)\n\n\nfig, (ax1,ax2,ax3) = plt.subplots(3, 1,figsize=(15,7))\nimport statsmodels.api as sm\nresults=sm.tsa.seasonal_decompose(logscaleminusmovingavg)\nax1.plot(results.trend)\nax2.plot(results.seasonal)\nax3.plot(results.resid)\n\n#Another method of making data stationary\nrolling_mean_exp_decay = log_series.ewm(halflife=1, min_periods=0, adjust=True).mean()\ndf_log_exp_decay = log_series - rolling_mean_exp_decay\ndf_log_exp_decay.dropna(inplace=True)\nget_stationarity(df_log_exp_decay)\n\nfig, (ax1,ax2,ax3) = plt.subplots(3, 1,figsize=(15,7))\nimport statsmodels.api as sm\nresults=sm.tsa.seasonal_decompose(df_log_exp_decay)\nax1.plot(results.trend)\nax2.plot(results.seasonal)\nax3.plot(results.resid)\n\n#another way is substrating one point from other\ndf_log_shift = log_series - log_series.shift()\ndf_log_shift.dropna(inplace=True)\nget_stationarity(df_log_shift)\n\nfig, (ax1,ax2,ax3) = plt.subplots(3, 1,figsize=(15,7))\nimport statsmodels.api as sm\nresults=sm.tsa.seasonal_decompose(df_log_shift)\nax1.plot(results.trend)\nax2.plot(results.seasonal)\nax3.plot(results.resid)\n\n# we are using logscaleminusmovingavg ######\nfrom statsmodels.tsa.stattools import acf, pacf\nlag_acf = acf(logscaleminusmovingavg, nlags = 2)\nlag_pacf = pacf(logscaleminusmovingavg, nlags = 2, method = 'ols')\n\n\n#Plot ACF:\nplt.subplot(121)\nplt.plot(lag_acf)\nplt.axhline(y=0, linestyle='--', color='gray')\nplt.axhline(y=-1.96/np.sqrt(len(logscaleminusmovingavg)), linestyle='--', color='gray')\nplt.axhline(y=1.96/np.sqrt(len(logscaleminusmovingavg)), linestyle='--', color='gray')\nplt.title('Autocorrelation Function')            \n\n#Plot PACF\nplt.subplot(122)\nplt.plot(lag_pacf)\nplt.axhline(y=0, linestyle='--', color='gray')\nplt.axhline(y=-1.96/np.sqrt(len(logscaleminusmovingavg)), linestyle='--', color='gray')\nplt.axhline(y=1.96/np.sqrt(len(logscaleminusmovingavg)), linestyle='--', color='gray')\nplt.title('Partial Autocorrelation Function')\n            \nplt.tight_layout()\n\nmodel_arima=ARIMA(log_series,(0,1,0))\nmodel_arima_fit=model_arima.fit()\nprint(model_arima_fit.summary())\nmodel_arima_fit.plot_predict(dynamic = False)\nplt.show()\n\n# Plot residual errors\nresiduals = pd.DataFrame(model_arima_fit.resid)\nfig, ax = plt.subplots(1,2)\nresiduals.plot(title=\"Residuals\", ax=ax[0])\nresiduals.plot(kind='kde', title='Density', ax=ax[1])\nplt.show()\n\n\nmodel_arima_fit.plot_predict(1,100)\nplt.show()\n\nprediction_arima=model_arima_fit.forecast(len(y_TS_test))[0]\ny_pred_TS[\"ARIMA Model Prediction\"]=list(np.exp(prediction_arima))\n\nmodel_scores.append(np.sqrt(mean_squared_error(list(y_TS_test[\"Confirmed\"]),np.exp(prediction_arima))))\nprint(\"Root Mean Square Error for AR Model: \",np.sqrt(mean_squared_error(list(y_TS_test[\"Confirmed\"]),np.exp(prediction_arima))))\nMSE_ts = np.sqrt(mean_squared_error(list(y_TS_test[\"Confirmed\"]),np.exp(prediction_arima)))\n\n\nplt.figure(figsize=(10,5))\nplt.plot(X_TS_train.index,X_TS_train[\"Confirmed\"],label=\"Train Set\",marker='o')\nplt.plot(y_TS_test.index,y_TS_test[\"Confirmed\"],label=\"Validation Set\",marker='*')\nplt.plot(y_pred_TS[\"ARIMA Model Prediction\"],label=\"ARIMA Model Prediction Set\",marker='^')\nplt.legend()\nplt.xlabel(\"Date Time\")\nplt.ylabel('Confirmed Cases')\nplt.xticks(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Final \n#Comparision of results\n\nscores = []\nscores.append(np.sqrt(MSE_lr))\nscores.append(np.sqrt(MSE_svm))\nscores.append(np.sqrt(MSE_pr))\nscores.append(MSE_ts)\nscores\n\nmodels=[\"Linear Regression\",\"SVM\",\"Polynomial Regression\", \"Time Series\"]\nfinal = pd.DataFrame(zip(models,scores),columns=[\"Models\",\"RMSE\"]).sort_values([\"RMSE\"])\nfinal\n\n#Polynomial Regression is most fit plot the preditction of confimred cases over time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}