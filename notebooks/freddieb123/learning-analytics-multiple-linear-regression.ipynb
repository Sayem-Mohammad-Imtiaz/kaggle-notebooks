{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Learning Analytics - Multiple Linear Regression"},{"metadata":{},"cell_type":"markdown","source":"Data Source: https://www.kaggle.com/rocki37/open-university-learning-analytics-dataset\nData description: https://analyse.kmi.open.ac.uk/open_dataset#description\n\nIn this investigation, I am looking at whether student data such as gender and age, as well as interaction in the VLE can be a predictor of assessment scores by module. "},{"metadata":{},"cell_type":"markdown","source":"Database Schema:\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import Image\nImage(\"../input/databaseschema/DataBase_schema.png\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Initial Question: \nCan we use what we know about students, and their engagement on the VLE to predict assessment outcomes?  \n\nWe will use:  \naverage number of clicks per module  \naverage score on assessments per module"},{"metadata":{},"cell_type":"markdown","source":"## Loading the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nprint(os.listdir('../input/open-university-learning-analytics-dataset'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport seaborn as sns\n\n\nassessments = pd.read_csv('../input/open-university-learning-analytics-dataset/assessments.csv')\nstudent_assessment = pd.read_csv('../input/open-university-learning-analytics-dataset/studentAssessment.csv')\nstudent_info = pd.read_csv('../input/open-university-learning-analytics-dataset/studentInfo.csv')\nvle_activity = pd.read_csv('../input/open-university-learning-analytics-dataset/studentVle.csv')\n\n#we only need code_module so that we can perform a join with studenAssessment and then studentInfo tables\nassessments.drop(['code_presentation','assessment_type','date','weight'], axis = 1, inplace = True)\n#assessments.code_module.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#merge individual assessments data with assessment data, so that we know which module each assessment belongs to\ncomb_assess = pd.merge(student_assessment,assessments,on='id_assessment')\ncomb_assess.drop(['is_banked','date_submitted'],axis = 1,inplace=True)\ncomb_assess.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#clean some of the data - we don't want score as a string, we want it as an integer. So let's remove the ?\n#comb_assess.drop(comb_assess[comb_assess.score == '?'].index, inplace = True);\n#comb_assess.score = comb_assess.score.astype(int);\n#comb_assess.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#how much data do we have?\ncomb_assess.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#group by student and then subgroup by module, so that we retain ability to evaluate different module predictability\ngrouped = comb_assess.groupby(['id_student','code_module']).mean()\ngrouped.sort_values('id_student')\n#we can't keep id_assessment, because we have just grouped by module. We have to group by module, as our vle interaction data is \n#only grouped by module\ngrouped.drop(['id_assessment'],axis=1,inplace = True)\ngrouped.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"student_info.shape","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"#put it all together\nstudent_all_info = pd.merge(student_info,grouped,on='id_student')\n#just getting a feel for it - how many modules is each student enrolled in?\nfig1 = student_all_info.groupby(['id_student']).code_module.count().sort_values().hist()\nfig1.set_title('Number of modules by student')\nfig1.set_xlabel('Number of modules')\nfig1.set_ylabel('Number of students')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note: The plot above shows most students are enrolled in one module. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#total number of clicks per student by module\nvle_grouped = vle_activity.groupby(['id_student','code_module']).sum()\n#we have to drop the columns below as we have grouped by student and subgrouped by module, so they are meaningless\nvle_grouped.drop(['id_site','date'],axis=1,inplace=True)\nvle_grouped.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"student_all_info.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#left join as we want to keep student info where no clicks were made\ndf = pd.merge(student_all_info,vle_grouped,on = ['id_student','code_module'],how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#remove rows where there are null values for sum_click. There are only 201 so it won't have a huge impact\ndf.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#save the new table\ndf.to_csv('joinedData.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So we now have a dataframe with student info, average assessment score for that module and average number of clicks for that module. We will now inspect the data for missing data, and ensure it's clean. "},{"metadata":{},"cell_type":"markdown","source":"## We need to create the categorical variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.code_module = pd.Categorical(df.code_module)\ndf.code_presentation = pd.Categorical(df.code_presentation)\ndf.gender = pd.Categorical(df.gender)\ndf.region = pd.Categorical(df.region)\ndf.highest_education = pd.Categorical(df.highest_education)\ndf.imd_band = pd.Categorical(df.imd_band)\ndf.age_band = pd.Categorical(df.age_band)\ndf.disability = pd.Categorical(df.disability)\ndf.final_result = pd.Categorical(df.final_result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Initial exploration of the data"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"import plotly.express as px\ndata = df\nfig = px.box(data, x=\"code_module\", y=\"score\",title='Student average scores by Module')\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = df\nfig = px.box(data, x=\"region\", y=\"score\",title='Student average scores by Region')\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### What this tells us:\nAll modules have a lower tail, and 6 out of 7 have zero scores included  \nScores by region are fairly consistent  \n\nLet's look at numbers of each students' highest achieved education level, and see if that tells us anything"},{"metadata":{"trusted":true},"cell_type":"code","source":"highest_ed = df.highest_education.value_counts()\nf, ax = plt.subplots(figsize=(18,5))\nax.bar(highest_ed.index,highest_ed)\nax.set_ylabel('number of students')\ndf.highest_education.cat.categories","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### What this tells us:\nWe need to be careful about generalising for the two categories Post Grad and No prior quals as they only have small numbers  \n\nAnd below, we can see there isn't much variation by gender"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"for_bar = df.pivot_table(index = 'highest_education', columns='gender', values = 'score')\nfor_bar.plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"interaction_by_module = df.sum_click\nfig2, ax2 = plt.subplots(figsize=(5,5));\nax2.hist(interaction_by_module,bins=50);\nax2.set_xlabel('Number of Clicks by module');\nax2.set_title('Number of clicks by module for each student');\nax2.set_ylabel('Number of occurences');\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"interaction_by_module = df.sum_click\nfig2, ax2 = plt.subplots(figsize=(5,5));\nax2.boxplot(interaction_by_module);\nax2.set_xlabel('Number of Clicks by module');\nax2.set_title('Number of clicks by module for each student');\nax2.set_ylabel('Number of occurences');","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"plt.scatter((df.sum_click),(df.score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### What this shows us\nMost students perform under 1000 clicks per module. There is a long tail of keen students though!  \nThere isn't a clear linear relationship between number of clicks and average assessment score by module"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plt.scatter((df.studied_credits),(df.score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### What this shows us\nWe should put the studied_credits data in bins, as it would make more sense as categorical data - it only appears as certain value."},{"metadata":{"trusted":true},"cell_type":"code","source":"bins = [0,50,100,150,200,250,300,350,400,450,500,550,600]\ndf['studied_credits'] = pd.cut(df['studied_credits'], bins=bins)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df2 = df.groupby(['gender','code_module']).score.mean()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df3 = df.groupby(['gender','code_module']).sum_click.mean()\ncodes =  df2.index.get_level_values(1)\ncodes\nsns.scatterplot(df3,df3.index.get_level_values(1), hue = df2.index.get_level_values(0), legend='full');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### What this shows us\nWomen tend to be more engaged with the VLE"},{"metadata":{},"cell_type":"markdown","source":"### Question: Does this higher engagement for women translate to better scores? "},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"import seaborn as sns\ncodes =  df2.index.get_level_values(1)\ncodes\nsns.scatterplot(df2,df2.index.get_level_values(1), hue = df2.index.get_level_values(0), legend='full');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### What this shows us\nThere aren't huge differences in performance by gender for each module"},{"metadata":{},"cell_type":"markdown","source":"## Does the total number of clicks impact the final result?"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df.groupby('final_result').sum_click.mean().sort_values().plot(kind='bar',)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So there does seem to be some pattern between final score and engagement on the vle"},{"metadata":{},"cell_type":"markdown","source":"Let's look at the range now"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"data = df\nfig = px.box(data, x=\"final_result\", y=\"sum_click\",title='Student final score by the total clicks on the vle')\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So it looks like there are some keen beans skewing our conclusion a bit, but there is still some difference in clicks by result  \n\nAnd how about final score and average score for that module? There should be a relationship no?"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"df.groupby('final_result').score.mean().sort_values().plot(kind='bar',)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### What this shows us:\nIt looks as though the number of clicks above 700 isn't that predictive, but below 700 could be. Particularly of withdrawal and failure. There also seems to be a link between final_result and number of clicks"},{"metadata":{},"cell_type":"markdown","source":"### Next question: Let's look just at those people/modules that have less than 700 clicks, and see if it's more predictive"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter((df.sum_click[df.sum_click < 700]),(df.score[df.sum_click < 700]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Overall conclusion so far\nWe have seen that number there is a relationship between number of clicks and final result, and particularly that it might be possible at the lower end of engagement to predict withdrawal or failure from VLE engagement. However our independent variables by themselves don't seem to be predictive of mean assessment score.  \n\nLet's continue anyway, to see if we get any results from a multiple linear regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's check the datatypes\ndf.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()\ndf.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So num_of_prev_attempts is heavily positively skewed. studied_credits might have significant outliers. There is a large variation in sum_click, with std larger than mean. "},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df_target = df.score\ndf.drop(['score'],axis=1,inplace=True)\ndf.drop(['id_student'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check for multicollinearity"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df.head()\ndf.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check multicollinearity\ncorr = df.corr()\ncorr","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is no significant multicollinearity between independent variables  \n\nNext, let's normalise the continuous variables - num_of_prev_attempts, studied_credits,score,date, sum_clicks, plus the target variable score"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.hist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Scaling the continuous features"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.num_of_prev_attempts = (df.num_of_prev_attempts - df.num_of_prev_attempts.mean())/df.num_of_prev_attempts.std()\ndf.sum_click = (df.sum_click - df.sum_click.mean())/df.sum_click.std()\ndf_target = (df_target - df_target.mean())/df_target.std()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.hist();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_target.hist();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### How normal are these independent variables?"},{"metadata":{"trusted":true},"cell_type":"code","source":"#test skew and kurtosis\nprint(\"Kurtosis\",df.kurtosis(axis=0))\nprint(\"Skew\",df.skew(axis=0))\nprint(\"Target Kurtosis\",df_target.kurtosis(axis=0))\nprint(\"Target Skew\",df_target.skew(axis=0))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All variables have positive skewness and kurtosis nowhere near zero. However we can't log transform with the data we have, as there are lots of invalid values including 0s. "},{"metadata":{},"cell_type":"markdown","source":"### Perform log transformation on the variables - apart from date which has negative values"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df.num_of_prev_attempts.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_trans = df\ndf_trans.head()\n#df_trans['num_of_prev_attempts'] = np.log(df.num_of_prev_attempts)\n#df_trans['studied_credits'] = np.log(df.studied_credits)\n#df_trans['sum_click'] = np.log(df.sum_click)\n#df_trans_target = np.log(df_target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_target.hist()\ndf_trans.hist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelling"},{"metadata":{},"cell_type":"markdown","source":"## One hot encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_trans = pd.get_dummies(df_trans)\ndf_trans.shape\ndf_trans.dtypes\nfor i in df_trans.columns[2:]:\n    df_trans[i] = df_trans[i].astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_trans.dtypes\ndf_trans['score']=df_target\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check for Linearity between each independent variable and the target variable"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"plt.scatter(df_trans['sum_click'],df_target)\ndf_trans.sum_click.isnull().sum()\ndf_trans.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#replace spaces in strings with _ for modelling purposes\ndf_trans.columns = df_trans.columns.str.replace(' ', '_')\ndf_trans.columns = df_trans.columns.str.replace('-', '_')\ndf_trans.columns = df_trans.columns.str.replace('%', '')\ndf_trans.columns = df_trans.columns.str.replace('?', '')\ndf_trans.columns = df_trans.columns.str.replace('<', '')\ndf_trans.columns = df_trans.columns.str.replace('=', '')\ndf_trans.columns = df_trans.columns.str.replace(']', ')')\ndf_trans.columns = df_trans.columns.str.replace('(', '')\ndf_trans.columns = df_trans.columns.str.replace(')', '')\ndf_trans.columns = df_trans.columns.str.replace(',', '')\n\ndf_trans.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's look at linear regression by variable"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"import statsmodels.formula.api as smf\n\ndfcol = ['num_of_prev_attempts','sum_click']\nresult = []\nfor count, i in enumerate(dfcol):\n    formula = 'score ~' + ' ' + i\n    model = smf.ols(formula, data = df_trans).fit()\n    #print(model.params[0],model.params[1],model.pvalues[1])\n    result.append([i, model.rsquared, model.params[0],model.params[1],model.pvalues[1]])\nresult","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So not great. Let's try the categorical variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_trans.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_module= df_trans.columns[2:9]\ncols_pres= df_trans.columns[9:13]\ncols_gender = df_trans.columns[13:15]\ncols_region = df_trans.columns[13:28]\ncols_ed = df_trans.columns[28:33]\ncols_imd = df_trans.columns[33:44]\ncols_age = df_trans.columns[44:47]\ncols_cred = df_trans.columns[47:59]\ncols_dis = df_trans.columns[59:61]\ncols_result = df_trans.columns[61:65]\n\nprint(cols_result)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = [cols_module, cols_pres , cols_gender, cols_region,cols_ed,cols_imd,cols_age,cols_cred,cols_dis,cols_result]\nfor col in cols:\n    sum_cols = \"+\".join(col)\n    form = \"score ~\" + sum_cols\n    model = smf.ols(formula= form, data= df_trans).fit()\n    #model = smf.ols(formula, data = df).fit()\n    print(model.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's drop some of the less predictive columns, and one from each category"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_final = df_trans.drop([\"num_of_prev_attempts\",\"code_module_AAA\",\"code_presentation_2013B\",\"gender_F\",\"region_East_Anglian_Region\",\"highest_education_No_Formal_quals\",\"imd_band_0_10\",\"studied_credits_550_600\",\"disability_Y\",\"final_result_Fail\"], axis=1)\ny = df_final[[\"score\"]]\nX = df_final.drop([\"score\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df_final.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature selection\nWe will use recursive feature selection to find the best combination of features. "},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.formula.api as smf\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression\n\n\n\nr_list = []\nadj_r_list = []\nlist_n = list(range(1,56,2))\nfor n in list_n: \n    linreg = LinearRegression()\n    select_n = RFE(linreg, n_features_to_select = n)\n    select_n = select_n.fit(X, np.ravel(y))\n    selected_columns = X.columns[select_n.support_ ]\n    linreg.fit(X[selected_columns],y)\n    yhat = linreg.predict(X[selected_columns])\n    SS_Residual = np.sum((y-yhat)**2)\n    SS_Total = np.sum((y-np.mean(y))**2)\n    r_squared = 1 - (float(SS_Residual))/SS_Total\n    print(r_squared)\n    adjusted_r_squared = 1 - (1-r_squared)*(len(y)-1)/(len(y)-X.shape[1]-1)\n    print(adjusted_r_squared)\nr_list.append(r_squared)\nadj_r_list.append(adjusted_r_squared)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion:\nThis regression didn't yield much. However we can look further into the relationship between final score and vle engagement using logarithmic regression. "}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}