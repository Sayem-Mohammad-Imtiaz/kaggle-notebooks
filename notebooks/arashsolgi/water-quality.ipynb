{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-11T18:53:30.18265Z","iopub.execute_input":"2021-08-11T18:53:30.183443Z","iopub.status.idle":"2021-08-11T18:53:30.213792Z","shell.execute_reply.started":"2021-08-11T18:53:30.183278Z","shell.execute_reply":"2021-08-11T18:53:30.212617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As you see , this data set is about the water quality and At its most basic level, potabible water relates to the safety of water.\n\nMany questions begin to emerge. we want to find out the Water quality and Potability of it \n\n* Are we able to consume all fresh water types?\n\n* What percentage of the worlds fresh water can be accessed?\n\n* Has the water table increased as sea levels have rised?\n","metadata":{}},{"cell_type":"markdown","source":"1. ph: pH of 1. water (0 to 14).\n2. Hardness: Capacity of water to precipitate soap in mg/L.\n3. Solids: Total dissolved solids in ppm.\n4. Chloramines: Amount of Chloramines in ppm.\n5. Sulfate: Amount of Sulfates dissolved in mg/L.\n6. Conductivity: Electrical conductivity of water in μS/cm.\n7. Organic_carbon: Amount of organic carbon in ppm.\n8. Trihalomethanes: Amount of Trihalomethanes in μg/L.\n9. Turbidity: Measure of light emiting property of water in NTU.\n10. Potability: Indicates if water is safe for human consumption. Potable -1 and Not potable -0","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport warnings\nimport plotly.express as ex\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots","metadata":{"execution":{"iopub.status.busy":"2021-08-11T18:53:30.215785Z","iopub.execute_input":"2021-08-11T18:53:30.216214Z","iopub.status.idle":"2021-08-11T18:53:35.545856Z","shell.execute_reply.started":"2021-08-11T18:53:30.216175Z","shell.execute_reply":"2021-08-11T18:53:35.544194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('../input/water-potability/water_potability.csv')\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T18:53:35.548767Z","iopub.execute_input":"2021-08-11T18:53:35.549182Z","iopub.status.idle":"2021-08-11T18:53:35.638959Z","shell.execute_reply.started":"2021-08-11T18:53:35.54914Z","shell.execute_reply":"2021-08-11T18:53:35.636996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-08-11T18:53:35.641559Z","iopub.execute_input":"2021-08-11T18:53:35.642269Z","iopub.status.idle":"2021-08-11T18:53:35.678094Z","shell.execute_reply.started":"2021-08-11T18:53:35.642203Z","shell.execute_reply":"2021-08-11T18:53:35.674123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of rows and columns\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-11T18:53:35.679905Z","iopub.execute_input":"2021-08-11T18:53:35.68032Z","iopub.status.idle":"2021-08-11T18:53:35.689662Z","shell.execute_reply.started":"2021-08-11T18:53:35.680283Z","shell.execute_reply":"2021-08-11T18:53:35.687935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we want to divide the data into categorical and numerical \ncat_cols=df.select_dtypes(include='object')\nnum_cols=df.select_dtypes(exclude='object')","metadata":{"execution":{"iopub.status.busy":"2021-08-11T18:53:35.691184Z","iopub.execute_input":"2021-08-11T18:53:35.691542Z","iopub.status.idle":"2021-08-11T18:53:35.709886Z","shell.execute_reply.started":"2021-08-11T18:53:35.691509Z","shell.execute_reply":"2021-08-11T18:53:35.708602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# As you see, we do not have any categorical attributes\nfor cat in cat_cols.columns:\n    print(f\"{cat}\")\n    print(cat_cols[cat].unique())\n    print(cat)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T18:53:35.711906Z","iopub.execute_input":"2021-08-11T18:53:35.712337Z","iopub.status.idle":"2021-08-11T18:53:35.726527Z","shell.execute_reply.started":"2021-08-11T18:53:35.712299Z","shell.execute_reply":"2021-08-11T18:53:35.725507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we find out all information about the data\nnum_cols.describe()","metadata":{"execution":{"iopub.status.busy":"2021-08-11T18:53:35.728853Z","iopub.execute_input":"2021-08-11T18:53:35.729227Z","iopub.status.idle":"2021-08-11T18:53:35.79227Z","shell.execute_reply.started":"2021-08-11T18:53:35.729193Z","shell.execute_reply":"2021-08-11T18:53:35.790892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sum of the numbers and divide to number by amount of the numbers\ndf.mean()","metadata":{"execution":{"iopub.status.busy":"2021-08-11T18:53:35.794384Z","iopub.execute_input":"2021-08-11T18:53:35.79475Z","iopub.status.idle":"2021-08-11T18:53:35.804608Z","shell.execute_reply.started":"2021-08-11T18:53:35.794714Z","shell.execute_reply":"2021-08-11T18:53:35.803351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Middle of the point\ndf.median()","metadata":{"execution":{"iopub.status.busy":"2021-08-11T18:53:35.806442Z","iopub.execute_input":"2021-08-11T18:53:35.806839Z","iopub.status.idle":"2021-08-11T18:53:35.823929Z","shell.execute_reply.started":"2021-08-11T18:53:35.806802Z","shell.execute_reply":"2021-08-11T18:53:35.822493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we want to divide our goal into target and non_target\ntarget=df[df['Potability']==1]\nnon_target=df[df['Potability']==0]","metadata":{"execution":{"iopub.status.busy":"2021-08-11T18:53:35.826065Z","iopub.execute_input":"2021-08-11T18:53:35.826537Z","iopub.status.idle":"2021-08-11T18:53:35.866847Z","shell.execute_reply.started":"2021-08-11T18:53:35.826486Z","shell.execute_reply":"2021-08-11T18:53:35.865516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_cols=['Potability']\ncat_cols=df.nunique()[df.nunique()<8].keys().tolist()\ncat_cols=[x for x in cat_cols if x not in target_cols]\nnum_col=[x for x in df.columns if x not in cat_cols+ target_cols]","metadata":{"execution":{"iopub.status.busy":"2021-08-11T18:53:35.868459Z","iopub.execute_input":"2021-08-11T18:53:35.868795Z","iopub.status.idle":"2021-08-11T18:53:35.898827Z","shell.execute_reply.started":"2021-08-11T18:53:35.868763Z","shell.execute_reply":"2021-08-11T18:53:35.897418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"median=df['ph'].median()\ndf['ph'].fillna(median,inplace=True)\nmedian=df['Sulfate'].median()\ndf['Sulfate'].fillna(median,inplace=True)\nmedian=df['Trihalomethanes'].median()\ndf['Trihalomethanes'].fillna(median,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T18:53:35.900778Z","iopub.execute_input":"2021-08-11T18:53:35.9015Z","iopub.status.idle":"2021-08-11T18:53:35.912188Z","shell.execute_reply.started":"2021-08-11T18:53:35.901443Z","shell.execute_reply":"2021-08-11T18:53:35.910979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display missing values using a heatmap to understand if any patterns are present( we cleaned all the missing values by median and use heatmap for better understanding)\nplt.figure(figsize=(15,8))\nsns.heatmap(df.isnull());","metadata":{"execution":{"iopub.status.busy":"2021-08-11T18:53:35.913507Z","iopub.execute_input":"2021-08-11T18:53:35.914414Z","iopub.status.idle":"2021-08-11T18:53:37.006203Z","shell.execute_reply.started":"2021-08-11T18:53:35.914349Z","shell.execute_reply":"2021-08-11T18:53:37.005061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# As you see, the most portion is 0, it means it is not potable(Almost 60%)\ndf['Potability'].value_counts(normalize=True)*100","metadata":{"execution":{"iopub.status.busy":"2021-08-11T18:53:37.008084Z","iopub.execute_input":"2021-08-11T18:53:37.008503Z","iopub.status.idle":"2021-08-11T18:53:37.019203Z","shell.execute_reply.started":"2021-08-11T18:53:37.008465Z","shell.execute_reply":"2021-08-11T18:53:37.017725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we use filter to find out the the potability is 0 , sulfate is more than 300 , chloramines more than 10 and hardness of the water is more than 220\ndf[(df['Potability']==0) &(df['Sulfate']>300)&(df['Chloramines']>10)&(df['Hardness']>220)]","metadata":{"execution":{"iopub.status.busy":"2021-08-11T18:53:37.021132Z","iopub.execute_input":"2021-08-11T18:53:37.021596Z","iopub.status.idle":"2021-08-11T18:53:37.052394Z","shell.execute_reply.started":"2021-08-11T18:53:37.021555Z","shell.execute_reply":"2021-08-11T18:53:37.050929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we want to use groupby with sum and counts and also with potability\n\n# Read the data\ndf_grouped_sum=df.groupby('Potability',as_index=False)['Conductivity'].agg('sum').rename(columns={'Conductivity':'Conductivity_Sum'})\ndf_grouped_cnt=df.groupby('Potability',as_index=False)['Conductivity'].agg('count').rename(columns={'Conductivity':'Conductivity_Count'})\n#Merge the data\ndf_grouped_Avg=df_grouped_sum.merge(df_grouped_cnt,left_on='Potability',right_on='Potability',how='inner')\n\ndf_grouped_Avg.loc[:,'Average of Conductivity']=df_grouped_Avg['Conductivity_Sum']/df_grouped_Avg['Conductivity_Count']\n\n\n# The final result\ndf_grouped_Avg.sort_values('Conductivity_Sum',ascending=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T18:53:37.054539Z","iopub.execute_input":"2021-08-11T18:53:37.054917Z","iopub.status.idle":"2021-08-11T18:53:37.098763Z","shell.execute_reply.started":"2021-08-11T18:53:37.054884Z","shell.execute_reply":"2021-08-11T18:53:37.097434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we want to use groupby, sum and count with Potability by Hardness\n# Read the data\ndf_grouped_sum=df.groupby('Potability',as_index=False)['Hardness'].agg('sum').rename(columns={'Hardness':'Hardness_Sum'})\ndf_grouped_cnt =df.groupby('Potability',as_index=False)['Hardness'].agg('sum').rename(columns={'Hardness':'Hardness_Count'})\n# Merge the 2 lines of code \ndf_grouped_Avg=df_grouped_sum.merge(df_grouped_cnt,left_on='Potability',right_on='Potability',how='inner')\n\ndf_grouped_Avg.loc[:,'Average of Hardness']=df_grouped_Avg['Hardness_Sum']/df_grouped_Avg['Hardness_Count']\n\n# Final result\ndf_grouped_Avg.sort_values('Hardness_Sum',ascending=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T18:53:37.100534Z","iopub.execute_input":"2021-08-11T18:53:37.100904Z","iopub.status.idle":"2021-08-11T18:53:37.137399Z","shell.execute_reply.started":"2021-08-11T18:53:37.100868Z","shell.execute_reply":"2021-08-11T18:53:37.135768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# We want to use some visualization parts with different attributes","metadata":{}},{"cell_type":"code","source":"plt.rcParams['figure.figsize']=(10,9)\ndf['Potability'].value_counts().sort_values(ascending=False).plot.bar(color='orange')\nplt.xlabel('amount of the potability')\nplt.ylabel('count')\nplt.show()\n# As you see , most portion of water is potable( zero is more than one)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T18:53:37.13886Z","iopub.execute_input":"2021-08-11T18:53:37.139242Z","iopub.status.idle":"2021-08-11T18:53:37.3401Z","shell.execute_reply.started":"2021-08-11T18:53:37.1392Z","shell.execute_reply":"2021-08-11T18:53:37.338419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# As you see, the range of the ph for non potable water is between 6 to 8 and for potable water is 6 to 7.5\nsns.violinplot(y='ph',x='Potability',data=df, color='aqua')","metadata":{"execution":{"iopub.status.busy":"2021-08-11T18:53:37.342107Z","iopub.execute_input":"2021-08-11T18:53:37.342651Z","iopub.status.idle":"2021-08-11T18:53:37.826409Z","shell.execute_reply.started":"2021-08-11T18:53:37.342599Z","shell.execute_reply":"2021-08-11T18:53:37.824939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.relplot('Conductivity','Turbidity',data=df, color='pink')\nplt.title('Show the amount of the conductivity with the Turbidity')\nplt.show()\n# As you see, the most amount of the conductivity is between 400 to 550 and the amount for Turbidity is between 3 to 5","metadata":{"execution":{"iopub.status.busy":"2021-08-11T18:53:37.828304Z","iopub.execute_input":"2021-08-11T18:53:37.828728Z","iopub.status.idle":"2021-08-11T18:53:38.204609Z","shell.execute_reply.started":"2021-08-11T18:53:37.828659Z","shell.execute_reply":"2021-08-11T18:53:38.203556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.scatterplot('Chloramines','Trihalomethanes',data=df,color='yellow')\nplt.show()\n# As you see, we use scatterplot to visualize the amount of the Chloramines which the most portion is between 5 to 9 and the amount of the Trihalomethanes is 50 to 100 μg/L","metadata":{"execution":{"iopub.status.busy":"2021-08-11T18:53:38.205952Z","iopub.execute_input":"2021-08-11T18:53:38.206496Z","iopub.status.idle":"2021-08-11T18:53:38.449904Z","shell.execute_reply.started":"2021-08-11T18:53:38.206457Z","shell.execute_reply":"2021-08-11T18:53:38.448206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use the distplot for ph with mean and median\nsns.distplot(df['ph'],kde=False)\nplt.axvline(x=df.ph.mean(),linewidth=3, color='r', label=\"mean\", alpha=0.5)\nplt.axvline(x=df.ph.median(),linewidth=3,color='y',label='median',alpha=0.5)\n\n# set the labels\nplt.xlabel('ph')\nplt.ylabel('count')\nplt.title('Distribution of ph')\nplt.legend(['mean','median'])\n\nprint(f'Mean pH value {df.ph.mean()} \\n Median pH value {df.ph.median()} \\n Min pH value {df.ph.min()} \\n Max pH value {df.ph.max()}')","metadata":{"execution":{"iopub.status.busy":"2021-08-11T18:53:38.454995Z","iopub.execute_input":"2021-08-11T18:53:38.45559Z","iopub.status.idle":"2021-08-11T18:53:38.98468Z","shell.execute_reply.started":"2021-08-11T18:53:38.455552Z","shell.execute_reply":"2021-08-11T18:53:38.982919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.distplot(df['Hardness'],kde=False)\nplt.axvline(x=df.Hardness.mean(),linewidth=3,color='g',label='Mean',alpha=0.4)\nplt.axvline(x=df.Hardness.median(),linewidth=3,color='purple',label='Median',alpha=0.5)\n\n# set the labels\nplt.xlabel('Hardness')\nplt.ylabel('count')\nplt.title('Distribution of Hardness',size=10)\nplt.legend(['Mean','Median'])\n\n# result with percentage\nprint(f'Mean Hardness value {df.Hardness.mean()} \\n Median Hardness value {df.Hardness.median()} \\n Min Hardness value {df.Hardness.min()} \\n Max Hardness value {df.Hardness.max()}')","metadata":{"execution":{"iopub.status.busy":"2021-08-11T18:53:38.986892Z","iopub.execute_input":"2021-08-11T18:53:38.987494Z","iopub.status.idle":"2021-08-11T18:53:39.520649Z","shell.execute_reply.started":"2021-08-11T18:53:38.987443Z","shell.execute_reply":"2021-08-11T18:53:39.518878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(df['Sulfate'],kde=True,color='silver')\nplt.show()\n# In this graph, the most portion of sulfate is 330 mg/L and the amount of this is more than 900","metadata":{"execution":{"iopub.status.busy":"2021-08-11T18:53:39.5236Z","iopub.execute_input":"2021-08-11T18:53:39.524227Z","iopub.status.idle":"2021-08-11T18:53:40.296624Z","shell.execute_reply.started":"2021-08-11T18:53:39.524174Z","shell.execute_reply":"2021-08-11T18:53:40.294919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.distplot(df['Organic_carbon'],kde=False)\nplt.axvline(x=df.Organic_carbon.mean(),linewidth=3,color='y',label='Mean',alpha=0.4)\nplt.axvline(x=df.Organic_carbon.median(),linewidth=3,color='r',label='Median',alpha=0.4)\n\n# set the labels\nplt.xlabel('Organic_carbon')\nplt.ylabel('count')\nplt.title('Distribute of Organic_carbon',size=12)\nplt.legend(['Mean','Median'])\n\nprint(f'Mean Organic_carbon value {df.Organic_carbon.mean()} \\n Median Organic_carbon value {df.Organic_carbon.median()} \\n Min Organic_carbon value {df.Organic_carbon.min()} \\n Max Organic_carbon value {df.Organic_carbon.max()}')","metadata":{"execution":{"iopub.status.busy":"2021-08-11T18:53:40.298582Z","iopub.execute_input":"2021-08-11T18:53:40.299175Z","iopub.status.idle":"2021-08-11T18:53:40.75814Z","shell.execute_reply.started":"2021-08-11T18:53:40.29912Z","shell.execute_reply":"2021-08-11T18:53:40.756681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocessing\nfrom sklearn.preprocessing import scale\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\n\n#Classifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC \n\n# performance metrics\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.model_selection import cross_val_score","metadata":{"execution":{"iopub.status.busy":"2021-08-11T18:53:40.760215Z","iopub.execute_input":"2021-08-11T18:53:40.760827Z","iopub.status.idle":"2021-08-11T18:53:41.319106Z","shell.execute_reply.started":"2021-08-11T18:53:40.760776Z","shell.execute_reply":"2021-08-11T18:53:41.317545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df.drop(['Potability','ph'],axis=1)\ny = df['Potability'].values","metadata":{"execution":{"iopub.status.busy":"2021-08-11T18:57:31.646572Z","iopub.execute_input":"2021-08-11T18:57:31.646973Z","iopub.status.idle":"2021-08-11T18:57:31.6547Z","shell.execute_reply.started":"2021-08-11T18:57:31.646941Z","shell.execute_reply":"2021-08-11T18:57:31.653074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T18:57:33.992034Z","iopub.execute_input":"2021-08-11T18:57:33.992468Z","iopub.status.idle":"2021-08-11T18:57:34.010291Z","shell.execute_reply.started":"2021-08-11T18:57:33.992427Z","shell.execute_reply":"2021-08-11T18:57:34.009295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# k-NN classifier\n\n# Split into training and test set\nX_train , X_test , y_train , y_test=train_test_split(X , y , test_size=0.3 , random_state=1234, stratify= y )\n\n# Create a k-NN classifier with 7 neighbors\nknn = KNeighborsClassifier(n_neighbors=7)\n\n# Fit the classifier to the training data\nknn.fit(X_train, y_train)\n\n# Print the accuracy\nprint(knn.score(X_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2021-08-11T19:01:51.669512Z","iopub.execute_input":"2021-08-11T19:01:51.669937Z","iopub.status.idle":"2021-08-11T19:01:51.735257Z","shell.execute_reply.started":"2021-08-11T19:01:51.669901Z","shell.execute_reply":"2021-08-11T19:01:51.734227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we want to know the performance of the KNeighbors for testing and training result\nneighbors = np.arange(1, 12)\ntrain_accuracy = np.empty(len(neighbors))\ntest_accuracy = np.empty(len(neighbors))\n\nfor i, k in enumerate(neighbors):\n    # Train and test the model\n    knn = KNeighborsClassifier(n_neighbors=k)\n\n    # train the model\n    knn.fit(X_train, y_train)\n         \n    # compute the accuracy\n    train_accuracy[i] = knn.score(X_train, y_train)\n        \n    # compute the test\n    test_accuracy[i]=knn.score(X_test, y_test)\n    \n        \n# result\nplt.title('kNeighbors: Varying Number of Neighbors')\nplt.plot(neighbors , test_accuracy , label='Test_Acuracy')\nplt.plot(neighbors, train_accuracy , label='Train_Accuracy')\nplt.legend()\nplt.xlabel('number of neighbors')\nplt.ylabel('Accuracy')\nplt.show()\n# You can see the differences the number of the neighbors and also train and test of the KNeighbors and amount of the acuracy","metadata":{"execution":{"iopub.status.busy":"2021-08-11T18:53:41.470399Z","iopub.execute_input":"2021-08-11T18:53:41.471308Z","iopub.status.idle":"2021-08-11T18:53:43.46104Z","shell.execute_reply.started":"2021-08-11T18:53:41.471261Z","shell.execute_reply":"2021-08-11T18:53:43.460079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape,y_train.shape,X_test.shape,y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T18:53:43.462426Z","iopub.execute_input":"2021-08-11T18:53:43.463021Z","iopub.status.idle":"2021-08-11T18:53:43.47097Z","shell.execute_reply.started":"2021-08-11T18:53:43.462951Z","shell.execute_reply":"2021-08-11T18:53:43.469683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models=[]\nmodels.append(('LR ',LogisticRegression(random_state=12345)))\nmodels.append(('DT',DecisionTreeClassifier(random_state=12345)))\nmodels.append(('RF',RandomForestClassifier(random_state=12345)))\nmodels.append(('NN',MLPClassifier(random_state=12345)))\nmodels.append(('KN', KNeighborsClassifier()))\nmodels.append(('SVM',SVC(random_state=12345)))\n\n#value\nresult=[]\nname=[]","metadata":{"execution":{"iopub.status.busy":"2021-08-11T18:53:43.472889Z","iopub.execute_input":"2021-08-11T18:53:43.473324Z","iopub.status.idle":"2021-08-11T18:53:43.489644Z","shell.execute_reply.started":"2021-08-11T18:53:43.473288Z","shell.execute_reply":"2021-08-11T18:53:43.488134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# We want to find out what is the classification report and confusion matrix and when we use it:\n* Percision: measure the model performance on measuring the count of true positives in correct manner out of all positive predictions made.\n\n* Recall score :is used to measure the model performance in terms of measuring the count of true positives in correct manner out of all the actual positive values.\n\n* F1-score :is harmonic mean of precision and recall score and is used as a metrics in the scenarios where choosing either of precision or recall score can result in compromise in terms of model giving high false positives and false negatives respectively.\n\n*  Macro average gives each prediction similar weight while calculating loss but there might be case when your data might be imbalanced and you want to give importance to some prediction more (based on their proportion), there you use 'weighted' averag\n","metadata":{}},{"cell_type":"code","source":"# As you see, these are the result of making model( Random Forest has the highest percent among another )\nfor name , model in models:\n    model.fit(X_train, y_train)\n    predictions=model.predict(X_test)\n    accuracy=accuracy_score(y_test, predictions)\n    msg = \"%s: (%f)\" % (name, accuracy)\n    print(msg)\n    print(classification_report(y_test, predictions))\n    print(confusion_matrix(y_test, predictions))\n    ","metadata":{"execution":{"iopub.status.busy":"2021-08-11T19:09:55.838497Z","iopub.execute_input":"2021-08-11T19:09:55.838883Z","iopub.status.idle":"2021-08-11T19:09:58.165403Z","shell.execute_reply.started":"2021-08-11T19:09:55.838849Z","shell.execute_reply":"2021-08-11T19:09:58.164059Z"},"trusted":true},"execution_count":null,"outputs":[]}]}