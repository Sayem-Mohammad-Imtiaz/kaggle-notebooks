{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Prepare all our necessary libraries\nimport numpy as np \nimport pandas as pd \nimport os\nimport matplotlib.pyplot as plt\n\n#pytorch libraries\nimport torch\nfrom torch.utils.data import Dataset\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor, Pad, Compose,CenterCrop, ToPILImage, Normalize, ConvertImageDtype, Resize\n\nfrom torchvision.models import resnet50\nfrom torch import nn\nfrom torch.nn import init, Linear, ReLU, Softmax\nfrom torch.nn.init import xavier_uniform_\nfrom torch.optim import SGD, Adam\nimport torch.nn.functional as F\nfrom torch.nn.init import xavier_uniform_\nfrom seaborn import heatmap\nimport datetime\n\n# libs f√ºr AE\n\n!pip install cleverhans --upgrade\nfrom cleverhans.torch.attacks.projected_gradient_descent import projected_gradient_descent","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-20T13:32:05.997506Z","iopub.execute_input":"2021-07-20T13:32:05.997876Z","iopub.status.idle":"2021-07-20T13:32:15.785754Z","shell.execute_reply.started":"2021-07-20T13:32:05.997798Z","shell.execute_reply":"2021-07-20T13:32:15.78479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(\"You are using Device: \", device)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T13:32:15.78753Z","iopub.execute_input":"2021-07-20T13:32:15.787871Z","iopub.status.idle":"2021-07-20T13:32:15.835638Z","shell.execute_reply.started":"2021-07-20T13:32:15.787827Z","shell.execute_reply":"2021-07-20T13:32:15.834709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Prepare our Dataset Structure, as it has to be normalized for pytorch\n\nfrom torchvision.io import read_image\n\nclass GTSRB(Dataset):\n    def __init__(self, annotations_file, img_dir , transform=None, target_transform=None):\n        self.img_labels = pd.read_csv(annotations_file)[[\"Path\",\"ClassId\"]]\n        self.img_dir = img_dir\n        self.transform = transform\n        self.target_transform = target_transform\n\n    def __len__(self):\n        return len(self.img_labels)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n        label = self.img_labels.iloc[idx, 1]\n        image = read_image(img_path)\n        if self.transform:\n            image = self.transform(image)\n        if self.target_transform:\n            label = self.target_transform(label)\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2021-07-20T13:32:15.837875Z","iopub.execute_input":"2021-07-20T13:32:15.838575Z","iopub.status.idle":"2021-07-20T13:32:15.847587Z","shell.execute_reply.started":"2021-07-20T13:32:15.838535Z","shell.execute_reply":"2021-07-20T13:32:15.84677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_dir = \"/kaggle/input/gtsrb-german-traffic-sign/\"\ntest_file = \"/kaggle/input/gtsrb-german-traffic-sign/Test.csv\"\ntest_data = GTSRB(img_dir = img_dir, annotations_file = test_file,\n                  transform = Compose([Resize((30,30)), ConvertImageDtype(torch.float32)]))\nfrom torch.utils.data import DataLoader\ntest_dataloader = DataLoader(test_data)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-20T13:32:15.84912Z","iopub.execute_input":"2021-07-20T13:32:15.849661Z","iopub.status.idle":"2021-07-20T13:32:15.900177Z","shell.execute_reply.started":"2021-07-20T13:32:15.849624Z","shell.execute_reply":"2021-07-20T13:32:15.899371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display image and label.\ntest_features, test_labels = next(iter(test_dataloader))\nprint(f\"Feature batch shape: {test_features.size()}\")\nprint(f\"Labels batch shape: {test_labels.size()}\")\nimg = test_features[0]\nlabel = test_labels[0]\nimg = ToPILImage()(img).convert(\"RGB\")\nplt.imshow(img)\nplt.show()\nprint(f\"Label: {label}\")","metadata":{"execution":{"iopub.status.busy":"2021-07-20T13:32:15.901657Z","iopub.execute_input":"2021-07-20T13:32:15.901993Z","iopub.status.idle":"2021-07-20T13:32:16.118134Z","shell.execute_reply.started":"2021-07-20T13:32:15.901959Z","shell.execute_reply":"2021-07-20T13:32:16.117263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#downloading resent50 pretrained on ImageNet \n\n\n#adjust resnet50 to my dataset\nclass r50(nn.Module):\n    def __init__(self, pretrained_model):\n        super(r50,self).__init__()\n        self.rn50 = pretrained_model\n        self.fl1 = nn.Linear(1000, 256)\n        self.fl2 = nn.Linear(256,43)\n        \n    def forward(self, X):\n        X = self.rn50(X)\n        X = F.relu(self.fl1(X))\n        X = F.dropout(X, p=0.25)\n        X = self.fl2(X)\n        return X","metadata":{"execution":{"iopub.status.busy":"2021-07-20T13:32:16.11944Z","iopub.execute_input":"2021-07-20T13:32:16.119945Z","iopub.status.idle":"2021-07-20T13:32:16.126654Z","shell.execute_reply.started":"2021-07-20T13:32:16.119905Z","shell.execute_reply":"2021-07-20T13:32:16.125779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class conv_net(nn.Module):\n    def __init__(self):\n        super(conv_net,self).__init__()\n        self.conv1 = nn.Conv2d(3,32,(5,5))\n        self.conv2 = nn.Conv2d(32,64, (3,3))\n        self.pool = nn.MaxPool2d((2,2))\n        self.dropout1 = nn.Dropout(p=0.25)\n        self.conv3 = nn.Conv2d(64,3,(3,3))\n        self.linear1 = Linear(75,256)\n        self.dropout2 = nn.Dropout(p=0.5)\n        self.linear2 = Linear(256,43)\n\n        \n    def forward(self, X):\n        X = F.relu(self.conv1(X))\n        X = self.pool(F.relu(self.conv2(X)))\n        X = self.dropout1(X)\n        X = self.pool(F.relu(self.conv3(X)))\n        X = self.dropout1(X)\n        X = torch.flatten(X,1)\n        X = F.relu(self.linear1(X))\n        X = self.dropout2(X)\n        X = self.linear2(X)\n        \n        return X","metadata":{"execution":{"iopub.status.busy":"2021-07-20T13:32:16.129446Z","iopub.execute_input":"2021-07-20T13:32:16.129686Z","iopub.status.idle":"2021-07-20T13:32:16.140639Z","shell.execute_reply.started":"2021-07-20T13:32:16.129663Z","shell.execute_reply":"2021-07-20T13:32:16.139847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"SELECT YOUR MODEL HERE","metadata":{}},{"cell_type":"code","source":"alternative_model = True","metadata":{"execution":{"iopub.status.busy":"2021-07-20T13:32:16.144692Z","iopub.execute_input":"2021-07-20T13:32:16.144996Z","iopub.status.idle":"2021-07-20T13:32:16.150133Z","shell.execute_reply.started":"2021-07-20T13:32:16.144971Z","shell.execute_reply":"2021-07-20T13:32:16.148478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nif alternative_model:\n    model = conv_net()\n    PATH = '/kaggle/input/alternative-gtsrb/alt_gtsrb.pth'\n\nelse:\n    resn50 = resnet50(pretrained=True, progress = True)\n    model = r50(resn50)\n    PATH = '/kaggle/input/gtsrb/gtsrbX.pth'\n\nmodel.load_state_dict(torch.load(PATH, map_location=torch.device('cpu')))\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T13:32:16.152116Z","iopub.execute_input":"2021-07-20T13:32:16.152566Z","iopub.status.idle":"2021-07-20T13:32:16.175116Z","shell.execute_reply.started":"2021-07-20T13:32:16.152532Z","shell.execute_reply":"2021-07-20T13:32:16.17422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#put on cuda if possible\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(\"You are using Device: \", device)\nmodel.to(device)\ntest_features = test_features.to(device)\n# Export the model for translation purposes\nbatch_size= 1\ntorch.onnx.export(model,                     # model being run\n                  test_features,         # model input (or a tuple for multiple inputs)\n                  \"gtsrb.onnx\",   # where to save the model (can be a file or file-like object)\n                  export_params=True,        # store the trained parameter weights inside the model file\n                  opset_version=10,          # the ONNX version to export the model to\n                  do_constant_folding=True,  # whether to execute constant folding for optimization\n                  input_names = ['input'],   # the model's input names\n                  output_names = ['output'], # the model's output names\n                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n                                'output' : {0 : 'batch_size'}})\n\ntorch.save(test_data,\"/kaggle/working/test_data.pt\")\ntorch.save(test_data,\"/kaggle/working/test_data.h5\")\ntorch.save(test_data,\"/kaggle/working/test_data.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-07-20T13:32:16.176344Z","iopub.execute_input":"2021-07-20T13:32:16.176684Z","iopub.status.idle":"2021-07-20T13:32:21.416913Z","shell.execute_reply.started":"2021-07-20T13:32:16.176651Z","shell.execute_reply":"2021-07-20T13:32:21.416078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#AE Generator \n#look at some AEs\nae_generator = ((projected_gradient_descent(model.to(device),image.to(device), 0.05, 0.0075, 10,np.inf,  clip_min=0, clip_max=1 ).detach().to(device), label) for image, label in test_dataloader)\nfor i in range(3):\n    #print(next(ae_generator))\n    ae = next(ae_generator)\n    image = ToPILImage()(ae[0][0]).convert(\"RGB\")\n    plt.imshow(image)\n    plt.show()\n    print(ae[1])\n    ","metadata":{"execution":{"iopub.status.busy":"2021-07-20T13:32:21.420055Z","iopub.execute_input":"2021-07-20T13:32:21.42033Z","iopub.status.idle":"2021-07-20T13:32:22.01481Z","shell.execute_reply.started":"2021-07-20T13:32:21.420292Z","shell.execute_reply":"2021-07-20T13:32:22.013858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def heatmapping(cm):\n    precision = []\n    recall = []\n    class_count = []\n    for i in range(43):\n        precision.append(round(cm[i][i]/cm[i].sum(),2))\n        recall.append(round(cm[i][i]/cm[i].sum()))           \n        class_count.append(cm[i].sum())\n    metrics = pd.DataFrame({\"precision\" : precision, \"recall\" : recall, \"class_count\": class_count})\n    \n    plt.subplots(figsize=(20,15))\n    heatmap(cm)\n    return metrics","metadata":{"execution":{"iopub.status.busy":"2021-07-20T13:32:22.016354Z","iopub.execute_input":"2021-07-20T13:32:22.016748Z","iopub.status.idle":"2021-07-20T13:32:22.024723Z","shell.execute_reply.started":"2021-07-20T13:32:22.016706Z","shell.execute_reply":"2021-07-20T13:32:22.023156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = np.zeros((43,43))\npredictions = []\ntruth = []\nae_count = len(test_dataloader)-10\nepsilon = [0.2, 0.1,0.0925 ,0.085, 0.075, 0.065, 0.05, 0.025 ]\nmetrics = []\nfor eps in epsilon:\n    correct = 0\n    ae_generator = ((projected_gradient_descent(model.to(device),image.to(device),\n                                                eps, eps/10, 15 ,np.inf,  clip_min=0, clip_max=1 ).detach().to(device), label) for image, label in test_dataloader)\n    for i in range(ae_count):\n        ae = next(ae_generator)\n        image, label = ae[0].to(device), ae[1].to(device)\n\n        predicted = F.softmax(model(image), dim = 1).argmax()\n\n        predictions.append(predicted)\n        truth.append(label)\n        correct += (predicted == label)\n        cm[int(label)][int(predicted)] += 1\n\n    print('Accuracy of the network on the {tst_len} adversarial images with perturbation {e}: {acc}'.format(\n        acc= int(correct) / ae_count, tst_len = ae_count, e = eps))\n    metrics.append(heatmapping(cm))","metadata":{"execution":{"iopub.status.busy":"2021-07-20T13:32:22.026777Z","iopub.execute_input":"2021-07-20T13:32:22.027208Z","iopub.status.idle":"2021-07-20T13:35:44.230137Z","shell.execute_reply.started":"2021-07-20T13:32:22.027172Z","shell.execute_reply":"2021-07-20T13:35:44.227905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check accuracy on test set\ncorrect = 0\ntotal = 0\ncm = np.zeros((43,43))\npredictions = []\n\n# since we're not training, we don't need to calculate the gradients for our outputs\nwith torch.no_grad():\n    for data in test_dataloader:        \n        images, labels = data\n        images, labels = images.to(device), labels.to(device)\n            \n        output = model(images)\n        predicted = output.argmax()\n        predictions.append(predicted)\n        total += 1\n        correct += (predicted == labels)\n        cm[int(labels)][int(predicted)] += 1\n        \n\n\nprint('Accuracy of the network on the {tst_len} test images: {acc}'.format(\n    acc= int(correct) / int(total), tst_len=len(test_data)))\n","metadata":{"execution":{"iopub.status.busy":"2021-07-20T13:35:44.231307Z","iopub.status.idle":"2021-07-20T13:35:44.232048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f = open(\"/kaggle/working/metrics.csv\", 'a')\nfor df in metrics:\n    df.to_csv(f, decimal = \",\")\nf.close()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"precision: correctly predicted class A/predicted class A\n recall: number of correctly predicted class A photos out of the number of actual class A\n\nprecision = []\nrecall = []\nclass_count = []\nfor i in range(43):\n    precision.append(round(cm[i][i]/cm[i].sum(),2))\n    recall.append(round(cm[i][i]/cm[i].sum()))           \n    class_count.append(cm[i].sum())\nmetrics = pd.DataFrame({\"precision\" : precision, \"recall\" : recall, \"class_count\": class_count})\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-07-20T13:35:44.233417Z","iopub.status.idle":"2021-07-20T13:35:44.234171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"from seaborn import heatmap\nplt.subplots(figsize=(20,15))\nheatmap(cm)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-07-20T13:35:44.235575Z","iopub.status.idle":"2021-07-20T13:35:44.236436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"metrics\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-07-20T13:35:44.237754Z","iopub.status.idle":"2021-07-20T13:35:44.238469Z"},"trusted":true},"execution_count":null,"outputs":[]}]}