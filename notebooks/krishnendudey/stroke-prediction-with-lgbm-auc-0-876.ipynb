{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this notebook you will get to see the prediction of the probability of a person having stroke from the dataset given.The machine learning algorithm used to get the prediction is LightGBM with hyperparameter tuning and cross validation. <br>\nI hope you like the notebook, Happy Reading ;-D"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing the libraries \nimport pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \nimport seaborn as sns \nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To supress the warnings \nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading and Reading the Dataset\ndf=pd.read_csv(\"/kaggle/input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exploratory Data Analysis :"},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking missing values \ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking is the dataset is balanced or not \n\nK=df.stroke.value_counts(normalize=True)*100\nprint(\"Positive outcomes : {:.2f}% \\nNegative outcomes : {:.2f}%\".format(K[1],K[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.bar(['No','Yes'],df.stroke.value_counts()/df.shape[0]*100)\nplt.xlabel(\"Suffered Stroke (YES/NO)\")\nplt.ylabel(\"% of People\")\nplt.title(\"Check for Imbalance in target variable \")\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As seen from the above plot,the dataset is highly Imbalanced."},{"metadata":{},"cell_type":"markdown","source":"##### - Handling the work_type column:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking value counts for each work type\ndf.work_type.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking distribution for each work type\n\nplt.bar(list(df.work_type.unique()),df.work_type.value_counts())\nplt.xlabel(\"Work Type\")\nplt.ylabel(\"Number of People\")\nplt.title(\"Check for Imbalance in work_type variable \")\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As the median age of the entries whose work_type=Never_worked is 16 years and also as the upper quantile of the entries whose work_type= children is also 16 years so we are changing the work type of the entries with \"Never_worked\" and combining with the children column"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Quantiles : \\n{}\".format(df.loc[df.work_type=='children'].age.quantile([0.25,0.50,0.75,1.0])))\n\nprint(\"\\nNumber of entries whose work_type=children : \",df.loc[(df.work_type=='children')].age.count())\nprint(\"Number of teenagers whose work_type=children : \",df.loc[(df.work_type=='children')&(df.age>=13)&(df.age<=19)].age.count())\nprint(\"Median age of entries whose work_type=Never_worked : \",df.loc[df.work_type=='Never_worked'].age.median())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Replacing those rows of work_type==Never_worked to work_type==children, In short we are clubbing to unique type of worktype into one for the logical reason explained above"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in df.index:\n    if df.loc[i,\"work_type\"] =='Never_worked':\n        df.loc[i,\"work_type\"]='children'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.work_type.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### - Handling gender colums :"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.gender.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is only one record where the Gender=\"Other\" so with just one record it will not be a wise decision to predict anything as we always look for averaging stuffs so this 1 record would not help. So we better delete that"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[df.gender=='Other']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(df.loc[df.gender=='Other'].index,axis=0,inplace=True)\ndf.reset_index(drop=True,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape # Number of records has decreased by 1 as we deleted ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Target=df.stroke\nprint(len(Target))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### - Handling the columns with object datatype"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transforming categorical features into numerical ones \nfrom sklearn.preprocessing import LabelEncoder\nfor c in df.columns:\n    if df[c].dtype=='object': \n        lbl = LabelEncoder()\n        lbl.fit(list(df[c].values))\n        df[c] = lbl.transform(df[c].values)\n           \ndf.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### - Handling BMI column"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Handling the nan values in BMI columns\n\nWithoutBMI=df[df.bmi.isna()]         # The dataframe is constructed of the entries that have bmi as nan \n\nWithBMI=df[df.bmi.isna()==False]     # The dataframe is constructed of the entries that do not have bmi as nan \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"BMI varies with age so for every 10 year age range we are taking the median of the BMI's availbale in WithBMI dataframe and replacing the nan values with it in the dataframe(df) that have bmi=nan in that age range."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(WithBMI.age.max())\nAgeRanges=[(0,10),(10,20),(20,30),(30,40),(40,50),(50,60),(60,70),(70,80),(80,WithBMI.age.max())]\n\nReplacements=[]\nfor i in AgeRanges:\n    R1=WithBMI.loc[(WithBMI.age<i[1]) & (WithBMI.age>i[0])].bmi.median()\n    Replacements.append((R1)) \nReplacements","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replacing all the missing values with None\ndf.fillna(\"None\",inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in df.index:\n    if df.loc[i,\"age\"] <=10:\n        if df.loc[i,\"bmi\"]==\"None\":\n            df.loc[i,\"bmi\"]=Replacements[0]\n            \n    elif df.loc[i,\"age\"] in range(11,21):\n        if df.loc[i,\"bmi\"]==\"None\":\n            df.loc[i,\"bmi\"]=Replacements[1]\n            \n    elif df.loc[i,\"age\"] in range(21,31):\n        if df.loc[i,\"bmi\"]==\"None\":\n            df.loc[i,\"bmi\"]=Replacements[2]\n                    \n    elif df.loc[i,\"age\"] in range(31,41):\n        if df.loc[i,\"bmi\"]==\"None\":\n            df.loc[i,\"bmi\"]=Replacements[3]\n            \n            \n    elif df.loc[i,\"age\"] in range(41,51):\n        if df.loc[i,\"bmi\"]==\"None\":\n            df.loc[i,\"bmi\"]=Replacements[4]\n            \n            \n    elif df.loc[i,\"age\"] in range(51,61):\n        if df.loc[i,\"bmi\"]==\"None\":\n            df.loc[i,\"bmi\"]=Replacements[5]\n            \n        \n    elif df.loc[i,\"age\"] in range(61,71):\n        if df.loc[i,\"bmi\"]==\"None\":\n            df.loc[i,\"bmi\"]=Replacements[6]\n            \n            \n    elif df.loc[i,\"age\"] in range(71,81):\n        if df.loc[i,\"bmi\"]==\"None\":\n            df.loc[i,\"bmi\"]=Replacements[7]\n            \n    elif df.loc[i,\"age\"] in range(81,91):\n        if df.loc[i,\"bmi\"]==\"None\":\n            df.loc[i,\"bmi\"]=Replacements[8]\n            \n    \n            \ndf.bmi.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# all the missing values have been replaced with suitable substitutions\ndf.isnull().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As features with object datatypes can not be fed into the ML model so we are converting it into float datatype "},{"metadata":{"trusted":true},"cell_type":"code","source":"df.bmi=df.bmi.astype('float')\nprint(df.bmi.dtype)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model Building :"},{"metadata":{"trusted":true},"cell_type":"code","source":"Y=df.stroke                                           # Target \ndf.drop(['id','stroke'],axis=1,inplace=True)\nX=df                                                  # Features ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.3,train_size=0.7,stratify=Y,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Handling the data imbalance with SMOTE \n\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.over_sampling import SMOTE\nfrom collections import Counter\n\noversample=RandomOverSampler()\n\nX_train_sm,y_train_sm=oversample.fit_resample(X_train,y_train)\nCount1=Counter(y_train)\nCount2=Counter(y_train_sm)\nprint(\"Target counts before upsampling : {}\".format(Count1))\nprint(\"Target counts after upsampling : {}\".format(Count2))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Taking some of the best classifiers and without any Hyperparameter tuning trying to get the best classifier as a base  "},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing the Classifiers\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n\nlgbm=LGBMClassifier()\ncat=CatBoostClassifier(verbose = False)\nxgb=XGBClassifier()\nrf=RandomForestClassifier()\n\nmodels=[lgbm,cat,xgb,rf]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_auc_score\n\nRocAucScores=[]\nconfMatrix=[]\nfor i in models:\n    i.fit(X_train_sm,y_train_sm)\n    y_pred=i.predict_proba(X_test)[:,1]\n    RocAucScores.append(roc_auc_score(y_test,y_pred))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Printing roc_auc_score for all the classifier models we used \nprint(RocAucScores)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we saw LightGBM performed the best without any hyperparameter tuning so we would look to increase its auc score with hyperparamter tuning. We are using Optuna for that purpose"},{"metadata":{},"cell_type":"markdown","source":"Hyperparameter Tuning using optuna"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nimport lightgbm as lgb\ndef objective(trial,data=X_train_sm, target = y_train_sm):\n    #X_train,X_test,y_train,y_test = train_test_split(train,target,train_size=0.9)\n    dtrain = lgb.Dataset(X_train_sm, label=y_train_sm)\n    param = {\n        'objective': 'binary',\n        'metric': 'binary_logloss',\n        'verbosity': -1,\n        'boosting_type': 'gbdt',\n        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n        'num_leaves': trial.suggest_int('num_leaves', 2, 500),\n        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n        'min_child_samples': trial.suggest_int('min_child_samples', 3, 200),\n        'n_jobs' :-1\n    }\n    model = lgb.train(param,dtrain)\n    y_pred = model.predict(X_test)#[:,1]\n    pred_labels = np.rint(y_pred)\n    auc_roc_score = roc_auc_score(y_test,pred_labels)\n    return auc_roc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time \nimport optuna\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=100)\n# print('Number of finished trials:', len(study.trials))\n# print('Best trial:', study.best_trial.params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params=study.best_params \nparams['metric'] = 'roc_auc_score'\nparams","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Estimators=[50,60,70,80,100,120,150,180,200,210,220,250,300,400,500]\nEstimatorsAndScores=[]\nfor i in Estimators:\n    params['n_estimators']=i\n    LGBM = LGBMClassifier(**params)\n    LGBM.fit(X_train_sm,y_train_sm)\n    y_pred = LGBM.predict_proba(X_test)[:,1]\n    EstimatorsAndScores.append((i,metrics.roc_auc_score(y_test,y_pred)))\n    #target_names = [\"class 0 \",\"class 1\"]\n    #print(\"\\n\\n For Estimators = {} \\t  AUC Score : {} \\n\\n\".format(i,metrics.roc_auc_score(y_test,y_pred)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For having the best value for \"n_estimators\" parameter\ndef take2nd(elem):\n    return elem[1]\nBestEstimators=sorted(EstimatorsAndScores,key=take2nd,reverse=True)[0][0]\nparams['n_estimators']=BestEstimators\nparams","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm=LGBMClassifier(**params) \nlgbm.fit(X_train_sm,y_train_sm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred2=lgbm.predict_proba(X_test)[:,1]\ny_pred2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Before cross validation \nprint(\"The AUC score before Hyperparameter tuning : {} \".format(roc_auc_score(y_test,y_pred)))\nprint(\"The AUC score after Hyperparameter tuning : {} \".format(roc_auc_score(y_test,y_pred2)))\nprint(\"Improvement after Hyperparameter Tuning : {}\".format((roc_auc_score(y_test,y_pred2))-(roc_auc_score(y_test,y_pred))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Improving the results further we are using StratifiedKFold"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nSEED = 1024\nN_SPLITS =5\nkfold = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i=1\npred_test_full =0\nmax_auc = 0 \nlgbmodel=LGBMClassifier(**params) \nfor train_idx,test_idx in kfold.split(X,Y): \n    print(' Running {} of KFold {}'.format(i,kfold.n_splits)) \n    xtr,xvl = X.loc[train_idx],X.loc[test_idx] \n    ytr,yvl = Y.loc[train_idx],Y.loc[test_idx] \n    lgbmodel.fit(xtr,ytr) \n    score = roc_auc_score(yvl,lgbmodel.predict_proba(xvl)[:,1])\n    print('\\nROC AUC score: {}\\n\\n'.format(score))\n    pred_test = lgbmodel.predict_proba(X_test)[:,1]\n    pred_test_full +=pred_test\n    i+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred3=pred_test_full\ny_pred3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# After Hyperparameter tuning and cross validation, we get a score of \nroc_auc_score(y_test,y_pred3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The AUC score before Hyperparameter tuning : {} \".format(roc_auc_score(y_test,y_pred)))\nprint(\"The AUC score after Hyperparameter tuning : {} \".format(roc_auc_score(y_test,y_pred2)))\nprint(\"The AUC score after Hyperparameter tuning & cross validation : {} \".format(roc_auc_score(y_test,y_pred3)))\nprint(\"Improvement after Hyperparameter Tuning : {}\".format((roc_auc_score(y_test,y_pred2))-(roc_auc_score(y_test,y_pred))))\nprint(\"Improvement after cross validation : {}\".format((roc_auc_score(y_test,y_pred3))-(roc_auc_score(y_test,y_pred2))))\nprint(\"\\nOverall Improvement after using Hyperparameter tuning and cross validation from the base model : {}\".format((roc_auc_score(y_test,y_pred3))-(roc_auc_score(y_test,y_pred))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h4 align=\"center\"> ..._/\\_ Thank You _/\\_...</h4>"},{"metadata":{},"cell_type":"markdown","source":"If the Notebook was good enough then kindly support me with an upvote :-D<br>\nIf you want to share your opinion or have any suggestions do let me know in the comments ;-D"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}