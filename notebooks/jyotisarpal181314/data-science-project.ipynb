{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\nplt.rcParams['figure.figsize'] = (10, 7)\n\n# Warnings\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.read_csv('../input/india-air-quality-data/data.csv',encoding=\"ISO-8859-1\")\ndata.fillna(0, inplace=True)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_si(so2):\n    si=0\n    if (so2<=40):\n     si= so2*(50/40)\n    if (so2>40 and so2<=80):\n     si= 50+(so2-40)*(50/40)\n    if (so2>80 and so2<=380):\n     si= 100+(so2-80)*(100/300)\n    if (so2>380 and so2<=800):\n     si= 200+(so2-380)*(100/800)\n    if (so2>800 and so2<=1600):\n     si= 300+(so2-800)*(100/800)\n    if (so2>1600):\n     si= 400+(so2-1600)*(100/800)\n    return si\ndata['si']=data['so2'].apply(calculate_si)\ndf= data[['so2','si']]\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_ni(no2):\n    ni=0\n    if(no2<=40):\n     ni= no2*50/40\n    elif(no2>40 and no2<=80):\n     ni= 50+(no2-14)*(50/40)\n    elif(no2>80 and no2<=180):\n     ni= 100+(no2-80)*(100/100)\n    elif(no2>180 and no2<=280):\n     ni= 200+(no2-180)*(100/100)\n    elif(no2>280 and no2<=400):\n     ni= 300+(no2-280)*(100/120)\n    else:\n     ni= 400+(no2-400)*(100/120)\n    return ni\ndata['ni']=data['no2'].apply(calculate_ni)\ndf= data[['no2','ni']]\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Function to calculate no2 individual pollutant index(rpi)\ndef calculate_(rspm):\n    rpi=0\n    if(rpi<=30):\n     rpi=rpi*50/30\n    elif(rpi>30 and rpi<=60):\n     rpi=50+(rpi-30)*50/30\n    elif(rpi>60 and rpi<=90):\n     rpi=100+(rpi-60)*100/30\n    elif(rpi>90 and rpi<=120):\n     rpi=200+(rpi-90)*100/30\n    elif(rpi>120 and rpi<=250):\n     rpi=300+(rpi-120)*(100/130)\n    else:\n     rpi=400+(rpi-250)*(100/130)\n    return rpi\ndata['rpi']=data['rspm'].apply(calculate_si)\ndf= data[['rspm','rpi']]\ndf.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Function to calculate no2 individual pollutant index(spi)\ndef calculate_spi(spm):\n    spi=0\n    if(spm<=50):\n     spi=spm\n    if(spm<50 and spm<=100):\n     spi=spm\n    elif(spm>100 and spm<=250):\n     spi= 100+(spm-100)*(100/150)\n    elif(spm>250 and spm<=350):\n     spi=200+(spm-250)\n    elif(spm>350 and spm<=450):\n     spi=300+(spm-350)*(100/80)\n    else:\n     spi=400+(spm-430)*(100/80)\n    return spi\ndata['spi']=data['spm'].apply(calculate_spi)\ndf= data[['spm','spi']]\ndf.tail()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#function to calculate the air quality index (AQI) of every data value\ndef calculate_aqi(si,ni,spi,rpi):\n    aqi=0\n    if(si>ni and si>spi and si>rpi):\n     aqi=si\n    if(spi>si and spi>ni and spi>rpi):\n     aqi=spi\n    if(ni>si and ni>spi and ni>rpi):\n     aqi=ni\n    if(rpi>si and rpi>ni and rpi>spi):\n     aqi=rpi\n    return aqi\ndata['AQI']=data.apply(lambda x:calculate_aqi(x['si'],x['ni'],x['spi'],x['rpi']),axis=1)\ndf= data[['sampling_date','state','si','ni','rpi','spi','AQI']]\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.state.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"state=pd.read_csv(\"../input/indianstateslatlong/LatLong.csv\")\nstate.head()\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dff=pd.merge(state.set_index(\"State\"),df.set_index(\"state\"), right_index=True, left_index=True).reset_index()\ndff.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from mpl_toolkits.basemap import Basemap\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\n%config InlineBackend.figure_format = 'retina'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m = Basemap(projection='mill',llcrnrlat=5,urcrnrlat=40, llcrnrlon=60,urcrnrlon=110,lat_ts=20,resolution='c')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"longitudes = dff[\"Longitude\"].tolist()\nlatitudes = dff[\"Latitude\"].tolist()\nx,y = m(longitudes,latitudes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(12,10))\nplt.title(\"All affected areas\")\nm.plot(x, y, \"o\", markersize = 3, color = 'blue')\nm.drawcoastlines()\nm.fillcontinents(color='coral',lake_color='aqua')\nm.drawmapboundary()\nm.drawcountries()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['date'] = pd.to_datetime(data['date'],format='%Y-%m-%d') # date parse\ndata['year'] = data['date'].dt.year # year\ndata['year'] = data['year'].fillna(0.0).astype(int)\ndata = data[(data['year']>0)]\n\ndf = data[['AQI','year','state']].groupby([\"year\"]).median().reset_index().sort_values(by='year',ascending=False)\nf,ax=plt.subplots(figsize=(15,10))\nsns.pointplot(x='year', y='AQI', data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#setting up date parameter\nimport warnings\nimport itertools\nimport dateutil\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nimport seaborn as sns\n%matplotlib inline\ndf=data[['AQI','date']]\ndf[\"date\"] = pd.to_datetime(df['date'])\ndf.tail(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df.set_index('date').resample('M')[\"AQI\"].mean()\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=df.reset_index(level=0, inplace=False)\ndata = data[np.isfinite(data['AQI'])]\ndata=data[data.date != '1970-01-31']\ndata = data.reset_index(drop=True)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=data.set_index('date')\ndf.sort_values(by='date',ascending=False)\ndf.plot(figsize=(15, 6))\nplt.show()\ny=df.AQI","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#spliting dataframes into test and train\nn = df.shape[0]\ntrain_size = 0.65\n\nfeatures_dataframe = df.sort_values('date')\ntrain = df.iloc[:int(n * train_size)]\ntest = df.iloc[int(n * train_size):]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotting the yearly variations of AQI\n\ntrain.AQI.plot(figsize=(15,8), title= 'YEARLY VARIATIONS', fontsize=14)\ntest.AQI.plot(figsize=(15,8), title= 'YEARLY VARIATIONS', fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Naive Forecast Approach to find the variations(trend)\n\ndd= np.asarray(train.AQI)\ny_hat = test.copy()\ny_hat['naive'] = dd[len(dd)-1]\nplt.figure(figsize=(12,8))\nplt.plot(train.index, train['AQI'], label='Train')\nplt.plot(test.index,test['AQI'], label='Test')\nplt.plot(y_hat.index,y_hat['naive'], label='Naive Forecast')\nplt.legend(loc='best')\nplt.title(\"Naive Forecast\",fontsize=20)\n\nplt.legend([\"actual \",\"predicted\"])\nplt.xlabel(\"YEAR\",fontsize=20)\nplt.ylabel(\"AQI\",fontsize=20)\nplt.tick_params(labelsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=data[['AQI','date']]\n\ndf['date']=pd.to_datetime(df['date'])\ndate=df.groupby(pd.Grouper(key='date',freq='1MS'))[\"AQI\"].mean()\ndf.count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['month'] = data['date'].dt.month\ndata['year'] = data['date'].dt.year\ndata=data[['AQI','date','month','year']]\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predicting JANUARY-AQI across india\ndata=data[data['month']==1]\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Appling BOXPLOT analysis\ndf = data[['AQI','year']].groupby([\"year\"]).mean().reset_index().sort_values(by='year',ascending=False)\ndf=df.dropna()\ndd=df\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.boxplot(x=df['AQI'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[np.isfinite(df['AQI'])]\ndf=df[df.AQI >153]\ndf=df[df.AQI <221]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nyear=df['year'].values\nAQI=df['AQI'].values\ndf['AQI']=pd.to_numeric(df['AQI'],errors='coerce')\ndf['year']=pd.to_numeric(df['year'],errors='coerce')\n\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = (20.0, 10.0)\nfrom mpl_toolkits.mplot3d import Axes3D\nfig = plt.figure()\nax = Axes3D(fig)\nax.scatter(year,AQI, color='red')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#scatter plot of data points\ncols =['year']\ny = df['AQI']\nx=df[cols]\n\nplt.scatter(x,y)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = (x - x.mean()) / x.std()\nx = np.c_[np.ones(x.shape[0]), x]\nx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nalpha = 0.1 #Step size\niterations = 3000 #No. of iterations\nm = y.size #No. of data points\nnp.random.seed(4) #Setting the seed\ntheta = np.random.rand(2) #Picking random values to start with\n\ndef gradient_descent(x, y, theta, iterations, alpha):\n    past_costs = []\n    past_thetas = [theta]\n    for i in range(iterations):\n        prediction = np.dot(x, theta)\n        error = prediction - y\n        cost = 1/(2*m) * np.dot(error.T, error)\n        past_costs.append(cost)\n        theta = theta - (alpha * (1/m) * np.dot(x.T, error))\n        past_thetas.append(theta)\n    return past_thetas, past_costs\npast_thetas, past_costs = gradient_descent(x, y, theta, iterations, alpha)\ntheta = past_thetas[-1]\n\n#Printing the results...\nprint(\"Gradient Descent: {:.2f}, {:.2f}\".format(theta[0], theta[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting the cost function...\nplt.title('Cost Function J')\nplt.xlabel('No. of iterations')\nplt.ylabel('Cost')\nplt.plot(past_costs)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"newB=[ 200.17, -1.54]\ndef rmse(y,y_pred):\n    rmse=np.sqrt(sum(y-y_pred))\n    return rmse\n\n   \ny_pred=x.dot(newB)\n\ndt = pd.DataFrame({'Actual': y, 'Predicted': y_pred})  \nx=pd.concat([df, dt], axis=1)\nx\nx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#calculating the root mean squared error for the predicted AQi values\nfrom sklearn import metrics\nprint(np.sqrt(metrics.mean_squared_error(y,y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_axis=x.year\ny_axis=x.Actual\ny1_axis=x.Predicted\nplt.plot(x_axis,y_axis)\nplt.plot(x_axis,y1_axis)\nplt.title(\"Actual vs Predicted\",fontsize=20)\nplt.legend([\"actual \",\"predicted\"])\nplt.xlabel(\"YEAR\",fontsize=20)\nplt.ylabel(\"AQI\",fontsize=20)\nplt.tick_params(labelsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#improving the accuracy by splitting the data on heavy variations\n\ndf=dd[['year','AQI']]\n\n\n#huge variations aqi accures on year 2009-2010 (by moving average graph)\ndf=df[df.year<2011]\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.boxplot(x=df['AQI'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#removing outliers\ndf = df[np.isfinite(df['AQI'])]\ndf=df[df.AQI >200]\ndf=df[df.AQI <226]\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotting data points\ncols =['year']\ny = df['AQI']\nx=df[cols]\n\nplt.scatter(x,y)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = (x - x.mean()) / x.std()\nx = np.c_[np.ones(x.shape[0]), x]\nx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Tunning model with GRADIENT DESCENT\n\nalpha = 0.1 #Step size\niterations = 3000 #No. of iterations\nm = y.size #No. of data points\nnp.random.seed(4) #Setting the seed\ntheta = np.random.rand(2) #Picking some random values to start with\n\ndef gradient_descent(x, y, theta, iterations, alpha):\n    past_costs = []\n    past_thetas = [theta]\n    for i in range(iterations):\n        prediction = np.dot(x, theta)\n        error = prediction - y\n        cost = 1/(2*m) * np.dot(error.T, error)\n        past_costs.append(cost)\n        theta = theta - (alpha * (1/m) * np.dot(x.T, error))\n        past_thetas.append(theta)\n        \n    return past_thetas, past_costs\n\npast_thetas, past_costs = gradient_descent(x, y, theta, iterations, alpha)\ntheta = past_thetas[-1]\n#Print the results...\nprint(\"Gradient Descent: {:.2f}, {:.2f}\".format(theta[0], theta[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting the cost function...\nplt.title('Cost Function J')\nplt.xlabel('No. of iterations')\nplt.ylabel('Cost')\nplt.plot(past_costs)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predicting january(1988-2009) AQI across india\n\nimport numpy as np\nnewB=[ 214.47, 1.18]\n\ndef rmse(y,y_pred):\n    rmse= (np.sqrt(np.mean((y-y_pred)**2)))\n    return rmse\n   \ny_pred=x.dot(newB)\ndt = pd.DataFrame({'Actual': y, 'Predicted': y_pred})  \nx=pd.concat([df, dt], axis=1)\nx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn import metrics\nprint(np.sqrt(metrics.mean_squared_error(y,y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_axis=x.year\ny_axis=x.Actual\ny1_axis=x.Predicted\nplt.plot(x_axis,y_axis)\nplt.plot(x_axis,y1_axis)\nplt.title(\"Actual vs Predicted\",fontsize=20)\nplt.legend([\"actual \",\"predicted\"])\nplt.xlabel(\"YEAR\",fontsize=20)\nplt.ylabel(\"AQI\",fontsize=20)\nplt.tick_params(labelsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#improving the accuracy by splitting the data on heavy variations\n\ndf= dd[['year','AQI']]\n\n#huge variations aqi accures on year 2009-2010 (by moving average graph)\ndf=df[df.year>2010]\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.boxplot(x=df['AQI'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[np.isfinite(df['AQI'])]\ndf=df[df.AQI >101]\ndf=df[df.AQI <107]\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols =['year']\ny = df['AQI']\nx=df[cols]\n\nplt.scatter(x,y)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = (x - x.mean()) / x.std()\nx = np.c_[np.ones(x.shape[0]), x]\nx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nalpha = 0.1 #Step size\niterations = 3000 #No. of iterations\nm = y.size #No. of data points\nnp.random.seed(4) #Setting the seed\ntheta = np.random.rand(2) #Picking some random values to start with\n\ndef gradient_descent(x, y, theta, iterations, alpha):\n    past_costs = []\n    past_thetas = [theta]\n    for i in range(iterations):\n        prediction = np.dot(x, theta)\n        error = prediction - y\n        cost = 1/(2*m) * np.dot(error.T, error)\n        past_costs.append(cost)\n        theta = theta - (alpha * (1/m) * np.dot(x.T, error))\n        past_thetas.append(theta)\n        \n    return past_thetas, past_costs\n\npast_thetas, past_costs = gradient_descent(x, y, theta, iterations, alpha)\ntheta = past_thetas[-1]\n\n#Print the results...\nprint(\"Gradient Descent: {:.2f}, {:.2f}\".format(theta[0], theta[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting the cost function...\nplt.title('Cost Function J',fontsize=28)\nplt.xlabel('No. of iterations',fontsize=25)\nplt.ylabel('Cost',fontsize=25)\nplt.plot(past_costs)\nplt.tick_params(labelsize=30)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#prediction of january(2013-2015) across india\nimport numpy as np\nnewB=[ 103.59, -2.74]\n\ndef rmse(y,y_pred):\n    rmse= np.sqrt(sum(y-y_pred))\n    return rmse\n   \ny_pred=x.dot(newB)\n\ndt = pd.DataFrame({'Actual': y, 'Predicted': y_pred})  \nx=pd.concat([df, dt], axis=1)\nx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#testing the accuracy of the model\n\nfrom sklearn import metrics\nprint(np.sqrt(metrics.mean_squared_error(y,y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotting the actual and predicted results\nx_axis=x.year\ny_axis=x.Actual\ny1_axis=x.Predicted\nplt.plot(x_axis,y_axis)\nplt.plot(x_axis,y1_axis)\nplt.title(\"Actual vs Predicted\",fontsize=20)\nplt.legend([\"actual \",\"predicted\"])\nplt.xlabel(\"YEAR\",fontsize=20)\nplt.ylabel(\"AQI\",fontsize=20)\nplt.tick_params(labelsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Prediction for the future \nfrom sklearn.preprocessing import MinMaxScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#feeding in the x value-years\ndata=[[-1,2016],[-1,2017],[-1,2018],[-1,2019],[-1,2020]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#normalization\nscaler=MinMaxScaler(feature_range=(-1,1))\nscaler.fit(data)\nx=scaler.transform(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#calculations\nnewB=[103.59,-2.74]\nypred=-(x.dot(newB))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#AQI for the year 2020\nprint(\"AQI for the year 2020===>\",ypred[-1])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}