{"cells":[{"metadata":{"id":"tITYjrdvyZVI"},"cell_type":"markdown","source":"#Categorising the IMDB rating into 3 classes Hit,Avg,Flop\nHere I have dataset named movie_metadata in which the target variable is IMDB score and other variables that decide the IMDB score. Instead of just IMDB score,With the help of other parameters I want to predict whether a movie is Hit,Avg or Flop.\n\n\n\n|imdb_score | Classify |\n| --- | ---|\n|1-3 | Flop Movie|\n|3-6 | Average Movie|\n|6-10 | Hit Movie|\n","execution_count":null},{"metadata":{"id":"yMTKK9GM6cQ9"},"cell_type":"markdown","source":"# 1 INTRODUCTION\n","execution_count":null},{"metadata":{"id":"GQ9myKeWyBdT"},"cell_type":"markdown","source":"## 1.1 Background\n\n\nSuccess of a movie depends upon alot of factors like good directors or excellent actors or story plotline.However, famous directors and actors can always bring an expected box-office income but cannot guarantee a highly rated imdb score.\n\n","execution_count":null},{"metadata":{"id":"UveLsKUXyBqK"},"cell_type":"markdown","source":"## 1.2 Describing Data\n\nThe dataset contains 28 variables for 5043 movies, spanning across 100 years in 66 countries. There are 2399 unique director names, and thousands of actors/actresses. “imdb_score” is the response variable while the other 27 variables are possible predictors.","execution_count":null},{"metadata":{"id":"zJ_UlIb8yBv3"},"cell_type":"markdown","source":"|Variable Name |\tDescription|\n| --- | --- |\n|movie_title\t | Title of the Movie|\n|duration\t| Duration in minutes|\n|director_name\t| Name of the Director of the Movie|\n|director_facebook_likes |\tNumber of likes of the Director on his Facebook Page|\n|actor_1_name |\tPrimary actor starring in the movie|\n|actor_1_facebook_likes |\tNumber of likes of the Actor_1 on his/her Facebook Page|\n|actor_2_name |\tOther actor starring in the movie|\n|actor_2_facebook_likes\t| Number of likes of the Actor_2 on his/her Facebook Page|\n|actor_3_name |\tOther actor starring in the movie|\n|actor_3_facebook_likes |\tNumber of likes of the Actor_3 on his/her Facebook Page|\n|num_user_for_reviews |\tNumber of users who gave a review|\n|num_critic_for_reviews |\tNumber of critical reviews on imdb|\n|num_voted_users | \tNumber of people who voted for the movie|\n|cast_total_facebook_likes |\tTotal number of facebook likes of the entire cast of the movie|\n|movie_facebook_likes |\tNumber of Facebook likes in the movie page|\n|plot_keywords |\tKeywords describing the movie plot|\n|facenumber_in_poster |\tNumber of the actor who featured in the movie poster|\n|color |\tFilm colorization. ‘Black and White’ or ‘Color’|\n|genres |\tFilm categorization like ‘Animation’, ‘Comedy’, ‘Romance’, ‘Horror’, ‘Sci-Fi’, ‘Action’, ‘Family’|\n|title_year |\tThe year in which the movie is released (1916:2016)|\n|language |\tEnglish, Arabic, Chinese, French, German, Danish, Italian, Japanese etc|\n|country |\tCountry where the movie is produced|\n|content_rating |\tContent rating of the movie|\n|aspect_ratio |\tAspect ratio the movie was made in|\n|movie_imdb_link |\tIMDB link of the movie|\n|gross |\tGross earnings of the movie in Dollars|\n|budget |\tBudget of the movie in Dollars|\n|imdb_score |\tIMDB Score of the movie on IMDB|","execution_count":null},{"metadata":{"id":"zqUdPqTTqF5C"},"cell_type":"markdown","source":"Lets see which features influence the target varible(IMDB Score)","execution_count":null},{"metadata":{"id":"_asnnbcm7Eff"},"cell_type":"markdown","source":"# 2 DATA EXPLORATION","execution_count":null},{"metadata":{"id":"wswrtl4jPN6Y"},"cell_type":"markdown","source":"## 2.1 Importing necessary Libraries\n","execution_count":null},{"metadata":{"id":"0Pu9vNn_ayuz","outputId":"ffc479bf-f88d-42dc-9a4a-bf72c826cc28","trusted":true},"cell_type":"code","source":"#Importing necessary Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"id":"Is7Ix5HJa9p_","outputId":"9b5fab29-808c-4539-8594-f10479cf8516","trusted":true},"cell_type":"code","source":"#Reading the dataset\ndata=pd.read_csv('../input/imdb-5000-movie-dataset/movie_metadata.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"uront9NnLvii"},"cell_type":"markdown","source":"## 2.2 Categorizing the target varible \n\nHere we are categorizing the target variable in such a way that IMDB score between 1 and 3 is FLOP , between 3 and 6 is AVG, between 6 and 10 is HIT.\n\nAnd we are using binning in pandas to acheive this.\n","execution_count":null},{"metadata":{"id":"Cu6eK6NKbOQG","trusted":true},"cell_type":"code","source":"#Categorising the target varible \nbins = [ 1, 3, 6, 10]\nlabels = ['FLOP', 'AVG', 'HIT']\ndata['imdb_binned'] = pd.cut(data['imdb_score'], bins=bins, labels=labels)","execution_count":null,"outputs":[]},{"metadata":{"id":"RZ8j4QKkgdrJ"},"cell_type":"markdown","source":" Barplot of imbd_binned column","execution_count":null},{"metadata":{"id":"00kv3hDogEik","outputId":"2d5721e2-7049-41a0-fc10-3452f1f8a95d","trusted":true},"cell_type":"code","source":"data.groupby(['imdb_binned']).size().plot(kind=\"bar\",fontsize=14)\nplt.xlabel('Categories')\nplt.ylabel('Number of Movies')\nplt.title('Categorization of Movies')","execution_count":null,"outputs":[]},{"metadata":{"id":"4Pu6SF-CLDz5"},"cell_type":"markdown","source":"We can see a new column named imdb_binned correctly categorising the imdb score\n","execution_count":null},{"metadata":{"id":"SbHOvcgBb-1d","outputId":"bf032e7e-37b1-47d3-9e84-426810f445c8","trusted":true},"cell_type":"code","source":"#Checking the new column\ndata.head(5)","execution_count":null,"outputs":[]},{"metadata":{"id":"_DuDeTQ4UyPF"},"cell_type":"markdown","source":"Our dataset contains 5043 samples(rows) and 28 variables(columns)","execution_count":null},{"metadata":{"id":"AYupTKGYcHAU","outputId":"b95627fc-2b0b-4b56-ad72-5e62838752f4","trusted":true},"cell_type":"code","source":"#Shape of the dataset\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.3 Handling the Missing values\n\nEvery datset have some missing values, lets find out in which cloumns they are?","execution_count":null},{"metadata":{"id":"qV_9xy_ycXzB","outputId":"1b9c8b4a-2959-440b-d048-18c9f60c4808","trusted":true},"cell_type":"code","source":"#Total null values present in each column\ndata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"id":"nIAtAwObWvwj"},"cell_type":"markdown","source":"Dropping all the samples that having missing values\n","execution_count":null},{"metadata":{"id":"oYHzP76_cd_s","trusted":true},"cell_type":"code","source":"#Droping the samples that have missing values\ndata.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"UubAN0YoW-mK"},"cell_type":"markdown","source":"Total samples remaining after dropping missing values\n","execution_count":null},{"metadata":{"id":"d2_jHPwgcg5W","outputId":"c5343e56-bc36-4652-efc2-4f7ccb52e670","trusted":true},"cell_type":"code","source":"#Final shape of the data after Droping missing values\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"lw1VJ07JcifK","outputId":"f2b1bdd7-2bff-467b-cb47-31ec6a57b33e","trusted":true},"cell_type":"code","source":"#List of variables in the datset\ndata.columns","execution_count":null,"outputs":[]},{"metadata":{"id":"eL09qqAD-PfW","outputId":"8bffa724-4bad-4e4e-99a2-3b2044a328d0","trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets find out how the string variables are behaving","execution_count":null},{"metadata":{"id":"mDhyXZ7PL2Z7","outputId":"1addd9ad-49ca-448f-a0e6-f922eed82913","trusted":true},"cell_type":"code","source":"#Describing the categorical data\ndata.describe(include='object')","execution_count":null,"outputs":[]},{"metadata":{"id":"9UqaybAdz_c_"},"cell_type":"markdown","source":"'movie_title','movie_imdb_link' columns are almost unique,so they doesn't contribute in predicting target variable","execution_count":null},{"metadata":{"id":"adsg3H6Nz_3p","trusted":true},"cell_type":"code","source":"#Dropping 2 columns\ndata.drop(columns=['movie_title','movie_imdb_link'],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"hc7v-_TmXdsL"},"cell_type":"markdown","source":"## 2.4 Label Encoding\n\nAll the categorical columns and the columns with text data are being Label Encodeded in this step.","execution_count":null},{"metadata":{"id":"Ymr1_JW0cih_","trusted":true},"cell_type":"code","source":"#Label encoding the categorical columns\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ncat_list=['color', 'director_name', 'actor_2_name',\n        'genres', 'actor_1_name',\n        'actor_3_name',\n        'plot_keywords',\n        'language', 'country', 'content_rating',\n       'title_year', 'aspect_ratio']\ndata[cat_list]=data[cat_list].apply(lambda x:le.fit_transform(x))","execution_count":null,"outputs":[]},{"metadata":{"id":"sYkknNcEcinJ","outputId":"b3bae2a8-2400-4970-98b9-fc3ecbb64cf6","trusted":true},"cell_type":"code","source":"#A sample of data after label encoding\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"MXFyaJpRX_t6"},"cell_type":"markdown","source":"## 2.5 Correlation\n\nTo find out whether there is any relation between variables, in other terms multicollineariaty.\n\n","execution_count":null},{"metadata":{"id":"ipvQqmWuci_P","outputId":"f3abb1b3-890a-48a1-c2cd-31638f3ab65d","trusted":true},"cell_type":"code","source":"#Finding Correlation between variables\ncorr = data.corr()\nmask = np.zeros(corr.shape, dtype=bool)\nmask[np.triu_indices(len(mask))] = True\nplt.subplots(figsize=(20,15))\nsns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns,cmap='RdYlGn',annot=True,mask = mask)","execution_count":null,"outputs":[]},{"metadata":{"id":"CHV6DdhBZRiv"},"cell_type":"markdown","source":"These variables that are correlated cause errors in the prediction, so removing them\n","execution_count":null},{"metadata":{"id":"fVd68GNMkYoL","trusted":true},"cell_type":"code","source":"#Removing few columns due to multicollinearity\ndata.drop(columns=['cast_total_facebook_likes','num_critic_for_reviews'],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"ek4QNCrm0Z58"},"cell_type":"markdown","source":"Removing the column \"imdb_score\" since we have \"imdb_binned\n\nI am gonna train the model with imdb_binned not with imdb_score so dropping the column.\n","execution_count":null},{"metadata":{"id":"SIxIcmAvzcPI","trusted":true},"cell_type":"code","source":"#Removing the column \"imdb_score\" since we have \"imdb_binned\"\ndata.drop(columns=['imdb_score'],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"-uZLoAnwcjJO","outputId":"ce680e2a-4684-46cc-9bb6-f01071556461","trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"r__-AMG08zKa"},"cell_type":"markdown","source":"# 3 CLASSIFICATION MODEL BUILDING","execution_count":null},{"metadata":{"id":"5yRAmtM1aNVO"},"cell_type":"markdown","source":"Splitting the data into X and y where X contains Indepentent variables and y contain Target/Dependent variable.\n","execution_count":null},{"metadata":{"id":"g01XPGExcjNC","outputId":"64142935-457a-4d15-8264-a694576c79ed","trusted":true},"cell_type":"code","source":"#Independent Variables\nX = data.iloc[:, 0:23].values\n#Dependent/Target Variable\ny = data.iloc[:, 23].values\ny","execution_count":null,"outputs":[]},{"metadata":{"id":"TNlmQcB8aMrQ"},"cell_type":"markdown","source":"## 3.1 Train Test Split\n\nWe need data not only to train our model but also to test our model. So splitting the dataset into 70:30 (Train:Test) ratio.We have a predefined a function in Sklearn library called test_train_split, lets use that.","execution_count":null},{"metadata":{"id":"5tROd04FcjUN","outputId":"64901b9e-ee26-42d1-962a-57757b31c1b2","trusted":true},"cell_type":"code","source":"#Spliting the data into train and test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0,stratify = y)\nprint(X_train.shape)\nprint(y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"aHU4HSv-bYMT"},"cell_type":"markdown","source":"## 3.2 Scaling\n\nFew variables will be in the range of Millions and some in Tens, lets bring all of them into same scale\n","execution_count":null},{"metadata":{"id":"JRI6LfyLcjYU","trusted":true},"cell_type":"code","source":"#Scaling the dependent variables\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"RCF9IHoxb2wI"},"cell_type":"markdown","source":"## 3.4 Feature Selection using RFECV\n\n","execution_count":null},{"metadata":{"id":"-LNox6E1Wpd1"},"cell_type":"markdown","source":"Finding optimal features to use for Machine learning model training can sometimes be a difficult task to accomplish.There are just so many methods to choose from and here I am going with RFECV.","execution_count":null},{"metadata":{"id":"M8_YyiO1Wqeq"},"cell_type":"markdown","source":"Recursive Feature Elimination  with Cross Validation\n\nRecursive — involving doing or saying the same thing several times in order to produce a particular result or effect\n\nFeature — individual measurable property or characteristic of a phenomenon being observed — an  attribute in your dataset\n\nCross-Validation — a technique for evaluating ML models by training several ML models on subsets of the available input data and evaluating them on the complementary subset of the data. Use cross-validation to detect overfitting, ie, failing to generalize a pattern.","execution_count":null},{"metadata":{"id":"88lLv51QYp_q"},"cell_type":"markdown","source":"You will need to declare two variables — X and y where first represents all the features, and the second represents the target variable. Then you’ll make an instance of the Machine learning algorithm (In this case RandomForests). In it, you can optionally pass a random state seed for reproducibility. Now you can create an instance of RFECV.\n\n\n","execution_count":null},{"metadata":{"id":"qg_HTJDt--lS","trusted":true},"cell_type":"code","source":"#Performing Recursive Feauture Elimation with Cross Validation\n#Using Random forest for RFE-CV and logloss as scoring\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import log_loss\nclf_rf=RandomForestClassifier(random_state=0)\nrfecv=RFECV(estimator=clf_rf, step=1,cv=5,scoring='neg_log_loss')\nrfecv=rfecv.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"id":"ZLyUhZIi_HZa","outputId":"7ea7fc8e-39fb-4c68-907a-548a6ea679fa","trusted":true},"cell_type":"code","source":"#Optimal number of features\nX_train = pd.DataFrame(X_train)\nX_test = pd.DataFrame(X_test)\nprint('Optimal number of features :', rfecv.n_features_)\nprint('Best features :', X_train.columns[rfecv.support_])","execution_count":null,"outputs":[]},{"metadata":{"id":"RxFi3iSTPPmx"},"cell_type":"markdown","source":"|Features Selected |\tFeatures Dropped|\n| --- | --- |\n|duration| color|\n|director_facebook_likes\t| director name|\n|actor_3_facebook_likes\t| actor_2_name|\n|actor_1_facebook_likes|\tactor_1_name   |\n|gross|\tfacenumber_in_poster|\n|genres |\tlanguage|\n|num_voted_users |country\t|\n|actor_3_name \t| content_rating|\n|actor_3_name |\taspect_ratio|\n|plot_keywords |\t|\n|num_user_for_reviews |\t |\n|budget| |\n|title_year | \t|\n|actor_2_facebook_likes |\t |\n|movie_facebook_likes |\t |\n","execution_count":null},{"metadata":{"id":"URnMrDLz_KYs","trusted":true},"cell_type":"code","source":"#Feauture Ranking\nclf_rf = clf_rf.fit(X_train,y_train)\nimportances = clf_rf.feature_importances_\n\nstd = np.std([tree.feature_importances_ for tree in clf_rf.estimators_],\n             axis=0)\nindices = np.argsort(importances)[::-1]\n","execution_count":null,"outputs":[]},{"metadata":{"id":"w7ONzE3v_OVs","outputId":"cd528cea-f107-4953-dd01-23eb053db637","trusted":true},"cell_type":"code","source":"#Logloss vs Number of features\nimport matplotlib.pyplot as plt\nplt.figure()\nplt.xlabel(\"Number of features selected\")\nplt.ylabel(\"Cross validation score of number of selected features\")\nplt.title(\"Log loss vs Number of fetures\")\nplt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"K9mkDj8DAW0n","trusted":true},"cell_type":"code","source":"#Selecting the Important Features\nX_opt = X_train.iloc[:,X_train.columns[rfecv.support_]]\nX_test = X_test.iloc[:,X_test.columns[rfecv.support_]]","execution_count":null,"outputs":[]},{"metadata":{"id":"F16nSSZwRYW2","outputId":"cf06324e-31b0-4b6e-afe7-236e270e03ef","trusted":true},"cell_type":"code","source":"#Creating anew dataframe with column names and feature importance\ndset = pd.DataFrame()\ndata1 = data\ndata1.drop(columns=['imdb_binned'],inplace=True)\ndset['attr'] = data1.columns\n\ndset['importance'] = clf_rf.feature_importances_\n#Sorting with importance column\ndset = dset.sort_values(by='importance', ascending=True)\n\n#Barplot indicating Feature Importance\nplt.figure(figsize=(16, 14))\nplt.barh(y=dset['attr'], width=dset['importance'], color='#1976D2')\nplt.title('RFECV - Feature Importances', fontsize=20, fontweight='bold', pad=20)\nplt.xlabel('Importance', fontsize=14, labelpad=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"eBot54tQHbAK"},"cell_type":"markdown","source":"## 3.4 Random Forest\n\nRandom forests is an ensemble learning method for classification that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification)  of the individual trees\n\n*n_estimators* is a parameter that specify number of trees in the forest.\n\n*criterion* is to specify what function to measure the quality of a split. “entropy” is for the information gain. ","execution_count":null},{"metadata":{"id":"JQ_doeT7hj-Z","outputId":"52cf55a4-ed73-436a-bb75-066af0cbb2f1","trusted":true},"cell_type":"code","source":"#Training the Random Forest Classifer on Train data\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 0)\nclassifier.fit(X_opt, y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"ncb7wwA2SXkH"},"cell_type":"markdown","source":"Predicting the test data","execution_count":null},{"metadata":{"id":"bv6u4-lXcjFw","trusted":true},"cell_type":"code","source":"#Predicting the target variable\ny_pred = classifier.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"Rg7keUykedDe"},"cell_type":"markdown","source":"## 3.5 Confusion Matrix\n\nConfusion matrix gives a clear view of ground truth and prediction.","execution_count":null},{"metadata":{"id":"2Cp-RASLcjDA","outputId":"0a349db5-fac9-4766-952f-bbfcd4875a54","trusted":true},"cell_type":"code","source":"#Confusion Matrix\nfrom sklearn.metrics import confusion_matrix \ncm = confusion_matrix(y_test,y_pred)\ncm","execution_count":null,"outputs":[]},{"metadata":{"id":"1hr8f0sMfILX"},"cell_type":"markdown","source":"## 3.6 Classification Report","execution_count":null},{"metadata":{"id":"fYbsAHZsci9d","outputId":"258a9a00-4946-49cb-d636-5ae1cef59561","trusted":true},"cell_type":"code","source":"#Classification Report\nfrom sklearn.metrics import classification_report\ncr = classification_report(y_test,y_pred)\nprint(cr)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}