{"cells":[{"metadata":{"_uuid":"534e902b7584b45c1fed60951983f3a0d3191875"},"cell_type":"markdown","source":"# Facial landmark detection with Keras CNN\n\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# load the dataset\nPface = np.moveaxis(np.load('../input/face_images.npz')['face_images'],-1,0)\nLMs = pd.read_csv('../input/facial_keypoints.csv')\n\nLMpos=LMs.columns.tolist()\nprint(LMs.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8a758b4eab52f435e69a62c9314e2672e823e32a"},"cell_type":"markdown","source":"I will only select the x and y of the eyes center, nose tip and mouth center, because these values are most avaiable. This gives 7000 images and X and Y are build to fit Keras format. Y is rescaled between 0 and 1."},{"metadata":{"trusted":true,"_uuid":"06c605bfafadd55d230593338b637781f88d0f52"},"cell_type":"code","source":"iselect=np.nonzero(LMs.left_eye_center_x.notna() & LMs.right_eye_center_x.notna() &\n         LMs.nose_tip_x.notna() & LMs.mouth_center_bottom_lip_x.notna())[0]\n\nSpic=Pface.shape[1]\nm=iselect.shape[0]\nX=np.zeros((m,Spic,Spic,1))\nY=np.zeros((m,8))\n\nX[:,:,:,0]=Pface[iselect,:,:]/255.0\nY[:,0]=LMs.left_eye_center_x[iselect]/Spic\nY[:,1]=LMs.left_eye_center_y[iselect]/Spic\nY[:,2]=LMs.right_eye_center_x[iselect]/Spic\nY[:,3]=LMs.right_eye_center_y[iselect]/Spic\nY[:,4]=LMs.nose_tip_x[iselect]/Spic\nY[:,5]=LMs.nose_tip_y[iselect]/Spic\nY[:,6]=LMs.mouth_center_bottom_lip_x[iselect]/Spic\nY[:,7]=LMs.mouth_center_bottom_lip_y[iselect]/Spic\n\nprint('# selected images = %d' %(m))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"25b3c1b8b954a3c6cd2d08d505e06e9a7a41105c"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nn = 0\nnrows = 4\nncols = 4\nirand=np.random.choice(Y.shape[0],nrows*ncols)\nfig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True,figsize=[ncols*2,nrows*2])\nfor row in range(nrows):\n    for col in range(ncols):\n        ax[row,col].imshow(X[irand[n],:,:,0], cmap='gray')\n        ax[row,col].scatter(Y[irand[n],0::2]*Spic,Y[irand[n],1::2]*Spic,marker='X',c='r',s=100)\n        ax[row,col].set_xticks(())\n        ax[row,col].set_yticks(())\n        ax[row,col].set_title('image index = %d' %(irand[n]),fontsize=10)\n        n += 1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ff30b8eee19ec728aa4aa80d437b247d1d88695"},"cell_type":"code","source":"# Split the dataset\nfrom sklearn.model_selection import train_test_split\n\nrandom_seed=21\nXtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=random_seed)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7c0473f5fbeee196e724b259d987e990341e9138"},"cell_type":"markdown","source":"The model I used is a very simple CNN just to try if it works. I used the sigmoid activation for the output layer because this produces an output between 0 and 1 and because it is not a classification problem. Softmax is not usefull."},{"metadata":{"trusted":true,"_uuid":"26872c1c068619bdc84e182321b7ccd55364df7c"},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import SGD\n\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), padding = 'same', activation='tanh', input_shape=(Spic, Spic, 1)))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='tanh'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(8, activation='sigmoid'))\n\nsgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='mean_squared_error', optimizer=sgd)\n\nmodel.fit(Xtrain, Ytrain, batch_size=128, epochs=10, validation_data = (Xtest, Ytest), verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a2f74319021eaaa186f6a43038178a2f96ec03a"},"cell_type":"code","source":"Ytrain_pred = model.predict(Xtrain)\nYtest_pred = model.predict(Xtest)\n\nn = 0\nnrows = 4\nncols = 4\nirand=np.random.choice(Ytest.shape[0],nrows*ncols)\nfig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True,figsize=[ncols*2,nrows*2])\nfor row in range(nrows):\n    for col in range(ncols):\n        ax[row,col].imshow(Xtest[irand[n],:,:,0], cmap='gray')\n        ax[row,col].scatter(Ytest[irand[n],0::2]*Spic,Ytest[irand[n],1::2]*Spic,marker='X',c='r',s=100)\n        ax[row,col].scatter(Ytest_pred[irand[n],0::2]*Spic,Ytest_pred[irand[n],1::2]*Spic,marker='+',c='b',s=100)\n        ax[row,col].set_xticks(())\n        ax[row,col].set_yticks(())\n        ax[row,col].set_title('image index = %d' %(irand[n]),fontsize=10)\n        n += 1\nplt.suptitle('x: Manual; +: CNN', fontsize=16)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}