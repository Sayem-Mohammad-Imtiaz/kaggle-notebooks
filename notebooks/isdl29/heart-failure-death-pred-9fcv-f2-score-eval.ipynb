{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Heart Failure Death Prediction | 9-Fold CV F2 Score Evaluation "},{"metadata":{},"cell_type":"markdown","source":"## 0. Program setup"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\n\nfrom sklearn.metrics import make_scorer\nfrom sklearn.metrics import fbeta_score\nfrom sklearn.metrics import matthews_corrcoef\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ndatafile=\"/kaggle/input/heart-failure-clinical-data/heart_failure_clinical_records_dataset.csv\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Data inspection"},{"metadata":{},"cell_type":"markdown","source":" First let's take a look at the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"rawdata=pd.read_csv(datafile)\nrawdata","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"rawdata.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's look for direct correlations to death events."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(rawdata, y_vars=\"DEATH_EVENT\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There doesn't seem to be a strong logistic behaviour of any of the variables. We need to look further at the death/survival distribution for each parameter."},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in rawdata.columns:\n    if column!=\"DEATH_EVENT\": sns.displot(data=rawdata, x=rawdata[column], hue=\"DEATH_EVENT\", element=\"step\", stat=\"probability\",common_norm=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The feature with most correlation is \"time\", which makes sense because patients with severe heart issues tend to die within the examination period whereas the survivors complete the full examination process. However, we can't use that variable for our prediction since initially we don't know how long the examination time will be."},{"metadata":{},"cell_type":"markdown","source":"## 2. Data cleaning"},{"metadata":{},"cell_type":"markdown","source":"Now let's remove the outliers using the quantile criteria:\n\n\\begin{equation}\nQ_1- 1.5 \\ Q_{13}<{(X,y)} \\leq Q_3+1.5 \\ Q_{13}\n\\end{equation}\n\nwhere\n\n\\begin{equation}\nQ_{13}=Q_3-Q_1\n\\end{equation}\n\nAlong with the feature \"time\"."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"def outlier_remover(columnseries,q):\n    Q1=columnseries.describe()[\"25%\"]\n    Q3=columnseries.describe()[\"75%\"]\n    Q13=Q3-Q1\n    lowerbound=Q1-q*Q13\n    upperbound=Q3+q*Q13\n    newcolumnseries=columnseries[columnseries.between(lowerbound,upperbound)]\n    return newcolumnseries\n\ndef outlier_clean(dataframe, exception_col=[],quo=1.5):\n    newdataframe=pd.DataFrame()\n    for columnname in dataframe.columns:\n        if columnname not in exception_col: newdataframe[columnname]=outlier_remover(dataframe[columnname],q=quo)\n    newdataframe=newdataframe.dropna()\n    return newdataframe\n    \ncleandata=outlier_clean(rawdata.drop(columns=[\"time\"]),quo=1.5)\n\ncleandata.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After that, let's take a look the new death/survivors distributions."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"for column in cleandata.columns:\n    if column!=\"DEATH_EVENT\": \n        sns.displot(data=cleandata, x=cleandata[column], hue=\"DEATH_EVENT\", element=\"step\", stat=\"probability\",common_norm=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Not so much has changed. \"age\", \"serum_creatinine\", \"anaemia\", \"high_blood_pressure\" and \"ejection_fraction\" are the features with most difference between the death and survivor distributions. Nevertheless we can use the rest as well to see if the machine learning algorythms can find some hidden patterns within them."},{"metadata":{},"cell_type":"markdown","source":"## 3. Prepparing the data to be machine learnt."},{"metadata":{},"cell_type":"markdown","source":"Now we will transform the binary input features into dummy variables to be easier to learn. For example, sex can be 0 or 1. We will create a feature sex_0 that will activate only when \"sex\"=0, and the same with sex_1 when \"sex\"=1. This could make our variables easier to understand by the algorythms."},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"learndata=cleandata\ncatvarnames=[\"anaemia\",\"diabetes\",\"high_blood_pressure\",\"sex\",\"smoking\"]\n\nfor colname in catvarnames:\n    dummies=pd.get_dummies(cleandata[colname],prefix=colname)\n    learndata=pd.concat([learndata,dummies],axis=1)\n    learndata=learndata.drop(columns=[colname])\n    \nlearndata","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the last stage of this section we will make the data split into input features \"X\" and the output \"y\". Then we will split the data into train and test sets and we will scale it using the training data to fit the scaler. Then we will define the scorers we will use and assign the F2 as the CV score criteria, since we want to put special emphasis on false negatives. Finally we will define the functions we will use to evatuate each algorythm."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separation of the data into input X and output y.\n\ndata_col=list(learndata.columns)\ny_col=data_col.pop(data_col.index(\"DEATH_EVENT\"))\nX_col=data_col\n\nX_data=learndata[X_col] \ny_data=learndata[y_col]\n\n# K value of K-Fold CV assignation.\n\nk=9\nr=29\n\n# Split into CV Training data and Testing data. We choose the test size to be equal to the validation size of our K-Fold CV.\n# For doing so, we split the data into K+1 pieces and we use the first K pieces to K-Fold CV and the left one for final testing.\n\nX_train, X_test, y_train, y_test = train_test_split(X_data,y_data,test_size=1/(k+1), random_state=r)\n\n# Standard scaling of the input data X.\n\nXscaler=StandardScaler()\nXscaler.fit(X_train)\nX_train=Xscaler.transform(X_train)\nX_test=Xscaler.transform(X_test)\n\n# Creation of the variables we will use to store the evaluation results for each algorythm.\n\nmodelScore_train={}\nmodelScore_test={}\nmodelScore_KFCV={}\nmodel_KFCV={}\n\nmodelConfussionMatrix_train={}\nmodelConfussionMatrix_test={}\n\ndeathevents_train=pd.DataFrame()\ndeathevents_test=pd.DataFrame()\ndeathevents_train[\"Reality\"]=y_train\ndeathevents_test[\"Reality\"]=y_test\n\n# Scorers setup and F2 assignation as the evaluation score.\nscorersCV={\"Acc\": make_scorer(accuracy_score),\n           \"MCC\": make_scorer(matthews_corrcoef), \n           \"F1\": make_scorer(fbeta_score, beta=1), \n           \"F2\": make_scorer(fbeta_score, beta=2)}\nscorerCVkey=\"F2\"\n\n# Definition of the algorythm evaluation function.\n\ndef tuned_model(model, param_grid, modelname, results):\n    tuner=GridSearchCV(model,param_grid=param_grid,scoring=scorersCV,cv=k,refit=scorerCVkey)\n    tuner.fit(X_train,y_train)\n    best_model=tuner.best_estimator_\n    best_params=tuner.best_params_\n    model_KFCV[modelname]=best_model\n    print(f\"Best model: {best_model}\")\n    \n    modelScore_KFCV[modelname]={}\n    resultcols=['rank_test_'+scorerCVkey]\n    resultsdata=pd.DataFrame(tuner.cv_results_)\n    for paramkey in param_grid:\n        paramcolname=\"param_\"+paramkey\n        resultcols.append(paramkey)\n        resultsdata=resultsdata.rename(columns={paramcolname:paramkey})\n        \n    for i in range(0,k):\n        old_split_score_name=\"split%s_test_%s\" % (i,scorerCVkey)\n        new_split_score_name=\"s%s_%s\" % (i,scorerCVkey)\n        resultsdata=resultsdata.rename(columns={old_split_score_name: new_split_score_name})\n        resultcols.append(new_split_score_name)\n    \n    for scorerkey in scorersCV:\n        old_mean_score_name=\"mean_test_\"+scorerkey\n        new_mean_score_name=\"mean_\"+scorerkey\n        resultsdata=resultsdata.rename(columns={old_mean_score_name: new_mean_score_name})\n        resultcols.append(new_mean_score_name)\n        \n        best_row=resultsdata[resultsdata[\"params\"]==best_params]\n        modelScore_KFCV[modelname][scorerkey]=round(best_row[new_mean_score_name].values[0],3)\n        \n    if results==True: print(resultsdata[resultcols].sort_values(by=resultcols[0]).round(3))\n        \n    return best_model\n\ndef plot_confusion_matrix(confusion_matrix,model_name):\n    ax=plt.axes()\n    confusionmatrix=sns.heatmap(data=confusion_matrix,annot=True,ax=ax)\n    ax.set_title(model_name)\n    plt.show()\n\ndef execute_model(model,modelname):\n    model.fit(X_train,y_train)\n    y_train_pred=model.predict(X_train)\n    y_test_pred=model.predict(X_test)\n    deathevents_train[modelname]=y_train_pred\n    deathevents_test[modelname]=y_test_pred\n    modelScore_train[modelname]={}\n    modelScore_test[modelname]={}\n    for scorerkey in scorersCV:\n        scorermaker=scorersCV[scorerkey]\n        scorer=scorermaker._score_func\n        scorerparams=scorermaker._kwargs\n        modelScore_train[modelname][scorerkey]=round(scorer(y_train,y_train_pred,**scorermaker._kwargs) , 3)\n        modelScore_test[modelname][scorerkey]=round(scorer(y_test,y_test_pred,**scorermaker._kwargs) , 3)\n    modelConfussionMatrix_train[modelname]=confusion_matrix(y_train,y_train_pred,labels=[0, 1],normalize=\"true\")\n    modelConfussionMatrix_test[modelname]=confusion_matrix(y_test,y_test_pred,labels=[0, 1],normalize=\"true\")\n    \ndef eval_model(model_func,model_pgrid, model_name, results_info=False):\n    model=tuned_model(model=model_func, param_grid=model_pgrid, modelname=model_name, results=results_info)\n    execute_model(model,model_name)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Machine learning algorythms evaluation"},{"metadata":{},"cell_type":"markdown","source":"First each algorythm will be tuned via 9-Fold CV with SKLearn GridSearchCV. The scores are refered to the testing sets of the CV process (for each split and the mean value)."},{"metadata":{},"cell_type":"markdown","source":"#### Logistic Regression"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"LogitRegr_params={\"C\":[1,0.5,0.1,0.01],\n                  \"solver\":[\"lbfgs\", \"liblinear\"]}\neval_model(LogisticRegression(),LogitRegr_params,\"Logistic Regr.\",True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Stochastic Gradient Descend Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"SGDClf_params={\"alpha\":[0.1,0.05,0.01,0.005],\n               \"loss\":[\"hinge\",\"log\",\"modified_huber\"]}\neval_model(SGDClassifier(),SGDClf_params,\"Stochastic Gradient Descend Clf.\",True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Support Vector Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"SVClf_params={\"C\":[10,5,1,0.1],\n              \"gamma\":[\"scale\",\"auto\"],\n              \"kernel\":[\"linear\", \"poly\", \"rbf\", \"sigmoid\"]}\neval_model(SVC(),SVClf_params, \"Support Vector Clf.\",True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### K Neighbors Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"KNClf_params={\"n_neighbors\":[1,3],\n              \"weights\":[\"uniform\",\"distance\"],\n              \"algorithm\":[\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"]}\neval_model(KNeighborsClassifier(), KNClf_params, \"K Neighbors Clf.\", True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Decision Tree Classification"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"DTClf_params={\"ccp_alpha\":[0,0.05,0.001],\n              \"criterion\":[\"gini\", \"entropy\"],\n              \"max_features\":[None,\"auto\", \"sqrt\", \"log2\"]}\neval_model(DecisionTreeClassifier(), DTClf_params, \"Decision Tree Clf.\", True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Multi-Layer Perceptron Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"MLPClf_params={\"alpha\":[0.05,0.01,0.001,0.0001],\n               \"activation\":[\"identity\",\"tanh\"],\n               \"hidden_layer_sizes\":[15,(15,2)],\n               \"learning_rate\":[\"constant\",\"adaptive\"]}\neval_model(MLPClassifier(), MLPClf_params, \"Multi-Layer Perceptron Clf.\", True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Random Forest Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"RFClf_params={\"ccp_alpha\":[0.01,0.03,0.05,0.005],\n              \"criterion\":[\"gini\", \"entropy\"],\n              \"n_estimators\":[1,2,5,10]}\neval_model(RandomForestClassifier(), RFClf_params, \"Random Forest Clf.\",True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Gradient Boosting Classification"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"GBClf_params={\"ccp_alpha\":[0.0,0.1,0.01],\n              \"loss\":[\"deviance\", \"exponential\"],\n             \"n_estimators\":[50,200]}\neval_model(GradientBoostingClassifier(), GBClf_params, \"Gradient Boosting Clf.\", True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then the mean scores of the algorythms in the 9FCV and the testing set."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Score (%d-fold CV Train data)\" % k)\nfor key in modelScore_KFCV:\n    print(\"%s: %s\" % (key, modelScore_KFCV[key]))\nprint(\"\\n\")    \nprint(\"Score (Test data)\")\nfor key in modelScore_test:\n    print(\"{}: {}\".format(key,modelScore_test[key]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After executing the evaluation of the algorythms, let's see briefly how they can predict the training set output."},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"deathevents_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's see how each algorythm predicts the testing set, totally unknown for them."},{"metadata":{"trusted":true},"cell_type":"code","source":"try: \n    deathevents_test=deathevents_test.drop(columns=[\"Positivity\"])\nexcept:\n    pass\ndeathevents_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To continue, let's plot the confusion matrices. "},{"metadata":{"trusted":true},"cell_type":"code","source":"for modelname in deathevents_test.columns:\n    if modelname!=\"Reality\":\n       c_matrix=modelConfussionMatrix_test[modelname]\n       c_matrix_plot=plot_confusion_matrix(c_matrix,modelname)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's focus on the best algorythm according to the 9-Fold CV test. Also, let's define the positivity of a patient of the testing set as the probability of being an actual positive given a predicted output, based on the confusion matrix of the testing set.\n\n\\begin{equation}\nP(y_{pred})=\\begin{cases}\n \\frac{FN}{TN+FN} & \\quad \\text{if  } y_{pred}=0 \\\\\n \\\\\n \\frac{TP}{TP+FP} & \\quad \\text{if  } y_{pred}=1\n\\end{cases}\n\\end{equation}\n\nIn the ideal case, the positivity when predicted positive and negative should be 1 and 0, respectively."},{"metadata":{"trusted":true},"cell_type":"code","source":"def positivity(A,a):\n    \"\"\"\n    A -> The Confussion Matrix of the best model.\n    a -> Output of the the best model.\n    \"\"\"\n    positive=A[1][a]\n    negative=A[0][a]\n    return positive/(positive+negative)\n\ntuned_scores={}\nfor modelkey in modelScore_KFCV:\n    tuned_scores[modelkey]=modelScore_KFCV[modelkey][scorerCVkey]\n\nbest_model=max(tuned_scores,key=tuned_scores.get)\n\nc_matrix_best=modelConfussionMatrix_test[best_model]\n\ndeathevents_test[\"Positivity\"]=positivity(A=c_matrix_best, a=deathevents_test[best_model])\ndeathevents_test[[\"Reality\",best_model,\"Positivity\"]].head(50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Data splitting: K = {:d} , Test-Train Split Random State Seed = {:d}\".format(k,r))\nprint(\"BEST MODEL: %s\" % (model_KFCV[best_model]))\nprint(\"Test dataset scores:\")\nprint(\"· {:<35s} {:.3f}\".format(\"Accuracy\",modelScore_test[best_model][\"Acc\"]))\nprint(\"· {:<35s} {:.3f}\".format(\"Matthews Correlation Coefficient\",modelScore_test[best_model][\"MCC\"]))\nprint(\"· {:<35s} {:.3f}\".format(\"F1 Score\",modelScore_test[best_model][\"F1\"]))\nprint(\"· {:<35s} {:.3f}\".format(\"F2 Score\",modelScore_test[best_model][\"F2\"]))\nprint(\"Positivity when y_pred = 0 : {:.3f}\".format(positivity(A=c_matrix_best, a=0)))\nprint(\"Positivity when y_pred = 1 : {:.3f}\".format(positivity(A=c_matrix_best, a=1)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This results may be poor, good or quite good depending on the run. Now let's try a random seed whose algorythms performance is generally poor."},{"metadata":{"trusted":true},"cell_type":"code","source":"#New splitting\n\nr=0\nX_train, X_test, y_train, y_test = train_test_split(X_data,y_data,test_size=1/(k+1), random_state=r)\n\n# Standard scaling of the input data X.\n\nXscaler=StandardScaler()\nXscaler.fit(X_train)\nX_train=Xscaler.transform(X_train)\nX_test=Xscaler.transform(X_test)\n\n# Reset of storing program variables.\nmodelScore_train={}\nmodelScore_test={}\nmodelScore_KFCV={}\n\nmodelConfussionMatrix_train={}\nmodelConfussionMatrix_test={}\n\ndeathevents_train=pd.DataFrame()\ndeathevents_test=pd.DataFrame()\n\n# New train/test output split.\ndeathevents_train[\"Reality\"]=y_train\ndeathevents_test[\"Reality\"]=y_test\n\n# Logistic Regression\nLogitRegr_params={\"C\":[1,0.5,0.1,0.01],\n                  \"solver\":[\"lbfgs\", \"liblinear\"]}\neval_model(LogisticRegression(),LogitRegr_params,\"Logistic Regr.\")\n\n# Stochastic Gradient Descend Classification\nSGDClf_params={\"alpha\":[0.1,0.05,0.01,0.005],\n               \"loss\":[\"hinge\",\"log\",\"modified_huber\"]}\neval_model(SGDClassifier(),SGDClf_params,\"Stochastic Gradient Descend Clf.\")\n\n# Support Vector Classification\nSVClf_params={\"C\":[10,5,1,0.1],\n              \"gamma\":[\"scale\",\"auto\"],\n              \"kernel\":[\"linear\", \"poly\", \"rbf\", \"sigmoid\"]}\neval_model(SVC(),SVClf_params, \"Support Vector Clf.\")\n\n# K Neighbors Classification\nKNClf_params={\"n_neighbors\":[1,3],\n              \"weights\":[\"uniform\",\"distance\"],\n              \"algorithm\":[\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"]}\neval_model(KNeighborsClassifier(), KNClf_params, \"K Neighbors Clf.\")\n\n# Decision Tree Classification\nDTClf_params={\"ccp_alpha\":[0,0.05,0.001],\n              \"criterion\":[\"gini\", \"entropy\"],\n              \"max_features\":[None,\"auto\", \"sqrt\", \"log2\"]}\neval_model(DecisionTreeClassifier(), DTClf_params, \"Decision Tree Clf.\")\n\n# Multi-Layer Perceptron Classification\nMLPClf_params={\"alpha\":[0.05,0.01,0.001,0.0001],\n               \"activation\":[\"identity\",\"tanh\"],\n               \"hidden_layer_sizes\":[15,(15,2)],\n               \"learning_rate\":[\"constant\",\"adaptive\"]}\neval_model(MLPClassifier(), MLPClf_params, \"Multi-Layer Perceptron Clf.\")\n\n# Random Forest Classification\nRFClf_params={\"ccp_alpha\":[0.01,0.03,0.05,0.005],\n              \"criterion\":[\"gini\", \"entropy\"],\n              \"n_estimators\":[1,2,5,10]}\neval_model(RandomForestClassifier(), RFClf_params, \"Random Forest Clf.\")\n\n# Gradient Boosting Classification\nGBClf_params={\"ccp_alpha\":[0.0,0.1,0.01],\n              \"loss\":[\"deviance\", \"exponential\"],\n             \"n_estimators\":[50,200]}\neval_model(GradientBoostingClassifier(), GBClf_params, \"Gradient Boosting Clf.\")\n\ntry: \n    deathevents_test=deathevents_test.drop(columns=[\"Positivity\"])\nexcept:\n    pass\ndeathevents_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Score (%d-fold CV Train data)\" % k)\nfor key in modelScore_KFCV:\n    print(\"%s: %s\" % (key, modelScore_KFCV[key]))\nprint(\"\\n\")    \nprint(\"Score (Test data)\")\nfor key in modelScore_test:\n    print(\"{}: {}\".format(key,modelScore_test[key]))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"for modelname in deathevents_test.columns:\n    if modelname!=\"Reality\":\n       c_matrix=modelConfussionMatrix_test[modelname]\n       c_matrix_plot=plot_confusion_matrix(c_matrix,modelname)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now again let's focus on the best algorythm according to the 9FCV."},{"metadata":{"trusted":true},"cell_type":"code","source":"for modelkey in modelScore_KFCV:\n    tuned_scores[modelkey]=modelScore_KFCV[modelkey][scorerCVkey]\n\nbest_model=max(tuned_scores,key=tuned_scores.get)\n\nc_matrix_best=modelConfussionMatrix_test[best_model]\n\ndeathevents_test[\"Positivity\"]=positivity(A=c_matrix_best, a=deathevents_test[best_model])\ndeathevents_test[[\"Reality\",best_model,\"Positivity\"]].head(50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Data splitting: K = {:d} , Test-Train Split Random State Seed = {:d}\".format(k,r))\nprint(\"BEST MODEL: %s\" % (model_KFCV[best_model]))\nprint(\"Test dataset scores:\")\nprint(\"· {:<35s} {:.3f}\".format(\"Accuracy\",modelScore_test[best_model][\"Acc\"]))\nprint(\"· {:<35s} {:.3f}\".format(\"Matthews Correlation Coefficient\",modelScore_test[best_model][\"MCC\"]))\nprint(\"· {:<35s} {:.3f}\".format(\"F1 Score\",modelScore_test[best_model][\"F1\"]))\nprint(\"· {:<35s} {:.3f}\".format(\"F2 Score\",modelScore_test[best_model][\"F2\"]))\nprint(\"Positivity when y_pred = 0 : {:.3f}\".format(positivity(A=c_matrix_best, a=0)))\nprint(\"Positivity when y_pred = 1 : {:.3f}\".format(positivity(A=c_matrix_best, a=1)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this case the results are horrible."},{"metadata":{},"cell_type":"markdown","source":"## 5. Conclusions"},{"metadata":{},"cell_type":"markdown","source":"The selected algorythm models performance is inconsistent and it depends on the random split seed. Maybe more samples could help improving the consistency. Even in several runs of the same random seed, the results can change."},{"metadata":{},"cell_type":"markdown","source":"<span style=\"color:blue\">\n    <B><i>\n        Author note: If there is something wrong (or improvable) in this notebook please leave a comment below. It will help me for the next tasks or for updating this one.\n    </i></B>\n</span>"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}