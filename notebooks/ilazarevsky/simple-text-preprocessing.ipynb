{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"['imdb_master.csv']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nfrom collections import Counter\nimport itertools","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Рассмотрим преобразование текстов в удобоваримый для нейронной сети вид.<br>\nА именно:<br>\n    - Текст разбивается на слова (токенизация, знаки препинания считаются словами)<br>\n    - Слова подсчитываются для формирования ограниченного словаря. Каждому слову сопоставляется определеннный номер в словаре. \n    Редким словам назначается специальный номер (эквивалентно замене редких слов на спец. слово <UNK> (неизвестное слово)). \n    - Последовательности слов преобразуются в последовательности номеров слов. Добавляются спец. слова для обозначения начала и конца текста. \n    - Полученные последовательности выравниваются по заданной максимальной длине через обрезание или дополнение номером спец.символа <PAD>\n"},{"metadata":{},"cell_type":"markdown","source":"Класс для хранения текста в виде последовательности номеров и его закодированной метки"},{"metadata":{"trusted":true},"cell_type":"code","source":"class InputFeatures(object):\n    \"\"\"A single set of features of data.\"\"\"\n\n    def __init__(self, input_ids, label_id):\n        self.input_ids = input_ids\n        self.label_id = label_id","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Класс словаря. Метод word2id возвращает номер слова, id2word - наоборот, восстанавливает слово."},{"metadata":{"trusted":true},"cell_type":"code","source":"class Vocab:\n    def __init__(self, itos, unk_index):\n        self._itos = itos\n        self._stoi = {word:i for i, word in enumerate(itos)}\n        self._unk_index = unk_index\n        \n    def __len__(self):\n        return len(self._itos)\n    \n    def word2id(self, word):\n        idx = self._stoi.get(word)\n        if idx is not None:\n            return idx\n        return self._unk_index\n    \n    def id2word(self, idx):\n        return self._itos[idx]","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm_notebook","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Интерфейс объекта, преобразующего тексты в последовательности номеров.\ntransform выполняет преобразование при помощи словаря.\nfit_transform выучивает словарь из текста и возвращает такое же преобразование при помощи свежеполученного словаря."},{"metadata":{"trusted":true},"cell_type":"code","source":"class TextToIdsTransformer:\n    def transform():\n        raise NotImplementedError()\n        \n    def fit_transform():\n        raise NotImplementedError()\n\n","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Простая реализация данного интерфейса. Разбиение на слова производится с помощью библиотеки NLTK.\nВ словаре содержатся несколько спец. слов.\nПосле токенизации, к полученной последовательности слов добавляются слева и справа спец. слова для начала и конца текста."},{"metadata":{"trusted":true},"cell_type":"code","source":"class SimpleTextTransformer(TextToIdsTransformer):\n    def __init__(self, max_vocab_size):\n        self.special_words = ['<PAD>', '</UNK>', '<S>', '</S>']\n        self.unk_index = 1\n        self.pad_index = 0\n        self.vocab = None\n        self.max_vocab_size = max_vocab_size\n        \n    def tokenize(self, text):\n        return nltk.tokenize.word_tokenize(text.lower())\n        \n    def build_vocab(self, tokens):\n        itos = []\n        itos.extend(self.special_words)\n        \n        token_counts = Counter(tokens)\n        for word, _ in token_counts.most_common(self.max_vocab_size - len(self.special_words)):\n            itos.append(word)\n            \n        self.vocab = Vocab(itos, self.unk_index)\n    \n    def transform(self, texts):\n        result = []\n        for text in texts:\n            tokens = ['<S>'] + self.tokenize(text) + ['</S>']\n            ids = [self.vocab.word2id(token) for token in tokens]\n            result.append(ids)\n        return result\n    \n    def fit_transform(self, texts):\n        result = []\n        tokenized_texts = [self.tokenize(text) for text in texts]\n        self.build_vocab(itertools.chain(*tokenized_texts))\n        for tokens in tokenized_texts:\n            tokens = ['<S>'] + tokens + ['</S>']\n            ids = [self.vocab.word2id(token) for token in tokens]\n            result.append(ids)\n        return result","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Строим экземпляр входных данных. Обеспечиваем длину последовательности номеров равной max_seq_len. "},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_features(token_ids, label, max_seq_len, pad_index, label_encoding):\n    if len(token_ids) >= max_seq_len:\n        ids = token_ids[:max_seq_len]\n    else:\n        ids = token_ids + [pad_index for _ in range(max_seq_len - len(token_ids))]\n    return InputFeatures(ids, label_encoding[label])\n        ","execution_count":9,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Собираем экземпляры в тензоры"},{"metadata":{"trusted":true},"cell_type":"code","source":"def features_to_tensor(list_of_features):\n    text_tensor = torch.tensor([example.input_ids for example in list_of_features], dtype=torch.long)\n    labels_tensor = torch.tensor([example.label_id for example in list_of_features], dtype=torch.long)\n    return text_tensor, labels_tensor","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import model_selection","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imdb_df = pd.read_csv('../input/imdb_master.csv', encoding='latin-1')\ndev_df = imdb_df[(imdb_df.type == 'train') & (imdb_df.label != 'unsup')]\ntest_df = imdb_df[(imdb_df.type == 'test')]\ntrain_df, val_df = model_selection.train_test_split(dev_df, test_size=0.05, stratify=dev_df.label)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_seq_len=200\nclasses = {'neg': 0, 'pos' : 1}","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text2id = SimpleTextTransformer(10000)\n\ntrain_ids = text2id.fit_transform(train_df['review'])\nval_ids = text2id.transform(val_df['review'])\ntest_ids = text2id.transform(test_df['review'])","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_df.review.iloc[0][:160])\nprint(train_ids[0][:30])","execution_count":15,"outputs":[{"output_type":"stream","text":"This is one of my all time favorite movies and I would recommend it to anyone. On my list of favorite movies (mental list, mind) the only ones on par with it ar\n[2, 19, 11, 42, 9, 72, 45, 78, 507, 120, 7, 18, 70, 387, 16, 10, 263, 6, 32, 72, 1063, 9, 507, 120, 30, 1709, 1063, 5, 360, 29]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features = [build_features(token_ids, label,max_seq_len, text2id.pad_index, classes) \n                  for token_ids, label in zip(train_ids, train_df['label'])]\n\nval_features = [build_features(token_ids, label,max_seq_len, text2id.pad_index, classes) \n                  for token_ids, label in zip(val_ids, val_df['label'])]\n\ntest_features = [build_features(token_ids, label,max_seq_len, text2id.pad_index, classes) \n                  for token_ids, label in zip(test_ids, test_df['label'])]","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_features[3].input_ids)","execution_count":17,"outputs":[{"output_type":"stream","text":"[2, 45, 19, 1, 435, 9, 28, 2018, 718, 11, 1561, 1, 6404, 74, 189, 1, 1587, 6, 778, 46, 198, 1135, 1, 5, 2521, 1, 5, 310, 1, 5, 7, 851, 1, 313, 32, 8, 299, 7, 96, 33, 97, 741, 729, 1984, 5, 59, 2689, 1, 5, 9, 48, 755, 26, 6, 444, 89, 19, 170, 2810, 6, 54, 11, 33, 42, 216, 383, 5, 218, 5, 337, 5, 56, 952, 50, 6405, 636, 702, 10, 6405, 552, 6, 4, 2430, 5, 1, 2521, 1, 9, 729, 765, 1399, 92, 371, 6, 1135, 1, 92, 371, 6, 310, 1, 92, 371, 6, 4, 215, 3757, 92, 371, 6, 61, 19, 11, 8, 648, 26, 5, 1, 1354, 11, 8, 1, 668, 6, 14, 15, 12, 13, 14, 15, 12, 13, 623, 92, 189, 105, 26, 1324, 111, 217, 1786, 9, 111, 8797, 6, 609, 16, 21, 17, 4, 636, 912, 92, 35, 437, 5, 539, 5, 7, 1117, 47, 34, 42, 241, 6, 56, 44, 4, 69, 2187, 9, 4, 235, 11, 64, 8165, 51, 9994, 20, 31, 140, 54, 21, 42, 7, 79, 42, 291, 19, 2867, 198, 113, 6, 147, 5, 31, 58, 33, 181, 62]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_tensor, train_labels = features_to_tensor(train_features)\nval_tensor, val_labels = features_to_tensor(val_features)\ntest_tensor, test_labels = features_to_tensor(test_features)","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_tensor.size())","execution_count":23,"outputs":[{"output_type":"stream","text":"torch.Size([23750, 200])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(text2id.vocab))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}