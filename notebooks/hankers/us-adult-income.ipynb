{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom plotnine import *\nimport matplotlib.pyplot as plt\nfrom pandas.api.types import is_string_dtype\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input/\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 读取数据"},{"metadata":{"trusted":true},"cell_type":"code","source":"training_data = '../input/adult-training.csv'\ntest_data = '../input/adult-test.csv'\ncolumns = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', 'relationship',\\\n           'race', 'gender', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income_bracket']\n\ndf_train_set = pd.read_csv(training_data, names = columns)\ndf_test_set = pd.read_csv(test_data, names = columns)\n\n#fnlwgt列无实际意义，不重要可去除\ndf_train_set.drop('fnlwgt', axis = 1, inplace=True)\nprint('Training data shape: ', df_train_set.shape)\nprint('Tesing data shape: ', df_test_set.shape)\ndf_train_set.head()\nall_data = [df_train_set, df_test_set]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 数据预处理"},{"metadata":{"trusted":true},"cell_type":"code","source":"#查看缺失值\ndef missing_values_table(df):\n    # Total missing values\n        mis_val = df.isnull().sum()\n        # Percentage of missing values\n        mis_val_percent = 100 * df.isnull().sum() / len(df)\n        \n        # Make a table with the results\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        \n        # Rename the columns\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        \n        # Sort the table by percentage of missing descending\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n        \n        # Print some summary information\n        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n              \" columns that have missing values.\")\n        \n        # Return the dataframe with missing information\n        return mis_val_table_ren_columns\n\nprint(\"df_train_set\")\nmissing_values_table(df_train_set)\nprint(\"df_test_set\")\nmissing_values_table(df_test_set)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test_set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#通过查看数据，发现存在异常数据如？,将?替换为Nan或Unknown\ndf_test_set.drop(df_test_set.index[0])\ndf_train_set.replace(\" ?\", np.nan, inplace=True)\ndf_test_set.replace(\" ?\", np.nan, inplace=True)\ndf_train_set.dropna(inplace=True)\ndf_test_set.dropna(inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_set.income_bracket.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test_set.income_bracket.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data = [df_train_set, df_test_set]\nfor data in all_data:\n    data['target']=data['income_bracket'].apply(lambda x: x.replace('.', ''))\n    data['target']=data['target'].apply(lambda x: x.strip())\n    data['target'] = data['target'].apply(lambda x: 1 if x=='>50K' else 0)\n    data.drop(['income_bracket'], axis=1, inplace=True)\ndf_train_set.target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_set.dtypes.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_set.select_dtypes('object').apply(pd.Series.nunique, axis = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_set.drop('native_country', axis=1, inplace=True)\ndf_test_set.drop('native_country', axis=1, inplace=True)\ndf_train_set.drop('education', axis=1, inplace=True)\ndf_test_set.drop('education', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a label encoder object\nle = LabelEncoder()\nle_count = 0\n\n# Iterate through the columns\nfor col in df_train_set:\n    if df_train_set[col].dtype == 'object':\n        # If 2 or fewer unique categories\n        if len(list(df_train_set[col].unique())) <= 2:\n            print(col + \" were label encoded\")\n            # Train on the training data\n            le.fit(df_train_set[col])\n            # Transform both training and testing data\n            df_train_set[col] = le.transform(df_train_set[col])\n            df_test_set[col] = le.transform(df_test_set[col])\n            \n            # Keep track of how many columns were label encoded\n            le_count += 1\n            \nprint('%d columns were label encoded.' % le_count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# one-hot encoding of categorical variables\ndf_train_set = pd.get_dummies(df_train_set)\ndf_test_set = pd.get_dummies(df_test_set)\nprint('Training Features shape: ', df_train_set.shape)\nprint('Testing Features shape: ', df_test_set.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_set, df_test_set = df_train_set.align(df_test_set, join = 'inner', axis = 1)\nprint('Training Features shape: ', df_train_set.shape)\nprint('Testing Features shape: ', df_test_set.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_set.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = list(df_train_set.columns)\ncols.remove(\"target\")\n\nx_train, y_train = df_train_set[cols].values, df_train_set[\"target\"].values\nx_test, y_test = df_test_set[cols].values, df_test_set[\"target\"].values\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 算法模型"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 采用决策树算法\ntreeClassifier = DecisionTreeClassifier()\ntreeClassifier.fit(x_train, y_train)\ntreeClassifier.score(x_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import itertools\nfrom sklearn.metrics import confusion_matrix\n# 混淆矩阵\ndef plot_confusion_matrix(cm, classes, normalize=False):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    cmap = plt.cm.Blues\n    title = \"Confusion Matrix\" \n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        cm = np.around(cm, decimals=3)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 决策树算法评估\ny_pred = treeClassifier.predict(x_test)\ncfm = confusion_matrix(y_test, y_pred, labels=[0, 1])\nplt.figure(figsize=(10,6))\nplot_confusion_matrix(cfm, classes=[\"<=50K\", \">50K\"], normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 采用随机森林算法\nrclf = RandomForestClassifier(n_estimators=500)\nrclf.fit(x_train, y_train)\nrclf.score(x_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 随机森林算法评估\ny_pred = rclf.predict(x_test)\ncfm = confusion_matrix(y_test, y_pred, labels=[0, 1])\nplt.figure(figsize=(10,6))\nplot_confusion_matrix(cfm, classes=[\"<=50K\", \">50K\"], normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 特征重要性\nimportances = rclf.feature_importances_\nindices = np.argsort(importances)\ncols = [cols[x] for x in indices]\nplt.figure(figsize=(10,20))\nplt.title('Feature Importances')\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), cols)\nplt.xlabel('Relative Importance')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 采用5折交叉验证进行优化"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nparameters = {\n    'n_estimators':(100, 500, 1000),\n    'max_depth':(None, 24, 16),\n    'min_samples_split': (2, 4, 8),\n    'min_samples_leaf': (16, 4, 12)\n}\n\nclf = GridSearchCV(RandomForestClassifier(), parameters, cv=5, n_jobs=8)\nclf.fit(x_train, y_train)\nclf.best_score_, clf.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rclf2 = RandomForestClassifier(n_estimators=1000,max_depth=24,min_samples_leaf=4,min_samples_split=8)\nrclf2.fit(x_train, y_train)\n\ny_pred = rclf2.predict(x_test)\ncfm = confusion_matrix(y_test, y_pred, labels=[0, 1])\nplt.figure(figsize=(10,6))\nplot_confusion_matrix(cfm, classes=[\"<=50K\", \">50K\"], normalize=True)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}