{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport datetime\nimport matplotlib.pyplot as plt\nimport keras\nfrom keras import Model\nfrom keras import metrics\nfrom keras.models import *\nfrom keras.layers import *\nfrom keras.optimizers import *\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split\nimport os\n\nseed = 42","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/renfe.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df.drop(columns = ['Unnamed: 0'])\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['price'].fillna(df['price'].mean(),inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['insert_date'] = pd.to_datetime(df['insert_date'])\ndf['start_date'] = pd.to_datetime(df['start_date'])\ndf['end_date'] = pd.to_datetime(df['end_date'])\n\ndf['start_date_weekday'] = df['start_date'].dt.weekday\ndf['start_date_month'] = df['start_date'].dt.month\ndf['start_date_hour'] = df['start_date'].dt.hour\ndf['start_date_day'] = df['start_date'].dt.day\ndf['start_date_minute'] = df['start_date'].dt.minute\ndf['end_date_weekday'] = df['end_date'].dt.weekday\ndf['end_date_month'] = df['end_date'].dt.month\ndf['end_date_hour'] = df['end_date'].dt.hour\ndf['end_date_day'] = df['end_date'].dt.day\ndf['end_date_minute'] = df['end_date'].dt.minute","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['duration_h'] = (df['end_date'] - df['start_date']).astype('timedelta64[h]')\ndf['duration_m'] = (df['end_date'] - df['start_date']).astype('timedelta64[m]')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df['duration_m'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['price'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df.origin)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df.destination)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df.train_type)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df.train_class)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df.fare)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler_y = MinMaxScaler()\ny=np.reshape(df['price'].values, (-1,1))\nprint(scaler_y.fit(y))\nyscale=scaler_y.transform(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['price_norm'] = yscale","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#stack input data\ndef prepare_data_for_nn(frame, categorical_vars, numerical_vars, text_vars, label_col) : \n    inputs = []\n    for c in categorical_vars :     \n        cat_values = np.asarray(frame[c].tolist())\n        inputs.append(np.array(pd.factorize(cat_values)[0]))\n    if numerical_vars:\n        inputs.append(frame[numerical_vars].values)\n    return inputs, frame[label_col]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_vars = ['start_date_month',\n                    'start_date_day',\n                    'start_date_weekday',\n                    'start_date_hour',\n                    'duration_h',\n                    'end_date_month',\n                    'end_date_day',\n                    'end_date_weekday',\n                    'end_date_hour',\n                    'fare',\n                    'train_class',\n                    'train_type',\n                    'destination', \n                    'origin']\nnumerical_vars = []\ntext_vars = []\n\ninpts, outpts = prepare_data_for_nn(\n        df,\n        categorical_vars, \n        numerical_vars, \n        text_vars, \n        'price')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_data(inputs, output, train_part=0.8, test_part=0.1, valid_part = 0.1):\n    X_train = []\n    X_val = []\n    X_test = []\n    for input_feature in inputs:\n        i_train, i_valtest = train_test_split(input_feature, test_size=test_part + valid_part, random_state=seed)\n        i_test, i_val = train_test_split(i_valtest, test_size=test_part/(test_part + valid_part), random_state=seed)\n        X_train.append(i_train)\n        X_test.append(i_test)\n        X_val.append(i_val)\n\n    y_train, y_valtest = train_test_split(output, test_size=test_part + valid_part, random_state=seed)\n    y_test, y_val = train_test_split(y_valtest, test_size=test_part/(test_part + valid_part), random_state=seed)\n    return X_train, X_val, X_test, y_train, y_val, y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def emb_model_train(xtrain, xval, ytrain, yval, balanced_df):\n    cat_inputs = []\n    cat_outputs = []\n    for cat_column in categorical_vars:\n        cat_size = balanced_df[cat_column].nunique()\n        cat_input = Input(shape=(1,), name=cat_column + '_input')\n        embedding_size = min(np.ceil((cat_size)/2), 50 )\n        embedding_size = int(embedding_size)\n        x = Embedding(cat_size+1, embedding_size, input_length=1)(cat_input)\n        cat_output = Flatten()(x)\n        cat_inputs.append(cat_input)\n        cat_outputs.append(cat_output)\n    concatenate_inputs = []\n    concatenate_inputs.extend(cat_outputs)\n\n    lyr = keras.layers.concatenate(concatenate_inputs)\n    lyr = Dense(128, activation=\"relu\")(lyr)\n    lyr = Dropout(0.3)(lyr)    \n    lyr = Dense(64, activation=\"relu\")(lyr)\n    lyr = Dropout(0.3)(lyr)\n    main_output = Dense(1, activation='relu', name='main_output')(lyr)\n\n    all_inputs = []\n    all_inputs.extend(cat_inputs)\n\n    t_model = Model(inputs= all_inputs, outputs=[main_output])\n\n    #t_model.summary()\n\n    t_model.compile(loss=\"mse\",optimizer=Adam(),metrics=['mse', 'mae']\n    )\n    checkpointer = keras.callbacks.ModelCheckpoint(filepath=\"weights_best.hdf5\", verbose=1, save_best_only=True)\n    t_model.fit(\n        xtrain, \n        ytrain,\n        batch_size=16,\n        epochs=5,\n        shuffle=True,\n        validation_data = (xval, yval),\n        callbacks=[checkpointer],\n        verbose=1)\n    #results = t_model.evaluate(xtest, ytest)\n    \n    #y_pred = t_model.predict(xtest)\n    #y_pred_bool = np.round(y_pred)\n    \n    #return t_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, x_val, y_train, y_test, y_val = split_data(inpts, outpts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emb_model_train(x_train, x_val, y_train, y_val, df)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import load_model\nmodel = load_model('weights_best.hdf5')\n#model.load_weights('weights_best.hdf5')\npredicted = model.evaluate(x_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"mean squared error on test sample is {}\".format(predicted[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}