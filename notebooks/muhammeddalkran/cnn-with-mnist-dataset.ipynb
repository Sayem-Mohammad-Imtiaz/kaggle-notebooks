{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Needed Libraries**\n\n> Sequential provides us to add our layers with order.\n\n> In my model, I plan to use \n    1. Convolutional layers(CNN), \n    2. Maxpooling layers, \n    3. Activation layers, \n    4. Droupout Layers, \n    5. Fully Connected Layers.\n  \n> I need to make preprocessing to my data; therefore, I need to import ralated libraries, namely \n    1. ImageDataGenerator\n    2. img_to_array => convert image to array\n    3. load_img => to load image\n    \n> To plot and visualize the data and results, matplotlib.pyplot will be used. \n\n> To learn how many class I have, glob library will be used","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense,BatchNormalization\nfrom keras.utils import to_categorical\nfrom keras.preprocessing.image  import ImageDataGenerator, img_to_array,load_img\nimport matplotlib.pyplot as plt\nfrom glob import glob","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_and_preprocess(data_path):\n    data = pd.read_csv(data_path)\n    data = data.to_numpy()\n    np.random.shuffle(data)\n    x = data[:,1:].reshape(-1,28,28,1)/255.0\n    y = data[:,0].astype(np.int32)\n    y = to_categorical(y, num_classes=len(set(y)))\n\n    return x,y","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Load Train Data & Preprocessing**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,y_train = load_and_preprocess(\"/kaggle/input/mnist-in-csv/mnist_train.csv\"\n)\nprint(\"Shape of x_train : \" , x_train.shape)\nprint(\"Shape of y_train : \" , y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Load Test Data & Preprocessing**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test,y_test = load_and_preprocess(\"/kaggle/input/mnist-in-csv/mnist_test.csv\"\n)\nprint(\"Shape of x_test : \" , x_test.shape)\nprint(\"Shape of y_test : \" , y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Now, we load and preprocess our data. \n\n**Visualization of Data**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> Lets look at one example image","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"i = 20;\ntemp = x_train.reshape(60000,28,28)\nplt.imshow(temp[i,:,:])\nplt.legend()\nplt.axis('off')\nplt.title(np.argmax(y_train[i]))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Implementing The Model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> Our class number is 10 since there are 10 number(0,1,2,3,4,5,6,7,8,9)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"number_of_class = y_train.shape[1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Initializing Model**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Our model sturucture :**\n1. 3 Convolutional Layers with Different Filters\n2. 3 Batch Normalization Layers\n3. Activation function in Convolutional Layers is Relu\n4. 3 MaxPooling Layers","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model.add(Conv2D(input_shape = (28,28,1), filters = 16, kernel_size = (3,3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.add(Conv2D(filters = 64, kernel_size = (3,3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.add(Conv2D(filters = 128, kernel_size = (3,3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Flatten process and Fully Conncected Neural Network**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model.add(Flatten())\nmodel.add(Dense(units = 256))\nmodel.add(Activation(\"relu\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> To learn different proporties of image, we use Dropout\n\n**Dropout and Output Layers**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model.add(Dropout(0.2))\nmodel.add(Dense(units = number_of_class))\nmodel.add(Activation(\"softmax\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Compiling Our Model**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss = \"categorical_crossentropy\",\n              optimizer = \"adam\",\n              metrics = [\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist = model.fit(x_train,y_train, validation_data=(x_test,y_test), epochs= 5, batch_size= 32)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train Proccessing","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Save Model**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_weights('cnn_mnist_model.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluation of Model & Results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(hist.history.keys())\nplt.plot(hist.history[\"loss\"],label = \"Train Loss\")\nplt.plot(hist.history[\"val_loss\"],label = \"Validation Loss\")\nplt.legend()\nplt.show()\nplt.figure()\nplt.plot(hist.history[\"accuracy\"],label = \"Train Accuracy\")\nplt.plot(hist.history[\"val_accuracy\"],label = \"Validation Accuracy\")\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#%% save history\nimport json\nwith open('cnn_mnist_hist.json', 'w') as f:\n    json.dump(hist.history, f)\n    \n#%% load history\nimport codecs\nwith codecs.open(\"cnn_mnist_hist.json\", 'r', encoding='utf-8') as f:\n    h = json.loads(f.read())\n\nplt.figure()\nplt.plot(h[\"loss\"],label = \"Train Loss\")\nplt.plot(h[\"val_loss\"],label = \"Validation Loss\")\nplt.legend()\nplt.show()\nplt.figure()\nplt.plot(h[\"accuracy\"],label = \"Train Accuracy\")\nplt.plot(h[\"val_accuracy\"],label = \"Validation Accuracy\")\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}