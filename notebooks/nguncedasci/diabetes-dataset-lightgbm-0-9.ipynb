{"cells":[{"metadata":{},"cell_type":"markdown","source":"- Bu çalışmada yapılan ön işleme adımlarının %99'u, tez ve bilimsel araştırmaların referans alınması ile yapılmıştır.\n- Önce veri seti ve değişkenler tanıtıldı, literatürdeki thresholdlar belirtildi.\n- Veri setindeki tüm 0'ların alınamayan değerleri yani NA'leri temsil ettiği literatür araştırmalarından bilinmektedir.\n- Önce 0'lara NA atandı, sonra bu NA'ler na olmayan df'teki target kırılımlarına göre dolduruldu.\n- Base model kuruldu. (XGB: 0.889)\n- Alınan ilk feature importance ile 4 yeni değişken oluşturuldu, Age değişkeni veri setinden atıldı.Model sonucu: XGB: 0.897180\n- LOF ile ilk 50 değer drop edildi, Light GBM: 0.901154\n- Verinin son haline lojistic regresyon uygulanarak overfit olup olmadığının anlaşılması hedeflendmiştir. \n- Overfit olmadığı ve recall değerinin düşük olduğu gözlemlenmiştir. Bu durumu düzelmeye yönelik bir eylemde bulunulmamıştır.\n- Not: Robust Scaler denenerek sonuçların daha kötü olduğu anlaşılmış olup çalışmadan kaldırılmıştır."},{"metadata":{},"cell_type":"markdown","source":"# INFORMATION ABOUT THE DATASET\n\n\n    \n# Veri seti üzerinde yapılan araştırmalara göre,\n\n- Veri seti ABD'deki Ulusal Diyabet-Sindirim-Böbrek Hastalıkları Enstitüleri'nde tutulan büyük veri setinin parçasıdır.\n- ABD'deki Arizona Eyaleti'nin en büyük 5. şehri olan Phoenix şehrinde yaşayan 21 yaş ve üzerinde olan Pima Indian kadınları\nüzerinde yapılan diyabet araştırması için kullanılan verilerdir.(Bazı kaynaklarda Hintli ya da bazılarında Kızılderili olarak geçiyorlar.)\n- 768 gözlem, 8 numerik bağımsız değişkenden oluşmaktadır. Hedef değişken \"outcome\" olarak belirtilmiş olup 1 diyabet test sonucunun pozitif oluşunu, 0 ise negatif oluşunu belirtmektedir. (268:1, 500:0)\n\n# Değişkenler:\n\n- **Pregnancies**: Hamilelik Sayısı\n- **Glucose**: OGTT: Oral glukoz tolerans testi gebelere yapılır. İlk defa gebelikte başlayan veya teşhis edilen glukoz intoleransı ölçüm testi.Gestasyonel diyabet tanısı konur. \n    - 2 saatlik yapılan OGTT'yi temsil etmektedir.(tek aşamalı)\n    - 140 mg/dL >= : diyabet riskinin arttığı durumdur.\n    -  \n- **BloodPressure**: DBP Diastolik kan basıncını mmHg cinsinden temsil etmektedir.\n    \n    - <85 :2 yılda bir kontrol edilmeli\n    - 85-89 : Senede bir\n    - 90-99 : 2 ay içinde \n    - 100-109 : 1 ay içinde\n    - 110 > : 1 hafta içinde ya da hemen\n\n- **SkinThickness**: TSFT Triceps skinfold thickness (mm).        \n        \n- **Insulin**: Two-hour serum insulin (μU/mL) (2HSI). Insülin testi(tokluk 2 saat)\n    - 120 altı normal- 140-199 gizli şeker- 200 ve üzeri diyabet\n\n- **BMI** :Body Mass Index : kilo/ boy^2\n    - <18.5 zayıf\n    - 18.5-24.9 sağlıklı\n    - 25-29.9 kilolu\n    - 30-40 şişman\n    - 40.1-60 aşırı şişman\n        \n- **DiabetesPedigreeFunction** : Soyağacı  \n- **Age** : Yaş ( diyabet ise yaş median değeri 36, değilse 25)\n- **Outcome**\n\n# DİKKAT\n\n- **Misingler değerlerin olmayışını temsil etmektedir.** \n    - (Referans: https://www.sciencedirect.com/science/article/pii/S2352914816300016#bib65 (3.7. madde))\n    \n# References:\n- https://www.sciencedirect.com/science/article/pii/S2352914816300016#bib65 (3.7. madde)\n- https://tr.ulfsciences.com/native-america-s-alleles-44932\n- https://www.foodandnutritionjournal.org/volume7number2/significance-of-health-related-predictors-of-diabetes-in-pima-indians-women/\n- https://www.novonordisk.com.tr/hastalara-ozel/diyabet/diyabet-tanisi-ve-tipleri.html\n- https://tkd.org.tr/kilavuz/k03/3_18530.htm?wbnum=1103\n- https://aysetugbasengel.com/kan-sekeri-degerleri-ne-olmali-aclik-tokluk-kan-sekeri-olcumu/#Tokluk_Kan_Sekeri_Testi_Nedir,_Nasil_Yapilir\n- http://www.taylankumeli.com/hesaplama/bmi-hesapla/l"},{"metadata":{"trusted":true},"cell_type":"code","source":"# IMPORT LIBRARIES\nimport numpy as np\nimport pandas as pd \nimport seaborn as sns\nimport statsmodels.api as sm\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import scale, StandardScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.metrics import confusion_matrix, accuracy_score, mean_squared_error, r2_score, roc_auc_score, roc_curve, classification_report\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import KFold\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.preprocessing import RobustScaler\n\nimport warnings\nwarnings.simplefilter(action = \"ignore\") \n\n\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# READ THE DATA\n\ndiabetes= pd.read_csv(\"../input/pima-indians-diabetes-database/diabetes.csv\")\ndf=diabetes.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DATA UNDERSTANDING"},{"metadata":{"trusted":true},"cell_type":"code","source":"# AT FIRST GLANCE\n\ndef info_(dataframe):\n    print(\"DF SHAPE:\",dataframe.shape, \"\\n\")\n    print(\"OUTCOME 1/ALL DF RATIO:\",len(df[df[\"Outcome\"]==1])/len(df), \"\\n\")\n    print(\"OUTCOME 0/ALL DF RATIO:\",len(df[df[\"Outcome\"]==0])/len(df), \"\\n\")\n    print(\"NUMBER OF NULL VALUES:\", df.isnull().any(axis=1).sum(), \"\\n\")\n    print(dataframe.head(3), \"\\n\")\n    object_list=[col for col in dataframe.columns if dataframe[col].dtypes==\"O\"]\n    numeric_list=[col for col in dataframe.columns if dataframe[col].dtypes!=\"O\"]\n    print(\"ALL COLUMNS:\", df.columns, \"\\n\")\n    print(\"OBJECT COLUMNS:\",object_list,\"\\n\")\n    print(\"NUMERIC COLUMNS\",numeric_list,\"\\n\")\n    print(\"CORRELATIONS\",sns.heatmap(df.corr()));\n    print(sns.pairplot(df));\n    return object_list, numeric_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"obj_list, num_list=info_(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DATA PREPROCESSING"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 0'ların NA değerler olduğunu yukarıda verilen referanslardan biliyorduk.\n# Bu kısımda önce Df'in 0'larının atılmış halini bulacağım. \n#Sonra NA değerlerine, bu sıfırsız df'e yaptığım kırılımla atama yapacağım.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1=df.copy()\ndf1=df1.loc[:,\"Pregnancies\": \"Age\"].replace(0, np.nan).dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in df1.columns:\n    if i!=\"Outcome\":\n        print(i.upper(),\"\\n\",\"for diabet:\", df1.loc[df[\"Outcome\"]==1, i].median(),\"\\n\",\"for non-diabet:\" , df1.loc[df[\"Outcome\"]==0, i].median())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TÜM SÜTUNLARDAKİ 0 DEĞERLERİNE KIRILIMLA ATAMA"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in df.columns:\n    for k in range(len(df)):\n        if i!=\"Outcome\":\n            if df.loc[k,i]==0: #eğer değer 0'a eşitse\n                if df.loc[k,\"Outcome\"]==1:   #bu değerin outcome'ı 1'se\n                     df.loc[k,i]=df1.loc[df[\"Outcome\"]==1, i].median()# na değer olmayan df'teki outcome'ı 1 olanların i medyanını ata.\n                elif df.loc[k,\"Outcome\"]==0:\n                     df.loc[k,i]=df1.loc[df[\"Outcome\"]==0, i].median()# na değer olmayan df'teki outcome'ı 0 olanların i medyanını ata.\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# BASE MODEL : XGB: 0.889371"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df[\"Outcome\"]\nX = df.drop([\"Outcome\"], axis = 1)\nlog_model = LogisticRegression().fit(X,y)\ny_pred = log_model.predict(X)\nprint(accuracy_score(y, y_pred))\nprint(classification_report(y, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df[\"Outcome\"]\nX = df.drop([\"Outcome\"], axis = 1)\n\n\n\nmodels = []\nmodels.append(('LR', LogisticRegression()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('RF', RandomForestClassifier()))\nmodels.append(('SVM', SVC(gamma='auto')))\nmodels.append(('XGB', GradientBoostingClassifier()))\nmodels.append((\"LightGBM\", LGBMClassifier()))\n\n# evaluate each model in turn\nresults = []\nnames = []\n\n\n\nfor name, model in models:\n    \n        kfold = KFold(n_splits = 10, random_state = 123456)\n        cv_results = cross_val_score(model, X, y, cv = 10, scoring= \"accuracy\")\n        results.append(cv_results)\n        names.append(name)\n        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n        print(msg)\n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Base Model: Feature Importance "},{"metadata":{"trusted":true},"cell_type":"code","source":"Importance = pd.DataFrame({'Importance':GradientBoostingClassifier().fit(X, y).feature_importances_*100}, \n                          index = X.columns)\n\nImportance.sort_values(by = 'Importance', \n                       axis = 0, \n                       ascending = True).plot(kind = 'barh', \n                                              color = 'r', figsize=(8,6))\n\nplt.xlabel('Variable Importance')\nplt.gca().legend_ = None","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# NEW FEATURES : XGB: 0.897180"},{"metadata":{"trusted":true},"cell_type":"code","source":"df2=df.copy()\ndf2[\"Insulin/Age\"]=df2[\"Insulin\"]/df2[\"Age\"]\ndf2[\"BMI/Age\"]=df2[\"BMI\"]/df2[\"Age\"]\ndf2[\"Pregnancies/Age\"]=df2[\"Pregnancies\"]/df2[\"Age\"]\ndf2[\"Ins*Glu\"]=df2[\"Insulin\"]* df2[\"Glucose\"]\n\ndf2=df2.drop([\"Age\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ÇEŞİTLİ FEATURE DENEMELERİ\n#df2[\"BMI*Skin\"]=df2[\"BMI\"]* df2[\"SkinThickness\"]\n#df2=df2.drop([DiabetesPedigreeFunction\",\"BloodPressure\",\"SkinThickness\"], axis=1)\n#df2=df2.drop([\"BMI\",\"SkinThickness\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df2[\"Outcome\"]\nX = df2.drop([\"Outcome\"], axis = 1)\n\nmodels = []\nmodels.append(('XGB', GradientBoostingClassifier()))\nmodels.append((\"LightGBM\", LGBMClassifier()))\n\n# evaluate each model in turn\nresults = []\nnames = []\n\nfor name, model in models:\n    \n        kfold = KFold(n_splits = 10, random_state = 123456)\n        cv_results = cross_val_score(model, X, y, cv = 10, scoring= \"accuracy\")\n        results.append(cv_results)\n        names.append(name)\n        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n        print(msg)\n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LOF: LightGBM: 0.901154"},{"metadata":{"trusted":true},"cell_type":"code","source":"def lof(dataframe, n,c, numlist, plot_xlim,thr):\n    clf=LocalOutlierFactor(n_neighbors=n, contamination=c)\n    clf.fit_predict(dataframe[numlist])\n    df_scores= clf.negative_outlier_factor_\n    threshold=np.sort(df_scores)[thr]\n    print(np.sort(df_scores)[0:50])\n    pd.DataFrame(np.sort(df_scores)).plot(stacked=True,xlim=[0,plot_xlim], style=\".-\");\n    plt.show()\n    return df_scores,threshold ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols=[col for col in df2.columns if col!=\"Outcome\"]\nscores, threshold =lof(df2, 20, 0.1, cols, 100,50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df3=df2.drop(df2[scores< threshold].index, axis=0).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df3[\"Outcome\"]\nX = df3.drop([\"Outcome\"], axis = 1)\n\nmodels = []\nmodels.append(('XGB', GradientBoostingClassifier()))\nmodels.append((\"LightGBM\", LGBMClassifier()))\n\n# evaluate each model in turn\nresults = []\nnames = []\n\nfor name, model in models:\n    \n        kfold = KFold(n_splits = 10, random_state = 123456)\n        cv_results = cross_val_score(model, X, y, cv = 10, scoring= \"accuracy\")\n        results.append(cv_results)\n        names.append(name)\n        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n        print(msg)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Overfit var mı?\ny = df3[\"Outcome\"]\nX = df3.drop([\"Outcome\"], axis = 1)\nlog_model = LogisticRegression().fit(X,y)\ny_pred = log_model.predict(X)\nprint(accuracy_score(y, y_pred))\nprint(classification_report(y, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}