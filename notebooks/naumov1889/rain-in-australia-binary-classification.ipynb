{"cells":[{"metadata":{"_uuid":"31b2ed2e19ecb0c7f8ac86af880eb5520f7dbdea"},"cell_type":"markdown","source":"The content is daily weather observations from numerous Australian weather stations.\n\nThe target RainTomorrow means: Did it rain the next day? Yes or No."},{"metadata":{"_uuid":"dfb8c6b9ad699dc1784fdbde84ef3b50db086c10"},"cell_type":"markdown","source":"# Importing libraries and dataset"},{"metadata":{"trusted":true,"_uuid":"318f7ab54147832d30f8ed0a6120c4f1fca771ff"},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndata = pd.read_csv('../input/weatherAUS.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1ec9633a0249b6bae5517596f6c8c036de6de6ab"},"cell_type":"markdown","source":"# Exploring the data"},{"metadata":{"trusted":true,"_uuid":"e51ddc36362266a75afc6dde97ea7998b7eb5f0f"},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d7eaf8348da124c92e8578683f37822f80d28ffa"},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"be6d1803bc36fa19c9d12e86121c3b4c6454f36c"},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"ea97dc7003cd33e4948ba24bd9ced7438a43ab12"},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"60b8dd9750ef63186e303095114d6778c26ae049"},"cell_type":"markdown","source":"The dataset has below columns :\n*  **DateThe** — date of observation\n*  **Location** — The common name of the location of the weather station\n*  **MinTemp** — The minimum temperature in degrees celsius\n*  **MaxTemp** — The maximum temperature in degrees celsius\n*  **Rainfall** — The amount of rainfall recorded for the day in mm\n*  **Evaporation** — The so-called Class A pan evaporation (mm) in the 24 hours to 9am\n*  **Sunshine** — The number of hours of bright sunshine in the day.\n*  **WindGustDir** — The direction of the strongest wind gust in the 24 hours to midnight\n*  **WindGustSpeed** — The speed (km/h) of the strongest wind gust in the 24 hours to midnight\n*  **WindDir9am** — Direction of the wind at 9am\n*  **WindDir3pm** — Direction of the wind at 3pm\n*  **WindSpeed9am** — Wind speed (km/hr) averaged over 10 minutes prior to 9am\n*  **WindSpeed3pm** — Wind speed (km/hr) averaged over 10 minutes prior to 3pm\n*  **Humidity9am** — Humidity (percent) at 9am\n*  **Humidity3pm** — Humidity (percent) at 3pm\n*  **Pressure9am** — Atmospheric pressure (hpa) reduced to mean sea level at 9am\n*  **Pressure3pm** — Atmospheric pressure (hpa) reduced to mean sea level at 3pm\n*  **Cloud9am** — Fraction of sky obscured by cloud at 9am. This is measured in \"oktas\", which are a unit of eigths. It records how many eigths of the sky are obscured by cloud. A 0 measure indicates completely clear *  sky whilst an 8 indicates that it is completely overcast.\n*  **Cloud3pm** — Fraction of sky obscured by cloud (in \"oktas\": eighths) at 3pm. See Cload9am for a description of the values\n*  **Temp9am** — Temperature (degrees C) at 9am\n*  **Temp3pm** — Temperature (degrees C) at 3pm\n*  **RainToday** — Boolean: 1 if precipitation (mm) in the 24 hours to 9am exceeds 1mm, otherwise 0\n*  **RISK_MM** — The amount of rain. A kind of measure of the \"risk\".\n*  **RainTomorrow** — The target variable. Did it rain tomorrow?"},{"metadata":{"_uuid":"f4a7ada773daf68d94ec4a21050a456039ba1ba9"},"cell_type":"markdown","source":"The type of machine learning we will be doing is called **classification**, because when we make predictions we are classifying each day as rainy or not. More specifically, we are performing **binary classification**, which means that there are only two different states we are classifying."},{"metadata":{"_uuid":"d97c8405855b1eba3c1b5437c817b7b90e0636dc"},"cell_type":"markdown","source":"# Null values\nLet's get rid of columns with significant amount of null values. And in the rest columns we will drop rows with null values. "},{"metadata":{"trusted":true,"_uuid":"8fb97ccad2bbcb153a19225f66a18249b0a783ef"},"cell_type":"code","source":"data_null_percent = pd.Series(index=data.columns)\n\nfor column_name in data:\n    data_null_percent[column_name] = data[column_name].count()/data.shape[0]\n    \ndata_null_percent_sorted = data_null_percent.sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"21fcccf21c8093c47cd2967eaa2f7e5f8c203f53"},"cell_type":"code","source":"data_null_percent_sorted.plot.barh()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"feb9825778471512260aba8304eb4921c99489a2"},"cell_type":"markdown","source":"**Cloud9pm, Cloud3pm, Evaporation, and Sunshine** must be droped since significant amount of records in these columns is missed. Also we should exclude **RISK_MM** because it can leak the answers to the model and reduce its predictability."},{"metadata":{"trusted":true,"_uuid":"7d2beda1c088243bd2efc32745397745f863f517"},"cell_type":"code","source":"data = data.drop(columns=['Cloud9am','Cloud3pm', 'Evaporation', 'Sunshine','RISK_MM'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da349918a5838d4acbe07b5a40abcadfc543c7d8"},"cell_type":"markdown","source":"Let's drop rows with null values in them."},{"metadata":{"trusted":true,"_uuid":"d7ed6ecad74739a64bd120a8416fe0e3469aa2e6"},"cell_type":"code","source":"data = data.dropna()\ndata.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8af31c194e1ca52de4044cb5ddbb0e4de7876512"},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3fdb0c913618aa87261e8ce8ccc051675efe3d06"},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e5996bd725838255c7fa32a0cb3eba312e189fbe"},"cell_type":"markdown","source":"# Split into train and test\nWe must be aware of one important thing: any change we make to the train data, we also need to make to the test data, otherwise we will be unable to use our model. "},{"metadata":{"trusted":true,"_uuid":"849ac0cd5921dbbeacecae20eb26f39c2a439085"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain, test = train_test_split(data, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49bf48c2332f3dab36db19467685f2c47d35f411"},"cell_type":"code","source":"print(\"train: \" + str(train.shape) + \", test: \" + str(test.shape))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"59fa434dc51ea294cd802f915fccd70d156f3d09"},"cell_type":"markdown","source":"# Deal with categorical variables\nTo apply such algorithms as Logistic Regression we need to convert the non-numeric data into numeric data. Categorical variables with only 2 possible values can be converted into variables with 0s and 1s as values. For categorical variables with 3 and more possible value we will create dummy variables."},{"metadata":{"_uuid":"f9e4c281a66f1138c65f098aabccedcbe06d603b"},"cell_type":"markdown","source":"Convert values in columns \"RainToday\" and \"RainTomorrow\" from **\"No\" and \"Yes\"** to **0 and 1**."},{"metadata":{"trusted":true,"_uuid":"ac71db490d14db29a40cce64a8ce21afcc089ae0"},"cell_type":"code","source":"train[\"RainToday\"] = train[\"RainToday\"].map({\"No\":0, \"Yes\":1})\ntrain[\"RainTomorrow\"] = train[\"RainTomorrow\"].map({\"No\":0, \"Yes\":1})\n\ntest[\"RainToday\"] = test[\"RainToday\"].map({\"No\":0, \"Yes\":1})\ntest[\"RainTomorrow\"] = test[\"RainTomorrow\"].map({\"No\":0, \"Yes\":1})","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0644e21612011e65f33061c101aec404ba449bfd"},"cell_type":"markdown","source":"Visualization of how categorical variables impact on forming tomorrow's rain"},{"metadata":{"trusted":true,"_uuid":"fcab5b1261d913cfc3f7d73bde2c7893804478d4"},"cell_type":"code","source":"def category_impact_plot(variable, subplot_position):\n    plt.subplot(subplot_position)\n    pd.pivot_table(train, index=variable, values='RainTomorrow').plot.bar(figsize=(25,5), ax=plt.gca()) \n   \nplt.figure(1)\ncategory_impact_plot(\"WindGustDir\", 131)\ncategory_impact_plot(\"WindDir9am\", 132)\ncategory_impact_plot(\"WindDir3pm\", 133)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a362b93c2313cd1d828418b3ed2efa040319de60"},"cell_type":"markdown","source":"Create dummy variables for **WindGustDir, WindDir9am, WindDir3pm**"},{"metadata":{"trusted":true,"_uuid":"c47c279ceb82fb36a7be4f0c7ae626edbde770c4"},"cell_type":"code","source":"categorical_variables = [\"WindGustDir\", \"WindDir9am\", \"WindDir3pm\"]\n\ntrain = pd.get_dummies(train, columns=categorical_variables)\ntest = pd.get_dummies(test, columns=categorical_variables)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"4f3d702bdc16be1814a4c110d087d48bcd0de8ab"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"010626553ee3b9e966057d6dac2952c36c5df810"},"cell_type":"markdown","source":"# Does Location affect the formation of rain?"},{"metadata":{"trusted":true,"_uuid":"ebfb1785fefce3c99e4b651df1e42df26986f753"},"cell_type":"code","source":"location_pivot = train.pivot_table(index=\"Location\", values=\"RainTomorrow\")\nlocation_pivot_sorted = location_pivot.sort_values(by=[\"RainTomorrow\"])\n\nlocation_pivot_sorted.plot.barh(figsize=(10,12))\nplt.ylabel('')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e731fe7090814088cd45106290a7d46857c79978"},"cell_type":"markdown","source":"Yes, **Location** obviously affect the formation of tomorrow's rain! So, we're going to use this variable, and in order to use this categorical variable we have to create dummies."},{"metadata":{"trusted":true,"_uuid":"1c062302e3c98834660da59a9c0f1273e0fad34a"},"cell_type":"code","source":"train = pd.get_dummies(train, columns=[\"Location\"])\ntest = pd.get_dummies(test, columns=[\"Location\"])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b5d39c623af266047f9934645597ce1f3aaf0201"},"cell_type":"markdown","source":"# Does Date affect the formation of rain?"},{"metadata":{"trusted":true,"_uuid":"6570c6f8bba2ed4a8ae2f0488af4e64b5568cd7f"},"cell_type":"code","source":"train[\"Month\"] = pd.to_datetime(train[\"Date\"]).dt.month\ntest[\"Month\"] = pd.to_datetime(test[\"Date\"]).dt.month","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e2bbd761b9efcc5a450685087e7f35e81859a4b"},"cell_type":"code","source":"date_pivot = train.pivot_table(index=\"Month\", values=\"RainTomorrow\")#.sort_index(ascending=False)\n\ndate_pivot.plot.barh()\nplt.ylabel('')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5b4cc7158323f9029a6ea6c222f3b155acdf82db"},"cell_type":"markdown","source":"There's a certain tendency, season 6-8 is a rainy season."},{"metadata":{"trusted":true,"_uuid":"db0fc7287870e7efa07d62969bf45893529a6174"},"cell_type":"code","source":"train = pd.get_dummies(train, columns=[\"Month\"])\ntest = pd.get_dummies(test, columns=[\"Month\"])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"89516c26f3d138f10e453d707080bae3f48daf2c"},"cell_type":"markdown","source":"# Rescaling\nLooking at our numeric columns, we can see a big difference between the range of each.  In order to make sure these values are equally weighted within our model, we'll need to rescale the data.\n\nRescaling simply stretches or shrinks the data as needed to be on the same scale, in our case between 0 and 1."},{"metadata":{"trusted":true,"_uuid":"3c778d312db27e3db39fb8ce8d1256ec6d72e467"},"cell_type":"code","source":"# the preprocessing.minmax_scale() function allows us to quickly and easily rescale our data\nfrom sklearn.preprocessing import minmax_scale\n\n# Added 2 backets to make it a dataframe. Otherwise you will get a type error stating cannot iterate over 0-d array.\ndef apply_minmax_scale(dataset, features):\n    for feature in features:\n        dataset[feature] = minmax_scale(dataset[[feature]])\n        \nnumerical_features = [\"MinTemp\",\"MaxTemp\", \"Rainfall\", \"WindGustSpeed\", \"WindSpeed9am\",\n                     \"WindSpeed3pm\", \"Humidity9am\", \"Humidity3pm\", \"Pressure9am\", \n                     \"Pressure3pm\", \"Temp9am\", \"Temp3pm\"]\n\napply_minmax_scale(train, numerical_features)\napply_minmax_scale(test, numerical_features)\n\ntrain[numerical_features].head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1a2385d11c2820b6ae56aae5050decc4d431154b"},"cell_type":"markdown","source":"# Visualization of how numerical variables impact on forming tomorrow's rain"},{"metadata":{"trusted":true,"_uuid":"14869592105a824b28025795ea78d648d0fe4aeb"},"cell_type":"code","source":"rainTomorrow_yes = train[train[\"RainTomorrow\"] == 1]\nrainTomorrow_no = train[train[\"RainTomorrow\"] == 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4da3c57a60ddd43a4b22f07751310fbbf4773408"},"cell_type":"code","source":"def variable_impact_plot(variable, subplot_position):\n    plt.subplot(subplot_position)\n    rainTomorrow_yes[variable].plot.hist(figsize=(25,10), alpha=0.5, color=\"blue\", bins=50, ax=plt.gca())\n    rainTomorrow_no[variable].plot.hist(figsize=(25,10), alpha=0.5, color=\"yellow\", bins=50, ax=plt.gca())\n    plt.ylabel('')\n    plt.xticks([], [])\n    plt.yticks([], [])\n    plt.title(variable)\n\nplt.figure(1)\nvariable_impact_plot(\"MinTemp\", 341)\nvariable_impact_plot(\"MaxTemp\", 342)\nvariable_impact_plot(\"Rainfall\", 343)\nvariable_impact_plot(\"WindGustSpeed\", 344)\nvariable_impact_plot(\"WindSpeed9am\", 345)\nvariable_impact_plot(\"WindSpeed3pm\", 346)\nvariable_impact_plot(\"Humidity9am\", 347)\nvariable_impact_plot(\"Humidity3pm\", 348)\nplt.figure(2)\nvariable_impact_plot(\"Pressure9am\", 341)\nvariable_impact_plot(\"Pressure3pm\", 342)\nvariable_impact_plot(\"Temp9am\", 343)\nvariable_impact_plot(\"Temp3pm\", 344)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"853d1ba44aa4208e8701c584c9dd5e7c2a891ec2"},"cell_type":"markdown","source":"We are intrested in variables with plots where blue and yellow areas have different shapes. Such variables have impact(positive or negative) on forming tomorrow's rain. The most obvious one is **Humidity3pm**! The rest is not that clear, we will use another feature selection method."},{"metadata":{"_uuid":"ee33f0c763d37f8f200051527aaeb9f5813c9ef5"},"cell_type":"markdown","source":"# Collinearity\nWe now have 73 possible feature columns we can use to train our model. One thing to be aware of as you start to add more features is a concept called collinearity. Collinearity occurs where more than one feature contains data that are similar.\n\nThe effect of collinearity is that your model will overfit - you may get great results on your test data set, but then the model performs worse on unseen data (like the test set).\n\n A common way to spot collinearity is to plot correlations between each pair of variables in a heatmap."},{"metadata":{"trusted":true,"_uuid":"75ce8b9914f828834c7eb1a803561a33f212f35a"},"cell_type":"code","source":"# columns we will be using all the way down\ncolumns = list(train.columns[1:])\ncolumns.remove(\"RainTomorrow\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1af0e23dc31e2fdb91874dcf0f9c1b06773640ae"},"cell_type":"code","source":"import seaborn as sns\n\n# custom function to set the style for heatmap\ndef plot_correlation_heatmap(df):\n    corr = df.corr()\n    sns.set(style=\"white\")\n    mask = np.zeros_like(corr, dtype=np.bool)\n    mask[np.triu_indices_from(mask)] = True\n\n    f, ax = plt.subplots(figsize=(30, 25))\n    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n    sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n    plt.show()\n\nplot_correlation_heatmap(train[columns])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5fe4f199d4d286f7f16f675a5efe4fdf91470f22"},"cell_type":"markdown","source":"We can see that there is correlation about 30-50% between some variables. That's not enough to remove one of them and rely on the other.\n\nApart from that, we should remove one of each of our dummy variables to reduce the collinearity in each. We'll remove:\n* WindGustDir_E\n* WindDir9am_E\n* WindDir3pm_E"},{"metadata":{"trusted":true,"_uuid":"b01c064cb7a4837e58a5a2d45fb3ffeb9e5f0537"},"cell_type":"markdown","source":"# Feature selection\nIn order to select the best-performing features, we need a way to measure which of our features are relevant to our outcome - in this case, the impact on forming tomorrow's rain. One effective way is by training a logistic regression model using all of our features, and then looking at the coefficients of each feature.\n\nThe scikit-learn LogisticRegression class has an attribute in which coefficients are stored after the model is fit, LogisticRegression.coef_. We first need to train our model, after which we can access this attribute."},{"metadata":{"trusted":true,"_uuid":"368e67f19c5a95c9c23ac2c5ee88a2191d94c904"},"cell_type":"code","source":"# Applying Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nlogisticRegression = LogisticRegression()\nlogisticRegression.fit(train[columns], train[\"RainTomorrow\"])\ncoefficients = logisticRegression.coef_\nprint(coefficients)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"72ada86197e728c8cd8b69bad4e11d370c5a5a7a"},"cell_type":"markdown","source":"The coef() method returns a NumPy array of coefficients, in the same order as the features that were used to fit the model. To make these easier to interpret, we can convert the coefficients to a pandas series, adding the column names as the index:"},{"metadata":{"trusted":true,"_uuid":"6845e939c7bf964d1c903b02eadc87283ab96942"},"cell_type":"code","source":"feature_importance = pd.Series(coefficients[0], index=columns)\nprint(feature_importance)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f3538f64c80a174cdfe20b95edf1106e8f5d5692"},"cell_type":"code","source":"# Plotting as a horizontal Bar chart\nfeature_importance.plot.barh(figsize=(10,25))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c161eb0d614004de3d44d66656d9a5055fb70cf0"},"cell_type":"markdown","source":"The plot we generated shows a range of both positive and negative values. Whether the value is positive or negative isn't as important in this case, relative to the magnitude of the value. If you think about it, this makes sense. A feature that indicates strongly whether a it's not going to rain tomorrow is just as useful as a feature that indicates strongly that a it's going to rain tomorrow, given they are mutually exclusive outcomes.\n\nTo make things easier to interpret, we'll alter the plot to show all positive values, and have sorted the bars in order of size:"},{"metadata":{"trusted":true,"_uuid":"13ac54660ab96daa26a9637b0f28966babf1954c"},"cell_type":"code","source":"ordered_feature_importance = feature_importance.abs().sort_values()\nordered_feature_importance.plot.barh(figsize=(10,25))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"942db813dbd14151c9fb65d01ee3a46c6c7e1e22"},"cell_type":"markdown","source":"We'll train a model with the top 4 scores."},{"metadata":{"trusted":true,"_uuid":"de4fb218eeadc373d4ce3d361ad5f7c65ca3f9e8"},"cell_type":"code","source":"predictors = [\"Pressure3pm\", \"WindGustSpeed\", \"Pressure9am\", \"Humidity3pm\"]\n\nlr = LogisticRegression()\nlr.fit(train[predictors], train[\"RainTomorrow\"])\npredictions = lr.predict(test[predictors])\nprint(predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4014e6b138401cdb7f2d58f547a6dab67e371d74"},"cell_type":"code","source":"# Calculating the accuracy using the k-fold cross validation method with k=10\nfrom sklearn.model_selection import cross_val_score\nscores = cross_val_score(lr, train[predictors], train[\"RainTomorrow\"], cv=10)\nprint(scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a4fd1d153e18d365476b86c07a82de4515ac5cee"},"cell_type":"code","source":"# Taking the mean of all the scores\naccuracy = scores.mean()\nprint(accuracy)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}