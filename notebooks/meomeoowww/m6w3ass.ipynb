{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Identifying the Groups of Customers "},{"metadata":{},"cell_type":"markdown","source":"As presented in its description:\n\n    \"This is a transnational data set which contains all the transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail.The company mainly sells unique all-occasion gifts. Many customers of the company are wholesalers.\""},{"metadata":{},"cell_type":"markdown","source":"What are the main goals of our notebook ?:"},{"metadata":{},"cell_type":"markdown","source":"## Goals\n**First step:**\n\n* EDA and Data Cleaning\n* Preprocessing\n\n**Second step, we'll try to answer to these questions:**\n\n* Find the \"behaviour\" groups / clusters (Hint: you can use the purchase behaviour for that)\n* Explain, if possible, what clusters you have found (for example, customers purchasing furniture, purchasing jewellery, etc.)\n* How you can use the clusters from the given dataset to make actionable business insights and what will these insights be?"},{"metadata":{},"cell_type":"markdown","source":"## First Step"},{"metadata":{},"cell_type":"markdown","source":"### EDA and Data Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd #import pandas\nimport numpy as np #import numpy\nimport matplotlib.pyplot as plt #import matplotlib.pyplot with plt as alias\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/ecommerce-data/data.csv\", encoding = 'ISO-8859-1') # import csv file","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Different kind of columns with 541.909 rows and 8 columns. First look reveals that:\n* *We can see that there are some column types that are not suitable, as InvoiceDate which is 'object' instead of datetime.*\n* *CustomerID has less filled rows 406.829, which means that there are some Invoices without customer ID.* \n\nAs response to these cases:\n* *Change it's type.*\n* *We will admit that these cases can't be processed and should be dropped, as we want to study customers behaviour.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate']) #InvoiceDate to datetime\ndf = df.dropna() #drop NA","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we are facing an invoice table we are going to have a row for each action made. But are we sure that we don't have any duplicates ?\n\nLet's check if by any means we have duplicates:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df.duplicated(keep=False)].sort_values(by=['InvoiceNo', 'StockCode']).head(2) # select duplicates and show header 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(str('We have {} duplicates.').format(len(df[df.duplicated(keep=False)].sort_values(by=['InvoiceNo', 'StockCode']))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's drop them:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop_duplicates()\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can add total value of purchase as 'Total:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Total'] = df['Quantity'] * df['UnitPrice']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have negative values for quantity (min). How can it be interpreted ?\n\nLet's suppose that these are returns or cancelled purchases.\n\nWe can decide to split our dataset in two (one for valid purchases, another one for negative quantities) or add a new feature giving categories of purchases."},{"metadata":{},"cell_type":"markdown","source":"Purchase behaviour needs to know exactly, a part of invoice detailed level how many products and the amount of purchase."},{"metadata":{"trusted":true},"cell_type":"code","source":"#first option\ndfp = df[df['Quantity']>0]\ndfn = df[df['Quantity']<=0]\n\n#second option\ndfd = df\ndfd['Purchase'] = df['Quantity'].apply(lambda x: 1 if x > 0 else 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For each Customer, Year, Month, Product, Quantity Purchased, Total value purchased could help us get more insights on how customers acts."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(str('As we can see we have {} unique customers for {} description products over {} countries.').format(df.nunique()['CustomerID'], df.nunique()['Description'], df.nunique()['Country']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"recod_df = pd.get_dummies(df[['Description', 'Country']], drop_first = True)\ndfc = pd.concat([df, recod_df], axis=1)\ndfc = dfc.drop(['InvoiceNo', 'StockCode', 'Description', 'Country', 'Purchase', 'InvoiceDate','CustomerID'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfc.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> To study customer,s behaviour, we will focus on Customer ID, Price, Quantity and Total"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import normalize\n\na = dfc[['Quantity', 'UnitPrice', 'Total']]\ndfc_scaled = normalize(a)\ndfc_scaled = pd.DataFrame(dfc_scaled, columns=a.columns)\ndfc_scaled.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = dfc_scaled['Total']\ny1 = dfc_scaled[['Total']]\nX = dfc_scaled.drop('Total', axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1 - Find the &quot;behaviour&quot; groups / clusters (Hint: you can use the purchase behaviour for that)"},{"metadata":{},"cell_type":"markdown","source":"As asked, we are going to focus on total purchases as main feature for classification.\nFor this we will try kmean."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using Kmeans we will try to find first the optimal number of clusters with elbow method\nfrom sklearn.cluster import KMeans #import kmeans\n\nlistkm = [] # define an empty list to add inertia at each number of clusters\n\nfor i in range(1,8):\n    km=KMeans(n_clusters=i,init='k-means++', max_iter=300, n_init=10, random_state=0)\n    km.fit(y1)\n    listkm.append(km.inertia_)\n    \n# Plot it\nplt.plot(range(1,8),listkm, marker ='s')\nplt.title('Plot showing inertia versus number of clusters')\nplt.xlabel('Number of clusters')\nplt.ylabel('Inertia')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"markdown","source":"Optimal number of clusters is 3. let's now fit a 3 clusters kmean:"},{"metadata":{"trusted":true},"cell_type":"code","source":"kms = KMeans(n_clusters=3, random_state=1).fit(X) #kmeans fitting to have our model\npredict = kms.predict(X) #predicting\nctds = kms.cluster_centers_\nprint(ctds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Original array:\")\nprint(predict)\nunique_elements, counts_elements = np.unique(predict, return_counts=True)\nprint(\"Frequency of unique values of the said array:\")\nprint(np.asarray((unique_elements, counts_elements)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(X.iloc[predict == 0, 0], X.iloc[predict == 0, 1], s = 50, c = 'green', label = 'Group 1')\nplt.scatter(X.iloc[predict == 1, 0], X.iloc[predict == 1, 1], s = 50, c = 'yellow', label = 'Group 2')\nplt.scatter(X.iloc[predict == 2, 0], X.iloc[predict == 2, 1], s = 50, c = 'red', label = 'Group 3')\nplt.scatter(kms.cluster_centers_[:, 0], kms.cluster_centers_[:, 1], s = 100, c = 'purple', label = 'Centroids')\nplt.title('Customer clusters on price and quantity')\nplt.xlabel('Quantity')\nplt.ylabel('Unit Price')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Test 2 : PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.decomposition import PCA\n#pca = PCA().fit(dfc)\n#pca_ax2 = pca.transform(dfc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import scipy.cluster.hierarchy as sch\n\n#dist = sch.distance.pdist(dfc, lambda u, v: u != v)\n#merging = sch.linkage(df_scaled, method='ward')\n\n#plt.figure(figsize=(10,10))\n#sch.dendrogram(merging,leaf_font_size=6, leaf_rotation=90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2 â€“ Explain, if possible, what clusters you have found (for example, customers purchasing furniture, purchasing jewellery, etc.)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS\n\ndf_word1 = df[predict == 0]['Description']\ndf_word2 = df[predict == 1]['Description']\ndf_word3 = df[predict == 2]['Description']\n\npatchwork1 = \" \".join(word for word in df_word1)\npatchwork2 = \" \".join(word for word in df_word2)\npatchwork3 = \" \".join(word for word in df_word3)\n\n# Generate a word cloud image\nwordcloud1 = WordCloud(background_color=\"white\").generate(patchwork1)\nwordcloud2 = WordCloud(background_color=\"white\").generate(patchwork2)\nwordcloud3 = WordCloud(background_color=\"white\").generate(patchwork3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot each cluster\nplt.figure(figsize=(36, 12))\nplt.subplots_adjust(top=1.2)\n\nplt.subplot(131)\nplt.imshow(wordcloud1, interpolation='bilinear')\nplt.axis(\"off\")\nplt.title('Cluster 1 : Home furnitures', fontsize=30)\nplt.subplot(132)\nplt.imshow(wordcloud2, interpolation='bilinear')\nplt.axis(\"off\")\nplt.title('Cluster 2 : Travel Bags and others', fontsize=30)\nplt.subplot(133)\nplt.imshow(wordcloud3, interpolation='bilinear')\nplt.axis(\"off\")\nplt.title('Cluster 3 : Birthday events ', fontsize=30)\n\nplt.suptitle('Wordcloud by Cluster', fontsize=70)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3- How you can use the clusters from the given dataset to make actionable business insights and what will these insights be?"},{"metadata":{},"cell_type":"markdown","source":"The above mentioned Clusters are a good hint on what kind of products custommers are fond of. It might be used to recommend other product of the same genre to people of the same cluster."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}