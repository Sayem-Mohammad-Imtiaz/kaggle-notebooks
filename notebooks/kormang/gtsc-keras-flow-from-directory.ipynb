{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport random\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom shutil import copyfile, rmtree","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"INPUT_ROOT = \"../input/\"\ndef from_input(path):\n    return os.path.join(INPUT_ROOT, path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_info = pd.read_csv(from_input(\"Train.csv\"))\ntrain_info.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_info.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_info = pd.read_csv(from_input(\"Test.csv\"))\ntest_info.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_info.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"VALIDATION_RATIO = 0.2\nTRAINING_DIR = '/tmp/ts_train/'\nVALIDATION_DIR = '/tmp/ts_val'\nTEST_DIR = '/tmp/ts_test'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def copy_files(srcdir, dstdir, file_names):\n    for file in file_names:\n        src_file_path = os.path.join(srcdir, file)\n        if os.path.getsize(src_file_path) > 0:\n            try:\n                # Check if image if currupt by by trying to open and flip it.\n                im = Image.open(src_file_path)\n                im.transpose(Image.FLIP_LEFT_RIGHT)\n                im.close()\n                copyfile(src_file_path, os.path.join(dstdir, file))\n            except Exception as e:\n                print(e)\n                print(\"{} is corrupt, skipping\".format(file))\n        else:    \n            print(\"{} is corrupt, skipping\".format(file))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"split_size = 1 - VALIDATION_RATIO\n\nfor i in range(43):\n    print('\\rCopying images of class {}'.format(i), end = '\\r')\n    dst_train_class_dir = os.path.join(TRAINING_DIR, str(i))\n    if os.path.isdir(dst_train_class_dir):\n        rmtree(dst_train_class_dir)\n    os.makedirs(dst_train_class_dir)    \n    dst_val_class_dir = os.path.join(VALIDATION_DIR, str(i))\n    if os.path.isdir(dst_val_class_dir):\n        rmtree(dst_val_class_dir)\n    os.makedirs(dst_val_class_dir)\n    src_class_dir = os.path.join(from_input('train'), str(i))\n    file_names = os.listdir(src_class_dir)\n    # Use custom generator to avoid real randomness\n    # on multiple executions.\n    randgen = random.Random(29)\n    randgen.shuffle(file_names)\n    train_size = int(len(file_names) * split_size)\n    train_file_names = file_names[:train_size]\n    val_file_names = file_names[train_size:]\n    copy_files(src_class_dir, dst_train_class_dir, train_file_names)\n    copy_files(src_class_dir, dst_val_class_dir, val_file_names)\n    \nprint('Done copying files                            ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(43):\n    dir = os.path.join(VALIDATION_DIR, str(i))\n    print('{} contains {} images'.format(dir, len(os.listdir(dir))))\n    dir = os.path.join(TRAINING_DIR, str(i))\n    print('{} contains {} images'.format(dir, len(os.listdir(dir))))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\n\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\n\n# Parameters for our graph; we'll output images in a 4x4 configuration\nnrows = 8\nncols = 6\n\npic_offset = 0 # Index for iterating over images\nvpic_offset = 0 # Index for iterating over validation images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_images(dir, offset):\n    # Set up matplotlib fig, and size it to fit 4x4 pics\n    fig = plt.gcf()\n    fig.set_size_inches(ncols*3, nrows*3)\n\n    for i in range(43):\n        # Set up subplot; subplot indices start at 1\n        sp = plt.subplot(nrows, ncols, i + 1)\n        sp.axis('Off') # Don't show axes (or gridlines)\n        subdir = os.path.join(dir, str(i))\n        files = os.listdir(subdir)\n        img_path = os.path.join(subdir, files[offset % len(files)])\n        img = mpimg.imread(img_path)\n        #print(img.shape)\n        plt.imshow(img)\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_images(TRAINING_DIR, pic_offset)\npic_offset += 1\nshow_images(VALIDATION_DIR, vpic_offset)\nvpic_offset += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class StopOnAccReachedCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if logs['acc'] >= 0.999 and logs['val_acc'] >= 0.999:\n            self.model.stop_training = True\n            print(\"\\nReached accuracy {} at epoch {}, stopping...\".format(logs['acc'], epoch))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TARGET_SIZE = (40, 40)\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Flatten(input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.Dense(256, activation='relu'),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(43, activation='softmax')\n])\n\nmodel.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 300\nclasses = [str(i) for i in range(43)]\n\ntrain_datagen = ImageDataGenerator(rescale=1.0/255.0)\ntrain_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n                                                   target_size=TARGET_SIZE,\n                                                    batch_size=BATCH_SIZE,\n                                                    shuffle=True,\n                                                    seed=17,\n                                                    classes=classes,\n                                                    class_mode='categorical')\n\nvalidation_datagen = ImageDataGenerator(rescale=1.0/255.0)\nvalidation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n                                                   target_size=TARGET_SIZE,\n                                                    batch_size=BATCH_SIZE, #2502,\n                                                    shuffle=False,\n                                                    classes=classes,\n                                                    class_mode='categorical')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(train_generator,\n                              epochs=20,\n                              verbose=1,\n                              callbacks=[\n                                  tf.keras.callbacks.EarlyStopping(monitor='acc', min_delta=0.0001, patience=2),\n                                  StopOnAccReachedCallback()\n                              ],\n                              validation_data=validation_generator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PLOT LOSS AND ACCURACY\n%matplotlib inline\n\nimport matplotlib.image  as mpimg\nimport matplotlib.pyplot as plt\n\n#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\nacc=history.history['acc']\nval_acc=history.history['val_acc']\nloss=history.history['loss']\nval_loss=history.history['val_loss']\n\nepochs=range(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot(epochs, acc, 'r', \"Training Accuracy\")\nplt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\nplt.title('Training and validation accuracy')\nplt.xlabel('Epoch')\nplt.figure()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot(epochs, loss, 'r', \"Training Loss\")\nplt.plot(epochs, val_loss, 'b', \"Validation Loss\")\nplt.xlabel('Epoch')\nplt.title('Training and validation loss')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predicting with the test data\npaths = test_info['Path'].values\ny_test = test_info['ClassId'].values\n\ndata=[]\n    \nsrc_class_dir = from_input(\"test\")\n#file_names = os.listdir(src_class_dir)\nfor i in range(43):\n    print('\\rCopying images of class {}'.format(i), end = '\\r')\n    dst_test_class_dir = os.path.join(TEST_DIR, str(i))\n    if os.path.isdir(dst_test_class_dir):\n        rmtree(dst_test_class_dir)\n    os.makedirs(dst_test_class_dir)    \n    # Use custom generator to avoid real randomness\n    # on multiple executions.\n    file_names = [f.replace('Test/', '') for (j, f) in enumerate(paths) if y_test[j] == i]\n    copy_files(src_class_dir, dst_test_class_dir, file_names)\n\ntest_datagen = ImageDataGenerator(rescale=1.0/255.0)\ntest_generator = test_datagen.flow_from_directory(TEST_DIR,\n                                                   target_size=TARGET_SIZE,\n                                                    batch_size=BATCH_SIZE,\n                                                    classes=classes,\n                                                    class_mode='categorical')\n\nprint(model.metrics_names)\nprint(model.evaluate_generator(test_generator))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predicting with the test data\npaths = test_info['Path'].values\ny_test = test_info['ClassId'].values\nfrom tensorflow.keras.utils import to_categorical\ny_test = to_categorical(y_test, 43)\n\ndata=[]\n#resized_image = None\nfor f in paths:\n    image = Image.open(os.path.join(from_input('test'), f.replace('Test/', '')))\n    resized_image = image.resize(TARGET_SIZE)\n    data.append(np.array(resized_image))\n\nX_test = np.array(data).astype('float32') / 255.0 \n\nresult = model.evaluate(X_test, y_test)\nprint(model.metrics_names)\nprint(result)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}