{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n\nwine = pd.read_csv(\"../input/winequality-red.csv\")\nwine.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wine['quality'] = np.where(wine['quality']<6.5, 'Bad', 'Good')\nwine[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#One hot encoding\nfrom sklearn.preprocessing import LabelEncoder,OneHotEncoder\n#Since many ML alogrithms operate with numerical data well than categorical data,\n#encoding the target variable to have 0 & 1 in place of Good and Bad\nEncoder = LabelEncoder()\nwine['quality'] = Encoder.fit_transform(wine['quality'])\nwine[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = wine.drop('quality',axis = 1)\n\ny  = wine.quality\nwine[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n\nwine.quality.value_counts()\nsns.countplot(wine.quality)\nplt.show()\n#The distribution of the target population classes is skewed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Train test split\nx_train,x_test,y_train,y_test = train_test_split(X,y,test_size = 0.2)\nx_train.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Exploring Classification algorithms\n#Random forest\nfrom sklearn.ensemble import RandomForestClassifier\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import confusion_matrix\nrf = RandomForestClassifier(random_state = 10)\nrf.fit(x_train,y_train)\npred_rfc = rf.predict(x_test)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix\nprint(classification_report(y_test, pred_rfc))\n#Random forest gives 93% accuracy\nprint(confusion_matrix(y_test, pred_rfc))\nplt.figure(figsize=(5,5))\n\ncm_rf = confusion_matrix(y_test,pred_rfc)\n\nplt.suptitle(\"Confusion Matrixes\",fontsize=20)\n\n#plt.subplot(2,3,1)\nplt.title(\"Random Forest Confusion Matrix\")\nsns.heatmap(cm_rf,cbar=False,annot=True,cmap=\"Greens\",fmt=\"d\")\n#Read more about precision and recall in this article\n#https://towardsdatascience.com/model-evaluation-techniques-for-classification-models-eac30092c38b#:~:text=In%20machine%20learning%2C%20we%20often,predicted%20result%20of%20population%20data.&text=The%20training%20dataset%20trains%20the,Decision%20tree%2C%20Naive%20Bayes%20etc.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predctn_RF =pd.DataFrame({'Actual':y_test, 'Predicted':pred_rfc})\npredctn_RF","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print( np.unique( pred_rfc) )\n#Model is predicting for both 0 & 1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Decision Tree\nfrom sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier(random_state = 10)\ndt.fit(x_train,y_train)\npred_dt = dt.predict(x_test)\nprint(classification_report(y_test,pred_dt))\nprint(confusion_matrix(y_test, pred_dt))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(5,5))\ncm_dt = confusion_matrix(y_test,pred_dt)\nplt.suptitle(\"Confusion Matrixes\",fontsize=20)\n\n#plt.subplot(2,3,1)\nplt.title(\"Random Forest Confusion Matrix\")\nsns.heatmap(cm_dt,cbar=False,annot=True,cmap=\"Blues\",fmt=\"d\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predctn_DT =pd.DataFrame({'Actual':y_test, 'Predicted':pred_dt})\npredctn_DT","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print( np.unique( pred_dt) )\n#Model is predicting for both 0 & 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlogit = LogisticRegression()\nlogit.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logit_pred = logit.predict(x_test)\nprint(classification_report(y_test,logit_pred))\nprint(confusion_matrix(y_test, logit_pred))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print( np.unique( logit_pred) )\n#Model is predicting for both 0 & 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(5,5))\n\ncm_lg = confusion_matrix(y_test,logit_pred)\n\nplt.suptitle(\"Confusion Matrixes\",fontsize=20)\n\n#plt.subplot(2,3,1)\nplt.title(\"Random Forest Confusion Matrix\")\nsns.heatmap(cm_lg,cbar=False,annot=True,cmap=\"Oranges\",fmt=\"d\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\n\nsvc1= SVC(random_state = 42, C = 10, gamma = 1, kernel = 'rbf')\nsvc1.fit(x_train, y_train)\n\nac = accuracy_score(y_test,svc1.predict(x_test))\n#accuracies['SVM'] = ac\n\n\nprint('Accuracy is: ',ac, '\\n')\ncm = confusion_matrix(y_test,svc1.predict(x_test))\nsns.heatmap(cm,annot=True,fmt=\"d\")\n\nprint('SVM report\\n',classification_report(y_test, svc1.predict(x_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(x_train.iloc[:, 0], x_train.iloc[:, 1], c=y_train, s=100, cmap='autumn')\n\nplt.scatter(model.support_vectors_[:,0],model.support_vectors_[:,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Here we should not talk about the accuracy but the precision and recall rates, more soon...."},{"metadata":{},"cell_type":"markdown","source":"Please upvote and fork if you find this kernel helpful.Thanks!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}