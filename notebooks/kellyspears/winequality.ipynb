{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Building a Model to Predict Red Wine Quality\n\nUsing the UCI Machine Learning Red Wine Quality dataset, I'll demonstrate how to quickly train and compare different algorithms to build a model that classifies whether a wine is high quality or not.\n\nBelow is an outline of my work:\n\n1. Import libraries and read in the dataset.\n2. Review variable correlation and check dataset for nulls, of which there are none.\n3. Plot wine quality ratings in a histogram and find the 50th percentile.\n4. Build my supervisor ('IsHighQualityWine') based off of 50th percentile value of wine quality column.\n5. All of the data is numerical, so I can move on and separate it into X (independent variables) and Y (our supervisor) to prepare to train models.\n6. Build a function so I can input which algorithm I'd like to train and test with and output metrics such as precision, recall, and f-score.\n7. Finally, build one last function that allows me to run multiple iterations of the BuildModel function with various algorithms."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport sklearn.metrics as metrics\nfrom sklearn.metrics import roc_curve, confusion_matrix, f1_score, recall_score, precision_score, accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import tree\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\n\nfile_path = '/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv'\nquality = pd.read_csv(file_path)\ndisplay(quality)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get an idea of vairable correlation:"},{"metadata":{"trusted":true},"cell_type":"code","source":"correlation = quality.iloc[:,1:].corr()\ndisplay(correlation)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check for nulls in the dataset:"},{"metadata":{"trusted":true},"cell_type":"code","source":"quality.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Look at frequeny of wine quality ratings:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(quality['quality'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Find the 50th percentile of wine quality ratings and use that to build a supervisor, IsHighQualityWine:"},{"metadata":{"trusted":true},"cell_type":"code","source":"isHQ_split = np.percentile(quality['quality'],50)\nprint('I will split wine quality values at ' + str(isHQ_split) + ' to build my supervisor.')\nquality['IsHighQualityWine'] = np.where(quality['quality'] >= isHQ_split,1,0)\nquality.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"My BuildModel function allows the user to train and test a model, evaluate the model, and output the results. It has the ability to use any of four algorithms from: Logistic Regression, Decision Tree, Random Forest, and Naive Bayes."},{"metadata":{"trusted":true},"cell_type":"code","source":"def BuildModel(df, Algorithm, ScaleData = 0):\n    # Separate data into independent and dependent variables\n    X = df.iloc[:,1:-2] # features\n    Y = df.iloc[:,-1] # supervisor\n\n    if ScaleData == 1:\n        from sklearn.preprocessing import StandardScaler\n        scale = StandardScaler()\n        X_scaled = scale.fit_transform(X)\n        X_scaled = pd.DataFrame(X_scaled)\n        X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size = 0.2, random_state = 0)\n    else:\n        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n    \n    # Save training set if need to reference in future when evaluating model\n    TrainingSet = pd.merge(X_train, pd.DataFrame(Y_train), left_index  = True, right_index = True)\n    \n    if Algorithm == 'LogisticRegression':\n        Classifier = LogisticRegression(max_iter=1000)\n\n    if Algorithm == 'DecisionTree':\n        Classifier = tree.DecisionTreeClassifier()\n\n    if Algorithm == 'RandomForest':\n        Classifier = RandomForestClassifier(n_estimators = 1000)\n    \n    if Algorithm == 'NaiveBayes':\n        Classifier = GaussianNB()\n            \n    Classifier = Classifier.fit(X_train,Y_train)\n    Y_pred = Classifier.predict(X_test)\n    \n    # Evaluate model with confusion matrix\n    cf = confusion_matrix(Y_test,Y_pred)\n    f_score = f1_score(Y_test, Y_pred)\n    precision = precision_score(Y_test,Y_pred)\n    recall = recall_score(Y_test,Y_pred)\n    accuracy = accuracy_score(Y_test,Y_pred)\n\n    print('Using the {} classifier, we receive a precision value of {}, recall value of {}, and f-score of {}. \\n' \\\n          .format(Algorithm,round(precision,4),round(recall,4),round(f_score,4)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I'll build a logistic regression model to test my function, first without scaling the features and then with scaling:"},{"metadata":{"trusted":true},"cell_type":"code","source":"BuildModel(quality,'LogisticRegression')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BuildModel(quality,'LogisticRegression', 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The BuildAndCompareModels function below calls the BuildModel function and allows a user to create and compare models built using different algorithms. To use this function, I'll input an array such as ['LogisticRegression','DecisionTree'] and it will loop through to build each model specified. The output will be the precision, recall, and f-score values from each model that was built."},{"metadata":{"trusted":true},"cell_type":"code","source":"def BuildAndCompareModels(df, AlgArray, ScaleData = 0):\n    for i in range(0,len(AlgArray)):\n        BuildModel(df,AlgArray[i],ScaleData)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I'll build all four algorithms and see how they compare."},{"metadata":{"trusted":true},"cell_type":"code","source":"BuildAndCompareModels(quality,['LogisticRegression','NaiveBayes','DecisionTree','RandomForest'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Summary:\n* Logistic Regression, Naive Bayes, and Decision Tree all performed about the same\n* We got slightly higher performance with Random Forest\n* Random Forest compute time was only marginally slower than the other three algorithms\n\nIn order to get the best predictions at a low compute cost, I would choose to deploy the Random Forest model. It's also worth noting that Random Forest is not much more difficult to explain to a client than something like Logistic Regression, so if there was a business need to keep the deployed model simple, this selection would meet that need."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}