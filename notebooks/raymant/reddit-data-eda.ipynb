{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\nreddit_data = pd.read_csv('/kaggle/input/dataisbeautiful/r_dataisbeautiful_posts.csv')\nreddit_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"Dropping columns(author_flair_text, removed_by, total_awards_received, awarders) having more null values(around 90%)"},{"metadata":{"trusted":true},"cell_type":"code","source":"reddit_data1 = reddit_data.drop(['author_flair_text', 'removed_by', 'total_awards_received', 'awarders'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, dropping one null value that is in the title ccolumn."},{"metadata":{"trusted":true},"cell_type":"code","source":"reddit_data1 = reddit_data1.dropna()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As there are some author names that are given as deleted so i will drop them for basic EDA."},{"metadata":{"trusted":true},"cell_type":"code","source":"reddit_data2 = reddit_data1.drop(reddit_data.index[reddit_data['author']=='[deleted]'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now , we will see Top 10 authors having more number of titles written by them."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,6))\nchart = sns.countplot(x = 'author', data = reddit_data2, \n                      order = reddit_data2.author.value_counts().iloc[:10].index)\nchart.set_xticklabels(chart.get_xticklabels(), rotation = 45)\nplt.title('Top 10 authors having more number of titles')\nplt.xlabel('Author')\nplt.ylabel('Number of titles')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we will look at Top 10 titles with most score."},{"metadata":{"trusted":true},"cell_type":"code","source":"reddit_data3 = pd.DataFrame(reddit_data1.groupby('title').agg({'score':['sum']}))\nreddit_data3.columns = ['sum']\n\nreddit_data3 = reddit_data3.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reddit_data3_sorted_desc = reddit_data3.sort_values('sum',ascending = False)\nreddit_data3_sorted_desc.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,6))\n\nchart1 = sns.barplot(x = 'title', y = 'sum', data = reddit_data3_sorted_desc[:10])\nchart1.set_xticklabels(chart1.get_xticklabels(), rotation = 45)\nplt.title('Top 10 titles with most scores')\nplt.xlabel('Title')\nplt.ylabel('Scores')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we will look at Top 10 titles with most number of comments."},{"metadata":{"trusted":true},"cell_type":"code","source":"reddit_data4 = pd.DataFrame(reddit_data1.groupby('title').agg({'num_comments':['sum']}))\nreddit_data4.columns = ['sum']\n\nreddit_data4 = reddit_data4.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reddit_data4_sorted_desc = reddit_data4.sort_values('sum',ascending = False)\nreddit_data4_sorted_desc.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,6))\n\nchart1 = sns.barplot(x = 'title', y = 'sum', data = reddit_data4_sorted_desc[:10])\nchart1.set_xticklabels(chart1.get_xticklabels(), rotation = 45)\nplt.title('Top 10 titles with most number of comments')\nplt.xlabel('Title')\nplt.ylabel('Number of Comments')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reddit_data1['over_18'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As, we can see NSFW articles is only about .5 % of all articles."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(reddit_data1[reddit_data1['over_18'] == True]['score'].mean())\nprint(reddit_data1[reddit_data1['over_18'] == False]['score'].mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The average score as we an see is more for NSFW articles as compared to not NSFW articles. This may be because in our data there are more of not NSFW articles."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(reddit_data1[reddit_data1['over_18'] == True]['num_comments'].mean())\nprint(reddit_data1[reddit_data1['over_18'] == False]['num_comments'].mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here also we can see the average number of comments is more for NSFW artiles."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,8))\n\nsplot = reddit_data1.groupby('over_18').agg({'score':['sum']}).plot.bar()\nfor p in splot.patches:\n    splot.annotate(format(p.get_height(), '.2f'), (p.get_x() + p.get_width() / 2., \n                                                   p.get_height()), ha = 'center', va = 'center', \n                   xytext = (0, 10), textcoords = 'offset points')\nplt.ylabel('Total score')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,8))\n\nsplot = reddit_data1.groupby('over_18').agg({'num_comments':['sum']}).plot.bar()\nfor p in splot.patches:\n    splot.annotate(format(p.get_height(), '.2f'), (p.get_x() + p.get_width() / 2., \n                                                   p.get_height()), ha = 'center', va = 'center', \n                   xytext = (0, 10), textcoords = 'offset points')\nplt.ylabel('Total number of comments')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we will check whether more number of comments is helping to get more score or not."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.regplot(x = 'num_comments', y = 'score', data = reddit_data1[reddit_data1['over_18'] == True])\nplt.title('Number of Comments vs Score')\nplt.xlabel('Number of Comments')\nplt.ylabel('Score')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As, we can observe there is no correlation between number of comments and score."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.residplot(x = 'num_comments', y = 'score', data = reddit_data1[reddit_data1['over_18'] == True])\nplt.title('Residual plot')\nplt.xlabel('Number of Comments')\nplt.ylabel('Score')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we will check for, who have removed the articles?"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(reddit_data[reddit_data['over_18'] == True]['removed_by'].dropna(),)\n\nplt.title('NSFW content')\nplt.xlabel('Removed by')\nplt.ylabel('Count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(reddit_data[reddit_data['over_18'] == False]['removed_by'].dropna())\n\nplt.title('Mass Orinted content')\nplt.xlabel('Removed by')\nplt.ylabel('Count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}