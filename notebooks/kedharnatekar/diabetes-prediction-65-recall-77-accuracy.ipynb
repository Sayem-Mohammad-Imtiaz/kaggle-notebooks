{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Diabetics prediction using logistic regression\n\n#### Kaggle Problem : https://www.kaggle.com/kandij/diabetes-dataset\n\n###  Overview : \nThe data was collected and made available by “National Institute of Diabetes and Digestive and Kidney Diseases” as part of the Pima Indians Diabetes Database. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here belong to the Pima Indian heritage (subgroup of Native Americans), and are females of ages 21 and above.\n\n### Task :\nOur Task is to predict if the patient has diabetes or not. \n\nThe aim is to make sure we dont miss out having a wrong prediction to a diabetic patient as non-diabetic although we are fine if we wrongly classify a non-diabetic patient as diabetic. \n\nHence we should give more importance to Recall score and try finding the algorithm which gives a better Recall score along with good accuracy.\n\nWe will be trying various Classification Algorithms give a better prediction."},{"metadata":{},"cell_type":"markdown","source":"### Importing modules and dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing necessary modules\n\nimport pandas as pd\nimport matplotlib as mp\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nimport os\n\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.feature_selection import SelectKBest, chi2\nfrom sklearn.feature_selection import f_classif\nfrom sklearn.metrics import classification_report\n\nfrom sklearn.linear_model import LogisticRegressionCV\nfrom sklearn import preprocessing\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom xgboost import XGBClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def diabetes_data_import():\n    \"\"\"\n    Function useful for importing a file and converting it to a dataframe\n    \"\"\"\n    fileDir = os.path.dirname(os.path.realpath('__file__'))\n    print(fileDir)\n    relativeDir = '/kaggle/input/diabetes-dataset/diabetes2.csv'\n    filename = os.path.join(fileDir,relativeDir)\n    datafile = pd.read_csv(relativeDir)\n    return datafile","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing the dataset file\ndiab_df = diabetes_data_import()\ndiab_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Understanding the Data "},{"metadata":{"trusted":true},"cell_type":"code","source":"diab_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diab_df.isna().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining a function for Horizonal bar plot \n\ndef plot_counts_bar(data,column,fig_size=(9,4),col='blue',col_annot='grey',water_m=False,water_text='KedNat'):\n    \"\"\"\n    Function plot_counts_bar plots a horizontal bar graph for Value counts for a given Dataframe Attribute.\n    This is much useful in analysis phase in Datascience Projects where data counts for a particular attributes needs to be visualized.\n    Mandatory inputs to this function. \n        1. 'data' where dataframe is given as input \n        2. 'column' where column name is given as input for which we need the value counts.\n    Optional inputs to this function:\n        1. 'fig_size' which represent the figure size for this plot. Default input is (16,9)\n        2. 'col' which represents the color of the bar plot. Default input is 'blue'\n        3. 'col_annot' which represents the color of annotations. Default input is 'grey'\n        4. 'water_m' which represents if we need a watermark text. Default input is boolean as False\n        5. 'water_text' which inputs a string variable used for watermark. Default is KedNat\n    \"\"\"\n    \n    # Figure Size \n    fig, ax = plt.subplots(figsize =fig_size) \n\n    # Defining the dataframe for value counts\n    df = data[column].value_counts().to_frame()\n    df.reset_index(inplace=True)\n    df.set_axis([column ,'Counts'], axis=1, inplace=True)\n    X_data = df[column]\n    y_data = df['Counts']\n\n    # Horizontal Bar Plot \n    ax.barh(X_data, y_data , color=col) \n\n    # Remove axes splines \n    for s in ['top', 'bottom', 'left', 'right']: \n        ax.spines[s].set_visible(False)\n\n    # Remove x, y Ticks \n    ax.xaxis.set_ticks_position('none') \n    ax.yaxis.set_ticks_position('none') \n\n    # Add padding between axes and labels \n    ax.xaxis.set_tick_params(pad = 5) \n    ax.yaxis.set_tick_params(pad = 10) \n\n    # Show top values \n    ax.invert_yaxis()\n    \n    # Add annotation to bars \n    for i in ax.patches: \n        plt.text(i.get_width()+0.2, i.get_y()+0.5,str(round((i.get_width()), 2)),fontsize = 10, fontweight ='bold',color =col_annot) \n\n    # Add Plot Title \n    title = 'Counts of each '+column\n    ax.set_title(title, loc ='left', fontweight=\"bold\" , fontsize=16) \n    \n    # Add Text watermark \n    if water_m == True:\n        fig.text(0.9, 0.15, water_text, fontsize = 12, color ='grey', ha ='right', va ='bottom', alpha = 0.7) \n\n    ax.get_xaxis().set_visible(False)\n\n    # Show Plot \n    plt.show() \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the labels to check the distribution\nplot_counts_bar(diab_df,'Outcome',(8,4),col='green',col_annot='blue')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Splitting the Data into Train and Test datasets"},{"metadata":{},"cell_type":"markdown","source":"As we seen above the ratio of splits with 1 and 0 Outcome is 1:2.\n\nIf we go by normal split we may have a chance to end up having most of the 0 Outcome in Test set. \n\nHence we will be going with StratifiedShuffleSplit approach on Column Outcome"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining a function for Stratified split on a given column\ndef strat_shuffle_split(data,column,testsize=0.2):\n    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n    for train_index, test_index in split.split(data, data[column]):    \n        strat_train_set = data.loc[train_index]    \n        strat_test_set = data.loc[test_index]\n        return(strat_train_set,strat_test_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting into train and test dataset on basis of Stratified split for label\ntrain_set,test_set = strat_shuffle_split(diab_df,'Outcome')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# A check on Outcome in Test Dataset after split\nplot_counts_bar(test_set,'Outcome',(8,4),col='Purple',col_annot='Blue')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Wrangling"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setting up train set \ndiab_df = train_set.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diab_num = diab_df[['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age']]\ny = diab_df['Outcome']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Understanding the data distribution for each independent feature w.r.t label Outcome\nsns.pairplot(diab_df,hue='Outcome')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining a function for Heatmap on a given data\ndef heat_map(data,fig_size=(8,8)):\n\n    fig, ax = plt.subplots(figsize=fig_size)\n    heatmap = sns.heatmap(data,\n                          square = True,\n                          linewidths = .2,\n                          cmap = 'YlGnBu',\n                          cbar_kws = {'shrink': 0.8,'ticks' : [-1, -.5, 0, 0.5, 1]},\n                          vmin = -1,\n                          vmax = 1,\n                          annot = True,\n                          annot_kws = {'size': 12})\n\n    #add the column names as labels\n    ax.set_yticklabels(data.columns, rotation = 0)\n    ax.set_xticklabels(data.columns)\n\n    sns.set_style({'xtick.bottom': True}, {'ytick.left': True})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation Matrix Heatmap for Featutes\nheat_map(diab_num.corr())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Observations made from Pairplot and Correlation Heatmap:</b>\n\n<b>Which Model can be better ?</b>\n\nFor all plots there is no proper way to differentiate Outcome 1 and 0 . i.e overlapping is clear.\n\nData for Outcome cannot be classified using a single straight line.\n\nHence Logistic regression cannot be used here for classification.\n\nKNN or tree based classifiers (Random Forest , XGBoost etc) can fit the data better.\n\n\n<b>Data Insights if any ?</b>\n\nWe could see  lots of values as 0. Eg : For BloodPressure , SkinThickness , Insulin values at 0 form a straight line.\n\nThere are datafixes needed before starting with model selection.\n\nHeatmap shows there is no good correlation within features available. Hence there is no Multicollinerity."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining a Function that gives the stats for no of zeros and nulls in a given dataset\n\ndef get_stats(data,columns,check_zero = True):\n    '''\n    Function get_stats gives the insights of bad data like Nulls of zeros in a given dataframe\n    Mandatory Inputs to this function:\n    data    : Dataframe name\n    columns : Columns in dataframe that needs to be checked \n    Optional inputs to this function:\n    check_zero : True if no of zeros needs to be checked\n    '''\n    print('Count of records in dataframe '+str(data.shape[0])+'\\n')\n    for i in columns:\n        is_na_c = 0\n        zero_c = 0\n        is_na = data[i].isna().any()\n        if is_na == True:\n            is_na_c = data[i].isna().count()\n        if check_zero == True:\n            zero_c = data[i][data[i]<=0].count()\n        print('Column :'+str(i))\n        print('   No of Nulls :'+str(is_na_c)+'   No of Zeros or less :'+str(zero_c))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting stats on Test dataset\nget_stats(diab_num,list(diab_num.columns))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Insulin</b> has 290 nulls out of 614. Almost 50% of data is Null. This Attribute can be removed.\n\n<b>Pregnancies</b> with 0 is a valid condition. Hence Pregnancies with 0 doesnt need a fix."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining an Imputer to fix zero values. Same will be used for Train and Test dataset. \n# This will exclude Pregnancies and Insulin\n\nfrom sklearn.impute import SimpleImputer\nimp = SimpleImputer(missing_values=0, strategy='median')\nimp.fit(diab_num[['Glucose','BloodPressure','SkinThickness','BMI','DiabetesPedigreeFunction','Age']])\nimp.statistics_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function impute_transform can be used to fit a imputer on the given dataset\n\ndef impute_transform(data,imp):\n    '''\n    impute_transform used to fix the dataframe 'data' with given Imputer instance 'imp'.\n    It returns a transformed data in form of dataframe \n    '''\n    print('\\nStats before Imputing :\\n')\n    get_stats(data,list(data.columns))\n    imp_df = imp.transform(data)\n    imp_df = pd.DataFrame(imp_df,columns=list(data.columns))\n    print('\\nStats after Imputing :\\n')\n    get_stats(imp_df,list(imp_df.columns))\n    return imp_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function data_transform is used to Merge Imputed dataframe with Pregnancies and return the cleaned dataframe\n\ndef data_transform(data):\n    '''\n    data_transform merges the transformed dataframe using impute_transform along with Feature 'Pregnancies'\n    '''\n    imputed = impute_transform(data[['Glucose','BloodPressure','SkinThickness','BMI','DiabetesPedigreeFunction','Age']],imp)\n    df = pd.merge(data[['Pregnancies']],imputed,on=data.index)\n    df.drop(columns=['key_0'],inplace=True)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating Independent feature list in X where data is tranformed using imputer\n\nX = data_transform(diab_num)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Feature Selection</b>"},{"metadata":{},"cell_type":"markdown","source":"From earlier analysis for Pair plot we had guessed that Logistic regression will not be a better model.\n\nBut lets try using Logistic regression so as to measure its performance w.r.t other models."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Annova test results for features in X\n\nanova_num = f_classif(X, y)\nx=0\nfor i in X:\n    print('F value for '+i+' is '+str(anova_num[0][x])+' and p-value is '+str(anova_num[1][x]))\n    x+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Selecting Best 3 features based on Annova test \n\ndef k_best_select(X,y,classifier,k):\n    '''\n    'X' features for predict 'y' using classifier as 'classifier' with no of features to be selected as k\n    This function returns the dataframe\n    '''\n    selector = SelectKBest(classifier, k = 3)\n    selector.fit_transform(X, y)\n    cols = selector.get_support(indices=True)\n    X_logreg = X.iloc[:,cols]\n    return X_logreg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_logreg = k_best_select(X,y,f_classif,3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining a function to process Logistic regression Algorithm with splits and Standardization\n\ndef logistic_reg(X,y,cv=5,standardize=True):\n    '''\n    Features representing 'X' for labels 'y' for a Cross validation splits as 'cv'\n    standardize = True uses StandardScaler before fitting the data\n    '''\n    if standardize== True:\n        X = preprocessing.StandardScaler().fit(X).transform(X.astype(float))\n    clf = LogisticRegressionCV(cv=cv, random_state=0).fit(X, y)\n    yhat = clf.predict(X)\n    print('Accuracy score using Logistic regression :'+str(clf.score(X, y)))\n    print ('\\nClassification Report given below :\\n'+str(classification_report(y, yhat)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logistic_reg(X_logreg,y,5,True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Above results we can see that Logistic Regression gives a recall score of 0.56 which is less </b>\n\nLets try other models to check their performances."},{"metadata":{},"cell_type":"markdown","source":"### Model Selection"},{"metadata":{},"cell_type":"markdown","source":"We will be using below Algorithms to test which one suits best on diabetes dataset.\n\n1. KNN Neighbors\n2. Random Forest Classifier\n3. XG Boost Classifier\n\nSince for all the algorithms we need to find the best hyperparameter that fits the data we will used RandomizedSearchCV.\n\nBelow will be the process of finding an optimal model:\n1. Give a wide set of parameters and find the best fit model for given parameters using RandomizedSearchCV.\n2. Using Best fit model get the model's Recall and Accuracy on entire Training set.\n3. Try the best fit model on Test Set directly (since we have not classified into a Validation set due to less data)\n4. Get the Recall and Accuracy on Test set.\n5. Compare the Train and Test dataset Recall and Accuracy scores.\n6. Point 5 will give us idea if the Train model was overfit or underfit.\n7. Modify the parameter set again (either reducing or expanding).\n8. Repeat steps 1 to 6 until we find a model that has low variance on test set and less bias on train set."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining a function which helps in finding the best fit parameters for a given model using RandomizedSearchCV\n\ndef best_fit_search(X,y,estimator,param,n_iter,cv=5,scoring='accuracy',return_model = False):\n    '''\n   This function uses RandomizedSearchCV to search the optimal fit for given set of parameters 'param'.\n   'X' and 'Y' are Features and Labels for a given algorithm 'estimator' for a RandomizedSearchCV that runs for iterations 'n_iter'.\n    No of splits is defined using 'cv' and 'scoring' defines scoring pattern.\n    'return_model' if True then the functions returns the bestfit model.\n    '''\n    search = RandomizedSearchCV(estimator=estimator, param_distributions=param, n_iter=n_iter, n_jobs=-1, cv=cv, random_state=42,scoring=scoring)\n    result = search.fit(X,y)\n    #print('Best parameters for fit : '+str(result.best_params_)+'\\n')\n\n    if return_model == False:\n        print('Best parameters for fit : '+str(result.best_params_)+'\\n')\n        print('Best score for fit :'+str(result.best_score_)+'\\n')\n        print('Best Estimator :'+str(result.best_estimator_)+'\\n')\n    model = result.best_estimator_\n    model.fit(X,y)\n    yhat = model.predict(X)\n    print('Classification Report \\n'+str(classification_report(y, yhat)))\n    if return_model == True:\n        return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### K Nearest Neighbors :"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finding Best fit for K-Nearest Neighbors\nparams = {'n_neighbors' : list(range(2,20))}\nbest_fit_search(X,y,KNeighborsClassifier(),params,18,cv=5,scoring='recall')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>KNN of 3 is the best fit as per cross validations on training set.</b>\n\nSince we have very less data rows creating an extra validation set to test in validation set is not possible. \n\nHence we will test the same in test set directly to get Test set recall and accuracy.\n\nAlthough in this notebook it comes as a code later I had tested it with different parameter sets on test set so that we can find an optimal parameter fit.\n\nBelow are the results"},{"metadata":{"trusted":true},"cell_type":"code","source":"data=[[3,0.71 , 0.84,0.63 , 0.73]]\npd.DataFrame(data,columns=['K-Values','Train_Recall','Train_Accuracy','Test_Recall','Test_Accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>KNN model also performs well on Test set with recall of 0.63 and accuracy of 0.73</b>"},{"metadata":{},"cell_type":"markdown","source":"### Random Forest Classifier :\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {'max_features' : [2,3,4,6] , 'max_depth' : [2,3,4,5,6,7,8] ,'n_estimators': [100]}\nbest_fit_search(X,y,RandomForestClassifier(),params,28,cv=5,scoring='recall')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random Forest model with given set of parameters on training data tends to give a recall of 0.92 and accuracy of 0.96.\n\nBut looking at the parameters of Best fit it seems to be overfit given that it uses depth of 8.\n\nTo test if it really overfits we need to test it on Validation dataset. \n\nBut since we have very less data rows creating an extra validation set is not possible. \n\nHence we will test the same in test set directly to get Test set recall and accuracy.\n\nAlthough in this notebook it comes as a code later I had tested it with different parameter sets on test set so that we can find an optimal parameter fit.\n\nBelow are the results"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = [[100,3,3,0.53 , 0.79,0.48 , 0.73],\n        [100,3,8,0.92 , 0.96,0.59 , 0.75],\n        [100,4,6,0.78 , 0.89,0.56 , 0.74],\n        [100,4,5,0.74 , 0.86,0.57 , 0.74],\n        [100,3,4,0.64 , 0.83,0.50 , 0.73],\n        [100,4,4,0.64 , 0.82,0.56 , 0.75]]\npd.DataFrame(data,columns=['n_estimators','min_child_weight','max_depth','Train_Recall','Train_Accuracy','Test_Recall','Test_Accuracy']).sort_values(by =['Test_Recall','Test_Accuracy'],ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As seen above highest Recall is 0.59 on test set which is less than KNN model 0.63.\n\nRandom Forest seems to overfit the training set a lot when min_child_weight and max_depth depth increases.\n\n<b>Best fit model here is on Index 5 where min_child_weight and max_depth is 4 (which is less than index no 1 ,3) and also gives a test recall of 0.56 and accuracy of 0.75\n\nBut Its seen that KNN performs better than best fit Random Forest model\n</b>"},{"metadata":{},"cell_type":"markdown","source":"### XGBoost Classifier :"},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n'max_depth' : [2,3,4],\n'min_child_weight' : [1,2,3,4,5],\n'n_estimators' : [100,200,300]\n}\nbest_fit_search(X,y,XGBClassifier(),params,40,cv=5,scoring='recall')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Given set of parameters looks an Overfit with 99% Recall.\n\nHence after Testing the model in Test dataset and with different parameter combincations below is the result"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = [[100,3,3,0.83 , 0.96,0.63 , 0.75],\n        [100,3,2,0.81 , 0.90,0.65 , 0.77],\n        [100,1,2,0.85 , 0.91,0.63 , 0.77],\n        [200,1,3,1,1,0.61 , 0.75],\n        [200,5,3,0.95 , 0.98 ,0.65 , 0.75],\n        [100,5,3,0.90 , 0.94,0.65,0.77],\n        [200,5,4,0.99,1,0.63 ,0.72],\n        [300,5,3,0.99 , 1.00,0.67,0.76]]\npd.DataFrame(data,columns=['n_estimators','min_child_weight','max_depth','Train_Recall','Train_Accuracy','Test_Recall','Test_Accuracy']).sort_values(by =['Test_Recall','Test_Accuracy'],ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Best Recall on Test set for XGBoost is 0.67 with accuracy of 0.76 which has max depth of 3 and min_child_weight of 5\n\nBut Index 1 is also good fit as the min_child_weight reduces to 3 and max_depth reduces to 2 with only 100 estimators keeping the the model less complex but giving good Test recall of 0.65 and accuracy of 0.77 on Test Data\n    \nResults from XGBoost are slightly better than KNN and this model can be used over Random Forest or KNN. </b> "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets build the model using XGBoost best test Recall \n\nparams = {'max_depth' : [2],'min_child_weight' : [3],'n_estimators' : [100]}\nmodel = best_fit_search(X,y,XGBClassifier(),params,1,cv=5,scoring='recall',return_model=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Testing the data on Test dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a copy of Test dataset\ndiab_df = test_set.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diab_num = diab_df[['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age']]\ny_test = diab_df['Outcome']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tranforming the Testdatset  features\nX_test = data_transform(diab_num)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting the Outcomes\nyhat_test = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Classification report for XGBoost on Test dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('\\n'+str(classification_report(y_test, yhat_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclusion:\n\n#### Both KNN and XGBoostClassifier can be used for predicting if the patient is diabetic of not. Difference is minimal.\n\n#### Logistic Regression is out of scope for this dataset.\n\n#### Random Forest also doesnt provide good recall score and takes longer time for training the model.\n\n#### In this we successfully implemented XGBoost as final model due to its edge over KNN on recall and accuracy.\n\n#### It gives a Recall score of 0.65 and Accuracy of 0.77."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}