{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7290d3dd-4a95-475d-f097-e871ec17ce9a"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"56e4d4e6-8440-fd8c-bb17-3b20771e383f"},"outputs":[],"source":"movies = pd.read_csv(\"../input/movie_metadata.csv\")\nmovies.info()\nmovies.head()[:2]\nmovies.columns\nmovies.describe()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"63a874b8-f7e0-ecf2-b36f-a685630c5774"},"outputs":[],"source":"print(movies.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"16456dbc-0fb7-ee26-d7f1-f63ed9fec165"},"outputs":[],"source":"movie_nonobj=movies.dtypes[movies.dtypes!='object'].index\nmovie_train=movies[movie_nonobj]\nmovie_train.head()[:4]\nmovie_train.info()\nmovie_train.shape\nmovie_train.describe()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"738cb635-7334-079c-b06d-00296c51c89e"},"outputs":[],"source":"np.sum(movie_train.isnull())\nmovie_train=movie_train.fillna(0)\nmovie_cols=movie_train.columns.tolist()\ny=movie_train['imdb_score']\nmovie_train.drop(['imdb_score'],axis=1,inplace=True)\nmovie_train.head()[:2]\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"885e44d7-f8d9-f724-8a43-8858e4f1c343"},"outputs":[],"source":"mov_corr_mat=movie_train.corr(method='pearson')\nplt.figure(figsize=(20,10))\nsns.heatmap(mov_corr_mat,vmax=1,square=True,annot=True,cmap='cubehelix')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ad90bb0d-bf1c-e701-aa1c-38abe73fc52d"},"outputs":[],"source":"from sklearn.preprocessing import StandardScaler\nmovie_Train=movie_train.values\nmovie_Train=np.asarray(movie_Train)\n\n# Finding normalised array of X_Train\nmovie_norm=StandardScaler().fit_transform(movie_Train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f92727b8-b37d-634f-9503-101cc9bb1d28"},"outputs":[],"source":"from sklearn.decomposition import PCA\npca = PCA().fit(movie_norm)\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.xlim(0,7,1)\nplt.xlabel('Number of components')\nplt.ylabel('Cumulative explained variance')\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b8e3c5aa-85b3-225f-08bd-a657e710fc27"},"outputs":[],"source":"from sklearn.decomposition import PCA\nsklearn_pca=PCA(n_components=5)\nmovie_Train=sklearn_pca.fit_transform(movie_norm)\nsns.set(style='darkgrid')\nm, axis = plt.subplots(figsize=(8, 8))\n\naxis = sns.kdeplot(movie_Train[:,0], movie_Train[:,1], cmap=\"Greens\",\n          shade=True, shade_lowest=False)\naxis = sns.kdeplot(movie_Train[:,1],movie_Train[:,2], cmap=\"Reds\",\n          shade=True, shade_lowest=False)\naxis = sns.kdeplot(movie_Train[:,2], movie_Train[:,3], cmap=\"Blues\",\n          shade=True, shade_lowest=False)\nred = sns.color_palette(\"Reds\")[-2]\nblue = sns.color_palette(\"Blues\")[-2]\ngreen = sns.color_palette(\"Greens\")[-2]\naxis.text(0.5, 0.5, \"2nd and 3rd Projection\", size=12, color=blue)\naxis.text(-4, 0.0, \"1st and 3rd Projection\", size=12, color=red)\naxis.text(2, 0, \"1st and 2nd Projection\", size=12, color=green)\nplt.xlim(-6,5)\nplt.ylim(-2,2)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c2fb4036-62df-4897-d206-b6d5b47c5025"},"outputs":[],"source":"number_of_samples = len(y)\nnp.random.seed(0)\nrandom_indices = np.random.permutation(number_of_samples)\nnum_training_samples = int(number_of_samples*0.8)\nmx_train = movie_Train[random_indices[:num_training_samples]]\nmy_train=y[random_indices[:num_training_samples]]\nmx_test=movie_Train[random_indices[num_training_samples:]]\nmy_test=y[random_indices[num_training_samples:]]\nmy_Train=list(my_train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1ad4ef89-7ea5-5c2b-5729-8c9fe90f1e95"},"outputs":[],"source":"# Ridge Regresson\nfrom sklearn import linear_model\nmodel=linear_model.Ridge()\nmodel.fit(mx_train,my_train)\nmy_predict=model.predict(mx_train)\n\nerror=0\nfor i in range(len(my_Train)):\n    error+=(abs(my_Train[i]-my_predict[i])/my_Train[i])\ntrain_error_ridge=error/len(my_Train)*100\nprint(\"Train error = \"'{}'.format(train_error_ridge)+\" percent in Ridge Regression\")\n\ny_test=model.predict(mx_test)\ny_Predict=list(my_test)\n\nerror=0\nfor i in range(len(my_test)):\n    error+=(abs(y_Predict[i]-y_test[i])/y_Predict[i])\ntest_error_ridge=error/len(y_test)*100\nprint(\"Test error = \"'{}'.format(test_error_ridge)+\" percent in Ridge Regression\")\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"29770f4c-f725-6146-9562-999128efbc84"},"outputs":[],"source":"import matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = (6.0, 6.0)\n\npreds = pd.DataFrame({\"preds\":model.predict(mx_train), \"true\":my_train})\npreds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\npreds.plot(x = \"preds\", y = \"residuals\",kind = \"scatter\")\nplt.title(\"Residual plot in Ridge Regression\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7b73ecc0-c4d1-3791-9442-b0ce4219490e"},"outputs":[],"source":"#Baysian Regression\nreg = linear_model.BayesianRidge()\nreg.fit(mx_train,my_train)\ny1_reg=reg.predict(mx_train)\ny1_reg=list(y1_reg)\ny2_reg=reg.predict(mx_test)\ny2_reg=list(y2_reg)\n\nerror=0\nfor i in range(len(my_train)):\n    error+=(abs(y1_reg[i]-my_Train[i])/my_Train[i])\ntrain_error_bay=error/len(my_Train)*100\nprint(\"Train error = \"+'{}'.format(train_error_bay)+\" percent\"+\" in Bayesian Regression\")\n\nerror=0\nfor i in range(len(my_test)):\n    error+=(abs(y2_reg[i]-y_test[i])/y_test[i])\ntest_error_bay=(error/len(y_test))*100\nprint(\"Test error = \"+'{}'.format(test_error_bay)+\" percent\"+\" in Bayesian Regression\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6efb2914-7485-347d-3466-42cffb364505"},"outputs":[],"source":"import matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = (6.0, 6.0)\npreds = pd.DataFrame({\"preds\":reg.predict(mx_train), \"true\":my_train})\npreds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\npreds.plot(x = \"preds\", y = \"residuals\",kind = \"scatter\")\nplt.title(\"Residual plot in Bayesian Regression\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ac3e7894-86c7-64c8-a971-3dcbb772febc"},"outputs":[],"source":"# KNN Regression\nfrom sklearn import neighbors\nn_neighbors=5\nknn=neighbors.KNeighborsRegressor(n_neighbors,weights='uniform')\nknn.fit(mx_train,my_train)\ny1_knn=knn.predict(mx_train)\ny1_knn=list(y1_knn)\n\nerror=0\nfor i in range(len(my_train)):\n    error+=(abs(y1_knn[i]-my_Train[i])/my_Train[i])\ntrain_error_knn=error/len(my_Train)*100\nprint(\"Train error = \"+'{}'.format(train_error_knn)+\" percent\"+\" in Knn algorithm\")\n\ny2_knn=knn.predict(mx_test)\ny2_knn=list(y2_knn)\nerror=0\nfor i in range(len(my_test)):\n    error+=(abs(y2_knn[i]-y_test[i])/y_test[i])\ntest_error_knn=error/len(y_test)*100\nprint(\"Test error = \"'{}'.format(test_error_knn)+\" percent\"+\" in knn algorithm\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f7567bb3-84ab-0d3d-e681-ec5b56cdd0c9"},"outputs":[],"source":"import matplotlib\n\nmatplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\npreds = pd.DataFrame({\"preds\":knn.predict(mx_train), \"true\":my_train})\npreds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\npreds.plot(x = \"preds\", y = \"residuals\",kind = \"scatter\")\nplt.title(\"Residual plot in Knn\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1b7c6af8-6ac6-b672-0852-c952d53c6e15"},"outputs":[],"source":"#Decission tree regression        \nfrom sklearn import tree\ndec = tree.DecisionTreeRegressor(max_depth=1)\ndec.fit(mx_train,my_train)\ny1_dec=dec.predict(mx_train)\ny1_dec=list(y1_dec)\ny2_dec=dec.predict(mx_test)\ny2_dec=list(y2_dec)\n\nerror=0\nfor i in range(len(my_train)):\n    error+=(abs(y1_dec[i]-my_Train[i])/my_Train[i])\ntrain_error_tree=error/len(my_Train)*100\nprint(\"Train error = \"+'{}'.format(train_error_tree)+\" percent\"+\" in Decision Tree Regressor\")\n\nerror=0\nfor i in range(len(my_test)):\n    error+=(abs(y1_dec[i]-y_test[i])/y_test[i])\ntest_error_tree=error/len(y_test)*100\nprint(\"Test error = \"'{}'.format(test_error_tree)+\" percent in Decision Tree Regressor\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"70b3c1a0-2b4b-6872-1517-a7b60652c637"},"outputs":[],"source":"import matplotlib\nmatplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\npreds = pd.DataFrame({\"preds\":dec.predict(mx_train), \"true\":my_train})\npreds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\npreds.plot(x = \"preds\", y = \"residuals\",kind = \"scatter\")\nplt.title(\"Residual plot in Decision Tree\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d4ae19d6-dac2-7f27-513f-dc626159722a"},"outputs":[],"source":"#SVM Regressor\nfrom sklearn import svm\nsvm_reg=svm.SVR()\nsvm_reg.fit(mx_train,my_train)\ny1_svm=svm_reg.predict(mx_train)\ny1_svm=list(y1_svm)\ny2_svm=svm_reg.predict(mx_test)\ny2_svm=list(y2_svm)\n\nerror=0\nfor i in range(len(my_train)):\n    error+=(abs(y1_svm[i]-my_Train[i])/my_Train[i])\ntrain_error_svm=error/len(my_Train)*100\nprint(\"Train error = \"+'{}'.format(train_error_svm)+\" percent\"+\" in SVM Regressor\")\n\nerror=0\nfor i in range(len(my_test)):\n    error+=(abs(y2_svm[i]-y_test[i])/y_test[i])\ntest_error_svm=error/len(y_test)*100\nprint(\"Test error = \"'{}'.format(test_error_svm)+\" percent in SVM Regressor\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"070f9ee0-501b-d15c-e122-59189760775f"},"outputs":[],"source":"import matplotlib\nmatplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\npreds = pd.DataFrame({\"preds\":svm_reg.predict(mx_train), \"true\":my_train})\npreds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\npreds.plot(x = \"preds\", y = \"residuals\",kind = \"scatter\")\nplt.title(\"Residual plot in SVM\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"28e82bce-2f31-8102-c33e-665f59e9a904"},"outputs":[],"source":"import pandas as pd\ntrain_error=[train_error_ridge,train_error_knn,train_error_bay,train_error_tree,train_error_svm]\ntest_error=[test_error_ridge,test_error_knn,test_error_bay,test_error_tree,test_error_svm]\n\ncol={'Train Error':train_error,'Test Error':test_error}\nmodels=['Ridge Regression','Knn','Bayesian Regression','Decision Tree','SVM']\nerror_matching=pd.DataFrame(data=col,index=models)\nerror_matching"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"35e559d8-682e-5e67-ff51-c4c686908ba3"},"outputs":[],"source":"Looks KNN has the best Model"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}