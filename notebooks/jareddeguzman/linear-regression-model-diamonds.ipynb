{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"filepath = '../input/diamonds/diamonds.csv'\ndiamond_data = pd.read_csv(filepath, index_col=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diamond_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diamond_data.head()\ndiamond_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now looking at the qualitative data...","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\ndataTypes = (diamond_data.dtypes == 'object')\ncategories = list(dataTypes[dataTypes].index)\n\ndiamond_data_cat = diamond_data.copy()\nlabel_encoder = LabelEncoder()\n\nfor category in categories:\n    diamond_data_cat[category] = label_encoder.fit_transform(diamond_data_cat[category])\n    \ndiamond_data_cat.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_correlation = diamond_data_cat.corr(method='pearson')\nmask = np.triu(np.ones_like(data_correlation, dtype=np.bool))\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\nplt.figure(figsize=(30, 10))\nsns.heatmap(data_correlation, cmap=cmap, vmax=.3, center=0, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unstacked_correlation = data_correlation.abs().unstack()\nsorted_correlation = unstacked_correlation.sort_values(kind='quicksort', ascending=False)\nsorted_correlation['price']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nsns.regplot(data=diamond_data, x='carat', y='price')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nsns.regplot(data=diamond_data, x='x', y='price')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nsns.regplot(x=np.log(diamond_data['x']), y=np.log(diamond_data['price']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Coding the Model:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n#Select Columns here:\nX_columns = ['carat', 'x', 'y', 'z']\ny_columns = ['price']\nX = diamond_data_cat[X_columns]\ny = diamond_data[y_columns]\n\n#splitting the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LinearRegression().fit(X_train, np.log(y_train))\npredictions = model.predict(X_test)\nX_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stats_df = pd.DataFrame(X_test.copy())\nstats_df['price'] = y_test['price'].copy()\nstats_df['predictions'] = predictions.copy()\nstats_df['predictions'] = np.exp(stats_df['predictions'])\nstats_df.sort_values(by='carat')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nimport math\n\n#Finding the RMSE of the model\nmse = mean_squared_error(predictions, y_test['price'])\nrmse = math.sqrt(mse)\nrmse","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Getting the log values of price and inserting it to the prediction removes negative values. However, it inflates the overall predictions making it inaccurate in general. The code below shows a lower RMSE with negative values on the table.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"second_model = LinearRegression().fit(X_train, y_train)\nsecond_predictions = second_model.predict(X_test)\nsecond_metric = mean_squared_error(second_predictions, y_test['price'])\nsecond_metric = math.sqrt(second_metric)\nsecond_metric","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"second_stats_df = pd.DataFrame(X_test.copy())\nsecond_stats_df['price'] = y_test['price'].copy()\nsecond_stats_df['predictions'] = second_predictions.copy()\nsecond_stats_df['predictions'] = second_stats_df['predictions']\nsecond_stats_df.sort_values(by='carat')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Personal Skills Gained:\n-As someone new, I familiarized myself with Categorical Feature labelling and feature selection. Using the correlation heatmap helped me find relevant features more effectively.\n\nMy Takeaways:\n-Linear Regression fits \"ok\" with the data. But, it doesn't accurately predict the ends of the values of each feature.\n\nAdjustments that can be done:\n- remove carat values that are lesser than 0.5\n","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}