{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Note: still a work in progress**\n\nAs a beginner to data-science, I've just chosen a dataset that I am interested in right now. \nMore details would be explained as we go.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport json\nimport ast\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"tft_data_filepath = '../input/tft-match-data/TFT_GrandMaster_MatchData.csv'\ntft_df = pd.read_csv(tft_data_filepath)\ntft_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cleaning and selecting data for the model:\n\nModel Assumptions:\nThe game ID/session that the player is under is not accounted for, including:\n* Contested/Counter picks within rounds \n* Possible item combinations and available items within the game","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Choosing Columns\nimportant_columns = ['level', 'lastRound', 'Ranked', 'combination']\nclean_tft_data = tft_df.copy()\n\n#Choosing the first 500 rows to quicken computations\nclean_tft_data = clean_tft_data[important_columns][0:500]\nclean_tft_data.head()\n\n#DataFrame for the \"Data-Science Aspect\"\nstatistical_df = tft_df.copy()\ncomposition_column = statistical_df['combination']\nshortened_composition_column = composition_column[0:500]\n\n#Querying Columns from the DataFrame\nX_columns = ['combination', 'lastRound', 'level']\ny_column = ['Ranked']\nX = clean_tft_data[X_columns]\ny = clean_tft_data[y_column]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shortened_statistical_df = statistical_df.copy()[0:1000]\nshortened_statistical_df['combination'] = shortened_statistical_df['combination'].apply(lambda x: ast.literal_eval(x))\nteam_comp_column = shortened_statistical_df['combination']\n\nteam_comp_dict = team_comp_column.copy().to_dict()\nteam_comp_list = [values for values in team_comp_dict.values()]\ndistinct_classes = []\nfor el in team_comp_list:\n    for item in el:\n        if item not in distinct_classes:\n            distinct_classes.append(item)\n            \nfor item in distinct_classes:\n    shortened_statistical_df[item] = 0\n    \ntrait_only_columns = shortened_statistical_df.copy()[distinct_classes]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#trait_only_columns['Blaster'] \n#trait_only_columns['Blaster'] = shortened_statistical_df['combination']['Blaster']\n\n\n#trait_only_columns['Blaster'].map(team_comp_dict['Blaster']) #I think .map() is the answer I'm looking for.\n#team_comp_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"raw","source":"","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Statistical Analysis**\n\nAlong with the predictions, I want to find the relationships of the following:\n* Correlation between gameDuration and level\n* Frequency of different unit types in relation to rank and gameDuration\n\nVisualizing these sets of data can serve as a meta snapshot for the current TFT patch. Korean metas (Most Effective Tactics Available) are already known by the time this is created. However, I feel like this would be a fun project: to back up what's meta with actual numbers from hundreds of different matches in the lobby.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Cleaning the data for the classification model that would predict the rank of the player in each match given the team compositions**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Splitting data into training and testing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking if data in a column do not have numerical values:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"s = (X_train.dtypes == 'object')\ncategorical_cols = list(s[s].index)\nprint('Categorical Columns:')\nprint(categorical_cols)\nnumerical_cols = list(set(X_train.columns) - set(categorical_cols))\nprint(numerical_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\n\nnumerical_transformer = SimpleImputer(strategy='constant')\n\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ]\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Part 2: Using Different Models on the Processed Data**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Using the RandomForestRegressor","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nmodel = RandomForestRegressor(random_state=0, n_estimators=100)\nfirst_pipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('forest_model', model)\n])\nfirst_pipeline.fit(X_train, y_train)\nfirst_pipeline_predictions = first_pipeline.predict(X_valid)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Using the DecisionTreeRegressor**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nsecond_model = DecisionTreeRegressor(random_state=1)\nsecond_pipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('DecisionTreeRegressor', second_model)\n])\n\nsecond_pipeline.fit(X_train, y_train)\nsecond_pipeline_predictions = second_pipeline.predict(X_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\nprint(\"Random Forest MAE\")\nprint(mean_absolute_error(first_pipeline_predictions, y_valid))\nprint('')\nprint('Decision Tree Regressor MAE')\nprint(mean_absolute_error(second_pipeline_predictions, y_valid))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The MAE for both models is roughly around 0.75. TFT's gives drastically different LP gains depending on what rank the player finishes. Decreasing the error to around 0.5 or less would be considered a good estimator for the rank of the player in each game.\n\nFuture tasks to work on:\n* Find better parameters to suit the models\n* Reorganize data in such a way that the match id is better accounted for\n* Add actual champion details to model\n\n","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}