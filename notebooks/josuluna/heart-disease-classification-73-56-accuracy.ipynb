{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"I accept any type of criticism or comment about the code, it is my first project here in kaggle\n\n\n# Predicting heart disease with Sklearn\n\nThis notebook uses python and many helpful libraries to predict whether or not a patient has heart disease training a machine learning model with the dataset from https://www.kaggle.com/sulianova/cardiovascular-disease-dataset\n\n## Data and features\nData description\nThere are 3 types of input features:\n\nObjective: factual information;\nExamination: results of medical examination;\nSubjective: information given by the patient.\nFeatures:\n\n- Age: Objective Feature | age | int (days)\n- Height: Objective Feature | height | int (cm) |\n- Weight: Objective Feature | weight | float (kg) |\n- Gender: Objective Feature | gender | categorical code | 1 - women, 2 - men\n- Systolic blood pressure: Examination Feature | ap_hi | int |\n- Diastolic blood pressure: Examination Feature | ap_lo | int |\n- Cholesterol | Examination Feature | cholesterol | 1: normal, 2: above normal, 3: well above normal |\n- Glucose: Examination Feature | gluc | 1: normal, 2: above normal, 3: well above normal |\n- Smoking: Subjective Feature | smoke | binary |\n- Alcohol intake: Subjective Feature | alco | binary |\n- Physical activity: Subjective Feature | active | binary |\n- Presence or absence of cardiovascular disease: Target Variable | cardio | binary | 1 = disease, 0 = no disease","metadata":{}},{"cell_type":"code","source":"# imports for data analysis and plot\nimport numpy as np\nimport pandas as pd\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# import models to use from sklearn\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.linear_model import LogisticRegression\n\n# import fuctions for model evaluation and tuning \nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score, recall_score, precision_score, plot_roc_curve","metadata":{"execution":{"iopub.status.busy":"2021-08-28T23:41:16.672591Z","iopub.execute_input":"2021-08-28T23:41:16.673132Z","iopub.status.idle":"2021-08-28T23:41:16.681205Z","shell.execute_reply.started":"2021-08-28T23:41:16.673081Z","shell.execute_reply":"2021-08-28T23:41:16.679922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Import the data and view it","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/cardiovascular-disease-dataset/cardio_train.csv', sep = ';')\ndata","metadata":{"execution":{"iopub.status.busy":"2021-08-28T23:41:16.683043Z","iopub.execute_input":"2021-08-28T23:41:16.683465Z","iopub.status.idle":"2021-08-28T23:41:16.84525Z","shell.execute_reply.started":"2021-08-28T23:41:16.683421Z","shell.execute_reply":"2021-08-28T23:41:16.844186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Drop the `id` column, because is useless","metadata":{}},{"cell_type":"code","source":"data.drop(labels = 'id', axis = 1, inplace = True)\ndata","metadata":{"execution":{"iopub.status.busy":"2021-08-28T23:41:16.846874Z","iopub.execute_input":"2021-08-28T23:41:16.84717Z","iopub.status.idle":"2021-08-28T23:41:16.87255Z","shell.execute_reply.started":"2021-08-28T23:41:16.847142Z","shell.execute_reply":"2021-08-28T23:41:16.871458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check how many samples of each class there are and plot it \ndata['cardio'].value_counts().plot(kind = 'bar');","metadata":{"execution":{"iopub.status.busy":"2021-08-28T23:41:16.874563Z","iopub.execute_input":"2021-08-28T23:41:16.874959Z","iopub.status.idle":"2021-08-28T23:41:17.047652Z","shell.execute_reply.started":"2021-08-28T23:41:16.874916Z","shell.execute_reply":"2021-08-28T23:41:17.046456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check datatypes in our data\ndata.info()","metadata":{"execution":{"iopub.status.busy":"2021-08-28T23:41:17.048971Z","iopub.execute_input":"2021-08-28T23:41:17.049296Z","iopub.status.idle":"2021-08-28T23:41:17.067412Z","shell.execute_reply.started":"2021-08-28T23:41:17.049256Z","shell.execute_reply":"2021-08-28T23:41:17.06643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# view information about our data\ndata.describe()","metadata":{"execution":{"iopub.status.busy":"2021-08-28T23:41:17.068777Z","iopub.execute_input":"2021-08-28T23:41:17.069043Z","iopub.status.idle":"2021-08-28T23:41:17.139015Z","shell.execute_reply.started":"2021-08-28T23:41:17.069016Z","shell.execute_reply":"2021-08-28T23:41:17.138142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# use pd.crosstab to check the heart disease frequency acording to the gender and plot it\npd.crosstab(data['cardio'], data['gender']).plot(kind = 'bar')\nplt.xlabel('0 = no heart disease, 1 = heart disease')\nplt.legend(['woman','man'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-28T23:41:17.140245Z","iopub.execute_input":"2021-08-28T23:41:17.140514Z","iopub.status.idle":"2021-08-28T23:41:17.313947Z","shell.execute_reply.started":"2021-08-28T23:41:17.140486Z","shell.execute_reply":"2021-08-28T23:41:17.313052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### We can se that it is more common for women to have heart disease in this dataset \n\n### View the distribution of the age using a histogram (remember that the age is in days)","metadata":{}},{"cell_type":"code","source":"data['age'].T.hist(bins = 40)","metadata":{"execution":{"iopub.status.busy":"2021-08-28T23:41:17.315151Z","iopub.execute_input":"2021-08-28T23:41:17.315427Z","iopub.status.idle":"2021-08-28T23:41:17.532426Z","shell.execute_reply.started":"2021-08-28T23:41:17.315398Z","shell.execute_reply":"2021-08-28T23:41:17.531492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Make a correlation matrix and plot it using seaborn ","metadata":{}},{"cell_type":"code","source":"corr_matrix = data.corr()\nfig, ax = plt.subplots(figsize = (15,10))\nax = sns.heatmap(\n    corr_matrix, \n    annot = True, \n    linewidths = 0.5,\n    fmt = '0.2f', \n    cmap = 'GnBu'\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-28T23:41:17.534807Z","iopub.execute_input":"2021-08-28T23:41:17.535098Z","iopub.status.idle":"2021-08-28T23:41:18.655056Z","shell.execute_reply.started":"2021-08-28T23:41:17.535058Z","shell.execute_reply":"2021-08-28T23:41:18.654016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We can se a positive correlation betweeen the gender an if the patient smoke or not, lets see it in a bar graph ","metadata":{}},{"cell_type":"code","source":"pd.crosstab(data['smoke'], data['gender']).plot(kind = 'bar')\nplt.xlabel('0 = no smoke, 1 = smoke')\nplt.legend(['woman','man'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-28T23:41:18.657338Z","iopub.execute_input":"2021-08-28T23:41:18.657734Z","iopub.status.idle":"2021-08-28T23:41:18.800782Z","shell.execute_reply.started":"2021-08-28T23:41:18.657695Z","shell.execute_reply":"2021-08-28T23:41:18.799718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### In proportion, there are many more male smokers than female smokers \n\n## Creating models","metadata":{}},{"cell_type":"code","source":"# Split data into X and y\nX = data.drop(labels = 'cardio', axis = 1)\ny = data['cardio']","metadata":{"execution":{"iopub.status.busy":"2021-08-28T23:41:18.802103Z","iopub.execute_input":"2021-08-28T23:41:18.802365Z","iopub.status.idle":"2021-08-28T23:41:18.810322Z","shell.execute_reply.started":"2021-08-28T23:41:18.802339Z","shell.execute_reply":"2021-08-28T23:41:18.809365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split the data into training and test datasets\nnp.random.seed(42)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)","metadata":{"execution":{"iopub.status.busy":"2021-08-28T23:41:18.811586Z","iopub.execute_input":"2021-08-28T23:41:18.811855Z","iopub.status.idle":"2021-08-28T23:41:18.839057Z","shell.execute_reply.started":"2021-08-28T23:41:18.811819Z","shell.execute_reply":"2021-08-28T23:41:18.838229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### In this notebook we are going to build, test and tune 2 sklearn machine learning models\n - `RandomForestClassifier()`\n - `LogisticRegression()`","metadata":{}},{"cell_type":"markdown","source":"### Create and fit a stock random forest classifier","metadata":{}},{"cell_type":"code","source":"np.random.seed(7)\nclf = RandomForestClassifier()\nclf.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-28T23:41:18.840324Z","iopub.execute_input":"2021-08-28T23:41:18.840596Z","iopub.status.idle":"2021-08-28T23:41:27.007135Z","shell.execute_reply.started":"2021-08-28T23:41:18.840561Z","shell.execute_reply":"2021-08-28T23:41:27.006096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluate the stock model on test data\nclf.score(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-28T23:41:27.008318Z","iopub.execute_input":"2021-08-28T23:41:27.008736Z","iopub.status.idle":"2021-08-28T23:41:27.530027Z","shell.execute_reply.started":"2021-08-28T23:41:27.008701Z","shell.execute_reply":"2021-08-28T23:41:27.52915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Improving this score tuning the hyperparameters with `RandomizedSearchCV()`","metadata":{}},{"cell_type":"code","source":"# grid of hyperparameters to tune\nrandom_forest_grid = {\n    'n_estimators': np.arange(10,1000, 50),\n    'max_depth': [None, 3, 5, 10],\n    'min_samples_split': np.arange(2,20,2),\n    'min_samples_leaf': np.arange(1,20,2)\n}","metadata":{"execution":{"iopub.status.busy":"2021-08-28T23:41:27.531246Z","iopub.execute_input":"2021-08-28T23:41:27.531587Z","iopub.status.idle":"2021-08-28T23:41:27.537103Z","shell.execute_reply.started":"2021-08-28T23:41:27.53156Z","shell.execute_reply":"2021-08-28T23:41:27.535893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(7)\n\nrandom_search_rf = RandomizedSearchCV(\n    RandomForestClassifier(),\n    param_distributions = random_forest_grid,\n    cv = 5,\n    n_iter = 25,\n    verbose = True,\n    n_jobs = -1\n)\n\n# Fit random search for random forest classifier\nrandom_search_rf.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-28T23:41:27.538672Z","iopub.execute_input":"2021-08-28T23:41:27.53919Z","iopub.status.idle":"2021-08-28T23:56:57.379266Z","shell.execute_reply.started":"2021-08-28T23:41:27.539142Z","shell.execute_reply":"2021-08-28T23:56:57.378147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check wich are the best params\nrandom_search_rf.best_params_","metadata":{"execution":{"iopub.status.busy":"2021-08-28T23:56:57.38102Z","iopub.execute_input":"2021-08-28T23:56:57.381433Z","iopub.status.idle":"2021-08-28T23:56:57.388521Z","shell.execute_reply.started":"2021-08-28T23:56:57.381384Z","shell.execute_reply":"2021-08-28T23:56:57.387605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluate the model on the test data using the score method\nrandom_search_rf.score(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-28T23:56:57.389716Z","iopub.execute_input":"2021-08-28T23:56:57.389983Z","iopub.status.idle":"2021-08-28T23:56:59.405389Z","shell.execute_reply.started":"2021-08-28T23:56:57.389956Z","shell.execute_reply":"2021-08-28T23:56:59.404455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluating the RandomForestClassifier model","metadata":{}},{"cell_type":"code","source":"# make some predictions to calculate evaluation metrics\ny_preds = random_search_rf.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-28T23:56:59.406655Z","iopub.execute_input":"2021-08-28T23:56:59.40693Z","iopub.status.idle":"2021-08-28T23:57:01.382203Z","shell.execute_reply.started":"2021-08-28T23:56:59.406902Z","shell.execute_reply":"2021-08-28T23:57:01.381288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_preds","metadata":{"execution":{"iopub.status.busy":"2021-08-28T23:57:01.383392Z","iopub.execute_input":"2021-08-28T23:57:01.383651Z","iopub.status.idle":"2021-08-28T23:57:01.390277Z","shell.execute_reply.started":"2021-08-28T23:57:01.383625Z","shell.execute_reply":"2021-08-28T23:57:01.389325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ROC curve and Area under the curve\nAUC of 0.8 is acceptable, but not exellent ","metadata":{}},{"cell_type":"code","source":"plot_roc_curve(random_search_rf, X_test, y_test);","metadata":{"execution":{"iopub.status.busy":"2021-08-28T23:57:01.391853Z","iopub.execute_input":"2021-08-28T23:57:01.392251Z","iopub.status.idle":"2021-08-28T23:57:03.530678Z","shell.execute_reply.started":"2021-08-28T23:57:01.392211Z","shell.execute_reply":"2021-08-28T23:57:03.529622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Making a confussion matrix and ploting it using `sns.heatmap`","metadata":{}},{"cell_type":"code","source":"# make a fucntion for ploting the confussion matrix for later use\nsns.set(font_scale = 1.5)\ndef conf_matrix(y_true, y_preds):\n    fig, ax = plt.subplots(figsize = (5,5))\n    ax = sns.heatmap(\n        confusion_matrix(y_true,y_preds),\n        annot=True,\n        cbar = False,\n        fmt = 'g'\n    ) \n    plt.xlabel('Predicted Label')\n    plt.ylabel('True Label')","metadata":{"execution":{"iopub.status.busy":"2021-08-28T23:57:03.532198Z","iopub.execute_input":"2021-08-28T23:57:03.532595Z","iopub.status.idle":"2021-08-28T23:57:03.540943Z","shell.execute_reply.started":"2021-08-28T23:57:03.532554Z","shell.execute_reply":"2021-08-28T23:57:03.539811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting the confusion matrix of our randomforestclassifier model\nconf_matrix(y_test,y_preds)","metadata":{"execution":{"iopub.status.busy":"2021-08-28T23:57:03.542757Z","iopub.execute_input":"2021-08-28T23:57:03.543285Z","iopub.status.idle":"2021-08-28T23:57:03.72333Z","shell.execute_reply.started":"2021-08-28T23:57:03.543232Z","shell.execute_reply":"2021-08-28T23:57:03.722226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The confusion matrix shows a high number of false-negative predictions, lets see the precision predicting each category with a classification report:\n\n### Classification report","metadata":{}},{"cell_type":"code","source":"print(classification_report(y_test, y_preds))","metadata":{"execution":{"iopub.status.busy":"2021-08-28T23:57:03.724615Z","iopub.execute_input":"2021-08-28T23:57:03.724896Z","iopub.status.idle":"2021-08-28T23:57:03.761274Z","shell.execute_reply.started":"2021-08-28T23:57:03.724866Z","shell.execute_reply":"2021-08-28T23:57:03.760179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluation metrics calculated using cross validation","metadata":{}},{"cell_type":"code","source":"# Check the best params for the RandomForestClassifier\nrandom_search_rf.best_params_","metadata":{"execution":{"iopub.status.busy":"2021-08-28T23:57:03.762454Z","iopub.execute_input":"2021-08-28T23:57:03.762701Z","iopub.status.idle":"2021-08-28T23:57:03.767709Z","shell.execute_reply.started":"2021-08-28T23:57:03.762675Z","shell.execute_reply":"2021-08-28T23:57:03.766819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a RandomForestClassifier instance with the best params\nrf_clf = RandomForestClassifier(\n    n_estimators = 910,\n    min_samples_split = 4,\n    min_samples_leaf = 15,\n    max_depth = 10\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-28T23:57:03.768857Z","iopub.execute_input":"2021-08-28T23:57:03.769208Z","iopub.status.idle":"2021-08-28T23:57:03.779443Z","shell.execute_reply.started":"2021-08-28T23:57:03.769179Z","shell.execute_reply":"2021-08-28T23:57:03.778532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use cross_validation and the scoring parameter to evaluate the classifier and make a function for later use\ndef cv_classification_report(classifier, X, y):\n    \n    cv_accuracy = cross_val_score(classifier, X, y, scoring = 'accuracy', n_jobs = -1)\n    cv_accuracy = np.mean(cv_accuracy)\n    \n    cv_precision = cross_val_score(classifier, X, y, scoring = 'precision', n_jobs = -1)\n    cv_precision = np.mean(cv_precision)\n    \n    cv_recall = cross_val_score(classifier,X,y,scoring = 'recall', n_jobs = -1)\n    cv_recall = np.mean(cv_recall)\n    \n    cv_f1 = cross_val_score(classifier, X, y, scoring = 'f1', n_jobs = -1)\n    cv_f1 = np.mean(cv_f1)\n    \n    return {\n    'Accuracy': cv_accuracy,\n    'Precision': cv_precision,\n    'Recall': cv_recall,\n    'F1 Score': cv_f1\n    }","metadata":{"execution":{"iopub.status.busy":"2021-08-28T23:57:03.782948Z","iopub.execute_input":"2021-08-28T23:57:03.783443Z","iopub.status.idle":"2021-08-28T23:57:03.790561Z","shell.execute_reply.started":"2021-08-28T23:57:03.783399Z","shell.execute_reply":"2021-08-28T23:57:03.789863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# use the function\ncv_metrics = cv_classification_report(rf_clf, X, y)","metadata":{"execution":{"iopub.status.busy":"2021-08-28T23:57:03.792145Z","iopub.execute_input":"2021-08-28T23:57:03.792581Z","iopub.status.idle":"2021-08-29T00:03:29.514537Z","shell.execute_reply.started":"2021-08-28T23:57:03.79254Z","shell.execute_reply":"2021-08-29T00:03:29.513787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# view the cross-validated metrics\ncv_metrics","metadata":{"execution":{"iopub.status.busy":"2021-08-29T00:03:29.515491Z","iopub.execute_input":"2021-08-29T00:03:29.515762Z","iopub.status.idle":"2021-08-29T00:03:29.521606Z","shell.execute_reply.started":"2021-08-29T00:03:29.515734Z","shell.execute_reply":"2021-08-29T00:03:29.520744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save the metrics in a pandas dataframe and plot it in a bar graph\n# the variable name is for 'cross-validated random forest classifier metrics'\ncv_rfc_metrics_df = pd.DataFrame(cv_metrics, index = [0]) \n\nsns.set(font_scale = 1.3)\n\ncv_rfc_metrics_df.T.plot.bar(title = 'Cross-validated random forest classifier metrics', legend = False)\nplt.yticks(np.linspace(0,1,11));","metadata":{"execution":{"iopub.status.busy":"2021-08-29T00:03:29.522919Z","iopub.execute_input":"2021-08-29T00:03:29.523198Z","iopub.status.idle":"2021-08-29T00:03:29.709497Z","shell.execute_reply.started":"2021-08-29T00:03:29.523166Z","shell.execute_reply":"2021-08-29T00:03:29.708552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Create and fit a stock LogisticRegression classifier\n\n#### Preprocing the data\nGradientDecent based model requiere data to be scaled","metadata":{}},{"cell_type":"code","source":"# create an instance of the scaler\nstd = StandardScaler()\n\n# use StandardScaler to scale X\nX_scaled = std.fit_transform(X)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T00:03:29.711088Z","iopub.execute_input":"2021-08-29T00:03:29.711495Z","iopub.status.idle":"2021-08-29T00:03:29.740709Z","shell.execute_reply.started":"2021-08-29T00:03:29.711449Z","shell.execute_reply":"2021-08-29T00:03:29.739833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split into train and test datasets (The s in the varible names is for scaled)\nX_train_s, X_test_s, y_train, y_test = train_test_split(X_scaled, y)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T00:03:29.741792Z","iopub.execute_input":"2021-08-29T00:03:29.742048Z","iopub.status.idle":"2021-08-29T00:03:29.756078Z","shell.execute_reply.started":"2021-08-29T00:03:29.742022Z","shell.execute_reply":"2021-08-29T00:03:29.754938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_stock = LogisticRegression()\nlr_stock.fit(X_train_s, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T00:03:29.757234Z","iopub.execute_input":"2021-08-29T00:03:29.757518Z","iopub.status.idle":"2021-08-29T00:03:30.056956Z","shell.execute_reply.started":"2021-08-29T00:03:29.757491Z","shell.execute_reply":"2021-08-29T00:03:30.056016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the stock model on the test data using the scoring method\nlr_stock.score(X_test_s, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T00:03:30.058579Z","iopub.execute_input":"2021-08-29T00:03:30.059254Z","iopub.status.idle":"2021-08-29T00:03:30.079104Z","shell.execute_reply.started":"2021-08-29T00:03:30.059211Z","shell.execute_reply":"2021-08-29T00:03:30.078055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Lets improve the model tuning the hyperparameters using RandomizedSearchCV","metadata":{}},{"cell_type":"code","source":"# grid with hyperparameters to tune\nlogistic_regression_grid = {\n    'C': np.logspace(-4,4,20),\n    'solver': ['liblinear']\n}\n\nrs_logistic_regression = RandomizedSearchCV(\n    LogisticRegression(),\n    param_distributions = logistic_regression_grid,\n    cv = 5,\n    n_iter = 20,\n    verbose = True,\n    n_jobs = -1\n)\n\n# Fit the random hyperparameter search for logistic regression\nrs_logistic_regression.fit(X_train_s, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T00:03:30.080545Z","iopub.execute_input":"2021-08-29T00:03:30.087299Z","iopub.status.idle":"2021-08-29T00:03:37.675Z","shell.execute_reply.started":"2021-08-29T00:03:30.087242Z","shell.execute_reply":"2021-08-29T00:03:37.674048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the best hyperparameters\nrs_logistic_regression.best_params_","metadata":{"execution":{"iopub.status.busy":"2021-08-29T00:03:37.676198Z","iopub.execute_input":"2021-08-29T00:03:37.676469Z","iopub.status.idle":"2021-08-29T00:03:37.681765Z","shell.execute_reply.started":"2021-08-29T00:03:37.67644Z","shell.execute_reply":"2021-08-29T00:03:37.680951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluate the model on the test data using the score method\nrs_logistic_regression.score(X_test_s, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T00:03:37.68298Z","iopub.execute_input":"2021-08-29T00:03:37.683278Z","iopub.status.idle":"2021-08-29T00:03:37.706869Z","shell.execute_reply.started":"2021-08-29T00:03:37.68325Z","shell.execute_reply":"2021-08-29T00:03:37.705264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluating the Logistic regression model","metadata":{}},{"cell_type":"code","source":"# make a logistic regression classifier model with the best params\nlr_clf = LogisticRegression(\n    solver = 'liblinear',\n    C =  29.763514416313132\n)\n\n# Fit the model\nlr_clf.fit(X_train_s, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T00:03:37.708721Z","iopub.execute_input":"2021-08-29T00:03:37.710794Z","iopub.status.idle":"2021-08-29T00:03:37.948479Z","shell.execute_reply.started":"2021-08-29T00:03:37.710734Z","shell.execute_reply":"2021-08-29T00:03:37.947508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# make predictions on test data to evaluate\nlr_y_preds = lr_clf.predict(X_test_s)\nlr_y_preds","metadata":{"execution":{"iopub.status.busy":"2021-08-29T00:03:37.949674Z","iopub.execute_input":"2021-08-29T00:03:37.949948Z","iopub.status.idle":"2021-08-29T00:03:37.963098Z","shell.execute_reply.started":"2021-08-29T00:03:37.949919Z","shell.execute_reply":"2021-08-29T00:03:37.961817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ROC curve and Area under the curve","metadata":{}},{"cell_type":"code","source":"plot_roc_curve(lr_clf, X_test_s, y_test);","metadata":{"execution":{"iopub.status.busy":"2021-08-29T00:03:37.964621Z","iopub.execute_input":"2021-08-29T00:03:37.965235Z","iopub.status.idle":"2021-08-29T00:03:38.229762Z","shell.execute_reply.started":"2021-08-29T00:03:37.965185Z","shell.execute_reply":"2021-08-29T00:03:38.228767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Confusion matrix","metadata":{}},{"cell_type":"code","source":"conf_matrix(y_test,lr_y_preds)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T00:03:38.231022Z","iopub.execute_input":"2021-08-29T00:03:38.231322Z","iopub.status.idle":"2021-08-29T00:03:38.408855Z","shell.execute_reply.started":"2021-08-29T00:03:38.231292Z","shell.execute_reply":"2021-08-29T00:03:38.407818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Classification Report ","metadata":{}},{"cell_type":"code","source":"print(classification_report(y_test,lr_y_preds))","metadata":{"execution":{"iopub.status.busy":"2021-08-29T00:03:38.410497Z","iopub.execute_input":"2021-08-29T00:03:38.410915Z","iopub.status.idle":"2021-08-29T00:03:38.455804Z","shell.execute_reply.started":"2021-08-29T00:03:38.410867Z","shell.execute_reply":"2021-08-29T00:03:38.454828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv_lr_metrics = cv_classification_report(lr_clf, X_test_s, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T00:03:38.456941Z","iopub.execute_input":"2021-08-29T00:03:38.45724Z","iopub.status.idle":"2021-08-29T00:03:39.431162Z","shell.execute_reply.started":"2021-08-29T00:03:38.457209Z","shell.execute_reply":"2021-08-29T00:03:39.430161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv_lr_metrics","metadata":{"execution":{"iopub.status.busy":"2021-08-29T00:03:39.432541Z","iopub.execute_input":"2021-08-29T00:03:39.432935Z","iopub.status.idle":"2021-08-29T00:03:39.43996Z","shell.execute_reply.started":"2021-08-29T00:03:39.43289Z","shell.execute_reply":"2021-08-29T00:03:39.439085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save the metrics in a pandas dataframe and plot it in a bar graph\ncv_lr_metrics_df = pd.DataFrame(cv_lr_metrics, index = [0]) \n\nsns.set(font_scale = 1.3)\n\ncv_lr_metrics_df.T.plot.bar(title = 'Cross-validated logistic regression classifier metrics', legend = False)\nplt.yticks(np.linspace(0,1,11));","metadata":{"execution":{"iopub.status.busy":"2021-08-29T00:03:39.441634Z","iopub.execute_input":"2021-08-29T00:03:39.442031Z","iopub.status.idle":"2021-08-29T00:03:39.626217Z","shell.execute_reply.started":"2021-08-29T00:03:39.44199Z","shell.execute_reply":"2021-08-29T00:03:39.625204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model comparison\nNow that we have 2 classifiers, one random forest classifier and one logistic regression we should compare both of them, and we have the cross validated metrics for each model in 2 variables:","metadata":{}},{"cell_type":"code","source":"# evaluation metrics for the random forest classifier\ncv_rfc_metrics_df","metadata":{"execution":{"iopub.status.busy":"2021-08-29T00:03:39.627591Z","iopub.execute_input":"2021-08-29T00:03:39.628164Z","iopub.status.idle":"2021-08-29T00:03:39.640657Z","shell.execute_reply.started":"2021-08-29T00:03:39.628119Z","shell.execute_reply":"2021-08-29T00:03:39.639354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluation metrics for the logistic regression classifier\ncv_lr_metrics_df","metadata":{"execution":{"iopub.status.busy":"2021-08-29T00:03:39.641927Z","iopub.execute_input":"2021-08-29T00:03:39.642257Z","iopub.status.idle":"2021-08-29T00:03:39.659829Z","shell.execute_reply.started":"2021-08-29T00:03:39.642227Z","shell.execute_reply":"2021-08-29T00:03:39.658994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can se that both models are so close, but in every metric the RandomForestClassifier wins over the Logistic Regression\n\nThe RandomForestClassifier model is still in a variable:","metadata":{}},{"cell_type":"code","source":"rf_clf","metadata":{"execution":{"iopub.status.busy":"2021-08-29T00:03:39.661025Z","iopub.execute_input":"2021-08-29T00:03:39.661425Z","iopub.status.idle":"2021-08-29T00:03:39.67582Z","shell.execute_reply.started":"2021-08-29T00:03:39.661397Z","shell.execute_reply":"2021-08-29T00:03:39.674627Z"},"trusted":true},"execution_count":null,"outputs":[]}]}