{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-15T09:06:41.506494Z","iopub.execute_input":"2021-09-15T09:06:41.506777Z","iopub.status.idle":"2021-09-15T09:06:41.515315Z","shell.execute_reply.started":"2021-09-15T09:06:41.506737Z","shell.execute_reply":"2021-09-15T09:06:41.514479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reading the csv file\ndf= pd.read_csv('../input/pima-indians-diabetes-database/diabetes.csv')","metadata":{"execution":{"iopub.status.busy":"2021-09-15T09:06:41.516686Z","iopub.execute_input":"2021-09-15T09:06:41.517044Z","iopub.status.idle":"2021-09-15T09:06:41.536922Z","shell.execute_reply.started":"2021-09-15T09:06:41.517016Z","shell.execute_reply":"2021-09-15T09:06:41.535989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-09-15T09:06:41.538161Z","iopub.execute_input":"2021-09-15T09:06:41.538533Z","iopub.status.idle":"2021-09-15T09:06:41.574537Z","shell.execute_reply.started":"2021-09-15T09:06:41.538502Z","shell.execute_reply":"2021-09-15T09:06:41.573714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-15T09:06:41.575571Z","iopub.execute_input":"2021-09-15T09:06:41.575798Z","iopub.status.idle":"2021-09-15T09:06:41.588075Z","shell.execute_reply.started":"2021-09-15T09:06:41.575766Z","shell.execute_reply":"2021-09-15T09:06:41.587311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Does data has some missing values\na= df.isnull().sum().sum()\nif a == 0:\n    print('Data has no missing values')\nelse:\n    print('Data has missing values')","metadata":{"execution":{"iopub.status.busy":"2021-09-15T09:06:41.589899Z","iopub.execute_input":"2021-09-15T09:06:41.590095Z","iopub.status.idle":"2021-09-15T09:06:41.60148Z","shell.execute_reply.started":"2021-09-15T09:06:41.590072Z","shell.execute_reply":"2021-09-15T09:06:41.600736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# defining independent variables and target(outcome) variable\nlist_X= ['Glucose', 'SkinThickness']\nX= df[list_X]\ny= df.Outcome","metadata":{"execution":{"iopub.status.busy":"2021-09-15T09:06:41.602837Z","iopub.execute_input":"2021-09-15T09:06:41.603395Z","iopub.status.idle":"2021-09-15T09:06:41.612525Z","shell.execute_reply.started":"2021-09-15T09:06:41.603352Z","shell.execute_reply":"2021-09-15T09:06:41.611838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# importing useful libraries\nfrom mlxtend.plotting import plot_decision_regions\nimport matplotlib.pyplot as plt\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nimport matplotlib.gridspec as gridspec\nimport itertools\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import LinearSVC","metadata":{"execution":{"iopub.status.busy":"2021-09-15T09:06:41.613727Z","iopub.execute_input":"2021-09-15T09:06:41.613975Z","iopub.status.idle":"2021-09-15T09:06:41.624909Z","shell.execute_reply.started":"2021-09-15T09:06:41.61395Z","shell.execute_reply":"2021-09-15T09:06:41.623947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training a Linear SVC Model classifier\nsvm = LinearSVC(random_state=1, max_iter=850000)\nsvm.fit(X, y)\n\n\n# Plotting decision regions\nplot_decision_regions(X.to_numpy(), y.to_numpy(), clf=svm, legend=2)\n\n# Adding axes annotations\nplt.xlabel('Glucose')\nplt.ylabel('SkinThickness')\nplt.title('Linear SVM', fontweight='bold')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-15T09:06:41.626078Z","iopub.execute_input":"2021-09-15T09:06:41.626737Z","iopub.status.idle":"2021-09-15T09:07:03.210185Z","shell.execute_reply.started":"2021-09-15T09:06:41.626698Z","shell.execute_reply":"2021-09-15T09:07:03.209258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training a Random Forest classifier\nrf = RandomForestClassifier(random_state=1)\nrf.fit(X, y)\n\n# Plotting the Figure in bigger size for better visualization\nfig = plt.figure(figsize=(10, 5))\n\n# Plotting decision regions\nfig = plot_decision_regions(X.to_numpy(), y.to_numpy(), clf=rf, legend=2)\n\n# Adding axes annotations\nplt.xlabel('Glucose')\nplt.ylabel('SkinThickness')\nplt.title('Random Forest Classifier', fontweight='bold')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-15T09:07:03.21302Z","iopub.execute_input":"2021-09-15T09:07:03.213318Z","iopub.status.idle":"2021-09-15T09:07:04.948761Z","shell.execute_reply.started":"2021-09-15T09:07:03.21328Z","shell.execute_reply":"2021-09-15T09:07:04.94791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training a SVC with polynomial kernel classifier\nsvc_p = SVC(kernel='poly', random_state=1)\nsvc_p.fit(X, y)\n\n# Plotting decision regions\nplot_decision_regions(X.to_numpy(), y.to_numpy(), clf=svc_p, legend=2)\n\n# Adding axes annotations\nplt.xlabel('Glucose')\nplt.ylabel('SkinThickness')\nplt.title('SVM with polynomial kernel', fontweight='bold')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-15T09:07:04.950113Z","iopub.execute_input":"2021-09-15T09:07:04.950402Z","iopub.status.idle":"2021-09-15T09:07:05.710448Z","shell.execute_reply.started":"2021-09-15T09:07:04.950364Z","shell.execute_reply":"2021-09-15T09:07:05.709565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training a SVC with rbf kernel classifier\nsvc_rbf = SVC(kernel='rbf', random_state=1)\nsvc_rbf.fit(X, y)\n\n# Plotting decision regions\nplot_decision_regions(X.to_numpy(), y.to_numpy(), clf=svc_rbf, legend=2)\n\n# Adding axes annotations\nplt.xlabel('Glucose')\nplt.ylabel('SkinThickness')\nplt.title('SVM with RBF kernel', fontweight='bold')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-15T09:07:05.711881Z","iopub.execute_input":"2021-09-15T09:07:05.712186Z","iopub.status.idle":"2021-09-15T09:07:07.283069Z","shell.execute_reply.started":"2021-09-15T09:07:05.712149Z","shell.execute_reply":"2021-09-15T09:07:07.282227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training a Logistic Regression classifier\nlr= LogisticRegression(random_state=1)\nlr.fit(X, y)\n\n# Plotting decision regions\nplot_decision_regions(X.to_numpy(), y.to_numpy(), clf=lr, legend=2)\n\n# Adding axes annotations\nplt.xlabel('Glucose')\nplt.ylabel('SkinThickness')\nplt.title('Logistic Regression', fontweight='bold')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-15T09:07:07.284028Z","iopub.execute_input":"2021-09-15T09:07:07.284223Z","iopub.status.idle":"2021-09-15T09:07:07.572026Z","shell.execute_reply.started":"2021-09-15T09:07:07.284199Z","shell.execute_reply":"2021-09-15T09:07:07.571196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Final Code to train all models\nfrom mlxtend.plotting import plot_decision_regions\nimport matplotlib.pyplot as plt\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nimport matplotlib.gridspec as gridspec\nimport itertools\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import LinearSVC\n\n# makes a grid of 3 rows and 2 columns\ngs = gridspec.GridSpec(3, 2)\n\ndf= pd.read_csv('../input/pima-indians-diabetes-database/diabetes.csv')\n\n# defining independent variables and target(outcome) variable\nlist_X= ['Glucose', 'SkinThickness']\nX= df[list_X]\ny= df.Outcome\n\n# Initializing the classifiers\nsvc_p = SVC(kernel='poly', random_state=1)\nsvc_rbf = SVC(kernel='rbf', random_state=1)\nsvc_l = LinearSVC(random_state=1, max_iter=850000)\nrfc= RandomForestClassifier(random_state=1)\nlr= LogisticRegression(random_state=1)\nfig = plt.figure(figsize=(15,15))\n\nlabels = ['Random Forest Classifier', 'Logistic Regression', 'Linear SVC', 'SVM with polynomial kernel', 'SVM with RBF kernel']\n\nfor clf, lab, grd in zip([rfc, lr, svc_l, svc_p, svc_rbf], labels, [(0,0), (0,1), (1,0), (1,1), (2,0), (2,1)]):\n    clf.fit(X, y)\n    ax = plt.subplot(gs[grd[0], grd[1]])\n    fig = plot_decision_regions(X=X.to_numpy(), y=y.to_numpy(), clf=clf, legend=2)\n    plt.xlabel('Glucose')\n    plt.ylabel('SkinThickness')\n    plt.title(lab, fontweight='bold')\n\n# Plotting decision regions\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-15T09:07:07.573337Z","iopub.execute_input":"2021-09-15T09:07:07.573655Z","iopub.status.idle":"2021-09-15T09:07:53.81151Z","shell.execute_reply.started":"2021-09-15T09:07:07.573616Z","shell.execute_reply":"2021-09-15T09:07:53.810656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Finding which one has best prediction. ","metadata":{}},{"cell_type":"code","source":"# Making training and validating data set.\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\n\n# defining training & validating sets\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state= 0)\n\n# Initializing the classifiers\nsvc_p = SVC(kernel='poly', random_state=1)\nsvc_rbf = SVC(kernel='rbf', random_state=1)\nsvc_l = LinearSVC(random_state=1, max_iter=1075000)\nrfc= RandomForestClassifier(random_state=1)\nlr= LogisticRegression(random_state=1)\n\nmae = []\n# calculating mean absolute error\nfor clf, lab in zip([rfc, lr, svc_l, svc_p, svc_rbf], labels):\n    clf.fit(train_X, train_y)\n    mae.append((mean_absolute_error(val_y, clf.predict(val_X)), lab))\n    print('Mean Absolute Error of', lab,':-', mean_absolute_error(val_y, clf.predict(val_X)))\n\nprint('Minimum Mean Absolute Error is from', min(mae)[1])","metadata":{"execution":{"iopub.status.busy":"2021-09-15T09:07:53.812702Z","iopub.execute_input":"2021-09-15T09:07:53.812958Z","iopub.status.idle":"2021-09-15T09:08:15.437769Z","shell.execute_reply.started":"2021-09-15T09:07:53.812924Z","shell.execute_reply":"2021-09-15T09:08:15.436968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}