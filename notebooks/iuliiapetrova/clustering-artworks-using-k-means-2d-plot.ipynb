{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#Imports \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport sqlite3\n\n\nimport fuzzywuzzy # determine disstance berween words\nfrom fuzzywuzzy import process\n\n# kmeans for clustering\nfrom sklearn import datasets \nfrom sklearn.cluster import KMeans\n\n# plot charts\nimport matplotlib.pyplot as plt\n\nartists = pd.read_csv('../input/museum-collection/artists.csv')\nartworks = pd.read_csv('../input/museum-collection/artworks.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# =======================================================\n# Data quality review\n# =======================================================","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 1\n# =======================================================\n# Handling missing values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1.1 Take a look on the samples of both tables and looking to see if there are missing values, \n# which could be reprsented with NaN or None.\nartists.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"artworks.sample(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1.2 Count the number of missing values per column\n# Artists\ncount_missing_values_artists = artists.isnull().sum()\ncount_missing_values_artists","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Artworks\ncount_missing_values_artworks = artworks.isnull().sum()\ncount_missing_values_artworks","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1.3 \n# Looks like a lot of missing values, but let's evaluate them in percents \ntotal_cells = np.product(artists.shape) # total cells\ntotal_missing = count_missing_values_artists.sum() # total cells without values\n\n# percent of data that is missing\n(total_missing/total_cells) * 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The same for Artworks\ntotal_cells = np.product(artworks.shape) \ntotal_missing = count_missing_values_artworks.sum() \n(total_missing/total_cells) * 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We have almost a quarter of missing values. Quite a lot. Let's continue to explore...","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 2 Convert values\n# =======================================================\n# Before checking duplicates it is a good practic to delete white spaces and to make all letters Upper case or lower case, \n# delete or replace caracters \",\",\".\",.. etc.\n\n# convert to upper case\nartists['Name'] = artists['Name'].str.upper()\nartists['Nationality'] = artists['Nationality'].str.upper()\nartists['Gender'] = artists['Gender'].str.upper()\n\n# remove trailing white spaces\nartists['Name'] = artists['Name'].str.strip()\nartists['Nationality'] = artists['Nationality'].str.strip()\nartists['Gender'] = artists['Gender'].str.strip()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 3 Check duplicates values\n# =======================================================\n\n\n# 3.1 Check Artist table on duplicates of Artist ID and Name\nartists[artists.duplicated(subset=['Artist ID'], keep=False)] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# There is no one duplicate Artist ID. It's good. \n# Check duplicates of Name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"artists[artists.duplicated(subset=['Name'], keep=False)]\n# We can see that we have 73 rows of Names which are at least two times in the table. \n# But we know that people can have the same names... Let's explore these values..","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# I would like to take a look on these duplicates and sort then by Name to get the same Names together.\n\nartists[artists.duplicated(subset=['Name'], keep=False)][0:60].sort_values(by=['Name'])\n\n# Cases:\n# --- We can see that some Names are \"UNKNOWN DESIGNER\"/ \"UNKNOWN ARTIST\" / \"UNKNOWN\" without any other data. \n#     I propose to delete these rows.\n\n# --- In case of  \"JOHANN LOETZ\" we have to investigete if it is one person or not.\n# --- In case of \"DANESE S.R.L., ITALY\" and \"J.A. HENCKELS, SOLINGEN, GERMANY\", \"ROBERT DAWSON\"\n#     we have to delete lines where Artist ID are 9409 and 10857, 37602. Also modify this IDs in Artworks table.\n# --- In case of \"CARL AUBÃ–CK\" looks like it is OK. Maybe they are father and son.\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 4 Check inconsistent data entry and replace values\n# =======================================================\n\n# 4.1 In columne Nationality replace \"NATIONALITY UNKNOWN\" to None \nartists.loc[(artists.Nationality == 'NATIONALITY UNKNOWN'),'Nationality']='None'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 4.2 Check Names in the columne Names\n\n# As example, I have found two different names 'AB GUSTAVSBERG FABRIKER, SWEDEN' and 'AB GUSTAVSBERG, SWEDEN'\n# but it is the same company. I guess there is a lot of data entry errors in this column. \n# Also split the Name values such as \"J.A. HENCKELS, SOLINGEN, GERMANY\" to Name and Nationality.\n# It is enough long work to fix them.\n\n# We could use fuzzywuzzy package to help identify which string are closest to each other.\n\n# extract all names\nnames = artists['Name'].unique()\n\n# get the top 5 closest matches to \"AB GUSTAVSBERG, SWEDEN\"\nmatches = fuzzywuzzy.process.extract(\"AB GUSTAVSBERG, SWEDEN\", names, limit=5, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n\n# print top 5\nmatches","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 5 Check data types\n# =======================================================\n\n#5.1 Check value \"Birth Year\" and \"Death Year\"\nprint(artists['Birth Year'].head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(artists['Death Year'].head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Both fields have type float64. We have to convert them to datetime\nartists['Birth Year'] = pd.to_datetime(artists['Birth Year'], format = \"%Y\",errors='coerce')\n# print the first few rows\nartists['Birth Year'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"artists['Death Year'] = pd.to_datetime(artists['Death Year'], format = \"%Y\",errors='coerce')\nartists['Death Year'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make the similar steps to check data in the Artworks table:\n# --- Missing values, \n# --- fixe inconsistent data entry, \n# --- duplicates, \n# --- replace values, \n# --- data types\n# Also can be found\n# --- all possible not correct character encoding","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"artworks.sample(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# =======================================================\n# Clustering of artworks\n# =======================================================\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The idea is to define new clusters depends on size of art picture and Birth Year of an artists.\n# As example, to get groups like:\n# \"Lost Generation - low dimention pictures\"\n# \"Generation X - low dimention pictures\"\n# \"Generation Y - Hight dimention pictures\"\n# etc\n\n# I have chosen Kmeans algorithm.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# prepare a data set for clustering\n# - joined Artworks and Artists \n\njoint_df = pd.merge(artworks, artists, on='Name', how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# - deleted rows where Birth Year contained null, Nan, None values.\n# - deleted null values and outliers for Height (cm) and Width (cm)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"joint_df=joint_df[['Height (cm)','Width (cm)']]\n\njoint_df = joint_df[joint_df['Height (cm)'].between(0.1,400, inclusive=True)]\njoint_df = joint_df[joint_df['Width (cm)'].between(0.1,400, inclusive=True)]\n#joint_df['Birth Year'] = joint_df['Birth Year'].dt.year\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print the table\njoint_df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#joint_df.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#joint_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define an array and assign values from joint_df DataFrame\nsamples = joint_df.values\nsamples","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define the model, where n_clusters is a number of clusters.\nmodel = KMeans(n_clusters=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#modeling\nmodel.fit(samples.data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The result is in the array all_predictions which size corresponds to the number of rows in the joint_df DataFrame\nall_predictions = model.predict(samples.data)\nprint(all_predictions[0:9]) # print first 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# the same array\nmodel.labels_[0:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# centers of clusters are:\nmodel.cluster_centers_\n# Year values we have to change to int values... TBD...","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2D Plot of clusters\nx_axis = joint_df['Height (cm)']  \ny_axis = joint_df['Width (cm)']  \n\nplt.title(\"2D Viz of clusters\")\nplt.xlabel('Height size of the artwork')\nplt.ylabel('Width size of the artwork')\n\nplt.scatter(x_axis, y_axis, c=all_predictions)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 3D Plot of clusters\n#x_axis = joint_df['Width (cm)']  \n#y_axis = joint_df['Birth Year']  \n#z_axis = joint_df['Height (cm)']  \n\n#ax = plt.axes(projection =\"3d\")\n\n#plt.title(\"3D Viz of clusters\")\n#ax.set_xlabel('Width')\n#ax.set_zlabel('Height')\n#ax.set_ylabel('Birth Year')\n\n#ax.scatter3D(x_axis, y_axis, z_axis, c = all_predictions)\n#plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Each predict value from 0 to n we can match to string such as\n# \"Lost Generation - low dimention pictures\"\n# \"Generation X - low dimention pictures\"\n# \"Generation Y - Hight dimention pictures\"\n# etc\n# and save this values in Artworks table","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}