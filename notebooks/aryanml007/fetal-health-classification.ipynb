{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<html>\n    <h1 style='color:pink;'>MOTIVATION</h1>\n</html>","metadata":{}},{"cell_type":"markdown","source":"![FETAL](https://media.istockphoto.com/vectors/pregnancy-fertilization-related-vector-id975895412?k=6&m=975895412&s=612x612&w=0&h=L-uCk_0_OJsVAedKwijXtRfxJ0NkZaqOsfX20K9Hq-s=)","metadata":{}},{"cell_type":"markdown","source":"* **Cardiotocography can be used to monitor a baby's heart rate and a mother's contractions while the baby is in the uterus**\n\n* **CTG is used both before birth and during labour, to monitor the baby for any signs of distress. By looking at various different aspects of the baby's heart rate, doctors can see the condition of a baby**\n\n* **The vast majority of these deaths (94%) occurred in low-resource settings, and most could have been prevented**\n\n* **I have worked on data and trying to predict the well being of baby**","metadata":{}},{"cell_type":"markdown","source":"<html>\n    <h1 style='color:pink;'>TABLE OF CONTENTS</h1>\n</html>\n\n* **ANALYSIS**\n\n\n* **PREDICTING WITHOUT REMOVING ANY FEATURES**\n   * **RANDOM FOREST CLASSIFIER**\n   * **LIGHT GBM**\n   \n* **ANALYSING WITH MUTUAL INFORMATION**\n   * **PLOTTING MI SCORES**\n   * **VISUALIZING IMPORTANT FEATURES**\n   * **PREDICTIONS ON THE BASIS OF MUTUAL INFORMATION**\n     * **RANDOM FOREST CLASSIFIER**\n     * **LIGHT GBM CLASSIFIER**\n     \n* **CONCLUSIONS**\n\n\n   \n","metadata":{}},{"cell_type":"markdown","source":"<html>\n    <p style='color:green;'><b>IMPORTING LIBRARIES</b></p>\n</html>","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom colorama import Fore,Back,Style","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<html>\n    <h1 style='color:pink;'>ANALYSIS</h1>\n</html>\n\n* **METRICS WE WILL FOCUS ON**\n  * **F1 SCORE**\n  * **PRECISION AND RECALL**","metadata":{}},{"cell_type":"code","source":"#Importing Data\ndf=pd.read_csv(\"../input/fetal-health-classification/fetal_health.csv\")\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**WE HAVE 2126 ROWS and 22 COLUMNS**\n\n* **THREE TARGET FEATURES**\n  * **NORMAL**\n  * **SUSPECT**\n  * **PATHOLOGICAL**","metadata":{}},{"cell_type":"code","source":"print(\"SHAPE OF OUR DATA IS : \",df.shape)\nprint(\" \")\nprint(\"***** DTYPES IN OUR DATA *****\")\nprint(df.dtypes)\n      ","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#COLUMN NAMES\nprint(list(df.columns))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<html>\n    <p style='color:green;'><b>CHECKING NULL VALUES</b></p>\n</html>\n\n* **There is no null values in this data**","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<html>\n    <p style='color:green;'><b>REMOVING DUPLICATES</b></p>\n</html>\n","metadata":{}},{"cell_type":"code","source":"df_dup=df.copy()\ndf_dup.drop_duplicates(inplace=True)\nprint(\"NEW SHAPE AFTER REMOVING DUPLICATES : \",df_dup.shape)\ndf_dup.head()\n","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def with_hue(data,feature,ax):\n    \n    #Number of categories\n    num_of_cat=len([x for x in data[feature].unique() if x==x])\n    \n    bars=ax.patches\n    \n    for ind in range(num_of_cat):\n        ##     Get every hue bar\n        ##     ex. 8 X categories, 4 hues =>\n        ##    [0, 8, 16, 24] are hue bars for 1st X category\n        hueBars=bars[ind:][::num_of_cat] \n        # Get the total height (for percentages)\n        total=sum([x.get_height() for x in hueBars])\n        #Printing percentages on bar\n        for bar in hueBars:\n            percentage='{:.1f}%'.format(100 * bar.get_height()/total)\n            ax.text(bar.get_x()+bar.get_width()/2.0,\n                   bar.get_height(),\n                   percentage,\n                    ha=\"center\",va=\"bottom\",fontweight='bold',fontsize=15)\n    \n\n    \ndef without_hue(data,feature,ax):\n    \n    total=float(len(data))\n    bars_plot=ax.patches\n    \n    for bars in bars_plot:\n        percentage = '{:.1f}%'.format(100 * bars.get_height()/total)\n        x = bars.get_x() + bars.get_width()/2.0\n        y = bars.get_height()\n        ax.text(x, y,(percentage,bars.get_height()),ha='center',fontweight='bold',fontsize=15)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set_theme(context='notebook',style='white')\nplt.figure(figsize=(20,10))\nplt.text(0.7,1100,\"Data is imbalanced between three classes\",fontweight='bold',fontsize=25,fontstyle='oblique')\nplt.title(\"Countplot of fetal_health\",fontweight='bold',fontsize=25,fontstyle='oblique')\nax=sns.countplot(data=df_dup,x=\"fetal_health\",palette='rocket')\nplt.xticks(fontweight='bold',fontsize=15)\nplt.yticks(fontweight='bold',fontsize=15)\nplt.xlabel(\"fetal_health\",fontweight='bold',fontsize=20,fontstyle='oblique')\nplt.ylabel(\"fetal_health\",fontweight='bold',fontsize=20,fontstyle='oblique')\nwithout_hue(df_dup,\"fetal_health\",ax)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**WE HAVE 22 FEATURES AND WE WON'T ANALYSE EACH AND EVERY COLUMN , SO WHAT WE ARE GOING TO DO?**\n\n* **FIRST OF ALL WE WILL DO PREDCITIONS WITHOUT REMOVING ANY FEATURES AND OBSERVE OUR RESULTS, I WILL USE ENSEMBLING METHODS TO OBTAIN RESULTS (RANDOM FOREST AND LIGHT GBM)**\n\n* **SECOND , WE WILL ANALYSE WHICH ARE THE MOST IMPORTANT FEATURES ACCORDING TO OUR TARGET \"fetal_health\" (THIS TIME WILL TRY SOMETHING NEW , YEAH I LOVE TO DO EXPERIMENTS)**\n\n* **THEN WE WILL REMOVE THOSE FEATURES WHICH ARE LEAST IMPORTANT AND NOT EFFECTIVELY CONTRIBUTING TOWARDS TARGET , WE WILL ALSO CHECK WHETHER LEAST CONTRIBUTING TARGETS ARE INTERACTING FEATURES BETWEEN ANY TWO FEATURES OR NOT AND DECIDE WHETHER TO KEEP THOSE FEATURES OR NOT**\n\n* **WE WIL BE USING \"MUTUAL INFORMATION\" RATHER THAN CORRELATION TO GET MOST IMPORTANT FEATURES**\n\n* **WELL I AM ASLO LEARNING NEW THINGS :) , IF YOU FIND ANY MISTAKES PLEASE LET ME KNOW AND I WILL TRY MY BEST TO MAKE YOU UNDERSTAND**\n","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,20))\nplt.title(\"HEATMAP OF DATA\",fontsize=25,fontweight='bold')\nsns.heatmap(df_dup.corr(),cmap=\"vlag\",annot=True,annot_kws={'size':13})\nplt.yticks(fontweight='bold',fontsize=20)\nplt.xticks(fontweight='bold',fontsize=20)\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<html>\n    <p style='color:pink;'><b>IMPORTING LIBRARIES FOR PREDICTION</b></p>\n</html>","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split,cross_val_score\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.ensemble import RandomForestClassifier\nimport optuna\nfrom sklearn.metrics import f1_score, roc_auc_score,accuracy_score,confusion_matrix,precision_recall_curve, auc, roc_curve, recall_score, classification_report,plot_confusion_matrix,precision_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<html>\n    <h1 style='color:green;'>PREDICTING WITHOUT REMOVING ANY FEATURES</h1>\n</html>","metadata":{}},{"cell_type":"code","source":"df_dup_ori=df_dup.copy()\n#df_dup_ori=df_dup_ori.drop(['histogram_mode','histogram_median'],axis=1)\ndf_dup_ori","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_ori=df_dup_ori.copy()\nY_ori=X_ori.pop('fetal_health')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_ori.value_counts() #Checking for value counts in our targets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Splitting the data into train and test sets\nx_train_ori,x_test_ori,y_train_ori,y_test_ori=train_test_split(X_ori,Y_ori,test_size=0.3,random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<html>\n    <p style='color:pink;'><b>RANDOMFOREST CLASSIFIER</b></p>\n</html>","metadata":{}},{"cell_type":"markdown","source":"<html>\n    <p style='color:green;'><b>HYPERPARAMETER TUNING USING OPTUNA</b></p>\n</html>","metadata":{}},{"cell_type":"code","source":"def objective_rf_ori(trial):\n    \n    n_estimators = trial.suggest_int('n_estimators', 2, 200)\n    max_depth = int(trial.suggest_int('max_depth', 1, 40))\n    clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth,class_weight='balanced')\n    return cross_val_score(clf, x_train_ori, y_train_ori, \n           n_jobs=-1, cv=5,scoring=\"f1_micro\").mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study=optuna.create_study(direction='maximize',study_name=\"RANDOM FOREST\")\nstudy.optimize(objective_rf_ori,n_trials=50)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trial_ori=study.best_trial\nprint(\"Best accuracy  : \",trial_ori.values)\nprint(\"Best Parameter : \",trial_ori.params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Training of the model\nmodel_ori_rf=RandomForestClassifier(n_estimators=158,max_depth=27,class_weight='balanced')\nmodel_ori_rf.fit(x_train_ori,y_train_ori)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_ori_rf=model_ori_rf.predict(x_test_ori)\naccuracy_rf=accuracy_score(y_test_ori,pred_ori_rf)\nprecision_rf=precision_score(y_test_ori,pred_ori_rf,average='weighted')\nrecall_rf=recall_score(y_test_ori,pred_ori_rf,average='weighted')\nf1_rf=f1_score(y_test_ori,pred_ori_rf,average='micro')\n\nprint(\"******* RANDOM FOREST CLASSIFIER RESULTS ********\")\nprint(\"Accuracy  :\", accuracy_rf)\nprint(\"Precision : \", precision_rf)\nprint(\"Recall    : \",recall_rf)\nprint(\"F1 Score  : \",f1_rf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('** CLASSIFICATION REPORT OF RANDOM FOREST CLASSIFIER **')\nprint(\" \")\nprint(classification_report(y_test_ori,pred_ori_rf))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_ori.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(model_ori_rf,x_test_ori,y_test_ori)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<html>\n    <p style='color:pink;'><b>LIGHT GBM CLASSIFIER</b></p>\n</html>","metadata":{}},{"cell_type":"code","source":"import lightgbm as lgb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def objective_lgbm(trial):\n    \n    n_estimators = trial.suggest_int('n_estimators', 2, 300)\n    max_depth = int(trial.suggest_int('max_depth', 2, 50))\n    learning_rate=trial.suggest_loguniform('learning_rate',0.001,1)\n    colsample_bytree=trial.suggest_loguniform(\"colsample_bytree\",0.1, 1)\n    num_leaves=trial.suggest_int('num_leaves',10,300)\n    reg_alpha= trial.suggest_loguniform('reg_alpha',0.1,1)\n    reg_lambda= trial.suggest_loguniform('reg_lambda',0.1,1)\n    min_split_gain=trial.suggest_loguniform('min_split_gain',0.1,1)\n    subsample=trial.suggest_loguniform('subsample',0.1,1)    \n    clf = lgb.LGBMClassifier(n_estimators=n_estimators, max_depth=max_depth,\n                            learning_rate=learning_rate,colsample_bytree=colsample_bytree,\n                            num_leaves=num_leaves,reg_alpha=reg_alpha,reg_lambda=reg_lambda,\n                            min_split_gain=min_split_gain,subsample=subsample,class_weight='balanced')\n    \n    return cross_val_score(clf, x_train_ori, y_train_ori, \n           n_jobs=-1, cv=5).mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study=optuna.create_study(direction='maximize',study_name='LIGHTGBM')\nstudy.optimize(objective_lgbm,n_trials=50)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trial=study.best_trial\nprint(\"Best F1   :\", trial.values)\nprint(\"Best parameters :\",trial.params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_lgbm=lgb.LGBMClassifier(n_estimators=92, max_depth=6, learning_rate=0.15906569428502207, \n                              colsample_bytree=0.9814279100755071, num_leaves=127, reg_alpha=0.16318429872212306, \n                              reg_lambda=0.10256590944837159, \n                              min_split_gain=0.10060819627698767,subsample=0.5115021752468786,class_weight='balanced')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_lgbm.fit(x_train_ori,y_train_ori)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_lgbm=model_lgbm.predict(x_test_ori)\naccuracy_lgbm=accuracy_score(y_test_ori,pred_lgbm)\nprecision_lgbm=precision_score(y_test_ori,pred_lgbm,average='weighted')\nrecall_lgbm=recall_score(y_test_ori,pred_lgbm,average='weighted')\nf1_lgbm=f1_score(y_test_ori,pred_lgbm,average='micro')\n\nprint(\"******* LGBM CLASSIFIER RESULTS ********\")\nprint(\"Accuracy  :\" ,  accuracy_lgbm)\nprint(\"Precision : \", precision_lgbm)\nprint(\"Recall    : \", recall_lgbm)\nprint(\"F1 Score  : \", f1_lgbm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('** CLASSIFICATION REPORT OF LIGHTGBM CLASSIFIER **')\nprint(\" \")\nprint(classification_report(y_test_ori,pred_lgbm))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(model_lgbm,x_test_ori,y_test_ori)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**CONCLUSION**\n* **LGBM CLASSIFIER PROVIDES US EXTREMELY GOOD RESULTS AS COMPARED TO RANDOM FOREST CLASSIIFIER**\n* **NOW THE QUESTION ARISES WHAT IF WE REMOVE SOME FEATURES BASED ON \"MUTUAL INFORMATION\" AND OBSERVE THE RESULTS , LET'S START WITH THIS EXPERIMENT AND OBSERVE WILL IT MAKE MORE IMPACT?**\n","metadata":{}},{"cell_type":"markdown","source":"<html>\n    <h1 style='color:pink;'>ANALYSING WITH \"MUTUAL INFORMATION\"</h1>\n</html>","metadata":{}},{"cell_type":"code","source":"df['fetal_health'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Importing mutual information library from sklearn feature selection\nfrom sklearn.feature_selection import mutual_info_classif,mutual_info_regression","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=df_dup.copy()\nY=X.pop(\"fetal_health\")\n\n#ENCODING CATEGORICAL FEATURES\n'''for columns in X.select_dtypes('object'):\n    X[columns],_=X[columns].factorize()'''\n\n#Evaluating Mutual information score for each feature    \ndef make_mi_scores(X,Y):\n    mi_scores=mutual_info_classif(X,Y)\n    mi_scores=pd.Series(mi_scores ,name=\"MI_scores\",index=X.columns)\n    mi_scores=mi_scores.sort_values(ascending=False)\n    return(mi_scores)\n\nmi_scores=make_mi_scores(X,Y)\nmi_scores\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**PLOTTING MI SCORES**","metadata":{}},{"cell_type":"code","source":"#Plotting mutual information bar graph \ndef plot_mi_scores(scores):\n    scores=scores.sort_values(ascending=True)\n    width=np.arange(len(scores))\n    ticks=scores.index\n    plt.barh(width,scores)\n    plt.yticks(width,ticks,fontweight='bold',fontsize=20)\n    plt.xticks(fontweight='bold',fontsize=20)\nplt.figure(figsize=(16,18))\nplot_mi_scores(mi_scores)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**FROM THE ABOVE BAR GRAPH WE WILL TAKE THOSE FEATURES WHOSE MI SCORES ARE NEAR TO 0.0**\n\n* **THERE IS SOMETHING I WANT TO SHARE IS THAT:**\n\n    1. **'histogram_mean' , 'histogram_mode' , 'histogram_median' features are highly correlated with       each other, these features will lead to the problem of multicollinearity,but we should consider       this problem while using regression models , here we will use ensemble methods so this               multicollinearity won't effect much**","metadata":{}},{"cell_type":"code","source":"#WE CAN SEE HOW MUCH 'histogram_mean' , 'histogram_mode' , 'histogram_median' features are highly correlated\nf,ax=plt.subplots(nrows=1,ncols=3,figsize=(25,10))\nsns.regplot(data=df_dup,x=\"histogram_mean\",y=\"histogram_mode\",ax=ax[0])\nsns.regplot(data=df_dup,x=\"histogram_mean\",y=\"histogram_median\",ax=ax[1])\nsns.regplot(data=df_dup,x=\"histogram_median\",y=\"histogram_mode\",ax=ax[2])","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<html>\n    <p style='color:green;'><b>VISUALIZING IMPORTANT FEATURES</b></p>\n</html>","metadata":{}},{"cell_type":"markdown","source":"* **AS WE CAN SEE BELOW IN BOX PLOTS THERE ARE LOT OF OUTLIERS PRESENT IN THE DATA FOR MANY FEATURES IF WE REMOVE THEM THERE WILL LOSS OF DATA , SO WE WILL MOVE FORWARD WITHOUT REMOVING OUTLIERS**","metadata":{}},{"cell_type":"code","source":"#VISUALIZING CHOSEN IMPORTANT W.R.T TARGET FEATURE\nf,ax1=plt.subplots(nrows=5,ncols=2,figsize=(18,40))\n\nsns.stripplot(data=df_dup,x='fetal_health',y='mean_value_of_short_term_variability',palette='cool',ax=ax1[0][0])\nsns.boxplot(data=df_dup,x='fetal_health',y='mean_value_of_short_term_variability',palette='gnuplot',ax=ax1[0][1])\n\nsns.stripplot(data=df_dup,x='fetal_health',y='abnormal_short_term_variability',palette='cool',ax=ax1[1][0])\nsns.boxplot(data=df_dup,x='fetal_health',y='abnormal_short_term_variability',palette='gnuplot',ax=ax1[1][1])\n\nsns.stripplot(data=df_dup,x='fetal_health',y='percentage_of_time_with_abnormal_long_term_variability',palette='cool',ax=ax1[2][0])\nsns.boxplot(data=df_dup,x='fetal_health',y='percentage_of_time_with_abnormal_long_term_variability',palette='gnuplot',ax=ax1[2][1])\n\nsns.stripplot(data=df_dup,x='fetal_health',y='histogram_mean',palette='cool',ax=ax1[3][0])\nsns.boxplot(data=df_dup,x='fetal_health',y='histogram_mean',palette='gnuplot',ax=ax1[3][1])\n\nsns.stripplot(data=df_dup,x='fetal_health',y='histogram_min',palette='cool',ax=ax1[4][0])\nsns.boxplot(data=df_dup,x='fetal_health',y='histogram_min',palette='gnuplot',ax=ax1[4][1])\n","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f,ax1=plt.subplots(nrows=4,ncols=2,figsize=(18,40))\n\nsns.stripplot(data=df_dup,x='fetal_health',y='histogram_variance',palette='cool',ax=ax1[0][0])\nsns.boxplot(data=df_dup,x='fetal_health',y='histogram_variance',palette='gnuplot',ax=ax1[0][1])\n\nsns.stripplot(data=df_dup,x='fetal_health',y='accelerations',palette='cool',ax=ax1[1][0])\nsns.boxplot(data=df_dup,x='fetal_health',y='accelerations',palette='gnuplot',ax=ax1[1][1])\n\nsns.stripplot(data=df_dup,x='fetal_health',y='histogram_width',palette='cool',ax=ax1[2][0])\nsns.boxplot(data=df_dup,x='fetal_health',y='histogram_width',palette='gnuplot',ax=ax1[2][1])\n\nsns.stripplot(data=df_dup,x='fetal_health',y='baseline value',palette='cool',ax=ax1[3][0])\nsns.boxplot(data=df_dup,x='fetal_health',y='baseline value',palette='gnuplot',ax=ax1[3][1])\n","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f,ax1=plt.subplots(nrows=6,ncols=2,figsize=(18,40))\n\nsns.stripplot(data=df_dup,x='fetal_health',y='mean_value_of_long_term_variability',palette='cool',ax=ax1[0][0])\nsns.boxplot(data=df_dup,x='fetal_health',y='mean_value_of_long_term_variability',palette='gnuplot',ax=ax1[0][1])\n\nsns.stripplot(data=df_dup,x='fetal_health',y='prolongued_decelerations',palette='cool',ax=ax1[1][0])\nsns.boxplot(data=df_dup,x='fetal_health',y='prolongued_decelerations',palette='gnuplot',ax=ax1[1][1])\n\nsns.stripplot(data=df_dup,x='fetal_health',y='fetal_movement',palette='cool',ax=ax1[2][0])\nsns.boxplot(data=df_dup,x='fetal_health',y='fetal_movement',palette='gnuplot',ax=ax1[2][1])\n\nsns.stripplot(data=df_dup,x='fetal_health',y='uterine_contractions',palette='cool',ax=ax1[3][0])\nsns.boxplot(data=df_dup,x='fetal_health',y='uterine_contractions',palette='gnuplot',ax=ax1[3][1])\n\nsns.stripplot(data=df_dup,x='fetal_health',y='light_decelerations',palette='cool',ax=ax1[4][0])\nsns.boxplot(data=df_dup,x='fetal_health',y='light_decelerations',palette='gnuplot',ax=ax1[4][1])\n\nsns.stripplot(data=df_dup,x='fetal_health',y='histogram_tendency',palette='cool',ax=ax1[5][0])\nsns.boxplot(data=df_dup,x='fetal_health',y='histogram_tendency',palette='gnuplot',ax=ax1[5][1])\n\n","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<html>\n    <p style='color:pink;'><b>SOME PLOTS THAT MIGHT BE USEFUL</b></p>\n</html>\n","metadata":{}},{"cell_type":"code","source":"sns.lmplot(data=df_dup,x='abnormal_short_term_variability',y='fetal_movement',palette='cool'\n           ,hue='fetal_health')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.lmplot(data=df_dup,x='mean_value_of_short_term_variability',y='fetal_movement',palette='cool'\n           ,hue='fetal_health')\n","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.lmplot(data=df_dup,x='prolongued_decelerations',y='fetal_movement',palette='cool'\n           ,hue='fetal_health')\n","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.lmplot(data=df_dup,x='accelerations',y='fetal_movement',palette='cool'\n           ,hue='fetal_health')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_dup.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<html>\n    <p style='color:pink;'><b>GETTING IMPORTANT FEATURES INTO DATAFRAME</b></p>\n</html>\n","metadata":{}},{"cell_type":"code","source":"mi_scores1=pd.DataFrame(mi_scores)\nmi_scores2=pd.DataFrame({'Features':mi_scores1.index,'MI':mi_scores1.MI_scores})\nmi_scores2.reset_index(drop=True,inplace=True)\nmi_scores2=mi_scores2[mi_scores2[\"MI\"]>0.0100]\n\nmi_scores2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#CREATING NEW DATAFRAME\ndf_dup_new=pd.DataFrame()\n\nfor i in mi_scores2.Features:\n    df_dup_new[i]=df_dup[i]\n    \ndf_dup_new","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#PLOTTING CORRELATION \ndf_heatmap=df_dup_new.copy()\ndf_heatmap['Fetal_health']=Y\nplt.figure(figsize=(18,18))\nsns.heatmap(data=df_heatmap.corr(),annot=True,cmap='vlag',annot_kws={\"size\":14})\nplt.yticks(fontweight='bold',fontsize=20)\nplt.xticks(fontweight='bold',fontsize=20)\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n<html>\n    <p style='color:pink;'><b>LET'S DO PREDICTIONS AND SEE HOW OUR MUTUAL INFORMATION METHOD WORKS</b></p>\n</html>\n","metadata":{}},{"cell_type":"code","source":"x_train,x_test,y_train,y_test=train_test_split(df_dup_new,Y,test_size=0.3,random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lis=list(x_train.columns)\nprint(lis)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<html>\n    <p style='color:green;'><b>RANDOM FOREST CLASSIFIER</b></p>\n</html>\n","metadata":{}},{"cell_type":"code","source":"def objective(trial):\n    \n    n_estimators = trial.suggest_int('n_estimators', 2, 200)\n    max_depth = int(trial.suggest_int('max_depth', 1, 40))\n    clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth,class_weight='balanced')\n    return cross_val_score(clf, x_train, y_train, \n           n_jobs=-1, cv=5,scoring=\"f1_micro\").mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study=optuna.create_study(direction='maximize')\nstudy.optimize(objective,n_trials=50)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trial=study.best_trial\nprint(\"Best F1   : \",trial.values)\nprint(\"Best parameterst: \",trial.params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_rf=RandomForestClassifier(n_estimators=163,max_depth=30,class_weight='balanced')\nmodel_rf.fit(x_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_rf=model_rf.predict(x_test)\naccuracy_rf=accuracy_score(y_test,pred_rf)\nprecision_rf=precision_score(y_test,pred_rf,average='weighted')\nrecall_rf=recall_score(y_test,pred_rf,average='weighted')\nf1_rf=f1_score(y_test,pred_rf,average='micro')\n\nprint(\"******* RANDOM FOREST CLASSIFIER RESULTS ********\")\nprint(\"Accuracy  :\", accuracy_rf)\nprint(\"Precision : \", precision_rf)\nprint(\"Recall    : \",recall_rf)\nprint(\"F1 Score  : \",f1_rf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test,pred_rf))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(model_rf,x_test,y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<html>\n    <p style='color:green;'><b>LIGHT GBM CLASSIFIER</b></p>\n</html>\n","metadata":{}},{"cell_type":"code","source":"import lightgbm as lgb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def objective_lgbm(trial):\n    \n    n_estimators = trial.suggest_int('n_estimators', 2, 300)\n    max_depth = int(trial.suggest_int('max_depth', 2, 50))\n    learning_rate=trial.suggest_loguniform('learning_rate',0.001,1)\n    colsample_bytree=trial.suggest_loguniform(\"colsample_bytree\",0.1, 1)\n    num_leaves=trial.suggest_int('num_leaves',10,300)\n    reg_alpha= trial.suggest_loguniform('reg_alpha',0.1,1)\n    reg_lambda= trial.suggest_loguniform('reg_lambda',0.1,1)\n    min_split_gain=trial.suggest_loguniform('min_split_gain',0.1,1)\n    subsample=trial.suggest_loguniform('subsample',0.1,1)    \n    clf = lgb.LGBMClassifier(n_estimators=n_estimators, max_depth=max_depth,\n                            learning_rate=learning_rate,colsample_bytree=colsample_bytree,\n                            num_leaves=num_leaves,reg_alpha=reg_alpha,reg_lambda=reg_lambda,\n                            min_split_gain=min_split_gain,subsample=subsample,class_weight='balanced')\n    \n    return cross_val_score(clf, x_train, y_train, \n           n_jobs=-1, cv=5,scoring='f1_micro').mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study=optuna.create_study(direction='maximize')\nstudy.optimize(objective_lgbm,n_trials=50)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trial=study.best_trial\nprint(\"Best accuarcy : \",trial.values)\nprint(\"Best Params   : \",trial.params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_lgbm=lgb.LGBMClassifier(n_estimators=232, max_depth=19, learning_rate=0.6892271434058066, \n                              colsample_bytree=0.7209642378652753, num_leaves=58, reg_alpha=0.2789929636049069, \n                              reg_lambda=0.22306483739443742, \n                              min_split_gain=0.10007706931197725,subsample=0.3982537512515395,class_weight='balanced')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_lgbm.fit(x_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_lgbm=model_lgbm.predict(x_test)\naccuracy_lgbm=accuracy_score(y_test,pred_lgbm)\nprecision_lgbm=precision_score(y_test,pred_lgbm,average='weighted')\nrecall_lgbm=recall_score(y_test,pred_lgbm,average='weighted')\nf1_lgbm=f1_score(y_test,pred_lgbm,average='micro')\n\nprint(\"******* LGBM CLASSIFIER RESULTS ********\")\nprint(\"Accuracy  :\" ,  accuracy_lgbm)\nprint(\"Precision : \", precision_lgbm)\nprint(\"Recall    : \", recall_lgbm)\nprint(\"F1 Score  : \", f1_lgbm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test,pred_lgbm))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(model_lgbm,x_test,y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<html>\n    <h1 style='color:pink;'>CONCLUSIONS</h1>\n</html>","metadata":{}},{"cell_type":"markdown","source":"* **AFTER REMOVING SOME FEATURES THERE IS NO AS SUCH IMPROVEMENT IN THE F1_SCORE**\n\n* **BUT WE ARE ABLE TO GET GOOD SCORE WITH LESS FEATURES , THAT MEANS THE FEATURES WE REMOVED ARE NOT CONTRIBUTING TOWARDS TARGET**\n\n* **LIGHT GBM CLASSIFIER WORKS BETTER THAN RANDOM FOREST CLASSIFIER**","metadata":{}},{"cell_type":"markdown","source":"<html>\n    <p style='color:green;'><b>WHAT WILL BE THE RESULTS IF WE USE UPSAMPLING</b></p>\n</html>\n","metadata":{}},{"cell_type":"code","source":"sm=SMOTE()\nx_train_samp,y_train_samp=sm.fit_resample(x_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def objective(trial):\n    \n    n_estimators = trial.suggest_int('n_estimators', 2, 200)\n    max_depth = int(trial.suggest_int('max_depth', 1, 40))\n    clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)\n    return cross_val_score(clf, x_train_samp, y_train_samp, \n           n_jobs=-1, cv=5,scoring=\"f1_micro\").mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study=optuna.create_study(direction='maximize')\nstudy.optimize(objective,n_trials=50)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trial=study.best_trial\nprint(\"Best F1   : \",trial.values)\nprint(\"Best parameterst: \",trial.params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_rf_samp=RandomForestClassifier(n_estimators=195,max_depth=22)\nmodel_rf_samp.fit(x_train_samp,y_train_samp)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_rf=model_rf_samp.predict(x_test)\naccuracy_rf=accuracy_score(y_test,pred_rf)\nprecision_rf=precision_score(y_test,pred_rf,average='weighted')\nrecall_rf=recall_score(y_test,pred_rf,average='weighted')\nf1_rf=f1_score(y_test,pred_rf,average='micro')\n\nprint(\"******* RANDOM FOREST CLASSIFIER RESULTS WITH UPSAMPLING********\")\nprint(\"Accuracy  :\", accuracy_rf)\nprint(\"Precision : \", precision_rf)\nprint(\"Recall    : \",recall_rf)\nprint(\"F1 Score  : \",f1_rf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test,pred_rf))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(model_rf_samp,x_test,y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<html>\n    <h1 style='color:pink;'><b>FINISH</b></h1>\n</html>\n\n* **I WAS TRYING TO DO SOMETHING DIFFERENT ABOVE , BUT IN MY OPINION DATASET AND OUR ENSEMBLERS ARE SO GOOD , THAT EVEN WITHOUT DOING ANYTHING ON DATA WE ARE GETTING GOOD RESULTS**\n\n* **WE EVEN GOT VERY GOOD RESULTS WITH SMOTE UPSAMPLING**\n\n* **IF YOU HAVE ANY DOUBTS OR I HAVE DONE ANY MISTAKE , PLEASE TELL ME I WILL EDIT THIS NOTEBOOK AGAIN , I AM ALWAYS READY TO IMPROVE MYSELF**\n\n* **IF YOU REALLY LIKE MY NOTEBOOOK DO PROVIDE FEEDBACK AND UPVOTE , MAY BE IT WILL BE HELP TO GET A JOB**\n\n* **I LOVE TO DO EXPERIMENTS AND TRYING OUT NEW THINGS , IF YOU WANT ME TO DO SOMETHING LET ME KNOW IN THE COMMENTS SECTION**\n\n* **IF YOU WANT TO KNOW ABOUT MUTUAL INFORMATION PLEASE VISIT FEATURE ENGINEERING MINI COURSE ON KAGGLE AND I HAVE DECIDED TO APPLY THAT IN THIS NOTEBOOK**\n\n* **LET'S MEET ONTO NEXT NOTEBOOK**\n","metadata":{}}]}