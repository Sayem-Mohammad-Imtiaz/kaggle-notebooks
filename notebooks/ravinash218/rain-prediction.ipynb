{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport plotly.express as px\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nimport joblib","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Problem Statement\n\nPredict whether it is going to rain tomorrow or not based on todays's weather report","metadata":{}},{"cell_type":"markdown","source":"# Import Dataset","metadata":{}},{"cell_type":"code","source":"raw_df = pd.read_csv('../input/weather-dataset-rattle-package/weatherAUS.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_df.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Total Columns = 23<br>\nDate is irrelevant feature<br>\nRainTomorrow is taget feature<br>\nSo, 21 features and one taget feature<br>\nIn the dataset, there are missing values for some rows which can be preprocessed.<br>\n\n<b>Note :</b>There are also missing values in the target column 'RainTomorrow', <br>\nso those rows for which there are null values in target column 'RainTomorrow' are to be removed.<br>\n\nAlso, the feature 'RainToday' is a feature is likely to be very closely related to the target variable.<br>\nSo, we consider this hypothesis and remove rows with null values","metadata":{}},{"cell_type":"code","source":"raw_df.dropna(subset=['RainToday','RainTomorrow'], inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_df.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The number of rows are reduced from 145460 to 140787 <br>\nAlso, no null values in the columns RainToday, RainTomorrow","metadata":{}},{"cell_type":"markdown","source":"# Data Visualization & Analysis","metadata":{}},{"cell_type":"code","source":"#configure matplotlib for visulaisation style\nsns.set_style('darkgrid')\nmatplotlib.rcParams['font.size'] = 14\nmatplotlib.rcParams['figure.figsize'] = (10, 6)\nmatplotlib.rcParams['figure.facecolor'] = '#00000000'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Location Distribution","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(raw_df, x='Location', title='Distribution of Location', marginal='box',color='RainToday' )\nfig.update_layout(bargap=0.1)\nfig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Uniform Distribution<br>\nAbove 20% there were rain in all cities<br>\nNhil, Katherine, Uluru has lesser values than other cities.<br>\nThis might be probably due to no weather stations or data lost, or any other factors<br>\n\nTherefore, Location is a factor for rainfall","metadata":{}},{"cell_type":"markdown","source":"## Minimum Temperature","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(raw_df, x='MinTemp', title='Minimum Temperature Distribution', color='RainTomorrow', marginal='box')\nfig.update_layout(bargap=0.1)\nfig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Whatever the minimum temperature is, there is more possible of ***no rain*** on the next day.<br>\nThere is less possibility to rain on the next day if the minimum temperature on the previous day is around 5 to 25<br>","metadata":{}},{"cell_type":"markdown","source":"## Maximum Temperature","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(raw_df, x='MaxTemp', title='Maximum Temperature Distribution', color='RainTomorrow', marginal='box')\nfig.update_layout(bargap=0.1)\nfig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Whatever the maximum temperature is, there is more possible of ***no rain*** on the next day.<br>\nThere are rain on the next day if the maximum temperature on the previous day is around 10 to 35 <br>","metadata":{}},{"cell_type":"markdown","source":"## Rainfall Distribution - Rain Tomorrow Vs Rain Today\nWe assumed a hypothesis that if there is rain on a day it is more likely to rain on the next day too<br>","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(raw_df, x='RainTomorrow', title='Rain Tomorrow Vs Rain Today', marginal='box', color='RainToday')\nfig.update_layout(bargap=0.1)\nfig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Out of 140787 sample cases,around 110k there were rain the next day<br>\nbut around 30k there were no rain the next day.<br>\nThis is class imbalance i.e, no imbalance of each classes of target variable which may lead to bias towards not raining on tomorrow.\n\nThere were 92.728k cases with no rain today and tomorrow<br>\nThere were 16.858k cases with rain today and no rain tomorrow<br>\nThere were 16.604k cases with no rain today and rain tomorrow<br>\nThere were 14.597k cases with rain today and tomorrow<br>\n\nSo, there is a high chance that it will not rain tomorrow if it didn't rain today<br>\nBut it is not the case that it will rain tomorrow if it did rain today<br>\ni.e, there is equal chance of raining tomorrow if it either rains today or not.<br>\n\n<b>So it is easy to predict rain tomorrow as No but not easy to predict rain tomorrow as Yes (when rain today is no)","metadata":{}},{"cell_type":"markdown","source":"## Evaporation Distribution","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(raw_df, x='Evaporation', title='Evaporation Distribution', color='RainTomorrow', marginal='box')\n#fig = px.histogram(raw_df[raw_df.Evaporation < 10], x='Evaporation', title='Evaporation Distribution', color='RainTomorrow', marginal='box')\nfig.update_layout(bargap=0.01)\nfig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Whatever the evaporation rate, there is more possibility of ***no rain*** on the next day<br>\nAlso most commonly evaporation rate in which there is a low probability to rain on the next day is in the range is 0.6 - 8.","metadata":{}},{"cell_type":"markdown","source":"## Sunshine Distribution","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(raw_df, x='Sunshine', title='Sunshine Distribution', color='RainTomorrow', marginal='box')\n#fig = px.histogram(raw_df[raw_df.Sunshine <8], x='Sunshine', title='Sunshine Distribution', color='RainTomorrow', marginal='box')\nfig.update_layout(bargap=0.1)\nfig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the histogram, as the luminuous intensity of sun increases it is more probably that it will ***not rain*** on the next day.<br>\nAnd when the luminuous intensity of sun is low it is more probably ***to rain*** on the next day","metadata":{}},{"cell_type":"markdown","source":"## Wind Gust Direction\nThis is a categorical value with 16 categories of direction","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(raw_df, x='WindGustDir', title='Wind Gust Direction Distribution', color='RainTomorrow', marginal='box')\nfig.update_layout(bargap=0.1)\nfig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Whatever the wind gust direction is, there is more possibility of ***no rain*** on the next day<br>\nAlso for every of the 16 directions, there is lower probability that there will be rain on the next day.","metadata":{}},{"cell_type":"markdown","source":"## Wind Gust Speed Distribution\nA sudden burst in wind speed is called the wind gusts","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(raw_df, x='WindGustSpeed', title='Wind Gust Speed Distribution', color='RainTomorrow', marginal='box')\nfig.update_layout(bargap=0.1)\nfig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Whatever the wind gust speed, there is more possibility of ***no rain*** on the next day<br>\nAlso most commonly wind gust speed is in the range is 24 - 65 for which there is low probability to rain on the next day.","metadata":{}},{"cell_type":"markdown","source":"## Wind Direction@9AM\nThis is a categorical value with 16 categories of direction","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(raw_df, x='WindDir9am', title='Wind Direction@9am Distribution', color='RainTomorrow', marginal='box')\nfig.update_layout(bargap=0.1)\nfig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Whatever the wind gust direction is, there is more possibility of ***no rain*** on the next day<br>\nAlso for every of the 16 directions, there is lower probability that there will be rain on the next day.","metadata":{}},{"cell_type":"markdown","source":"## Wind Direction@3PM\nThis is a categorical value with 16 categories of direction","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(raw_df, x='WindDir3pm', title='Wind Direction@3pm Distribution', color='RainTomorrow', marginal='box')\nfig.update_layout(bargap=0.1)\nfig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Whatever the wind gust direction is, there is more possibility of ***no rain*** on the next day<br>\nAlso for every of the 16 directions, there is lower probability that there will be rain on the next day.","metadata":{}},{"cell_type":"markdown","source":"## WindSpeed@9am Distribution","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(raw_df, x='WindSpeed9am', title='WindSpeed@9am Distribution', color='RainTomorrow', marginal='box')\nfig.update_layout(bargap=0.1)\nfig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Whatever the wind speed at 9am, there is more possibility of ***no rain*** on the next day.<br>\nAlso most commonly wind speed at 9am is in the range is 0 - 28 for which there is low probability to rain on the next day","metadata":{}},{"cell_type":"markdown","source":"## WindSpeed@3PM Distribution","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(raw_df, x='WindSpeed3pm', title='WindSpeed@3pm Distribution', color='RainTomorrow', marginal='box')\nfig.update_layout(bargap=0.1)\nfig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Whatever the wind speed at 3pm, there is more possibility of ***no rain*** on the next day.<br>\nAlso most commonly wind speed at 3pm is in the range is 7 - 31 for which there is low probability to rain on the next day","metadata":{}},{"cell_type":"markdown","source":"## Humidity@9AM Distribution","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(raw_df, x='Humidity9am', title='Humidity@9am Distribution', color='RainTomorrow', marginal='box')\nfig.update_layout(bargap=0.1)\nfig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Whatever the humidity at 9am, there is more possibility of ***no rain*** on the next day.<br>\nAlso most commonly humidity at 9am is in the range is 60 - 100 for which there is low probability to rain on the next day","metadata":{}},{"cell_type":"markdown","source":"## Humidity@3PM Distribution","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(raw_df, x='Humidity3pm', title='Humidity@3pm Distribution', color='RainTomorrow', marginal='box')\nfig.update_layout(bargap=0.1)\nfig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Whenever the humidity at 3pm is in the range 0 - 78, there is more possibility of ***no rain*** on the next day.<br>\nWhenever the humidity at 3pm is above 78, there is more possibility of ***raining*** on the next day.<br>","metadata":{}},{"cell_type":"markdown","source":"## Pressure@9AM Distribution","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(raw_df, x='Pressure9am', title='Pressure@9am Distribution', color='RainTomorrow', marginal='box')\nfig.update_layout(bargap=0.1)\nfig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Whatever the pressure at 9am, there is more possibility of ***no rain*** on the next day.<br>\nAlso most commonly pressure at 9am is in the range is 1000 - 1030 for which there is low probability to rain on the next day","metadata":{}},{"cell_type":"markdown","source":"## Pressure@3PM Distribution","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(raw_df, x='Pressure3pm', title='Pressure@3pm Distribution', color='RainTomorrow', marginal='box')\nfig.update_layout(bargap=0.1)\nfig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Whatever the pressure at 3pm, there is more possibility of ***no rain*** on the next day.<br>\nAlso most commonly pressure at 3pm is in the range is 1000 - 1030 for which there is low probability to rain on the next day","metadata":{}},{"cell_type":"markdown","source":"## Cloud@9AM Distribution","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(raw_df, x='Cloud9am', title='Cloud@9am Distribution', color='RainTomorrow', marginal='box')\nfig.update_layout(bargap=0.1)\nfig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Whatever the cloud at 9am, there is more possibility of ***no rain*** on the next day.<br>\nAs cloud at 9am(6-8) increases probability of raining on the next day increases","metadata":{}},{"cell_type":"markdown","source":"## Cloud@3PM Distribution","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(raw_df, x='Cloud3pm', title='Cloud@3pm Distribution', color='RainTomorrow', marginal='box')\nfig.update_layout(bargap=0.1)\nfig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Whatever the cloud at 3pm, there is more possibility of ***no rain*** on the next day.<br>\nAs cloud at 3pm increases probability of raining on the next day increases.<br>\nFor cloud at 3pm = 8, there is more probability ofraining on the next day","metadata":{}},{"cell_type":"markdown","source":"## Temperature@9AM Distribution","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(raw_df, x='Temp9am', title='Temperature@9AM Distribution', color='RainTomorrow', marginal='box')\nfig.update_layout(bargap=0.1)\nfig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Whatever the Temperature at 9am, there is more possibility of no rain on the next day.<br>\nAlso most commonly temperature at 9am is in the range is 10 - 30 for which there is low probability to rain on the next day.","metadata":{}},{"cell_type":"markdown","source":"## Temperature@3PM Distribution","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(raw_df, x='Temp3pm', title='Temperature@3PM Distribution', color='RainTomorrow', marginal='box')\nfig.update_layout(bargap=0.1)\nfig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Gaussian / Normal Distibution<br>\nIt seems for Lower the temperature, more cases of rain the next day<br>\nAlso there are some cases when temperature is high and there was rain the next day","metadata":{}},{"cell_type":"markdown","source":"## Min Temp Vs Max Temp","metadata":{}},{"cell_type":"code","source":"px.scatter(raw_df.sample(2000), x='MinTemp', y='MaxTemp', title='MinTemp Vs MaxTemp', color='RainToday')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Note***<br>\nFor RainToday=Yes, Minimum temperature and maximum temperature are nearer.<br>\nFor RainToday=No, Minimum temperature and maximum temperature are not nearer.<br>\n\nWhen there is rain, variation in temperature is small (i.e,maximum temperature is nearer to minimum temperature)","metadata":{}},{"cell_type":"markdown","source":"## Rainfall Vs Evaporation","metadata":{}},{"cell_type":"code","source":"px.scatter(raw_df.sample(2000), x='Rainfall', y='Evaporation', title='Rainfall Vs Evaporation', color='RainToday')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As rainfall increases, evaporation decreases<br>\nWhen rainfall in a day is less than or equal to 1, there is no rain on the next day<br>\nWhen rainfall in a day is more than 1, there is rain on the next day<br>","metadata":{}},{"cell_type":"markdown","source":"## Sunshine Vs Evaporation","metadata":{}},{"cell_type":"code","source":"px.scatter(raw_df.sample(2000), x='Sunshine', y='Evaporation', title='Sunshine Vs Evaporation', color='RainToday')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With increase in sunshine, the evaporation rate is almost constant<br>\nWith increase in sunshine, there is a more possibility to rain on the next day as<br>\nthe number of samples where it rained the next day increases with increase in sunshine<br>","metadata":{}},{"cell_type":"markdown","source":"## Temp@9AM Vs Humidity@9AM","metadata":{}},{"cell_type":"code","source":"px.strip(raw_df.sample(2000), x='Temp9am', y='Humidity9am', title='Temp@9AM Vs Humidity@9AM', color='RainTomorrow')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"When temperature@9am increases Humidity@9am decreases for both rainTomorrow=Yes or No<br>\nFor higher temperature and lower humidity it is more probable that it will not rain the next day","metadata":{}},{"cell_type":"markdown","source":"## Temp@3PM Vs Humidity@3PM","metadata":{}},{"cell_type":"code","source":"px.strip(raw_df.sample(2000), x='Temp3pm', y='Humidity3pm', title='Temp@3PM Vs Humidity@3PM', color='RainTomorrow')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"When temperature@3pm increases Humidity@3pm decreases for both rainTomorrow=Yes or No<br>\nBut during rainTomorrow=Yes, Humidity is more compared to rainTomorrow=No<br>\n\nWhen temperature@3pm is low & humidity@3pm is high, there is high chance that it will rain tomorrow","metadata":{}},{"cell_type":"markdown","source":"## Pressure@9AM Vs Humidity@9AM","metadata":{}},{"cell_type":"code","source":"px.strip(raw_df.sample(2000), x='Pressure9am', y='Humidity9am', title='Pressure@9AM Vs Humidity@9AM', color='RainTomorrow')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"When Pressure@9am increases Humidity@9am increases<br>\nMost samples for which there will be no rain the next day have humidity > 20<br>\nMost samples for which there will be no rain the next day have humidity > 50<br>","metadata":{}},{"cell_type":"markdown","source":"## Pressure@3PM Vs Humidity@3PM","metadata":{}},{"cell_type":"code","source":"px.strip(raw_df.sample(2000), x='Pressure3pm', y='Humidity3pm', title='Pressure@3PM Vs Humidity@3PM', color='RainTomorrow')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Most of the samples for which the next day will rain have humidity > 30<br>\nMost of the samples for which the next day will not rain have humidity > 0<br>","metadata":{}},{"cell_type":"markdown","source":"## Temp@9AM Vs Pressure@9AM","metadata":{}},{"cell_type":"code","source":"px.strip(raw_df.sample(2000), x='Temp9am', y='Pressure9am', title='Temp@9AM Vs Pressure@9AM', color='RainTomorrow')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With increase in temperature@9am pressure@9am decreases slightly<br>\nFor less temperature and high pressure, it is more probable that it will not rain the next day","metadata":{}},{"cell_type":"markdown","source":"## Temp@3PM Vs Pressure@3PM","metadata":{}},{"cell_type":"code","source":"px.strip(raw_df.sample(2000), x='Temp3pm', y='Pressure3pm', title='Temp@3PM Vs Pressure@3PM', color='RainTomorrow')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With increase in temperature@3pm pressure@3pm decreases slightly<br>\nFor lesser temperature and pressure it is more likely to rain the next day<br>\nFor higher temperature and lower pressure it is not likely to rain on the next day","metadata":{}},{"cell_type":"markdown","source":"# Working With Sample","metadata":{}},{"cell_type":"code","source":"use_sample = False\nsample_fraction = 0.1\nif use_sample:\n    raw_df = raw_df.sample(sample_fraction).copy()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training, Validation, Test Sets","metadata":{}},{"cell_type":"code","source":"train_val_df, test_df = train_test_split(raw_df, test_size=0.2, random_state=42)\ntrain_df, val_df = train_test_split(train_val_df, test_size=0.25, random_state=42)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('train_df shape :',train_df.shape)\nprint('val_df shape :',val_df.shape)\nprint('test_df shape :',test_df.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Note :*** While working with dates (time-series data), it's often a better idea to separate the training, validation and test sets<br> with time, so that the model is trained on data from the past and evaluated on data from the future.<br>\n\nLet us analyse the years from which the dataset are from.","metadata":{}},{"cell_type":"code","source":"plt.title('No. of Rows per year')\nsns.countplot(x=pd.to_datetime(raw_df.Date).dt.year);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We'll use datas till 2014 (inclusive) for training, 2015 for validation and 2016 & 2017 for testing<br>\neven there is no 60-20-20 ratio maintained.\n\nData from 2018, 2019 can be used for deployment (future).","metadata":{}},{"cell_type":"code","source":"year = pd.to_datetime(raw_df.Date).dt.year\nyear","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = raw_df[year < 2015]\nval_df = raw_df[year == 2015]\ntest_df = raw_df[year > 2015]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('train_df shape :',train_df.shape)\nprint('val_df shape :',val_df.shape)\nprint('test_df shape :',test_df.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Identify Input & Target Columns","metadata":{}},{"cell_type":"code","source":"raw_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Note :***\nThe date column is 2018 everywhere due to the split we have done. So, during testing our model won't<br> see any date as 2018 so it is useless to use date column as an input column.<br>\n\nRainTomorrow is target.<br>\nAll other than these are input columns.","metadata":{}},{"cell_type":"code","source":"cols = list(train_df.columns)\ninput_cols = cols[1:-1]\ntarget_cols = cols[-1]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Training Set","metadata":{}},{"cell_type":"code","source":"X_train = train_df[input_cols].copy()\nY_train = train_df[target_cols].copy()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Validation Set","metadata":{}},{"cell_type":"code","source":"X_val = val_df[input_cols].copy()\nY_val = val_df[target_cols].copy()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Test Set","metadata":{}},{"cell_type":"code","source":"X_test = test_df[input_cols].copy()\nY_test = test_df[target_cols].copy()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Identify Numerical & Categorical Columns","metadata":{}},{"cell_type":"code","source":"numeric_cols = list(X_train.select_dtypes(include=np.number).columns)\ncategorical_cols = list(X_train.select_dtypes('object').columns)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numeric_cols,categorical_cols","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Statistics of Numerical Data in Training Set","metadata":{}},{"cell_type":"code","source":"X_train.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Unique Categories of Categorical Data in Training Set","metadata":{}},{"cell_type":"code","source":"X_train[categorical_cols].nunique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Imputing Missing Numeric Data\n\nSince there are some missing values, we'll get error when performing some steps in ML.\n\n<img src=\"https://i.imgur.com/W7cfyOp.png\" width=\"480\">\n\nSo, we'll replace those values with average value from the column.<br>\n\nWe'll compute average from the entire set and fill it in train, val, test set individually","metadata":{}},{"cell_type":"markdown","source":"#### Find Total Number of Nan in Numeric Coumns","metadata":{}},{"cell_type":"code","source":"raw_df[numeric_cols].isna().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imputer = SimpleImputer(strategy='mean')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imputer.fit(raw_df[numeric_cols])   #fitting in raw_df not in X_train, X_val ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imputer.statistics_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train[numeric_cols] = imputer.transform(X_train[numeric_cols])\nX_val[numeric_cols] = imputer.transform(X_val[numeric_cols])\nX_test[numeric_cols] = imputer.transform(X_test[numeric_cols])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Values Replaced by Average ","metadata":{}},{"cell_type":"code","source":"X_train[numeric_cols].isna().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> **EXERCISE**: Apply some other imputation techniques and observe how they change the results of the model. You can learn more about other imputation techniques here: https://scikit-learn.org/stable/modules/impute.html","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Scaling","metadata":{}},{"cell_type":"code","source":"scaler = MinMaxScaler()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler.fit(raw_df[numeric_cols])  #not splitted data set","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Scale Training Data Set","metadata":{}},{"cell_type":"code","source":"X_train[numeric_cols] = scaler.transform(X_train[numeric_cols])\nX_train[numeric_cols]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train[numeric_cols].describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Scaling Validation Data Set","metadata":{}},{"cell_type":"code","source":"X_val[numeric_cols] = scaler.transform(X_val[numeric_cols])\nX_val","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Scaling Test Data Set","metadata":{}},{"cell_type":"code","source":"X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])\nX_test","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Encoding Categorical Values\n\nSince machine learning models can only be trained with numeric data, we need to convert categorical data to numbers by using techniques like one-hot encoding for categorical columns.\n\n<img src=\"https://i.imgur.com/n8GuiOO.png\" width=\"640\">\n\nOne hot encoding involves adding a new binary (0/1) column for each unique category of a categorical column. ","metadata":{}},{"cell_type":"code","source":"raw_df[categorical_cols].nunique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Encoding Location Column","metadata":{}},{"cell_type":"code","source":"raw_df.Location.unique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder.fit(raw_df[categorical_cols])    #fit with entire dataset","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorical_cols","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder.categories_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Get Feature Names for the Encoded Columns","metadata":{}},{"cell_type":"code","source":"encoded_cols = list(encoder.get_feature_names(categorical_cols))\nencoded_cols","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Training Data Set","metadata":{}},{"cell_type":"code","source":"X_train[encoded_cols] = encoder.transform(X_train[categorical_cols])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Validation Data Set","metadata":{}},{"cell_type":"code","source":"X_val[encoded_cols] = encoder.transform(X_val[categorical_cols])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Test Data Set","metadata":{}},{"cell_type":"code","source":"X_test[encoded_cols] = encoder.transform(X_test[categorical_cols])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Note :***<br>\nIn these data frames, both categorical columns and corresponding encoded columns are also present","metadata":{}},{"cell_type":"markdown","source":"# Save Processed Data","metadata":{}},{"cell_type":"code","source":"print('X_train:', X_train.shape)\nprint('Y_train:', Y_train.shape)\nprint('X_val:', X_val.shape)\nprint('Y_val:', Y_val.shape)\nprint('X_test:', X_test.shape)\nprint('Y_test:', Y_test.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Store DataFrames as parquet format","metadata":{}},{"cell_type":"code","source":"X_train.to_parquet('X_train.parquet')\nX_val.to_parquet('X_val.parquet')\nX_test.to_parquet('X_test.parquet')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(Y_train).to_parquet('Y_train.parquet')\npd.DataFrame(Y_val).to_parquet('Y_val.parquet')\npd.DataFrame(Y_test).to_parquet('Y_test.parquet')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Read those stored data","metadata":{}},{"cell_type":"code","source":"X_train = pd.read_parquet('X_train.parquet')\nX_val = pd.read_parquet('X_val.parquet')\nX_test = pd.read_parquet('X_test.parquet')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_train = pd.read_parquet('Y_train.parquet')[target_cols]\nY_val = pd.read_parquet('Y_val.parquet')[target_cols]\nY_test = pd.read_parquet('Y_test.parquet')[target_cols]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('X_train:', X_train.shape)\nprint('Y_train:', Y_train.shape)\nprint('X_val:', X_val.shape)\nprint('Y_val:', Y_val.shape)\nprint('X_test:', X_test.shape)\nprint('Y_test:', Y_test.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training a Logistic Regression Model","metadata":{}},{"cell_type":"code","source":"model = LogisticRegression(solver ='liblinear') #liblinear optimization","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nmodel.fit(X_train[numeric_cols + encoded_cols], Y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weight_df = pd.DataFrame({\n    'feature' : (numeric_cols + encoded_cols),\n    'weight' : model.coef_.tolist()[0]\n})","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,50))\nsns.barplot(data=weight_df, x='weight', y='feature');","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Top 10 Important Features","metadata":{}},{"cell_type":"code","source":"sns.barplot(data=weight_df.sort_values('weight', ascending=False).head(10), x='weight', y='feature');","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Making Predictions & Evaluations","metadata":{}},{"cell_type":"code","source":"X_train = X_train[numeric_cols + encoded_cols]\nX_val = X_val[numeric_cols + encoded_cols]\nX_test = X_test[numeric_cols + encoded_cols]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_pred = model.predict(X_train)\ntrain_probs = model.predict_proba(X_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_pred","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_probs","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_train","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Accuracy","metadata":{}},{"cell_type":"code","source":"print('Accuracy =',accuracy_score(Y_train, train_pred))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model achieves an accuracy of 85.1% on the training set. We can visualize the breakdown of correctly and incorrectly classified inputs using a confusion matrix.\n\n<img src=\"https://i.imgur.com/UM28BCN.png\" width=\"480\">","metadata":{}},{"cell_type":"markdown","source":"#### Confusion Matrix - Training Data Set","metadata":{}},{"cell_type":"code","source":"cf = confusion_matrix(Y_train, train_pred, normalize='true')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Accuracy =',accuracy_score(Y_train, train_pred)*100)\nplt.figure();\nsns.heatmap(cf, annot=True);\nplt.title('Training Confusion Matrix');\nplt.xlabel('Prediction');\nplt.ylabel('Target');","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Confusion Matrix - Validation Data Set","metadata":{}},{"cell_type":"code","source":"X_val","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_pred = model.predict(X_val)\ncf = confusion_matrix(Y_val, val_pred, normalize='true')\ncf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Accuracy =',accuracy_score(Y_val, val_pred)*100)\nplt.figure();\nsns.heatmap(cf, annot=True);\nplt.title('Validation Confusion Matrix');\nplt.xlabel('Prediction');\nplt.ylabel('Target');","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Confusion Matrix - Test Data Set","metadata":{}},{"cell_type":"code","source":"test_pred = model.predict(X_test)\ncf = confusion_matrix(Y_test, test_pred, normalize='true')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Accuracy =', accuracy_score(Y_test, test_pred))\nplt.figure()\nsns.heatmap(cf, annot = True);\nplt.title('Testing Confusion Matrix');\nplt.xlabel('Prediction');\nplt.ylabel('Targer');","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The accuracy of the model on the test and validation set are above 84%, which suggests that our model generalizes well to data it hasn't seen before. \n\nBut how good is 84% accuracy? While this depends on the nature of the problem and on business requirements, a good way to verify whether a model has actually learned something useful is to compare its results to a \"random\" or \"dumb\" model.\n\nLet's create two models: one that guesses randomly and another that always return \"No\". Both of these models completely ignore the inputs given to them.","metadata":{}},{"cell_type":"code","source":"def random_model(inputs):\n    return np.random.choice(['No', 'Yes'], len(inputs))\nprint('Accuracy on Random Model on Validation Data Set =',accuracy_score(random_model(X_val), Y_val))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Therefore, just by predicting randomly accuracy is 50 %","metadata":{}},{"cell_type":"code","source":"def all_no(inputs):\n    return np.full(len(inputs), ['No'])\nprint('Accuracy on All_No Model on Test Data Set =',accuracy_score(all_no(X_test), Y_test))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Therefore, just by predicting all as 'No' gives accuracy as 77 %.<br>\n***Note : *** Accuracy for All_No model is 77% and our model has accuracy as 84% for test data set<br>\n\nThis is because the validation data set is skewed towards 'No' as see below:","metadata":{}},{"cell_type":"code","source":"Y_test.value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> **EXERCISE**: Initialize the `LogisticRegression` model with different arguments and try to achieve a higher accuracy. The arguments used for initializing the model are called hyperparameters (to differentiate them from weights and biases - parameters that are learned by the model during training). You can find the full list of arguments here: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html ","metadata":{}},{"cell_type":"markdown","source":"> **EXERCISE**: Train a logistic regression model using just the numeric columns from the dataset. Does it perform better or worse than the model trained above?","metadata":{}},{"cell_type":"markdown","source":"> **EXERCISE**: Train a logistic regression model using just the categorical columns from the dataset. Does it perform better or worse than the model trained above?","metadata":{}},{"cell_type":"markdown","source":"> **EXERCISE**: Train a logistic regression model without feature scaling. Also try a different strategy for missing data imputation. Does it perform better or worse than the model trained above?","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Making Prediction on Single Input","metadata":{}},{"cell_type":"code","source":"new_input = {'Date': '2021-06-19',\n             'Location': 'Katherine',\n             'MinTemp': 23.2,\n             'MaxTemp': 33.2,\n             'Rainfall': 10.2,\n             'Evaporation': 4.2,\n             'Sunshine': np.nan,\n             'WindGustDir': 'NNW',\n             'WindGustSpeed': 52.0,\n             'WindDir9am': 'NW',\n             'WindDir3pm': 'NNE',\n             'WindSpeed9am': 13.0,\n             'WindSpeed3pm': 20.0,\n             'Humidity9am': 89.0,\n             'Humidity3pm': 58.0,\n             'Pressure9am': 1004.8,\n             'Pressure3pm': 1001.5,\n             'Cloud9am': 8.0,\n             'Cloud3pm': 5.0,\n             'Temp9am': 25.7,\n             'Temp3pm': 33.0,\n             'RainToday': 'Yes'}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Note : ***There is Nan value also","metadata":{}},{"cell_type":"code","source":"new_input = pd.DataFrame([new_input])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_input","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We must now apply the same transformations applied while training the model:\n\n1. Imputation of missing values using the `imputer` created earlier (Average values for numeric columns only)\n2. Scaling numerical features using the `scaler` created earlier\n3. Encoding categorical features using the `encoder` created earlier","metadata":{}},{"cell_type":"code","source":"new_input[numeric_cols] = imputer.transform(new_input[numeric_cols])\nnew_input[numeric_cols] = scaler.transform(new_input[numeric_cols])\nnew_input[encoded_cols] = encoder.transform(new_input[categorical_cols])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_inp = new_input[numeric_cols + encoded_cols]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(model.predict(X_inp))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.predict_proba(X_inp)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Seems our model is not  confident with its prediction","metadata":{}},{"cell_type":"code","source":"new_input = {'Date': '2021-06-19',\n             'Location': 'Launceston',\n             'MinTemp': 23.2,\n             'MaxTemp': 33.2,\n             'Rainfall': 10.2,\n             'Evaporation': 4.2,\n             'Sunshine': np.nan,\n             'WindGustDir': 'NNW',\n             'WindGustSpeed': 52.0,\n             'WindDir9am': 'NW',\n             'WindDir3pm': 'NNE',\n             'WindSpeed9am': 13.0,\n             'WindSpeed3pm': 20.0,\n             'Humidity9am': 89.0,\n             'Humidity3pm': 58.0,\n             'Pressure9am': 1004.8,\n             'Pressure3pm': 1001.5,\n             'Cloud9am': 8.0,\n             'Cloud3pm': 5.0,\n             'Temp9am': 25.7,\n             'Temp3pm': 33.0,\n             'RainToday': 'Yes'}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_input(single_input):\n    input_df = pd.DataFrame([single_input])\n    input_df[numeric_cols] = imputer.transform(input_df[numeric_cols])\n    input_df[numeric_cols] = scaler.transform(input_df[numeric_cols])\n    input_df[encoded_cols] = encoder.transform(input_df[categorical_cols])\n    X_input = input_df[numeric_cols + encoded_cols]\n    pred = model.predict(X_input)[0]\n    prob = model.predict_proba(X_input)[0][list(model.classes_).index(pred)]\n    return pred, prob","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_input(new_input)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Saving & Loading Model\n\nWe can save the parameters (weights and biases) of our trained model to disk, so that we needn't retrain the model from scratch each time we wish to use it. Along with the model, it's also important to save imputers, scalers, encoders and even column names. Anything that will be required while generating predictions using the model should be saved.\n\nWe can use the `joblib` module to save and load Python objects on the disk. ","metadata":{}},{"cell_type":"markdown","source":"Let's first create a dictionary containing all the required objects.","metadata":{}},{"cell_type":"code","source":"aussie_rain = {\n    'model': model,\n    'imputer': imputer,\n    'scaler': scaler,\n    'encoder': encoder,\n    'input_cols': input_cols,\n    'target_col': target_cols,\n    'numeric_cols': numeric_cols,\n    'categorical_cols': categorical_cols,\n    'encoded_cols': encoded_cols\n}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Save All","metadata":{}},{"cell_type":"code","source":"joblib.dump(aussie_rain,'aussie_rain.joblib')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Load","metadata":{}},{"cell_type":"code","source":"aussie_rain = joblib.load('aussie_rain.joblib')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aussie_rain","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(aussie_rain['model'].predict(X_test), Y_test)","metadata":{},"execution_count":null,"outputs":[]}]}