{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Predicting The Age of Death - Linear Regression\nDataset : https://www.kaggle.com/kumarajarshi/life-expectancy-who","metadata":{}},{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"import requests\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n#%matplotlib inline\nimport seaborn as sns\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.feature_selection import mutual_info_regression\nfrom sklearn.model_selection import ShuffleSplit, cross_val_score, train_test_split, KFold, GridSearchCV\nfrom sklearn.linear_model import LinearRegression, Lasso\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import Dataset","metadata":{}},{"cell_type":"markdown","source":"```\nDATASET_URL = 'https://raw.githubusercontent.com/avinash-218/Life-Expectancy-WHO/master/Life_Expectancy_Data.csv'\nreq = requests.get('https://raw.githubusercontent.com/avinash-218/Life-Expectancy-WHO/master/Life_Expectancy_Data.csv')\nurl_content = req.content\ncsv_file = open('Life_Expectancy_Data.csv','wb')\ncsv_file.write(url_content)\ncsv_file.close()\n```","metadata":{}},{"cell_type":"code","source":"dataset = pd.read_csv('../input/life-expectancy-who/Life Expectancy Data.csv')\ndataset","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Cleaning","metadata":{}},{"cell_type":"markdown","source":"#### Removing Trailing Spaces in Column Names\nSome column names in the dataset contains trailing space. So let's remove the trailing spaces","metadata":{}},{"cell_type":"code","source":"list(dataset.columns)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rename_col_names(x):\n    out={}\n    for i in x:\n        out[i] = i.rstrip()\n    return out","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col_names = list(dataset.columns)\ndataset.rename(columns=rename_col_names(col_names), inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col_names = list(dataset.columns)\ncol_names","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's Analyse and continue the preprocessing","metadata":{}},{"cell_type":"markdown","source":"# Data Analysis","metadata":{}},{"cell_type":"markdown","source":"### Numeric Columns","metadata":{}},{"cell_type":"code","source":"dataset","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numeric_cols = list(dataset.select_dtypes(include=np.number).columns)\nnumeric_cols.remove('Life expectancy') #target column\ncnt_numeric_cols = len(numeric_cols)\nfig, axes = plt.subplots(nrows=cnt_numeric_cols, ncols=3, figsize=(25,150))\nfig.tight_layout(pad=3)\n\nfor i in range(cnt_numeric_cols):\n    col = numeric_cols[i]\n    axes[i,0].set_title('{} Distribution'.format(col))\n    axes[i,0].set_xlabel(col)\n    sns.histplot(ax=axes[i,0], x=dataset[col])\n      \n    axes[i,1].set_title('{} Boxplot'.format(col))\n    axes[i,1].set_xlabel(col)\n    sns.boxplot(ax=axes[i,1], x=dataset[col])\n        \n    axes[i,2].set_title('{} Scatterplot'.format(col))\n    axes[i,2].set_xlabel(col)\n    sns.scatterplot(ax=axes[i,2], data=dataset, x=col, y='Life expectancy')\nplt.show()\nfig.savefig('Numerical Data Visualisation.jpeg', pil_kwargs={'quality': 95})","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b> Note :</b><br>\nAxes, title might not be visible in the saved image if your windows is in dark mode and the image launcher is the default windows program. Try to open with paint if these are not visible.<bt>\nOpening in the notebook also helps.","metadata":{}},{"cell_type":"markdown","source":"Below Code displays nunique, unique, % of nunique in the column, % of nan for each columns.","metadata":{}},{"cell_type":"code","source":"print('column \\t nunique \\t unique \\t % of nunique in column \\t % of nan')\nprint('-'*100)\nfor i in dataset[numeric_cols]:\n    print(i,':',dataset[i].nunique(),dataset[i].unique(),dataset[i].nunique()*100/13320,dataset[i].isna().sum()*100/13320,end='\\n\\n\\n')","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Categorical Columns\nLesser categorical valued columns only can be visualized properly.<br>\nSo visualize only those columns with lesser categories (but let's say threshold 200 here -explained in Note).<br>\n<b>Note:</b> This throws error when only one categorical column satisfy with threshold since it will be 1D which contradicts with the below code for 2D.<br>\nThe plots for the categorical column country is included below because there will be only one categorical column that satisfy lesser nuniques which throws error.","metadata":{}},{"cell_type":"code","source":"categorical_cols = list(dataset.select_dtypes('object'))\nless_category_cols = dataset[categorical_cols].columns[dataset[categorical_cols].nunique() < 200]\ncnt_less_category_cols = len(less_category_cols)\nfig, axes = plt.subplots(nrows=cnt_less_category_cols, ncols=3, figsize=(35, 20))\nfig.tight_layout(pad=3)\n\nfor i in range(cnt_less_category_cols):\n    col = less_category_cols[i]\n      \n    axes[i,0].set_title('{} Bargraph'.format(col))\n    axes[i,0].set_xlabel(col)\n    sns.barplot(ax=axes[i,0], data=dataset, x=col, y='Life expectancy')\n    \n    axes[i,1].set_title('{} Box Plot'.format(col))\n    axes[i,1].set_xlabel(col)\n    sns.boxplot(ax=axes[i,1], x=dataset[col], y=dataset['Life expectancy'])\n        \n    axes[i,2].set_title('{} Scatter Plot'.format(col))\n    axes[i,2].set_xlabel(col)\n    sns.scatterplot(ax=axes[i,2], data=dataset, x=col, y='Life expectancy')\n    \nplt.show()\nfig.savefig('Categorical Data Visualisation.jpeg', pil_kwargs={'quality': 95})","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Null Values Tratement","metadata":{}},{"cell_type":"markdown","source":"Percentage of null values in each columns","metadata":{}},{"cell_type":"markdown","source":"Fill missing values grouped by countries.<br>\nEg: Fill missing values in GDP based on the same country.<br>\nRemove the rows in which the target column is NaN","metadata":{}},{"cell_type":"code","source":"dataset = dataset[dataset['Life expectancy'].notna()].copy()\ndataset","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.isna().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.isna().sum() / dataset.shape[0] * 100","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns_with_null = list(dataset.columns[dataset.isna().any()])\ndataset[columns_with_null] = dataset.groupby('Country')[columns_with_null].transform(lambda x:x.fillna(x.mean()))\ndataset","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.isna().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.isna().sum() / dataset.shape[0] * 100","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Even now some data are NaN. This is because for some countries these columns were not measured. So just drop them","metadata":{}},{"cell_type":"code","source":"dataset.dropna(inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.isna().sum() / dataset.shape[0] * 100","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Encoding Status Column","metadata":{}},{"cell_type":"code","source":"def status_encode(x):\n    if(x=='Developed'):\n        return 1\n    else:\n        return 0","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset['Status'] = dataset['Status'].apply(status_encode)\ndataset","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\nencoder.fit(dataset[['Country']])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_cols = list(encoder.get_feature_names())\nencoded_cols","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset[encoded_cols] = encoder.transform(dataset[['Country']])\ndataset = dataset.drop('Country',axis=1)\ndataset","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Identifying Input & Target Column(s)","metadata":{}},{"cell_type":"code","source":"def identify_cols(dataset):\n    col_names = list(dataset.columns)\n    input_cols = col_names.copy()\n    input_cols.remove('Life expectancy')\n    target_col = 'Life expectancy'\n    #encoded_cols\n    X = dataset[input_cols]\n    Y = dataset[target_col]\n    return  X, Y","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X, Y = identify_cols(dataset)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering\nscikit-learn's mutual_info_regression and mutual_info_classif treat discrete and continuous values differently. So it is required to inform which are discrete columns.","metadata":{}},{"cell_type":"markdown","source":"##### Base Model","metadata":{}},{"cell_type":"code","source":"model_df=pd.DataFrame()\ndef train_validate(X, Y,stri):\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=42, test_size=0.2)\n    #X_train.shape, Y_train.shape, X_test.shape, Y_test.shape\n    model = LinearRegression()\n    model.fit(X_train, Y_train)\n    df = pd.DataFrame({'Train Accuracy':[model.score(X_train, Y_train)*100],'Test Accuracy':[model.score(X_test, Y_test)*100]},index=[stri])\n    return df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_df = pd.concat([model_df, train_validate(X,Y,'Base Model')])\nmodel_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_acc = abs(model_df['Train Accuracy'][0]-model_df['Test Accuracy'][0])\nbase_acc","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## MI Scores","metadata":{}},{"cell_type":"code","source":"discrete_features = (X.dtypes == 'int64') #finding the discrete columns\ndef find_mi_scores(X, Y, discrete_features):\n    mi_scores = mutual_info_regression(X, Y, discrete_features=discrete_features)\n    mi_scores = pd.Series(mi_scores, name='MI Scores', index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mi_scores = find_mi_scores(X, Y, discrete_features)\nmi_scores","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_mi_scores(scores):\n    scores = scores.sort_values(ascending=True)\n    width = np.arange(len(scores))\n    ticks=list(scores.index)\n    plt.barh(width, scores)\n    plt.yticks(width, ticks)\n    plt.title('Mutual Information Scores')\nplt.figure(dpi=100, figsize=(8,5))\nplot_mi_scores(mi_scores[:20])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The bar graph is plotted in descending order.<br>\nSo, the rest of the encoded Country Columns are still lesser.<br>\nSo it is not necessary to visualize the MI Score of them too.","metadata":{}},{"cell_type":"markdown","source":"### Model without Categorical Columns (manual)","metadata":{}},{"cell_type":"markdown","source":"##### Model without Country Column(original + encoded)","metadata":{}},{"cell_type":"code","source":"X, Y = identify_cols(dataset.drop(encoded_cols, axis=1))\ntrain_validate(X, Y, 'Without Country')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuray decreases so this column should be considered","metadata":{}},{"cell_type":"markdown","source":"### Model without Numerical Columns (Auto)","metadata":{}},{"cell_type":"markdown","source":"```\ncol_names = list(mi_scores.index)\nfor i in range(len(col_names)-1,-1,-1):\n    col = col_names[i]\n    if(col not in encoded_cols):\n        X, Y = identify_cols(dataset.drop(col, axis=1))\n        model_df = pd.concat([model_df, train_validate(X,Y,'Without ' + col + ' :')])\n```","metadata":{}},{"cell_type":"code","source":"model_df.sort_values(by=['Train Accuracy','Test Accuracy'], ascending=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Selection\nDiscard the features which are causing irrelevant contribution to the dataset.<br>\n(Negative Impact or no Impact)","metadata":{}},{"cell_type":"code","source":"col_names = list(mi_scores.index)\nfor i in range(len(col_names)-1,-1,-1):\n    col = col_names[i]\n    if(col not in encoded_cols):\n        val_col = dataset[col].copy()\n        dataset = dataset.drop(col, axis=1)\n        X, Y = identify_cols(dataset)\n        tr,te = train_validate(X,Y,'Without ' + col + ' :')['Train Accuracy'],train_validate(X,Y,'Without ' + col + ' :')['Test Accuracy']\n        err = abs(tr[0]-te[0])\n        if(base_acc <= err):\n            base_acc = err\n        else:\n            dataset[col] = val_col","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col_to_consider =[i for i in dataset.columns.to_list() if i not in encoded_cols]\nprint('Columns Which are to be considered (after Feature Engineering)\\n',col_to_consider)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(col_to_consider)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Test Split","metadata":{}},{"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=42, test_size=0.2)\nX_train.shape, Y_train.shape, X_test.shape, Y_test.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = LinearRegression()\nmodel.fit(X_train, Y_train)\nprint('Training Accuracy :',model.score(X_train, Y_train)*100)\nprint('Test Accuracy :',model.score(X_test, Y_test)*100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# K-Fold Cross Validation","metadata":{}},{"cell_type":"code","source":"kf = KFold(n_splits=5, shuffle=True, random_state=42)\nkf_sc = cross_val_score(LinearRegression(), X, Y, cv=kf)\nprint('Accuracy :',kf_sc.mean()*100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cross Validation","metadata":{}},{"cell_type":"code","source":"cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\ncv_sc = cross_val_score(LinearRegression(), X, Y, cv=cv)\nprint('Accuracy :',cv_sc.mean()*100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Grid Search CV","metadata":{}},{"cell_type":"code","source":"def find_best_model(X, Y):\n    algos={\n        'linear_reg':{'model':LinearRegression(), 'params':{'normalize':[True, False]}},\n        'lasso':{'model':Lasso(), 'params':{'alpha':[1,2], 'selection':['random', 'cyclic']}},\n        'decision_tree':{'model':DecisionTreeRegressor(), 'params':{'criterion':['mse','friedman_mse'],'splitter':['best','random']}},\n        'random_forest':{'model':RandomForestRegressor(), 'params':{'n_jobs':[-1], 'n_estimators':[10, 50, 100],'max_depth':[5,10,20], 'max_leaf_nodes':[50, 100]}},\n        'xgb':{'model':XGBRegressor(), 'params':{'n_jobs':[-1], 'n_estimators':[10,50,100],'max_depth':[5,10,20],'max_leaf_nodes':[50,100],'learning_rate':[0.1,0.2,0.3,0.4,0.5,0.55],'booster':['gblinear']}}\n            }\n    scores = []\n    cv = ShuffleSplit(n_splits=5, random_state=42, test_size=0.2)\n    for algo, config in algos.items():\n        gs = GridSearchCV(config['model'], config['params'], cv=cv, return_train_score=False)\n        gs.fit(X, Y)\n        scores.append({\n            'model':algo,\n            'best_score': gs.best_score_,\n            'best_params':gs.best_params_\n        })\n    return pd.DataFrame(scores, columns=['model','best_score', 'best_params'])\nmodels_summary = find_best_model(X, Y)","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models_summary","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the summary above,<br>\n<b>Linear Regression</b> with parameter(s) : normalize:'False' gives the best result","metadata":{}},{"cell_type":"markdown","source":"# Final Best Model","metadata":{}},{"cell_type":"code","source":"model = LinearRegression(normalize=True)\nmodel.fit(X_train, Y_train)\nprint('Training Accuracy :',model.score(X_train, Y_train)*100)\nprint('Test Accuracy :',model.score(X_test, Y_test)*100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_train.values,model.predict(X_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_test.values,model.predict(X_test)","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}