{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objs as go\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df=pd.read_csv('../input/customer-segmentation-tutorial-in-python/Mall_Customers.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfig,ax=plt.subplots(1,3,figsize=(20,5))\nsns.distplot(df['Age'],ax=ax[0])\nsns.distplot(df['Annual Income (k$)'],ax=ax[1])\nsns.distplot(df['Spending Score (1-100)'],ax=ax[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"px.violin(df,y='Annual Income (k$)',color='Gender',violinmode='overlay')\n#most of women anuual income is concentrated is  40-80K, whereas men 50_80K","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"px.box(df,x='Gender',y='Age')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we can see that spending score vs annual income there is cluster we can assume it as 5 clusters\npx.scatter(df,x='Annual Income (k$)',y='Spending Score (1-100)',color='Age')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Age_bins']=pd.qcut(df['Age'],q=3,labels=['young','middle_age','aged'])\npx.scatter(df,x='Annual Income (k$)',y='Spending Score (1-100)',color='Age_bins')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"px.box(df,x='Age_bins',y='Annual Income (k$)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(df['Age_bins'],df['Spending Score (1-100)'],hue=df['Gender'])\n#young people both men and female have high spending score than other as expected\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Gender']=df['Gender'].map({'Male':0,'Female':1})\ndf['Age_bins']=df['Age_bins'].map({'young':0,'middle_age':1,'aged':2})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(df.corr(),annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from  sklearn.cluster import KMeans,hierarchical,DBSCAN\nfrom sklearn.metrics  import silhouette_score\n\nkm_inertia=[]\nX=df[['Age','Spending Score (1-100)','Annual Income (k$)']]\nfor n in range(1,10):\n    km=KMeans(n_clusters=n,init='k-means++')\n    km.fit(X)\n    km_inertia.append(km.inertia_)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lineplot(x=np.arange(1,10),y=km_inertia,marker='o')#3 ,4,5 as k value","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"km=KMeans(3)\ndf['k=3']=km.fit_predict(X)\nkm=KMeans(4)\ndf['k=4']=km.fit_predict(X)\nkm=KMeans(5)\ndf['k=5']=km.fit_predict(X)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots(1,3,figsize=(25,5))\nsns.scatterplot(X['Annual Income (k$)'],X['Spending Score (1-100)'],hue=df['k=3'],ax=ax[0],palette=['red','green','blue'])\nsns.scatterplot(X['Annual Income (k$)'],X['Spending Score (1-100)'],hue=df['k=4'],ax=ax[1],palette=['red','green','blue','yellow'])\nsns.scatterplot(X['Annual Income (k$)'],X['Spending Score (1-100)'],hue=df['k=5'],ax=ax[2],palette=['red','green','blue','yellow','orange'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(silhouette_score(X,labels=df['k=3']))\nprint(silhouette_score(X,labels=df['k=4']))\nprint(silhouette_score(X,labels=df['k=5']))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from yellowbrick.cluster import SilhouetteVisualizer\nmodel = KMeans(5, random_state=42)\nvisualizer = SilhouetteVisualizer(model, colors='yellowbrick')\nvisualizer.fit(X)        # Fit the data to the visualizer\nvisualizer.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"#Hirerachical Clustering\nAdditive Clustering is bottom-up approach  ,here each datapoint is treated as seperate cluster in begining,and then twoclusters are merged based on \nthe minimum distance between those  two. it continous till single clusters is left"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.preprocessing import normalize\n\nX_scaled=normalize(X)\nX_scaled","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import scipy.cluster.hierarchy as shc\n\n\nplt.figure(figsize=(20, 6))  \nplt.title(\"Dendrograms\")  \ndend = shc.dendrogram(shc.linkage(X, method='ward'))\nplt.ylabel('EuclideanDistance')\nplt.xlabel('Clusters')\n\n#method ward groupsobs by reducing sum of squared distances of each observation from the average observation in a cluster. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import AgglomerativeClustering\n\ncluster=AgglomerativeClustering(n_clusters=5,linkage='ward')\nX['hire_cluster']=cluster.fit_predict(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots(1,2,figsize=(20,5))\nsns.scatterplot(X['Spending Score (1-100)'],X['Annual Income (k$)'],hue=X['hire_cluster'],palette=['green','blue','orange','black','red'],ax=ax[0]).set_title('Hirerachical')\n\nsns.scatterplot(X['Spending Score (1-100)'],X['Annual Income (k$)'],hue=df[\"k=5\"],palette=['green','blue','orange','black','red'],ax=ax[1]).set_title('KMEANs at 5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(silhouette_score(X,labels=X['hire_cluster']))#there is slight increase in score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import DBSCAN\n\nepsilon = np.arange(8,12.75,0.25) # eps values to be investigated\nno_samples = np.arange(3,10)\n\nsil_score=[]\nno_of_cluster=[]\nfor ep in epsilon:\n    for sample in no_samples:\n        db=DBSCAN(eps=ep,min_samples=sample)\n        db.fit(X)\n        no_of_cluster.append(len(np.unique(db.labels_)))\n        print((ep,sample),silhouette_score(X,db.labels_),len(np.unique(db.labels_)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#for 6 cluster the score is high for eps=12.5,min_sample=4\ndb=DBSCAN(eps=12.5,min_samples=4).fit(X)\nX['dbscan']=db.labels_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots(1,3,figsize=(25,5))\n\nsns.scatterplot(y=X['Spending Score (1-100)'],x=X['Annual Income (k$)'],hue=X['hire_cluster'],palette=['green','blue','orange','black','red'],ax=ax[0]).set_title('Hirerachical')\nsns.scatterplot(y=X['Spending Score (1-100)'],x=X['Annual Income (k$)'],hue=df[\"k=5\"],palette=['green','blue','orange','black','red'],ax=ax[1]).set_title('KMEANs at 5')\nsns.scatterplot(y=X['Spending Score (1-100)'],x=X['Annual Income (k$)'],hue=X[\"dbscan\"],palette=['black','green','yellow','blue','orange','red'],ax=ax[2]).set_title('DBSCAN')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on Spending score and AnnualIncome  cluster are formed both in hireeachical and Kmean\n1>low annual income(>40) and spending score than 40\n2>annaul  income(>40)and spending score <60\n3>high annual income(<60)and low spending score(>40)\n4>high income and spending score\n5>income between(30,60)and spending score (40,60)\n\nCustomer with high spending score and high income to be considered\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"----------------Thanks ---------------","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}