{"nbformat_minor":1,"cells":[{"cell_type":"markdown","metadata":{"_uuid":"32ffe50da42e7b2859676479bfd58970981ca547","_cell_guid":"43233258-f411-4372-8545-966de997838e"},"source":"<h1>TMDB <h1>\n    \n\n    - Part 1: Exploring and Preparing the data for analysis\n    - Part 2: Analyses of different genres\n    - Part 3: "},{"cell_type":"markdown","metadata":{"_uuid":"01090834384d4d38704f7fd71c67fd838ca95a0f","_cell_guid":"13ca24a5-5033-45e2-af40-059be883228a"},"source":"<h2> Part 1: Exploring and  preparing the data for analysis:  </h2> \n We start with the import of packages we will eventually need. Furthermore, we import the datasets and start with exploring and preparing the data for further analysis."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"5d7762e7e6a3a1948c2badf10cdd6ab594bb47fb","_cell_guid":"b38e4ac8-fc0f-4461-b711-528ae409ea62","collapsed":true},"outputs":[],"source":"import json\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nfrom sklearn.preprocessing import Imputer\nfrom sklearn.decomposition import PCA # Principal Component Analysis module\nfrom sklearn.cluster import KMeans # KMeans clustering \n\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\n\nmovies = pd.read_csv('../input/tmdb_5000_movies.csv')\ncredits = pd.read_csv('../input/tmdb_5000_credits.csv')\n\n\n"},{"cell_type":"markdown","metadata":{"_uuid":"06c444c86f78e4492cb641f21f31e95b8e734ce2","_cell_guid":"1b993148-9acb-46fa-b90e-26711e3d44e6","collapsed":true},"source":"Let's just start with some easy questions to get familiar with the data. So what does the data look like? We'll start with taking a look at the movies data frame."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"3521f7b1c828d6a8cecf4258d97c73506d4d8812","_cell_guid":"15feacf0-141d-4e52-bbe8-9d07a11b04f6","collapsed":true},"outputs":[],"source":"movies.head()"},{"cell_type":"markdown","metadata":{"_uuid":"aa96aa0c5994704fd29d1edb64104845ec2d4785","_cell_guid":"b5cc4329-42ed-42fd-9833-fe03a6f2b272"},"source":"The first thing we notice is that the columns are a bit in an awkward order to take a fine look at the data. A preferable first column of this data frame, would, for example, be the title of the movie and not the movie's budget. \n\nWe also notice that the columns 'genres', 'keywords', 'production_companies', 'production_countries' and 'spoken_languages' are of the dictionary type, so right now they are quite hard to read, but later on we will find a way to work with them.\n\nAmongst the numerical columns, there's a movie budget, a movie ID, popularity, revenue, runtime, a vote average and the amount of votes a movie has received. \n\nA good description of what the popularity variable should be telling us, is no where to be found, so it will be hard to use this column for our predictions later on. Besides the fact that the ID column is numerical, it is also not of interest for making predictions about, for example, the revenue of a movie. For now, we leave this data frame as it is and we'll take a quick look at the other one."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"2de14aa9cc14d5bae92e3aba68912f2d9cfafeb0","_cell_guid":"bc927a9a-af92-4aee-b46e-13daecdffd55","collapsed":true},"outputs":[],"source":"credits.head()"},{"cell_type":"markdown","metadata":{"_uuid":"8a78a61876e0725e8a3dc94433d61df430471f85","_cell_guid":"4143b5cf-b20e-4372-8baa-d4b2e9557619"},"source":"So this data frame has way fewer columns. The cast and crew might be interesting later on. Since this data frame contains only two extra columns, we'll try to merge it with the  movies data frame. If they are in the same order, we can just concatenate the data frames, so let's see if in both data frames every row is about the same movie:"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"6619bc14972f794ca6e6f2261017653c1abf8696","_cell_guid":"913fe37f-31e5-4d9d-842f-5976393aa486","collapsed":true},"outputs":[],"source":"(credits['title']==movies['title']).describe()"},{"cell_type":"markdown","metadata":{"_uuid":"b67bd4cf768334b8a4256b917b1245c810a433e5","_cell_guid":"12312760-98bc-4ccc-82a7-d67d9e889633"},"source":"This tells us that every row in the credits data base has the same movie title as the same row in the movies data base. To prevent getting duplicate columns, we'll remove the movie_id and title column from the credits data frame and concatenate them."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"8b216c0bac88f1031e5458f281ecf160bb57cf30","_cell_guid":"1e9918a0-a718-4b08-a879-c3361c677112","collapsed":true},"outputs":[],"source":"del credits['title']\ndel credits['movie_id']\nmovie_df = pd.concat([movies, credits], axis=1)"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"a3ee4a5a79724853c8e9ab69f286b0c25e2c7238","_cell_guid":"a6a266af-5287-4ec7-9026-da88ee0dc52f","collapsed":true},"outputs":[],"source":"movie_df.head()"},{"cell_type":"markdown","metadata":{"_uuid":"9d1fa3f87cc1b62065cc3f01a04d11772607ce2d","_cell_guid":"91da2366-53f3-46f0-9f74-201cf4ff4665"},"source":"The concatenation worked. However, the columns are a bit in an awkward order and columns like homepage aren't that interesting for us. We choose the interesting columns, put them in a nice order and create a new data frame"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"6e00b42d4c416011ec397ecf9a47df912c5129ee","_cell_guid":"74ced328-fd19-4c35-ab65-586003b0e3c3","collapsed":true},"outputs":[],"source":"newCols = ['id','title','release_date','popularity','vote_average','vote_count',\n           'budget','revenue','genres','keywords','cast','crew','tagline', 'runtime', 'production_companies', \n           'production_countries', 'status']\n\ndf2 = movie_df[newCols]\ndf2.head()"},{"cell_type":"markdown","metadata":{"_uuid":"f0f08b4b17c6f06b9935a9ec4840997fdf3368c0","_cell_guid":"964610ba-534f-4b32-a66d-ea456a8eacfe"},"source":"Let's explore our data frame a bit more in depth, let's take a look at our numerical columns."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"ca50ea6bfb20a83c0910e709115c7e6a8378e769","_cell_guid":"00fbecc8-3fbe-4f40-a0d6-25c8e578f8b7","collapsed":true},"outputs":[],"source":"df2.describe().round()"},{"cell_type":"markdown","metadata":{"_uuid":"7113974cc14d2da705bcf65ba9092a443ca5f314","_cell_guid":"ef5f3307-8765-4e74-a189-79c81d2b4109"},"source":"Note that runtime consists of a few empty values, before we can really work with our data frame, we need to solve this. We use an imputer for this:"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"f68f39cf7b1dc5f1307dec637f344a37ab29ff63","_cell_guid":"c46d807c-2b26-446d-8305-a8be44068965","collapsed":true},"outputs":[],"source":"my_imputer = Imputer()\n\ntemp=df2\nX2 = my_imputer.fit_transform(df2[['runtime']])\ndf2['runtime'] = X2\ndf2.describe().round()"},{"cell_type":"markdown","metadata":{"_uuid":"f40fd211c41af26b1e535b1365135699c0526e6b","_cell_guid":"ddc2b4f7-9e86-441f-9ac8-8728b7bb641e"},"source":"So now at least all the numerical columns are complete. Let's take a quick look at how all the variables are distributed."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"8db6f719580d0353838d672a6ee7a41feacde5b9","_cell_guid":"53ffb508-c08c-45db-8f26-97d3b04c5ea9","collapsed":true},"outputs":[],"source":"del df2['id']"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"f1b686a0c1e82f9242ea8266aecd541bd09764f4","_cell_guid":"bfb78386-25dd-4729-8905-f1721c3fdc55","collapsed":true},"outputs":[],"source":"#df2['vote_classes'] = pd.cut(df2['vote_average'],10, labels=[\"1\", \"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"])\ndf2['vote_classes'] = pd.cut(df2['vote_average'],4, labels=[\"low\", \"medium-low\",\"medium-high\",\"high\"])"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"2d155e1996a1f5ef1593a55529b7eb916343a7dd","_cell_guid":"2bc54a2a-2cfc-41db-9741-4867998af93b","collapsed":true},"outputs":[],"source":"fig = plt.figure(figsize = (10,15))\nax = fig.gca()\n\n#fig, axes = plt.subplots(nrows=3, ncols=2)\n#fig.tight_layout() # Or equivalently,  \"plt.tight_layout()\"\n\n#fig.subplots_adjust(hspace=0.1)\ndf2.hist(ax=ax)\n#df2.hist(ax=ax)"},{"cell_type":"markdown","metadata":{"_uuid":"e71d9b9e317ed5c1383289b0bd00f0589749e9cf","_cell_guid":"a6e5045a-6315-476a-aec1-e60bd0dbd99d"},"source":"Note that everything is quite skewed. We'll try getting more in depth into this later."},{"cell_type":"markdown","metadata":{"_uuid":"a2a7eadcb28f782698aa5137833b6d775287c5d4","_cell_guid":"b5db640e-b726-456c-bf24-fe75c6ec53c3","collapsed":true},"source":"<h2> Part 3: Analyze genres: <h2>"},{"cell_type":"markdown","metadata":{"_uuid":"fc43c19c83caa27d529a8e3b7aca2943d7ac9ea4","_cell_guid":"5d761fd4-ea8d-46bb-9494-8ded461964c6"},"source":"Now that we've got a good overview of the distribution of our numerical variables, let's take a closer look at our non-numerical variables. We choose to start with looking at the genres, since this variable has got the least variability, should be the most easy target for analysis.\n\nThe genres column contains variables of the string type, while they are in dictionaries. Moreover, the colomn is a json column. To analyse and understand the data it is necessary to change the type of the variable and filter the columns.\nDespite the fact that we already loaded our data for the exploration, we'll reload it here and make sure to load the json columns correctly. To do this, we made use of a few tricks found in another Kernel*"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"ae548a0a33350d637c8a605eaabf9a7b81358687","_cell_guid":"7cd6fbee-ea88-41e0-b78a-8f762e08dd09","collapsed":true},"outputs":[],"source":"def load_tmdb_movies(path):\n    df = pd.read_csv(path)\n    df['release_date'] = pd.to_datetime(df['release_date']).apply(lambda x: x.date())\n    json_columns = ['genres', 'keywords', 'production_countries', 'production_companies', 'spoken_languages']\n    for column in json_columns:\n        df[column] = df[column].apply(json.loads)\n    return df\n\ndef load_tmdb_credits(path):\n    df = pd.read_csv(path)\n    json_columns = ['cast', 'crew']\n    for column in json_columns:\n        df[column] = df[column].apply(json.loads)\n    return df\n\ndef pipe_flatten_names(keywords):\n    return '|'.join([x['name'] for x in keywords])\n\ncredits = load_tmdb_credits(\"../input/tmdb_5000_credits.csv\")\nmovies = load_tmdb_movies(\"../input/tmdb_5000_movies.csv\")\n\ndel credits['title']\ndf = pd.concat([movies, credits], axis=1)\n\ndf['genres'] = df['genres'].apply(pipe_flatten_names)\n\nliste_genres = set()\nfor s in df['genres'].str.split('|'):\n    liste_genres = set().union(s, liste_genres)\nliste_genres = list(liste_genres)\nliste_genres.remove('')"},{"cell_type":"markdown","metadata":{"_uuid":"208f1001665f51f1e2d68e634b18dd05853a5e89","_cell_guid":"f63087c2-8f91-474b-abb8-48163728f2fd"},"source":"\nSo what happened here is the following: first, we changed the type of the genres variable. Aferwards, we made use of the structure of the column and the *split()* function.  Because the genre always appears after the word *name*, we were able to filter out al the words after the word name and create a list of every genre that occurs in the genre-column.\n\nNow, let's reduce our data frame. To get more insight about the influence of a movie's genre, title, vote_average, release_data, runtime, budget and revenue are the most import important variables. We also add a column for every genre, containing only 1s and 0s whether a movie is of a specific genre or not.  "},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"546cd83ee1cd2551a24c2ac18995bacada87b617","_cell_guid":"063e1015-f0f7-4633-8869-43ace83a5e20","collapsed":true},"outputs":[],"source":"df_reduced = df[['title','vote_average','release_date','runtime','budget','revenue']].reset_index(drop=True)\n\nfor genre in liste_genres:\n    df_reduced[genre] = df['genres'].str.contains(genre).apply(lambda x:1 if x else 0)\ndf_reduced[:5]\n\ndf_reduced.head()"},{"cell_type":"markdown","metadata":{"_uuid":"e7c965e688f8a84716b585b787f5633894b14617","_cell_guid":"5e162a45-3bcb-4f6f-b9a6-3bc636e33da8"},"source":"Now that we've got an easy to work with data frame for the movie genres, we can take a look to the distribution of the genres by creating a pie chart*. "},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"95e084d16b6e4ad9671d49dcd27411608e481ca2","_cell_guid":"31407e63-2509-499e-8ffa-095c69523b65","collapsed":true},"outputs":[],"source":"plt.rc('font', weight='bold')\nf, ax = plt.subplots(figsize=(5,5))\ngenre_count = []\nfor genre in liste_genres:\n    genre_count.append([genre, df_reduced[genre].values.sum()])\ngenre_count.sort(key = lambda x:x[1], reverse = True)\nlabels, sizes = zip(*genre_count)\nlabels_selected = [n if v > sum(sizes) * 0.01 else '' for n, v in genre_count]\nax.pie(sizes, labels=labels_selected,\n      autopct = lambda x:'{:2.0f}%'.format(x) if x>1 else '',\n      shadow = False, startangle=0)\nax.axis('equal')\nplt.tight_layout()"},{"cell_type":"markdown","metadata":{"_uuid":"1748a70022387bb720dafced4697b287a8e3fa50","_cell_guid":"bad2ec31-e627-470a-83fb-47416b3a8c59"},"source":"This pie chart shows which genres are most common in the movies dataset.We find that drama movies are most common, followed by comedy. Afterwards, thriller and action movies are the most popular. Interestingly, half of the movies is from the top 5 genres. (51%). This suggest that the main genre of the most movies are drama, comedy, thriller, action. However, the top 5 most common genres could be seen as more general descriptions. For example, movies with the genre war might also be tagged as action movies or drama movies.\n\nNow let's try to get a more in depth view of the genres. In this cell we calculate the average votes, budget, and revenue for the different genres. we create a new data frame consisiting of every genre and the calculated averages. **"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"8746016cd7d4978250628d685a94581a810afaa2","_cell_guid":"ec92952c-0c80-452a-ba30-b63ec341d862","collapsed":true},"outputs":[],"source":"mean_per_genre = pd.DataFrame(liste_genres)\n\n#Mean votes average\nnewArray = []*len(liste_genres)\nfor genre in liste_genres:\n    newArray.append(df_reduced.groupby(genre, as_index=True)['vote_average'].mean())\nnewArray2 = []*len(liste_genres)\nfor i in range(len(liste_genres)):\n    newArray2.append(newArray[i][1])\n\nmean_per_genre['mean_votes_average']=newArray2\n\n#Mean budget\nnewArray = []*len(liste_genres)\nfor genre in liste_genres:\n    newArray.append(df_reduced.groupby(genre, as_index=True)['budget'].mean())\nnewArray2 = []*len(liste_genres)\nfor i in range(len(liste_genres)):\n    newArray2.append(newArray[i][1])\n\nmean_per_genre['mean_budget']=newArray2\n\n#Mean revenue \nnewArray = []*len(liste_genres)\nfor genre in liste_genres:\n    newArray.append(df_reduced.groupby(genre, as_index=True)['revenue'].mean())\nnewArray2 = []*len(liste_genres)\nfor i in range(len(liste_genres)):\n    newArray2.append(newArray[i][1])\n\nmean_per_genre['mean_revenue']=newArray2\n\nmean_per_genre['profit'] = mean_per_genre['mean_revenue']-mean_per_genre['mean_budget']\n\nmean_per_genre    "},{"cell_type":"markdown","metadata":{"_uuid":"acc63b2656394388bfff1c9808c96649061b53b2","_cell_guid":"1117897d-c80e-48c7-81d0-c75a485816d6"},"source":"Let's see which genres are the best scoring ones in each category:"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"66421e96bb5ae2ff033f92ac25c3e02f98239123","_cell_guid":"a694ce90-d488-4a6f-ab64-3b0364665098","collapsed":true},"outputs":[],"source":"mean_per_genre.sort_values('mean_votes_average', ascending=False).head()\n"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"5062908e8d8dc8c5f36549bfd1c2f81b40f2cea1","_cell_guid":"fa21b801-946a-4409-a527-20d807a77791","collapsed":true},"outputs":[],"source":"mean_per_genre.sort_values('mean_budget', ascending=False).head()"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"e248c007212ef8de6c1319626fadc3a517a4cd17","_cell_guid":"d349786b-ddf4-466d-8269-bc3bcf3e7280","collapsed":true},"outputs":[],"source":"mean_per_genre.sort_values('mean_revenue', ascending=False).head()"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"aa3b7bdc2dfe97a222974b8520694551108d15d7","_cell_guid":"1f555138-f013-4cba-9527-a5ccaaa221e3","collapsed":true},"outputs":[],"source":"mean_per_genre.sort_values('profit', ascending=False).head()"},{"cell_type":"markdown","metadata":{"_uuid":"e9035b148da480c59d07a34e1d61ab0080d6a345","_cell_guid":"29dfe3c0-d38a-4555-9e76-cd150440b453"},"source":"It's very interesting to see that the top 5 highest vote average consists of *History, War, Drama, Music* and *Foreign*, while none of these genres are in either one of the other three categories, which all have the same top 3: *Animation, Adventure, Fantasy*. On the one hand, this is easily explained, since budget and revenue should be closely elated and profit is directly derived from budget and revenue. However, we would have expected a higher correlation between the budget and the quality of a movie.\n\nTo go even more in depth, we want to analyse the averages per genre per year.  Therefore, we first extend the dataframe. with the year of release per movie.  Afterwards, we create a new dataframe which contains the average votes, average runtime, and average budget per release year and per genre. \n\nIn the last step in the cell below, only the rows that contain a 1 for genre are kept, so we create a data frame with only the specific genres. "},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"756fbc41e0f7b112e6b60e7b2495d17a3b4e6706","_cell_guid":"9fcdbaa0-1d9e-4a50-a07c-c58bc5e19746","collapsed":true},"outputs":[],"source":"from datetime import datetime\n\nt = df_reduced['release_date']\nt = pd.to_datetime(t)\nt = t.dt.year\ndf_reduced['release_year'] = t\n\ndf_list = []*len(liste_genres)\nfor genre in liste_genres:\n    df_list.append(df_reduced.groupby([genre,'release_year']).mean().reset_index())\n\ndf_per_genre = []*len(liste_genres)\nfor i in range(len(df_list)):\n    df_per_genre.append(df_list[i][df_list[i].ix[:,0] == 1])\n"},{"cell_type":"markdown","metadata":{"_uuid":"4747dbe0851e7d52e6430bdccc42abb8c117dad6","_cell_guid":"42932903-d22d-4533-a46f-67a0883f26e9"},"source":"Now we create tables which contain the average budget, average revenue, and average votes per year per genre. We start with creating a new table with the cloumns 1988 till 2017. Afterwards, the data for the different variables is implemented. **"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"203b23b2c8b1a0f415abdb1235833bcf3948675c","_cell_guid":"002c17d2-abf5-4b3b-a912-9deb8132d3cc","collapsed":true},"outputs":[],"source":"# Budget\ncolumns = range(1988,2018)\nbudget_genre = pd.DataFrame( columns = columns)\n\nfor genre in liste_genres:\n    temp=(df_per_genre[liste_genres.index(genre)].pivot_table(index = genre, columns = 'release_year', values = 'budget', aggfunc = np.mean))\n    temp = temp[temp.columns[-30:]].loc[1]\n    budget_genre.loc[liste_genres.index(genre)]=temp\nbudget_genre['genre']=liste_genres\n\n# Revenue \n\ncolumns = range(1988,2018)\nrevenue_genre = pd.DataFrame( columns = columns)\n\nfor genre in liste_genres:\n    temp=(df_per_genre[liste_genres.index(genre)].pivot_table(index = genre, columns = 'release_year', values = 'revenue', aggfunc = np.mean))\n    temp = temp[temp.columns[-30:]].loc[1]\n    revenue_genre.loc[liste_genres.index(genre)]=temp\nrevenue_genre['genre']=liste_genres\n\n# Vote average \ncolumns = range(1988,2018)\nvote_avg_genre = pd.DataFrame( columns = columns)\n\nfor genre in liste_genres:\n    temp=(df_per_genre[liste_genres.index(genre)].pivot_table(index = genre, columns = 'release_year', values = 'vote_average', aggfunc = np.mean))\n    temp = temp[temp.columns[-30:]].loc[1]\n    vote_avg_genre.loc[liste_genres.index(genre)]=temp\nvote_avg_genre['genre']=liste_genres\n\n#vote_avg_genre.index = vote_avg_genre['genre']"},{"cell_type":"markdown","metadata":{"_uuid":"2fa64e74ad476f3b29cde956a6f7cc1cb02c5a6a","_cell_guid":"95b4fcf2-6e96-40d1-b3c7-ec8d057da90e"},"source":"Let's take a look at the data frames we generated."},{"cell_type":"markdown","metadata":{"_uuid":"7cb80cae8686fa75fc30d59ec4c5c883f6b6a14f","_cell_guid":"04be61ef-4f51-495f-bdd1-6c50eddb6999"},"source":"### Mean budget per genre per year:"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"7b20331d3843949bfa4542a3eae492782a57c8ae","_cell_guid":"782c6822-8bca-472d-9c4e-a89820f35719","collapsed":true},"outputs":[],"source":"budget_genre.index = budget_genre['genre']\nbudget_genre"},{"cell_type":"markdown","metadata":{"_uuid":"e445f6ebfb717b62b6e03a154a2a721de5acd07a","_cell_guid":"8ae8f5ab-880b-4996-bc66-daf724490fbe"},"source":"### Mean revenue per genre per year:"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"deda1f2c4f05904804a1f4947c3fa4fb51ec586e","_cell_guid":"411df1fc-e087-4499-b508-02fc1ac35dce","collapsed":true},"outputs":[],"source":"revenue_genre.index = revenue_genre['genre']\nrevenue_genre\n"},{"cell_type":"markdown","metadata":{"_uuid":"3ae4afb0a1bc9a1bc814b90a98283784b1d2df9b","_cell_guid":"d55aaa9d-7f6d-47d8-ad3b-91de7fe62061"},"source":"### Mean vote average per genre per year:"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"9509d23876cfa146e060abc2d4fca507e41994c1","_cell_guid":"c51a50d4-4ec2-4f00-be0f-d59b41a46cc6","collapsed":true},"outputs":[],"source":"vote_avg_genre.index = vote_avg_genre['genre']\nvote_avg_genre"},{"cell_type":"markdown","metadata":{"_uuid":"351d48695d117a084b202ae30e565f610c1a2ff5","_cell_guid":"691b10e6-b9a5-4027-93d5-6ac2f867d653"},"source":"We can create more insight in these tables by making heatmaps**. "},{"cell_type":"markdown","metadata":{"_uuid":"ee4d690a6b738739892656d716a3421f020d6b3e","_cell_guid":"5af29e71-fc21-41de-a451-6819e68ed47e"},"source":"### Budget:"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"a63481acf40045e027cb78c035f0f72d74ab692d","_cell_guid":"0a4a4992-3f40-404b-8167-2d162494d2ab","collapsed":true},"outputs":[],"source":"fig, ax = plt.subplots(figsize=(9,9))\ncmap = sns.cubehelix_palette(start = 1.5, rot = 1.5, as_cmap = True)\nsns.heatmap(budget_genre.ix[:,0:30], xticklabels=3, cmap=cmap, linewidths=0.05)"},{"cell_type":"markdown","metadata":{"_uuid":"10d30ac9fc3aa47726b1f66584a29b55544e107d","_cell_guid":"109e0b02-053a-47e2-99ca-b7ccc880b3cb"},"source":"The heatmap shows that in general, movies had  an increasing budget over the years. Especially the genres Fantasy, advernture, family, action, science fiction, and animation. The heatmap also shows that Western movies had an extremely high budget in 2013. This could mean that a costly movie is produced in 2013 which has great influence on the average.  We might later on remove this possible outlier, to get a better overview of the distribution of the rest of the movies."},{"cell_type":"markdown","metadata":{"_uuid":"bbb6ee57e7b0dc097844ab3da37aa12ce1726b51","_cell_guid":"f39845d7-9268-416d-8ff5-7cf085525c5d"},"source":"## Revenue:"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"fa901321d89c0ac0507b0c966398ff0a943547ae","_cell_guid":"2cca70eb-fca1-482c-adba-a5f05cfe25db","collapsed":true},"outputs":[],"source":"\nfig, ax = plt.subplots(figsize=(9,9))\ncmap = sns.cubehelix_palette(start = 1.5, rot = 1.5, as_cmap = True)\nsns.heatmap(revenue_genre.ix[:,0:30], xticklabels=3, cmap=cmap, linewidths=0.05)"},{"cell_type":"markdown","metadata":{"_uuid":"2c863e7b471e25bd0c154a22244ec512922a22dc","_cell_guid":"5e2e1822-65ef-4c2e-a88e-2aa6ebecb1ec"},"source":"This heatmap shows the average revenue of genres from 1988 till 2017. The most clear increase of average is in the genres fantasy, adventure, family, action, science fiction. Interestingly, the graph shows that the revenues of the genre animation are colored black in 1994. This is surprisingly because there are no black colored revenues in the graph and in general revenues are lower in 1994 than movies that are produced in later years.  A reason for this could be that there are only a few movies in the genre animation in 1994 and that those movies did extremely well.  The previous heatmap does not show an above average budget for animation movies in 1994. \n"},{"cell_type":"markdown","metadata":{"_uuid":"1023faa9506389ebb3fe40712454787377223caf","_cell_guid":"ad3faf78-0c6c-4a2f-a3a5-dab0af33cb83"},"source":"## Vote average:"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"465ce8c77199e58d25da58cfc1a03043d1eb0111","_cell_guid":"f32c90a3-5775-4e13-8ef4-d04f04f86d06","collapsed":true},"outputs":[],"source":"fig, ax = plt.subplots(figsize=(9,9))\ncmap = sns.cubehelix_palette(start = 1.5, rot = 1.5, as_cmap = True)\nsns.heatmap(vote_avg_genre.ix[:,0:30], xticklabels=3, cmap=cmap, linewidths=0.05)"},{"cell_type":"markdown","metadata":{"_uuid":"b74ef8bb3eac54e027842ec0f207e0552bbccc17","_cell_guid":"3d3e3330-510d-4047-914a-e03c6d3c13dd"},"source":"This heatmap is way darker than the previous two, which suggests that the average is relatively higher than in the other two categories. Most of the categories seem to be getting somewhere around a 6 out of 10 score. Especially notable is the fact that there are very few green or orange colored cells, which should mean that the most movies are on average just a nice watch."},{"cell_type":"markdown","metadata":{"_uuid":"3af5e342bbb6f1414f635f7c7efbcd36eeb4cad4","_cell_guid":"0e5818f8-e11a-4607-9f42-518e734989a1"},"source":"As said before, we would like to remove the very high budget input from the Western genre, to make the heatmap less skewed. Let's see what happens:"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"0f8f0acda5902cc103cefab3be2e739703f50cd0","_cell_guid":"2fbe958c-f9a1-4b25-99af-635ff92dedde","collapsed":true},"outputs":[],"source":"temp = budget_genre\ntemp[2013]=temp[2013].replace(2.550000e+08, 0)"},{"cell_type":"markdown","metadata":{"_uuid":"51b321a729d054067ce40e054d63ea18829074d9","_cell_guid":"d5a4f57b-0db6-4c89-9b37-e15b8329c3ea"},"source":"This heatmap obviously shows that Fantasy Adventure, Science Fiction, and Animation have on average the highest budget. It is also clear that movies had an increasing budget over the years. However, there are a few exceptions. For example  Western movies had an above average budget in 2004 and history in 2000. This might be an effect of individual movies with a high budget. "},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"1ecc9a386a0e4eaf29272967cb17103bc5905973","_cell_guid":"60bcb993-b92e-41ea-bf6d-31e7f764ef08","collapsed":true},"outputs":[],"source":"fig, ax = plt.subplots(figsize=(9,9))\ncmap = sns.cubehelix_palette(start = 1.5, rot = 1.5, as_cmap = True)\nsns.heatmap(temp.ix[:,0:30], xticklabels=3, cmap=cmap, linewidths=0.05)"},{"cell_type":"markdown","metadata":{"_uuid":"a3c07f0d787c6d672eae186109212e4540255ec7","_cell_guid":"89bb8592-4105-476f-a27c-592f9ac57d33"},"source":"## It might also be nice to create a visualisation on how many times different genres are connected with each other. So which genres occur the most together in the same movie, but this is something for later on."},{"cell_type":"markdown","metadata":{"_uuid":"297a2803d8052f132c7602c409dfa94d4b7a1181","_cell_guid":"41d64add-2063-498c-86a1-fcf5b764b2eb"},"source":"# Numerical Analysis"},{"cell_type":"markdown","metadata":{"_uuid":"42d4706706074e01f701dd7bbd3cbb445ed80f40","_cell_guid":"caf9707d-92b4-4b2c-aa12-f44672294aee"},"source":"So let's take a closer look at our the numerical columns in our data frame.  Let's start by creating a data frame containing only numbered columns."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"4e035069ec164d109e1ce0629de4eb4cb3203311","_cell_guid":"4f1e894e-f944-4439-83bf-69ed57797cee","collapsed":true},"outputs":[],"source":"num_list = ['budget','popularity','revenue','runtime','vote_average','vote_count']\nmovie_num = df2[num_list]\nmovie_num.head()"},{"cell_type":"markdown","metadata":{"_uuid":"d1978dd98195a5b9351c91a79f7e11f7d6112381","_cell_guid":"84decbd1-5abc-499b-9f43-30d403b1135d"},"source":"Let's take a look at how everything is correlated:"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"a1471c267df868039902a1b3c33392c08b040241","_cell_guid":"1baa319a-c910-4827-9e6e-1c1f173a0ce4","collapsed":true},"outputs":[],"source":"f, ax = plt.subplots(figsize=(12,10))\nplt.title('Pearson Correlation of Movie Features')\nsns.heatmap(movie_num.astype(float).corr(), linewidths=0.25, vmax=1.0, square=True,\n           cmap=\"YlGnBu\", linecolor='black', annot=True)"},{"cell_type":"markdown","metadata":{"_uuid":"36bd4ce2794254ec9ecb2573207eb6e9f63c0eab","_cell_guid":"1de6b660-fc0a-4e33-8867-190879a2a168"},"source":"We see quite a few dark/blue squares. These are the higher correlated variables. To be able to make predictions about certain movies later on, this might be some important knowledge."},{"cell_type":"markdown","metadata":{"_uuid":"7ef660585251b97777b885e9accb051ce203aead","_cell_guid":"a3637435-bcf5-47f3-be79-a547ab6f9006"},"source":"# Comparing different regression techniques\n\nWe want to compare a few regression techniques to help us in making predictions. We'll use linear regression and random forest, as treated in the lectures.\nWe start by recreating our numerical data frame."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"740669c7dad802bf5a99e5878d84bb2eec5e3b2c","_cell_guid":"90150996-8c2d-4440-8728-efacb0c50ba6","collapsed":true},"outputs":[],"source":"num_list = ['budget','popularity','revenue','runtime','vote_average','vote_count']\nmovie_num = df2[num_list]\nmovie_num.head()"},{"cell_type":"markdown","metadata":{"_uuid":"e18c5a4cc53e6789c0e9b2dcdce131724d278139","_cell_guid":"0ed09b60-c3b8-4b69-b50c-a5af5972d4ff"},"source":"We want the vote_average to be our target values, budget, popularity, revenue, runtime and vote_count are trainng values."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"96dc062dc837d040e7191147c0a1f07922b7febe","_cell_guid":"611acbfd-0a5b-440d-a293-b41061844326","collapsed":true},"outputs":[],"source":"training_list = ['budget','popularity','revenue','runtime','vote_count']\ntraining = movie_num[training_list]\ntarget = movie_num['vote_average']"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"bff4d76b5c949253f3d419a3c1a066d9577d2228","_cell_guid":"c29dbcd7-7908-4b01-9951-b82ca5777b3b","collapsed":true},"outputs":[],"source":"X = training.values\ny = target.values"},{"cell_type":"markdown","metadata":{"_uuid":"56408e9d30f8d9d38b231a4c191c75185c82507c","_cell_guid":"381a9a8c-cecf-4620-98a1-d2c6390d9e93"},"source":"We split our data in a train and a test frame."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"b6f6afeebc4a4a73b3f3d1ddfcdd2584c59da7cb","_cell_guid":"c99549c4-c0d4-4e22-9484-0b56d857849b","collapsed":true},"outputs":[],"source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.33, random_state=42)"},{"cell_type":"markdown","metadata":{"_uuid":"5252f15a6c80534d874ee630d2c345964a49d31a","_cell_guid":"e345b98b-9b41-4c5a-9ace-aa251e6ba745"},"source":"Now let's train a linear regression model and plot the results: \\***"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"e0efdbc203a7550e342f8a19cf5a239e48b454cb","_cell_guid":"70d2eabe-c475-4aa8-9110-7fe49c8cd6ea","collapsed":true},"outputs":[],"source":"from sklearn import linear_model\n# Create linear regression object\nregr = linear_model.LinearRegression()\n\n# Train the model using the training sets\nregr.fit(X_train, y_train)\n\n# Make predictions using the testing set\ny_pred_lr = regr.predict(X_test)"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"2fcbd59362c59f920e5de810d5b9c883defa4978","_cell_guid":"3e1a7b80-261d-44f3-87af-2fb58caf160f","collapsed":true},"outputs":[],"source":"f = plt.figure(figsize=(10,5))\nplt.scatter(X_test[:,1], y_test, s=50,label=\"Real vote_average\");\nplt.scatter(X_test[:,1], y_pred_lr,s=100, c='r',label=\"Predicted vote_average\");\nplt.ylabel(\"vote_average\");\nplt.legend(loc=2);"},{"cell_type":"markdown","metadata":{"_uuid":"ab2df75cab5f5f05a588ca9683f6166a5d9542e1","_cell_guid":"dac2c70f-1131-4f41-9e48-586a4854a4fe"},"source":"Now let's see what happens if we use a random forest regression model:"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"2cf4f9a90c14990b96e2bd336f086256c5360455","_cell_guid":"0419256f-5a47-41f0-a89e-426170d0e902","collapsed":true},"outputs":[],"source":"from sklearn.ensemble import RandomForestRegressor\n# Create linear regression object\nrf = RandomForestRegressor(1)\n\n# Train the model using the training sets\nrf.fit(X_train, y_train)\n\n# Make predictions using the testing set\ny_pred_rf = rf.predict(X_test)"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"57bd79fa03dd9dfb632d365d5b930d5caa17ecc9","_cell_guid":"a8a0aaae-139c-4eea-a8c3-1006e0816421","collapsed":true},"outputs":[],"source":"f = plt.figure(figsize=(10,5))\nplt.scatter(X_test[:,1], y_test, s=50,label=\"Real vote_average\");\nplt.scatter(X_test[:,1], y_pred_rf,s=100, c='r',label=\"Predited vote_average\");\nplt.ylabel(\"vote_average\");\nplt.legend(loc=2);"},{"cell_type":"markdown","metadata":{"_uuid":"a9899976789eef4b1f2a8d5da8a37aa6dec7fa75","_cell_guid":"b631d6e3-f168-4e91-b0a4-461ea704654d"},"source":"And let's compare them:"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"065bd96f247140e09b10b72693c4454dfa32beaa","_cell_guid":"dbba4676-9c20-4a2d-b00b-1e920ad5aa7f","collapsed":true},"outputs":[],"source":"from sklearn.metrics import mean_squared_error\n\nerror_lr = mean_squared_error(y_test,y_pred_lr)\nerror_rf = mean_squared_error(y_test,y_pred_rf)\n\nprint(error_lr)\nprint(error_rf)"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"81b2a25df53f10774fa8e6db2894326a0326317f","_cell_guid":"d65f8cb0-cbb7-48df-9cab-74b2fbafe3c8","collapsed":true},"outputs":[],"source":"f = plt.figure(figsize=(10,5))\nplt.bar(range(2),[error_lr,error_rf])\nplt.xlabel(\"Classifiers\");\nplt.ylabel(\"Mean Squared Error of the vote_average\");\nplt.xticks(range(2),['Linear Regression','Random Forest'])\nplt.legend(loc=2);"},{"cell_type":"markdown","metadata":{"_uuid":"a2d0430f9e5d4f35bd83159677882d375da79c3b","_cell_guid":"4bc3351f-2643-46c3-a487-f48265158138"},"source":"So the mean squared error for the random forest regression is a little higher than for the linear regression, but both estimators seem to be very decent."},{"cell_type":"markdown","metadata":{"_uuid":"e859f5e09fd9f31afbc96ec11b5c80e2cde684b2","_cell_guid":"0345fa3b-2b80-449c-a57b-7d03dab371ab"},"source":"\\* https://www.kaggle.com/fabiendaniel/categorizing-actors-hands-on-plotly <br>\n\\** https://www.kaggle.com/diegoinacio/imdb-genre-based-analysis <br>\n\\*** introduction to data science, week 4, Comparison of Regression Techniques on House prediction prices.ipynb"},{"cell_type":"markdown","metadata":{"_uuid":"8adda38e3f5ef0e5ac7818188571f5e1e031a749","_cell_guid":"165aee9c-ee64-4ed8-8ed8-ed22aa501071"},"source":"**ROBBERT**"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"cc060124593a189631ae1184286841213e531254","scrolled":true,"_cell_guid":"41529ef2-a905-4f11-981a-2e90ba1cece6","collapsed":true},"outputs":[],"source":"\nimport nltk\nfrom nltk.corpus import wordnet\nPS = nltk.stem.PorterStemmer()\n\nimport plotly.offline as pyo\npyo.init_notebook_mode()\nfrom plotly.graph_objs import *\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode,iplot\ninit_notebook_mode(connected=True)"},{"cell_type":"markdown","metadata":{"_uuid":"36546b3796bc88c5e21b3dbe3e27081ae34d6457","_cell_guid":"ce37b4c3-688b-43ab-9ad6-285fd01dafad"},"source":"# Country Analysis<br>\nWe are interested in the following question: What countries produce the most movies?[](http://)\n"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"63c4d4b76e4fda881a452416c4edc9a1d1adca39","_cell_guid":"d96f150b-1c24-48ee-98db-cfe1cdb70aed","collapsed":true},"outputs":[],"source":"def load_tmdb_movies(path):\n    df = pd.read_csv(path)\n    df['release_date'] = pd.to_datetime(df['release_date']).apply(lambda x: x.date())\n    json_columns = ['genres', 'keywords', 'production_countries', 'production_companies', 'spoken_languages']\n    for column in json_columns:\n        df[column] = df[column].apply(json.loads)\n    return df\n#____________________________\ndef load_tmdb_credits(path):\n    df = pd.read_csv(path)\n    json_columns = ['cast', 'crew']\n    for column in json_columns:\n        df[column] = df[column].apply(json.loads)\n    return df\n#_______________________________________\ndef safe_access(container, index_values):\n    result = container\n    try:\n        for idx in index_values:\n            result = result[idx]\n        return result\n    except IndexError or KeyError:\n        return pd.np.nan\n#_______________________________________\nLOST_COLUMNS = [\n    'actor_1_facebook_likes',\n    'actor_2_facebook_likes',\n    'actor_3_facebook_likes',\n    'aspect_ratio',\n    'cast_total_facebook_likes',\n    'color',\n    'content_rating',\n    'director_facebook_likes',\n    'facenumber_in_poster',\n    'movie_facebook_likes',\n    'movie_imdb_link',\n    'num_critic_for_reviews',\n    'num_user_for_reviews']\n#_______________________________________\nTMDB_TO_IMDB_SIMPLE_EQUIVALENCIES = {\n    'budget': 'budget',\n    'genres': 'genres',\n    'revenue': 'revenue',\n    'title': 'movie_title',\n    'runtime': 'duration',\n    'original_language': 'language',  \n    'keywords': 'plot_keywords',\n    'vote_count': 'num_voted_users'}\n#_______________________________________     \nIMDB_COLUMNS_TO_REMAP = {'imdb_score': 'vote_average'}\n#_______________________________________\ndef get_director(crew_data):\n    directors = [x['name'] for x in crew_data if x['job'] == 'Director']\n    return safe_access(directors, [0])\n#_______________________________________\ndef pipe_flatten_names(keywords):\n    return '|'.join([x['name'] for x in keywords])\n#_______________________________________\ndef convert_to_original_format(movies, credits):\n    tmdb_movies = movies.copy()\n    tmdb_movies.rename(columns=TMDB_TO_IMDB_SIMPLE_EQUIVALENCIES, inplace=True)\n    tmdb_movies['title_year'] = pd.to_datetime(tmdb_movies['release_date']).apply(lambda x: x.year)\n    # I'm assuming that the first production country is equivalent, but have not been able to validate this\n    tmdb_movies['country'] = tmdb_movies['production_countries'].apply(lambda x: safe_access(x, [0, 'name']))\n    tmdb_movies['language'] = tmdb_movies['spoken_languages'].apply(lambda x: safe_access(x, [0, 'name']))\n    tmdb_movies['director_name'] = credits['crew'].apply(get_director)\n    tmdb_movies['actor_1_name'] = credits['cast'].apply(lambda x: safe_access(x, [1, 'name']))\n    tmdb_movies['actor_2_name'] = credits['cast'].apply(lambda x: safe_access(x, [2, 'name']))\n    tmdb_movies['actor_3_name'] = credits['cast'].apply(lambda x: safe_access(x, [3, 'name']))\n    tmdb_movies['genres'] = tmdb_movies['genres'].apply(pipe_flatten_names)\n    tmdb_movies['plot_keywords'] = tmdb_movies['plot_keywords'].apply(pipe_flatten_names)\n    return tmdb_movies"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"4e09e642efa118cb54a1213eed20ea746b4bce80","_cell_guid":"7be7b98d-b975-44a3-8a6f-3d117ffc9315","collapsed":true},"outputs":[],"source":"#______________\n# the packages\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode,iplot\ninit_notebook_mode(connected=True)\n#___________________\n# and the dataframe\ncredits = load_tmdb_credits(\"../input/tmdb_5000_credits.csv\")\nmovies = load_tmdb_movies(\"../input/tmdb_5000_movies.csv\")\ndf = convert_to_original_format(movies, credits)\n#___________________________\n# countries in the dataframe\ndf['country'].unique()\n"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"256e295f2360bac89c1d4418a1e64481931eac81","_cell_guid":"e9601bef-1f99-46fe-acd8-98b7d6bc49ed","collapsed":true},"outputs":[],"source":"df['country'].describe()"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"9672c7b3a591abeabc5874b4c7896ed1a9f1d63b","_cell_guid":"4d4166d0-2b6b-4b41-aae1-63b63e80b09e","collapsed":true},"outputs":[],"source":"#Extract number of films per country\ndf_countries = df['title_year'].groupby(df['country']).count()\ndf_countries = df_countries.reset_index()\ndf_countries.rename(columns ={'title_year':'count'}, inplace = True)\ndf_countries = df_countries.sort_values('count', ascending = False)\ndf_countries.reset_index(drop=True, inplace = True)\n\n#Create pie chart with number of films per country\nsns.set_context(\"poster\", font_scale=0.6)\nplt.rc('font', weight='bold')\nf, ax = plt.subplots(figsize=(11, 6))\nlabels = [s[0] if s[1] > 80 else ' ' \n          for index, s in  df_countries[['country', 'count']].iterrows()]\nsizes  = df_countries['count'].values\nexplode = [0.0 if sizes[i] < 100 else 0.0 for i in range(len(df_countries))]\nax.pie(sizes, explode = explode, labels = labels,\n       autopct = lambda x:'{:1.0f}%'.format(x) if x > 1 else '',\n       shadow=False, startangle=45)\nax.axis('equal')\nax.set_title('% of films per country',\n             bbox={'facecolor':'k', 'pad':5},color='w', fontsize=16);"},{"cell_type":"markdown","metadata":{"_uuid":"6664b12e1c578408756859b2bab0a61931e63144","_cell_guid":"fe49b26c-b652-4b19-92d0-7f8d14f44806"},"source":"As one would have expected, most of the movies were created in the united states."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"073fc33e67ffdb1b1813df0809ac90b6dc0b1e6e","_cell_guid":"b0b9baae-5f10-4971-a709-683ec96753ff","collapsed":true},"outputs":[],"source":"#Create a chloropleth map\ndata = dict(type='choropleth',\nlocations = df_countries['country'],\nlocationmode = 'country names', z = df_countries['count'],\ntext = df_countries['country'], colorbar = {'title':'Films nb.'},\ncolorscale=[[0, 'rgb(224,255,255)'],\n            [0.01, 'rgb(166,206,227)'], [0.02, 'rgb(31,120,180)'],\n            [0.03, 'rgb(178,223,138)'], [0.05, 'rgb(51,160,44)'],\n            [0.10, 'rgb(251,154,153)'], [0.20, 'rgb(255,255,0)'],\n            [1, 'rgb(227,26,28)']],    \nreversescale = False)\n\nlayout = dict(title='Number of films in the TMDB database',\ngeo = dict(showframe = True, projection={'type':'Mercator'}))\n\nchoromap = go.Figure(data = [data], layout = layout)\niplot(choromap, validate=False)"},{"cell_type":"markdown","metadata":{"_uuid":"bc85503c7e993e2f5f5a4f629c6c927446d5e4df","_cell_guid":"a6534657-ea3c-43dc-b2d9-d807f0f490ea"},"source":"# Keyword Analysis\n### Part 1: Cleaning the data\nFor the analysis of the keywords, we will be using the same method we applied in the genre analysis. However, before it is possible for us to analyze the data, it needs a lot of cleaning. To clean the data, we use the same method as applied in this notebook: https://www.kaggle.com/fabiendaniel/film-recommendation-engine."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"223e550acdb4ff829e87a22d3ec436c5d973d4f7","_cell_guid":"f2fe3cb8-a42b-42b7-a97b-823bfe9764d3","collapsed":true},"outputs":[],"source":"def load_tmdb_movies(path):\n    df = pd.read_csv(path)\n    df['release_date'] = pd.to_datetime(df['release_date']).apply(lambda x: x.date())\n    json_columns = ['genres', 'keywords', 'production_countries', 'production_companies', 'spoken_languages']\n    for column in json_columns:\n        df[column] = df[column].apply(json.loads)\n    return df\n\ndef load_tmdb_credits(path):\n    df = pd.read_csv(path)\n    json_columns = ['cast', 'crew']\n    for column in json_columns:\n        df[column] = df[column].apply(json.loads)\n    return df\n\ndef pipe_flatten_names(keywords):\n    return '|'.join([x['name'] for x in keywords])\n\ncredits = load_tmdb_credits(\"../input/tmdb_5000_credits.csv\")\nmovies = load_tmdb_movies(\"../input/tmdb_5000_movies.csv\")\n\ndel credits['title']\ndf = pd.concat([movies, credits], axis=1)\n\ndf['keywords'] = df['keywords'].apply(pipe_flatten_names)\n\nliste_keywords = set()\nfor s in df['keywords'].str.split('|'):\n    liste_keywords = set().union(s, liste_keywords)\nliste_keywords = list(liste_keywords)\nliste_keywords.remove('')"},{"cell_type":"markdown","metadata":{"_uuid":"e745ca10bcc6ee49d28d34c6cb39b3fea844189b","_cell_guid":"0bb12ea5-040f-4d10-8214-c1b2308e137c"},"source":"We are interested in which keywords occur the most in our dataset. We use the following function to count them.\n"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"c62a5f99ecb3790407ab8fe8a8671c0270fd8a8c","_cell_guid":"84bbe208-5443-479a-b08c-22a802929182","collapsed":true},"outputs":[],"source":"def count_word(df, ref_col, liste):\n    keyword_count = dict()\n    for s in liste: keyword_count[s] = 0\n    for liste_keywords in df[ref_col].str.split('|'):        \n        if type(liste_keywords) == float and pd.isnull(liste_keywords): continue        \n        for s in [s for s in liste_keywords if s in liste]: \n            if pd.notnull(s): keyword_count[s] += 1\n    #______________________________________________________________________\n    # convert the dictionary in a list to sort the keywords by frequency\n    keyword_occurences = []\n    for k,v in keyword_count.items():\n        keyword_occurences.append([k,v])\n    keyword_occurences.sort(key = lambda x:x[1], reverse = True)\n    return keyword_occurences, keyword_count\n\nkeyword_occurences, dum = count_word(df, 'keywords', liste_keywords)\nkeyword_occurences[:5]"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"4c6b063492ea28c84c138062bb421bc15df7a658","_cell_guid":"3437bed3-3a62-4b0a-aed3-2b61b76239d3","collapsed":true},"outputs":[],"source":"# Collect the keywords\ndef keywords_inventory(dataframe, colonne = 'keywords'):\n    PS = nltk.stem.PorterStemmer()\n    keywords_roots  = dict()  # collect the words / root\n    keywords_select = dict()  # association: root <-> keyword\n    category_keys = []\n    icount = 0\n    for s in dataframe[colonne]:\n        if pd.isnull(s): continue\n        for t in s.split('|'):\n            t = t.lower() ; racine = PS.stem(t)\n            if racine in keywords_roots:                \n                keywords_roots[racine].add(t)\n            else:\n                keywords_roots[racine] = {t}\n    \n    for s in keywords_roots.keys():\n        if len(keywords_roots[s]) > 1:  \n            min_length = 1000\n            for k in keywords_roots[s]:\n                if len(k) < min_length:\n                    clef = k ; min_length = len(k)            \n            category_keys.append(clef)\n            keywords_select[s] = clef\n        else:\n            category_keys.append(list(keywords_roots[s])[0])\n            keywords_select[s] = list(keywords_roots[s])[0]\n                   \n    print(\"Nb of keywords in variable '{}': {}\".format(colonne,len(category_keys)))\n    return category_keys, keywords_roots, keywords_select\n\nkeywords, keywords_roots, keywords_select = keywords_inventory(df, colonne = 'keywords')"},{"cell_type":"markdown","metadata":{"_uuid":"b451f9c65cd0153124d183dbdd5bcbceea51a619","_cell_guid":"4a8e7f23-45de-4749-9288-2ade435cb238"},"source":"Of course, different movies use different keywords for their movies. A problem is, that often a lot of those keywords are the same, although they are communicated in a different form by the different movie producers. The function above inventorizes the different keywords using nltk. The package identifies the 'roots' of different words and groups the different words according to its root. Then, we can replace the words that have a common root with their root. In this way, similar words that are phrased differently are assigned a common 'root'.\n\nWhen executing the function, it also shows the amount of different keywords, 9474 in our case."},{"cell_type":"markdown","metadata":{"_uuid":"522b0d66817a054553ebf2f72dc933d43056c0e5","_cell_guid":"340e9911-7514-4390-8659-a705d547ca13"},"source":"### Roots"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"ef1423e674a295d736ec30267eeb569ef2cea254","_cell_guid":"84a307e6-1726-4af2-bf7c-fe84280378d4","collapsed":true},"outputs":[],"source":"# Plot of a sample of keywords that appear in close varieties\n# Different words with similar roots\nicount = 0\nfor s in keywords_roots.keys():\n    if len(keywords_roots[s]) > 1: \n        icount += 1\n        if icount < 15: print(icount, keywords_roots[s], len(keywords_roots[s]))"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"b2db94737626b158db678e50792aa9701276785c","_cell_guid":"47e3cdee-3d90-44dc-bc7f-ceb45e47c860","collapsed":true},"outputs":[],"source":"#Each different form of a word will be replaced by their roots\n\ndef remplacement_df_keywords(df, dico_remplacement, roots = False):\n    df_new = df.copy(deep = True)\n    for index, row in df_new.iterrows():\n        chaine = row['keywords']\n        if pd.isnull(chaine): continue\n        nouvelle_liste = []\n        for s in chaine.split('|'): \n            clef = PS.stem(s) if roots else s\n            if clef in dico_remplacement.keys():\n                nouvelle_liste.append(dico_remplacement[clef])\n            else:\n                nouvelle_liste.append(s)       \n        df_new.set_value(index, 'keywords', '|'.join(nouvelle_liste)) \n    return df_new\n\n#The cleaned keywords will be stored in a new dataframe\ndf_keywords_cleaned = remplacement_df_keywords(df, keywords_select, roots = True)"},{"cell_type":"markdown","metadata":{"_uuid":"4973a151f05cf82162f5aec6cccdc68b34f9ead8","_cell_guid":"6efbdca3-241a-4b01-8599-f9cca12d4ab9"},"source":"### Synonyms\nWe use the nltk package to get rid of synonyms. "},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"2e36d5c673be9fea9bc3d683ba85830b627fed54","_cell_guid":"c58220ac-8aae-4729-9bfb-f865a662e331","collapsed":true},"outputs":[],"source":"#The function below takes a word as a parameter and returns all of the synonyms of that word according to the nltk package.\ndef get_synonymes(word):\n    lemma = set()\n    for ss in wordnet.synsets(word):\n        for w in ss.lemma_names():\n            # We just get the 'nouns':\n            index = ss.name().find('.')+1\n            if ss.name()[index] == 'n': lemma.add(w.lower().replace('_',' '))\n    return lemma  \n#__________________________________________________________________________\ndef test_keyword(mot, key_count, threshold):\n    return (False , True)[key_count.get(mot, 0) >= threshold]\n\n#__________________________________________________________________________\nkeyword_occurences.sort(key = lambda x:x[1], reverse = False)\nkey_count = dict()\nfor s in keyword_occurences:\n    key_count[s[0]] = s[1]\n\n# Creation of a dictionary to replace keywords by higher frequency keywords\nremplacement_mot = dict()\nicount = 0\nfor index, [mot, nb_apparitions] in enumerate(keyword_occurences):\n    if nb_apparitions > 5: continue  # only the keywords that appear less than 5 times\n    lemma = get_synonymes(mot)\n    if len(lemma) == 0: continue     # case of the plurals\n    liste_mots = [(s, key_count[s]) for s in lemma \n                  if test_keyword(s, key_count, key_count[mot])]\n    liste_mots.sort(key = lambda x:(x[1],x[0]), reverse = True)    \n    if len(liste_mots) <= 1: continue       # no replacement\n    if mot == liste_mots[0][0]: continue    # replacement by himself\n    icount += 1\n    if  icount < 8:\n        print('{:<12} -> {:<12} (init: {})'.format(mot, liste_mots[0][0], liste_mots))    \n    remplacement_mot[mot] = liste_mots[0][0]\n\nprint(90*'_'+'\\n'+'The replacement concerns {}% of the keywords.'\n      .format(round(len(remplacement_mot)/len(keywords)*100,2)))\n"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"77f6fd25e4f42de8bbc62ffbf5e35dcfb3b0f145","_cell_guid":"2796a83f-cbe4-4055-9706-5e2138d297f7","collapsed":true},"outputs":[],"source":"# 2 successive replacements\nprint('Keywords that appear both in keys and values:'.upper()+'\\n'+45*'-')\nicount = 0\nfor s in remplacement_mot.values():\n    if s in remplacement_mot.keys():\n        icount += 1\n        if icount < 10: print('{:<20} -> {:<20}'.format(s, remplacement_mot[s]))\n\nfor key, value in remplacement_mot.items():\n    if value in remplacement_mot.keys():\n        remplacement_mot[key] = remplacement_mot[value]"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"e11d84f914de2e8f9e4822a1309ecd216fd604c7","_cell_guid":"abde9fb6-b294-4da4-9f41-4e7deca56e92","collapsed":true},"outputs":[],"source":"# replacement of keyword varieties by the main keyword\ndf_keywords_synonyms = remplacement_df_keywords(df_keywords_cleaned, remplacement_mot, roots = False)   \nkeywords, keywords_roots, keywords_select = keywords_inventory(df_keywords_synonyms, colonne = 'keywords')"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"98817abab3ef1040e472728250b4ed23f9942eb2","_cell_guid":"e61586c3-0f36-4127-9361-e9f0155ccef0","collapsed":true},"outputs":[],"source":"# New count of keyword occurences\nkeywords.remove('')\nnew_keyword_occurences, keywords_count = count_word(df_keywords_synonyms,'keywords',keywords)\nnew_keyword_occurences[:5]"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"40c7228158c4109f2ca6904245436e24244d631b","_cell_guid":"80f5f171-aeb5-49dd-8215-f1b310fa9ece","collapsed":true},"outputs":[],"source":"# deletion of keywords with low frequencies\ndef remplacement_df_low_frequency_keywords(df, keyword_occurences):\n    df_new = df.copy(deep = True)\n    key_count = dict()\n    for s in keyword_occurences: \n        key_count[s[0]] = s[1]    \n    for index, row in df_new.iterrows():\n        chaine = row['keywords']\n        if pd.isnull(chaine): continue\n        nouvelle_liste = []\n        for s in chaine.split('|'): \n            if key_count.get(s, 4) > 3: nouvelle_liste.append(s)\n        df_new.set_value(index, 'keywords', '|'.join(nouvelle_liste))\n    return df_new\n\n# Creation of a dataframe where keywords of low frequencies are suppressed\ndf_keywords_occurence = remplacement_df_low_frequency_keywords(df_keywords_synonyms, new_keyword_occurences)\ndf2 = df_keywords_occurence\nkeywords, keywords_roots, keywords_select = keywords_inventory(df2, colonne = 'keywords')   "},{"cell_type":"markdown","metadata":{"_uuid":"2b01fc950b6d888bc4fa83c00445035d484b43ab","_cell_guid":"5d8f5711-df52-4568-a454-228a2d43565b"},"source":"We see a drastic decrease in different keywords"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"bc934042f5896991953b32c7abd01d7ca089085f","_cell_guid":"c04b2def-3d00-45de-8d88-51dc056a8594","collapsed":true},"outputs":[],"source":"#Show the 50 most occuring keywords in a histogram\nfig = plt.figure(1, figsize=(18,13))\ntrunc_occurences = new_keyword_occurences[0:50]\n# LOWER PANEL: HISTOGRAMS\nax2 = fig.add_subplot(2,1,2)\ny_axis = [i[1] for i in trunc_occurences]\nx_axis = [k for k,i in enumerate(trunc_occurences)]\nx_label = [i[0] for i in trunc_occurences]\nplt.xticks(rotation=85, fontsize = 15)\nplt.yticks(fontsize = 15)\nplt.xticks(x_axis, x_label)\nplt.ylabel(\"Nb. of occurences\", fontsize = 18, labelpad = 10)\nax2.bar(x_axis, y_axis, align = 'center', color='g')\n#_______________________\nplt.title(\"Keywords popularity\",bbox={'facecolor':'k', 'pad':5},color='w',fontsize = 25)\nplt.show()"},{"cell_type":"markdown","metadata":{"_uuid":"abb1bb7ab503dc3930ed9630c812a24fc6a9da68","_cell_guid":"cea99c97-5699-4068-86cf-392e3239e6e7","collapsed":true},"source":"### Part 2: Analysis\n\nFor our analysis of the keywords, not every single column is relevent, so we remove a couple of columns from the dataset, the same way we did before. We also add a column for every single keyword, containing a 1 or 0 depending on whether that keyword belongs to a specific movie or not.\n\nThen, we are interested in computing the means of several categories for all the keywords, the same way as we did with the genres.\n"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"e1c2ed3dd7dc93df09c2cbf248df514ffbac8901","_cell_guid":"d70355b6-b0b2-4e25-81b1-568f40f7edc2","collapsed":true},"outputs":[],"source":"liste_keywords = set()\nfor s in df2['keywords'].str.split('|'):\n    liste_keywords = set().union(s, liste_keywords)\nliste_keywords = list(liste_keywords)\nliste_keywords.remove('')\n\ndf_reduced = df2[['title','vote_average','release_date','runtime','budget','revenue']].reset_index(drop=True)\n\nfor keywords in liste_keywords:\n    df_reduced[keywords] = df2['keywords'].str.contains(keywords).apply(lambda x:1 if x else 0)\ndf_reduced.head()\n"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"a381bf2fd18669e5dc1d3d1e18f4f2b2a8e6e1f8","_cell_guid":"6ea7bc2b-392c-4b1a-8ad8-53a494adc98d","collapsed":true},"outputs":[],"source":"#Brackets in the name of the keyword are not allowed in our way of computing the mean --> remove them.\n#We identified three keywords containing brackets, we remove them as follows:\nliste_keywords.remove('national security agency (nsa)')\nliste_keywords.remove('middle-earth (tolkien)')\nliste_keywords.remove('lover (female)')"},{"cell_type":"markdown","metadata":{"_uuid":"27711025c5fbf7b6cd7a1e98df51483eb4027829","_cell_guid":"33c14cd6-2592-41e2-be3c-2b228f9e0bed"},"source":"Now, we use the exact same way as we did with the genres to compute several averages for the keywords."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"57544a76d4c1df7e95bd5f3d9dd03160aed52bde","_cell_guid":"34835cba-dbc9-4d75-8823-14791ee8ca0d","collapsed":true},"outputs":[],"source":"mean_per_keywords = pd.DataFrame(liste_keywords)\n\n#Mean votes average\nnewArray = []*len(liste_keywords)\nfor keywords in liste_keywords:\n    newArray.append(df_reduced.groupby(keywords, as_index=True)['vote_average'].mean())\nnewArray2 = []*len(liste_keywords)\nfor i in range(len(liste_keywords)):\n    # print(newArray[i][1], i)\n    newArray2.append(newArray[i][1])\n\nmean_per_keywords['mean_votes_average']=newArray2\n\n#Mean budget\nnewArray = []*len(liste_keywords)\nfor keywords in liste_keywords:\n    newArray.append(df_reduced.groupby(keywords, as_index=True)['budget'].mean())\nnewArray2 = []*len(liste_keywords)\nfor i in range(len(liste_keywords)):\n    newArray2.append(newArray[i][1])\n\nmean_per_keywords['mean_budget']=newArray2\n\n#Mean revenue \nnewArray = []*len(liste_keywords)\nfor keywords in liste_keywords:\n    newArray.append(df_reduced.groupby(keywords, as_index=True)['revenue'].mean())\nnewArray2 = []*len(liste_keywords)\nfor i in range(len(liste_keywords)):\n    newArray2.append(newArray[i][1])\n\nmean_per_keywords['mean_revenue']=newArray2\n\nmean_per_keywords['profit'] = mean_per_keywords['mean_revenue']-mean_per_keywords['mean_budget']\n\nmean_per_keywords.head()"},{"cell_type":"markdown","metadata":{"_uuid":"14f3f734a1ca4518bd6efec2df816ed16b588bc4","_cell_guid":"5472651b-9885-4afd-88ef-b95a12a347f7"},"source":"For every category the five largerst mean are shown."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"b7a85c167d94916d428cd37451326b16a25a748d","_cell_guid":"d00fb4eb-6b5d-496e-864c-220cb14f56f5","collapsed":true},"outputs":[],"source":"mean_per_keywords.sort_values('mean_votes_average', ascending=False).head()"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"0203b3fc61b650d40c28122bb467c4a5ff653b37","_cell_guid":"b8bb5e10-420b-4385-a680-08fe0a9deefe","collapsed":true},"outputs":[],"source":"mean_per_keywords.sort_values('mean_budget', ascending=False).head()"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"0482c6a547a7506eed0ac0df44a72b68be64fab3","_cell_guid":"39a47dfb-9c23-4c4f-9f2e-0c6ad2c71077","collapsed":true},"outputs":[],"source":"mean_per_keywords.sort_values('mean_revenue', ascending=False).head()"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"3eba733c90a3a8374eb40b8a198e59bd69fdbb99","_cell_guid":"52f16c89-22ad-445c-9a19-f07cd4c4a8a2","collapsed":true},"outputs":[],"source":"mean_per_keywords.sort_values('profit', ascending=False).head()"},{"cell_type":"markdown","metadata":{"_uuid":"2384a35c1136ca466acbf46296b8c6130175c497","_cell_guid":"fe3acef9-e48a-4267-b746-f35298f30457"},"source":"We can further visualize our findings using bar plots. \n"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"3d38965b91fdd119dbfedbe57fd92f0a8f1116c3","_cell_guid":"37ae88f6-41b3-42a8-8d2a-0539099d98da","collapsed":true},"outputs":[],"source":"#In order to to get a good visualisation we restructure our dataframe a little bit.\nmean_per_keywords.index = mean_per_keywords.loc[:,0]\nmean_per_keywords = mean_per_keywords.drop(0,axis=1)"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"4ce5ff23a86f0e0b568c589ff750a8e9117c0234","_cell_guid":"9ffbbc72-d324-43c8-8dc0-6cecc15d9382","collapsed":true},"outputs":[],"source":"df = mean_per_keywords.sort_values('mean_votes_average', ascending=False)\ndf = df[0:50]\nfig = plt.figure(1, figsize=(18,13))\n\nimport matplotlib.pyplot as plt\nax = df['mean_votes_average'].plot(kind='bar', title =\"mean_vote_average\", figsize=(15, 4), legend=True, fontsize=12, color='green')\nax.set_xlabel(\"Keyword\", fontsize=12)\nax.set_ylabel(\"mean_votes_average\", fontsize=12 )\nax.set_ylim([7.2,7.7])\nplt.show()"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"b9700934099d526768f603674a89e31e3967d3e0","_cell_guid":"aaf0eab0-82a6-4655-98b7-5f18ac1bab3f","collapsed":true},"outputs":[],"source":"df = mean_per_keywords.sort_values('mean_budget', ascending=False)\ndf = df[0:50]\nfig = plt.figure(1, figsize=(18,13))\n\nimport matplotlib.pyplot as plt\nax = df['mean_budget'].plot(kind='bar', title =\"mean_budget\", figsize=(15, 4), legend=True, fontsize=12, color='red')\nax.set_xlabel(\"Keyword\", fontsize=12)\nax.set_ylabel(\"mean_budget\", fontsize=12)\nax.set_ylim([1e+08 , 2.2e+08])\nplt.show()"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"564641735fe4aee4214e6d925d145a2f6aebf4ad","_cell_guid":"c2544db2-f0b0-4ac4-95b4-cbaedd224c1c","collapsed":true},"outputs":[],"source":"df = mean_per_keywords.sort_values('mean_revenue', ascending=False)\ndf = df[0:50]\nfig = plt.figure(1, figsize=(18,13))\n\nimport matplotlib.pyplot as plt\nax = df['mean_revenue'].plot(kind='bar', title =\"mean_revenue\", figsize=(15, 4), legend=True, fontsize=12, color='blue')\nax.set_xlabel(\"Keyword\", fontsize=12)\nax.set_ylabel(\"mean_revenue\", fontsize=12)\nax.set_ylim([4e+08 , 10e+08])\nplt.show()"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"eb7af3a5cce97e5246160c7b5b400eee1426e20d","_cell_guid":"fad1e1ac-0686-46a5-9332-d7410d6db507","collapsed":true},"outputs":[],"source":"df = mean_per_keywords.sort_values('profit', ascending=False)\ndf = df[0:50]\nfig = plt.figure(1, figsize=(18,13))\n\nimport matplotlib.pyplot as plt\nax = df['profit'].plot(kind='bar', title =\"Profit\", figsize=(15, 4), legend=True, fontsize=12, color='pink')\nax.set_xlabel(\"Keyword\", fontsize=12)\nax.set_ylabel(\"Profit\", fontsize=12)\nax.set_ylim([3e+08 , 8e+08])\nplt.show()"},{"cell_type":"markdown","metadata":{"_uuid":"218bac6738460e8f7fdea5584d259b57f42948be","_cell_guid":"fdb88b97-527a-40f9-99f9-666e397d05bf"},"source":"## Cast Analysis\nA previous version of this dataset only contained the top three actors per movie. Since we only want to analyze the most important actors of a movie and since the old dataset was a bit more suited to do that, we convert the dataset back to its previous state using Sohier Dane's method."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"421d8fc99f72cc6080b1bdcec398714952566eaa","_cell_guid":"b8fe2bd8-1b91-48a4-ab19-b313f963e8d1","collapsed":true},"outputs":[],"source":"# Columns that existed in the IMDB version of the dataset and are gone.\nLOST_COLUMNS = [\n    'actor_1_facebook_likes',\n    'actor_2_facebook_likes',\n    'actor_3_facebook_likes',\n    'aspect_ratio',\n    'cast_total_facebook_likes',\n    'color',\n    'content_rating',\n    'director_facebook_likes',\n    'facenumber_in_poster',\n    'movie_facebook_likes',\n    'movie_imdb_link',\n    'num_critic_for_reviews',\n    'num_user_for_reviews'\n                ]\n\n# Columns in TMDb that had direct equivalents in the IMDB version. \n# These columns can be used with old kernels just by changing the names\nTMDB_TO_IMDB_SIMPLE_EQUIVALENCIES = {\n    'budget': 'budget',\n    'genres': 'genres',\n    'revenue': 'revenue',\n    'title': 'movie_title',\n    'runtime': 'duration',\n    'original_language': 'language',  # it's possible that spoken_languages would be a better match\n    'keywords': 'plot_keywords',\n    'vote_count': 'num_voted_users',\n                                         }\n\nIMDB_COLUMNS_TO_REMAP = {'imdb_score': 'vote_average'}\n\n\ndef safe_access(container, index_values):\n    # return a missing value rather than an error upon indexing/key failure\n    result = container\n    try:\n        for idx in index_values:\n            result = result[idx]\n        return result\n    except IndexError or KeyError:\n        return pd.np.nan\n\n\ndef get_director(crew_data):\n    directors = [x['name'] for x in crew_data if x['job'] == 'Director']\n    return safe_access(directors, [0])\n\n\ndef pipe_flatten_names(keywords):\n    return '|'.join([x['name'] for x in keywords])\n\n\ndef convert_to_original_format(movies, credits):\n    # Converts TMDb data to make it as compatible as possible with kernels built on the original version of the data.\n    tmdb_movies = movies.copy()\n    tmdb_movies.rename(columns=TMDB_TO_IMDB_SIMPLE_EQUIVALENCIES, inplace=True)\n    tmdb_movies['title_year'] = pd.to_datetime(tmdb_movies['release_date']).apply(lambda x: x.year)\n    # I'm assuming that the first production country is equivalent, but have not been able to validate this\n    tmdb_movies['country'] = tmdb_movies['production_countries'].apply(lambda x: safe_access(x, [0, 'name']))\n    tmdb_movies['language'] = tmdb_movies['spoken_languages'].apply(lambda x: safe_access(x, [0, 'name']))\n    tmdb_movies['director_name'] = credits['crew'].apply(get_director)\n    tmdb_movies['actor_1_name'] = credits['cast'].apply(lambda x: safe_access(x, [1, 'name']))\n    tmdb_movies['actor_2_name'] = credits['cast'].apply(lambda x: safe_access(x, [2, 'name']))\n    tmdb_movies['actor_3_name'] = credits['cast'].apply(lambda x: safe_access(x, [3, 'name']))\n    tmdb_movies['genres'] = tmdb_movies['genres'].apply(pipe_flatten_names)\n    tmdb_movies['plot_keywords'] = tmdb_movies['plot_keywords'].apply(pipe_flatten_names)\n    return tmdb_movies\n\ncredits = load_tmdb_credits(\"../input/tmdb_5000_credits.csv\")\nmovies = load_tmdb_movies(\"../input/tmdb_5000_movies.csv\")\ndf = convert_to_original_format(movies, credits)\n\n# We store a copy of the dataframe for later use\ndf3 = df\n\n#Delete all the columns we won't be needing for this analysis.\ncolumns = ['homepage', 'plot_keywords', 'language', 'overview', 'popularity', 'tagline',\n           'original_title', 'num_voted_users', 'country', 'spoken_languages', 'duration',\n          'production_companies', 'production_countries', 'status']\n\ndf = df.drop(columns, axis=1)\n\n"},{"cell_type":"markdown","metadata":{"_uuid":"2c8c19af8ccfdcd9df91e9e3ae6e865b302c6384","_cell_guid":"729f2985-0993-4051-b367-f65ca2a2020b"},"source":"We are interested in the same descriptives for the actors, as we were for keywords and the genres. To do that, we first have to, once again, restructure the dataframe.\n\nWe first create a seperate dataframe for each of the three actors, after which we can combine them to get one dataframe with all three types of actor."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"f0a770efb9ef1d87116490a4f2acb76e64c91574","_cell_guid":"a035bfe3-4b4c-4a5d-aaf9-21520fee29f2","collapsed":true},"outputs":[],"source":"liste_genres = set()\nfor s in df['genres'].str.split('|'):\n    liste_genres = set().union(s, liste_genres)\nliste_genres = list(liste_genres)\nliste_genres.remove('')\n\ndf_reduced = df[['actor_1_name', 'vote_average',\n                 'title_year', 'movie_title', 'revenue', 'budget']].reset_index(drop = True)\nfor genre in liste_genres:\n    df_reduced[genre] = df['genres'].str.contains(genre).apply(lambda x:1 if x else 0)\n\ndf_reduced2 = df[['actor_2_name', 'vote_average',\n                 'title_year', 'movie_title', 'revenue', 'budget']].reset_index(drop = True)\nfor genre in liste_genres:\n    df_reduced2[genre] = df['genres'].str.contains(genre).apply(lambda x:1 if x else 0)\n\ndf_reduced3 = df[['actor_3_name', 'vote_average',\n                 'title_year', 'movie_title', 'revenue', 'budget']].reset_index(drop = True)\nfor genre in liste_genres:\n    df_reduced3[genre] = df['genres'].str.contains(genre).apply(lambda x:1 if x else 0)\n    \n#combine the three dataframes\ndf_reduced = df_reduced.rename(columns={'actor_1_name': 'actor'})\ndf_reduced2 = df_reduced2.rename(columns={'actor_2_name': 'actor'})\ndf_reduced3 = df_reduced3.rename(columns={'actor_3_name': 'actor'})\n\ntotal = [df_reduced, df_reduced2, df_reduced3]\ndf_total = pd.concat(total)\ndf_total.head()"},{"cell_type":"markdown","metadata":{"_uuid":"6532c86c7ad0d07d674a59ac165e7c07ba74cca4","_cell_guid":"6a3f4e78-0d71-4f30-948f-daea9c84ef5f"},"source":"We compute averages for all actors in two categories: vote_average and title_year. We also compute an actors favorite genre."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"2baa06b3877a4ff6c8b6dff5f94f023aac19a6c2","_cell_guid":"50c9c459-f05e-4276-97e3-22b651cbd352","collapsed":true},"outputs":[],"source":"df_actors = df_total.groupby('actor').mean()\ndf_actors.loc[:, 'favored_genre'] = df_actors[liste_genres].idxmax(axis = 1)\ndf_actors.drop(liste_genres, axis = 1, inplace = True)\ndf_actors = df_actors.reset_index()"},{"cell_type":"markdown","metadata":{"_uuid":"63a2af8af741ea115906d6edf502db5e34deab1e","_cell_guid":"438e3804-4b44-4d14-924c-c8d5a8f94f24"},"source":"We expect the dataframe to contain a lot of actors that have only a single observation. These observation are likely to cause outliers if these observations are very extreme. We delete all actors that are linked to less than 5 movies in our dataframe."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"dffa7e4f0cef18de1c73ee2d42faab00a3a8118c","_cell_guid":"ed3cfd93-c93f-40da-a3f3-2b40c8a0be8c","collapsed":true},"outputs":[],"source":"#The minimum amount of movies an actor plays in can easily be adapted by changing the selection\ndf_appearance = df_total[['actor', 'title_year']].groupby('actor').count()\ndf_appearance = df_appearance.reset_index(drop = True)\nselection = df_appearance['title_year'] > 4\nselection = selection.reset_index(drop = True)\nmost_prolific = df_actors[selection]"},{"cell_type":"markdown","metadata":{"_uuid":"120c47bcca1523dd7ac89b747ba02133e2b39480","_cell_guid":"67938ea3-fd83-4a4a-a76b-d6e99ed0f95b"},"source":"Now that we have a clear dataframe, let us show some descriptive statistics. We first sort the dataframe on all the different attributes from highest to lowest."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"679ef43c7c06ca1c5972743838e2035990fb3659","_cell_guid":"bc1f0c18-9ad0-43fc-bfdd-e9d4c6748d1b","collapsed":true},"outputs":[],"source":"most_prolific.sort_values('vote_average', ascending=False).head()"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"90a871d44a297c89430830d2eea85f16798551a6","_cell_guid":"d70eef86-7a72-4725-972a-07305302f30f","collapsed":true},"outputs":[],"source":"most_prolific.sort_values('revenue', ascending=False).head()"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"8b431b2393007774d9a0bfb31fc0a06c35358bb6","_cell_guid":"819e3a86-37ce-4d93-b566-96989475a424","collapsed":true},"outputs":[],"source":"most_prolific.sort_values('budget', ascending=False).head()"},{"cell_type":"markdown","metadata":{"_uuid":"5f3fb32496624ed91deca3e683ff2b531e8420b8","_cell_guid":"ef805db8-baf1-406c-8285-54e5ee0e49ff"},"source":"We can now develop several plots to analyze our actors. Let us start by plotting the average budget per actor and the average revenue per actor."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"6324f80be08c0e41f55a77dc50a2806b65f2148b","_cell_guid":"564fbd05-5053-4756-a74f-ea47d2c3fa6b","collapsed":true},"outputs":[],"source":"genre_count = []\nfor genre in liste_genres:\n    genre_count.append([genre, df_reduced[genre].values.sum()])\ngenre_count.sort(key = lambda x:x[1], reverse = True)\nlabels, sizes = zip(*genre_count)\nlabels_selected = [n if v > sum(sizes) * 0.01 else '' for n, v in genre_count]\nreduced_genre_list = labels[:19]\ntrace=[]\nfor genre in reduced_genre_list:\n    trace.append({'type':'scatter',\n                  'mode':'markers',\n                  'y':most_prolific.loc[most_prolific['favored_genre']==genre,'revenue'],\n                  'x':most_prolific.loc[most_prolific['favored_genre']==genre,'budget'],\n                  'name':genre,\n                  'text': most_prolific.loc[most_prolific['favored_genre']==genre,'actor'],\n                  'marker':{'size':10,'opacity':0.7,\n                            'line':{'width':1.25,'color':'black'}}})\nlayout={'title':'Actors favored genres',\n       'xaxis':{'title':'mean year of activity'},\n       'yaxis':{'title':'mean score'}}\nfig=Figure(data=trace,layout=layout)\npyo.iplot(fig)"},{"cell_type":"markdown","metadata":{"_uuid":"14337421b1069b39db24889451be897dc550f5ca","_cell_guid":"132e4ecc-ab9c-4fa5-afc7-155fca3a21b4"},"source":"Except for some outliers, this looks like a very nice linear regression. This gives us the insight that overall, actors are worth their money. For most actors it is so, that if they play in a high budget movie, the movie is likely to have high revenue as well.\n\nNext, let us look at the average vote an actor receives and their mean year of activity."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"6f4c702c3068e516ff00d6277e237b9dd80fbcaa","_cell_guid":"a34fe79f-ba98-4c97-b962-1739baf9eaa2","collapsed":true},"outputs":[],"source":"reduced_genre_list = labels[:19]\ntrace=[]\nfor genre in reduced_genre_list:\n    trace.append({'type':'scatter',\n                  'mode':'markers',\n                  'y':most_prolific.loc[most_prolific['favored_genre']==genre,'vote_average'],\n                  'x':most_prolific.loc[most_prolific['favored_genre']==genre,'title_year'],\n                  'name':genre,\n                  'text': most_prolific.loc[most_prolific['favored_genre']==genre,'actor'],\n                  'marker':{'size':10,'opacity':0.7,\n                            'line':{'width':1.25,'color':'black'}}})\nlayout={'title':'Actors favored genres',\n       'xaxis':{'title':'mean year of activity'},\n       'yaxis':{'title':'mean score'}}\nfig=Figure(data=trace,layout=layout)\npyo.iplot(fig)"},{"cell_type":"markdown","metadata":{"_uuid":"b596dde24903cd1438df77e86a3b8e108d634021","_cell_guid":"ec3f867b-129a-4528-824e-6979f6c63e55"},"source":"We can also use this data to highlight single actors. Let us take a look at actors for who we have data of more than 20 movies."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"0bbc74b80b3b1cc64faa392dcd56dbfa2129cedb","_cell_guid":"73271300-555a-4679-8561-cfc308edfcd6","collapsed":true},"outputs":[],"source":"selection = df_appearance['title_year'] > 20\nmost_prolific = df_actors[selection]\nmost_prolific"},{"cell_type":"markdown","metadata":{"_uuid":"5ccbed3274ef7fbfcc421070737695d0129d3872","_cell_guid":"b1fc7d73-99e7-4f82-89ff-99f3c0d34581"},"source":"## Part 4: Director Analysis\nWe start the actual analysis by computing the average per movie and total revenue of the directors. We only took into account the directs for which we have at least 4 movies as observations, to exclude extreme outliers. Not surprisingly, the top rated directors are probably directors you have heard about."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"16a4c2b8204ce9c5ad0f848a84d1b2730f08068d","_cell_guid":"46e1f469-1622-4b35-8546-f50c6ab853dc","collapsed":true},"outputs":[],"source":"df3 = df\n\ndef create_comparison_database(name, value, x, no_films):\n    \n    comparison_df = df3.groupby(name, as_index=False)\n    \n    if x == 'mean':\n        comparison_df = comparison_df.mean()\n    elif x == 'median':\n        comparison_df = comparison_df.median()\n    elif x == 'sum':\n        comparison_df = comparison_df.sum() \n    \n    # Create database with either name of directors or actors, the value being compared i.e. 'revenue',\n    # and number of films they're listed with. Then sort by value being compared.\n    name_count_key = df[name].value_counts().to_dict()\n    comparison_df['films'] = comparison_df[name].map(name_count_key)\n    comparison_df.sort_values(value, ascending=False, inplace=True)\n    comparison_df[name] = comparison_df[name].map(str) + \" (\" + comparison_df['films'].astype(str) + \")\"\n   # create a Series with the name as the index so it can be plotted to a subgrid\n    comp_series = comparison_df[comparison_df['films'] >= no_films][[name, value]][10::-1].set_index(name).ix[:,0]\n    \n    return comp_series\n\nfig = plt.figure(figsize=(18,6))\n\n# Director_name\nplt.subplot2grid((2,3),(0,0), rowspan = 2)\ncreate_comparison_database('director_name','revenue','sum', 4).plot(kind='barh', color='#006600')\nplt.legend().set_visible(False)\nplt.title(\"Total Revenue for Directors with 4+ Films\")\nplt.ylabel(\"Director (no. films)\")\nplt.xlabel(\"Revenue (in billons)\")\n\nplt.subplot2grid((2,3),(0,1), rowspan = 2)\ncreate_comparison_database('director_name','revenue','mean', 4).plot(kind='barh', color='#ffff00')\nplt.legend().set_visible(False)\nplt.title('Average revenue for Directors with 4+ Films')\nplt.ylabel(\"Director (no. films)\")\nplt.xlabel(\"Revenue (in billons)\")\n\nplt.tight_layout()"},{"cell_type":"markdown","metadata":{"_uuid":"2bd3460aa26ea989b5ce06f1d0059f1c8278fe5b","_cell_guid":"de5eff99-1c8a-4271-9ab3-ac0b271d6e8e"},"source":"Notice how many of the directors that have a very high average budget per movie were nowhere to be seen in the revenue plot. Implying that, although they make expensive movies, they don't make the most grossing movies. Also note that a lot of high scoring directors are not found in the top ten highest budgeted directors. This implies that a big budget doesn't necessarily lead to a good, or well-received, movie. On the other hand, it shows that some directors, for instance Hayao Miyazaki, is capable of creating excellent movies with needing a very high budget. \n\nNow, all of this is of course only true for directors with 4+ movies. It is possible that directors with few movies were lucky. A question to ask the dataset could be whether there exist any directors that are capable of consistently creating well-received movies, without the need for big budgets. To answer this question we plot the average budget next to the average score per director, for directors with at least 15 movies."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"0316f22bc0faadab3e4b3c0d5db1c763b27c51b5","_cell_guid":"daaffd3e-bd1e-4464-be7a-41eb163b2219","collapsed":true},"outputs":[],"source":"fig = plt.figure(figsize=(18,6))\n\n# Director_name\nplt.subplot2grid((2,3),(0,0), rowspan = 2)\ncreate_comparison_database('director_name','budget','mean', 10).plot(kind='barh', color='#006600')\nplt.legend().set_visible(False)\nplt.title(\"Average budget for Directors with 15+ Filmss\")\nplt.ylabel(\"Director (no. films)\")\nplt.xlabel(\"Budget (in billons)\")\n\nplt.subplot2grid((2,3),(0,1), rowspan = 2)\ncreate_comparison_database('director_name','vote_average','mean', 10).plot(kind='barh', color='#ffff00')\nplt.legend().set_visible(False)\nplt.title('Mean IMDB Score for Directors with 15+ Films')\nplt.ylabel(\"Director (no. films)\")\n\nplt.xlabel(\"IMDB Score\")\nplt.xlim(0,10)\n\nplt.tight_layout()"},{"cell_type":"markdown","metadata":{"_uuid":"cc7c7b05c0523990125311400390470bed8258e8","_cell_guid":"f328ed68-bc15-4cee-a80d-754af2157c07"},"source":"Now, we easily see that the two bar plots have more directors in common. Still, there are some directors who manage to create excellent movies without the need for a big budget. A funny observation is Michael Bay. While he is easily the king of budget, he is nowhere to be found in the top ten highest scoring directors."},{"cell_type":"markdown","metadata":{"_uuid":"aa66a19c488f93d9306b0e31acb1a199e17d75f1","_cell_guid":"c4f1a7a9-46b8-4bf4-a517-048de4d68c48"},"source":"Resources:\n\nhttps://www.kaggle.com/fabiendaniel/film-recommendation-engine\n\nhttps://www.kaggle.com/fabiendaniel/categorizing-actors-hands-on-plotly\n\nhttps://www.kaggle.com/willacy/director-and-actor-s-total-gross-and-imdb-score\n\nhttps://www.kaggle.com/fabiendaniel/choropleth-map-with-plot"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"80c896c65771bc3322a7a889cb17955a47014dba","_cell_guid":"e6fa90e6-beeb-4f9d-873a-83015bed930b","collapsed":true},"outputs":[],"source":""}],"nbformat":4,"metadata":{"language_info":{"nbconvert_exporter":"python","version":"3.6.3","name":"python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","file_extension":".py","mimetype":"text/x-python"},"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"}}}