{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **GENDER CLASSIFICATION**\n**By : Garry Ariel**\n\nThis notebook contains the steps of processing given information, build and train the model, and use it to predict gender. The model used here are Logistic Regression (LR) and Neural Network (NN).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"First thing to do is import some necessary packages and read the data in.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Import packages\nimport numpy as np\nimport pandas as pd\n\n# Read the data\ndata_df = pd.read_csv(\"/kaggle/input/gender-classification/Transformed Data Set - Sheet1.csv\")\n\n# Take a look at some data examples\ndata_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Take a look some statistics about the data using following syntax.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Describe the data\ndata_df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Preprocessing the Data**  \nNext, we will do some pre-processing to the data, such as turn categorical variables into one-hot-encoding form.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Turn male into 1 and female 0\ndata_df['Gender'].replace(to_replace = 'F', value = 0, inplace = True)\ndata_df['Gender'].replace(to_replace = 'M', value = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create one hot encoding\nfav_color_df = pd.get_dummies(data_df[[\"Favorite Color\"]], prefix = \"color\")\nfav_music_df = pd.get_dummies(data_df[[\"Favorite Music Genre\"]], prefix = \"music\")\nfav_beverage_df = pd.get_dummies(data_df[[\"Favorite Beverage\"]], prefix = \"beverage\")\nfav_drink_df = pd.get_dummies(data_df[[\"Favorite Soft Drink\"]], prefix = \"drink\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merging one hot encoding and create new dataframe\ntransformed_df = pd.merge(fav_color_df, fav_music_df, left_index = True, right_index = True)\ntransformed_df = pd.merge(transformed_df, fav_beverage_df, left_index = True, right_index = True)\ntransformed_df = pd.merge(transformed_df, fav_drink_df, left_index = True, right_index = True)\n\n# Take a look at some data examples\ntransformed_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Feature Selection**\nNext, we will select some features which will be used to feed the model later. We specified 3 ways to select the features.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"1. Choose the feature manually.\nWe can experiment about which features give higher accuracy.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Choose feature (Manual)\nfeature = [\n    \"music_Electronic\",\n    \"music_Hip hop\",\n    \"music_Jazz/Blues\",\n    \"music_Pop\",\n    \"music_R&B and soul\",\n    \"beverage_Vodka\",\n    \"drink_Other\"\n]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. Choose all features without filter it.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Choose all feature\n# feature = []\n# for col in transformed_df.columns:\n#     feature.append(col)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. Choose features based on its correlation to gender variable. Specify a threshold, such that every features which have correlation to gender variable greater than threshold will be chosen as a feature.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Choose feature (By rule)\n# feature = []\n# analyze_df = pd.merge(transformed_df, data_df[\"Gender\"], left_index = True, right_index = True)\n# for index, row in analyze_df.corr().iterrows():\n#     if abs(row[\"Gender\"]) > 0.08 and index != \"Gender\":\n#         feature.append(index)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Preparing Data**\nIn the following step, we will format the data so that the data can be feed into the model. We will also split the data into train and test dataset with the comparison of 4:1.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import packages related to training model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, matthews_corrcoef, accuracy_score\n\n# Turn into numpy array\nX = np.asarray(transformed_df[feature])\ny = np.asarray(data_df['Gender'])\n\n# Split dataset\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocess train data\nheader = []\nfor col in transformed_df[feature].columns:\n    header.append(col)\nheader = np.array(header)\n\nx_df = pd.DataFrame(\n    X_train,\n    columns = header\n)\n\ny_df = pd.DataFrame(\n    y_train,\n    columns = [\"gender\"]\n)\n\ntrain_df = pd.merge(x_df, y_df, left_index = True, right_index = True)\n\n# Look at the correlation\ncorr_df = train_df.corr()\ncorr_df.head(len(feature))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Build and Train Logistic Regression Model**\n\nWe will just simply feed the model with the data using any default parameters. After trained, we use the model to predict the gender, and evaluate the accuracy. To experiment with the accuracy, we can change the features we used in previous steps.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create logistic regression\nLR = LogisticRegression().fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predict result\ny_predict = LR.predict(X_test)\n\n# Evaluate the accuracy\nscore = accuracy_score(y_predict, y_test)\n\n# Print result\nprint(\"The accuracy is \" + str(score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Build and Train Neural Network**\n\nThe model we used here are as the following.\n1. Fully connected layer with 128 neurons using ReLU activation function.\n2. Dropout layer with probability 0.4.\n3. Fully connected layer with 2 neurons (as output) using softmax activation function.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using NN model\nimport tensorflow as tf\nfrom tensorflow import keras\n\n# Create callback\nclass myCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs = {}):\n        if ((logs.get('val_accuracy') > 0.72 and logs.get('val_loss') <= 0.5931) or logs.get('val_accuracy') >= 0.9):\n            self.model.stop_training = True\n            print(\"Stop here\")\ncallback = myCallback()\n\n# Build model\ntf.random.set_seed(42)\nmodel = keras.Sequential([\n    keras.layers.Dense(128, activation = 'relu', input_shape = [len(feature)]),\n    keras.layers.Dropout(0.4),\n    keras.layers.Dense(2, activation = 'softmax')\n])\n\n# Compile model\nmodel.compile(\n    loss = 'binary_crossentropy',\n    optimizer = keras.optimizers.Adam(0.001),\n    metrics = ['accuracy']\n)\n\n# Fit the model\nmodel.fit(\n    X_train, y_train,\n    epochs = 200,\n    batch_size = 1,\n    verbose = 1,\n    validation_split = 0.2,\n    callbacks = [callback]\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then we used the trained NN model to predict the gender and evaluate the accuracy. As before, we can experiment with the accuracy by change the features we used, or changing some parameters.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predict result (If the last layer using softmax)\ny_predict = model.predict(X_test)\nresult = []\nfor index in range(len(y_predict)):\n  each_result = np.argmax(y_predict[index])\n  result.append(each_result)\n\n# Formatting\nresult = np.array(result)\n    \n# Evaluate the accuracy\nscore = accuracy_score(result, y_test)\n\n# Print result\nprint(\"The accuracy is \" + str(score))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}