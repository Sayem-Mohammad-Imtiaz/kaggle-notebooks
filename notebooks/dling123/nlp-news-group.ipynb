{"cells":[{"metadata":{},"cell_type":"markdown","source":"1. 1. ## NLP_Capstone_Project (please copy the code into jupyter notebook)"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\n%matplotlib inline\nimport seaborn as sns\nimport re\nfrom nltk.corpus import stopwords\nimport string\nimport random\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import HashingVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn import metrics    \nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import PorterStemmer\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer \nimport timeit\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import Normalizer\nfrom nltk.corpus import gutenberg, stopwords\nfrom sklearn import ensemble\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.preprocessing import normalize\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.cluster import KMeans\nfrom sklearn.cluster import MeanShift, estimate_bandwidth\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.datasets import fetch_20newsgroups","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploring and modelling the 20 Newsgroups data set"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"### Dataset description: \nthe 20 Newsgroups data set is a collection of approximately 19K newsgroup documents.\nThe original form of this dataset is at this page: http://qwone.com/~jason/20Newsgroups/    "},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"## Inspiration:\nClassifying text documents into various news groups"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"## Sections:\n* Preparing full, train and test data set\n* Data cleaning: removing stopwords, filter out short words, stemming and lemmatization\n* vectorization: tf_idf\n* comparison Naive_Bayes performance between applying stemming and lemmatization \n* Exploring different ngrams in the vectorizer step\n* Exploring various ML algorithms: SVC, Logistic regression, Random forest, and Gradient boosting \n* Inspecting the top words calcualted by Naive_bayes\n* Text extraction: lsa, lda, and nnmf\n* Unsupervised learning with LSA: KMeans and GaussianMixture\n* Text summarization: tf_idf, calculate similarity, rank sentences based on scores\n* Word2vec\n"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"### Preparing the full_dataset, train_dataset and test_dataset"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_full = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'), shuffle=True, random_state=42)\ndf_full = pd.DataFrame()\ndf_full['text'] = dataset_full.data\ndf_full['source'] = dataset_full.target\nlabel=[]\nfor i in df_full['source']:\n    label.append(dataset_full.target_names[i])\ndf_full['label']=label\n\ndataset_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), shuffle=True, random_state=42)\ndf_train = pd.DataFrame()\ndf_train['text'] = dataset_train.data\ndf_train['source'] = dataset_train.target\nlabel=[]\nfor i in df_train['source']:\n    label.append(dataset_train.target_names[i])\ndf_train['label']=label\n\ndataset_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'), shuffle=True, random_state=42)\ndf_test = pd.DataFrame()\ndf_test['text'] = dataset_test.data\ndf_test['source'] = dataset_test.target\nlabel=[]\nfor i in df_test['source']:\n    label.append(dataset_test.target_names[i])\ndf_test['label']=label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data cleaning"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"* Removing stopwords\n* Filter out short words\n* Lowercase and removing everything except words\n* Applying stemming vs lemmatization to the text"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"stopWords = set(stopwords.words('english'))\n\ndef textcleaner_stem(text):\n    ''' Takes in raw unformatted text and strips punctuation, removes whitespace,\n    strips numbers, tokenizes and stems.\n    Returns string of processed text to be used into CountVectorizer\n    '''\n    # Lowercase and strip everything except words\n    cleaner = re.sub(r\"[^a-zA-Z ]+\", ' ', text.lower())\n    # Tokenize\n    cleaner = word_tokenize(cleaner)\n    ps = PorterStemmer()\n    clean = []\n    for w in cleaner:\n        # filter out stopwords\n        if w not in stopWords:\n            # filter out short words\n            if len(w)>2:\n                # Stem \n                clean.append(ps.stem(w))\n    return ' '.join(clean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_full['clean_text_stem'] = df_full.text.apply(lambda x: textcleaner_stem(x))\ndf_train['clean_text_stem'] = df_train.text.apply(lambda x: textcleaner_stem(x))\ndf_test['clean_text_stem'] = df_test.text.apply(lambda x: textcleaner_stem(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.stem import WordNetLemmatizer\nlemmatizer = WordNetLemmatizer()\n\nstopWords = set(stopwords.words('english'))\n\ndef textcleaner_lemmas(text):\n    ''' Takes in raw unformatted text and strips punctuation, removes whitespace,\n    strips numbers, tokenizes and stems.\n    Returns string of processed text to be used into CountVectorizer\n    '''\n    # Lowercase and strip everything except words\n    cleaner = re.sub(r\"[^a-zA-Z ]+\", ' ', text.lower())\n    # Tokenize\n    cleaner = word_tokenize(cleaner)\n    ps = PorterStemmer()\n    clean = []\n    for w in cleaner:\n        # filter out stopwords\n        if w not in stopWords:\n            # filter out short words\n            if len(w)>2:\n                # lemmatizer \n                clean.append(lemmatizer.lemmatize(w))\n    return ' '.join(clean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_full['clean_text_lemma'] = df_full.text.apply(lambda x: textcleaner_lemmas(x))\ndf_train['clean_text_lemma'] = df_train.text.apply(lambda x: textcleaner_lemmas(x))\ndf_test['clean_text_lemma'] = df_test.text.apply(lambda x: textcleaner_lemmas(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Converet sentences to vectors: test_stem to tf_idf"},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorizer = TfidfVectorizer(min_df=6, strip_accents='ascii', analyzer='word', lowercase=True,\n                             ngram_range=(1,2))\n\nx_train_stem = vectorizer.fit_transform(df_train['clean_text_stem'])\ny_train_stem = df_train['source']\nx_test_stem = vectorizer.transform(df_test['clean_text_stem'])\ny_test_stem = df_test['source']\nfeatures_train = vectorizer.get_feature_names()\nlen(features_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Naive_bayes: test the stem_text"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\n\n# Start timing\nstart = timeit.default_timer()\n\n#Initialize and fit\nnb = MultinomialNB()\nnb.fit(x_train_stem, y_train_stem)\n\n# Apply to testing data\ny_pred_stem = nb.predict(x_test_stem)\n\n# Stop timing\nstop = timeit.default_timer()\nnb_time = stop-start\nprint(\"Run time: %0.3f\" % (nb_time))\n\n# Showing model performance\nprint(\"Accuracy is: %0.3f\" % nb.score(x_test_stem, y_test_stem))\nprint(metrics.classification_report(y_test_stem, y_pred_stem, target_names=dataset_test.target_names))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Converet sentences to vectors: test_lemma to tf_idf"},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorizer = TfidfVectorizer(min_df=6, strip_accents='ascii', analyzer='word', lowercase=True,\n                             ngram_range=(1,2))\n\nx_train_lemma = vectorizer.fit_transform(df_train['clean_text_lemma'])\ny_train_lemma = df_train['source']\nx_test_lemma = vectorizer.transform(df_test['clean_text_lemma'])\ny_test_lemma = df_test['source']\nfeatures_train = vectorizer.get_feature_names()\nlen(features_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Naive_bayes: test the lemma_text"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\n\n# Start timing\nstart = timeit.default_timer()\n\n#Initialize and fit\nnb = MultinomialNB()\nnb.fit(x_train_lemma, y_train_lemma)\n\n# Apply to testing data\ny_pred_lemma = nb.predict(x_test_lemma)\n\n# Stop timing\nstop = timeit.default_timer()\nnb_time = stop-start\nprint(\"Run time: %0.3f\" % (nb_time))\n\n# Showing model performance\nprint(\"Accuracy is: %0.3f\" % nb.score(x_test_lemma, y_test_lemma))\nprint(metrics.classification_report(y_test_lemma, y_pred_lemma, target_names=dataset_test.target_names))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Comparison between stemming and lemmatization:\n* no significant accuracy different as applying different mothods\n* the running time using naive_bayes is quite fast\n* the following study will use the lemmatized text"},{"metadata":{},"cell_type":"markdown","source":"### Exploring different ngrams in the vectorizer step"},{"metadata":{"trusted":true},"cell_type":"code","source":"for n in range(1,4):\n    vectorizer = TfidfVectorizer(min_df=6, strip_accents='ascii', analyzer='word', lowercase=True,\n                                 ngram_range=(1,n))\n\n    x_train_lemma = vectorizer.fit_transform(df_train['clean_text_lemma'])\n    y_train_lemma = df_train['source']\n    x_test_lemma = vectorizer.transform(df_test['clean_text_lemma'])\n    y_test_lemma = df_test['source']\n    features_train = vectorizer.get_feature_names()\n    print(len(features_train))\n    \n# Start timing\n    start = timeit.default_timer()\n\n#Initialize and fit\n    nb = MultinomialNB()\n    nb.fit(x_train_lemma, y_train_lemma)\n\n# Apply to testing data\n    y_pred_lemma = nb.predict(x_test_lemma)\n\n# Stop timing\n    stop = timeit.default_timer()\n    nb_time = stop-start\n    print(\"Run time: %0.3f\" % (nb_time))\n\n# Showing model performance\n    print(\"Accuracy is: %0.3f\" % nb.score(x_test_lemma, y_test_lemma))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### As using different ngrams, there is no clear effect on the model prediction accuracy "},{"metadata":{},"cell_type":"markdown","source":"### Exploring more ml algorithms: SVC, Logistic regression, Random forest, and Gradient boosting"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train =  x_train_lemma\nY_train = y_train_lemma\nX_test = x_test_lemma \nY_test = y_test_lemma","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### SVC"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\n# Start timing\nstart = timeit.default_timer()\n\n# Create instance and fit\nsv = SVC(kernel='linear')\nsv.fit(X_train, Y_train)\n\n# Apply to testing data\ny_pred = sv.predict(X_test)\n\n# Stop timing\nstop = timeit.default_timer()\nsv_time = stop - start\nprint(\"Run time:%0.3f\" %sv_time)\n\n# Showing model performance\ncross = pd.crosstab(y_pred, Y_test)\nprint(\"Accuracy is: %0.3f\" % sv.score(X_test, Y_test))\nprint(metrics.classification_report(Y_test, y_pred, target_names=dataset_test.target_names))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### LogisticRegression"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\n# Start timing\nstart = timeit.default_timer()\n\nlr = LogisticRegression()\nlr.fit(X_train, Y_train)\n\ny_pred = lr.predict(X_test)\n\n# Stop timing\nstop = timeit.default_timer()\nlr_time = stop - start\nprint(\"Run time:%0.3f\" %sv_time)\n\n# Showing model performance\ncross = pd.crosstab(y_pred, Y_test)\nprint(\"Accuracy is: %0.3f\" % lr.score(X_test, Y_test))\nprint(metrics.classification_report(Y_test, y_pred, target_names=dataset_test.target_names));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### GradientBoosting"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import ensemble\n\n# Start timing\nstart = timeit.default_timer()\n\ngbc = ensemble.GradientBoostingClassifier()\ngbc.fit(X_train, Y_train)\n\npred = gbc.predict(X_test)\n\n# Stop timing\nstop = timeit.default_timer()\ngbc_time = stop - start\nprint(\"Run time:%0.3f\" %sv_time)\n\n# Showing model performance\ncross = pd.crosstab(y_pred, Y_test)\nprint(\"Accuracy is: %0.3f\" % gbc.score(X_test, Y_test))\nprint(metrics.classification_report(Y_test, y_pred, target_names=dataset_test.target_names))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### RandomForest"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import ensemble\n\n# Start timing\nstart = timeit.default_timer()\n\nrfc = ensemble.RandomForestClassifier()\nrfc.fit(X_train, Y_train)\n\ny_pred = rfc.predict(X_test)\n\n# Stop timing\nstop = timeit.default_timer()\nrfc_time = stop - start\nprint(\"Run time:%0.3f\" %rfc_time)\n\n# Showing model performance\ncross = pd.crosstab(y_pred, Y_test)\nprint(\"Accuracy is: %0.3f\" % rfc.score(X_test, Y_test))\nprint(\"Accuracy is: %0.3f\" % rfc.score(X_train, Y_train))\nprint(metrics.classification_report(Y_test, y_pred, target_names=dataset_test.target_names));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = [0.671,0.658,0.678,0.594,0.534]\n\nlabels = ['Naive Bayes', 'SVC', 'Logistic regression', 'Gradient boosting','Random forest']\nx = np.arange(len(labels))  # the label locations\nwidth = 0.3  # the width of the bars\nfig, ax = plt.subplots(1, 1,  figsize=(10, 4))\ng1 = ax.bar(x, accuracy, width, label='Model accuracy')\n\nax.set_ylabel('Model accuracy')\nax.set_title('Comparison for different ML algorithms')\nax.set_xticks(x)\nax.set_xticklabels(labels, rotation=50)\nax.set_ylim(0, 1)\nax.legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Summary: naive bayes and logistice regression performs the best in terms of model prediction accuracy. However, naive bayes running much faster than any other ML models, therefore should be the best algorithms for this test."},{"metadata":{},"cell_type":"markdown","source":"### Inspecting the top words calcualted by Naive_bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_top10(classifier, vectorizer, categories):\n    feature_names = np.asarray(vectorizer.get_feature_names())\n    for i, category in enumerate(categories):\n        top10 = np.argsort(classifier.coef_[i])[-10:]\n        print(\"%s: %s\" % (category, \" \".join(feature_names[top10])))\n        \na = show_top10(nb, vectorizer, dataset.target_names)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### There are seems five main fields that the news groups trying to focus: computer, recreation, science, religion and politics. Different new groups that reporting the same fields tend to use very similar words, therefore it makes the prediction very hard to distinguish different new groups in the same fields."},{"metadata":{},"cell_type":"markdown","source":"### Text extraction: lsa, lda, and nnmf"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of topics.\nntopics=20\n\n# Linking words to topics\ndef word_topic(tfidf, solution, wordlist):\n    \n    # Loading scores for each word on each topic/component.\n    words_by_topic=tfidf.T * solution\n\n    # Linking the loadings to the words in an easy-to-read way.\n    components=pd.DataFrame(words_by_topic,index=wordlist)\n\n    return components\n    \n# Extracts the top N words and their loadings for each topic.\ndef top_words(components, n_top_words):\n    n_topics = range(components.shape[1])\n    index= np.repeat(n_topics, n_top_words, axis=0)\n    topwords=pd.Series(index=index)\n    for column in range(components.shape[1]):\n        # Sort the column so that highest loadings are at the top.\n        sortedwords=components.iloc[:,column].sort_values(ascending=False)\n        # Choose the N highest loadings.\n        chosen=sortedwords[:n_top_words]\n        # Combine loading and index into a string.\n        chosenlist=chosen.index +\" \"+round(chosen,2).map(str) \n        topwords.loc[column]=[x for x in chosenlist]\n    return(topwords)\n\n# Number of words to look at for each topic.\nn_top_words = 10","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Since we know there are totally 20 news groups, we will use this number now. However, for unsupervised learn, we have to try different numbers and inpect the clusters."},{"metadata":{},"cell_type":"markdown","source":"### LSA"},{"metadata":{"trusted":true},"cell_type":"code","source":"terms = vectorizer.get_feature_names()\n\nsvd= TruncatedSVD(ntopics)\nlsa = make_pipeline(svd, Normalizer(copy=False))\nnews_group_lsa = lsa.fit_transform(x_train_lemma)\n\ncomponents_lsa = word_topic(x_train_lemma, news_group_lsa, terms)\n\ntopwords=pd.DataFrame()\ntopwords['LSA']=top_words(components_lsa, n_top_words) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### LDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import LatentDirichletAllocation as LDA\n\nlda = LDA(n_components=ntopics, \n          doc_topic_prior=None, # Prior = 1/n_documents\n          topic_word_prior=1/ntopics,\n          learning_decay=0.7, # Convergence rate.\n          learning_offset=10.0, # Causes earlier iterations to have less influence on the learning\n          max_iter=10, # when to stop even if the model is not converging (to prevent running forever)\n          evaluate_every=-1, # Do not evaluate perplexity, as it slows training time.\n          mean_change_tol=0.001, # Stop updating the document topic distribution in the E-step when mean change is < tol\n          max_doc_update_iter=100, # When to stop updating the document topic distribution in the E-step even if tol is not reached\n          n_jobs=-1, # Use all available CPUs to speed up processing time.\n          verbose=0, # amount of output to give while iterating\n          random_state=0\n         )\n\nnews_group_lda = lda.fit_transform(x_train_lemma) \n\ncomponents_lda = word_topic(x_train_lemma, news_group_lda, terms)\n\ntopwords['LDA']=top_words(components_lda, n_top_words)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### NNMF"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import NMF\n\nnmf = NMF(alpha=0.0, \n          init='nndsvdar', # how starting value are calculated\n          l1_ratio=0.0, # Sets whether regularization is L2 (0), L1 (1), or a combination (values between 0 and 1)\n          max_iter=200, # when to stop even if the model is not converging (to prevent running forever)\n          n_components=ntopics, \n          random_state=0, \n          solver='cd', # Use Coordinate Descent to solve\n          tol=0.0001, # model will stop if tfidf-WH <= tol\n          verbose=0 # amount of output to give while iterating\n         )\nnews_group_nmf = nmf.fit_transform(x_train_lemma) \n\ncomponents_nmf = word_topic(x_train_lemma, news_group_nmf, terms)\n\ntopwords['NNMF']=top_words(components_nmf, n_top_words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for topic in range(ntopics):\n    print('Topic {}:'.format(topic))\n    print(topwords.loc[topic])\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Inspecting the weight of word in different topics"},{"metadata":{"trusted":true},"cell_type":"code","source":"# The words to look at.\ntargetwords=['god','file','game','motor']\n\n# Storing the loadings.\nwordloadings=pd.DataFrame(columns=targetwords)\n\n# For each word, extracting and string the loadings for each method.\nfor word in targetwords:\n    loadings=components_lsa.loc[word].append(\n        components_lda.loc[word]).append(\n            components_nmf.loc[word])\n    wordloadings[word]=loadings\n\n# Labeling the data by method and providing an ordering variable for graphing purposes. \nwordloadings['method']=np.repeat(['LSA','LDA','NNMF'], 20, axis=0)\nwordloadings['loading']=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]*3\n\nsns.set(style=\"darkgrid\")\n\nfor word in targetwords:\n    sns.barplot(x=\"method\", y=word, hue=\"loading\", data=wordloadings)\n    plt.title(word)\n    plt.ylabel(\"\")\n#     plt.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Summary: for the first 4 words, LDA and NNMF showed a more clearly emphasizing on one particle topics than LSA. For the word 'motor', it seems LSA works better in classifying the topics."},{"metadata":{},"cell_type":"markdown","source":"### Unsupervised learning with LSA: KMeans and GaussianMixture"},{"metadata":{"trusted":true},"cell_type":"code","source":"# kmean\nx_norm = normalize(news_group_lsa)\n\nkmeans = KMeans(n_clusters=20, random_state=123)\ny_predict = kmeans.fit_predict(x_norm)\n\n# Check the solution against the data.\nprint('Comparing k-means clusters against news groups:')\nprint(pd.crosstab(Y_train, y_predict))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# GaussianMixtureModel\nfrom sklearn.mixture import GaussianMixture\n\ngmm_cluster = GaussianMixture(n_components=20, random_state=123)\nclusters = gmm_cluster.fit_predict(news_group_lsa)\n\n# Check the solution against the data.\nprint('Comparing k-means clusters against news groups:')\nprint(pd.crosstab(Y_train, clusters))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Summary: it seems both kmeans and GaussianMixtureModel does not work very well"},{"metadata":{},"cell_type":"markdown","source":"### Text summarization"},{"metadata":{},"cell_type":"markdown","source":"### Selecting 3 news_groups and choosing the highest score sentence to summarize the text"},{"metadata":{"trusted":true},"cell_type":"code","source":"for news_group in ['rec.autos','rec.sport.baseball','talk.politics.mideast']:\n\n    auto = df_train[df_train['label']== news_group]['text'][:50]\n    auto_str = ' '.join(auto)\n\n\n# Importing the text the lazy way.\n    text = auto_str\n\n# We want to use the standard english-language parser.\n    parser = spacy.load('en')\n    \n# Parsing Gatsby.\n    text = parser(text)\n\n# Dividing the text into sentences and storing them as a list of strings.\n    sentences=[]\n    for span in text.sents:\n    # go from the start to the end of each span, returning each token in the sentence\n    # combine each token using join()\n        sent = ''.join(text[i].string for i in range(span.start, span.end)).strip()\n        sentences.append(sent)\n\n# Creating the tf-idf matrix.\n    counter = TfidfVectorizer(lowercase=False, \n                              stop_words=None,\n                              ngram_range=(1, 1), \n                              analyzer=u'word', \n                              max_df=.5, \n                              min_df=1,\n                              max_features=None, \n                              vocabulary=None, \n                              binary=False)\n\n#Applying the vectorizer\n    data_counts=counter.fit_transform(sentences)\n    \n# Calculating similarity\n    similarity = data_counts * data_counts.T\n\n# Identifying the sentence with the highest rank.\n    nx_graph = nx.from_scipy_sparse_matrix(similarity)\n    ranks=nx.pagerank(nx_graph, alpha=.85, tol=.00000001)\n\n    ranked = sorted(((ranks[i],s) for i,s in enumerate(sentences)),\n                reverse=True)\n    print('Topic: {}'.format(news_group))\n    print(ranked[0])\n    print()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Summary: from the sentence selected by each news_group, it seems can be used for identifying the field of news very well."},{"metadata":{},"cell_type":"markdown","source":"### word2vec"},{"metadata":{"trusted":true},"cell_type":"code","source":"import string\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"news_lines=list()\nlines = df_train['clean_text_lemma'].values.tolist()\n\nfor line in lines:\n    tokens = word_tokenize(line)\n    \n    tokens = [w.lower() for w in tokens]\n    \n    table = str.maketrans('', '', string.punctuation)\n    stripped = [w.translate(table) for w in tokens]\n    \n    words = [word for word in stripped if word.isalpha()]\n    \n    stop_words = set(stopwords.words('english'))\n    words = [w for w in words if not w in stop_words]\n    news_lines.append(words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gensim\n# from gensim.models import Word2Vec\n\nmodel = gensim.models.Word2Vec(sentences=news_lines, window=5, workers=4, min_count=5)\n# model=Word2Vec(sentences=review_lines)\n\nwords = list(model.wv.vocab)\nprint('vocabulary size: %d' % len(words))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Exploring the similarities between different words"},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab = model.wv.vocab.keys()\n\nprint(model.wv.most_similar(positive=['hard', 'drive', 'floppy'], negative=['god']))\n\n# Similarity is calculated using the cosine, so again 1 is total\n# similarity and 0 is no similarity.\nprint(model.wv.similarity('drive', 'floppy'))\nprint(model.wv.similarity('drive', 'think'))\n\n# One of these things is not like the other...\nprint(model.doesnt_match(\"hard disk drive think\".split()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Finding the most similar and dissimilar words"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model.wv.most_similar(negative=[\"floppy\"]))\nprint()\nprint(model.wv.most_similar(positive=[\"floppy\"]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Plotting similar and dissimilar words in a 2-D plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n \nimport seaborn as sns\nsns.set_style(\"darkgrid\")\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tsnescatterplot(model, word, list_names):\n    \"\"\" Plot in seaborn the results from the t-SNE dimensionality reduction algorithm of the vectors of a query word,\n    its list of most similar words, and a list of words.\n    \"\"\"\n    arrays = np.empty((0, 100), dtype='f')\n    word_labels = [word]\n    color_list  = ['red']\n\n    # adds the vector of the query word\n    arrays = np.append(arrays, model.wv.__getitem__([word]), axis=0)\n    \n    # gets list of most similar words\n    close_words = model.wv.most_similar([word])\n    \n    # adds the vector for each of the closest words to the array\n    for wrd_score in close_words:\n        wrd_vector = model.wv.__getitem__([wrd_score[0]])\n        word_labels.append(wrd_score[0])\n        color_list.append('blue')\n        arrays = np.append(arrays, wrd_vector, axis=0)\n    \n    # adds the vector for each of the words from list_names to the array\n    for wrd in list_names:\n        wrd_vector = model.wv.__getitem__([wrd])\n        word_labels.append(wrd)\n        color_list.append('green')\n        arrays = np.append(arrays, wrd_vector, axis=0)\n        \n    # Reduces the dimensionality from 19 to 10 dimensions with PCA\n    reduc = PCA(n_components=10).fit_transform(arrays)\n    \n    # Finds t-SNE coordinates for 2 dimensions\n    np.set_printoptions(suppress=True)\n    \n    Y = TSNE(n_components=2, random_state=0, perplexity=15).fit_transform(reduc)\n    \n    # Sets everything up to plot\n    df = pd.DataFrame({'x': [x for x in Y[:, 0]],\n                       'y': [y for y in Y[:, 1]],\n                       'words': word_labels,\n                       'color': color_list})\n    \n    fig, _ = plt.subplots()\n    fig.set_size_inches(9, 9)\n    \n    # Basic plot\n    p1 = sns.regplot(data=df,\n                     x=\"x\",\n                     y=\"y\",\n                     fit_reg=False,\n                     marker=\"o\",\n                     scatter_kws={'s': 40,\n                                  'facecolors': df['color']\n                                 }\n                    )\n    \n    # Adds annotations one by one with a loop\n    for line in range(0, df.shape[0]):\n         p1.text(df[\"x\"][line],\n                 df['y'][line],\n                 '  ' + df[\"words\"][line].title(),\n                 horizontalalignment='left',\n                 verticalalignment='bottom', size='medium',\n                 color=df['color'][line],\n                 weight='normal'\n                ).set_size(15)\n\n    \n    plt.xlim(Y[:, 0].min()-50, Y[:, 0].max()+50)\n    plt.ylim(Y[:, 1].min()-50, Y[:, 1].max()+50)\n            \n    plt.title('t-SNE visualization for {}'.format(word.title()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tsnescatterplot(model, 'floppy', ['dog', 'bird', 'good', 'make', 'bob', 'mel', 'apple', 'duff'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tsnescatterplot(model, 'floppy', [i[0] for i in model.wv.most_similar(negative=[\"floppy\"])]);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Summary: word2vec works very well to identify similar words or extract words which are different from others"},{"metadata":{},"cell_type":"markdown","source":"## Conclusion:"},{"metadata":{},"cell_type":"markdown","source":"* As applying stemming or lemmatization to the text did not alter the machine learning model accuracy significantly\n* Model results did not changed much as using different ngrams in the vectorization step\n* Various supervised machine learning models were studied and Naive_Bayes seems worked best interms of model accuracy and efficiency\n* The top words calucated by Naive_Bayes model seems highly correlated with their corresponding news groups\n* Text extraction were performed using LSA, LDA, and NNMF, and they showed clearly different performace for different topics\n* Unsupervised learning: KMeans and GaussianMixtureModel were explorated in this project and both of them are not promising for identifying news groups\n* Text summarization techniques were used and it seems works well for select the most representative sentence\n* Word2vec has worked successfully for finding similar and dissimilar words "},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":4}