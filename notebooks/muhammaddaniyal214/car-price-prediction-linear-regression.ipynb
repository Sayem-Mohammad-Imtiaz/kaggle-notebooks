{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"05-05-2021\n\nIn this model Linear Regression model is used to Predict Car Prices.\nSteps:\n1. Understanding the Data and Check for Missing values if any\n2. Data Cleaning - Data Cleaning is the primmary step for any ML problem, if your data is not cleaned it will affect your model's accuracy\n3. Check Correlations\n4. Data Preparation - Make sure you don't have multicollinearity using Pearson-coeff and P_value\n5. Model Building and evaluation","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reading the Data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/car-price-prediction/CarPrice_Assignment.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Checking Null values","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Cleaning","metadata":{}},{"cell_type":"markdown","source":"Data cleaning is required especially in 'Car Names' column. Because we have spelling mistakes in them, also same brands are written in different way like volkswagen is also written as vw. So, we have to correct them","metadata":{}},{"cell_type":"code","source":"df['CarName'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df['CarName'].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I am using regular expression technique in replace method. This saves lot of time otherwise you have to write individually for each name to be replaced.","metadata":{}},{"cell_type":"code","source":"df['CarName'].replace(to_replace=r'alf.+', value='alfa', regex=True, inplace=True),\ndf['CarName'].replace(to_replace=r'aud.+', value='audi', regex=True, inplace=True),\ndf['CarName'].replace(to_replace=r'bmw.+', value='bmw', regex=True, inplace=True),\ndf['CarName'].replace(to_replace=r'chev.+', value='chevrolet', regex=True, inplace=True),\ndf['CarName'].replace(to_replace=r'dodge.+', value='dodge', regex=True, inplace=True),\ndf['CarName'].replace(to_replace=r'hondci.+', value='civic', regex=True, inplace=True),\ndf['CarName'].replace(to_replace=r'hondacc.+', value='accord', regex=True, inplace=True),\ndf['CarName'].replace(to_replace=r'j.+', value='jaguar', regex=True, inplace=True),\ndf['CarName'].replace(to_replace=r'isuz.+', value='isuzu', regex=True, inplace=True),\ndf['CarName'].replace(to_replace=r'max.+', value='mazda', regex=True, inplace=True),\ndf['CarName'].replace(to_replace=r'maz.+', value='mazda', regex=True, inplace=True),\ndf['CarName'].replace(to_replace=r'buic.+', value='buick', regex=True, inplace=True),\ndf['CarName'].replace(to_replace=r'mitsu.+', value='mitsubishi', regex=True, inplace=True),\ndf['CarName'].replace(to_replace=r'N.+', value='nissan', regex=True, inplace=True),\ndf['CarName'].replace(to_replace=r'niss.+', value='nissan', regex=True, inplace=True),\ndf['CarName'].replace(to_replace=r'peug.+', value='peugeot', regex=True, inplace=True),\ndf['CarName'].replace(to_replace=r'ply.+', value='plymouth', regex=True, inplace=True),\ndf['CarName'].replace(to_replace=r'por.+', value='porsche', regex=True, inplace=True),\ndf['CarName'].replace(to_replace=r'ren.+', value='renault', regex=True, inplace=True),\ndf['CarName'].replace(to_replace=r'saab.+', value='saab', regex=True, inplace=True),\ndf['CarName'].replace(to_replace=r'suba.+', value='subaru', regex=True, inplace=True),\ndf['CarName'].replace(to_replace=r'toyota corol.+', value='toyota corolla', regex=True, inplace=True),\ndf['CarName'].replace(to_replace=r'toyota coron.+', value='toyota corona', regex=True, inplace=True),\ndf['CarName'].replace(to_replace=r'toyota cel.+', value='toyota celica', regex=True, inplace=True),\ndf['CarName'].replace(to_replace=r'volk.+', value='volkswagen', regex=True, inplace=True),\ndf['CarName'].replace(to_replace=r'voks.+', value='volkswagen', regex=True, inplace=True),\ndf['CarName'].replace(to_replace=r'volv.+', value='volvo', regex=True, inplace=True),\ndf['CarName'].replace(to_replace=r'vw.+', value='volkswagen', regex=True, inplace=True),\ndf['CarName'].replace(to_replace=r'honda a.+', value='honda accord', regex=True, inplace=True),\ndf['CarName'].replace(to_replace=r'honda c.+', value='honda civic', regex=True, inplace=True),","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['CarName'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df['CarName'].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preparation","metadata":{}},{"cell_type":"markdown","source":"I will check Pearson Correlation to investigate the linear relationship between two continuous variables. If the features have a weak relationship with the price, I will drop from the dataset.\n\nI will also check P-value to analyze the correlation is statistically significant or not. It is generally accepted that if the value is above 0.05, the correlation is not significant. If it is below 0.05, the correlation is significant.","metadata":{}},{"cell_type":"code","source":"from scipy import stats\n\nnum_columns = df.select_dtypes(exclude='object').columns\n\nfor i in list(num_columns):\n    pearson_coeff, p_value = stats.pearsonr(df[i], df['price'])\n    print(i.capitalize())\n    print(f'Pearson Co-relation: {pearson_coeff}')\n    print(f'P-Value: {p_value}')\n    if p_value<0.05:\n        print('Correlation is Significant')\n    else:\n        print('Correlation is Insignificant')\n    print('')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"drop = []\nfor i in list(num_columns):\n    pearson_coeff, p_value = stats.pearsonr(df[i], df['price'])\n    if p_value > 0.05:\n        drop.append(i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"drop","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Symboling, Carheight, Stroke, Compressionratio, Peakrpm has a weak relationship with Price. The correlation between these variables and the price is not statistically significant. I will drop them from the dataset.\n\nWheelbase, Boreratio has a moderate relationship with Price. The correlation is statistically significant.\n\nCarlength, Carwidth, Curbweight, Enginesize, Horsepower has a strong positive relationship with Price. The correlation is statistically significant.\n\nCitympg, Highwaympg has a strong negative relationship with Price. The correlation is statistically significant.","metadata":{}},{"cell_type":"code","source":"df.drop(drop, axis=1, inplace=True)\ndf.drop('doornumber', axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I will add \"cars category\" column to the dataset according to car prices. I will group cars as budget friendly, medium range, expensive cars. I will drop \"cars name\" column as I will add \"cars category\" column.","metadata":{}},{"cell_type":"code","source":"data_new = df.copy()\ncat_price = data_new.groupby('CarName')['price'].mean()\n\ndata_new = data_new.merge(cat_price.reset_index(), how = 'left', on = 'CarName')\n\nbins = [0,10000,20000,40000]\nlabel =['Budget_Friendly','Medium_Range','Expensive_Cars']\n\ndf['Category'] = pd.cut(data_new['price_y'], bins, right=False, labels=label)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I will convert categorical variables to numerical variables. Categorical variables in the dataset are nominal. I can apply OneHotEncoder.","metadata":{}},{"cell_type":"code","source":"df.drop('CarName', axis=1,  inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"column = ['fueltype','aspiration','carbody', 'drivewheel', \n          'enginelocation', 'enginetype','cylindernumber', \n          'fuelsystem', 'Category']\ndummies = pd.get_dummies(df[column], drop_first = True)\ndf = pd.concat([df, dummies], axis = 1)\ndf.drop(column, axis = 1, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Rescaling","metadata":{}},{"cell_type":"markdown","source":"Ordinary Least Squares method does not make normality assumptions about the data. It makes normality assumptions about the residuals. I will not transform the data to ensure Gaussian distribution.\n\nOn the other hand, linear regression is sensitive to outliers. Quantile Transformer is robust to outliers. It will transform the variables and handle the outliers in the dataset.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import QuantileTransformer\n\ntransform = QuantileTransformer(n_quantiles=205)\ncolumns = ['wheelbase', 'carlength', 'carwidth', 'curbweight','enginesize',\n           'boreratio','horsepower','citympg','highwaympg','price']\ndf[columns] = transform.fit_transform(df[columns]) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.columns.values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Correlation Between Variables","metadata":{}},{"cell_type":"markdown","source":"Linear regression assumes the independent variables are not related with each other. If the correlation degree is high, it will cause problems when we fit the model.\n\nTo check multicollinearity, I will use heatmap and VIF.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (40, 40))\nsns.heatmap(df.corr(method ='pearson'), cmap='PuBu', annot=True, linewidths=.5)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.corr(method ='pearson').unstack().sort_values().drop_duplicates()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Multicollinearity exists among predictors. After even transforming the variables, there is a strong relationships between independent variables. For this reason, I will use Variation Inflation Factor (VIF) to detect multicollinearity and to eliminate these variables from the dataset.","metadata":{}},{"cell_type":"markdown","source":"### Checking Pearson Correlation","metadata":{}},{"cell_type":"markdown","source":"Before eliminating correlated variables, I will check Pearson Correlation and p values. I will eliminate the features based on the accordingly.","metadata":{}},{"cell_type":"code","source":"data = list(df.columns)\n\nfor i in data:\n    pearson_coeff, p_value = stats.pearsonr(df[i], df['price'])\n    print(i.capitalize())\n    print(f'Pearson Co-relation: {pearson_coeff}')\n    print(f'P-Value: {p_value}')\n    if p_value<0.05:\n        print('Correlation is Significant')\n    else:\n        print('Correlation is Insignificant')\n        df.drop(i, axis=1, inplace=True)\n    print('')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Variance Inflation Factor(VIF)","metadata":{}},{"cell_type":"markdown","source":"A variance inflation factor(VIF) detects multicollinearity in regression analysis. I will select the features with VIF that is below 10.","metadata":{}},{"cell_type":"code","source":"X =  df.drop('price', axis=1)\ny = df['price']\n\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = pd.DataFrame()\nvif['variables'] = X.columns\n\nvif['vif'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n    \nfor index,column in enumerate(X.columns):\n    print(index, column, vif['vif'][index])\n    if vif['vif'][index] > 10:\n        vif = vif.drop([index], axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Building the Model","metadata":{}},{"cell_type":"code","source":"columns = list(vif['variables'])\n\ndata = df[columns]\ndata = pd.concat([data, df['price']], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = data.drop('price', axis=1)\ny = data['price']\n\nX_train, X_test, y_train, y_test = train_test_split( X, y, train_size = 0.75, test_size=0.25, random_state=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\n\nmodel = LinearRegression().fit(X_train, y_train)\n\nprint(f'R Square Value of Test Data: {round(r2_score(y_test, model.predict(X_test))*100, 2)}%')\nprint(f'R Square Value of Train Data: {round(r2_score(y_train, model.predict(X_train))*100,2)}%')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}