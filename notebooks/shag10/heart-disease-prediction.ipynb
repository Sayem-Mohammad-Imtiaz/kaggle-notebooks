{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/heart-disease-uci/heart.csv\")\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Description and information**","metadata":{}},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking for Null values\ndata.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# **Data Analysis**\n\n**Feature Selection**\n\n1. Univariate Selction — Statistical tests may be used to pick certain features that have the best relationship to the performance variable. The scikit-learn library provides the SelectKBest class that can be used to select a specific number of features in a suite of different statistical tests.","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nX = data.iloc[:,0:13] \ny = data.iloc[:,-1]     \n#apply SelectKBest class to extract top best features\nbestfeatures = SelectKBest(score_func=chi2, k=10)\nfit = bestfeatures.fit(X,y)\ndfscores = pd.DataFrame(fit.scores_)\ndfcolumns = pd.DataFrame(X.columns)\n#concat two dataframes for better visualization \nfeatureScores = pd.concat([dfcolumns,dfscores],axis=1)\nfeatureScores.columns = ['Specs','Score']\n#print best features\nprint(featureScores.nlargest(12,'Score'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2.** **Feature Importance** — You can gain the significance of each feature of your dataset by using the Model Characteristics property.  \nFeature value gives you a score for every function of your results, the higher the score the more significant or appropriate the performance variable is.  \nWe will use the Extra Tree Classifier to extract the top features for the dataset.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\nmodel = ExtraTreesClassifier()\nmodel.fit(X,y)\nprint(model.feature_importances_) \n#plot graph of feature importances for better visualization\nfeat_importances = pd.Series(model.feature_importances_, index=X.columns)\nfeat_importances.nlargest(13).plot(kind='barh')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**3. Correlation Matrix with Heatmap** — Correlation indicates how the features are related to each other or to the target variable.  \nThe correlation may be positive (increase in one value of the feature increases the value of the target variable) or negative (increase in one value of the feature decreases the value of the target variable)  \nHeatmap makes it easy to classify the features are most relevant to the target variable, and we will plot the associated features of the heatmap using the seaborn library.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,10))\nsns.heatmap(data.corr(),annot=True,cmap=\"magma\",fmt='.2f')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Visualization**\n\nSeaborn","metadata":{}},{"cell_type":"code","source":"sns.set_style('darkgrid')\nsns.set_palette('Set2')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data1 = data.copy()\ndef chng(sex):\n    if sex == 0:\n        return 'female'\n    else:\n        return 'male'\ndata1['sex'] = data1['sex'].apply(chng)\ndef chng2(prob):\n    if prob == 0:\n        return 'Heart Disease'\n    else:\n        return 'No Heart Disease'\ndata['target'] = data1['target'].apply(chng2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Countplot\ndata1['target'] = data1['target'].apply(chng2)\nsns.countplot(data= data1, x='sex',hue='target')\nplt.title('Gender v/s target\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"sns.countplot(data= data1, x='cp',hue='target')\nplt.title('Chest Pain Type v/s target\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(data= data1, x='sex',hue='thal')\nplt.title('Gender v/s Thalassemia\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(data= data1, x='slope',hue='target')\nplt.title('Slope v/s Target\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(data= data1, x='exang',hue='thal')\nplt.title('exang v/s Thalassemia\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Boxplot\nsns.boxplot(data=data1,x='target',y='age')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(14,8))\nsns.violinplot(data=data1,x='ca',y='age',hue='target')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(data=data1,x='cp',y='thalach',hue='target')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,7))\nsns.boxplot(data=data1,x='fbs',y='trestbps',hue='target')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,7))\nsns.violinplot(data=data1,x='exang',y='oldpeak',hue='target')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,7))\nsns.boxplot(data=data1,x='slope',y='thalach',hue='target')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.violinplot(data=data1,x='thal',y='oldpeak',hue='target')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.violinplot(data=data1,x='target',y='thalach')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# PairPlot\nsns.pairplot(data,hue='cp')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Classification Tree**","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\nfrom sklearn.model_selection import train_test_split # Import train_test_split function\nfrom sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\nX = data.iloc[:,0:13] # Features\ny = data.iloc[:,13] # Target variable\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test\n# Create Decision Tree classifer object\nclf = DecisionTreeClassifier()\n# Train Decision Tree Classifer\nclf = clf.fit(X_train,y_train)\n#Predict the response for test dataset\ny_pred = clf.predict(X_test)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create Decision Tree classifer object\nclf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n# Train Decision Tree Classifer\nclf = clf.fit(X_train,y_train)\n#Predict the response for test dataset\ny_pred = clf.predict(X_test)\n# Model Accuracy, how often is the classifier correct?\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Pre-processing**  \n\nWe have 4 Categorical columns as seen in Data Description using pandas profiling:  \n1. cp — chest_pain_type  \n2. restecg — rest_ecg_type  \n3. slope — st_slope_type  \n4. thal — thalassemia_type  ","metadata":{}},{"cell_type":"code","source":"#Change Name of the column\ndata.columns = ['age', 'sex', 'chest_pain_type', 'resting_blood_pressure', 'cholesterol', 'fasting_blood_sugar', 'rest_ecg_type', 'max_heart_rate_achieved',\n       'exercise_induced_angina', 'st_depression', 'st_slope_type', 'num_major_vessels', 'thalassemia_type', 'target']\ndata.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generating categorical columns values\n#cp - chest_pain_type\ndata.loc[data['chest_pain_type'] == 0, 'chest_pain_type'] = 'asymptomatic'\ndata.loc[data['chest_pain_type'] == 1, 'chest_pain_type'] = 'atypical angina'\ndata.loc[data['chest_pain_type'] == 2, 'chest_pain_type'] = 'non-anginal pain'\ndata.loc[data['chest_pain_type'] == 3, 'chest_pain_type'] = 'typical angina'\n#restecg - rest_ecg_type\ndata.loc[data['rest_ecg_type'] == 0, 'rest_ecg_type'] = 'left ventricular hypertrophy'\ndata.loc[data['rest_ecg_type'] == 1, 'rest_ecg_type'] = 'normal'\ndata.loc[data['rest_ecg_type'] == 2, 'rest_ecg_type'] = 'ST-T wave abnormality'\n#slope - st_slope_type\ndata.loc[data['st_slope_type'] == 0, 'st_slope_type'] = 'downsloping'\ndata.loc[data['st_slope_type'] == 1, 'st_slope_type'] = 'flat'\ndata.loc[data['st_slope_type'] == 2, 'st_slope_type'] = 'upsloping'\n#thal - thalassemia_type\ndata.loc[data['thalassemia_type'] == 0, 'thalassemia_type'] = 'nothing'\ndata.loc[data['thalassemia_type'] == 1, 'thalassemia_type'] = 'fixed defect'\ndata.loc[data['thalassemia_type'] == 2, 'thalassemia_type'] = 'normal'\ndata.loc[data['thalassemia_type'] == 3, 'thalassemia_type'] = 'reversable defect'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#One Hot Encoding\ndummy = pd.get_dummies(data, drop_first=False)\ndummy.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_temp = dummy['thalassemia_type_fixed defect']\ndummy = pd.get_dummies(data, drop_first=True)\ndummy.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"frames = [dummy, data_temp]\nresult = pd.concat(frames,axis=1)\nresult.drop('thalassemia_type_nothing',axis=1,inplace=True)\nresultc = result.copy()# making a copy for further analysis","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Logistic Regression**  \n\n1. Gather columns\n2. Splitting Data  \n3. Normalization  \n4. Fitting into Model  \n5. Prediction  \n6. Model Evaluation","metadata":{}},{"cell_type":"code","source":"#Gather columns\nX = result.drop('target_No Heart Disease', axis = 1)\ny = result['target_No Heart Disease']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Splitting Data\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Normalization\nX_train=(X_train-np.min(X_train))/(np.max(X_train)-np.min(X_train)).values\nX_test=(X_test-np.min(X_test))/(np.max(X_test)-np.min(X_test)).values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fitting into Model\nfrom sklearn.linear_model import LogisticRegression\nlogre = LogisticRegression()\nlogre.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Prediction\ny_pred = logre.predict(X_test)\nactual = []\npredcition = []\nfor i,j in zip(y_test,y_pred):\n  actual.append(i)\n  predcition.append(j)\ndic = {'Actual':actual,\n       'Prediction':predcition\n       }\nresult  = pd.DataFrame(dic)\nimport plotly.graph_objects as go\n \nfig = go.Figure()\n \n \nfig.add_trace(go.Scatter(x=np.arange(0,len(y_test)), y=y_test,\n                    mode='markers+lines',\n                    name='Test'))\nfig.add_trace(go.Scatter(x=np.arange(0,len(y_test)), y=y_pred,\n                    mode='markers',name='Pred'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Model Evaluation\nfrom sklearn.metrics import accuracy_score\nprint(accuracy_score(y_test,y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nprint(confusion_matrix(y_test,y_pred))\nsns.heatmap(confusion_matrix(y_test,y_pred),annot=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ROC Score\nimport sklearn\nsklearn.metrics.roc_auc_score(y_test,y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_data = {'Actual Value':y_test, 'Predicted Value':y_pred}\nsubmission = pd.DataFrame(data=final_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission_lr.csv', index =False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}