{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Task for Today  \n***\n## Gender, Ethnicity, and Age Classification  \n\nGiven the face image data, let's see if we can correctly classify the **gender**, **ethnicity**, and **age** of a person.  \n  \nWe will use three different TensorFlow CNNs to make our predictions."},{"metadata":{},"cell_type":"markdown","source":"# Getting Started"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nfrom PIL import Image\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/age-gender-and-ethnicity-face-data-csv/age_gender.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop('img_name', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"{column: list(data[column].unique()) for column in ['gender', 'ethnicity', 'age']}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['age'] = pd.qcut(data['age'], q=4, labels=[0, 1, 2, 3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(data['pixels'][0].split(' ')))\nprint(np.sqrt(2304))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_pixels = 2304\nimg_height = 48\nimg_width = 48","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_columns = ['gender', 'ethnicity', 'age']\n\ny = data[target_columns]\nX = data.drop(target_columns, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pd.Series(X['pixels'])\nX = X.apply(lambda x: x.split(' ')) # Get array of pixels\nX = X.apply(lambda x: np.array(list(map(lambda z: np.int(z), x)))) # Turn all pixels into type int\nX = np.array(X) # Make array a numpy array \nX = np.stack(np.array(X), axis=0) # Rearange the numpy arrays from many small arrays to fewer I think. \n                                  # Ex.: [array([1,4,2 ..., 7]), array([...]),] => [[[1,4,2 ..., 7], [...]]]\nX = np.reshape(X, (-1, 48, 48)) # Reshape the array to same amounts of columns (images), but each image should be 48x48 because of image size\nX.shape # (length, 48, 48)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 10))\n\nfor index, image in enumerate(np.random.randint(2000, 3000, 9)):\n    plt.subplot(3, 3, index + 1)\n    plt.imshow(X[image])\n#     plt.axis('off')\n    plt.xlabel(\n        \"Age:\"+str(y['age'].iloc[index])+\n        \"  Ethnicity:\"+str(y['ethnicity'].iloc[index])+\n        \"  Gender:\"+ str(y['gender'].iloc[index])\n    )\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_gender = np.array(y['gender'])\ny_ethnicity = np.array(y['ethnicity'])\ny_age = np.array(y['age'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(num_classes, activation='softmax', loss='sparse_categorical_crossentropy'):\n    \n    inputs = tf.keras.Input(shape=(img_height, img_width, 1))\n    x = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)(inputs)\n    x = tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu')(x)\n    x = tf.keras.layers.MaxPooling2D()(x)\n    x = tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu')(x)\n    x = tf.keras.layers.MaxPooling2D()(x)\n    x = tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n    x = tf.keras.layers.MaxPooling2D()(x)\n    x = tf.keras.layers.Flatten()(x)\n    x = tf.keras.layers.Dense(128, activation='relu')(x)\n    outputs = tf.keras.layers.Dense(num_classes, activation=activation)(x)\n    \n    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n    \n    \n    model.compile(\n        optimizer='adam',\n        loss=loss,\n        metrics=['accuracy']\n    )\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"{column: list(data[column].unique()) for column in ['gender', 'ethnicity', 'age']}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_gender_train, X_gender_test, y_gender_train, y_gender_test = train_test_split(X, y_gender, train_size=0.7)\nX_ethnicity_train, X_ethnicity_test, y_ethnicity_train, y_ethnicity_test = train_test_split(X, y_ethnicity, train_size=0.7)\nX_age_train, X_age_test, y_age_train, y_age_test = train_test_split(X, y_age, train_size=0.7)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Gender Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"gender_model = build_model(1, activation='sigmoid', loss='binary_crossentropy')\n\ngender_history = gender_model.fit(\n    X_gender_train,\n    y_gender_train,\n    validation_split=0.2,\n    batch_size=64,\n    epochs=7,\n    callbacks=[tf.keras.callbacks.ReduceLROnPlateau()],\n    verbose=1\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.line(\n    gender_history.history,\n    y=['loss', 'val_loss'],\n    labels={'index': \"Epoch\", 'value': \"Loss\"},\n    title=\"Gender Model\"\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gender_acc = gender_model.evaluate(X_gender_test, y_gender_test)[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gender_model.evaluate(X_gender_test, y_gender_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Test model with own images (Predict)"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\ndef show_image(image):\n    plt.imshow(image)\n    plt.colorbar()\n    plt.grid(False)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sample image\nprediction_image = Image.open('../input/images/pia.jpg').convert('L') # Male, age 78\nshow_image(prediction_image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Input shape for one image: (1, 48, 48) => [[[row1],[row,2] ..., ]]\nprediction_image = np.asarray(prediction_image) \n# prediction_image = prediction_image[48:96,48:96]\nprint(prediction_image.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Picture of male with corresponding age group\nplt.figure()\nplt.imshow(X[9929])\nplt.colorbar()\nplt.grid(False)\nplt.show()\nprint(\"Age group: \", y['age'][9929])\nprint(\"Gender: \", y['gender'][9929]) # So male is 0 and female is 1 in gender","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using Keras ImageDataGenerator function. And divide all pixels in image by 255\ndatagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1./255,\n)\ndatagen","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a \"validation generator\", which we will later pass to the gender_model\nnew_generator = datagen.flow_from_directory(\n    '/kaggle/input/', # Path to images (for some reason adding 'images/' won't work)\n    target_size=(48, 48), # Make image 48x48 pixels\n    class_mode='binary', # Binary because the model outputs 1D binary labels,\n    batch_size=4,\n    color_mode='grayscale'\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let's transfer the images to class folders in the working directory"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport shutil","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# By putting the images in folders with class names, flow_from_directory will automatically infer the class names from the parent folders\nos.mkdir('./MALE')\nos.mkdir('./FEMALE')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Just copying the files into the proper folders\nshutil.copyfile('../input/images/Samuel-L-Jackson.jpg', './MALE/Samuel-L-Jackson.jpg')\nshutil.copyfile('../input/images/baby.jpg', './MALE/baby.jpg')\nshutil.copyfile('../input/images/paul_mccartney.jpg', './MALE/paul_mccartney.jpg')\nshutil.copyfile('../input/images/pia.jpg', './FEMALE/pia.jpg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using Keras ImageDataGenerator function. And divide all pixels in image by 255\ndatagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1./255,\n)\ndatagen","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a \"validation generator\", which we will later pass to the gender_model\nimage_generator = datagen.flow_from_directory(\n    './', # Using the working directory, which will create classes from all subfolders (i.e. MALE and FEMALE), and assign the respective classes to each image\n    target_size=(48, 48), # Make image 48x48 pixels\n    class_mode='binary', # Binary because the model outputs 1D binary labels,\n    color_mode='grayscale'\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_X, new_y = image_generator.next() # .next() allows us to grab the image batch (of size 4 in this case) and store the image data in new_X and the labels in new_y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_X.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### This seems to be the reason that we are having a hard time classifying the images.  \nSince the images are only 48x48 pixels, we lose a lot of quality and detail when we stretch the images to fit.  \nCompared to the image data in the original dataset, these ones are nearly unusable in their current state.  \nI recommend you crop the images to include only the face before feeding them into the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 10))\nfor i in range(len(new_X)):\n    plt.subplot(2, 2, i + 1)\n    plt.imshow(np.squeeze(new_X[i]))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_generator.class_indices # We can get the class labels that have been assigned to each name via .class_indices","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gender_model.predict(new_X) # The model predicts female for every image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gender_model.evaluate(new_X, new_y) # Which yields a 25% accuracy","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ethnicity Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ethnicity_model = build_model(5, activation='softmax', loss='sparse_categorical_crossentropy')\n\n# ethnicity_history = ethnicity_model.fit(\n#     X_ethnicity_train,\n#     y_ethnicity_train,\n#     validation_split=0.2,\n#     batch_size=64,\n#     epochs=8,\n#     callbacks=[tf.keras.callbacks.ReduceLROnPlateau()],\n#     verbose=0\n# )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fig = px.line(\n#     ethnicity_history.history,\n#     y=['loss', 'val_loss'],\n#     labels={'index': \"Epoch\", 'value': \"Loss\"},\n#     title=\"Ethnicity Model\"\n# )\n\n# fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ethnicity_acc = ethnicity_model.evaluate(X_ethnicity_test, y_ethnicity_test)[1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Age Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# age_model = build_model(4, activation='softmax', loss='sparse_categorical_crossentropy')\n\n# age_history = age_model.fit(\n#     X_age_train,\n#     y_age_train,\n#     validation_split=0.2,\n#     batch_size=64,\n#     epochs=7,\n#     callbacks=[tf.keras.callbacks.ReduceLROnPlateau()],\n#     verbose=0\n# )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fig = px.line(\n#     age_history.history,\n#     y=['loss', 'val_loss'],\n#     labels={'index': \"Epoch\", 'value': \"Loss\"},\n#     title=\"Age Model\"\n# )\n\n# fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# age_acc = age_model.evaluate(X_age_test, y_age_test)[1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"# fig = px.bar(\n#     x=[\"Gender\", \"Ethnicity\", \"Age\"],\n#     y=[gender_acc, ethnicity_acc, age_acc],\n#     labels={'x': \"\", 'y': \"Accuracy\"},\n#     color=[\"Gender\", \"Ethnicity\", \"Age\"],\n#     title=\"Model Performance\"\n# )\n\n# fig.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}