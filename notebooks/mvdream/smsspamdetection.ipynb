{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"message= pd.read_csv(\"../input/spam.csv\", encoding='ISO-8859-1')\nmessage.head()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5190e44e25e68816c8175ef268ec4f774864ad01"},"cell_type":"markdown","source":"Now we shoud remove null value from dataset. "},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"baf4fbb567c2ad032f22b3769f5103038016c43b"},"cell_type":"code","source":"message.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'],axis= 1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5114c13280320f235fef1de48b7f72b31cd1e2c8"},"cell_type":"code","source":"message.rename(columns={'v1':'label','v2':'messages'},inplace=True)\nmessage.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"13c09ca07b2865ce673fd8b5ea1d8e12218241b7"},"cell_type":"markdown","source":"**As we continue our analysis we want to start thinking about the features we are going to be using. This goes along with the general idea of feature engineering. The better your domain knowledge on the data, the better your ability to engineer more features from it. Feature engineering is a very large part of spam detection in general. I encourage you to read up on the topic!**\n\n**Let's make a new column to detect how long the text messages are:\n**"},{"metadata":{"trusted":true,"_uuid":"3070ca1e8de25812d1a6ae40e995617c753d27f0"},"cell_type":"code","source":"message['length'] = message['messages'].apply(len)\nmessage.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e91eda1d7cab8a18526a3013a876bbbb197bb29a"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"609e04d01f8c93a06fb0f275ea729312cad569bf"},"cell_type":"code","source":"message['length'].plot(bins=50, kind = 'hist')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8a77464259bf5f274342f86cf9188dbcc8856b09"},"cell_type":"code","source":"message.hist(columns='length',by='label', bins= 50 )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8c31261464f56cda7eb4e8b43316e36c9087fa31"},"cell_type":"markdown","source":" **Text - Preprocessing**"},{"metadata":{"_uuid":"c4e00a83ade07b4ce52eb21ed46b9b81cd1f00e2"},"cell_type":"markdown","source":""},{"metadata":{"trusted":true,"_uuid":"660fcc9da85bde65e5b1fb3232d4b31832416910"},"cell_type":"code","source":"from nltk.corpus import stopwords\nimport string","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b6584b740baa947665d35b1730b201ccd9a01fdc"},"cell_type":"code","source":"stopwords.words('english')[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3eba1a9cbac7e7c3c4c159acaf8d4277b9bef342"},"cell_type":"code","source":"def text_preprocess(mess):\n    nonpuc = [char for char in mess if char not in string.punctuation]\n    nonpuc = ''.join(nonpuc)\n    \n    return [word for word in nonpuc.split() if word.lower not in stopwords.words('english')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"808ac6e56bceec82b51a4301b7e04a4f7c9bca84"},"cell_type":"code","source":"text_preprocess(\"my name is it has  Mayur.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb70e7dea17245ad895c5204314a0dcd65e5ad01"},"cell_type":"code","source":"message['messages'].head(5).apply(text_preprocess)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"749d7548f151416c067cb374f81ba13e84820524"},"cell_type":"markdown","source":"**Vectorization**"},{"metadata":{"trusted":true,"_uuid":"7c4da91a13d86c4ee1fe322af26567479dcab455"},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nbow_trans = CountVectorizer(analyzer=text_preprocess).fit(message['messages'])\nprint(len(bow_trans.vocabulary_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5a07b0315fcd598e9a69e54c55e25d1e48bdd523"},"cell_type":"code","source":"messages_bow = bow_trans.transform(message['messages'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2110edbc46bfda492fddf9837cd8fb1f8efbb810"},"cell_type":"code","source":"print('Shape of Sparse Matrix: ', messages_bow.shape)\nprint('Amount of Non-Zero occurences: ', messages_bow.nnz)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"504cb47dc17c7bb9fce55ffd6ae8e24cdb445570"},"cell_type":"markdown","source":"**After the counting, the term weighting and normalization can be done with TF-IDF, using scikit-learn's TfidfTransformer.**"},{"metadata":{"trusted":true,"_uuid":"b78664ba3bf70b9b52916107d34955acd8bbb60e"},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfTransformer\ntfidf_transformer = TfidfTransformer().fit(messages_bow)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"458dd6b24ed6283bf943a1d17efcc7bd5a63e090"},"cell_type":"code","source":"messages_tfidf = tfidf_transformer.transform(messages_bow)\nprint(messages_tfidf.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6424c1658024f839e334e431f829d21e1a5179f3"},"cell_type":"markdown","source":"**Training a model**"},{"metadata":{"trusted":true,"_uuid":"c38ac8cacad83150d372b6dadbe3d42332264c16"},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nspam_detect_model = MultinomialNB().fit(messages_tfidf, message['label'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b454d0f74fea80f4238be27599d3c0479b9889b5"},"cell_type":"code","source":"from sklearn.metrics import classification_report\nall_predictions = spam_detect_model.predict(messages_tfidf)\nprint (classification_report(message['label'], all_predictions))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fde591a87ff2d56a5f1648d5b94edf1cc10f7f1d"},"cell_type":"markdown","source":"**You should never actually evaluate on the same dataset you train on!**"},{"metadata":{"_uuid":"2122e119f0ae70d29b7f9545f1e4ad28d4410fbe"},"cell_type":"markdown","source":"**Train Test Split**"},{"metadata":{"trusted":true,"_uuid":"5805bfa693dc05ae35207d696563e06f4c0c25fc"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nmsg_train, msg_test, label_train, label_test = \\\ntrain_test_split(message['messages'], message['label'], test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"99763691556829a876d483a5ae6a6845c5ef0251"},"cell_type":"markdown","source":"**Creating a Data Pipeline**\n\nLet's run our model again and then predict off the test set. We will use SciKit Learn's pipeline capabilities to store a pipeline of workflow. This will allow us to set up all the transformations that we will do to the data for future use. Let's see an example of how it works:"},{"metadata":{"trusted":true,"_uuid":"ba9c81df170be7c6a8118ebf968e724ad6a151ab"},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\n\npipeline = Pipeline([\n    ('bow', CountVectorizer(analyzer=text_preprocess)),  # strings to token integer counts\n    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ce8568d4560ce65ca3e08a1fba27b374fd6881f"},"cell_type":"code","source":"pipeline.fit(msg_train,label_train)\npredictions = pipeline.predict(msg_test)\nprint(classification_report(predictions,label_test))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}