{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv')\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Data Exploration","metadata":{}},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#unique values\nfor col in data.columns:\n    print(col,\": \",data[col].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Numbers of entries for each class\nstroke = len(data[data['stroke']==1])\nno_stroke = len(data[data['stroke']==0])\nprint(\"Stroke: \",len(data[data['stroke']==1]))\nprint(\"No Stroke: \",len(data[data['stroke']==0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Given that we have much more data for the class \"no stroke\", we can say that the dataset is highly imbalanced. ","metadata":{}},{"cell_type":"code","source":"#Number of entries for each gender category\nfor gen in data['gender'].unique():\n    print(gen,\": \",len(data[data['gender']==gen]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.subplot(1,2,1)\nplt.title('Stroke=1')\nax1 = sns.countplot(x=\"gender\", data=data[data[\"stroke\"]==1])\n\nplt.subplot(1,2,2)\nplt.title('Stroke=0')\nax2 = sns.countplot(x=\"gender\", data=data[data[\"stroke\"]==0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"No Stroke\")\nfor gen in data[data['stroke']==0]['gender'].unique():\n    print(gen,\": \",len(data.loc[(data['gender']==gen) & (data['stroke']==0)])/no_stroke)\n    \nprint(\"Stroke\")\nfor gen in data[data['stroke']==1]['gender'].unique():\n    print(gen,\": \",len(data.loc[(data['gender']==gen) & (data['stroke']==1)])/stroke)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is only one entry for other gender with no stroke. Comparing males and females, we can see there is a high percentage of females in the data. We cannot infer anything based on gender since females are having high number both for stroke and no stroke.","metadata":{}},{"cell_type":"code","source":"#Hypertension\nplt.subplot(1,2,1)\nplt.title('Stroke=1')\nax1 = sns.countplot(x=\"hypertension\", data=data[data[\"stroke\"]==1])\n\nplt.subplot(1,2,2)\nplt.title('Stroke=0')\nax2 = sns.countplot(x=\"hypertension\", data=data[data[\"stroke\"]==0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"No Stroke\")\nfor i in data[data['stroke']==0]['hypertension'].unique():\n    print(i,\": \",len(data.loc[(data['hypertension']==i) & (data['stroke']==0)])/no_stroke)\n    \nprint(\"Stroke\")\nfor i in data[data['stroke']==1]['hypertension'].unique():\n    print(i,\": \",len(data.loc[(data['hypertension']==i) & (data['stroke']==1)])/stroke)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The data has high percentage of people not having hypertension, although people having hypertension has a slightly higher chance of having stroke.","metadata":{}},{"cell_type":"code","source":"#Heart Disease\nplt.subplot(1,2,1)\nplt.title('Stroke=1')\nax1 = sns.countplot(x=\"heart_disease\", data=data[data[\"stroke\"]==1])\n\nplt.subplot(1,2,2)\nplt.title('Stroke=0')\nax2 = sns.countplot(x=\"heart_disease\", data=data[data[\"stroke\"]==0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"No Stroke\")\nfor i in data[data['stroke']==0]['heart_disease'].unique():\n    print(i,\": \",len(data.loc[(data['heart_disease']==i) & (data['stroke']==0)])/no_stroke)\n    \nprint(\"Stroke\")\nfor i in data[data['stroke']==1]['heart_disease'].unique():\n    print(i,\": \",len(data.loc[(data['heart_disease']==i) & (data['stroke']==1)])/stroke)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Again most of the people are not having heart_disease, but people having heart disease have slightly higher chance of having a stroke.","metadata":{}},{"cell_type":"code","source":"#Marital Status\nplt.subplot(1,2,1)\nplt.title('Stroke=1')\nax1 = sns.countplot(x=\"ever_married\", data=data[data[\"stroke\"]==1])\n\nplt.subplot(1,2,2)\nplt.title('Stroke=0')\nax2 = sns.countplot(x=\"ever_married\", data=data[data[\"stroke\"]==0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"No Stroke\")\nfor i in data[data['stroke']==0]['ever_married'].unique():\n    print(i,\": \",len(data.loc[(data['ever_married']==i) & (data['stroke']==0)])/no_stroke)\n    \nprint(\"Stroke\")\nfor i in data[data['stroke']==1]['ever_married'].unique():\n    print(i,\": \",len(data.loc[(data['ever_married']==i) & (data['stroke']==1)])/stroke)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is a higher percentage of married people, although married people have a higher chance of stroke.","metadata":{}},{"cell_type":"code","source":"#Work-type\nplt.subplot(1,2,1)\nplt.title('Stroke=1')\nax1 = sns.countplot(x=\"work_type\", data=data[data[\"stroke\"]==1])\n\nplt.subplot(1,2,2)\nplt.title('Stroke=0')\nax2 = sns.countplot(x=\"work_type\", data=data[data[\"stroke\"]==0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"No Stroke\")\nfor i in data[data['stroke']==0]['work_type'].unique():\n    print(i,\": \",len(data.loc[(data['work_type']==i) & (data['stroke']==0)])/no_stroke)\n    \nprint(\"Stroke\")\nfor i in data[data['stroke']==1]['work_type'].unique():\n    print(i,\": \",len(data.loc[(data['work_type']==i) & (data['stroke']==1)])/stroke)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Children and people who have never worked have a much lower chance of having a stroke. Again data is dominated by one category, people doing private jobs who have almost equal probability of having and not having a stroke. Self-employed people have a higher chances of stroke. ","metadata":{}},{"cell_type":"code","source":"#Residence type\nplt.subplot(1,2,1)\nplt.title('Stroke=1')\nax1 = sns.countplot(x=\"Residence_type\", data=data[data[\"stroke\"]==1])\n\nplt.subplot(1,2,2)\nplt.title('Stroke=0')\nax2 = sns.countplot(x=\"Residence_type\", data=data[data[\"stroke\"]==0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"No Stroke\")\nfor i in data[data['stroke']==0]['Residence_type'].unique():\n    print(i,\": \",len(data.loc[(data['Residence_type']==i) & (data['stroke']==0)])/no_stroke)\n    \nprint(\"Stroke\")\nfor i in data[data['stroke']==1]['Residence_type'].unique():\n    print(i,\": \",len(data.loc[(data['Residence_type']==i) & (data['stroke']==1)])/stroke)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"People living in urban areas have a higher chance of stroke compared to rural. ","metadata":{}},{"cell_type":"code","source":"#Smoking status\nplt.subplot(1,2,1)\nplt.title('Stroke=1')\nax1 = sns.countplot(x=\"smoking_status\", data=data[data[\"stroke\"]==1])\n\nplt.subplot(1,2,2)\nplt.title('Stroke=0')\nax2 = sns.countplot(x=\"smoking_status\", data=data[data[\"stroke\"]==0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"No Stroke\")\nfor i in data[data['stroke']==0]['smoking_status'].unique():\n    print(i,\": \",len(data.loc[(data['smoking_status']==i) & (data['stroke']==0)])/no_stroke)\n    \nprint(\"Stroke\")\nfor i in data[data['stroke']==1]['smoking_status'].unique():\n    print(i,\": \",len(data.loc[(data['smoking_status']==i) & (data['stroke']==1)])/stroke)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"People formerly smoked and never smoked have a higher chance of stroke than people who smokes or unkown.","metadata":{}},{"cell_type":"code","source":"#Age\n\nplt.subplot(1,3,1)\nn, bins, patches = plt.hist(x=data[data[\"stroke\"]==1][\"age\"], bins='auto', color='#0504aa',\n                            alpha=0.7, rwidth=0.85)\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.title('Visualizing effect of age')\nplt.text(23, 45,\"Stroke = 1\")\nmaxfreq = n.max()\nplt.ylim(ymax=np.ceil(maxfreq / 10) * 10 if maxfreq % 10 else maxfreq + 10)\nplt.show()\n\nplt.subplot(1,3,2)\nn, bins, patches = plt.hist(x=data[data[\"stroke\"]==0][\"age\"], bins='auto', color='#0504aa',\n                            alpha=0.7, rwidth=0.85)\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.title('Visualizing effect of age')\nplt.text(23, 75,\"Stroke = 0\")\nmaxfreq = n.max()\nplt.ylim(ymax=np.ceil(maxfreq / 10) * 10 if maxfreq % 10 else maxfreq + 10)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Stroke is more prevalent in older people, hence age can be a good feature for classification. ","metadata":{}},{"cell_type":"code","source":"#Average glucose level\n\nplt.subplot(1,3,1)\nn, bins, patches = plt.hist(x=data[data[\"stroke\"]==1][\"avg_glucose_level\"], bins='auto', color='#0504aa',\n                            alpha=0.7, rwidth=0.85)\nplt.xlabel('Avg Glucose Level')\nplt.ylabel('Frequency')\nplt.title('Visualizing effect of avg glucose level')\nplt.text(23, 45,\"Stroke = 1\")\nmaxfreq = n.max()\nplt.ylim(ymax=np.ceil(maxfreq / 10) * 10 if maxfreq % 10 else maxfreq + 10)\nplt.show()\n\nplt.subplot(1,3,2)\nn, bins, patches = plt.hist(x=data[data[\"stroke\"]==0][\"avg_glucose_level\"], bins='auto', color='#0504aa',\n                            alpha=0.7, rwidth=0.85)\nplt.xlabel('Avg Glucose Level')\nplt.ylabel('Frequency')\nplt.title('Visualizing effect of avg glucose level')\nplt.text(23, 75,\"Stroke = 0\")\nmaxfreq = n.max()\nplt.ylim(ymax=np.ceil(maxfreq / 10) * 10 if maxfreq % 10 else maxfreq + 10)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#BMI\n\nplt.subplot(1,3,1)\nn, bins, patches = plt.hist(x=data[data[\"stroke\"]==1][\"bmi\"], bins='auto', color='#0504aa',\n                            alpha=0.7, rwidth=0.85)\nplt.xlabel('BMI')\nplt.ylabel('Frequency')\nplt.title('Visualizing effect of BMI')\nplt.text(23, 45,\"Stroke = 1\")\nmaxfreq = n.max()\nplt.ylim(ymax=np.ceil(maxfreq / 10) * 10 if maxfreq % 10 else maxfreq + 10)\nplt.show()\n\nplt.subplot(1,3,2)\nn, bins, patches = plt.hist(x=data[data[\"stroke\"]==0][\"bmi\"], bins='auto', color='#0504aa',\n                            alpha=0.7, rwidth=0.85)\nplt.xlabel('BMI')\nplt.ylabel('Frequency')\nplt.title('Visualizing effect of BMI')\nplt.text(23, 75,\"Stroke = 0\")\nmaxfreq = n.max()\nplt.ylim(ymax=np.ceil(maxfreq / 10) * 10 if maxfreq % 10 else maxfreq + 10)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.scatterplot(data = data, x ='age', y = 'bmi', hue = 'stroke')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.scatterplot(data = data, x ='age', y = 'avg_glucose_level', hue = 'stroke')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.scatterplot(data = data, x ='avg_glucose_level', y = 'bmi', hue = 'stroke')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Encoding the categoircal features\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ncategorical_cols = ['gender','ever_married','work_type','Residence_type','smoking_status']\ndata[categorical_cols] = data[categorical_cols].apply(lambda col: le.fit_transform(col.astype(str)))\ndata.head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Searching columns with nan values\n\nprint(\"Age: \", np.any(np.isnan(data[\"age\"])))\nprint(\"Avg Glucose level: \", np.any(np.isnan(data[\"avg_glucose_level\"])))\nprint(\"BMI: \", np.any(np.isnan(data[\"bmi\"])))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Number of nan values in bmi: \",len(np.where(np.isnan(data[\"bmi\"]) == True)[0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Considering a large number of missing values in BMI, we need to come up with an efficient method for imputing missing values. ","metadata":{}},{"cell_type":"code","source":"data_num = data[['age','avg_glucose_level','bmi']]\nsns.heatmap(data_num.corr(), annot = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can infer, BMI is not having high correlation with any of the two numerical features.\n\nWe will use K-NearestNeighbor to compute the missing values in BMI","metadata":{}},{"cell_type":"code","source":"Y = data['stroke']\nX = data.drop(['stroke','id'],axis=1)\nX.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.impute import KNNImputer\n\nknn_impute = KNNImputer(n_neighbors=3,weights='distance').fit(X,Y)\nX_imputed = knn_impute.transform(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Splitting the data between training and test sets with test size of 0.4","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X_imputed, Y, test_size=0.4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualizing feature importance using decision trees\n\nfrom sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier()\nmodel.fit(X_train, y_train)\nimportance = model.feature_importances_\nfor i,v in enumerate(importance):\n\tprint('Feature: %0d, Score: %.5f' % (i,v))\n# plot feature importance\nplt.bar([x for x in range(len(importance))], importance)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since we have such scarce data for the stroke class, I have used SMOTE method to oversample the data for better training of the model.","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTENC\n\noversample = SMOTENC([0,2,3,4,5,6,9])\nX_train, y_train = oversample.fit_resample(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Verifying\n\nprint(\"Stroke: \",len(np.where(y_train == 1)[0]))\nprint(\"No Stroke: \",len(np.where(y_train == 0)[0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from numpy import mean\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nss = RobustScaler()\nX_train_scaled = ss.fit_transform(X_train)\n# define model\n#model = GradientBoostingClassifier()\n#parameters={'loss':('deviance', 'exponential'), 'learning_rate':[1, 0.5, 0.25, 0.1, 0.05, 0.01],\n#    'n_estimators':[16, 32, 64, 100, 200,500,1000],'max_depth':np.linspace(1, 32, 32, endpoint=True),\n#    'min_samples_split':np.linspace(0.1, 1.0, 10, endpoint=True),'min_samples_leaf':np.linspace(0.1, 0.5, 5, endpoint=True),\n#    'max_features':list(range(1,X_train.shape[1]))}\n#gridSearch = GridSearchCV(model, params,scoring='roc_auc',n_jobs=-1,cv=3,verbose=3)\n#gridSearch.fit(X_train_scaled, y_train)\n#print(gridSearch.cv_results_['params'])\n#print(gridSearch.cv_results_['mean_test_score'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = GradientBoostingClassifier(loss='deviance',learning_rate=0.5,n_estimators=5500,max_depth=3,\n                                  min_samples_split=0.1,min_samples_leaf=0.01,max_features=7)\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3)\nscores = cross_validate(model, X_train_scaled, y_train, scoring=('f1','roc_auc'), cv=cv, n_jobs=-1)\nprint('Mean F1 Score: %.3f' % mean(scores['test_f1']))\nprint('Mean ROC-AUC Score: %.3f' % mean(scores['test_roc_auc']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Stroke: \",len(np.where(y_test == 1)[0]))\nprint(\"No Stroke: \",len(np.where(y_test == 0)[0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score\nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.metrics import plot_roc_curve\n\nX_test_scaled = ss.transform(X_test)\nmodel.fit(X_train_scaled,y_train)\ny_predict = model.predict(X_test_scaled)\n\nplot_confusion_matrix(model, X_test_scaled, y_test)  \nplt.show()  \n\nplot_roc_curve(model, X_test_scaled, y_test)  \nplt.show()         ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}