{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport random\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom plotly import graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom tqdm import tqdm\nimport os\nimport re\nimport string\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/60k-stack-overflow-questions-with-quality-rate/train.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe(include = \"all\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.duplicated(subset=None, keep='first').value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_tech_keys(tag):\n    if(not tag):\n        return tag\n    tag = tag.replace('><', ',')\n    tag = tag.replace('<', '')\n    tag = tag.replace('>', '')\n    return tag","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['TechKeys'] = df['Tags'].apply(get_tech_keys)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tech_key_list   = []\ntech_key_values = None\nindex_counter = 0\ntech_key_index_list = []\n\nfor item in df['TechKeys']:\n    item_parts = item.split(',')\n    \n    for item_ in item_parts:\n        \n        tech_key_index_list.append(index_counter)\n        tech_key_list.append(item_)\n        index_counter += 1\n    \ndf_tech_key_new = pd.DataFrame({'id' : tech_key_index_list, 'tech_key' : tech_key_list}) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['TechKeys'].to_csv(\"Tags.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\ndf_tech_key_new.tech_key.value_counts().nlargest(10).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_tags_counts(col):\n    if(not col):\n        return 0\n    tags_count = len(col.split(','))\n    return tags_count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_donut_plot(col):\n    \n    rating_data = df.groupby(col)[['Id']].count().head(10)\n    plt.figure(figsize = (12, 8))\n    plt.pie(rating_data[['Id']], autopct = '%1.2f%%', startangle = 140, pctdistance = 1.1, shadow = True)\n\n    # create a center circle for more aesthetics to make it better\n    gap = plt.Circle((0, 0), 0.5, fc = 'white')\n    fig = plt.gcf()\n    fig.gca().add_artist(gap)\n    \n    plt.axis('equal')\n    \n    cols = []\n    for index, row in rating_data.iterrows():\n        cols.append(index)\n    plt.legend(cols)\n    \n    plt.title('Donut Plot: SOF Questions by ' +str(col), loc='center')\n    \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['TagsCount'] = df['TechKeys'].apply(get_tags_counts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_donut_plot('TagsCount')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df['Y'].value_counts())\nfig = go.Figure(go.Funnelarea(\n    text = df.Y,\n    values = df.Y.value_counts(),\n    title = {\"position\": \"top center\", \"text\": \"Funnel-Chart of Question Quality Distribution\"}\n    ))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Equal Distribution among quality"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Num_words_body'] = df['Body'].apply(lambda x:len(str(x).split())) #Number Of words in Selected Text\ndf['Num_words_title'] = df['Title'].apply(lambda x:len(str(x).split())) #Number Of words in main text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\np1=sns.kdeplot(df[df['Y']=='HQ']['Num_words_body'], shade=True, color=\"b\").set_title('Kernel Distribution of Number Of words')\np2=sns.kdeplot(df[df['Y']=='LQ_CLOSE']['Num_words_body'], shade=True, color=\"r\")\np2=sns.kdeplot(df[df['Y']=='LQ_EDIT']['Num_words_body'], shade=True, color=\"g\")\nplt.legend(labels=['HQ','LQ_CLOSE','LQ_EDIT'])\nplt.ylabel(\"Probability Density\")\nplt.xlabel(\"Number of words\")\nplt.xlim(-20,500)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Questions closed tends to have high probability of fewer words. So hence the reason getting closed due to lack of detailing"},{"metadata":{"trusted":true},"cell_type":"code","source":"def code_available(content):\n    \n    if('<code>' in content):\n        return True\n    \n    return False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['code_available'] = df['Body'].apply(code_available)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_donut_plot('code_available')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Almost half of the contents don't have code in the body."},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_week(col):\n    return col.strftime(\"%V\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['CreationDatetime'] = pd.to_datetime(df['CreationDate']) \ndf['CreationYear'] = df['CreationDatetime'].dt.year.astype(int)\ndf['CreationMonth'] = df['CreationDatetime'].dt.month.astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_donut_plot('CreationYear')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import squarify\ndef show_treemap_tech_key(col):\n    df_type_series = df_tech_key_new.groupby(col)['id'].count().sort_values(ascending = False).head(50)\n\n    type_sizes = []\n    type_labels = []\n    for i, v in df_type_series.items():\n        type_sizes.append(v)\n        \n        type_labels.append(str(i) + ' ('+str(v)+')')\n\n\n    fig, ax = plt.subplots(1, figsize = (12,12))\n    squarify.plot(sizes=type_sizes, \n                  label=type_labels[:25],  # show labels for only first 10 items\n                  alpha=.2 )\n    plt.title('TreeMap by '+ str(col))\n    plt.axis('off')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_treemap_tech_key('tech_key')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We can clearly see that Javascript and Python are dominating the questions followed by Java.\n* Python seems to be more popular and in demand than Java\n* Android is at 4th place"},{"metadata":{"trusted":true},"cell_type":"code","source":"code_start = '<code>'\ncode_end   = '</code>'\n\ndef get_codes(content):\n    \n    if('<code>' not in content):\n        return None\n    \n    code_list = []\n    \n    loop_counter = 0\n    while(code_start in content):\n\n        code_start_index = content.index(code_start)\n        if(code_end not in content):\n            code_end_index = len(content)\n        else:\n            code_end_index = content.index(code_end)\n\n        substring_1 = content[code_start_index : (code_end_index + len(code_end) )]\n \n        code_list.append(substring_1)\n        \n        content = content.replace(substring_1, '')\n        \n        loop_counter += 1\n\n    \n    return ' '.join(code_list)\n\ndef  clean_text(content):\n    \n    content = content.lower()\n    \n    content = re.sub('<.*?>+', '', content)\n    \n    content = re.sub(r\"(@[A-Za-z0-9]+)|^rt|http.+?\", \"\", content)\n    content = re.sub(r\"(\\w+:\\/\\/\\S+)\", \"\", content)\n    content = re.sub(r\"([^0-9A-Za-z \\t])\", \" \", content)\n    content = re.sub(r\"^rt|http.+?\", \"\", content)\n    content = re.sub(\" +\", \" \", content)\n\n    # remove numbers\n    content = re.sub(r\"\\d+\", \"\", content)\n    \n    return content\n\ndef get_non_codes(content):\n    \n    loop_counter = 0\n    while(code_start in content):\n\n        code_start_index = content.index(code_start)\n        if(code_end not in content):\n            code_end_index = len(content)\n        else:\n            code_end_index = content.index(code_end)\n\n        substring_1 = content[code_start_index : (code_end_index + len(code_end) )]\n\n        content = content.replace(substring_1, ' ')\n        \n        loop_counter += 1\n        \n    content = clean_text(content)\n\n    return content","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ndf['Body_code'] = df['Body'].apply(get_codes)\ndf['Body_content'] = df['Body'].apply(get_non_codes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nstopwords1 = stopwords.words('english')\ndf['content_words'] = df['Body_content'].apply(lambda x:str(x).split())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_short_words(content):\n\n    new_content_list = []\n    for item in content:\n        \n        if(len(item) > 2):\n            new_content_list.append(item)\n    \n    return new_content_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['content_words'] = df['content_words'].apply(remove_short_words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"words_collection = Counter([item for sublist in df['content_words'] for item in sublist if not item in stopwords1])\nfreq_word_df = pd.DataFrame(words_collection.most_common(30))\nfreq_word_df.columns = ['frequently_used_word','count']\n\nfreq_word_df.style.background_gradient(cmap='YlGnBu', low=0, high=0, axis=0, subset=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter(freq_word_df, x=\"frequently_used_word\", y=\"count\", color=\"count\", title = 'Frequently used words - Scatter plot')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.pie(freq_word_df, values='count', names='frequently_used_word', title='Stackoverflow Questions - Frequently Used Word')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_question_level(level):\n    if(not level):\n        return level\n    if(level == 'LQ_CLOSE'):\n        return 3\n    if(level == 'LQ_EDIT'):\n        return 2\n    if(level == 'HQ'):\n        return 1\n    return level\n\ndf['Level'] = df['Y'].apply(get_question_level)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.sunburst(df, path=['CreationYear', 'CreationMonth'], values='Level',\n                  color='Level', hover_data=['Level'])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import spacy\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# for advanced visualizations\nimport plotly.offline as py\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\nfrom plotly import tools\ninit_notebook_mode(connected = True)\nimport plotly.figure_factory as ff","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nlp = spacy.load('en')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Taking a random sentence for dependency parsing"},{"metadata":{"trusted":true},"cell_type":"code","source":"from spacy import displacy\nrand = df['Title'][1000]\ndoc = nlp(rand)\n  \ndisplacy.render(doc, style='dep', jupyter=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Word Similarity:\nSpacy has word vector model which we can use to find similar words."},{"metadata":{"trusted":true},"cell_type":"code","source":"nlp = spacy.load('en_core_web_lg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n\ncv = CountVectorizer(stop_words = 'english')\nwords = cv.fit_transform(df.Title)\nsum_words = words.sum(axis=0)\n\nwords_freq = [(word, sum_words[0, idx]) for word, idx in cv.vocabulary_.items()]\nwords_freq = sorted(words_freq, key = lambda x: x[1], reverse = True)\nfrequency = pd.DataFrame(words_freq, columns=['word', 'freq'])\n\nplt.style.use('fivethirtyeight')\ncolor = plt.cm.ocean(np.linspace(0, 1, 20))\nfrequency.head(20).plot(x='word', y='freq', kind='bar', figsize=(15, 6), color = color)\nplt.title(\"Question Title - Most Frequently Occuring Words\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud\n\nwordcloud = WordCloud(background_color = 'lightcyan', width = 2000, height = 2000).generate_from_frequencies(dict(words_freq))\nplt.figure(figsize=(10, 10))\nplt.axis('off')\nplt.imshow(wordcloud)\nplt.title(\"Corpus of Question Text\", fontsize = 20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trace = go.Scatter3d(\n    x = df['Num_words_body'],\n    y = df['Level'],\n    z = df['TechKeys'].apply(lambda x:x.split(\",\")[0]),\n    name = '3DPlot',\n    mode='markers',\n    marker=dict(\n        size=10,\n        color = df['Level'],\n        colorscale = 'Viridis',\n    )\n)\ndf_dia = [trace]\n\nlayout = go.Layout(\n    title = 'Number of words in body vs Quality vs Tags',\n    margin=dict(\n        l=0,\n        r=0,\n        b=0,\n        t=0  \n    )\n)\nfig = go.Figure(data = df_dia, layout = layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# if(level == 'LQ_CLOSE')  return 3\n# if(level == 'LQ_EDIT')   return 2\n# if(level == 'HQ')        return 1\ndf[['Title', 'TechKeys','TagsCount','Num_words_body','Num_words_title','code_available','content_words','Body_code','Body_content', 'Level']].to_csv(\"data.csv\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}