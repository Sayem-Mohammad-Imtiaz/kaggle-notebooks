{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Please upvote for further encouragement.\n\n**SentiWordNet is a library created by NLP community engineers for sentiment analysis.**\n\nIt contains POS Tags, Positivity score, Negativity score and SynsetTerms ie. in common language synonyms of a perticular words.\nAs scores related to words are already define in SentiWordNet based on some rules **and we are not considering context or sequence of word in which a word is used**, This approach is called as Rule Based Sentiment Analysis Approach.","metadata":{}},{"cell_type":"markdown","source":"# Importing Required Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport string\nimport re\nimport warnings \nwarnings.filterwarnings('ignore')\n\n#plotting libraries!\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom shapely.geometry import Point\nimport geopandas as gpd\nfrom geopandas import GeoDataFrame\n%matplotlib inline\n#PLOTLY\nimport plotly\nimport plotly.offline as offline\nimport plotly.graph_objs as go\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\nimport cufflinks as cf\nfrom collections import defaultdict\nfrom plotly import tools\nfrom nltk.util import ngrams\nfrom plotly.graph_objs import Scatter, Figure, Layout\ncf.set_config_file(offline=True)\nfrom nltk.corpus import stopwords\neng_stopwords = set(stopwords.words(\"english\"))\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.decomposition import NMF, LatentDirichletAllocation, TruncatedSVD\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport pyLDAvis.sklearn\nfrom pylab import bone, pcolor, colorbar, plot, show, rcParams, savefig\nimport squarify\nfrom PIL import Image\nfrom os import path\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom textblob import TextBlob\nimport nltk\nfrom nltk.corpus import wordnet as wn\nfrom nltk.corpus import sentiwordnet as swn\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk.sentiment import SentimentIntensityAnalyzer\nfrom nltk.corpus import stopwords\n\nnltk.download('wordnet')\nnltk.download('sentiwordnet')\nnltk.download('stopwords')\nnltk.download('punkt')\nnltk.download('averaged_perceptron_tagger')\nlemmatizer = WordNetLemmatizer()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tweet-preprocessor\nimport preprocessor as p\np.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.SMILEY, p.OPT.EMOJI)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#for suppressing DeprecationWarnings:\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/reddit-vaccine-myths/reddit_vm.csv')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(5)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.shape)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The TextBlob Sentiment Analysis of TextBlob returns two properties**\n\n* Polarity\n* Subjectivity\n* Polarity\nIt simply means emotions expressed in a sentence.\n\n* Emotions are closely related to sentiments. The strength of a sentiment or opinion is typically linked to the intensity of certain emotions, e.g., joy and anger.\n* The range of the Polarity lies in [-1.0,1.0] where 1 is a positive statment and -1 is negative statement. Values with 0 is Neutral statment\n\n**Subjectivity**\n* Subjective sentence expresses some personal individual feelings, views, or beliefs.\n* The range of Subjectivity is [0.0,1.0] where 0 is very objective and 1 is very Subjective.","metadata":{}},{"cell_type":"code","source":"print(df['title'][2])\nTweet = TextBlob(df['title'][4])\nTweet.sentiment","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Get score of each tweet - \nSentiWordNet is a library created by NLP community engineers for sentiment analysis.\nIt contains POS Tags, Positivity score, Negativity score and SynsetTerms ie. in common language synonyms of a perticular words.\nAs scores related to words are already define in SentiWordNet based on some rules [and we are not considering context or sequence of word in which a word is used], This approach is called as Rule Based Sentiment Analysis Approach.","metadata":{}},{"cell_type":"markdown","source":"# Text PreProcessing\n* Removing Punctuations\n* Change Case\n* Tokenization\n* Removing Stop Words\n* Lemmatization","metadata":{}},{"cell_type":"code","source":"from nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nstop_words = set(stopwords.words('english'))\ncleantweets = []\npostags = []\nimport string\ntable = str.maketrans('','', string.punctuation)\nfor title in df['title']:\n    try:\n        title = p.clean(title)\n        #tokenize + lower case\n        words2 = word_tokenize(title.lower())\n        #remove puncts\n        words3 = [w.translate(table) for w in words2]\n        #remove stopwords\n        words4 = [word for word in words3 if word not in stop_words]\n        #applying lemmatization\n        words5 = [lemmatizer.lemmatize(word) for word in words4]\n                \n        #combining all words\n        cleantweets.append((\" \".join(words5)).strip())\n    except:\n        cleantweets.append(title)\n        continue\n\nprint(len(cleantweets))\ndf['clean_Tweets'] = cleantweets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# POS Tagging","metadata":{}},{"cell_type":"code","source":"pos=neg=obj=count=0\n\npostagging = []\n\nfor title in df['clean_Tweets']:\n    list = word_tokenize(title)\n    postagging.append(nltk.pos_tag(list))\n\ndf['pos_tags'] = postagging","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Functions for Sentiment Scoring","metadata":{}},{"cell_type":"code","source":"# Convert between the PennTreebank tags to simple Wordnet tags\ndef penn_to_wn(tag):\n    if tag.startswith('J'):\n        return wn.ADJ\n    elif tag.startswith('N'):\n        return wn.NOUN\n    elif tag.startswith('R'):\n        return wn.ADV\n    elif tag.startswith('V'):\n        return wn.VERB\n    return None","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_sentiment(word,tag):\n    wn_tag = penn_to_wn(tag)\n    \n    if wn_tag not in (wn.NOUN, wn.ADJ, wn.ADV):\n        return []\n\n    #Lemmatization\n    lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n    if not lemma:\n        return []\n\n    #Synset is a special kind of a simple interface that is present in NLTK to look up words in WordNet. \n    #Synset instances are the groupings of synonymous words that express the same concept. \n    #Some of the words have only one Synset and some have several.\n    synsets = wn.synsets(word, pos=wn_tag)\n    if not synsets:\n        return []\n\n    # Take the first sense, the most common\n    synset = synsets[0]\n    swn_synset = swn.senti_synset(synset.name())\n\n    return [synset.name(), swn_synset.pos_score(),swn_synset.neg_score(),swn_synset.obj_score()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pos=neg=obj=count=0\nsenti_score = []\n\nfor pos_val in df['pos_tags']:\n    senti_val = [get_sentiment(x,y) for (x,y) in pos_val]\n    for score in senti_val:\n        try:\n            pos = pos + score[1]  #positive score is stored at 2nd position\n            neg = neg + score[2]  #negative score is stored at 3rd position\n        except:\n            continue\n    senti_score.append(pos - neg)\n    pos=neg=0    \n    \ndf['senti_score'] = senti_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(5)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"SentiWordNet is a lexical resource for opinion mining. SentiWordNet assigns to each synset of WordNet three sentiment scores: positivity, negativity, objectivity.","metadata":{}},{"cell_type":"code","source":"df.to_csv(\"Sentiment_predited_result.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['compound_label'] = df['senti_score'].apply(lambda number: 'positive' if number>=0 else 'negative')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['compound_label'].value_counts().plot(kind='pie')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = df['clean_Tweets']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wc = WordCloud(width = 900, height = 500, background_color = 'white', random_state = 10).generate(text[1])\n\nplt.title('Word Cloud for Bag Of Words')\nplt.imshow(wc)\nplt.axis('off')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Sentence tokenization is the process of splitting text into individual sentences**","metadata":{}},{"cell_type":"code","source":"sents1 = sent_tokenize(text\t[5])\nprint(f'Sentence Tokenization using NLTK: \\n {text\t[5]} => {sents1}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****It is used on words so that individual words are separated as items in a list.","metadata":{}},{"cell_type":"code","source":"words1 = word_tokenize(sents1[0])\nprint(f'Word Tokenization using NLTK: \\n {sents1[0]} => {words1}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokens1 = [word for word in words1 if not word in stopwords.words('english')] \nprint(f'Stopword Removal using NLTK: \\n{words1} => {tokens1}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****N-gram is a language model widely used in NLP and is applied to statistical problems involving text and audio. It is a probabilistic model that predicts the next series of words. For example, in the sentence, “The movie was boring.” ","metadata":{}},{"cell_type":"code","source":"n_grams1 = ngrams(tokens1, 2)\nn_grams1 = [ ' '.join(grams) for grams in n_grams1]\n\nprint(f'N-Gram using NLTK (n = 2): \\n{tokens1} => {n_grams1}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_gram_finder = nltk.collocations.TrigramCollocationFinder.from_words(tokens1)\n\nprint(f'Most Common N-Gram Finder using NLTK (n = 3): \\n{tokens1} => {n_gram_finder.ngram_fd.most_common(2)}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_count = {}\n\nfor word in tokens1:\n    \n    if word not in word_count.keys():\n        word_count[word] = 1\n    else:\n        word_count[word] += 1\n        \nprint(f'Bag of Words: \\n{tokens1} => {word_count}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stopwords = set(STOPWORDS)\n\nwc = WordCloud(width = 900, height = 500, background_color = 'white', random_state = 10).generate(text[1])\n\nplt.title('Word Cloud for Bag Of Words')\nplt.imshow(wc)\nplt.axis('off')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Sentimental analysis plays a significant role in determining the polarity of a review or a comment. It is used to know whether the person is talking about something in a positive way or a negative way. It can be classified broadly into positive, negative, and neutral. For example, on a tourism website, a person leaves a remark stating, “There are beautiful tourist spots in Switzerland. “The word ‘beautiful’ is positive as it describes Switzerland as pretty.****","metadata":{}},{"cell_type":"code","source":"sia = SentimentIntensityAnalyzer()\npolarity_scores1 = sia.polarity_scores(text[10])\n\nprint(f\"Sentiment Analysis using NLTK: \\n{text[10]} => {polarity_scores1}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = np.array([[sia.polarity_scores(word)['compound'] for word in word_tokenize(text[5])]])\nannot = np.array([word_tokenize(text[5])])\n\nplt.figure(figsize = (10, 3))\nsns.heatmap(x, annot = annot, fmt = '')\nplt.title('Heatmap for Sentiment Analysis')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}