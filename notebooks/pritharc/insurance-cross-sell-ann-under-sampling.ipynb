{"cells":[{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from IPython.display import Image\nimport os\n\nImage(\"../input/crosssell/edd-cross-sell-and-upsell.png\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* This Notebook is solved using Deep learning technique. \n* Imbalanced data has been corrected using Under Sampling.\n# Please upvote if like this notebook for further encouragement.  "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Supress unnecessary warnings so that presentation looks clean\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom imblearn.combine import SMOTETomek\nfrom imblearn.under_sampling import NearMiss","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/health-insurance-cross-sell-prediction/train.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This EDA will check the Y variable is imbalanced as class is not a 50/50 or 60/40 distribution."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"count_classes = pd.value_counts(df['Response'], sort = True)\n\ncount_classes.plot(kind = 'bar', rot=0)\n\nplt.title(\"Response Class Distribution\")\n\nplt.xticks(range(2))\n\nplt.xlabel(\"Response\")\n\nplt.ylabel(\"Frequency\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df['Response'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking Null Values\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"One hot encoding "},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Gender'] = pd.Categorical(df['Gender'])\ndf['Previously_Insured'] = pd.Categorical(df['Previously_Insured'])\ndf['Vehicle_Age'] = pd.Categorical(df['Vehicle_Age'])\ndf['Vehicle_Damage'] = pd.Categorical(df['Vehicle_Damage'])\ndf['Response'] = pd.Categorical(df['Response'])\ndf['Region_Code'] = pd.Categorical(df['Region_Code'])\ndf['Driving_License'] = pd.Categorical(df['Driving_License'])\n\ndf = pd.concat([df[['Age', 'Annual_Premium', 'Policy_Sales_Channel', 'Vintage', 'Response']],\n           pd.get_dummies(df[['Gender', 'Previously_Insured', 'Vehicle_Age', 'Vehicle_Damage','Driving_License','Response']])], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Correlation plot"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#Using Pearson Correlation\nplt.figure(figsize=(12,10))\ncor = df.corr()\nsns.heatmap(cor, annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.loc[:, ['Age','Annual_Premium','Policy_Sales_Channel','Vintage','Gender_Female','Gender_Male','Previously_Insured_0','Previously_Insured_1','Vehicle_Age_1-2 Year','Vehicle_Age_< 1 Year','Vehicle_Age_> 2 Years','Vehicle_Damage_No','Vehicle_Damage_Yes','Driving_License_0','Driving_License_1']] #Frpm 3rd column to 13th column all are indenpendent features.\ny = df.loc[:,[\"Response\"]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Implementing Oversampling for Handling Imbalanced"},{"metadata":{"trusted":true},"cell_type":"code","source":"smk = SMOTETomek(random_state=42)\nX_res,y_res=smk.fit_sample(X,y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Equally distributed ) 0 & 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_res.shape,y_res.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_res.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#kfold stratified\nfrom sklearn.model_selection import StratifiedKFold\nskf = StratifiedKFold(n_splits=2)\nskf.get_n_splits(X_res, y_res)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"StratifiedKFold(n_splits=2, random_state=None, shuffle=False)\nfor train_index, test_index in skf.split(X, y):\n    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size = 0.1, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ANN - Deep learning Started"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Dropout ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = Sequential() #Forward and Backward Propogation\n\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(units = 6,kernel_initializer='he_uniform',activation='relu',input_dim = 15))#in hidden layer 6 nodes and given dimension\n\n# Adding the second hidden layer\nclassifier.add(Dense(units = 6, kernel_initializer = 'he_uniform',activation='relu'))#Kernal intialization - Weight intializing technique. Problem may be- Exploding gradient problem1\n# Adding the output layer\nclassifier.add(Dense(units = 1, kernel_initializer = 'glorot_uniform', activation = 'sigmoid'))\n\n# Compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy']) #prit code restart kro phirse. mai dekh rha hu","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_history=classifier.fit(X_train, y_train,validation_split=0.33, batch_size = 10, epochs = 25)\n\n#low bias, high variance.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# list all data in history\n\nprint(model_history.history.keys())\n# summarize history for accuracy\nplt.plot(model_history.history['accuracy'])\nplt.plot(model_history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show() #galat he prit. graph dekho ha kya karu. ha upar se dekhta hu. 1min","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# summarize history for loss\nplt.plot(model_history.history['loss'])\nplt.plot(model_history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Part 3 - Making the predictions and evaluating the model\n\n# Predicting the Test set results\ny_pred = classifier.predict(X_test)\ny_pred = (y_pred > 0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\ncm ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate the Accuracy\nfrom sklearn.metrics import accuracy_score\nscore=accuracy_score(y_pred,y_test)\nscore","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_res","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictedcarinsurance = model_history.predict([[44, 40454, 26, 217, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}