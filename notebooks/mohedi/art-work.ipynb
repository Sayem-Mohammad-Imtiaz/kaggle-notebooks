{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom keras.models import Model\nfrom keras.applications.vgg19 import VGG19,preprocess_input\nimport os\nfrom PIL import Image\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"artists=os.listdir('../input/best-artworks-of-all-time/images/images')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"size=360","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=VGG19(include_top=False,input_shape=(size,size,3))\nmodel.trainable=False\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"content_layer='block3_conv4'\ncontent_model=Model(inputs=model.input,outputs=model.get_layer(content_layer).output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"style_layers=[ 'block1_conv1', 'block2_conv2','block3_conv3', 'block4_conv4','block5_conv2']\nstyle_models=[Model(inputs=model.input,outputs=model.get_layer(style_layer).output) for style_layer in style_layers]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gram_matrix(M):\n    num_channels = tf.shape(M)[-1]\n    M = tf.reshape(M, shape=(-1, num_channels))\n    n = tf.shape(M)[0]\n    G = tf.matmul(tf.transpose(M), M)\n    return G \ndef content_cost(content_img, generated_img):\n    C = content_model(content_img)\n    G = content_model(generated_img)\n    cost =  tf.reduce_mean(tf.square(generated_img-content_img))\n    return cost\ndef style_cost(style_img, generated_img):\n    total_cost = 0\n    \n    for i, style_model in enumerate(style_models):\n        S = style_model(style_img)\n        G = style_model(generated_img)\n        GS = gram_matrix(S)\n        GG = gram_matrix(G)\n        current_cost = style_layer_wts[i] * tf.reduce_mean(tf.square(GS-GG))\n        total_cost += current_cost\n    return total_cost","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"content_image_path='../input/best-artworks-of-all-time/images/images/Leonardo_da_Vinci/Leonardo_da_Vinci_121.jpg'\nstyle_image_path='../input/best-artworks-of-all-time/images/images/Francisco_Goya/Francisco_Goya_100.jpg'\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_img(path):\n    img=tf.keras.preprocessing.image.load_img(path,target_size=(size,size))\n    img=tf.keras.preprocessing.image.img_to_array(img,dtype='uint8')\n    img=np.expand_dims(img,axis=0)\n    return img\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_image(image_path):\n    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(size, size))\n    img = tf.keras.preprocessing.image.img_to_array(img)\n    img = tf.keras.applications.vgg19.preprocess_input(img)\n    return np.expand_dims(img, axis = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def deprocess(x):\n    x[:, :, 0] += 103.939\n    x[:, :, 1] += 116.779\n    x[:, :, 2] += 123.68\n    x = x[:, :, ::-1]\n\n    x = np.clip(x, 0, 255).astype('uint8')\n    return x\n\ndef display_image(image):\n    if len(image.shape) == 4:\n        image = image[0,:,:,:]\n\n    img = deprocess(image)\n    \n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(img)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = 23\nsize = 360\niterations = 250\nstyle_wt = 0.008\ncontent_wt = 0.8\nstyle_layer_wts = [4,2,1,0.1,0.1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate(content_image_path,style_image_path):\n    content_image_preprocessed = preprocess_image(content_image_path)\n    style_image_preprocessed = preprocess_image(style_image_path)\n    generated_image = tf.Variable(content_image_preprocessed, dtype=tf.float32)\n\n    generated_images = []\n    costs = []\n\n    min_cost=1*10**12\n    optimizer = tf.optimizers.Adam(learning_rate=lr)\n\n    for i in range(iterations):\n    \n        with tf.GradientTape() as tape:\n            J_content = content_cost(content_img=content_image_preprocessed, generated_img=generated_image)\n            J_style = style_cost(style_img=style_image_preprocessed, generated_img=generated_image)\n            J_total = content_wt * J_content + style_wt * J_style\n    \n        gradients = tape.gradient(J_total, generated_image)\n        optimizer.apply_gradients([(gradients, generated_image)])\n    \n        costs.append(J_total.numpy())\n        generated_images.append(generated_image.numpy())\n        min_cost=J_total\n        if i%50==0:\n            print(\"Iteration:{}/{}, Total Cost:{}, Style Cost: {}, Content Cost: {}\".format(i+1, iterations, J_total, J_style, J_content))\n    return generated_images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generated_images=generate(content_image_path,style_image_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generated_image=Image.fromarray(deprocess(generated_images[-1][0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(24,8))\ndict_title={1:\"Content_image\",2:\"Generated_image\",3:\"Style_image\"}\nimages={1:tf.keras.preprocessing.image.load_img(content_image_path),2:generated_image,3:tf.keras.preprocessing.image.load_img(style_image_path)}\nfor i in range(1,4):\n    plt.subplot(2,4,i)\n    plt.imshow(images[i])\n    plt.xticks([])\n    plt.yticks([])\n    plt.tight_layout()\n    plt.title(dict_title[i])\nplt.savefig('out2.png')\nplt.show","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}