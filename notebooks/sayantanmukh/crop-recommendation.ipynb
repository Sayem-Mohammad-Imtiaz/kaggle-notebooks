{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-20T16:40:23.676413Z","iopub.execute_input":"2021-05-20T16:40:23.677111Z","iopub.status.idle":"2021-05-20T16:40:23.693211Z","shell.execute_reply.started":"2021-05-20T16:40:23.677017Z","shell.execute_reply":"2021-05-20T16:40:23.692158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Let us import the required packages first","metadata":{}},{"cell_type":"code","source":"import os\nimport warnings\nwarnings.filterwarnings('ignore')\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-05-20T16:41:21.008718Z","iopub.execute_input":"2021-05-20T16:41:21.009242Z","iopub.status.idle":"2021-05-20T16:41:21.833674Z","shell.execute_reply.started":"2021-05-20T16:41:21.009199Z","shell.execute_reply":"2021-05-20T16:41:21.832598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Importing the data for doing analysis","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/crop-recommendation-dataset/Crop_recommendation.csv')","metadata":{"execution":{"iopub.status.busy":"2021-05-20T16:41:42.997641Z","iopub.execute_input":"2021-05-20T16:41:42.997967Z","iopub.status.idle":"2021-05-20T16:41:43.022075Z","shell.execute_reply.started":"2021-05-20T16:41:42.997935Z","shell.execute_reply":"2021-05-20T16:41:43.02122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Checking if there are any missing values","metadata":{}},{"cell_type":"code","source":"data.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-05-20T16:41:55.030468Z","iopub.execute_input":"2021-05-20T16:41:55.030818Z","iopub.status.idle":"2021-05-20T16:41:55.049571Z","shell.execute_reply.started":"2021-05-20T16:41:55.03079Z","shell.execute_reply":"2021-05-20T16:41:55.048647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Getting an overview of the dataset","metadata":{}},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-20T16:42:08.428613Z","iopub.execute_input":"2021-05-20T16:42:08.429Z","iopub.status.idle":"2021-05-20T16:42:08.450023Z","shell.execute_reply.started":"2021-05-20T16:42:08.428968Z","shell.execute_reply":"2021-05-20T16:42:08.449188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Seeing some samples of the dataset","metadata":{}},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-20T16:42:28.177986Z","iopub.execute_input":"2021-05-20T16:42:28.17831Z","iopub.status.idle":"2021-05-20T16:42:28.196172Z","shell.execute_reply.started":"2021-05-20T16:42:28.178284Z","shell.execute_reply":"2021-05-20T16:42:28.195441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The different categories of the dependent variables","metadata":{}},{"cell_type":"code","source":"data['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-05-20T16:42:53.077842Z","iopub.execute_input":"2021-05-20T16:42:53.078208Z","iopub.status.idle":"2021-05-20T16:42:53.085882Z","shell.execute_reply.started":"2021-05-20T16:42:53.078172Z","shell.execute_reply":"2021-05-20T16:42:53.085112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Custom class for model fitting, prediction and performance evaluation","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n\nclass Model:\n    \n    def __init__(self):\n        self.X_test=None\n        self.y_test=None\n        \n    \n    def fit_model(self,dataset,dep_var,classifier):\n        y=dataset[dep_var]\n        X=dataset.drop(columns=[dep_var],axis=1)\n        scaler = StandardScaler()\n        for col in X.columns:\n            x = np.array(X[col]).reshape(-1,1)\n            X[col]=scaler.fit_transform(x)\n        \n        X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=42)\n        self.X_test=X_test\n        self.y_test=y_test\n    \n        #forest = RandomForestClassifier()\n        classifier.fit(X_train,y_train)\n        return classifier\n    \n    def get_prediction(self,classifier,X_test):\n        y_pred = classifier.predict(X_test)\n        return y_pred\n    \n    def get_performance_metric(self,y_test,y_pred):\n        print(classification_report(y_test,y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-05-20T17:04:48.461596Z","iopub.execute_input":"2021-05-20T17:04:48.462071Z","iopub.status.idle":"2021-05-20T17:04:48.469646Z","shell.execute_reply.started":"2021-05-20T17:04:48.462033Z","shell.execute_reply":"2021-05-20T17:04:48.468655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Importing packages for predictive modelling","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression","metadata":{"execution":{"iopub.status.busy":"2021-05-20T17:05:56.614208Z","iopub.execute_input":"2021-05-20T17:05:56.614682Z","iopub.status.idle":"2021-05-20T17:05:56.618195Z","shell.execute_reply.started":"2021-05-20T17:05:56.614652Z","shell.execute_reply":"2021-05-20T17:05:56.617573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Using RandomForestClassifier for fitting dataset","metadata":{}},{"cell_type":"code","source":"m=Model()\n\nforest = RandomForestClassifier()\nmodel = m.fit_model(data,'label',forest)\ny_pred = m.get_prediction(model,m.X_test)\nm.get_performance_metric(m.y_test,y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T17:04:53.492819Z","iopub.execute_input":"2021-05-20T17:04:53.493129Z","iopub.status.idle":"2021-05-20T17:04:53.849275Z","shell.execute_reply.started":"2021-05-20T17:04:53.493104Z","shell.execute_reply":"2021-05-20T17:04:53.848371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Using DecisionTreeClassifier for fitting dataset","metadata":{}},{"cell_type":"code","source":"m=Model()\n\ntree = DecisionTreeClassifier()\nmodel = m.fit_model(data,'label',tree)\ny_pred = m.get_prediction(model,m.X_test)\nm.get_performance_metric(m.y_test,y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T17:05:26.600284Z","iopub.execute_input":"2021-05-20T17:05:26.600629Z","iopub.status.idle":"2021-05-20T17:05:26.643684Z","shell.execute_reply.started":"2021-05-20T17:05:26.600596Z","shell.execute_reply":"2021-05-20T17:05:26.642451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Using LogisticRegression for fitting dataset","metadata":{}},{"cell_type":"code","source":"m=Model()\n\nlogit = LogisticRegression()\nmodel = m.fit_model(data,'label',logit)\ny_pred = m.get_prediction(model,m.X_test)\nm.get_performance_metric(m.y_test,y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T17:06:27.695748Z","iopub.execute_input":"2021-05-20T17:06:27.696076Z","iopub.status.idle":"2021-05-20T17:06:27.977126Z","shell.execute_reply.started":"2021-05-20T17:06:27.696044Z","shell.execute_reply":"2021-05-20T17:06:27.976484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We can see that both RandomForestClassifier and DecisionTreeClassifier does a fantastic job in predicting the crop for a particular cultivation environment.","metadata":{}}]}