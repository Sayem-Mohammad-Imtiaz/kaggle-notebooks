{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Load Data\nheart_data = pd.read_csv('../input/heart.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"29a1e74962197efdc25de12c9285614ba12e60db"},"cell_type":"markdown","source":"# First Look at Data"},{"metadata":{"trusted":true,"_uuid":"b61ef0b8504929eb75d98f191e54b7286086c547","scrolled":false},"cell_type":"code","source":"heart_data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"81f185a2f5ad7519a761bca8ca6fc439bc6cb133"},"cell_type":"code","source":"heart_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"07faac8020107d57d3f5161de4d9c8e44551dc75"},"cell_type":"markdown","source":"# Column details\n\n* age : age in years\n* sex : (1 = male; 0 = female)\n* cp : chest pain type\n* trestbps : resting blood pressure (in mm Hg on admission to the hospital)\n* chol : serum cholestoral in mg/dl\n* fbs : (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n* restecg : resting electrocardiographic results\n* thalach : maximum heart rate achieved\n* exang : exercise induced angina (1 = yes; 0 = no)\n* oldpeak : ST depression induced by exercise relative to rest\n* slope : the slope of the peak exercise ST segment\n* ca : number of major vessels (0-3) colored by flourosopy\n* thal : 3 = normal; 6 = fixed defect; 7 = reversable defect\n* target : 1 or 0"},{"metadata":{"_uuid":"52d498a7d292dc9fa953fb112a7c3349b4cef3fa"},"cell_type":"markdown","source":"# Checking data for null values"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"b4a63441166c0a97612cb05fa004c55846f3c890"},"cell_type":"code","source":"heart_data.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"23a9b2a2d3846a20beb654bc2e6acc4f896b8b42"},"cell_type":"code","source":"# No Null Values in any column","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"scrolled":true,"_uuid":"d8b5f4447d6f62d74f9cd514d4f9803b1e740990"},"cell_type":"code","source":"all_columns = heart_data.columns.values.tolist()\nnum_columns = ['age','trestbps','chol','thalach','oldpeak']\ncat_columns = [clm_name for clm_name in all_columns if clm_name not in num_columns]\nprint('Columns with continuous data : {} Count = {}\\nColumns with catagorical data : {} Count = {}'.format(num_columns,len(num_columns),cat_columns,len(cat_columns)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4ac54be3353e0adaeaa56507e0b86b1fb7d6c69f"},"cell_type":"markdown","source":"# Now checking for duplicates and removing them (if any)"},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"16e29b406a991cd8bba5cdabed4ca08fa3fde58f"},"cell_type":"code","source":"heart_data[heart_data.duplicated() == True]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"549e2d67cad7f4159726bc2d6fc276c3a7b68730"},"cell_type":"code","source":"heart_data.drop_duplicates(inplace = True)\nheart_data[heart_data.duplicated() == True]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6c7da6f496d8f2cfec8b603ec9a8d15c4e1a7dc5"},"cell_type":"code","source":"# Removed the duplicate row","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3ab5073bd186b98651680833dbee15ef24b5e236"},"cell_type":"markdown","source":"# Analyzing data "},{"metadata":{"trusted":true,"_uuid":"e5bbe86f41c211047c157bca0e78b20679c59a33","_kg_hide-input":true},"cell_type":"code","source":"# Sex distribution \n\nmale_count = heart_data.sex.value_counts().tolist()[0]\nfemale_count = heart_data.sex.value_counts().tolist()[1]\nprint('Male :',male_count)\nprint('Female :',female_count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"a95646f816cb21de7a0328d72d8abcdb44b26367","_kg_hide-input":false},"cell_type":"code","source":"fig, (ax1,ax2) = plt.subplots(1,2,figsize = (12,5),constrained_layout=True)\nplt.subplots_adjust(wspace = 0.5)\n\nax1.bar(heart_data.sex.unique(),heart_data.sex.value_counts(),color = ['blue','red'],width = 0.8)\nax1.set_xticks(heart_data.sex.unique())\nax1.set_xticklabels(('Male','Female'))\n\nax2.pie((male_count,female_count), labels = ('Male','Female'), autopct='%1.1f%%', shadow=True, startangle=90, explode=[0,0.3])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"6ab844c988891f1c1c4217b6904942e631d51b9c","_kg_hide-input":true},"cell_type":"code","source":"# Population Distribution with age and sex\n\nfig, (ax1,ax2) = plt.subplots(1,2, figsize = (20,5),constrained_layout=True)\nbin_x = range(25,80,2)\n\nax1.hist(heart_data.age.tolist(),bins=bin_x,rwidth=0.9)\nax1.set_xticks(range(25,80,2))\nax1.set_xlabel('Age',fontsize=15)\nax1.set_ylabel('Population Count',fontsize=15)\nax1.set_title('Total population distribution',fontsize=20)\n\nax2.hist(heart_data[heart_data['sex']==1].age.tolist(),label = 'Male',bins=bin_x,rwidth=0.9)\nax2.hist(heart_data[heart_data['sex']==0].age.tolist(),label = 'Female',bins=bin_x,rwidth=0.5)\nax2.legend()\nax2.set_xticks(range(25,80,2))\nax2.set_xlabel('Age',fontsize=15)\nax2.set_ylabel('Population Count',fontsize=15)\nax2.set_title('Male vs female',fontsize=20)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b16fdee49c128f0aa8bc4009e3349d9fdde4270c","scrolled":true,"_kg_hide-input":true},"cell_type":"code","source":"# Population distribution for heart disease\n\nx = heart_data.groupby(['age','target']).agg({'sex':'count'})\ny = heart_data.groupby(['age']).agg({'sex':'count'})\nz = (x.div(y, level='age') * 100)\nq= 100 - z\n\nfig, axes = plt.subplots(2,2, figsize = (20,12))\nplt.subplots_adjust(hspace = 0.5)\n\naxes[0,0].hist(heart_data[heart_data['target']==1].age.tolist(),bins=bin_x,rwidth=0.8)\naxes[0,0].set_xticks(range(25,80,2))\naxes[0,0].set_xlabel('Age Range',fontsize=15)\naxes[0,0].set_ylabel('Population Count',fontsize=15)\naxes[0,0].set_title('People suffering from heart disease',fontsize=20)\n\naxes[0,1].hist(heart_data[heart_data['target']==0].age.tolist(),bins=bin_x,rwidth=0.8)\naxes[0,1].set_xticks(range(25,80,2))\naxes[0,1].set_xlabel('Age Range',fontsize=15)\naxes[0,1].set_ylabel('Population Count',fontsize=15)\naxes[0,1].set_title('People not suffering from heart disease',fontsize=20)\n\naxes[1,0].scatter(z.xs(1,level=1).reset_index().age,z.xs(1,level=1).reset_index().sex,s=(x.xs(1,level=1).sex)*30,edgecolors = 'r',c = 'yellow')\naxes[1,0].plot(z.xs(1,level=1).reset_index().age,z.xs(1,level=1).reset_index().sex)\naxes[1,0].set_xticks(range(25,80,2))\naxes[1,0].set_yticks(range(0,110,5))\naxes[1,0].set_xlabel('Age',fontsize=15)\naxes[1,0].set_ylabel('%',fontsize=15)\naxes[1,0].set_title('% of people with heart disease by age',fontsize=20)\n\naxes[1,1].scatter(z.xs(1,level=1).reset_index().age,q.xs(1,level=1).reset_index().sex,s=(x.xs(0,level=1).sex)*30,edgecolors = 'r',c = 'yellow')\naxes[1,1].plot(z.xs(1,level=1).reset_index().age,q.xs(1,level=1).reset_index().sex)\naxes[1,1].set_xticks(range(25,80,2))\naxes[1,1].set_yticks(range(0,110,5))\naxes[1,1].set_xlabel('Age',fontsize=15)\naxes[1,1].set_ylabel('%',fontsize=15)\naxes[1,1].set_title('% of people with no heart disease by age',fontsize=20)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f159cfdac7f61482a4d2c4147992c788d00a95f9"},"cell_type":"markdown","source":"# Analysis :\n> * **Data has lot more entries for Male compare to Female**\n> * **Majority of people suffering from heart disease lies between age 40 to 65**\n> * **Proability of getting heart disease starts reduce significiently after age of 60**\n> * **People from age 37 to 59 has highest chance of getting heart disease by volume**"},{"metadata":{"trusted":true,"_uuid":"175f6d1f3f11f78cd06ba7893eb20957f5bd96d3"},"cell_type":"code","source":"# Looking at other features and how they are distributed.\n# Scatter plot for continuous data\n# Pie plot for catagorical data","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"scrolled":true,"_uuid":"25000e41aa6c7a2ecab386ad040213035c3703c9"},"cell_type":"code","source":"fig, axes = plt.subplots(6,2, figsize = (20,40))\nplt.subplots_adjust(hspace = 0.5)\n\naxes[0,0].scatter(heart_data[heart_data['target']==0][['age','thalach']].sort_values(by = ['age']).age,heart_data[heart_data['target']==0][['age','thalach']].sort_values(by = ['age']).thalach, c = 'g',label = 'target=0')\naxes[0,0].scatter(heart_data[heart_data['target']==1][['age','thalach']].sort_values(by = ['age']).age,heart_data[heart_data['target']==1][['age','thalach']].sort_values(by = ['age']).thalach, c = 'r',label = 'target=1')\naxes[0,0].set_title('thalach distribution',fontsize=20)\naxes[0,0].set_xticks(range(25,80,2))\naxes[0,0].set_xlabel('Age',fontsize=15)\naxes[0,0].set_ylabel('thalach',fontsize=15)\naxes[0,0].axhline(np.mean(heart_data['thalach']),xmin=0,xmax=1,linewidth=1, color='black',linestyle = '--')\naxes[0,0].axvline(np.mean(heart_data['age']),ymin=0,ymax=1,linewidth=1, color='b',linestyle = '--')\naxes[0,0].legend()\n\naxes[0,1].scatter(heart_data[heart_data['target']==0][['age','trestbps']].sort_values(by = ['age']).age,heart_data[heart_data['target']==0][['age','trestbps']].sort_values(by = ['age']).trestbps, c = 'g',label = 'target=0')\naxes[0,1].scatter(heart_data[heart_data['target']==1][['age','trestbps']].sort_values(by = ['age']).age,heart_data[heart_data['target']==1][['age','trestbps']].sort_values(by = ['age']).trestbps, c = 'r',label = 'target=1')\naxes[0,1].set_title('trestbps distribution',fontsize=20)\naxes[0,1].set_xticks(range(25,80,2))\naxes[0,1].set_xlabel('Age',fontsize=15)\naxes[0,1].set_ylabel('trestbps',fontsize=15)\naxes[0,1].axhline(np.mean(heart_data['trestbps']),xmin=0,xmax=1,linewidth=1, color='r',linestyle = '--')\naxes[0,1].axvline(np.mean(heart_data['age']),ymin=0,ymax=1,linewidth=1, color='b',linestyle = '--')\n\n# heart_data[heart_data['target']==1][['age','chol',]].sort_values(by = ['age'])\naxes[1,0].scatter(heart_data[heart_data['target']==0][['age','chol',]].sort_values(by = ['age']).age,heart_data[heart_data['target']==0][['age','chol',]].sort_values(by = ['age']).chol,c = 'g',label = 'target=0')\naxes[1,0].scatter(heart_data[heart_data['target']==1][['age','chol',]].sort_values(by = ['age']).age,heart_data[heart_data['target']==1][['age','chol',]].sort_values(by = ['age']).chol,c = 'r',label = 'target=1')\naxes[1,0].set_title('chol distribution',fontsize=20)\naxes[1,0].set_xticks(range(25,80,2))\naxes[1,0].set_xlabel('Age',fontsize=15)\naxes[1,0].set_ylabel('chol',fontsize=15)\naxes[1,0].axhline(np.mean(heart_data['chol']),xmin=0,xmax=1,linewidth=1, color='r',linestyle = '--')\naxes[1,0].axvline(np.mean(heart_data['age']),ymin=0,ymax=1,linewidth=1, color='b',linestyle = '--')\n\naxes[1,1].scatter(heart_data[heart_data['target']==0][['age','oldpeak',]].sort_values(by = ['age']).age,heart_data[heart_data['target']==0][['age','oldpeak',]].sort_values(by = ['age']).oldpeak,c = 'g',label = 'target=0')\naxes[1,1].scatter(heart_data[heart_data['target']==1][['age','oldpeak',]].sort_values(by = ['age']).age,heart_data[heart_data['target']==1][['age','oldpeak',]].sort_values(by = ['age']).oldpeak,c = 'r',label = 'target=1')\naxes[1,1].set_title('oldpeak distribution',fontsize=20)\naxes[1,1].set_xticks(range(25,80,2))\naxes[1,1].set_xlabel('Age',fontsize=15)\naxes[1,1].set_ylabel('oldpeak',fontsize=15)\naxes[1,1].axhline(np.mean(heart_data['oldpeak']),xmin=0,xmax=1,linewidth=1, color='r',linestyle = '--')\naxes[1,1].axvline(np.mean(heart_data['age']),ymin=0,ymax=1,linewidth=1, color='b',linestyle = '--')\n\nfbs_count = heart_data['fbs'].value_counts()\nlabels = [('fbs = '+ str(x)) for x in fbs_count.index]\naxes[2,0].pie(fbs_count,labels = labels,autopct='%1.1f%%',shadow=True, startangle=45)\naxes[2,0].axis('equal')\naxes[2,0].set_title('fbs share',fontsize=15)\n\nrestecg_count = heart_data['restecg'].value_counts()\nlabels = [('restecg = '+ str(x)) for x in restecg_count.index]\naxes[2,1].pie(restecg_count,labels = labels,autopct='%1.1f%%',shadow=True, startangle=45,explode = [0,0,0.5])\naxes[2,1].axis('equal')\naxes[2,1].set_title('restecg share',fontsize=15)\n\nexang_count = heart_data['exang'].value_counts()\nlabels = [('exang = '+ str(x)) for x in exang_count.index]\naxes[3,0].pie(exang_count,labels = labels,autopct='%1.1f%%',shadow=True, startangle=45)\naxes[3,0].axis('equal')\naxes[3,0].set_title('exang share',fontsize=15)\n\nslope_count = heart_data['slope'].value_counts()\nlabels = [('slope = '+ str(x)) for x in slope_count.index]\naxes[3,1].pie(slope_count,labels = labels,autopct='%1.1f%%',shadow=True, startangle=45)\naxes[3,1].axis('equal')\naxes[3,1].set_title('slope share',fontsize=15)\n\nca_count = heart_data['ca'].value_counts()\nlabels = [('ca = '+ str(x)) for x in ca_count.index]\naxes[4,0].pie(ca_count,labels = labels,autopct='%1.1f%%',shadow=True, startangle=45)\naxes[4,0].axis('equal')\naxes[4,0].set_title('ca share',fontsize=15)\n\nthal_count = heart_data['thal'].value_counts()\nlabels = [('thal = '+ str(x)) for x in thal_count.index]\naxes[4,1].pie(thal_count,labels = labels,autopct='%1.1f%%',shadow=True, startangle=45)\naxes[4,1].axis('equal')\naxes[4,1].set_title('thal share',fontsize=15)\n\ncp_count = heart_data['cp'].value_counts()\nlabels = [('cp = '+ str(x)) for x in cp_count.index]\naxes[5,0].pie(cp_count,labels = labels,autopct='%1.1f%%',shadow=True, startangle=45)\naxes[5,0].axis('equal')\naxes[5,0].set_title('CP share',fontsize=15)\n\ntarget_count = heart_data['target'].value_counts()\nlabels = [('target = '+ str(x)) for x in target_count.index]\naxes[5,1].pie(target_count,labels = labels,autopct='%1.1f%%',shadow=True, startangle=45)\naxes[5,1].axis('equal')\naxes[5,1].set_title('target share',fontsize=15)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c1d55100861e5174670d7277ca95efd4f0ebcc5e"},"cell_type":"code","source":"#  Lets look at the correlation matrix and plot it using Pandas Style and Matplotlib\nheart_data.corr().round(decimals =2).style.background_gradient(cmap = 'Oranges')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"353028be620be133241a282afd9e776d1f281300"},"cell_type":"code","source":"names = ['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','target']\ncorrelations = heart_data.corr()\n# plot correlation matrix\nfig, ax = plt.subplots(1,1, figsize = (10,8),constrained_layout=True)\n\ncax = ax.matshow(correlations, vmin=-1, vmax=1,cmap = 'afmhot')\nfig.colorbar(cax)\nticks = np.arange(0,14,1)\nax.set_xticks(ticks)\nax.set_yticks(ticks)\nax.set_xticklabels(names)\nax.set_yticklabels(names)\nfor i in range(len(names)):\n    for j in range(len(names)):\n        text = ax.text(j, i, heart_data.corr().as_matrix(columns= None)[i, j].round(decimals =2),\n                       ha=\"center\", va=\"center\", color=\"black\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29eb4c81e4e253592c8f18f9bb18ff8c854dd8a2"},"cell_type":"code","source":"# Corelation with target\n\nx = heart_data.corr()\npd.DataFrame(x['target']).sort_values(by='target',ascending = False).style.background_gradient(cmap = 'Greens')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd171149c24a534cb632b7e877a2acf453572713"},"cell_type":"code","source":"# Importing stuff\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import MinMaxScaler,RobustScaler, StandardScaler, OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8e8dcf2b82a68065a4c402c74eaa3dc8927c39b0"},"cell_type":"markdown","source":"# Pre-Processing\n* Scaling the Data before doing anomoly detection\n* As anomoly detection methods works better with scaled data, but there is no compulsory need to do so.\n* Scale only continious data"},{"metadata":{"trusted":true,"_uuid":"543b47944a1b38e8b84286c4fe511c7eb1f8fac4","_kg_hide-input":true},"cell_type":"code","source":"# We have already saved all the continous columns\n\nprint('Columns with continous data = ',num_columns)\n\nimport scipy.stats as stats\n\nfig, axes = plt.subplots(2,2, figsize = (15,12))\nplt.subplots_adjust(hspace = 0.2)\n\nh= np.sort(heart_data.thalach)\nfit = stats.norm.pdf(h, np.mean(h), np.std(h)) \naxes[0,0].plot(h,fit,'--')\naxes[0,0].hist(h,density=True) \naxes[0,0].set_title(\"thalach\")\naxes[0,0].set_ylabel('Density')\n\nh2= np.sort(heart_data.trestbps)\nfit2 = stats.norm.pdf(h2, np.mean(h2), np.std(h2)) \naxes[0,1].plot(h2,fit2,'--')\naxes[0,1].hist(h2,density=True) \naxes[0,1].set_title(\"trestbps\")\naxes[0,1].set_ylabel('Density')\n\nh3= np.sort(heart_data.chol)\nfit3 = stats.norm.pdf(h3, np.mean(h3), np.std(h3)) \naxes[1,0].plot(h3,fit3,'--')\naxes[1,0].hist(h3,density=True) \naxes[1,0].set_title(\"chol\")\naxes[1,0].set_ylabel('Density')\n\nh4= np.sort(heart_data.oldpeak)\nfit4 = stats.norm.pdf(h4, np.mean(h4), np.std(h4)) \naxes[1,1].plot(h4,fit4,'--')\naxes[1,1].hist(h4,density=True) \naxes[1,1].set_title(\"oldpeak\")\naxes[1,1].set_ylabel('Density')\n\nplt.show()\n\nprint(r\"Scaling them using MinMax Scaler\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"705656be0e6b18b80c976d21a0cd97b9f0ca578d","scrolled":false},"cell_type":"code","source":"mm = MinMaxScaler()\n\nnum_data = heart_data[num_columns]\nnum_data_tf = mm.fit_transform(num_data)\nnum_data_tf","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4e644122787b07c730cc3ee713c088bfc52d4738"},"cell_type":"markdown","source":"# One Hot encoding all catagorical columns"},{"metadata":{"trusted":true,"_uuid":"f60d1aadca33fac972b347d65dc168a1b633c762"},"cell_type":"code","source":"ohe = OneHotEncoder()\n\ncat_columns.remove('target')\nprint(cat_columns)\ncat_data = heart_data[cat_columns]\ncat_data_tf = ohe.fit_transform(cat_data).toarray()\n\nheart_data_tf = np.hstack([num_data_tf,cat_data_tf])\nheart_data_tf","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"126723e8ded42149c4ccd31abec9ddf8bd312938"},"cell_type":"markdown","source":"# Anomoly detection with combination of two methods. Just to be sure we are not removing more relevant data."},{"metadata":{"trusted":true,"_uuid":"7ba046861862bf85ea727f4c628352ebfbe54f7c","scrolled":true,"_kg_hide-input":false},"cell_type":"code","source":"# Anomoly detection with DBscan (eps value was set using trial and error)\nfrom sklearn.cluster import DBSCAN\ndbscan = DBSCAN(eps=2.05)\npred = dbscan.fit_predict(heart_data_tf)\ndbanom = heart_data[pred == -1]\n\ncolumns_continous_data =  ['trestbps', 'chol', 'thalach', 'oldpeak']\n\nfig, axes = plt.subplots(2,2, figsize = (10,8))\n\np =0\nfor i in range(0,2):\n    for j in range(0,2):\n        axes[i,j].scatter(heart_data.index,heart_data[columns_continous_data[p]])\n        axes[i,j].scatter(dbanom.index,dbanom[columns_continous_data[p]],c='r')\n        axes[i,j].set_title('Anomalies with DBSCAN'+\" | plot = \"+columns_continous_data[p])\n        p +=1\n        \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"80c6ef64b46cbd014f46a92fe0b1ad30fb8830d7"},"cell_type":"code","source":"#  Anomoly detection with EE\nfrom sklearn.covariance import EllipticEnvelope\nee = EllipticEnvelope(contamination=.03)\nee.fit_predict(heart_data_tf)\neeanom = heart_data[ee.predict(heart_data_tf) == -1]\n\nfig, axes = plt.subplots(2,2, figsize = (10,8))\n\np =0\nfor i in range(0,2):\n    for j in range(0,2):\n        axes[i,j].scatter(heart_data.index,heart_data[columns_continous_data[p]])\n        axes[i,j].scatter(eeanom.index,eeanom[columns_continous_data[p]],c='r')\n        axes[i,j].set_title('Anomalies with DBSCAN'+\" | plot = \"+columns_continous_data[p])\n        p +=1\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"19c22bed89cdfde2e7cc77ad9b999e11cb250683","scrolled":true},"cell_type":"code","source":"#Checking for similar Anomolies in both above methods and removing them from dataset\ndf = pd.DataFrame\ndf= dbanom.index.intersection(eeanom.index)\nheart_data_tf_df = pd.DataFrame(heart_data_tf)\nheart_data_tf_df.drop(df,inplace = True)\nheart_data.drop(df,inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7e41c6605a0dc5d0de9e2c15baad19e26896ed91"},"cell_type":"code","source":"heart_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7eb7af1254fe5bf9168c6ee06a7af05081e9d65d"},"cell_type":"code","source":"heart_data_tf_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"99ec3ab543b6bf4b548022176c198458b1cb1c54"},"cell_type":"code","source":"heart_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8141024a1a8db0d21bde96c6cb9b77ad1b2b7295"},"cell_type":"code","source":"# Set X as feature data and Y as target data for Unscaled Data. set X_tf as feature data for scaled data.\nX = heart_data.drop(['target'],axis =1)\nY = heart_data.target\n\nX_tf = heart_data_tf_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7cf2b07ab97b8172b3e99888e4ee4b2ff292d1f6"},"cell_type":"markdown","source":"# Chi-Square for Non-negative feature & class, feature selection method to check dependency among feature & target"},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"6fafb3e3ab736f8dcaceb5be89ea4a491e7da095"},"cell_type":"code","source":"from sklearn import feature_selection\nchi2, pval = feature_selection.chi2(X,Y)\nprint(chi2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c149ed1450c4385cf5e3ad61a6fb62398b36db16","_kg_hide-input":true},"cell_type":"code","source":"print(X.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bad1f7b28b6b1ddb4e24326f49b58c6a84cd1b24"},"cell_type":"code","source":"dep = pd.DataFrame(chi2)\ndep.columns = ['Dependency']\ndep.index = X.columns\nprint(\"\"\"Looks like \"fbs\" has lowest effect on target and \"thalach\" has highest\"\"\")\ndep.sort_values('Dependency', ascending = False).style.background_gradient(cmap = 'terrain')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"751476aa63d1ee7b9e883655100a66d2ec0fcc06"},"cell_type":"code","source":"# Since the number of columns are not much and all features looks important, we can go ahead with same number of columns. ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"57d071b8876438419cd5c3661384443923767d1e"},"cell_type":"markdown","source":"# Check for target imbalance"},{"metadata":{"trusted":true,"_uuid":"b895cf02ed35329c63a7d124d9c9589c3c59026a","scrolled":false},"cell_type":"code","source":"Y.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c99afa6f13fe0f8f91dc1562a9f2ffa19f92fb7"},"cell_type":"code","source":"# Target is not much imbalanced and there is no need to balance it, but will use oversampling, SMOTE method to balance data.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4cff92fdf39f5c2a6ad8c6ed92cdd8db45cf26c6"},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nsmote = SMOTE()\nX_reshaped, Y_reshaped = SMOTE().fit_sample(X, Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5a54d81171db2a9f099b4120855d20b6a9e9c832"},"cell_type":"code","source":"import collections\ncollections.Counter(Y_reshaped)\n# Balanced the classes, but will not use it in predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1039a4ce264a9d8f58331798b7e700a5461fc762"},"cell_type":"code","source":"print(\"Split the data into train and test with unscaled data:\")\ntrainX,testX,trainY,testY = train_test_split(X,Y,test_size = 0.3,random_state = None)\nprint(\"trainX,testX,trainY,testY\")\nprint(\"Split the data into train and test with un scaled data:\")\ntrainX_tf,testX_tf,trainY_tf,testY_tf = train_test_split(X_tf,Y,test_size = 0.3,random_state = None)\nprint(\"trainX_tf,testX_tf,trainY_tf,testY_tf\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8fd15307037129a0c642b8dce1bc454a86710413"},"cell_type":"markdown","source":"# Using Random Forest Classifier with unscalled data and Grid Search CV"},{"metadata":{"trusted":true,"_uuid":"e04295a5676e7875ec6723fb82a8ce0c314b43be"},"cell_type":"code","source":"rf = RandomForestClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a151aa188f11f2580b8db4141ac927bae94b3b8"},"cell_type":"code","source":"#Using grid search to get best params for Randomforest\nparams = {\n    'n_estimators':[10,50,100,150,200,250],\n    'random_state': [10,5,15,20,50]\n         }\ngs = GridSearchCV(rf, param_grid=params, cv=5, n_jobs=-1)\ngs.fit(trainX,trainY)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"ce889a3f5da5cd216154fcc1fe772ee0eccabcb6"},"cell_type":"code","source":"n_est = []\nrnd_sta = []\nscore = []\nrand_state_list =  [5,10,15,20,50]\nfor x in range(len(gs.cv_results_['params'])):\n    n_est.append(gs.cv_results_['params'][x]['n_estimators'])\n    rnd_sta.append(gs.cv_results_['params'][x]['random_state'])\n    score.append(gs.cv_results_['mean_test_score'][x])\n\ngrid_frame = pd.DataFrame()\ngrid_frame['n_est'] = n_est\ngrid_frame['rnd_sta'] = rnd_sta\ngrid_frame['score'] = score\n\ngrid_frame[grid_frame['rnd_sta'] == 10]\n\nplt.figure(figsize=(10,6))\n\nfor value in rand_state_list:\n    plt.plot(grid_frame[grid_frame['rnd_sta'] == value].n_est,grid_frame[grid_frame['rnd_sta'] == value].score,'-o',label = 'random_state = value')\n\nplt.title('Mean Score with different params')\nplt.grid(True)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1deaaaa03aad81d7433efe67db1e9813a4b450b6","scrolled":true},"cell_type":"code","source":"# Grid Search Score with test Data\nprint(\"Grid search score with random forest classifier = \",gs.score(testX,testY)*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f2bc82dc158dd98cfc57bcca10451dd01ad0cbf","scrolled":true},"cell_type":"code","source":"#Best Params\ngs.best_params_","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"trusted":true,"scrolled":true,"_uuid":"c9334d7314ef05afd276800e75e322310d316831"},"cell_type":"code","source":"# Creating the Confusion matrix\npred = gs.predict(testX)\nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(y_pred=pred, y_true=testY)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c220cb9828f44282c5ca267100b9d3a8ace8072a"},"cell_type":"code","source":"# Using grid search to get best params for Randomforest . Now with scaled data (StandardScaler)\nparams = {\n    'n_estimators':[10,50,100,150,200,250,300],\n    'random_state': [10,5,15,20,50]\n         }\ngs = GridSearchCV(rf, param_grid=params, cv=10, n_jobs=-1)\ngs.fit(trainX_tf,trainY_tf)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true,"_uuid":"97c4e5310427662dadf70b008dc412a75d805ed9"},"cell_type":"code","source":"n_est = []\nrnd_sta = []\nscore = []\nfor x in range(len(gs.cv_results_['params'])):\n    n_est.append(gs.cv_results_['params'][x]['n_estimators'])\n    rnd_sta.append(gs.cv_results_['params'][x]['random_state'])\n    score.append(gs.cv_results_['mean_test_score'][x])\n\ngrid_frame = pd.DataFrame()\ngrid_frame['n_est'] = n_est\ngrid_frame['rnd_sta'] = rnd_sta\ngrid_frame['score'] = score\n\ngrid_frame[grid_frame['rnd_sta'] == 10]\n\nplt.figure(figsize=(10,6))\n\nfor value in rand_state_list:\n    plt.plot(grid_frame[grid_frame['rnd_sta'] == value].n_est,grid_frame[grid_frame['rnd_sta'] == value].score,'-o',label = 'random_state = value')\n\nplt.title('Mean Score with different params')\nplt.grid(True)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"87aa0c3132480f3bd8fe70b72c723ce5aa55eedf"},"cell_type":"code","source":"# Grid Search Score wih scaled test data \nprint(\"Grid search score with random forest classifier (Scaled Data)= \",gs.score(testX_tf,testY_tf)*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"633738065efb3e5d4e494781f9bad8f82490bccf"},"cell_type":"code","source":"#Best Params (We save best params for future use)\nprint(gs.best_params_)\nn_est = gs.best_params_['n_estimators']\nrnd_st = gs.best_params_['random_state']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ebfb2380d73552ac9a98990e96c1f4e808854952"},"cell_type":"code","source":"# Creating the Confusion matrix\npred = gs.predict(testX_tf)\nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(y_pred=pred, y_true=testY_tf)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eb49e45862a0d27574b8e7686d18f6f07453548f"},"cell_type":"markdown","source":"# Now Using other Methods including Random Forest, with Unscalled and scaled data."},{"metadata":{"trusted":true,"_uuid":"f00a7b01f82fc7cfece83d4b6fa8000a00b73215"},"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier,ExtraTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier,RandomForestClassifier, VotingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"382e4ab3160759ce0eeebcc4d829113ee024ae89"},"cell_type":"code","source":"models = [SVC(kernel='linear',C =100),\n          SGDClassifier(max_iter=1000,tol=0.003),\n          DecisionTreeClassifier(),\n          ExtraTreeClassifier(),\n          AdaBoostClassifier(), \n          BaggingClassifier(), \n          GradientBoostingClassifier(),\n          RandomForestClassifier(n_estimators=n_est,random_state=rnd_st),\n          GaussianNB(),\n          KNeighborsClassifier(), \n          LogisticRegression(max_iter=1000,solver='lbfgs')]\n\nmodelnames = ['SVC',\n              'SGDClassifier',\n              'DecisionTreeClassifier',\n              'ExtraTreeClassifier',\n              'AdaBoostClassifier', \n              'BaggingClassifier', \n              'GradientBoostingClassifier',\n              'RandomForestClassifier',\n              'GaussianNB',\n              'KNeighborsClassifier', \n              'LogisticRegression']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"2214afac3b40799973e725fcfbc8d53e5eb3211d"},"cell_type":"code","source":"# Train and test with unscaled model\nscores_unscaled = []\nfor index,model in enumerate(models):\n    try:\n        model.fit(trainX,trainY)\n        print(modelnames[index],\"Accuracy =\",round(model.score(testX,testY)*100,2),\"%\")\n        scores_unscaled.append(round(model.score(testX,testY)*100,2))\n    except:\n        print(\"Skipped\",modelnames[index])","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# plt.bar(range(len(modelnames)),scores_unscaled, color = ['blue','red'])\nplt.plot(range(len(modelnames)),scores_unscaled, '-o')\n\nplt.xticks(range(0,11,1),labels = modelnames, rotation = 90)\nplt.grid(visible=True)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"4d02b9a08333cbd562101d59d0ff5aad44b8afc3"},"cell_type":"code","source":"# Train and test with scaled model\nscores_unscaled = []\nfor index,model in enumerate(models):\n    try:\n        model.fit(trainX_tf,trainY_tf)\n        print(modelnames[index],\"Accuracy =\",round(model.score(testX_tf,testY_tf)*100,2),\"%\")\n        scores_unscaled.append(round(model.score(testX_tf,testY_tf)*100,2))\n    except:\n        print(\"Skipped\",modelnames[index])","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.plot(range(len(modelnames)),scores_unscaled, '-o')\n\nplt.xticks(range(0,11,1),labels = modelnames, rotation = 90)\nplt.grid(visible=True)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2c6d94628dfab7897a2b5dfeab3cdff76c8b268"},"cell_type":"markdown","source":"# Lets work on AdaBoost and try to use other base estimators and check if we can improve score further."},{"metadata":{"trusted":true,"_uuid":"44edd70171ffa9bfdf16f3bf2c1b4574c5f0546f"},"cell_type":"code","source":"#  base_estimator=DecisionTreeClassifier\nab = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(),n_estimators=1000)\nab.fit(trainX,trainY)\nprint('AdaBoost Accuracy with Decision Tree = ',(ab.score(testX,testY)*100))\n\nab = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(),n_estimators=1000)\nab.fit(trainX_tf,trainY_tf)\nprint('AdaBoost Accuracy with Decision Tree (Scaled Data)= ',(ab.score(testX_tf,testY_tf)*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"35aed234202b4adbe2b4d2b7c4d4cc40a02dba31"},"cell_type":"code","source":"#  base_estimator=RandomForest\nab = AdaBoostClassifier(base_estimator=RandomForestClassifier(n_estimators=1000,random_state=10),n_estimators=1000)\nab.fit(trainX,trainY)\nprint('AdaBoost Accuracy with Random Forest = ',(ab.score(testX,testY)*100))\n\nab = AdaBoostClassifier(base_estimator=RandomForestClassifier(n_estimators=1000,random_state=10),n_estimators=1000)\nab.fit(trainX_tf,trainY_tf)\nprint('AdaBoost Accuracy with Random Forest (Scaled Data)= ',(ab.score(testX_tf,testY_tf)*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5f442e79bbc058978aad0f09f7e1adcbeac0332a"},"cell_type":"code","source":"#  base_estimator=LogisticRegression\nab = AdaBoostClassifier(base_estimator=LogisticRegression(max_iter=1000,solver = 'lbfgs'),n_estimators=1000)\nab.fit(trainX,trainY)\nprint('AdaBoost Accuracy with Logistic Reg = ',(ab.score(testX,testY)*100))\n\nab = AdaBoostClassifier(base_estimator=LogisticRegression(max_iter=1000,solver = 'lbfgs'),n_estimators=1000)\nab.fit(trainX_tf,trainY_tf)\nprint('AdaBoost Accuracy with Logistic Reg (Scaled Data)= ',(ab.score(testX_tf,testY_tf)*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11f3d2dcb42c49bcd0720d537479b57853cceee9"},"cell_type":"code","source":"#  base_estimator=SVC\nab = AdaBoostClassifier(algorithm='SAMME',base_estimator=SVC(kernel='linear',C = 1000, gamma=1),n_estimators=1000)\nab.fit(trainX,trainY)\nprint('AdaBoost Accuracy with SVC = ',(ab.score(testX,testY)*100))\n\nab = AdaBoostClassifier(algorithm='SAMME',base_estimator=SVC(kernel='linear',C = 1000, gamma=1),n_estimators=1000)\nab.fit(trainX_tf,trainY_tf)\nprint('AdaBoost Accuracy with SVC = (Scaled Data)',(ab.score(testX_tf,testY_tf)*100))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"03ac82a2fa48d588fee5244a3a228f039115d150"},"cell_type":"markdown","source":"# Lets use Voting classifier to calculate a robust score. (Unscaled Data)"},{"metadata":{"trusted":true,"_uuid":"3ae97d88fc9f58de0c4008d0af758cfd7b35a657"},"cell_type":"code","source":"estimators = [ \n    ('RandomForestClassifier',RandomForestClassifier(n_estimators=n_est, random_state=rnd_st)),\n    ('SVC(kernel= rfb',SVC(kernel='rbf', probability=True,gamma=1)),\n    ('SVC(kernel= linear',SVC(kernel='linear',C = 100, gamma=1, probability=True)),\n    ('KNeighborsClassifier',KNeighborsClassifier()),\n    ('AdaBoostClassifier LR',AdaBoostClassifier(base_estimator=LogisticRegression(solver = 'lbfgs'),n_estimators=1000)),\n    ('LogisticRegression',LogisticRegression(max_iter= 10000,solver = 'lbfgs')),\n    ('GaussianNB',GaussianNB())\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ebd5a455511d2e8819fcb0739928b9b345b64f9"},"cell_type":"code","source":"vc = VotingClassifier(estimators=estimators, voting='hard')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea9a97d3155e877ac1a7bca9a30d293acce34d39"},"cell_type":"code","source":"vc.fit(trainX,trainY)\nprint('Voting Classifier accuracy = ',(vc.score(testX,testY)*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fca7a6c002ccf4c46286c1c139750c896195be38"},"cell_type":"code","source":"# Checking who contribute what % in voting","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6de2cdaf6454c7626b6edcd3f8255474735cc9c8","scrolled":false},"cell_type":"code","source":"weights = []\nfor est,name in zip(vc.estimators_,vc.estimators):\n    score = est.score(testX,testY)\n    print (name[0], score*100)\n    weights.append((100/(10-(score*10))))\n# Converting n saving Score in weights to be used later\nprint('Weights = ', weights)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9098ee4c68c3dbdbdf101daaf1edf7cb90b2a27e","scrolled":true},"cell_type":"code","source":"# Adjusting weights and recalculating accuracy\nvc = VotingClassifier(estimators=estimators, voting='soft', weights=weights)\nvc.fit(trainX,trainY)\nprint('Voting Classifier accuracy = ',(vc.score(testX,testY)*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Voting classifier to calculate a robust score. (Scaled Data)"},{"metadata":{"trusted":true},"cell_type":"code","source":"vc.fit(trainX_tf,trainY_tf)\nprint('Voting Classifier accuracy = ',(vc.score(testX_tf,testY_tf)*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weights = []\nfor est,name in zip(vc.estimators_,vc.estimators):\n    score = est.score(testX_tf,testY_tf)\n    print (name[0], score*100)\n    weights.append((100/(10-(score*10))))\n# Converting n saving Score in weights to be used later\nprint('Weights = ', weights)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}