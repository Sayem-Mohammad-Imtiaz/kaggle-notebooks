{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Importing all the necessary libraries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom wordcloud import WordCloud, STOPWORDS\nimport seaborn as sns\nfrom os import path\nsns.set()\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, f1_score\nimport datetime as dt\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nimport calendar\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n%matplotlib inline\nimport time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing the csv data files \nsarcasm_df = pd.read_csv('../input/sarcasm/train-balanced-sarcasm.csv')\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data Pre-Processing\n# Removing the null comments\nsarcasm_df.dropna(subset=['comment'], inplace=True)\nsarcasm_df['comment'] = sarcasm_df['comment'].str.lower()\nsarcasm_df['comment'] = sarcasm_df['comment'].str.replace('[^\\w\\s]','')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting the timestamp into DateTime object\nsarcasm_df.created_utc = pd.to_datetime(sarcasm_df.created_utc)\nsarcasm_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis"},{"metadata":{},"cell_type":"markdown","source":"## Distribution of the classes in the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(5,5))\nax = sns.countplot(x='label',  data= sarcasm_df)\nax.set(title = \"Distribution of Classes\", xlabel=\"Sarcasm Status\", ylabel = \"Total Count\")\ntotal = float(len(sarcasm_df ))\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()/2.,\n            height + 3,\n            '{:1.1f}%'.format((height/total)*100),\n            ha=\"center\") \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The figure above ensures that the dataset is balanced as the proportion of the sarcastic and non-sarcastic comments are same i.e.- 50%"},{"metadata":{},"cell_type":"markdown","source":"## Length of the comments"},{"metadata":{},"cell_type":"markdown","source":"Lets see if there is any relation between the length of the comment and the comment being sarcastic"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distribution of the lenth of Sarcastic comments\nsns.boxplot(x= sarcasm_df.loc[sarcasm_df['label'] == 1, 'comment'].str.len()).set(title = 'Length of Sarcastic Comments', xlabel = 'Length')\nsns.despine(offset=10, trim=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distribution of the lenth of Neutral comments\nsns.boxplot(x= sarcasm_df.loc[sarcasm_df['label'] == 0, 'comment'].str.len()).set(title = 'Length of Neutral Comments', xlabel = 'Length')\nsns.despine(offset=10, trim=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since the dataset is skewed log transformations are being made\n\nNatural Log Length of Comments for Sarcastic and Non-Sarcastic Comments"},{"metadata":{"trusted":true},"cell_type":"code","source":"sarcasm_df['log_comment'] = sarcasm_df['comment'].apply(lambda text: np.log1p(len(text)))\nsarcasm_df[sarcasm_df['label']==1]['log_comment'].hist(alpha=0.6,label='Sarcastic', color = 'blue')\nsarcasm_df[sarcasm_df['label']==0]['log_comment'].hist(alpha=0.6,label='Non-Sarcastic', color = 'red')\nplt.legend()\nplt.title('Natural Log Length of Comments')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"According to the graph above the lenght of the sarcastic comments is notmally distributed where as the non-sarcastic comments is slightly negatively skewed."},{"metadata":{},"cell_type":"markdown","source":"## Wordcloud of  Sarcastic comments"},{"metadata":{"trusted":true},"cell_type":"code","source":"wordcloud = WordCloud(background_color='black', stopwords = STOPWORDS,\n                max_words = 200, max_font_size = 100, \n                random_state = 17, width=800, height=400)\n\nplt.figure(figsize=(12, 12))\nwordcloud.generate(str(sarcasm_df.loc[sarcasm_df['label'] == 1, 'comment']))\nplt.grid(b= False)\nplt.imshow(wordcloud);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Popularity of the comments according to being sarcastic"},{"metadata":{},"cell_type":"markdown","source":"With the help of the score of the comments, we can determine whether the sarcastic comments are more popular in Reddit discussions."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting the scores into numpy array\nsarcasm_score = np.array(sarcasm_df.loc[sarcasm_df['label'] == 1]['score'])\nneutral_score = np.array(sarcasm_df.loc[sarcasm_df['label'] == 0]['score'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Displaying the distribution of Marital Status in a Pie chart\nlabels = ['Sarcastic Score', 'Neutral Score']\nsizes = [3235069, 3725113]\n#colors\ncolors = ['#F21F3B', '#1FF257']\n \nplt.rcParams.update({'font.size': 14})\nfig1, ax1 = plt.subplots()\nax1.pie(sizes, colors = colors, labels=labels, autopct='%1.1f%%', startangle=30)\nax1.set_title(\"Scores of Subreddits\")\n#draw circle\ncentre_circle = plt.Circle((0,0),0.70,fc='white')\nfig = plt.gcf()\nfig.gca().add_artist(centre_circle)\n# Equal aspect ratio ensures that pie is drawn as a circle\nax1.axis('equal') \nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"According to the dataset sarcastic comments tend to be less popular due to having lower overall scores."},{"metadata":{},"cell_type":"markdown","source":"## Length of Sarcastic comment compared to the parent comment"},{"metadata":{},"cell_type":"markdown","source":"Now, lets determine whether the length of the sarcastic comments is more than its parent comment."},{"metadata":{"trusted":true},"cell_type":"code","source":"sarcasm_comm_len = np.array(sarcasm_df.loc[sarcasm_df['label'] == 1]['comment'].str.len())\nparent_comm_len = np.array(sarcasm_df.loc[sarcasm_df['label'] == 1]['parent_comment'].str.len())\nratio_len = np.array((sarcasm_df.loc[sarcasm_df['label'] == 1]['comment'].str.len())/(sarcasm_df.loc[sarcasm_df['label'] == 1]['parent_comment'].str.len()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.DataFrame({'Comment Length': sarcasm_comm_len, 'Parent Comment Length': parent_comm_len, 'Ratio Length': ratio_len}, columns=['Comment Length', 'Parent Comment Length', 'Ratio Length'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = plt.axes()\nsns.scatterplot(data=dataset, x=\"Comment Length\", y=\"Parent Comment Length\",  size=ratio_len)\nax.set_title(\"Comparing Sarcastic Comment Length with Parent Comment\")\n# control x and y limits\nplt.ylim(0, 12000)\nplt.xlim(0, 800)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"According to the above visual, we can conclude that in most of the cases; the length of the sarcastic comments is longer than its corresponding parent comment."},{"metadata":{},"cell_type":"markdown","source":"## Top Five popular subreddits & Sarcastic comments"},{"metadata":{},"cell_type":"markdown","source":"In this EDA we will analyse the proportion of sarcastic comments for top 5 Subreddits in the dataset. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting the top 5 popular subreddits\nsarcasm_df['subreddit'].value_counts()[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_reddits =['AskReddit', 'politics', 'worldnews', 'leagueoflegends', 'pcmasterrace']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subreddit = pd.DataFrame()\nsubreddit['subreddit'] = top_reddits\nsubreddit['sarcastic'] = np.nan\nsubreddit['natural'] = np.nan\nsubreddit['total'] = np.nan","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculating the count of Sarcastic and Natural comments for the top 5 subreddits \nfor i in range(len(top_reddits)):\n    temp = sarcasm_df.loc[sarcasm_df['subreddit'] == subreddit.subreddit.iloc[i]]\n    length = len(temp)\n    count_sarcastic = len(temp.loc[temp['label'] == 1])\n    subreddit.sarcastic.iloc[i] = count_sarcastic\n    subreddit.natural.iloc[i] = length - count_sarcastic\n    subreddit.total.iloc[i] = length","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subreddit","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialize the matplotlib figure\nf, ax = plt.subplots(figsize=(15, 5))\n# Plot the total comments for the subreddits\nsns.barplot(x=\"total\", y=\"subreddit\", data=subreddit,\n            label=\"Total\", color=\"b\")\n# Plot the total sarcastic comments for the subreddits\nsns.barplot(x=\"sarcastic\", y=\"subreddit\", data=subreddit,\n            label=\"Sarcastic Comments\", color=\"r\")\nax.legend(ncol=2, loc=\"lower right\", frameon=True)\nax.set( ylabel=\"Subreddits\",\n       xlabel=\"Total number of comments\")\nsns.despine(left=True, bottom=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Being sarcastic on a specific day of the week"},{"metadata":{},"cell_type":"markdown","source":"In this EDA we are tying to figure out wehther the user of Reddit tend to be more sarcastic on a specific day of the week."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Engineering- Extracting the day of a week\nsarcasm_df['created_utc'] = pd.to_datetime(sarcasm_df['created_utc'], format = '%d/%m/%Y %H:%M:%S')\nsarcasm_df['Day of Week'] = sarcasm_df['created_utc'].dt.day_name()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualization of Column- label\nplt.figure(figsize=(10,5))\nax = sns.countplot(x='Day of Week',  data= sarcasm_df.loc[sarcasm_df['label']==1])\nax.set(title = \"Count of sarcastic comments per day\", xlabel=\"Days of the week\", ylabel = \"Total Count\")\ntotal = float(len(sarcasm_df ))\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()/2.,\n            height + 7,\n            '{:1.1f}%'.format((height/total)*100*2),\n            ha=\"center\") \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"According to the visual above we can see that the the count of the sarcastic comments decreases during the weekends. One of the reason for this issue could be due to the reduced number of traffic in Reddit during the weekends "},{"metadata":{},"cell_type":"markdown","source":"# **Creating the Classifier Model**"},{"metadata":{},"cell_type":"markdown","source":"## Feature Engineering"},{"metadata":{},"cell_type":"markdown","source":"Using unigram for the tokens"},{"metadata":{"trusted":true},"cell_type":"code","source":"tf_idf = TfidfVectorizer(ngram_range=(1, 1), stop_words= 'english', max_features=50000, min_df=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating the training and test dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(sarcasm_df['comment'], sarcasm_df['label'], test_size= 0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model traning- Using Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = {'solver': [ 'lbfgs', 'liblinear', 'saga'], 'verbose': [0, 1, 2]}\n\n# multinomial logistic regression a.k.a softmax classifier\nlogit = LogisticRegression(random_state= 42)\n\nlogit_classifier = GridSearchCV(logit, parameters, cv = 5, n_jobs= 4)\n\n# sklearn's pipeline\ntfidf_logit_pipeline = Pipeline([('tf_idf', tf_idf),  ('logit_classifier', logit_classifier)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training the model with the traning dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"start = time.time()\ntfidf_logit_pipeline.fit(x_train, y_train)\nend = time.time()\nprint(end - start)  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Parameters of the best performing model and its accuracy with the training dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(logit_classifier.best_params_)\nprint(logit_classifier.best_score_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Validating the accuracy of the model with the test datset"},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_pred = tfidf_logit_pipeline.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Test accuracy of the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(y_test, valid_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting the accuracy metric\nacc = accuracy_score(valid_pred, y_test)\npre = precision_score(valid_pred, y_test)\nrec = recall_score(valid_pred, y_test)\nf1 = f1_score(valid_pred, y_test)\n\nprint ('Model Performance Statistic Suite-1: ')\nprint ('Accuracy: ', acc)\nprint ('Precision: ', pre)\nprint ('Recall: ',rec)\nprint ('F1 Score: ', f1)\n\ncm = confusion_matrix(y_test,valid_pred)\n\nsensitivity = cm[0,0]/(cm[0,0]+cm[1,0])\nprint('Sensitivity : ', sensitivity )\n\nspecificity = cm[1,1]/(cm[0,1]+cm[1,1])\nprint('Specificity : ', specificity)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plotting the Confusion Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"cm =  pd.DataFrame(cm, index=['Natural','Sarcastic'],columns=['Natural','Sarcastic'])\nfig = plt.figure(figsize=(8,6))\nax = sns.heatmap(cm,annot=True,cbar=False, cmap='Greens',linewidths=0.5,fmt='.0f')\nax.set_title('Confusion Matrix',fontsize=16,y=1.25)\nax.set_ylabel('Ground Truth',fontsize=14)\nax.set_xlabel('Predicted',fontsize=14)\nax.xaxis.set_ticks_position('top')\nax.xaxis.set_label_position('top')\nax.tick_params(labelsize=12)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}