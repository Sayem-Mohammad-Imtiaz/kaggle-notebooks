{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Prepare data and import libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.svm import LinearSVC","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/sms-spam-collection-dataset/spam.csv', encoding='latin-1')\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1, inplace=True)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.rename(columns={'v1': 'class', 'v2': 'text'}, inplace=True)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['class_num'] = df['class'].map({'ham':0, 'spam':1})\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Split data into train and test"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pd.DataFrame(df['text'])\ny = pd.DataFrame(df['class_num'])\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Use CountVectorizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"vec_count = CountVectorizer(min_df=3)\nvec_count.fit(X_train['text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('word size: ', len(vec_count.vocabulary_))\nprint('word content: ', dict(list(vec_count.vocabulary_.items())[0:5]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_vec = vec_count.transform(X_train['text'])\nX_test_vec = vec_count.transform(X_test['text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(X_train_vec.toarray()[0:5], columns=vec_count.get_feature_names())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(X_test_vec.toarray()[0:5], columns=vec_count.get_feature_names())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classify by SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LinearSVC()\nmodel.fit(X_train_vec.toarray(), y_train['class_num'].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 訓練データとテストデータのスコア\nprint('正解率(train):{:.3f}'.format(model.score(X_train_vec.toarray(), y_train['class_num'].values)))\nprint('正解率(test):{:.3f}'.format(model.score(X_test_vec, y_test['class_num'].values)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict new data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = np.array(['I HAVE A DATE ON SUNDAY WITH WILL!!',\n                 'Nah I don\\'t think he goes to usf, he lives around here though',\n                 'Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030',\n                 'FreeMsg Hey there darling it\\'s been 3 week\\'s now and no word back! I\\'d like some fun you up for it still? Tb ok! XxX std chgs to send, å£1.50 to rcv',\n                 'Even my brother is not like to speak with me. They treat me like aids patent.',\n                 'SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info'])\n# ham, ham, spam, spam, ham, spam\ndf_data = pd.DataFrame(data, columns=['text'])\ndf_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_vec = vec_count.transform(df_data['text'])\np = model.predict(input_vec)\np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list(map(lambda x: 'spam' if x == 1 else 'ham', list(p)))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}