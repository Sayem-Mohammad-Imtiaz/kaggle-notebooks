{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%matplotlib notebook\n\n# Linear Algebra\nimport numpy as np\n\n# Data Processing\nimport pandas as pd\n\n# Data Visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Algorithms\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.metrics import mean_absolute_error, classification_report\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBRegressor\n\n# Stop unnecessary Seaborn warnings\nimport warnings\nwarnings.filterwarnings('ignore')\nsns.set()  # Stylises graphs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"wine_df = pd.read_csv('../input/winequality-red.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wine_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wine_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploring the Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting quality of wine\n\nfig = plt.figure(figsize=(40, 8))\nsns.countplot(x='quality', data=wine_df)\nplt.title(\"Barplot of Quality of Wine\")\nplt.xlabel(\"Quality\")\nplt.ylabel(\"Count\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Heatmap of variables\n\nsns.set(style=\"white\")\n\n# Computer correlation matrix\ncorr = wine_df.corr()\n\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set up the matplotlib figure\nfig, ax = plt.subplots(figsize=(20, 20))\n\n# Generate a custom diverging colourmap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(\n    corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n    square=True, linewidths=.5, cbar_kws={\"shrink\": .5}\n)\n\nax.set_title('Correlation Heatmap of the Variables of Wine')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking at the graph above, it seems that there are some correlations that may be worth exploring. There may be a correlation between alcohol and quality... Coincidence, I think not."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (20,8))\nsns.barplot(x='quality', y ='alcohol', data=wine_df)\nplt.title(\"Quality of Wine with Alcohol\")\nplt.ylabel(\"Alcohol (% of wine)\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training a Model"},{"metadata":{},"cell_type":"markdown","source":"#### Cleaning and Prepping Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Determining if there are any columns with missing data\n\ncols_with_missing = [col for col in wine_df.columns if wine_df[col].isnull().any()]\nprint(cols_with_missing)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, there are no missing bits of data within the dataset - this makes life easiser!"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get list of categorical variables\ns = (X_train.dtypes == 'object')\nobject_cols = list(s[s].index)\n\nprint(\"Categorical variables:\")\nprint(object_cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are no columns containing categorical data either."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Assigning training and validation data\n\nX = wine_df.copy()\ny = X.quality\nX.drop(['quality'], axis=1, inplace=True)\n\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Modelling with Random Forests"},{"metadata":{},"cell_type":"markdown","source":"#### Determining the Number of Estimators"},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = {}\n\nfor n_estimators in range(10, 510, 10):\n    RF_model = RandomForestClassifier(n_estimators=n_estimators, random_state=0)\n    RF_model.fit(X_train, y_train)\n    RF_predictions = RF_model.predict(X_valid)\n    RF_mae = mean_absolute_error(RF_predictions, y_valid)\n    scores[n_estimators] = RF_mae","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig_RF, ax_RF = plt.subplots(figsize=(10, 4))\nax_RF.set_title(\"Mean Absolute Error with Number of Estimators of a Random Forest\")\nax_RF.set_xlabel(\"Number of Estimators\")\nax_RF.set_ylabel(\"Mean Absolute Error\")\nplt.plot(scores.keys(), scores.values())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_n_estimators = 0\n\nfor n_estimators, score in scores.items():\n    if score == min(scores.values()):\n        best_n_estimators = n_estimators\n        print(f\"Best Number of Estimators: {n_estimators}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RF_model = RandomForestClassifier(n_estimators=best_n_estimators, random_state=0)\nRF_model.fit(X_train, y_train)\nRF_predictions = RF_model.predict(X_valid)\nRF_mae = mean_absolute_error(RF_predictions, y_valid)\n\nprint(f\"Mean Absolute Error: {RF_mae}\")\nprint(classification_report(y_valid, RF_predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Modelling using XGBoost"},{"metadata":{},"cell_type":"markdown","source":"#### Fix Learning Parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"XGB_model = XGBRegressor(\n    n_estimators=200, learning_rate=0.02,\n    max_depth=10, min_child_weight=1,\n    gamma=0, subsample=0.8,\n    colsample_bytree=0.7,\n    random_state=0, nthread=4\n)\n\nXGB_model.fit(X_train, y_train, early_stopping_rounds=10, verbose=False, eval_set=[(X_valid, y_valid)])\nXGB_predictions = XGB_model.predict(X_valid)\nXGB_mae = mean_absolute_error(XGB_predictions, y_valid)\n\nprint(f\"Mean Absolute Error: {XGB_mae}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Tuning Gamma"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"base_XGB_model = XGBRegressor(\n    n_estimators=200, learning_rate=0.02,\n    max_depth=10, min_child_weight=1,\n    subsample=0.8, colsample_bytree=0.7,\n    random_state=0, nthread=4\n)\n\nparam_test = {\n 'gamma':[i/10 for i in range(20)]\n}\n\ngrid_search = GridSearchCV(estimator=base_XGB_model, param_grid=param_test, n_jobs=1, iid=False, cv=5)\ngrid_search.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"grid_search.cv_results_, grid_search.best_params_, grid_search.best_score_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Applying Cross-Validation\nSince the dataset is smaller, we should use cross-validation "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Multiply by -1 since sklearn calculates *negative* MAE\nscores = -1 * cross_val_score(RF_model, X, y, cv=10, scoring='neg_mean_absolute_error')\nprint(f\"MAE Scores: {scores}\")\nprint(f\"Average MAE Score: {scores.mean()}\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}