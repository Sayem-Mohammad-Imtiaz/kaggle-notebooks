{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\ndata = pd.read_csv(\"../input/brasilian-houses-to-rent/houses_to_rent_v2.csv\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA :\n I am doing some analysis of data before building the Linear regression model.\n \n let's start with data cleaning and preparation step by step."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert datatype of floor into numeric value.\ndata['floor'] = pd.to_numeric(data['floor'], errors = 'coerce')\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# in floor I am replacing the null value with 0 as a ground floor.\ndata = data.fillna(0)\nprint(len(data))\nprint(data.describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check the outliers in rooms, bathroom,floor\nimport seaborn as sns\nimport matplotlib.pyplot as plot\n\nf,axes = plot.subplots(1,3)\n\nsns.boxplot(y = 'floor', data = data, ax=axes[0])\nsns.boxplot(y = 'rooms', data = data, ax = axes[1])\nsns.boxplot(y = 'bathroom', data = data, ax = axes[2])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# outlier treatment:\n\nq1 = data.floor.quantile(0.25)\nq3 = data.floor.quantile(0.75)\nIQR = q3-q1\ndata_1 = data[(data.floor >= q1-1.5*IQR) & (data.floor <= q3 + 1.5 * IQR)]\n\nq1 = data_1.rooms.quantile(0.25)\nq3 = data_1.rooms.quantile(0.75)\nIQR = q3-q1\ndata_1 = data_1[(data_1.rooms >= q1-1.5*IQR) & (data_1.rooms <= q3 + 1.5 * IQR)]\n\nq1 = data_1.bathroom.quantile(0.25)\nq3 = data_1.bathroom.quantile(0.75)\nIQR = q3-q1\ndata_1 = data_1[(data_1.bathroom >= q1-1.5*IQR) & (data_1.bathroom <= q3 + 1.5 * IQR)]\n\nprint(len(data_1))\n\nf,axes = plot.subplots(1,3)\n\nsns.boxplot(y = 'floor', data = data_1, ax=axes[0])\nsns.boxplot(y = 'rooms', data = data_1, ax = axes[1])\nsns.boxplot(y = 'bathroom', data = data_1, ax = axes[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot.tight_layout()\nsns.distplot(data_1['rent amount (R$)'],bins = 30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data has categorical variable. so I am converting categorical variable into numeric.\ndata_1 = pd.get_dummies(data = data_1 , columns = ['furniture','animal'])\nprint(data_1.head())\nprint(len(data_1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_1.groupby('city').size()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# drop the city column.\n\ndata_1 = data_1.drop(['city'],axis = 1)\n\n# Need to scale the dataset.\n\ndef normalize(x):\n    return ((x- np.mean(x))/(max(x)-min(x)))\n\ndata_1 = data_1.apply(normalize)\ndata_1.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nfig,ax = plot.subplots(figsize=(10,10))\ncal_corr = data_1.corr().round(2)\nsns.heatmap(cal_corr,annot = True, linewidths = 1, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. The above correlation matrix shows the relationship between variables ranges from -1 to 1.If value is close to 1 means there is strong relation between two variables.Here we are predicting the rent amount for the house. So We should take only those variables which has strong linear relationship with rent amount for Linear Regression model.  \n2. The \"area\", \"rooms\",\"bathroom\",\"parking space\",\"fire insurance\" has strong positive correlation with rent amount.\n3. The \"bathroom\" is highly correlated with \"rooms\" and the \"parking spaces\" is also  correlated with other variables.This term is called as multicollinearity.We can check it further and take some actions using VIF.\n"},{"metadata":{},"cell_type":"markdown","source":"# Linear Regression :"},{"metadata":{"trusted":true},"cell_type":"code","source":"xData = pd.DataFrame(data_1[['area','rooms','bathroom','parking spaces','fire insurance (R$)','furniture_furnished','furniture_not furnished','hoa (R$)','total (R$)']], columns = ['area','rooms','bathroom','parking spaces','fire insurance (R$)','furniture_furnished','furniture_not furnished','hoa (R$)','total (R$)'])\nprint(xData.head())\nyData = pd.DataFrame(data_1['rent amount (R$)'], columns = ['rent amount (R$)'])\nprint(yData.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data is prepared for regression model. Let's split the data into train and test data.\nwe are splitting the data as 70% train  and 30% test data."},{"metadata":{"trusted":true},"cell_type":"code","source":"# import the library for spliting the data.\nfrom sklearn.model_selection import train_test_split\nx_train, x_test,y_train, y_test = train_test_split(xData,yData, train_size = 0.7, test_size = 0.3,random_state = 5)\nprint(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\n\nx_train = sm.add_constant(x_train)\n\nlm_model1 = sm.OLS(y_train,x_train).fit()\nprint(lm_model1.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"our model is ready we have 98% of R-square, but the p value of rooms variable is >0.05 which is very high p value. So we\nneed to remove this variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = x_train.drop(['rooms'],1)\nlm_model2 = sm.OLS(y_train,x_train).fit()\nprint(lm_model2.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = x_train.drop(['fire insurance (R$)'],1)\nlm_model3 = sm.OLS(y_train,x_train).fit()\nprint(lm_model3.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now I am taking last model lm_model3 for the predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nytrain_predic = lm_model3.predict(x_train)\nrmse = (np.sqrt(mean_squared_error(y_train,ytrain_predic))).round(3)\nr2 = r2_score(y_train,ytrain_predic).round(3)\nprint('RMSE for training data is : {}'.format(rmse))\nprint('r2 for training data is : {}'. format(r2))\n\n# for test dataset we need to drop the columns which we drop during building the model.\nx_test_model3 = sm.add_constant(x_test)\nx_test_model3 = x_test_model3.drop(['rooms','fire insurance (R$)'], axis = 1)\nytest_predic = lm_model3.predict(x_test_model3)\nrmse = (np.sqrt(mean_squared_error(y_test,ytest_predic))).round(3)\nr2 = r2_score(y_test,ytest_predic).round(3)\nprint('RMSE for test data is : {}'.format(rmse))\nprint('r2 for test data is : {}'. format(r2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}