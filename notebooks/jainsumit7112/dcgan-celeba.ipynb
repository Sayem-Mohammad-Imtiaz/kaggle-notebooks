{"cells":[{"metadata":{"id":"94O9_Cgb3-vb","outputId":"c7a33310-718b-49ad-e815-4534e78139e0","trusted":true},"cell_type":"code","source":"import sys\nprint(sys.version)\ndevice='cuda' #Changing Device to Run on GPU\ndata_path=\"/kaggle/input/celeba-dataset/img_align_celeba/\"\n","execution_count":null,"outputs":[]},{"metadata":{"id":"q2ZYaVGk7qS7","outputId":"a298a3d9-0c1b-4c00-ea5f-45fda993d31d","trusted":true},"cell_type":"code","source":"from PIL import Image\nimport os\nfrom skimage import io, transform\nfrom skimage import io, transform\n\nimport random\nimport time\nimport itertools\nimport pandas as pd\nimport numpy as np\n\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom torch.autograd import Variable\nfrom scipy import ndimage\nfrom IPython.display import display\nimport torchvision.datasets as datasets\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import transforms\n\nfrom torch.utils.data import Dataset, DataLoader\n\n\nprint(torch.version.cuda)  \nprint(torch.cuda.device_count())\nprint(torch.cuda.is_available())\n","execution_count":null,"outputs":[]},{"metadata":{"id":"MNx8NL4WVj-S","trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{"id":"zuuv2c2pwsIC","outputId":"c5f223c1-ec0b-4e88-a873-ee92877cb42a","trusted":true},"cell_type":"code","source":"transforms_=transforms.Compose([\n                               transforms.Resize(64),\n                               transforms.CenterCrop(64),\n                               transforms.ToTensor(),\n                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n                           ])\ndataset = datasets.ImageFolder(root=data_path,\n                           transform=transforms_)\n# Create the dataloader\ndataloader = torch.utils.data.DataLoader(dataset, batch_size=128,\n                                         shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torchvision.utils as vutils\nreal_batch = next(iter(dataloader))\nprint(real_batch[0].size())\nprint(len(dataloader))","execution_count":null,"outputs":[]},{"metadata":{"id":"JRZ3oHWNbU2D","outputId":"ff2ef8bf-c9e4-440a-8c80-7a668b7c6552","trusted":true},"cell_type":"code","source":"\nplt.figure(figsize=(8,8))\nplt.axis(\"off\")\nplt.title(\"Training Images\")\nplt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))","execution_count":null,"outputs":[]},{"metadata":{"id":"8KrHAGsxnwxS","trusted":true},"cell_type":"code","source":"Z_gen_size=100","execution_count":null,"outputs":[]},{"metadata":{"id":"Xsk7EImQmWRV","trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{"id":"9fxbohUPrcyH","outputId":"9404990b-7729-4840-8a65-10ee3a61720a","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"kz-ZEoH6A9LI","outputId":"02377c74-5176-44b7-8ff1-86724799ea56","trusted":true},"cell_type":"code","source":"class Generator(nn.Module):\n  def __init__(self):\n    super(Generator, self).__init__()\n    self.fct1= nn.ConvTranspose2d(Z_gen_size,256,4,1,0) #4*4 out\n    self.fct2= nn.ConvTranspose2d(256, 128, 4,2,1)  #8*8 out\n    self.fct3= nn.ConvTranspose2d(128,64, 4, 2, 1)  #16*16\n    self.fct4= nn.ConvTranspose2d(64,32, 4,2,1)  #32*32\n    self.fct5= nn.ConvTranspose2d(32,3, 4,2,1)  #64x64\n    \n    self.norm1_2d= nn.BatchNorm2d(256)\n    self.norm2_2d= nn.BatchNorm2d(128)\n    self.norm3_2d=nn.BatchNorm2d(64)\n    self.norm4_2d=nn.BatchNorm2d(32)\n    \n    \n\n  def forward(self,x):\n\n    #FC1\n    x= self.fct1(x)\n    x= self.norm1_2d(x)\n    x= F.leaky_relu(x,0.2)\n    #FC2\n    x= self.fct2(x)    \n    x= self.norm2_2d(x)\n    x= F.leaky_relu(x,0.2)\n    #FC3\n    x= self.fct3(x)    \n    x= self.norm3_2d(x)\n    x= F.leaky_relu(x,0.2)\n    \n    #FC3\n    x= self.fct4(x)    \n    x= self.norm4_2d(x)\n    x= F.leaky_relu(x,0.2)\n    \n   #FC3\n    x= self.fct5(x)\n    x= F.tanh(x)\n      \n    \n    return x\n\ngenr=Generator()\ngenr=genr.float()\ngenr.to(device)","execution_count":null,"outputs":[]},{"metadata":{"id":"le_AVGhrCWiR","outputId":"9587999d-212d-4f67-f4c2-e6957e492b83","trusted":true},"cell_type":"code","source":"class Discriminator(nn.Module):\n  def __init__(self):\n    super(Discriminator, self).__init__()\n    self.conv1 = nn.Conv2d(3,32,4,2,1)    #32x32\n    self.conv2 = nn.Conv2d(32,64,4,2,1)    #16x16\n    self.conv3=  nn.Conv2d(64,128,4,2,1)  #8*8\n    self.conv4 = nn.Conv2d(128,256,4,2,1) #4*4\n    self.conv5 = nn.Conv2d(256,1,4,1,0)   #1*1\n    self.drop1 = nn.Dropout(0.3)\n    self.norm1_2d=nn.BatchNorm2d(32)\n    self.norm2_2d=nn.BatchNorm2d(64)\n    self.norm3_2d=nn.BatchNorm2d(128)\n    self.norm4_2d=nn.BatchNorm2d(256)\n    \n\n  def forward(self,x):\n\n   \n    #Three fully connected Layers\n    \n    #FC1\n    x= self.conv1(x)\n    x= self.norm1_2d(x)\n    x= F.leaky_relu(x,0.2)    \n    \n    #FC2\n    x= self.conv2(x)    \n    x= self.norm2_2d(x)\n    x= F.leaky_relu(x,0.2)\n    x= self.drop1(x)\n\n    #Fc3\n    x= self.conv3(x)\n    x= self.norm3_2d(x)\n    x= F.leaky_relu(x,0.2)\n       \n\n    #FC4\n    x= self.conv4(x)\n    x= self.norm4_2d(x)\n    x= F.leaky_relu(x,0.2)\n    \n    \n    x= self.conv5(x)\n    x=x.view(-1)\n    #x= torch.sigmoid(x)\n    \n\n\n    return x\n\ndiscr=Discriminator()\ndiscr=discr.float()\ndiscr.to(device)","execution_count":null,"outputs":[]},{"metadata":{"id":"u_4ijWDmc-ug","trusted":true},"cell_type":"code","source":"def dis_loss_fn(data_outs, gen_outs, smooth=1):\n  targets_d= torch.ones(data_outs.size()[0], dtype=torch.float64, device=device)*smooth\n  targets_g= torch.zeros(gen_outs.size()[0], dtype=torch.float64, device=device)\n  loss= nn.BCEWithLogitsLoss()\n  loss_calc=loss(data_outs, targets_d) + loss(gen_outs, targets_g)\n  return loss_calc\n\ndef gen_loss_fn(gen_outs):\n  targets= torch.ones(gen_outs.size()[0], dtype=torch.float64, device=device)\n  loss= nn.BCEWithLogitsLoss()\n  loss_calc=loss(gen_outs, targets)\n  return loss_calc","execution_count":null,"outputs":[]},{"metadata":{"id":"ZZYLNzAYz-dJ","trusted":true},"cell_type":"code","source":"z_e=np.random.uniform(-1, 1, size=(1, Z_gen_size,1,1))\nz_e=torch.from_numpy(z_e).float().to(device)","execution_count":null,"outputs":[]},{"metadata":{"id":"DrJaXeYOlW8j","trusted":true},"cell_type":"code","source":"dis_optim=optim.Adam(discr.parameters(), lr= 0.0002)\ngen_optim=optim.Adam(genr.parameters(), lr= 0.0002)","execution_count":null,"outputs":[]},{"metadata":{"id":"OXTcp7mMnsww","outputId":"c58a9359-c9af-4c7e-a76a-7fe90be0c6b6","trusted":true},"cell_type":"code","source":"epochs=40 #No. Of Epochs\nk=1\nbatch_loss_dis=[] #for storing losses of individual batches while training\nbatch_loss_gen=[] \n\ntotal_epochs=len(dataloader) \nfor st in range(0,epochs):\n\n  \n  for i, (x_batch, y_batch) in tqdm(enumerate(dataloader),position=0, leave=True, total=total_epochs):\n    \n    x_batch=x_batch.to(device)\n    z_batch=np.random.uniform(-1, 1, size=(x_batch.size()[0], Z_gen_size,1,1))\n    z_batch=torch.from_numpy(z_batch).float().to(device)\n\n    discr.train()\n    genr.train()\n    for q in range(0,k):\n      dis_optim.zero_grad()\n      dis_outs =discr(x_batch)\n     \n\n      gen_img  = genr(z_batch)\n      gen_outs = discr(gen_img)\n     \n      dis_loss= dis_loss_fn(data_outs= dis_outs, gen_outs= gen_outs, smooth=0.9)\n      dis_loss.backward()\n      dis_optim.step()\n      batch_loss_dis.append(dis_loss.item())\n    \n    gen_optim.zero_grad()\n    z_batch=np.random.uniform(-1, 1, size=(x_batch.size()[0], Z_gen_size,1,1))\n    z_batch=torch.from_numpy(z_batch).float().to(device)\n    gen_img  = genr(z_batch)    \n    gen_outs = discr(gen_img)\n\n    gen_loss= gen_loss_fn(gen_outs)\n    gen_loss.backward()\n    gen_optim.step()\n        \n    batch_loss_gen.append(gen_loss.item())\n\n\n  #Tests And Eval\n  dis_loss_ep=sum(batch_loss_dis)/len(batch_loss_dis)\n  gen_loss_ep=sum(batch_loss_gen)/len(batch_loss_gen)\n  genr.eval()\n  with torch.no_grad():\n    example=genr(z_e)\n    example =example.cpu().numpy().reshape(3,64,64)\n    print(example.shape)\n    plt.imshow(example.transpose(1,2,0)*0.5 +0.5)\n    plt.show()\n \n \n  print(\"Epoch\", str(st+1)+\"/\" + str(epochs))\n  print(\"DIS_Loss:\", dis_loss_ep,\"      \", \"GEN_Loss:\",  gen_loss_ep )\n  ","execution_count":null,"outputs":[]},{"metadata":{"id":"2mGSEerM0fKf","outputId":"ad6238a2-cae0-4abd-924c-42e98742cd9b","trusted":true},"cell_type":"code","source":"genr.eval()\nwith torch.no_grad():\n    example=genr(z_e)\n    example =example.cpu().numpy().reshape(3,64,64)\n    print(example.shape)\n    plt.imshow(example.transpose(1,2,0)*0.5 +0.5)\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"id":"NmeIqFY7-S1R","outputId":"f43bf2ba-720e-4a02-ecca-d5afafd69a8d","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nplt.title(\"Generator and Discriminator Loss During Training\", color='yellow')\nplt.plot(batch_loss_gen,label=\"G\")\nplt.plot(batch_loss_dis,label=\"D\", color='red')\nplt.xlabel(\"iterations\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"kmr4Uu3HYZfb","trusted":true},"cell_type":"code","source":"z_examples=np.random.uniform(-1, 1, size=(256, Z_gen_size,1,1))\nz_examples=torch.from_numpy(z_examples).float().to(device)","execution_count":null,"outputs":[]},{"metadata":{"id":"oM88XEUG-ZNX","outputId":"9ba88532-1b2c-48be-a912-133ab38d1d80","trusted":true},"cell_type":"code","source":"genr.eval()\n\nimport torchvision.utils as vutils\n\nwith torch.no_grad():\n  example=genr(z_examples)\n  example_f =example.detach().cpu()\n\ngrid_img=vutils.make_grid(example_f,16, padding=2 , normalize=True).numpy().transpose(1,2,0)\nprint(\"Generated Images\")\n\nimg = Image.fromarray( np.uint8((grid_img)*256),'RGB')\ndisplay(img)","execution_count":null,"outputs":[]},{"metadata":{"id":"O8VMNf-k25WF","outputId":"9784fe02-31ed-4af6-9905-881f629d670b","trusted":true},"cell_type":"code","source":"example_nm =example_f.cpu().numpy()\n\nplt.figure(figsize=(16,16)) \n\nfor i in range(256):\n    plt.subplot(16,16,i+1) \n    plt.axis(\"off\")   \n    plt.imshow(example_nm[i].transpose(1,2,0)*0.5 +0.5)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}