{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Table of Content\n\n1. Importing the library\n2. Loading the dataset\n3. Explore the data\n    - Checking the null values\n4. Answer to question asked by Gufthugu    \n5. Exploratory data analysis.\n\n    - What is the best-selling book?\n    - Visualize order status frequency\n    - Find a correlation between date and time with order status\n    - Find a correlation between city and order status\n    - Find any hidden patterns that are counter-intuitive for a layman\n    - Can we predict number of orders, or book names in advance?"},{"metadata":{},"cell_type":"markdown","source":"# 1. Import Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Loading the dataset"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/gufhtugu-publications-dataset-challenge/GP Orders - 4.csv');\ndata","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Explore the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# sample data\ndata.head()\n\n# get columns Name\nprint(data.columns)\n\n# convert columns having spaces to '_', because we can access order number column as data['Order Number'] but not like this data.Order Number.\n# So converting them is good idea. Also converting columns names into lower string\n\ncolumns = data.columns.str.replace(' ','_').str.lower()\n\n# remove the special characters\ncolumns = columns.str.replace('[(,)]', '')\n\ndata.columns = columns\n\n# as info shows count of each columns' rows. Columns order_number, order_status and order_date has rows equals to total rows. This show that these columns has null value.\n# book_name column has 2 null values and city_billing has 1 null value. \n# Lets count null count as varify this.\n\nprint(data.isnull().sum())\n\n# treat the null values \n# treament for book_name: as book name is string so we can use mode, to fill null values. Mode means which book is buy most i.e. 'انٹرنیٹ سے پیسہ کمائیں'\nprint(data.book_name.mode()[0])\ndata.book_name = data.book_name.fillna(data.book_name.mode()[0])\n\n# now book_name has no null values\nprint(data.isnull().sum())\n\n# treatment for city_billing: as city billing is string so we can use mode, to fill null values. Mode means which city has most buyer i.e. 'Karachi'\nprint(data.city_billing.mode())\ndata.city_billing = data.city_billing.fillna(data.city_billing.mode()[0])\n\n# now city_billing has no null values\nprint(data.isnull().sum())\n\n# book name column having multiple books seperated by '/'. we will convert them into array.\ndata['book_name_list'] = data.book_name.str.split('/')\n\n# coonvert Date string to Date object\ndata['order_date'] = pd.to_datetime(data['order_date'])\nprint(data.head())\n\n#include a book count column, having count of books in order\ndata['order_books_count'] = data.book_name_list.apply(len)\nprint(data.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory data analysis"},{"metadata":{},"cell_type":"markdown","source":"**Total order status**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# let get status of order\n\nstatuses = data.order_status.unique() # array(['Completed', 'Returned', 'Canceled'], dtype=object)\nplt.style.use('seaborn')\nplt.title('Order status Frequency')\nplt.xlabel('Order status')\nplt.ylabel('Number of orders')\nplt.hist(data.order_status)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Order Status by X Year**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# get unique years list from order_date column\ndata_years = data['order_date'].dt.strftime(\"%Y\").unique().tolist()\nprint(data_years)\n\n# get statuses of 2019 year\nstatus_2019 = data[data['order_date'].dt.strftime(\"%Y\") == \"2019\"].order_status\n\n#get statuses of 2020 year\nstatus_2020 = data[data['order_date'].dt.strftime(\"%Y\") == \"2020\"].order_status\n\n#get statuses of 2021 year\nstatus_2021 = data[data['order_date'].dt.strftime(\"%Y\") == \"2021\"].order_status\n\n\n#plot graph for year 2019\n\nplt.figure(figsize=(15,5))\n\nplt.subplot(1,3,1)\nplt.title('2019 Year Order Status')\nplt.xlabel('Order statuses')\nplt.ylabel('Number of orders')\nplt.hist(status_2019)\n\n#plot graph for year 2020\nplt.subplot(1,3,2)\nplt.title('2020 Year Order Status')\nplt.xlabel('Order statuses')\nplt.ylabel('Number of orders')\nplt.hist(status_2020)\n\n#plot graph for year 2021\nplt.subplot(1,3,3)\nplt.title('2021 Year Order Status')\nplt.xlabel('Order statuses')\nplt.ylabel('Number of orders')\nplt.hist(status_2021)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Number of orders by Year."},{"metadata":{"trusted":true},"cell_type":"code","source":"orders_count_per_month_per_year = data['order_date'].groupby([data['order_date'].dt.year.rename('year'), data['order_date'].dt.month.rename('month')]).agg({'count'})\norders_count_per_month_per_year.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* What is the 10 best-selling book?"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['book_name'].value_counts()[:10].plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Top Ten Cities**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['city_billing'].value_counts()[:10].plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Please Upvote if you find the notebook interesting.\nThis notebook is under MIT License Feel free to copy and edit it."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}