{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"## Pretendo inferir quantidade de suicídios baseado em sexo, faixa etária, gdp e populacao\ndf = pd.read_csv('/kaggle/input/suicide-rates-overview-1985-to-2016/master.csv')\n\n# Observe que o dataset tem colunas redundantes como country-year.\nprint(df.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.columns)\n# Geração e country-year não agregam muito, já que sabemos as idades\ndf = df.drop(columns=['country-year','generation','country','year'],errors='ignore')\n\nprint(df.head())\ndf.rename(columns={'HDI for year':'HDI_for_year',\n                   'suicide/100k pop':'suicide_per_100k_pop',\n                   ' gdp_for_year ($) ':'gdp_for_year',\n                   'gdp_per_capita ($)':'gdp_per_capita'},inplace=True,errors='ignore')\nprint(df.columns)\n\nprint(df.isna().sum())\n\n# aparentemente todos os HDI_for_year da albania estão NaN...\nprint(df.loc[df['HDI_for_year'].isna()].head())\n\ndf_dropna = df.dropna(subset=['HDI_for_year']).copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_dropna.columns)\nprint(df_dropna.iloc[0])\n\n## gdp_for_year usa vírgulas nos números... e tem um espaço antes de seu nome e depois\n#https://stackoverflow.com/questions/22137723/convert-number-strings-with-commas-in-pandas-dataframe-to-float#22137890\ndf_dropna['gdp_for_year'] = df_dropna['gdp_for_year'].str.replace(',','').astype(float)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tudo ok agora\nprint(df_dropna.iloc[0])\ndf_dropna['gdp_per_capita'] = df_dropna['gdp_per_capita'].astype(float)\nprint(df_dropna.isna().sum())\nprint(df_dropna.dtypes)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_dropna_dummies = pd.get_dummies(df_dropna)\nprint(df_dropna_dummies.head())\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX = np.array(df_dropna_dummies.drop(columns=['suicides_no']).copy())\ny = np.array(df_dropna_dummies['suicides_no'].copy())\n\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.4)\nfrom sklearn.linear_model import LinearRegression\n\nmodel = LinearRegression()\nmodel.fit(X_train,y_train)\n## quanto mais perto de 1, melhor\nprint(\"R2 score \",model.score(X_test,y_test))\n\n## mean squared error\nfrom sklearn.metrics import mean_squared_error\nprint('MSE :',mean_squared_error(y_test,model.predict(X_test)))\n\nprint('Erro muito alto. Indica que este modelo não É adequado e grande não-linearidade dos dados')\n\n# Vamos utilizar o mesmo dataset para clusterizar\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import v_measure_score\n\n\n# Minhas labels serão a ordem de grandeza do número de suicídios\n# Há as seguintes ordens de grandeza: 0,1,2,3,4 \ny = np.array(np.log10(df_dropna_dummies['suicides_no'].copy()+1),dtype=int)\n\nprint(set(y))\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.35)\n\nn_clusters = len(set(y))\nprint('n_clusters:',n_clusters)\nmodel = KMeans(n_clusters = n_clusters, max_iter=300)\nmodel.fit(X_train)\n\nprint(\"o v_measure baixo indica a baixa qualidade do clustering executado\")\nprint(v_measure_score(model.predict(X_test),y_test))\n\nfrom sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()\n\nmodel.fit(X_train,y_train)\ny_pred = model.predict(X_test)\nprint('Nem o classificador logístico consegue inferir as labels que eu criei artificialmente na validação')\nprint(model.score(X_test,y_test))\nprint((y_test==y_pred).sum()/y_test.shape[0])\nprint('no teste: ', (y_train==model.predict(X_train)).sum()/y_train.shape[0])\n\nprint('cenário de underfitting')\n#########\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### E se tivessemos removido a coluna 'HDI_for_year'?\n\ndf_no_HDI = df.drop(columns='HDI_for_year')\ndf_no_HDI['gdp_for_year'] = df_no_HDI['gdp_for_year'].str.replace(',','').astype(float)\ndf_no_HDI['gdp_per_capita']=df_no_HDI['gdp_per_capita'].astype(float)\nprint(df_no_HDI.dtypes)\n\ndf_no_HDI = pd.get_dummies(df_no_HDI)\n\nprint(df_no_HDI.columns)\nprint(df_no_HDI.info())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_dropna_dummies = df_no_HDI.copy()\nX = np.array(df_dropna_dummies.drop(columns=['suicides_no']).copy())\ny = np.array(df_dropna_dummies['suicides_no'].copy())\n\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.4)\nfrom sklearn.linear_model import LinearRegression\n\nmodel = LinearRegression()\nmodel.fit(X_train,y_train)\n## quanto mais perto de 1, melhor\nprint(\"R2 score \",model.score(X_test,y_test))\n\n## mean squared error\nfrom sklearn.metrics import mean_squared_error\nprint('MSE :',mean_squared_error(y_test,model.predict(X_test)))\n\nprint('Erro muito alto. Indica que este modelo não É adequado e grande não-linearidade dos dados')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}