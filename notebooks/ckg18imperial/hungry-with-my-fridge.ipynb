{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Hungry with my fridge!\nThis kernel aims to solve the task described [here](https://www.kaggle.com/shuyangli94/food-com-recipes-and-user-interactions/tasks?taskId=164).\n\n**Goals**\n\n* Create an API that takes as input a list of ingredients, and returns as output the top 3 recipes that maximises the use of ingredients in provided in the list, and minimises additional ingredients needed and preparation time.\n* The output is in the format of an array of arrays of [recipeId, recipeName, prepTimeInMinutes, numberOfFridgeItemUsed, numberOfAdditionalItemsNeeded].\n* The score of the recipes in output is given by $score = numberOfIngredientsUsed^{\\frac{60}{prepTimeInMinutes}} - numberOfAdditionalIngredientsNeeded^{\\frac{prepTimeInMinutes}{15}}$ \n* The ouput array is sorted by the score of that array.\n\n**Initial Commentary**\n\nThe task provided is an interesting one. In the context of the lockdown experienced by many across the world in 2020, such a tool seems even more apt. The idea behind the task is to find a recipe that uses as many of the ingredients available at hand, while minimising the number of ingredients needed to be purchased, and minimising the preparation time. On immediate inspection, it is clear that these three optimisation goals could be contradictory in nature. For example, a recipe that uses all the ingredients available may require many more ingredients to be purchased than a recipe that uses only a small amount of ingredients availble. Also, a recipe that uses all ingredients available and require no additional ingredients may then require an extraordinary amount of time to prepare. \n\nBased on the potentially contradictory optimisation requirements, it is then important to derive a metric that provides a required balance between these 3 requirements. The $score$ metric defined as part of the evaluation of the task attempts to do this. The $score$ metric increases when more ingredients are used but the increment is limited exponentially by $\\frac{60}{prepTimeInMinutes}$. This means the the longer it takes to prepare the recipe, assuming the same number of ingredients used, the contribution to score by the number of ingredients used decreases exponentially. Conversely, the $score$ metric decreases when more additional ingredients are needed but the reduction is limited exponentially by $\\frac{prepTimeInMinutes}{15}$. This means the the longer it takes to prepare the recipe, assuming the same number of additional ingredients needed, the reduction of the score by the number of ingredients needed used increases exponentially. \n\nWhile the balance offered by the $score$ metric seems reasonable, a quick review of the data raises potential issues. On inspection of the preperation time provided for each recipe, the existence of recipes with $0$min preperation time points to recipes that regardless of ingredients available, will lead to an undefined score. A quick inspection of these recipes suggests that this is a data anomally for recipes on food.com that do not have a time entry.\n\nTo handle this issue, the following 2 proposals are made:\n\n1. Treat recipes with $0$min preperation time to have $0.5$min preperation time. \n2. Ignore recipes with $0$min preperation time.\n\nThe later proposal will be used and recipes with $0$min prep time as part of the calculation will be assign a score of $-maxint$ where $maxint$ is an arbitrarily large number.\n\nFurthermore, the existance of preperation time that take days could result in scores sufficiently large in magnitude that the kernel will not be able to handle it. In this tool the decimal module is used to manage this issue. During evaluation, this module may be required. Interestingly there exist a single recipe with $2147483647$min preperation time representing roughly 4000 years. This results in a score with such an absurdly large magnitude that the decimal module is unable to handle it. For situations like this, the score is fixed at $-maxint$.\n\n\n\n**Contents:**\n\n1. Setup\n2. Loading and cleaning the data\n3. Creating the API to perform the search\n4. Final Solution"},{"metadata":{},"cell_type":"markdown","source":"## 1. Setup\nThe setup steps imports all necessary modules"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Importing libraries\nimport numpy as np\nimport pandas as pd\nimport os\nimport pickle\nimport ast # parses list in lit string to pythong list\nfrom tqdm import tqdm # progress bar helpful in monitoring processes\nimport decimal","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Loading and cleaning the data\n\n### 2.1 Loading the data\nA generic load all files function is used to parse all data provided in input as pd.DataFrames. The DataFrames are stored as values in a dictionary with the input file name as the corresponding key.\n\nFor this task, only 3 of the input DataFrames are required:\n1. `ingr_map.pkl` provides a mapping of ingredients (i) to ingredient ids (i_id)\n2. `RAW_recipes.csv` provides a mapping of recipes (r) to ingredients (i), time (t), and recipe ids (r_id)\n3. `PP_recipes.csv` provides a mapping of recipe ids (r_id) to ingredient ids (i_id)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Def Load Files func\ndef loadfiles(directory):\n    files = {} # Initiate file dict\n    for dirname, _, filenames in os.walk('/kaggle/input'):\n        for filename in filenames:\n            fullpath = os.path.join(dirname, filename)\n            if filename.split(\".\")[-1] == \"csv\": # load csv file\n                files[''.join(filename.split(\".\")[:-1])] = pd.read_csv(fullpath)\n                print(f\"Loaded file: {filename}\")\n            elif filename.split(\".\")[-1] == \"pkl\": # load pkl file\n                with open(fullpath, 'rb') as f:\n                    files[''.join(filename.split(\".\")[:-1])] =  pickle.load(f)\n                    print(f\"Loaded file: {filename}\")\n    return files\n\n# Load files\nfiles = loadfiles('/kaggle/input')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ingredients = files['ingr_map']\nrecipes = files['RAW_recipes']\nr2i_map_raw = files['PP_recipes']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2 Cleaning the data\nThe data is cleansed and processed to create mappers (dict) to be used in the API to retrieve appropriate recipes. \n\n* `r2i_map`: Key = recipe id, Value = set of ingredient ids required for this recipe\n* `i2r_map`: Key = ingredient id, Value = set of recipe ids that use this ingredient \n* `id2r_map`: Key = recipe id, Value = recipe\n* `i2id_map`: Key = ingredient, Value = ingredient id\n\nTo save time, the generated mappers (dict) are saved as pkls, the script to generate the mappers have been commented out, and scripts to load the pkls left inline."},{"metadata":{"trusted":true},"cell_type":"code","source":"# def method to clean r2i_map_raw table\ndef generate_maps(r2i_map_raw):\n    r2i_map = {} # key = recipe id, value = ingredient id set\n    i2r_map = {} # key = ingredient id, value = recipe id set\n\n    # parse and append individual rows\n    for i in tqdm(range(len(r2i_map_raw.id))):\n        recipe_id = r2i_map_raw.id[i]\n        \n        # retrieve ingredients\n        ingredients = ingredients = ast.literal_eval(r2i_map_raw.query(f\"id == '{recipe_id}'\").ingredient_ids.values[0])\n\n        # add r2i entry\n        r2i_map[recipe_id] = set(ingredients)\n\n        # add i2r entry\n        for i in ingredients:\n            if i in i2r_map.keys():\n                i2r_map[i] = i2r_map[i].union({recipe_id})\n            else:\n                i2r_map[i] = {recipe_id}\n    \n    return r2i_map, i2r_map\n\nr2i_map, i2r_map = generate_maps(r2i_map_raw)\n\ni2id_map_raw_replaced = ingredients[['id','replaced']].drop_duplicates(subset='replaced', keep=\"first\")\ni2id_map_raw_raw_ingr = ingredients[['id','raw_ingr']].drop_duplicates(subset='raw_ingr', keep=\"first\")\ni2id_map_raw_processed = ingredients[['id','processed']].drop_duplicates(subset='processed', keep=\"first\")\n\ni2id_map = {**dict(zip(list(i2id_map_raw_replaced['replaced']), list(i2id_map_raw_replaced['id']))),\n            **dict(zip(list(i2id_map_raw_raw_ingr['raw_ingr']), list(i2id_map_raw_raw_ingr['id']))),\n            **dict(zip(list(i2id_map_raw_processed['processed']), list(i2id_map_raw_processed['id'])))}\n\nid2r_map_raw = recipes[['name','id']].drop_duplicates(subset='id', keep=\"first\")\nid2r_map = dict(zip(list(id2r_map_raw['id']),list(id2r_map_raw['name'])))\n\nr2min_map_raw = recipes[['minutes','id']].drop_duplicates(subset='id', keep=\"first\")\nr2min_map = dict(zip(list(r2min_map_raw['id']),list(r2min_map_raw['minutes'])))\n\nwith open('/kaggle/working/i2r_map.pkl', 'wb') as handle:\n    pickle.dump(i2r_map, handle, protocol=pickle.HIGHEST_PROTOCOL)\n\nwith open('/kaggle/working/r2i_map.pkl', 'wb') as handle:\n    pickle.dump(r2i_map, handle, protocol=pickle.HIGHEST_PROTOCOL)\n\nwith open('/kaggle/working/i2id_map.pkl', 'wb') as handle:\n    pickle.dump(i2id_map, handle, protocol=pickle.HIGHEST_PROTOCOL)\n    \nwith open('/kaggle/working/id2r_map.pkl', 'wb') as handle:\n    pickle.dump(id2r_map, handle, protocol=pickle.HIGHEST_PROTOCOL)\n\nwith open('/kaggle/working/r2min_map.pkl', 'wb') as handle:\n    pickle.dump(r2min_map, handle, protocol=pickle.HIGHEST_PROTOCOL)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading previously generated mappers\nwith open('/kaggle/working/i2r_map.pkl', 'rb') as f:\n    i2r_map =  pickle.load(f)\n\nwith open('/kaggle/working/r2i_map.pkl', 'rb') as f:\n    r2i_map =  pickle.load(f)\n\nwith open('/kaggle/working/i2id_map.pkl', 'rb') as f:\n    i2id_map =  pickle.load(f)\n\nwith open('/kaggle/working/id2r_map.pkl', 'rb') as f:\n    id2r_map =  pickle.load(f)\n    \nwith open('/kaggle/working/r2min_map.pkl', 'rb') as f:\n    r2min_map =  pickle.load(f)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Creating the API to perform the search"},{"metadata":{"trusted":true},"cell_type":"code","source":"def getRecipes(ingredient_list_id):\n    output_data = {} # key = recipe id, value = {'i_req': set(),'i_avail': set(),'i_needed': set(), 'time_req':r2min_map[r]}\n    \n    for i in ingredient_list_id:\n        recipes = i2r_map[i] # Retrieve recipes containing this ingredient\n        for r in recipes:\n            if r in output_data.keys():\n                output_data[r]['i_avail'] = output_data[r]['i_avail'].union({i})\n            else:\n                output_data[r] = {'i_req': r2i_map[r],'i_avail': {i}, 'time_req':r2min_map[r]}\n    \n    for r in output_data.keys():\n        output_data[r]['i_needed'] = output_data[r]['i_req'].difference(output_data[r]['i_avail'])\n    \n    return output_data\n\ndef parseIngredientList(ingredient_list_string):\n    ingredient_list_id=[]\n    for i in ingredient_list_string:\n        ingredient_list_id.append(i2id_map[i])\n    return ingredient_list_id\n\ndef score(recipe_data):\n    try:\n        if recipe_data['time_req']==0: \n            return -decimal.Decimal(2)**decimal.Decimal(1000)\n        else:\n            score = (decimal.Decimal((len(recipe_data['i_avail']))**decimal.Decimal(60.0/float(recipe_data['time_req']))) - (decimal.Decimal(len(recipe_data['i_needed']))**decimal.Decimal(float(recipe_data['time_req'])/15)))\n        return score\n    except:\n        return -decimal.Decimal(2)**decimal.Decimal(1000)\n\ndef sortByScore(output_data):\n    return sorted(list(output_data.keys()), key=lambda recipe: score(output_data[recipe]), reverse=True)\n\ndef maxScoreRecipeId(output_data):\n    return sortByScore(output_data)[0]\n\ndef getRecipeData(r_id,output_data):\n    recipe_data_list = []\n    recipe_data_list.append(r_id) # Append recipeId to list\n    recipe_data_list.append(id2r_map[r_id]) # Append recipeName to list\n    recipe_data_list.append(output_data[r_id]['time_req']) # Append prepTimeInMinutes to list\n    recipe_data_list.append(len(output_data[r_id]['i_avail'])) # Append numberOfFridgeItemUsed to list\n    recipe_data_list.append(len(output_data[r_id]['i_needed'])) # Append numberOfAdditionalItemsNeeded to list\n    return recipe_data_list\n\ndef hungryWithMyFridgeAPI(arrayOfArrayOfIngredients):\n    output_array = []\n    for ingredientsArray in arrayOfArrayOfIngredients:\n        recipes = getRecipes(parseIngredientList(ingredientsArray))\n        output_array.append(getRecipeData(maxScoreRecipeId(recipes),recipes))\n    return output_array\n\ndef scoreOutputArray(output_array):\n    scores = []\n    for output in output_array:\n        scores.append((decimal.Decimal(output[3])**decimal.Decimal(60.0/output[2])) - (decimal.Decimal(output[4])**decimal.Decimal(output[2]/15)))\n    return np.mean(scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Evaluation\n\ninput = [\n    ['winter squash', 'mexican seasoning', 'mixed spice', 'honey', 'butter', 'olive oil', 'salt'],\n    ['low sodium chicken broth', 'tomatoes', 'zucchini', 'potatoes', 'wax beans', 'green beans', 'carrots'],\n    ['spinach',  'garlic powder', 'soft breadcrumbs', 'oregano', 'onion'] ]\noutput = hungryWithMyFridgeAPI(input)\n\nfor i in range(len(input)):\n    print(\"For Available ingredients:\")\n    print(input[i])\n    print(\"\\nRecommended Recipe:\")\n    print(output[i])\n    print(f\"With Score: {scoreOutputArray([output[i]])}\\n\")\n\nprint(f\"\\nOverall Mean Score: {scoreOutputArray(output)}\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}