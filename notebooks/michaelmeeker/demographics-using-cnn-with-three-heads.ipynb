{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.data import AUTOTUNE\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.layers import Conv2D, SpatialDropout2D, MaxPool2D, Dense, Input, Flatten, BatchNormalization\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-17T20:37:32.016291Z","iopub.execute_input":"2021-09-17T20:37:32.01663Z","iopub.status.idle":"2021-09-17T20:37:37.725643Z","shell.execute_reply.started":"2021-09-17T20:37:32.016601Z","shell.execute_reply":"2021-09-17T20:37:37.724585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/age-gender-and-ethnicity-face-data-csv/age_gender.csv')\ndf = df.drop('img_name', axis = 1)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-17T20:37:37.726767Z","iopub.execute_input":"2021-09-17T20:37:37.726995Z","iopub.status.idle":"2021-09-17T20:37:42.68047Z","shell.execute_reply.started":"2021-09-17T20:37:37.726953Z","shell.execute_reply":"2021-09-17T20:37:42.679731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The images are stored in pixels as a flat string. The images are sized 48, 48 so we'll convert this in a bit.","metadata":{}},{"cell_type":"code","source":"df[['age', 'ethnicity', 'gender']].nunique()","metadata":{"execution":{"iopub.status.busy":"2021-09-17T20:37:42.682115Z","iopub.execute_input":"2021-09-17T20:37:42.682433Z","iopub.status.idle":"2021-09-17T20:37:42.697061Z","shell.execute_reply.started":"2021-09-17T20:37:42.682401Z","shell.execute_reply":"2021-09-17T20:37:42.695942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AGE_UNIQUE = 120\nETH_UNIQUE = 5\nGENDER_UNIQUE = 1\n\nIMAGE_SIZE = (48, 48)\nDROP_RATE = 0.5\nEPOCHS = 30\nLEARNING_RATE = 1e-3\nBATCH_SIZE = 512\nRANDOM_SEED = 2","metadata":{"execution":{"iopub.status.busy":"2021-09-17T21:25:10.932962Z","iopub.execute_input":"2021-09-17T21:25:10.933295Z","iopub.status.idle":"2021-09-17T21:25:10.937736Z","shell.execute_reply.started":"2021-09-17T21:25:10.933267Z","shell.execute_reply":"2021-09-17T21:25:10.936812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['age'].value_counts()\nsns.displot(df['age'])\nplt.ylim(0, 100)","metadata":{"execution":{"iopub.status.busy":"2021-09-17T20:37:42.706401Z","iopub.execute_input":"2021-09-17T20:37:42.706694Z","iopub.status.idle":"2021-09-17T20:37:43.239821Z","shell.execute_reply.started":"2021-09-17T20:37:42.706664Z","shell.execute_reply":"2021-09-17T20:37:43.238705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['ethnicity'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-17T20:37:45.811294Z","iopub.execute_input":"2021-09-17T20:37:45.811562Z","iopub.status.idle":"2021-09-17T20:37:45.81927Z","shell.execute_reply.started":"2021-09-17T20:37:45.81154Z","shell.execute_reply":"2021-09-17T20:37:45.818004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are five different ethnicities in this dataset, with 1-3 having fairly similar counts, 4 being the least represented, and 0 being far overrepresented. This could cause some problems so I'm going to stratify this.","metadata":{}},{"cell_type":"code","source":"df['gender'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-17T20:37:48.259269Z","iopub.execute_input":"2021-09-17T20:37:48.259682Z","iopub.status.idle":"2021-09-17T20:37:48.268342Z","shell.execute_reply.started":"2021-09-17T20:37:48.259645Z","shell.execute_reply":"2021-09-17T20:37:48.267275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['pixels_test'] = df['pixels'].map(lambda x: np.array([i for i in x.split(' ')], dtype = float).reshape(IMAGE_SIZE) / 255)","metadata":{"execution":{"iopub.status.busy":"2021-09-17T20:37:50.277802Z","iopub.execute_input":"2021-09-17T20:37:50.278083Z","iopub.status.idle":"2021-09-17T20:38:00.972666Z","shell.execute_reply.started":"2021-09-17T20:37:50.27806Z","shell.execute_reply":"2021-09-17T20:38:00.971539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Convering the string of pixels into an np array","metadata":{}},{"cell_type":"code","source":"df['pixels'] = df['pixels_test']\ndf = df.drop('pixels_test', axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-09-17T20:38:00.97378Z","iopub.execute_input":"2021-09-17T20:38:00.974041Z","iopub.status.idle":"2021-09-17T20:38:00.985653Z","shell.execute_reply.started":"2021-09-17T20:38:00.974014Z","shell.execute_reply":"2021-09-17T20:38:00.984438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ident_model():\n    input_layer = Input(shape = (*IMAGE_SIZE, 1), name = 'Input_Layer')\n    conv_1 = Conv2D(16, 3, activation = 'relu', name = 'Conv_1', padding = 'same')(input_layer)\n    conv_2 = Conv2D(16, 3, activation = 'relu', name = 'Conv_2', padding = 'same')(conv_1)\n    drop_1 = SpatialDropout2D(0.3)(conv_2)\n    pool_1 = MaxPool2D((2,2), name = 'Pool_1')(drop_1)\n    batch_1 = BatchNormalization()(pool_1)\n    conv_3 = Conv2D(32, 3, activation = 'relu', name = 'Conv_3', padding = 'same')(batch_1)\n    conv_4 = Conv2D(32, 3, activation = 'relu', name = 'Conv_4', padding = 'same')(conv_3)\n    drop_2 = SpatialDropout2D(0.3)(conv_4)\n    pool_2 = MaxPool2D((2,2), name = 'Pool_2')(drop_2)\n    batch_2 = BatchNormalization()(pool_2)\n    conv_5 = Conv2D(64, 3, activation = 'relu', name = 'Conv_5', padding = 'same')(batch_2)\n    pool_3 = MaxPool2D((2,2), name = 'Pool_3')(conv_5)\n    batch_3 = BatchNormalization()(pool_3)\n    conv_6 = Conv2D(128, 3, activation = 'relu', name = 'Conv_6', padding = 'same')(batch_3)\n    pool_4 = MaxPool2D((2,2), name = 'Pool_4')(conv_6)\n    batch_4 = BatchNormalization()(pool_4)\n    drop_3 = SpatialDropout2D(0.3)(batch_4)\n    flat = Flatten()(drop_3)\n    \n    age_dense_1 = Dense(256, activation = 'relu', name = 'Age_Dense_1')(flat)\n    age_dense_2 = Dense(256, activation = 'relu', name = 'Age_Dense_2')(age_dense_1)\n    final_age = Dense(1, activation = 'relu', name = 'Final_Age')(age_dense_2)\n    \n    eth_dense_1 = Dense(256, activation = 'relu', name = 'Eth_Density_1')(flat)\n    eth_dense_2 = Dense(256, activation = 'relu', name = 'Eth_Density_2')(eth_dense_1)\n    final_eth = Dense(ETH_UNIQUE, activation = 'softmax', name = 'Final_ETH')(eth_dense_2)\n    \n    #gender_dense_1 = Dense(256, activation = 'relu', name = 'GENDER_Density')(flat)\n    final_gender = Dense(GENDER_UNIQUE, activation = 'sigmoid', name = 'Final_GENDER')(flat)\n    \n    #return Model(inputs = input_layer, outputs = final_age, name = 'Age_Eth_Gender_Model')\n    #return Model(inputs = input_layer, outputs = [final_age, final_eth, final_gender], name = 'Age_Eth_Gender_Model')\n    #return Model(inputs = input_layer, outputs = [final_age, final_eth], name = 'Age_Eth_Gender_Model')\n    return Model(inputs = input_layer, outputs = [final_age, final_eth, final_gender], name = 'Age_Eth_Gender_Model')\n    #return Model(inputs = input_layer, outputs = final_age, name = 'Age_Eth_Gender_Model')\n    ","metadata":{"execution":{"iopub.status.busy":"2021-09-17T21:24:06.670373Z","iopub.execute_input":"2021-09-17T21:24:06.670652Z","iopub.status.idle":"2021-09-17T21:24:06.682744Z","shell.execute_reply.started":"2021-09-17T21:24:06.670628Z","shell.execute_reply":"2021-09-17T21:24:06.681162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = ident_model()\nmodel.compile(optimizer = Adam(LEARNING_RATE), loss = {'Final_Age':'mean_squared_error','Final_ETH':'sparse_categorical_crossentropy', 'Final_GENDER': 'binary_crossentropy'}\n              , metrics = {'Final_Age':'mean_absolute_error','Final_ETH':'sparse_categorical_accuracy', 'Final_GENDER': 'accuracy'})\n","metadata":{"execution":{"iopub.status.busy":"2021-09-17T21:24:18.323292Z","iopub.execute_input":"2021-09-17T21:24:18.32358Z","iopub.status.idle":"2021-09-17T21:24:18.471459Z","shell.execute_reply.started":"2021-09-17T21:24:18.323551Z","shell.execute_reply":"2021-09-17T21:24:18.470472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(model, to_file = 'model.jpg', show_shapes = True)","metadata":{"execution":{"iopub.status.busy":"2021-09-17T21:24:18.488726Z","iopub.execute_input":"2021-09-17T21:24:18.489054Z","iopub.status.idle":"2021-09-17T21:24:18.727228Z","shell.execute_reply.started":"2021-09-17T21:24:18.489021Z","shell.execute_reply":"2021-09-17T21:24:18.726044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model has a set of coupled conv2d layers before max pooling. The additional conv layer allows for more feature extracting before reducing the dimensions, and I saw a slight boost in accuracy doing so. However, training that model gave amazing results eth/gender (>94%) in the training, and a much more modest 70-80% in the val, meaning that I'm overfitting. The spatial2d dropouts should help with the overfitting.","metadata":{}},{"cell_type":"code","source":"pixels = np.zeros((len(df), *IMAGE_SIZE))\nage = np.zeros(len(df), dtype = 'int32')\neth = np.zeros(len(df), dtype = 'int')\ngender = np.zeros(len(df), dtype = 'int')\n\nfor i in range(len(df)):\n    pixels[i] = df['pixels'].iloc[i]\n    age[i] = df['age'].iloc[i]\n    eth[i] = df['ethnicity'].iloc[i]\n    gender[i] = df['gender'].iloc[i]\n    \nX_train, X_val, age_train, age_val, eth_train, eth_val, gender_train, gender_val = train_test_split(pixels, age, eth, gender, stratify = eth, random_state = RANDOM_SEED)","metadata":{"execution":{"iopub.status.busy":"2021-09-17T21:25:16.449964Z","iopub.execute_input":"2021-09-17T21:25:16.450271Z","iopub.status.idle":"2021-09-17T21:25:17.622694Z","shell.execute_reply.started":"2021-09-17T21:25:16.450248Z","shell.execute_reply":"2021-09-17T21:25:17.621902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Setting up the training/test splits. I decided to stratify on the eth since gender should be relatively easy to distinguish, and age is relatively hard (compare a 20 yr old to a 30 yr old to a 25 yr old). Also, eth has a major imbalance in the case of class 0, and a minor imbalance in the case of class 4","metadata":{}},{"cell_type":"code","source":"early_stopping = EarlyStopping(monitor = 'val_loss', patience = 5, restore_best_weights = True)\nhistory = model.fit(x = X_train, y = [age_train, eth_train, gender_train], validation_data = (X_val, [age_val, eth_val, gender_val]), epochs = 50, callbacks = early_stopping)","metadata":{"execution":{"iopub.status.busy":"2021-09-17T21:25:22.531909Z","iopub.execute_input":"2021-09-17T21:25:22.53226Z","iopub.status.idle":"2021-09-17T21:48:14.414705Z","shell.execute_reply.started":"2021-09-17T21:25:22.532236Z","shell.execute_reply":"2021-09-17T21:48:14.413643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Validation Scores:\n\nAge MAE = 6.1\n\nEth Accuracy = 72.9%\n\nGender = 84.6%\n\nI'm mostly satisfied with these values for now.","metadata":{}},{"cell_type":"code","source":"epochs = range(len(history.history['val_loss']))\nsns.lineplot(x = epochs, y = history.history['val_loss'], color = 'r', label = 'Validation')\nsns.lineplot(x = epochs, y = history.history['loss'], color = 'b', label = 'Training')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.title('Loss vs Epoch')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-09-17T21:59:19.578285Z","iopub.execute_input":"2021-09-17T21:59:19.578573Z","iopub.status.idle":"2021-09-17T21:59:19.756855Z","shell.execute_reply.started":"2021-09-17T21:59:19.578549Z","shell.execute_reply":"2021-09-17T21:59:19.755988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.lineplot(x = epochs, y = history.history['val_Final_GENDER_accuracy'], label = 'Gender')\nsns.lineplot(x = epochs, y = history.history['val_Final_ETH_sparse_categorical_accuracy'], label = 'Ethnicity')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')","metadata":{"execution":{"iopub.status.busy":"2021-09-17T22:02:15.342424Z","iopub.execute_input":"2021-09-17T22:02:15.342942Z","iopub.status.idle":"2021-09-17T22:02:15.939613Z","shell.execute_reply.started":"2021-09-17T22:02:15.342911Z","shell.execute_reply":"2021-09-17T22:02:15.938596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(X_val)","metadata":{"execution":{"iopub.status.busy":"2021-09-17T22:30:14.82853Z","iopub.execute_input":"2021-09-17T22:30:14.829012Z","iopub.status.idle":"2021-09-17T22:30:18.883895Z","shell.execute_reply.started":"2021-09-17T22:30:14.828985Z","shell.execute_reply":"2021-09-17T22:30:18.882955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_ages = predictions[0].reshape(-1)\npred_ages = pred_ages.astype(int)\npred_eth = predictions[1]\npred_eth = [np.argmax(i) for i in pred_eth]\npred_gender = predictions[2].reshape(-1)\npred_gender[pred_gender >= 0.5] = 1\npred_gender[pred_gender < 0.5] = 0\npred_gender = pred_gender.astype(int)","metadata":{"execution":{"iopub.status.busy":"2021-09-17T23:02:09.200031Z","iopub.execute_input":"2021-09-17T23:02:09.200339Z","iopub.status.idle":"2021-09-17T23:02:09.220196Z","shell.execute_reply.started":"2021-09-17T23:02:09.200315Z","shell.execute_reply":"2021-09-17T23:02:09.219032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Pred_ages starts off as a list of an np array, hence the reshape\nPred eth is a list of np arrays of length 5 with the probabilities to being in each class. Argmax gives the class corresponding to the highest probability\nPred Gender is a list of values 0-1, I binizarize these values to get the predicted gender","metadata":{}},{"cell_type":"markdown","source":"Let's see some examples.","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(5, 5, figsize = (20, 20))\naxes = axes.flatten()\nfor i in range(25):\n    axes[i].imshow(X_val[i])\n    axes[i].set_title(f'''    (Predicted, Actual)\n                Age ({pred_ages[i]}, {age_val[i]})\n                Eth ({pred_eth[i]}, {eth_val[i]} )\n                Gender ({pred_gender[i]}, {gender_val[i]})''')\nfig.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-09-17T23:02:10.653089Z","iopub.execute_input":"2021-09-17T23:02:10.653412Z","iopub.status.idle":"2021-09-17T23:02:13.992019Z","shell.execute_reply.started":"2021-09-17T23:02:10.653386Z","shell.execute_reply":"2021-09-17T23:02:13.990531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I'm pretty satisfied with these quick examples","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}