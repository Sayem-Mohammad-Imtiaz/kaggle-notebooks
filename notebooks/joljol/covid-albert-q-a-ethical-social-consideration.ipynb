{"cells":[{"metadata":{"_uuid":"bcca8d60-a295-4ffc-a6bd-18619e4697fb","_cell_guid":"812b4ce8-f9bb-48a1-bbd6-cc265bfa41da","trusted":true},"cell_type":"markdown","source":"This work uses the [**ALBERT**](https://arxiv.org/abs/1909.11942) model (**a light [BERT](https://en.wikipedia.org/wiki/BERT_(language_model) model**) to perform **question answering** tasks on CORD-19 dataset.\n\n**Pros**: Currently, ALBERT outperforms most other BERT variants, including BERT itself, on the popular Q&A benchmark [SQuAD 2.0](https://rajpurkar.github.io/SQuAD-explorer/). As of April 9, 2020, it is ranked 9th in all Q&A models and its accuracy is only marginally lower than the top ones.\n**Cons**: The ALBERT model was not specifically trained on bio- or medical-related database, so output is still sometimes inaccurate. Fine-tuning it on SQuAD-like bio database could help.\n\nALBERT is relatively new (developed around Sep 2019), so it is difficult to find pretrained model specifically fine-tuned to Q&A, unlike BERT model. So I have went ahead and fine-tuned it with SQuAD 2.0 myself, and I simply attached the pretrained model as a Kaggle dataset. This notebook will use the pretrained model. Both pretraining and inference are done thanks to Huggingface's [Transformers](https://github.com/huggingface/transformers) module."},{"metadata":{"_uuid":"82ef091d-23b3-4a8b-b9fe-84ebd5e50679","_cell_guid":"4d1738b2-5b1a-42bb-b7fe-8254a8444eab","trusted":true},"cell_type":"markdown","source":"For brevity, this notebook is focused on the scientific task. For detailed walkthrough of the code, plase refer to the [notebook](https://www.kaggle.com/joljol/covid-19-albert-transformer-for-q-a-on-cord-19) from which this notebook was originally forked."},{"metadata":{"_uuid":"446e0603-36fc-4b15-ab33-a77d3458c5c4","_cell_guid":"762a97cf-07cd-4cd3-a14b-0c24b5af14f4","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import torch \ndevice = 'cuda' if torch.cuda.is_available() else 'cpu' # GPU recommended\n\n# Loading custom pre-trained ALBERT model already fine-tuned to SQuAD 2.0\nimport transformers\nfrom transformers import AlbertTokenizer, AlbertForQuestionAnswering\ntokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\nmodel = AlbertForQuestionAnswering.from_pretrained(\n    '/kaggle/input' \\\n    '/nlp-albert-models-fine-tuned-for-squad-20'\\\n    '/albert-base-v2-tuned-for-squad-2.0').to(device)\n\n# Loading the CORD-19 dataset and pre-processing\nimport pandas as pd\ndata = pd.read_csv('/kaggle/input/CORD-19-research-challenge/metadata.csv',\n                   keep_default_na=False)\ndata = data[data['abstract']!=''] \\\n       .reset_index(drop=True) # Remove rows with no abstracts","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"102778e0-2d54-4842-8f18-f113cf20a2fe","_cell_guid":"0eff693a-9cc6-4f2b-99e3-ca5c5f8a1834","trusted":true},"cell_type":"markdown","source":"Code for interfencing the ALBERT model."},{"metadata":{"_uuid":"65479e10-2cf8-4b85-85ae-8824f1fa2994","_cell_guid":"9fe9aa1e-4634-4d5a-b5e6-b5d4370c0074","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.utils import Progbar\n\ndef inference_ALBERT(question):\n    \n    spans, scores, token_ids = [], [], []\n    \n    # Iterating over all CORD-19 articles and perform model inference\n    progress_bar = Progbar(len(data))\n    for i in range(len(data)):\n        if i % 500 == 0:\n            progress_bar.update(i)\n        text = data['abstract'][i]\n        input_ids = tokenizer.encode(question, text)\n        \n        # We have token limit of 512, so truncate if needed\n        if len(input_ids) > 512:\n            input_ids, token_type_ids = \\\n                input_ids[:511] + [3], token_type_ids[:512]\n                # [3] is the SEP token\n        \n        token_type_ids = [0 if i <= input_ids.index(3) \n                          else 1 for i in range(len(input_ids))]\n\n        # Preparing the tensors for feeding into model\n        input_ids_tensor = torch.tensor([input_ids]).to(device)\n        token_type_ids_tensor = torch.tensor([token_type_ids]).to(device)\n        \n        # Performing model inference\n        start_scores, end_scores = \\\n            model(input_ids_tensor, \n                  token_type_ids=token_type_ids_tensor)\n        \n        # Releasing GPU memory by moving each tensor back to CPU\n        # If GPU is not used, this step is uncessary but won't give error\n        input_ids_tensor, token_type_ids_tensor, start_scores, end_scores = \\\n            tuple(map(lambda x: x.to('cpu').detach().numpy(), \n                     (input_ids_tensor, token_type_ids_tensor, \\\n                      start_scores, end_scores)))\n        # Let me know if there's an easier way to do this, as I mostly work\n        # with tensorflow and I'm not very familiar with Keras\n\n        # Appending results to the corresponding lists\n        # Spans are the indices of the start and end of the answer\n        spans.append( [start_scores.argmax(), end_scores.argmax()+1] )\n        # Scores are the \"confidence\" level in the start and end\n        scores.append( [start_scores.max(), end_scores.max()] )\n        token_ids.append( input_ids )\n\n    spans = np.array(spans, dtype='int')\n    scores = np.array(scores)\n    \n    return spans, scores, token_ids","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"197366c4-9373-4124-9a22-b31a0e3254b4","_cell_guid":"52f16a4d-a45a-4472-8273-cb419a8e59b1","trusted":true},"cell_type":"markdown","source":"Code for formatting and displaying results."},{"metadata":{"_uuid":"357e787a-5f14-4dd4-80cc-1429cc411ca9","_cell_guid":"99a87cca-2998-416c-9e52-32ded865fde6","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# Define a helper function to directly convert token IDs to string\nconvert_to_str = lambda token_ids: \\\n    tokenizer.convert_tokens_to_string(\n    tokenizer.convert_ids_to_tokens(token_ids))\n\nfrom IPython.display import display, HTML\n\ndef display_results(spans, scores, token_ids, first_n_entries=15,\n                    max_disp_len=100):\n    \n    display(HTML(\n        'Model output (<text style=color:red>red font</text> '\\\n        'highlights the answer predicted by ALBERT NLP model)'\\\n        ))\n    \n    # We first sort the results based on the confidence in either the \n    # start or end index of the answer, whichever is smaller\n    min_scores = scores.min(axis=1) \n    sorted_idx = (-min_scores).argsort() # Descending order\n    \n    counter = 0    \n    for idx in sorted_idx:\n        \n        # Stop if first_n_entries papers have been displayed\n        if counter >= first_n_entries:\n            break\n        \n        # If the span is empty, the model prdicts no answer exists \n        # from the article. In rare cases, the end is smaller than\n        # the start. Both will be skipped\n        if spans[idx,0] == 0 or spans[idx,1] == 0 or \\\n            spans[idx,1]<=spans[idx,0]:\n            continue\n\n        # Obtaining the start and end token indices of answer\n        start, end = spans[idx, :]\n\n        abstract = data['abstract'][idx]\n        abstract_highlight = convert_to_str(token_ids[idx][start:end])\n        \n        # If we cannot fully convert tokens to original text,\n        # we then use the detokenized text (lower cased)\n        # Otherwise it would be best to have the original text,\n        # because there's lots of formatting especially in bio articles\n        start = abstract.lower().find(abstract_highlight)\n        if start == -1:\n            abstract = convert_to_str(token_ids[idx]\n                                      [token_ids[idx].index(3)+1:])\n            start = abstract.find(abstract_highlight)\n            end = start + len(abstract_highlight)\n            abstract = abstract[:-5] # to remove the [SEP] token in the end\n        else:\n            end = start + len(abstract_highlight)\n            abstract_highlight = abstract[start:end]\n        abstract_before_highlight, abstract_after_highlight = \\\n            abstract[: start], \\\n            abstract[end : ]\n    \n        # Putting information in HTML format\n        html_str = f'<b>({counter+1}) {data[\"title\"][idx]}</b><br>' + \\\n                   f'Confidence: {scores[idx].min():.2f} | ' + \\\n                   f'<i>{data[\"journal\"][idx]}</i> | ' + \\\n                   f'{data[\"publish_time\"][idx]} | ' + \\\n                   f'<a href={data[\"url\"][idx]}>{data[\"doi\"][idx]}</a>' + \\\n                   '<p style=line-height:1.1><font size=2>' + \\\n                   abstract_before_highlight + \\\n                   '<text style=color:red>%s</text>'%abstract_highlight + \\\n                   abstract_after_highlight + '</font></p>'\n        \n        display(HTML(html_str))\n        \n        counter += 1\n\n# Combining the inference function and the display function into one\ndef inference_ALBERT_and_display_results(question, \n                                         first_n_entries=15,\n                                         max_disp_len=100):\n    \n    spans, scores, token_ids = inference_ALBERT(question)\n    display_results(spans, scores, token_ids, \n                    first_n_entries, max_disp_len)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"c6f5f516-f4f7-4220-bbfb-d713cfd10c9f","_cell_guid":"7266bf3e-c8f9-4346-a12f-e6512a60577d","trusted":true},"cell_type":"markdown","source":"# **Subtask 1**\n\nOriginal subtask description:\n\nEfforts to articulate and translate existing ethical principles and standards to salient issues in COVID-2019"},{"metadata":{"_uuid":"0df56efc-33b4-445a-a711-ce7be98e2d61","_cell_guid":"73baab2a-f471-4914-aeb3-dd8b59be3553","trusted":true},"cell_type":"code","source":"inference_ALBERT_and_display_results(\n    'Articulation and translation of existing ethical '\n    'principles and standards to salient issues in COVID-2019 ')","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"b6d12971-7896-411a-9863-1585584f59d3","_cell_guid":"d211d900-61e3-45f5-a72c-832ac9114f15","trusted":true},"cell_type":"markdown","source":"# **Subtask 2**\n\nOriginal subtask description:\n\nEfforts to embed ethics across all thematic areas, engage with novel ethical issues that arise and coordinate to minimize duplication of oversight"},{"metadata":{"_uuid":"5c0f4bc2-268c-4d5f-b5ef-8ebd700d58f4","_cell_guid":"a838ea33-bf7e-40ec-8024-5c069f646440","trusted":true},"cell_type":"code","source":"inference_ALBERT_and_display_results(\n    'Embedding ethics across all thematic areas, '\n    'engage with novel ethical issues that arise and '\n    'coordinate to minimize duplication of oversight ')","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"905e35fe-11b1-4bd9-9abf-8ba29820b367","_cell_guid":"8ae7b06a-7b65-4ba4-88ec-6eebecefe1cc","trusted":true},"cell_type":"markdown","source":"# **Subtask 3**\n\nOriginal subtask description:\n\nEfforts to support sustained education, access, and capacity building in the area of ethics"},{"metadata":{"_uuid":"70af865a-4518-4d4f-983b-01776b025e42","_cell_guid":"66ad6594-e82b-4554-8c27-f4f35d7b9b73","trusted":true},"cell_type":"code","source":"inference_ALBERT_and_display_results(\n    'Support for sustained education, access, and '\n    'capacity building in the area of ethics ')","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"7975e2ef-ffff-47cf-abe1-c4a60c9b803a","_cell_guid":"d1dcdc38-cc13-488b-b11f-5327efefa7eb","trusted":true},"cell_type":"markdown","source":"# **Subtask 4**\n\nOriginal subtask description:\n\nEfforts to establish a team at WHO that will be integrated within multidisciplinary research and operational platforms and that will connect with existing and expanded global networks of social sciences."},{"metadata":{"_uuid":"7c04db9a-775a-4848-a34a-86c0d7846266","_cell_guid":"95f153c9-e4d2-4a25-8692-d6252b38db6a","trusted":true},"cell_type":"code","source":"inference_ALBERT_and_display_results(\n    'Establishment of a team at WHO that will be '\n    'integrated within multidisciplinary research and '\n    'operational platforms and that will connect with '\n    'existing and expanded global networks of social '\n    'sciences')","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"de795a10-c2c7-40bb-afc2-90654bcadba0","_cell_guid":"53452c3f-481b-435a-9cab-85cf0b761d68","trusted":true},"cell_type":"markdown","source":"# **Subtask 5**\n\nOriginal subtask description:\n\nEfforts to develop qualitative assessment frameworks to systematically collect information related to local barriers and enablers for the uptake and adherence to public health measures for prevention and control. This includes the rapid identification of the secondary impacts of these measures. (e.g. use of surgical masks, modification of health seeking behaviors for SRH, school closures)"},{"metadata":{"_uuid":"c13e2263-3314-4fd1-9d65-768311dad9c3","_cell_guid":"c2142fb2-e73a-4fbc-86d1-3384fb410d13","trusted":true},"cell_type":"code","source":"inference_ALBERT_and_display_results(\n    'Development qualitative assessment frameworks '\n    'to systematically collect information related to '\n    'local barriers and enablers for the uptake and '\n    'adherence to public health measures for prevention '\n    'and control, including the rapid identification '\n    'of the secondary impacts of these measures '\n    '(e.g. use of surgical masks, modification of health '\n    'seeking behaviors for SRH, school closures) ')","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"92179cb5-1866-4f98-ac6b-c405e4d20654","_cell_guid":"d1a9801e-fb6f-49d0-8e4c-26a702d915ce","trusted":true},"cell_type":"markdown","source":"# **Subtask 6**\n\nOriginal subtask description:\n\nEfforts to identify how the burden of responding to the outbreak and implementing public health measures affects the physical and psychological health of those providing care for Covid-19 patients and identify the immediate needs that must be addressed."},{"metadata":{"_uuid":"3c0972b5-09e6-4142-a262-a2a56cf8ab34","_cell_guid":"cb8f2657-5b71-4b92-8f5b-7c502a1e2ba4","trusted":true},"cell_type":"code","source":"inference_ALBERT_and_display_results(\n    'Identification of how the burden of responding '\n    'to the outbreak and implementing public health '\n    'measures affects the physical and psychological '\n    'health of those providing care for Covid-19 '\n    'patients and identify the immediate needs that '\n    'must be addressed ')","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"c2ae684e-f114-45e8-be52-81d5232615e8","_cell_guid":"1b93c6fa-99c4-461c-a78b-7ab7b0e650d9","trusted":true},"cell_type":"markdown","source":"# **Subtask 7**\n\nOriginal subtask description:\n\nEfforts to identify the underlying drivers of fear, anxiety and stigma that fuel misinformation and rumor, particularly through social media."},{"metadata":{"_uuid":"c6ca7151-6e64-4a18-aea5-8918b9ad6677","_cell_guid":"8f3ba2e1-da61-4636-9280-7824870df428","trusted":true},"cell_type":"code","source":"inference_ALBERT_and_display_results(\n    'Identification the underlying drivers of fear, '\n    'anxiety and stigma that fuel misinformation and \n    'rumor, particularly through social media.')","execution_count":0,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}