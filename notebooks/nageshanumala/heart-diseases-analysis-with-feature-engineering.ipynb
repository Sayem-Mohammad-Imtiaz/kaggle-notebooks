{"cells":[{"metadata":{"_uuid":"ad5bda75f92b285753048a9bd0a1fe6649faeb22"},"cell_type":"markdown","source":"**Objectives of this kernal\n\nLearning Feature Engineering for classification . \nLearning use of Decision Tree. \nLearning use of Random Forests\n**\n"},{"metadata":{"_uuid":"530abcce5da7f2a8f283689010bf09b633f6a0e2"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"366c3015adeed7d7b2a4509a6d7b94b35f7b5696"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"d91e6c9e2f1c962c38fd2038c3f677a9b27428bf"},"cell_type":"markdown","source":"# 1. Import"},{"metadata":{"_uuid":"ff45af719e36f75ce1d1b1c046b0aaffef15ea31","trusted":false},"cell_type":"code","source":"#Importing Libraries for data analysis\n\n# Call data manipulation libraries\nimport pandas as pd\nimport numpy as np\n\n# Feature creation libraries\nfrom sklearn.random_projection import SparseRandomProjection as sr  # Projection features\nfrom sklearn.cluster import KMeans                    # Cluster features\nfrom sklearn.preprocessing import PolynomialFeatures  # Interaction features\n\n# For feature selection\n# Ref: http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import mutual_info_classif  # Selection criteria\n\n# Data processing\n#  Scaling data in various manner\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, scale\n# Transform categorical (integer) to dummy\nfrom sklearn.preprocessing import OneHotEncoder\n\n# Splitting data\nfrom sklearn.model_selection import train_test_split\n\n# Decision tree modeling\nfrom sklearn.tree import  DecisionTreeClassifier as dt\n\n# RandomForest modeling\nfrom sklearn.ensemble import RandomForestClassifier as rf\n\n# Plotting libraries to plot feature importance\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Misc\nimport os, time, gc\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"032da74f513848d001bfffdd586ad11cfb213351"},"cell_type":"markdown","source":"# 2.0 Set working directory and read file"},{"metadata":{"_uuid":"5e89f3486b4a5ebf1489348c177c577ed16c91c3","trusted":false},"cell_type":"code","source":"\n\n# Read train/test files\nheart = pd.read_csv(\"../input/heart.csv\")\n\nheart.head(5)\nheart.shape         ## 303 x 14","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2eceda842a02eb2fde92caedc3e2b1b9748be20a","trusted":false},"cell_type":"code","source":"#  Split into Test and Training Data\nX_train, X_test, y_train, y_test = train_test_split(\n        heart.drop('target', 1), \n        heart['target'], \n        test_size = 0.3, \n        random_state=10\n        ) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"edacf1e391805392bb7dcb6000f4dbc763899d7f","trusted":false},"cell_type":"code","source":"# Look at data\nX_train.head(2)\nX_train.shape                        # 212 x 13\nX_test.shape                         # 91 x 13\n\ny_test.shape                        # 91 x \ny_train.shape                       # 212 x\n\n# Data types\nX_train.dtypes.value_counts()   # All afeatures re integers \n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d1bcac91b990aeb79908f17eedb91ffe237c8485","trusted":false},"cell_type":"code","source":"# Target classes are almost balanced\nheart.target.value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2158e9c6024a09e05042605bfe603858bc4c8425","trusted":false},"cell_type":"code","source":"# Check if there are Missing values? None\nX_train.isnull().sum().sum()  # 0\nX_test.isnull().sum().sum()   # 0","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c92c147d7785400a339f3c2a198262347fee4d40"},"cell_type":"markdown","source":"# 3. Feature Engineering #"},{"metadata":{"_uuid":"54e6435643a5c98546d3478062bafc495db2bb8c","trusted":false},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cffc69add1d3c1088065a9a4560daff357cc0188"},"cell_type":"markdown","source":"#  Using Statistical Numbers \n"},{"metadata":{"_uuid":"ab03bf89f44c1a0e5141ac0a3693a47e03b2b283","trusted":false},"cell_type":"code","source":"#  Feature 1: Row sums of features  More successful\n#                when data is binary.\n\nX_train['sum'] = X_train.sum(numeric_only = True, axis=1)  # numeric_only= None is default\nX_test['sum'] = X_test.sum(numeric_only = True,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3f82389ae8c80fad9512e880411bae4f5dd94c2d","trusted":false},"cell_type":"code","source":"# Assume that value of '0' in a cell implies missing feature\n#     Transform train and test dataframes\n#     replacing '0' with NaN\n#     Use pd.replace()\ntmp_train = X_train.replace(0, np.nan)\ntmp_test = X_test.replace(0,np.nan)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2e8303fa2d10772f715b0558b2ac10c5f95787dc","trusted":false},"cell_type":"code","source":"#  Check if tmp_train is same as train or is a view\n#     of train? That is check if tmp_train is a deep-copy\n\ntmp_train is X_train                # False\ntmp_train._is_view                # False","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6a9900e50e34038d85f560a0836f6c93513afa49","trusted":false},"cell_type":"code","source":"# Check if 0 has been replaced by NaN\ntmp_train.head(1)\ntmp_test.head(1)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"20b4b53f88b77467e0610e621c108c10cf040cd1","trusted":false},"cell_type":"code","source":"# Feature 2 : For every row, how many features exist\n#                that is are non-zero/not NaN.\n#                Use pd.notna()\ntmp_train.notna().head(1)\nX_train[\"count_not0\"] = tmp_train.notna().sum(axis = 1)\nX_test['count_not0'] = tmp_test.notna().sum(axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"af4e4ec341955d64bf197c748029baf69571c25a","trusted":false},"cell_type":"code","source":"# Similary create other statistical features\n#    Feature 3\n\nfeat = [ \"var\", \"median\", \"mean\", \"std\", \"max\", \"min\"]\nfor i in feat:\n    X_train[i] = tmp_train.aggregate(i,  axis =1)\n    X_test[i]  = tmp_test.aggregate(i,axis = 1)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f4a4b3bff10e9e722d2eb72262124dcd13845f14","trusted":false},"cell_type":"code","source":"# Delete not needed variables and release memory\ndel(tmp_train)\ndel(tmp_test)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"32641099aa2b4e9cd48f33af4b2c82ffe74c25f6","trusted":false},"cell_type":"code","source":"# So what do we have finally\nX_train.shape                \nX_train.head(1)\nX_test.shape                 \nX_test.head(2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aa2200163b2113db9c400c5a604c18f0c3eeb863","trusted":false},"cell_type":"code","source":"# Before we proceed further, keep target feature separately\ntarget = y_train\ntarget.tail(2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"511b3fe815545079876b68eaf1f3709745d36548","trusted":false},"cell_type":"code","source":"# Store column names of our data somewhere\n#     We will need these later (at the end of this code)\ncolNames = X_train.columns.values\ncolNames\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"23e022c1ee2c77fee764ea9937becf62f45becb3"},"cell_type":"markdown","source":"# Feature creation Using Random Projections "},{"metadata":{"_uuid":"497a4177390021b4409d99e6fcb5d32a26d17f6a","trusted":false},"cell_type":"code","source":"\n# Random projection is a fast dimensionality reduction feature\n#     Also used to look at the structure of data\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3c8fc8d5a41d55afc0434983159711fb9cd8e64e","trusted":false},"cell_type":"code","source":"#  Generate features using random projections\n#     First stack train and test data, one upon another\ntmp = pd.concat([X_train,X_test],\n                axis = 0,            # Stack one upon another (rbind)\n                ignore_index = True\n                )\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6111d2b447f6ee88b616599a32241a23084af904","trusted":false},"cell_type":"code","source":"\ntmp.shape     # 303 X 21\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b7980486fa32003f15eb3173da95d560467ae121","trusted":false},"cell_type":"code","source":"# Transform tmp t0 numpy array\n\ntmp = tmp.values\ntmp.shape       # 303 X 21\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"47c44d0283adeb9900ac9ae445a0f5291d4af767","trusted":false},"cell_type":"code","source":"#  Let us create 8 random projections/columns\nNUM_OF_COM = 8","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"943025ed8d1d1cb874e8b1e62389b248a1164498","trusted":false},"cell_type":"code","source":"#  Create an instance of class\nrp_instance = sr(n_components = NUM_OF_COM)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"37b058b876604dcd8c78714ad32e771ab556e5bc","trusted":false},"cell_type":"code","source":"# fit and transform the (original) dataset\n#      Random Projections with desired number\n#      of components are returned\nrp = rp_instance.fit_transform(tmp[:, :13])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ce4c7594d3fddfa622087f931940861bb4dd0238","trusted":false},"cell_type":"code","source":"#  Look at some features\nrp[: 5, :  3]\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0f17aa8ff534e3fdf5b7d6ba525e6e55fe5c8c71","trusted":false},"cell_type":"code","source":"#  Create some column names for these columns\n#      We will use them at the end of this code\nrp_col_names = [\"r\" + str(i) for i in range(8)]\nrp_col_names\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cc6e3f001b52e9e3185b254a2a3de7a43a242ae4"},"cell_type":"markdown","source":"# Feature creation using kmeans \n\n"},{"metadata":{"_uuid":"3fce8c606e33e19e50ff1775dc0797f6fef32568","trusted":false},"cell_type":"code","source":"# Before clustering, scale data\n#  Create a StandardScaler instance\nse = StandardScaler()\n# fit() and transform() in one step\ntmp = se.fit_transform(tmp)\n# \ntmp.shape               ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c5ca9e7082da545f1c5045f715cd00f4093256b9","trusted":false},"cell_type":"code","source":"#  Perform kmeans using 13 features.\n#     No of centroids is no of classes in the 'target'\ncenters = target.nunique()    \ncenters               ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"507661eccb2ad9d99c36552fb644294b31230f7a","trusted":false},"cell_type":"code","source":"# Begin clustering\nstart = time.time()\n\n# First create object to perform clustering\nkmeans = KMeans(n_clusters=centers,\n                n_jobs = 4)         \n\n# Next train the model on the original data only\nkmeans.fit(tmp[:, : 13])\n\nend = time.time()\n(end-start)/60.0      ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"64869f023e4184f2c30c8741e7603303c6d5a9ea","trusted":false},"cell_type":"code","source":"# Get clusterlabel for each row (data-point)\nkmeans.labels_\nkmeans.labels_.size \n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a495206ada6dbbd555278df9cf75c55a7accbcec","trusted":false},"cell_type":"code","source":"# Cluster labels are categorical. So convert them to dummy\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d84b58b81920a0c228b8eb30afb5df582d496639","trusted":false},"cell_type":"code","source":"#  Create an instance of OneHotEncoder class\nohe = OneHotEncoder(sparse = False)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea6a145d6fa6645217543afd3cb898fa6986127a","trusted":false},"cell_type":"code","source":"# Use ohe to learn data\n#      ohe.fit(kmeans.labels_)\nohe.fit(kmeans.labels_.reshape(-1,1))     \n                                          \n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"02d6a6948202825b00c7d967b9933cfba86a07e8","trusted":false},"cell_type":"code","source":"# Transform data now\ndummy_clusterlabels = ohe.transform(kmeans.labels_.reshape(-1,1))\ndummy_clusterlabels\ndummy_clusterlabels.shape    \n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"199fd62d7cbb6c65d7bc5f5b7d63010a2287925b","trusted":false},"cell_type":"code","source":"# We will use the following as names of new two columns\n#      We need them at the end of this code\n\nk_means_names = [\"k\" + str(i) for i in range(2)]\nk_means_names\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c34bc2017a7a53e67f75ce937afead1effd75717"},"cell_type":"markdown","source":"# Creating Interaction features \n# Using Polynomials"},{"metadata":{"_uuid":"5856fabd89ea63032b6f45e6f22212ac44d343f9","trusted":false},"cell_type":"code","source":"\n#  Will require lots of memory if we take large number of features\n#     Best strategy is to consider only impt features\n\ndegree = 2\npoly = PolynomialFeatures(degree,                 # Degree 2\n                          interaction_only=True,  # Avoid e.g. square(a)\n                          include_bias = False    # No constant term\n                          )\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"abf04c4070c9cc88bddb649e3bfa924c82566bfd","trusted":false},"cell_type":"code","source":"# Consider only first 8 features\n#      fit and transform\ndf =  poly.fit_transform(tmp[:, : 8])\n\n\ndf.shape     # 303 X 36\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a3ba665344f7997697db77e037e002fc3049cfa0","trusted":false},"cell_type":"code","source":"#  Generate some names for these 36 columns\npoly_names = [ \"poly\" + str(i)  for i in range(36)]\npoly_names\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b7c38e0788a35fcadfda27381af773e434a3090b"},"cell_type":"markdown","source":"# concatenate all features  "},{"metadata":{"_uuid":"bcb63f38ba2c34855bd133cfb876a2a858054d56","trusted":false},"cell_type":"code","source":"\n\n# Append now all generated features together\n# Append random projections, kmeans and polynomial features to tmp array\n\ntmp.shape       \n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aaf5fc48aed983c881bed69fa35c587d53cc0039","trusted":false},"cell_type":"code","source":"#   If variable, 'dummy_clusterlabels', exists, stack kmeans generated\n#       columns also else not. 'vars()'' is an inbuilt function in python.\n#       All python variables are contained in vars().\n\nif ('dummy_clusterlabels' in vars()):               #\n    tmp = np.hstack([tmp,rp,dummy_clusterlabels, df])\nelse:\n    tmp = np.hstack([tmp,rp, df])       \n\n\ntmp.shape          \n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d7a34eb56dd55440dcbf6ede22bcc91fd9ace3a2","trusted":false},"cell_type":"code","source":"# Combine train and test into X and y to split compatible datasets\nX = tmp\nX.shape     \n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2fdfb95826f6254f90ecc15c159e5baf0ea3ab2c","trusted":false},"cell_type":"code","source":"# Combine y_train and y_test into y to split into compatible datasets later\ny = pd.concat([y_train,y_test],\n                axis = 0,            \n                ignore_index = True\n                )\ny.shape        ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2454a2115f8d1034c25eb19dea2822f6a0e21237","trusted":false},"cell_type":"code","source":"# Delete tmp - as a good programming practice\ndel tmp\ngc.collect()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"249c4a6669d9eaeb1361a40985821a693d600702"},"cell_type":"markdown","source":"# Model building \n"},{"metadata":{"_uuid":"e54b7f9cff425701b7baed693a0b7be2373c69be","trusted":false},"cell_type":"code","source":"# Split the feature engineered data into new training and test dataset\nX_train, X_test, y_train, y_test = train_test_split(\n                                                    X,\n                                                    y,\n                                                    test_size = 0.3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5b809aa0cba71f899b493f06e62e745de0c967bf"},"cell_type":"markdown","source":"## Final data for model creation and testing\n### X_train: Training Data with new features\n### y_train: expected output for training data\n\n### X_test: test data with new features\n### y_test: expected output for test data"},{"metadata":{"_uuid":"bb9f00fd0abdd2f8f1ff31981cb499a63b9bc559","trusted":false},"cell_type":"code","source":"# \nX_train.shape   \n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"63866f4088f020e4f97463e9fd36cad35e009d27","trusted":false},"cell_type":"code","source":"X_test.shape    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0e10347c013adddcff6e66845cc2c1335b1dedf5","trusted":false},"cell_type":"code","source":"# Decision tree classification\n# Create an instance of class\nclf1_dt = dt(min_samples_split = 5,\n         min_samples_leaf= 3\n        )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"83f5aad139869ce0fcd84e317340720a6acffc35","trusted":false},"cell_type":"code","source":"start = time.time()\n# Fit/train the object on training data\n#      Build model\nclf1_dt = clf1_dt.fit(X_train, y_train)\nend = time.time()\n(end-start)/60                     \n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3ee67fcff97ccb4778230124e56839082ae79d2b","trusted":false},"cell_type":"code","source":"#  Use model to make predictions\nclasses1_dt = clf1_dt.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5e5595c14b35e1ed80b42fc73ce316c5a210c26d","trusted":false},"cell_type":"code","source":"#  Check accuracy\n(classes1_dt == y_test).sum()/y_test.size      ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"73b2bb16cfc6e5fdd54723e1bf498c55437f934a"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"b3383d49697c1da4960441981b99afc871d23c3a","trusted":false},"cell_type":"code","source":"#  Instantiate RandomForest classifier\nclf1_rf = rf(n_estimators=50)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"94ffbff2c985f4038ffd4174c367b70774196762","trusted":false},"cell_type":"code","source":"# Fit/train the object on training data\n#      Build model\n\nstart = time.time()\nclf1_rf = clf1_rf.fit(X_train, y_train)\nend = time.time()\n(end-start)/60                    \n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b749e579d3f704b4748a2561508d2096e9ae9e47","trusted":false},"cell_type":"code","source":"# Use model to make predictions\nclasses1_rf = clf1_rf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"888ea0bb52534e047fc8b920c6c8da90dff46238","trusted":false},"cell_type":"code","source":"#  Check accuracy\n(classes1_rf == y_test).sum()/y_test.size      ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"44f2ba3b7c840583784b45fd63ef0551ef2b7096"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"f944f1a47ca6f9ea2b5db9e6b5721c24b6c5b610"},"cell_type":"markdown","source":"# Feature selection "},{"metadata":{"_uuid":"6ba4e6653454d5b9e998b91012c3f839570ab206"},"cell_type":"markdown","source":" ****************************************\n## Using feature importance given by model\n****************************************\n"},{"metadata":{"_uuid":"aef3b9d837429164972b627d55eab703ba62ddf1","trusted":false},"cell_type":"code","source":"#  Get feature importance\nclf1_rf.feature_importances_        \nclf1_rf.feature_importances_.size   ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"980496d0c29f55db89db3a2d797026b0e711ef15","trusted":false},"cell_type":"code","source":"# To our list of column names, append all other col names\n#      generated by random projection, kmeans (onehotencoding)\n#      and polynomial features\n#      But first check if kmeans was used to generate features\n\nif ('dummy_clusterlabels' in vars()):       \n    colNames = list(colNames) + rp_col_names+ k_means_names + poly_names\nelse:\n    colNames = colNames = list(colNames) + rp_col_names +  poly_names      ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"83c8bf6220caf3c02baf7995a9b407f0ce248992","trusted":false},"cell_type":"code","source":"# So how many columns?\nlen(colNames)           ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e6c74a1247c2193ea93d2a82caa1cd365454b272","trusted":false},"cell_type":"code","source":"#  Create a dataframe of feature importance and corresponding\n#      column names. Sort dataframe by importance of feature\nfeat_imp = pd.DataFrame({\n                   \"importance\": clf1_rf.feature_importances_ ,\n                   \"featureNames\" : colNames\n                  }\n                 ).sort_values(by = \"importance\", ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"24518de0ee23f5d174b10a5b9cc4df66bb3dd1a9","trusted":false},"cell_type":"code","source":"feat_imp.shape                  \nfeat_imp.head(13)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ce2df4c880a8d4dd171fd390d1c8d4c87deae4ca"},"cell_type":"markdown","source":"## Notice the number of derived parameters making into the top important features\n*******************"},{"metadata":{"_kg_hide-output":true,"_uuid":"3709f0d0018fca84f00ef2a7951b657db5083af4","trusted":false},"cell_type":"code","source":"# Plot feature importance for first 20 features\ng = sns.barplot(x = feat_imp.iloc[  : 20 ,  1] , y = feat_imp.iloc[ : 20, 0])\ng.set_xticklabels(g.get_xticklabels(),rotation=90)\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d3f3d6faaaae666548baaf5ae9f37fe1e14005bd"},"cell_type":"markdown","source":"## Notice the K-means parameters... they're found to be most relevant!!\n***********"},{"metadata":{"_uuid":"c62092347bf4a4e8afbe49631ef0326478e27e7d","trusted":false},"cell_type":"code","source":"# Select top 13 columns and get their indexes\n#      Note that in the selected list few kmeans\n#      columns also exist\nnewindex = feat_imp.index.values[:13]\nnewindex","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"00ae31b6d84f007508447a99d93301855bb176a7","trusted":false},"cell_type":"code","source":"# Use these top 13 columns for classification\n#   Create DTree classifier object\nclf2_dt = dt(min_samples_split = 5, min_samples_leaf= 3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cd415e251adb8ff83166330f5762e076bb087950","trusted":false},"cell_type":"code","source":"# Train the object on data\nstart = time.time()\nclf2_dt = clf2_dt.fit(X_train[: , newindex], y_train)\nend = time.time()\n(end-start)/60                     ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a81f06ba1176b2bc0d2f344542aee222f6423de","trusted":false},"cell_type":"code","source":"#  Make prediction\nclasses2_dt = clf2_dt.predict(X_test[: , newindex])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d5d138dbb7c79337ed702de7ad1b9ec2dd8e01ac","trusted":false},"cell_type":"code","source":"#  Accuracy?\n(classes2_dt == y_test).sum()/y_test.size ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6691f00a6f44922d4b846763bd7ecb836d2645ec"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"e5144bfa8c9f152d23377de9c95c234483c045a6","trusted":false},"cell_type":"code","source":"# Create RForest classifier object\nclf2_rf = rf(n_estimators=500)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b506a7eb616c7df8da0590187ac95fd816e91108","trusted":false},"cell_type":"code","source":"# Traion the object on data\nstart = time.time()\nclf2_rf = clf2_rf.fit(X_train[: , newindex], y_train)\nend = time.time()\n(end-start)/60                     ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e71c0d1eed7aa5356bd94f6ee27b4794e53a2fe8","trusted":false},"cell_type":"code","source":"# Make prediction\nclasses2_rf = clf2_rf.predict(X_test[: , newindex])\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"05a19fde828a3552c52fd311453274316c62d545","trusted":false},"cell_type":"code","source":"# Accuracy?\n(classes2_rf == y_test).sum()/y_test.size  \n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fba85a9416cdf3c7c5c5bda267283626e8251956"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"9fd0f76ea6582aa69684bb638a1532df331fe1db"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"8d7ed687731f5787a9e78598fdcee4aefb2cebee"},"cell_type":"markdown","source":"## Using top 16 features for classification as per newindex2"},{"metadata":{"_uuid":"f342e055bb6e0658e8e1de58e096d51c75ee1750","trusted":false},"cell_type":"code","source":"# Select top  columns and get their indexes\n#      Note that in the selected list few kmeans\n#      columns also exist\nnewindex2 = feat_imp.index.values[:10]\nnewindex2","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"16c81640342636ce2cb3449f93dd8db65f6ed6c2","trusted":false},"cell_type":"code","source":"#   Create DTree classifier object\nclf3_dt = dt(min_samples_split = 5, min_samples_leaf= 3)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3eafe8ea9da67d83d0770f4d905c0d587a24b309","trusted":false},"cell_type":"code","source":"# Train the object on data\nstart = time.time()\nclf3_dt = clf3_dt.fit(X_train[: , newindex2], y_train)\nend = time.time()\n(end-start)/60                     \n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"34ad2ae391b075bc833e83983132b03630b2c259","trusted":false},"cell_type":"code","source":"#  Make prediction\nclasses3_dt = clf3_dt.predict(X_test[: , newindex2])\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"382e5851438e9c79c5a7fa93253e5f563aa5d10c","trusted":false},"cell_type":"code","source":"# Accuracy?\n(classes3_dt == y_test).sum()/y_test.size\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4ce972044a7e8ecb3ba3bf945dd404998c060b03"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"8e9167f5f2cdc1d710abe42aeb04fe1ff03c7ab9","trusted":false},"cell_type":"code","source":"#  Create RForest classifier object\n# increasing the number of estimators to 300 from 50...\nclf3_rf = rf(n_estimators=500)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8a9941108616c2c035ba26285fd11481642b795c","trusted":false},"cell_type":"code","source":"# Train the object on data\nstart = time.time()\nclf3_rf = clf3_rf.fit(X_train[: , newindex2], y_train)\nend = time.time()\n(end-start)/60                     \n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"39f7a1172afbbd0965ead615bb59b4ea6a28e994","trusted":false},"cell_type":"code","source":"#  Make prediction\nclasses3_rf = clf3_rf.predict(X_test[: , newindex2])\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1aabac4a2ce06f5d39e9024caa03254464f21f5d","trusted":false},"cell_type":"code","source":"#  Accuracy?\n(classes3_rf == y_test).sum()/y_test.size \n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3d932df19e4010a44c3b210f97b78616d14192d9"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"5c6ed2607d3244d82905a1f9e86c08483cb771ad"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"1b146810f32390c9b36d7ec9b4e8557ee9830a40"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"cb18ed8011ff1c1e52fa72135f1258ccd1d47519","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}