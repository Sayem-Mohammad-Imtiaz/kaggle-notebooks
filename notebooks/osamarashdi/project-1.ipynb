{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"\n#Importing Packages\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport numpy.random as nr\nimport scipy.stats as ss\nimport math\nimport statsmodels.stats.weightstats as ws\nfrom statsmodels.stats.power import tt_ind_solve_power\nfrom statsmodels.stats.multicomp import pairwise_tukeyhsd\nfrom sklearn import preprocessing\nimport sklearn.model_selection as ms\nfrom sklearn import linear_model, mixture\nimport sklearn.metrics as sklm\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.cluster import KMeans, AgglomerativeClustering, SpectralClustering, DBSCAN\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.preprocessing import StandardScaler\n\nimport plotly.graph_objs as go\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import basic libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importing the Data\nins = pd.read_csv('../input/insurance/insurance.csv')\nins.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"About the Data\nage: Age of primary beneficiary.\nsex: Insurance contractor gender: female, male.\nbmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height, objective index of body weight (kg / m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9.\nchildren: Number of children covered by health insurance / Number of dependents.\nsmoker: Whether the contractor is a smoker or not. .\nregion: The beneficiary's residential area in the US, northeast, southeast, southwest, northwest.\ncharges: Individual medical costs billed by health insurance.\n\n along with the other interesting insights we gained form this table, I hope that this data will be a warning for smokers, and non-smokers, about the hazardous nature of this substance.\n \nthe problem: is the increased diseases that caused the smoking.\n solutions:I hope that this data will be a warning for smokers, and non-smokers, about the hazardous nature of this substance.\nProcedures:\n1- Visualizing and inspect the Data to get as much an insight about it as we can.\n2- Statistical analysis of data\n3- Model data either classification"},{"metadata":{},"cell_type":"markdown","source":"firstly i will provide the Visualize concept into this data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"ins.hist(layout = (3, 3), figsize=(12, 9), color='blue', grid=False, bins=15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Histogram Observations:\n-We can see that only the bmi feature is normally distributed, with a mean slightly above the maximum accepted value = 30.\n-Age seems to be uniformly distributed, except for the young ages at the far left, where we have more data coming from this age group.\n-Charges and children features are right-skewed.\n-For children, this is expected, as people prefer to have few (or no children) these days than to have larger fmailies. And also, as parnets get older, their children won't be cosidred as dependents anymore. So it makes sense to have more smaples with fewer children.\n-The skewness of Charges indicates that there are few people who are being charged higher than average. This may lead to some bias in the study. -The skwness and non-normal distibution of these categories is partly responsible for the low correlation we find between them"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizing the frequency of the smoker category:\ncounts = ins['smoker'].value_counts() \ncounts.plot.bar(color = 'blue', grid=False) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#For the numeric data, we can compare them with the combined histogram and KDNs plot:\ndef plot_density_hist(ins, cols, bins = 10, hist = False):\n    for col in cols:\n        sns.set_style(\"whitegrid\")\n        sns.distplot(ins[col], bins = bins, rug=True, hist = hist)\n        plt.title('Histogram of ' + col) \n        plt.xlabel(col) \n        plt.ylabel('')\n        plt.show()\n        \nplot_cols = ['bmi', 'charges', 'age', 'children']\nplot_density_hist(ins, plot_cols, bins = 20, hist = True) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data is much clearer now. (Notice how all the data is normalized on the y axis such that the area under the plot is equal to 1.)\n1- Notice how the bmi is fairly normal with few outliers to the right, but not much to make a noticable skew.\n2- We knew that the charges were right-skewed but now we can see a samll bump between 30000 and 40000$ whcih we may need to investigate further.\n3- Again, the number of participants around the age of 20 is too large compared to the rest. this could be the reason why the children plot is very much skewd to the right and has no bell shape at all."},{"metadata":{},"cell_type":"markdown","source":"# Visualizing the frequency of the smoker category:(smoking or no);"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking the skewness of charges\nskew = ss.skewtest(ins['charges'])\nskew","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_scatter(ins, cols, col_y = 'charges'):\n    for col in cols:\n        fig = plt.figure(figsize=(7,6)) # define plot area\n        ax = fig.gca() # define axis   \n        ins.plot.scatter(x = col, y = col_y, ax = ax)\n        ax.set_title('Scatter plot of ' + col_y + ' vs. ' + col) \n        ax.set_xlabel(col) \n        ax.set_ylabel(col_y)\n        plt.show()\n\nnum_cols = ['age', 'bmi', 'children']\nplot_scatter(ins, num_cols)   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above plots suffer from a some over-plotting of the data, especially the bmi-charges one. To resolve this we can use transparency in the data points or use a different type of plot, the contour plot"},{"metadata":{},"cell_type":"markdown","source":"# secondly i will provide the Statistical analysis concept to the data******"},{"metadata":{},"cell_type":"markdown","source":"# #Describing the Statistical Properties of the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nins.describe().round(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# We now compare charges by grouping them by the smoker category and look at the mean and std."},{"metadata":{"trusted":true},"cell_type":"code","source":"\ncharges_grouped = ins[['charges','smoker']].groupby('smoker')\nprint(' Mean by smoker')\nprint(charges_grouped.mean().round(2))\nprint('\\n Standard deviation by smoker')\nprint(charges_grouped.std().round(2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is obvious how much the smoker and non-smoker differ in their medical charges, and also by their standard deviation; std of smokers is more than double of that of non-smoker. Hence while non-smokers seem to have their medical charges varying little about the mean, in other words, their medical health seems to be, more or less, similar. Non-smokers, on the other hand, vary a lot around the mean, which indicates that their bodies respond differently to smoking (e.g. some may develop lung cancer while others won't)\n\nWe now run a 2-tailed t-test to test whether the difference we see above in the smoking categeory could be due to chance, in other words, due to sampling error (H0) or is it a real difference (H1)"},{"metadata":{},"cell_type":"markdown","source":"# **#Finally  Classification**\nNow I do a classification model to predict whether someone is a smoker or not from his insurance data. \nFirst, we start by digitizing the smoker category, however not in a binary code, but in single digit for each subcategory, e.g. 1 for Yes and 0 for no. This is so we won't get a double entry into the algorithm model. This is why I don't use the one-hot-encoder here."},{"metadata":{"trusted":true},"cell_type":"code","source":"label = np.array(ins['smoker'])\nenc = preprocessing.LabelEncoder()\nenc.fit(label)\nlabel = enc.transform(label)\nlabel.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We proceed as before.\ndef encode_string(cat_features):\n    enc = preprocessing.LabelEncoder()\n    enc.fit(cat_features)\n    enc_cat_features = enc.transform(cat_features)\n    ohe = preprocessing.OneHotEncoder()\n    encoded = ohe.fit(enc_cat_features.reshape(-1,1))\n    return encoded.transform(enc_cat_features.reshape(-1,1)).toarray()\n\ncategorical_columns = ['sex']\n\nFeatures = encode_string(ins['region'])\nfor col in categorical_columns:\n    temp = encode_string(ins[col])\n    Features = np.concatenate([Features, temp], axis = 1)\n\nFeatures = np.concatenate([Features, np.array(ins[['bmi', 'charges','children', 'age']])], axis = 1)\nprint(Features.shape)\nprint(Features[:2, :])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nr.seed(1144)\nindx = range(Features.shape[0])\nindx = ms.train_test_split(indx, test_size = 200)\nx_train = Features[indx[0],:]\ny_train = np.ravel(label[indx[0]])\nx_test = Features[indx[1],:]\ny_test = np.ravel(label[indx[1]])\nx_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scaling the numeric values\nscaler = preprocessing.StandardScaler().fit(x_train[:,6:])\nx_train[:,6:] = scaler.transform(x_train[:,6:])\nx_test[:,6:] = scaler.transform(x_test[:,6:])\nx_train[:2]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We now build the non-linear model. Notice that I included a class-weight correction to take into consideration that the number of smokers is much less than nonsmoker"},{"metadata":{"trusted":true},"cell_type":"code","source":"logistic_mod = linear_model.LogisticRegression(fit_intercept = False, class_weight={0:0.8, 1:0.2}) \nlogistic_mod.fit(x_train, y_train)\nprint(logistic_mod.intercept_)\nprint(logistic_mod.coef_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below are the probabilities of smoker category, yes or no, using the logistic function."},{"metadata":{"trusted":true},"cell_type":"code","source":"probabilities = logistic_mod.predict_proba(x_test)\nprint(probabilities[:5,:])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we set a threshold value to turn the above probabilities into binary digits of 1 and 0 to compare with the test values. We chose a threshold of 0.5."},{"metadata":{"trusted":true},"cell_type":"code","source":"def score_model(probs, threshold):\n    return np.array([1 if x > threshold else 0 for x in probs[:,1]])\nscores = score_model(probabilities, 0.5)\nprint(np.array(scores[:100]))\nprint(y_test[:100])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We set up a confusion table to examine our scores:\ndef print_metrics(label, scores):\n    metrics = sklm.precision_recall_fscore_support(label, scores)\n    conf = sklm.confusion_matrix(label, scores)\n    print('                 Confusion matrix')\n    print('                 Score positive    Score negative')\n    print('Actual positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])\n    print('Actual negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])\n    print('')\n    print('Accuracy  %0.2f' % sklm.accuracy_score(label, scores))\n    print(' ')\n    print('           Positive      Negative')\n    print('Num case   %6d' % metrics[3][0] + '          %6d' % metrics[3][1])\n    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])\n    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])\n   \nprint_metrics(y_test, scores) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting the ROC curve\ndef plot_auc(label, probs):\n    fpr, tpr, threshold = sklm.roc_curve(label, probs[:,1])\n    auc = sklm.auc(fpr, tpr)\n        \n    plt.title('Receiver Operating Characteristic')\n    plt.plot(fpr, tpr, color = 'orange', label = 'AUC = %0.2f' % auc)\n    plt.legend(loc = 'lower right')\n    plt.plot([0, 1], [0, 1],'r--')\n    plt.xlim([0, 1])\n    plt.ylim([0, 1])\n    plt.ylabel('True Positive Rate')\n    plt.xlabel('False Positive Rate')\n    plt.show()\n    \nplot_auc(y_test, probabilities)  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The accuracy of the classification model is 94% and of the 200 test values, the model only miss-labeled 13 of them. This is also obvious from the ROC curve with an area of 99%.\nThis seems too good to be true, if it is not for the fact that, as we saw earlier, smoker and nonsmoker values are very much separated. This makes it much easier for the system to predict them correctly.\nNevertheless, the model seems to have missed a big chunk of the smoker category only 66% accurate.\nInterestingly, when I ran the same model but without class_weight, the results were much better, only 5 missed from the non-smoker category and with accuracy of 99%. So, I guess when the two classification labels are very much separated, maybe it is better not to use weight correction.\nThat been said, a new set of data that may have a larger overlapping between the smoker two cases, may not be predicted as well as"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}