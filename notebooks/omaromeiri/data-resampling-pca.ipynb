{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Bank marketing data undersampling\n\nthis dataset was acquired from: <br>\n<br>\n\nhttps://archive.ics.uci.edu/ml/datasets/Bank+Marketing  <br>\n<br>\nThis is the full dataset, which has more features and a lot of class imbalance. <br>\n\nI'll resample the data using PCA, because I want to undersample the majority class as uniformly as possible."},{"metadata":{},"cell_type":"markdown","source":"Attribute Information:\n\nInput variables:\n# bank client data:\n1 - age (numeric)  <br>\n2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')  <br>\n3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)  <br>\n4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')  <br>\n5 - default: has credit in default? (categorical: 'no','yes','unknown')  <br>\n6 - housing: has housing loan? (categorical: 'no','yes','unknown')  <br>\n7 - loan: has personal loan? (categorical: 'no','yes','unknown')  <br>\n# related with the last contact of the current campaign:\n8 - contact: contact communication type (categorical: 'cellular','telephone')  <br> \n9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')  <br>\n10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')  <br>\n11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n# other attributes:\n12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)  <br>\n13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)  <br>\n14 - previous: number of contacts performed before this campaign and for this client (numeric)  <br>\n15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')  <br>\n# social and economic context attributes\n16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)  <br>\n17 - cons.price.idx: consumer price index - monthly indicator (numeric)   <br>\n18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)   <br>\n19 - euribor3m: euribor 3 month rate - daily indicator (numeric)  <br>\n20 - nr.employed: number of employees - quarterly indicator (numeric)  <br>\n\n# Output variable (desired target):  <br>\n21 - y - has the client subscribed a term deposit? (binary: 'yes','no')"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nimport math\n\npd.options.display.max_columns = None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/bank-additional-full.csv', delimiter=';')\ndata.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nRenaming columns just for better understanding\n'''\n\ndata.rename(columns={'housing':'housing_loan'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nThe column duration is not supposed to be used, since we only know the call duration\nafter it has been finished, so it is considered data leakage\n'''\n\ndata.drop(['duration'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"catg_cols = ['job', 'marital', 'education', 'default', 'housing_loan',\n             'loan', 'contact', 'month', 'day_of_week', 'campaign', 'pdays', 'previous',\n             'poutcome']\n\n\nnum_cols = ['age', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx',\n            'euribor3m', 'nr.employed']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nI just want to see how many of each feature there is in each column\n\n'''\n\n\nunique_df = pd.DataFrame()\n\nindex=0\nfor column in catg_cols:\n    \n    unique_df = pd.concat([unique_df,pd.DataFrame(data[column].value_counts()).reset_index()], axis=1)\n    unique_df[index] = '........'\n    index+=1\n\nunique_df.fillna('')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Some of these sparse categorical columns like \"'campaign', 'pdays' and 'previous'\" are going to be grouped"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_bar(col, size=(15,8), hue=True):\n    fig, ax = plt.subplots()\n    sns.set_style(\"whitegrid\")\n    if hue:\n        sns.countplot(col, hue='y', data=data)\n    else:\n        sns.countplot(col, data=data)\n        \n    fig.set_size_inches(size)\n    plt.xlabel(col) # Set text for the x axis\n    plt.ylabel('Count')# Set text for y axis\n    plt.show()\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Target balance"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_bar('y', hue=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Very imbalanced data, we'll need to think of undersampling strategies"},{"metadata":{},"cell_type":"markdown","source":"### Campaign"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_bar('campaign')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nI'm gonna group more than 5 contacts all into one category\n'''\n\ndata['campaign'] = data['campaign'].apply(lambda x: x if x<5 else 5) # More than 5 contacts are grouped","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_bar('campaign')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Pdays"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_bar('pdays')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data[data['pdays']!=999]['pdays'], hue=data['y'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nGoing to group them into 3 categories\n\n1 = equal or less than 10 days\n\n2 = more than 10 days\n\n0 = not contacted before\n\n'''\n\n\ndef treat_pdays(value):\n    \n    if value <= 10:\n        return 1\n    if value > 10 and value <= 27:\n        return 2\n    if value > 27:\n        return 0\n\ndata['pdays'] = data['pdays'].apply(treat_pdays)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_bar('pdays')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Previous"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_bar('previous')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nGoing to group them into 3 categories\n\n1 = contacted once before\n\n2 = contacted more than once before\n\n0 = not contacted before\n\n'''\n\n\ndef treat_previous(value):\n    \n    if value == 0:\n        return 0\n    if value == 1:\n        return 1\n    else:\n        return 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['previous'] = data['previous'].apply(treat_previous)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_bar('previous')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Job"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_bar('job')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nMerging housemaid into serices\n'''\n\ndata['job'] = data['job'].replace('housemaid', 'services')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_bar('job')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Resampling Data\n\nI'll try to resample data using PCA, the data is too inbalanced. <br>\nI want to resample the majority class as uniformly as possible. <br>\nSo, a good approach might be clustering the PCA components and taking equal samples from each cluster."},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nGetting dummies for the categorical columns\n'''\n\n\ndummy_features = pd.get_dummies(data[catg_cols])\n\nnum_features = data[num_cols]\n\nprint(dummy_features.shape)\nprint(num_features.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nScaling the numerical variables\n\n'''\n\nscaler = StandardScaler()\n\nnum_features = pd.DataFrame(scaler.fit_transform(num_features), columns=num_features.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nConcatenating the scaled numerical columns with\nthe dummy columns\n'''\n\n\npreprocessed_df = pd.concat([dummy_features, num_features], axis=1)\npreprocessed_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nBinarizing 'yes' and 'no'\nvalues in the labels\n'''\n\nlabels = data['y'].map({'no':0, 'yes':1})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components=2)\npcs = pca.fit_transform(preprocessed_df)\n\npcs_df = pd.DataFrame(pcs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_2d(X, y, label='Classes'):   \n \n    for l in zip(np.unique(y)):\n        plt.scatter(X[y==l, 0], X[y==l, 1], label=l)\n    plt.title(label)\n    plt.legend(loc='upper right')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_2d(pcs, labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now clustering the PCA components"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nManually setting initial cluster centers\nfor improved accuracy\n'''\nn_clusters = 15 # 15 clusters from visual inspection above\n\ncluster_centers = np.array([[-1.5,-1.5], [-1.6,-0.5], [-1.7,0.5], [-1.9,1.5], [-2,2.5],\n                            [0.5,-1], [0,0], [0,1], [-0.2,2], [-0.5, 2.8],\n                            [3,-1], [3,0], [2.5,1.1], [2.5,2], [2.5,3.2]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans = KMeans(n_clusters=n_clusters, max_iter=10000, verbose=1, n_jobs=4, init=cluster_centers)\n\nclusters = kmeans.fit_predict(pcs_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pcs_df['cluster'] = clusters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nWe can see that the clustering is acceptable\n'''\n\n\nplt.scatter(pcs_df[0], pcs_df[1], c=pcs_df['cluster'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nI'll extract 309 samples from each cluster\n'''\n\nn_samples = labels.value_counts()[1]//15\nn_samples","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nI'll select 309 random points from each cluster\nBut im only sampling the majority or label == 0\n\n'''\n\n\nindex_list = []\n\nfor i in range(0,n_clusters):\n    \n    choices = pcs_df[(labels==0) & (pcs_df['cluster'] == i)].index\n    \n   \n    \n    index_list.append(np.random.choice(choices, n_samples))\n\n    \nindex_list = np.ravel(index_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nCreating a new Dataframe with all the samples from the index_list which are all from the majority class\nand all the samples from the minority class\n'''\n\nresampled_raw_data = pd.concat([data.iloc[index_list], data[data['y'] == 'yes']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nConfirming concatenation\n'''\n\nresampled_raw_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nConfirming class imbalance\n'''\n\nresampled_raw_data['y'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nSaving resampled Dataframe for future classification task\n'''\n\n\nresampled_raw_data.to_csv('resampled_bank_data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":1}