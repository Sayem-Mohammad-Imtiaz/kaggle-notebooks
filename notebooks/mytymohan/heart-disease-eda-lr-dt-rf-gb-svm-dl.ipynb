{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"![](https://resources.healthydirections.com/resources/web/articles/hd/hd-women-and-heart-disease-sinatra-rollup-hd-cover.jpg)"},{"metadata":{},"cell_type":"markdown","source":"[](https://www.kaggle.com/ronitf/heart-disease-uci)"},{"metadata":{},"cell_type":"markdown","source":"**Note:**   \nKindly upvote the kernel if you find it useful. Suggestions are always welome. Let me know your thoughts in the comment if any.\n\nExperimenting with different models are the original work of Susan Li and I want to try her work on the new dataset and see how the results vary & learn things from it.\n\nLink of the original modelling work:    \n[Susan Li Work](https://towardsdatascience.com/machine-learning-for-diabetes-562dd7df4d42)"},{"metadata":{},"cell_type":"markdown","source":"**Context**  \nThis database contains 76 attributes, but all published experiments refer to using a subset of 14 of them. In particular, the Cleveland database is the only one that has been used by ML researchers to this date. The \"goal\" field refers to the presence of heart disease in the patient. It is integer valued from 0 (no presence) to 4.\n\n**Attribute Information:**   \n1. Age   \n2. Sex   \n3. Chest pain type (4 values)  \n4. Resting blood pressure  \n5. Serum cholestoral in mg/dl  \n6. Fasting blood sugar > 120 mg/dl \n7. Resting electrocardiographic results (values 0,1,2) \n8. Maximum heart rate achieved  \n9. Exercise induced angina  \n10. Oldpeak = ST depression induced by exercise relative to rest  \n11. The slope of the peak exercise ST segment  \n12. Number of major vessels (0-3) colored by flourosopy  \n13. Thal: 3 = normal; 6 = fixed defect; 7 = reversable defect   \n\nThe names and social security numbers of the patients were recently removed from the database, replaced with dummy values. One file has been \"processed\", that one containing the Cleveland database. All four unprocessed files also exist in this directory.\n\n**Acknowledgements - Creators: **  \n* Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.   \n* University Hospital, Zurich, Switzerland: William Steinbrunn, M.D.   \n* University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.   \n* V.A. Medical Center, Long Beach and Cleveland Clinic Foundation: Robert Detrano, M.D., Ph.D.  \n\nDonor: David W. Aha (aha '@' ics.uci.edu) (714) 856-8779  \n\n**Inspiration**  \nExperiments with the Cleveland database have concentrated on simply attempting to distinguish presence (values 1,2,3,4) from absence (value 0)."},{"metadata":{},"cell_type":"markdown","source":"**Global Options**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Listing the files**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"!ls ../input/","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Reading the Dataset**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import pandas as pd\nht_dt = pd.read_csv(\"../input/heart.csv\", header = 'infer')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Viewing the shape of the dataset**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print(\"The heart dataset has {0} rows and {1} columns\".format(ht_dt.shape[0], ht_dt.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Sample of the dataset**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"ht_dt.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Target Proportion in the Dataset**"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.countplot(ht_dt['target'],label=\"Count\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Missing value details**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#Function to calculate missing value\ndef missing_values_table(df):\n        # Total missing values\n        mis_val = df.isnull().sum()\n        \n        # Percentage of missing values\n        mis_val_percent = 100 * df.isnull().sum() / len(df)\n        \n        # Make a table with the results\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        \n        # Rename the columns\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        \n        # Sort the table by percentage of missing descending\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n        \n        # Print some summary information\n        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n              \" columns that have missing values.\")\n        \n        # Return the dataframe with missing information\n        return mis_val_table_ren_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"missing_values_table(ht_dt)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Visualizing the missing value**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#Missing values with respect to each column in the dataset\nimport seaborn as sns\nsns.heatmap(ht_dt.isnull(), cbar=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The dataset has no missing values in it. Hence, the plot is in one color."},{"metadata":{},"cell_type":"markdown","source":"**Correlation between the Features**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#correlation matrix\nimport matplotlib.pyplot as plt\n%matplotlib inline\nht_dt_ft = ht_dt.drop('target', axis=1)\nfig=plt.gcf()\nfig.set_size_inches(15,7)\nfig=sns.heatmap(ht_dt_ft.corr(),annot=True,cmap='cubehelix',linewidths=1,linecolor='k',\n                square=True,mask=False, vmin=-1, vmax=1,cbar_kws={\"orientation\": \"vertical\"},cbar=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Correaltion co-efficient Plot**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from scipy.stats import spearmanr\nimport numpy as np\nlabels = []\nvalues = []\nfor col in ht_dt.columns:\n    if col not in [\"target\"]:\n        labels.append(col)\n        values.append(spearmanr(ht_dt[col].values, ht_dt[\"target\"].values)[0])\ncorr_df = pd.DataFrame({'col_labels':labels, 'corr_values':values})\ncorr_df = corr_df.sort_values(by='corr_values')\n \nind = np.arange(corr_df.shape[0])\nwidth = 0.9\nfig, ax = plt.subplots(figsize=(12,30))\nrects = ax.barh(ind, np.array(corr_df.corr_values.values), color='g')\nax.set_yticks(ind)\nax.set_yticklabels(corr_df.col_labels.values, rotation='horizontal')\nax.set_xlabel(\"Correlation coefficient\")\nax.set_title(\"Correlation coefficient of the variables\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Pearson correlation coefficient, r, can take a range of values from +1 to -1. A value of 0 indicates that there is no association between the two variables. A value greater than 0 indicates a positive association; that is, as the value of one variable increases, so does the value of the other variable.\n\nHere, we can see the maximum correlation value is approximately lies between -.5 and .5 which means none of the variables have strong correlation."},{"metadata":{},"cell_type":"markdown","source":"**Bi-variate analysis with respect to Target variable**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#scatterplot - set 1\nset1 = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'target']\nset1_dt = ht_dt[set1]\nsns.pairplot(set1_dt, hue=\"target\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#scatterplot - set 2\nset2 = ['thalach','exang', 'oldpeak', 'slope', 'ca', 'thal', 'target']\nset2_dt = ht_dt[set2]\nsns.pairplot(set2_dt, hue=\"target\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Age Vs Target**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"cm_surv = [\"darkgrey\" , \"lightgreen\"]\nage_uniq = ht_dt.age.nunique()\nprint(\"Number of unique values in age is {}\".format(age_uniq))\nsns.catplot(x=\"sex\", y=\"age\", hue=\"target\", inner=\"quart\", kind=\"violin\", palette=cm_surv, split=True, data=ht_dt)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Trestbps Vs Target**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"trestbps_uniq = ht_dt.trestbps.nunique()\nprint(\"Number of unique values in trestbps is {}\".format(trestbps_uniq))\nsns.catplot(x=\"sex\", y=\"trestbps\", hue=\"target\", kind=\"violin\", inner=\"quart\", palette=cm_surv, split=True, data=ht_dt)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Thalach Vs Target**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"thalach_uniq = ht_dt.thalach.nunique()\nprint(\"Number of unique values in thalach is {}\".format(thalach_uniq))\nsns.catplot(x=\"sex\", y=\"thalach\", hue=\"target\", inner=\"quart\", kind=\"violin\", palette=cm_surv, split=True, data=ht_dt)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Chol Vs Target**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"chol_uniq = ht_dt.chol.nunique()\nprint(\"Number of unique values in chol is {}\".format(chol_uniq))\nsns.catplot(x=\"sex\", y=\"chol\", hue=\"target\", inner=\"quart\", kind=\"violin\", palette=cm_surv, split=True, data=ht_dt)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Oldpeak Vs Target**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"oldpeak_uniq = ht_dt.oldpeak.nunique()\nprint(\"Number of unique values in oldpeak is {}\".format(oldpeak_uniq))\nsns.catplot(x=\"sex\", y=\"oldpeak\", hue=\"target\", kind=\"violin\", inner=\"quart\", palette=cm_surv, split=True, data=ht_dt)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Sex Vs Target**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from pandasql import sqldf\npysqldf = lambda q: sqldf(q, globals())\n\nsex_q = \"\"\"\nselect sex, target, count(*) as cnt\nFrom ht_dt\nGROUP BY sex, target;\n\"\"\"\n\nsex_df = pysqldf(sex_q)\n\nsex_df_0 = sex_df[sex_df.target == 0]\nsex_df_1 = sex_df[sex_df.target == 1]\n\nimport plotly.plotly as py\nimport plotly.graph_objs as go\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\n\nfig = {\n  \"data\": [\n    {\n      \"values\": sex_df_0.cnt,\n      \"labels\": sex_df_0.sex,\n      \"domain\": {\"x\": [0, .48]},\n      \"name\": \"No Heart Disease\",\n      \"hoverinfo\":\"label+percent+name\",\n      \"hole\": .4,\n      \"type\": \"pie\"\n    },     \n    {\n      \"values\": sex_df_1.cnt,\n      \"labels\": sex_df_1.sex,\n      \"domain\": {\"x\": [.52, 1]},\n      \"name\": \"With Heart Disease\",\n      \"hoverinfo\":\"label+percent+name\",\n      \"hole\": .4,\n      \"type\": \"pie\"\n    }],\n  \"layout\": {\n        \"title\":\"Sex Vs Target\",\n        \"annotations\": [\n            {\n                \"font\": {\n                    \"size\": 15\n                },\n                \"showarrow\": False,\n                \"text\": \"No Disease\",\n                \"x\": 0.16,\n                \"y\": 0.5\n            },\n            {\n                \"font\": {\n                    \"size\": 15\n                },\n                \"showarrow\": False,\n                \"text\": \"With Disease\",\n                \"x\": 0.85,\n                \"y\": 0.5\n            }\n        ]\n    }\n}\n\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Cp Vs Target**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"cp_q = \"\"\"\nselect cp, target, count(*) as cnt\nFrom ht_dt\nGROUP BY cp, target;\n\"\"\"\n\ncp_df = pysqldf(cp_q)\n\ncp_df_0 = cp_df[cp_df.target == 0]\ncp_df_1 = cp_df[cp_df.target == 1]\n\nfig = {\n  \"data\": [\n    {\n      \"values\": cp_df_0.cnt,\n      \"labels\": cp_df_0.cp,\n      \"domain\": {\"x\": [0, .48]},\n      \"name\": \"No Heart Disease\",\n      \"hoverinfo\":\"label+percent+name\",\n      \"hole\": .4,\n      \"type\": \"pie\"\n    },     \n    {\n      \"values\": cp_df_1.cnt,\n      \"labels\": cp_df_1.cp,\n      \"domain\": {\"x\": [.52, 1]},\n      \"name\": \"With Heart Disease\",\n      \"hoverinfo\":\"label+percent+name\",\n      \"hole\": .4,\n      \"type\": \"pie\"\n    }],\n  \"layout\": {\n        \"title\":\"cp Vs Target\",\n        \"annotations\": [\n            {\n                \"font\": {\n                    \"size\": 15\n                },\n                \"showarrow\": False,\n                \"text\": \"No Disease\",\n                \"x\": 0.17,\n                \"y\": 0.5\n            },\n            {\n                \"font\": {\n                    \"size\": 15\n                },\n                \"showarrow\": False,\n                \"text\": \"With Disease\",\n                \"x\": 0.85,\n                \"y\": 0.5\n            }\n        ]\n    }\n}\n\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Fbs Vs Target**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fbs_q = \"\"\"\nselect fbs, target, count(*) as cnt\nFrom ht_dt\nGROUP BY fbs, target;\n\"\"\"\n\nfbs_df = pysqldf(fbs_q)\n\nfbs_df_0 = fbs_df[fbs_df.target == 0]\nfbs_df_1 = fbs_df[fbs_df.target == 1]\n\nfig = {\n  \"data\": [\n    {\n      \"values\": fbs_df_0.cnt,\n      \"labels\": fbs_df_0.fbs,\n      \"domain\": {\"x\": [0, .48]},\n      \"name\": \"No Heart Disease\",\n      \"hoverinfo\":\"label+percent+name\",\n      \"hole\": .4,\n      \"type\": \"pie\"\n    },     \n    {\n      \"values\": fbs_df_1.cnt,\n      \"labels\": fbs_df_1.fbs,\n      \"domain\": {\"x\": [.52, 1]},\n      \"name\": \"With Heart Disease\",\n      \"hoverinfo\":\"label+percent+name\",\n      \"hole\": .4,\n      \"type\": \"pie\"\n    }],\n  \"layout\": {\n        \"title\":\"Fbs Vs Target\",\n        \"annotations\": [\n            {\n                \"font\": {\n                    \"size\": 15\n                },\n                \"showarrow\": False,\n                \"text\": \"No Disease\",\n                \"x\": 0.17,\n                \"y\": 0.5\n            },\n            {\n                \"font\": {\n                    \"size\": 15\n                },\n                \"showarrow\": False,\n                \"text\": \"With Disease\",\n                \"x\": 0.85,\n                \"y\": 0.5\n            }\n        ]\n    }\n}\n\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**restecg Vs Target**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"restecg_q = \"\"\"\nselect restecg, target, count(*) as cnt\nFrom ht_dt\nGROUP BY restecg, target;\n\"\"\"\n\nrestecg_df = pysqldf(restecg_q)\n\nrestecg_df_0 = restecg_df[restecg_df.target == 0]\nrestecg_df_1 = restecg_df[restecg_df.target == 1]\n\nfig = {\n  \"data\": [\n    {\n      \"values\": restecg_df_0.cnt,\n      \"labels\": restecg_df_0.restecg,\n      \"domain\": {\"x\": [0, .48]},\n      \"name\": \"No Heart Disease\",\n      \"hoverinfo\":\"label+percent+name\",\n      \"hole\": .4,\n      \"type\": \"pie\"\n    },     \n    {\n      \"values\": restecg_df_1.cnt,\n      \"labels\": restecg_df_1.restecg,\n      \"domain\": {\"x\": [.52, 1]},\n      \"name\": \"With Heart Disease\",\n      \"hoverinfo\":\"label+percent+name\",\n      \"hole\": .4,\n      \"type\": \"pie\"\n    }],\n  \"layout\": {\n        \"title\":\"restecg Vs Target\",\n        \"annotations\": [\n            {\n                \"font\": {\n                    \"size\": 15\n                },\n                \"showarrow\": False,\n                \"text\": \"No Disease\",\n                \"x\": 0.17,\n                \"y\": 0.5\n            },\n            {\n                \"font\": {\n                    \"size\": 15\n                },\n                \"showarrow\": False,\n                \"text\": \"With Disease\",\n                \"x\": 0.85,\n                \"y\": 0.5\n            }\n        ]\n    }\n}\n\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**exang Vs Target**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"exang_q = \"\"\"\nselect exang, target, count(*) as cnt\nFrom ht_dt\nGROUP BY exang, target;\n\"\"\"\n\nexang_df = pysqldf(exang_q)\n\nexang_df_0 = exang_df[exang_df.target == 0]\nexang_df_1 = exang_df[exang_df.target == 1]\n\nfig = {\n  \"data\": [\n    {\n      \"values\": exang_df_0.cnt,\n      \"labels\": exang_df_0.exang,\n      \"domain\": {\"x\": [0, .48]},\n      \"name\": \"No Heart Disease\",\n      \"hoverinfo\":\"label+percent+name\",\n      \"hole\": .4,\n      \"type\": \"pie\"\n    },     \n    {\n      \"values\": exang_df_1.cnt,\n      \"labels\": exang_df_1.exang,\n      \"domain\": {\"x\": [.52, 1]},\n      \"name\": \"With Heart Disease\",\n      \"hoverinfo\":\"label+percent+name\",\n      \"hole\": .4,\n      \"type\": \"pie\"\n    }],\n  \"layout\": {\n        \"title\":\"exang Vs Target\",\n        \"annotations\": [\n            {\n                \"font\": {\n                    \"size\": 15\n                },\n                \"showarrow\": False,\n                \"text\": \"No Disease\",\n                \"x\": 0.17,\n                \"y\": 0.5\n            },\n            {\n                \"font\": {\n                    \"size\": 15\n                },\n                \"showarrow\": False,\n                \"text\": \"With Disease\",\n                \"x\": 0.85,\n                \"y\": 0.5\n            }\n        ]\n    }\n}\n\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Slope Vs Target**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"sl_q = \"\"\"\nselect slope, target, count(*) as cnt\nFrom ht_dt\nGROUP BY slope, target;\n\"\"\"\n\nsl_df = pysqldf(sl_q)\n\nsl_df_0 = sl_df[sl_df.target == 0]\nsl_df_1 = sl_df[sl_df.target == 1]\n\nfig = {\n  \"data\": [\n    {\n      \"values\": sl_df_0.cnt,\n      \"labels\": sl_df_0.slope,\n      \"domain\": {\"x\": [0, .48]},\n      \"name\": \"No Heart Disease\",\n      \"hoverinfo\":\"label+percent+name\",\n      \"hole\": .4,\n      \"type\": \"pie\"\n    },     \n    {\n      \"values\": sl_df_1.cnt,\n      \"labels\": sl_df_1.slope,\n      \"domain\": {\"x\": [.52, 1]},\n      \"name\": \"With Heart Disease\",\n      \"hoverinfo\":\"label+percent+name\",\n      \"hole\": .4,\n      \"type\": \"pie\"\n    }],\n  \"layout\": {\n        \"title\":\"Slope Vs Target\",\n        \"annotations\": [\n            {\n                \"font\": {\n                    \"size\": 15\n                },\n                \"showarrow\": False,\n                \"text\": \"No Disease\",\n                \"x\": 0.17,\n                \"y\": 0.5\n            },\n            {\n                \"font\": {\n                    \"size\": 15\n                },\n                \"showarrow\": False,\n                \"text\": \"With Disease\",\n                \"x\": 0.85,\n                \"y\": 0.5\n            }\n        ]\n    }\n}\n\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**ca Vs Target**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"ca_q = \"\"\"\nselect ca, target, count(*) as cnt\nFrom ht_dt\nGROUP BY ca, target;\n\"\"\"\n\nca_df = pysqldf(ca_q)\n\nca_df_0 = ca_df[ca_df.target == 0]\nca_df_1 = ca_df[ca_df.target == 1]\n\nfig = {\n  \"data\": [\n    {\n      \"values\": ca_df_0.cnt,\n      \"labels\": ca_df_0.ca,\n      \"domain\": {\"x\": [0, .48]},\n      \"name\": \"No Heart Disease\",\n      \"hoverinfo\":\"label+percent+name\",\n      \"hole\": .4,\n      \"type\": \"pie\"\n    },     \n    {\n      \"values\": ca_df_1.cnt,\n      \"labels\": ca_df_1.ca,\n      \"domain\": {\"x\": [.52, 1]},\n      \"name\": \"With Heart Disease\",\n      \"hoverinfo\":\"label+percent+name\",\n      \"hole\": .4,\n      \"type\": \"pie\"\n    }],\n  \"layout\": {\n        \"title\":\"Ca Vs Target\",\n        \"annotations\": [\n            {\n                \"font\": {\n                    \"size\": 15\n                },\n                \"showarrow\": False,\n                \"text\": \"No Disease\",\n                \"x\": 0.17,\n                \"y\": 0.5\n            },\n            {\n                \"font\": {\n                    \"size\": 15\n                },\n                \"showarrow\": False,\n                \"text\": \"With Disease\",\n                \"x\": 0.85,\n                \"y\": 0.5\n            }\n        ]\n    }\n}\n\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**thal Vs Target**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"thal_q = \"\"\"\nselect thal, target, count(*) as cnt\nFrom ht_dt\nGROUP BY thal, target;\n\"\"\"\n\nthal_df = pysqldf(thal_q)\n\nthal_df_0 = thal_df[thal_df.target == 0]\nthal_df_1 = thal_df[thal_df.target == 1]\n\nfig = {\n  \"data\": [\n    {\n      \"values\": thal_df_0.cnt,\n      \"labels\": thal_df_0.thal,\n      \"domain\": {\"x\": [0, .48]},\n      \"name\": \"No Heart Disease\",\n      \"hoverinfo\":\"label+percent+name\",\n      \"hole\": .4,\n      \"type\": \"pie\"\n    },     \n    {\n      \"values\": thal_df_1.cnt,\n      \"labels\": thal_df_1.thal,\n      \"domain\": {\"x\": [.52, 1]},\n      \"name\": \"With Heart Disease\",\n      \"hoverinfo\":\"label+percent+name\",\n      \"hole\": .4,\n      \"type\": \"pie\"\n    }],\n  \"layout\": {\n        \"title\":\"thal Vs Target\",\n        \"annotations\": [\n            {\n                \"font\": {\n                    \"size\": 15\n                },\n                \"showarrow\": False,\n                \"text\": \"No Disease\",\n                \"x\": 0.17,\n                \"y\": 0.5\n            },\n            {\n                \"font\": {\n                    \"size\": 15\n                },\n                \"showarrow\": False,\n                \"text\": \"With Disease\",\n                \"x\": 0.85,\n                \"y\": 0.5\n            }\n        ]\n    }\n}\n\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Training & Testing Dataset**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(ht_dt.loc[:, ht_dt.columns != 'target'], \n                                                    ht_dt['target'], stratify=ht_dt['target'], \n                                                    random_state=66)\n\nprint(\"Training features have {0} records and Testing features have {1} records.\".\\\n      format(X_train.shape[0], X_test.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Logistic regression**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression().fit(X_train, y_train)\nprint(\"Training set score: {:.3f}\".format(logreg.score(X_train, y_train)))\nprint(\"Test set score: {:.3f}\".format(logreg.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Decision Tree**"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ntree = DecisionTreeClassifier(random_state=0)\ntree.fit(X_train, y_train)\nprint(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(tree.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The accuracy on the training set is 100%, while the test set accuracy is much worse. This is an indicative that the tree is overfitting and not generalizing well to new data. Therefore, we need to apply pre-pruning to the tree.\n\nWe set max_depth=3, limiting the depth of the tree decreases overfitting. This leads to a lower accuracy on the training set, but an improvement on the test set."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"tree = DecisionTreeClassifier(max_depth=3, random_state=0)\ntree.fit(X_train, y_train)\nprint(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(tree.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Feature Importance in Decision Trees**"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(\"Feature importances:\\n{}\".format(tree.feature_importances_))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dis_ft = [x for i,x in enumerate(ht_dt.columns) if i!=8]\ndef plot_feature_importances_diabetes(model):\n    plt.figure(figsize=(8,6))\n    n_features = 13\n    plt.barh(range(n_features), model.feature_importances_, align='center')\n    plt.yticks(np.arange(n_features), dis_ft)\n    plt.xlabel(\"Feature importance\")\n    plt.ylabel(\"Feature\")\n    plt.ylim(-1, n_features)\nplot_feature_importances_diabetes(tree)\nplt.savefig('feature_importance')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Random Forest**"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#Random forest with 100 trees\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=100, random_state=0)\nrf.fit(X_train, y_train)\nprint(\"Accuracy on training set: {:.3f}\".format(rf.score(X_train, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(rf.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random forest gives better accuracy with respect to Test accuracy when compared to Decision trees. Now, let us prune the depth of trees and check the accuracy."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"rf1 = RandomForestClassifier(max_depth=3, n_estimators=100, random_state=0)\nrf1.fit(X_train, y_train)\nprint(\"Accuracy on training set: {:.3f}\".format(rf1.score(X_train, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(rf1.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Feature importance in Random Forest**"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plot_feature_importances_diabetes(rf1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Gradient Boosting**"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\ngb = GradientBoostingClassifier(random_state=0)\ngb.fit(X_train, y_train)\nprint(\"Accuracy on training set: {:.3f}\".format(gb.score(X_train, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(gb.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#GB after pruning\ngb1 = GradientBoostingClassifier(random_state=0, max_depth=1)\ngb1.fit(X_train, y_train)\nprint(\"****Gradient Boosting after Pruning using Max_depth****\")\nprint(\"Accuracy on training set: {:.3f}\".format(gb1.score(X_train, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(gb1.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#GB after tuning learning rate\ngb2 = GradientBoostingClassifier(random_state=0, learning_rate=0.01)\ngb2.fit(X_train, y_train)\nprint(\"****Gradient Boosting after tuning Learning rate****\")\nprint(\"Accuracy on training set: {:.3f}\".format(gb2.score(X_train, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(gb2.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Feature Importance using GB**"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plot_feature_importances_diabetes(gb2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Support Vector Machine**"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvc = SVC()\nsvc.fit(X_train, y_train)\nprint(\"Accuracy on training set: {:.2f}\".format(svc.score(X_train, y_train)))\nprint(\"Accuracy on test set: {:.2f}\".format(svc.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The model overfits quite substantially, with a perfect score on the training set and only 54% accuracy on the test set.\n\nSVM requires all the features to vary on a similar scale. We will need to re-scale our data that all the features are approximately on the same scale."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.fit_transform(X_test)\nsvc = SVC()\nsvc.fit(X_train_scaled, y_train)\nprint(\"****Results after scaling****\")\nprint(\"Accuracy on training set: {:.2f}\".format(svc.score(X_train_scaled, y_train)))\nprint(\"Accuracy on test set: {:.2f}\".format(svc.score(X_test_scaled, y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Deep Learning**"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\nmlp = MLPClassifier(random_state=42)\nmlp.fit(X_train, y_train)\nprint(\"Accuracy on training set: {:.2f}\".format(mlp.score(X_train, y_train)))\nprint(\"Accuracy on test set: {:.2f}\".format(mlp.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The accuracy of the Multilayer perceptrons (MLP) is not as good as the other models at all, this is likely due to scaling of the data. deep learning algorithms also expect all input features to vary in a similar way, and ideally to have a mean of 0, and a variance of 1. We must re-scale our data so that it fulfills these requirements."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.fit_transform(X_test)\nmlp = MLPClassifier(random_state=0)\nmlp.fit(X_train_scaled, y_train)\nprint(\"****Results after scaling****\")\nprint(\"Accuracy on training set: {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#Tuning the iteration\nmlp = MLPClassifier(max_iter=1000, random_state=0)\nmlp.fit(X_train_scaled, y_train)\nprint(\"****Results after tuning iteration****\")\nprint(\"Accuracy on training set: {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Increasing the number of iterations only increased the training set performance, not the test set performance.\n\nLet’s increase the alpha parameter and add stronger regularization of the weights."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"mlp = MLPClassifier(max_iter=100, alpha=1, random_state=0)\nmlp.fit(X_train_scaled, y_train)\nprint(\"****Results after tuning alpha & regularizing the weights****\")\nprint(\"Accuracy on training set: {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plotting the first layer weights in a Neural Network**"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 5))\nplt.imshow(mlp.coefs_[0], interpolation='none', cmap='viridis')\nplt.yticks(range(13), dis_ft)\nplt.xlabel(\"Columns in weight matrix\")\nplt.ylabel(\"Input feature\")\nplt.colorbar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Stay Tuned....**"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}