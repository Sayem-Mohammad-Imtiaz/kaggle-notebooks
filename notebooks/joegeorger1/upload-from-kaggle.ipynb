{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To read a file into a Kaggle worksheet, you need to use the pd.read_csv() function. In this case, a file was brought in from the Kaggle database. Kaggle's database is a great resource, with thousands of data sets ready to use. The only draw backs are that the data is not yours and there is not always a record of where the data came from. The data not being yours is usually not a problem, but can become a problem when the owner changes or deletes the dataset. That would obviously mess up your project. A way to get around that is downloading or saving the dataset locally on your computer. That way you own that dataset. The other problem is that we don't know where the data in the database comes from. There aren't always reliable records of the data's orgin. The data could be made up. This creates a weird situation where sometimes it is necessary to reseach your data before using it. Once you select your data set, the pd.read_csv() function with the file path in the parentheses will allow you to use the data in your code.","metadata":{}},{"cell_type":"code","source":"ratings = pd.read_csv('../input/ramen-ratings/ramen-ratings.csv')\nratings","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}