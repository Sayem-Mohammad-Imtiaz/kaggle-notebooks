{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"7d3edd5f-2d2e-b719-dc65-5784e59a2d25"},"source":"Here I develop an algorithm to  classify tweet sentiment using a Naive Bayes approach. The goal is for the algorithm to classify accurately whether the sentiment of tweets sent by U.S. airline travelers is positive or negative in tone. A positive tweet, for example, would be something like \"That was the best flight ever! I love United Airlines\", while a negative tweet would be \"That flight was awful, and we were delayed for five hours\".\n\nLet's load the appropriate Python libraries, read in the tweet data, and grab only the sentiment and tweet text columns."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e72c8022-9ac2-7a9a-e11f-29014426ce70"},"outputs":[],"source":"from sklearn.model_selection import train_test_split\nfrom stop_words import get_stop_words\nimport matplotlib.pyplot as plt\nfrom __future__ import division\nfrom collections import Counter\nimport pandas as pd\nimport numpy as np\nimport string\nimport re\n\n# Read in tweet data\ntweets_data_path = '../input/Tweets.csv'\n\ntweets = pd.read_csv(tweets_data_path, header=0)\n\ndf = tweets.copy()[['airline_sentiment', 'text']]"},{"cell_type":"markdown","metadata":{"_cell_guid":"4f7d383a-418d-e1a4-fc3e-8a8f66fd0163"},"source":"Define the number of classes and the number of tweets per class that you want to use. Let's do a binary classification where tweets are only labeled \"positive\" or \"negative\". Then we can define two function to clean the tweets (e.g., remove special characters, and make words lower case) and remove stop words from the tweet text. Stop words are words that really don't convey any sentiment; words like \"who\", \"and\", \"the\", etc."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ed780605-73f9-7494-056e-b9e4eb604f50"},"outputs":[],"source":"# Define number of classes and number of tweets per class\nn_class = 2\nn_tweet = 2363\n\n# Divide into number of classes\nif n_class == 2:\n    df_pos = df.copy()[df.airline_sentiment == 'positive'][:n_tweet]\n    df_neg = df.copy()[df.airline_sentiment == 'negative'][:n_tweet]\n    df_neu = pd.DataFrame()\n    df = pd.concat([df_pos, df_neg], ignore_index=True).reset_index(drop=True)\nelif n_class == 3:\n    df_pos = df.copy()[df.airline_sentiment == 'positive'][:n_tweet]\n    df_neg = df.copy()[df.airline_sentiment == 'negative'][:n_tweet]\n    df_neu = df.copy()[df.airline_sentiment == 'neutral'][:n_tweet]\n    df = pd.concat([df_pos, df_neg, df_neu], ignore_index=True).reset_index(drop=True)\n\n# Define functions to process Tweet text and remove stop words\ndef ProTweets(tweet):\n    tweet = ''.join(c for c in tweet if c not in string.punctuation)\n    tweet = re.sub('((www\\S+)|(http\\S+))', 'urlsite', tweet)\n    tweet = re.sub(r'\\d+', 'contnum', tweet)\n    tweet = re.sub(' +',' ', tweet)\n    tweet = tweet.lower().strip()\n    return tweet\n\ndef rmStopWords(tweet, stop_words):\n    text = tweet.split()\n    text = ' '.join(word for word in text if word not in stop_words)\n    return text"},{"cell_type":"markdown","metadata":{"_cell_guid":"cbf5f869-141d-8d2e-e9f0-0bcfeff2dc42"},"source":"Let's read in a list of stop words and process each line of tweets in the dataframe using the function we've defined above."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d0371825-ee52-a43f-3e3b-898e6766efcd"},"outputs":[],"source":"# Get list of stop words\nstop_words = get_stop_words('english')\nstop_words = [''.join(c for c in s if c not in string.punctuation) for s in stop_words]\nstop_words = [t.encode('utf-8') for t in stop_words]\n\n# Preprocess all tweet data\npro_tweets = []\nfor tweet in df['text']:\n    processed = ProTweets(tweet)\n    pro_stopw = rmStopWords(processed, stop_words)\n    pro_tweets.append(pro_stopw)\n\ndf['text'] = pro_tweets"},{"cell_type":"markdown","metadata":{"_cell_guid":"ef7e2fe5-02c0-5c00-a7da-e3b3046ea8cf"},"source":"We can now use train_test_split to divide the dataset up into training and test sets."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9a0326ce-96f5-476e-d2ba-0efafe543306"},"outputs":[],"source":"# Set up training and test sets by choosing random samples from classes\nX_train, X_test, y_train, y_test = train_test_split(df['text'], df['airline_sentiment'], test_size=0.33, random_state=0)\n\ndf_train = pd.DataFrame()\ndf_test = pd.DataFrame()\n\ndf_train['text'] = X_train\ndf_train['airline_sentiment'] = y_train\ndf_train = df_train.reset_index(drop=True)\n\ndf_test['text'] = X_test\ndf_test['airline_sentiment'] = y_test\ndf_test = df_test.reset_index(drop=True)"},{"cell_type":"markdown","metadata":{"_cell_guid":"36cf00fa-ace8-9d65-260f-e3379a59ad68"},"source":"Below we define our own class called TweetNBClassifier, which allows us to fit the classifier on our training data, predict the sentiment (positive or negative) of each tweet, and score our our results (i.e., determine how many tweets we've classified correctly. The \"fit\" function computes naive Bayes classification probabilities as defined here: https://web.stanford.edu/~jurafsky/slp3/7.pdf. The predict function uses these fit coefficients to predict the classes of our test data, and the \"score\" function scores our results in terms of classification accuracy."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3e2e670f-4979-116d-00a4-253cdedc812f"},"outputs":[],"source":"# Start training (input training set df_train)\nclass TweetNBClassifier(object):\n\n    def __init__(self, df_train):\n        self.df_train = df_train\n        self.df_pos = df_train.copy()[df_train.airline_sentiment == 'positive']\n        self.df_neg = df_train.copy()[df_train.airline_sentiment == 'negative']\n        self.df_neu = df_train.copy()[df_train.airline_sentiment == 'neutral']\n\n    def fit(self):\n        Pr_pos = df_pos.shape[0]/self.df_train.shape[0]\n        Pr_neg = df_neg.shape[0]/self.df_train.shape[0]\n        Pr_neu = df_neu.shape[0]/self.df_train.shape[0]\n        self.Prior  = (Pr_pos, Pr_neg, Pr_neu)\n\n        self.pos_words = ' '.join(self.df_pos['text'].tolist()).split()\n        self.neg_words = ' '.join(self.df_neg['text'].tolist()).split()\n        self.neu_words = ' '.join(self.df_neu['text'].tolist()).split()\n\n        all_words = ' '.join(self.df_train['text'].tolist()).split()\n\n        self.vocab = len(Counter(all_words))\n\n        wc_pos = len(' '.join(self.df_pos['text'].tolist()).split())\n        wc_neg = len(' '.join(self.df_neg['text'].tolist()).split())\n        wc_neu = len(' '.join(self.df_neu['text'].tolist()).split())\n        self.word_count = (wc_pos, wc_neg, wc_neu)\n        return self\n\n\n    def predict(self, df_test):\n        class_choice = ['positive', 'negative', 'neutral']\n\n        classification = []\n        for tweet in df_test['text']:\n            text = tweet.split()\n\n            val_pos = np.array([])\n            val_neg = np.array([])\n            val_neu = np.array([])\n            for word in text:\n                tmp_pos = np.log((self.pos_words.count(word)+1)/(self.word_count[0]+self.vocab))\n                tmp_neg = np.log((self.neg_words.count(word)+1)/(self.word_count[1]+self.vocab))\n                tmp_neu = np.log((self.neu_words.count(word)+1)/(self.word_count[2]+self.vocab))\n                val_pos = np.append(val_pos, tmp_pos)\n                val_neg = np.append(val_neg, tmp_neg)\n                val_neu = np.append(val_neu, tmp_neu)\n\n            val_pos = np.log(self.Prior[0]) + np.sum(val_pos)\n            val_neg = np.log(self.Prior[1]) + np.sum(val_neg)\n            val_neu = np.log(self.Prior[2]) + np.sum(val_neu)\n\n            probability = (val_pos, val_neg, val_neu)\n            classification.append(class_choice[np.argmax(probability)])\n        return classification\n\n\n    def score(self, feature, target):\n\n        compare = []\n        for i in range(0,len(feature)):\n            if feature[i] == target[i]:\n                tmp ='correct'\n                compare.append(tmp)\n            else:\n                tmp ='incorrect'\n                compare.append(tmp)\n        r = Counter(compare)\n        accuracy = r['correct']/(r['correct']+r['incorrect'])\n        return accuracy"},{"cell_type":"markdown","metadata":{"_cell_guid":"98b05657-5c89-6abb-d8c8-afaf8d625d43"},"source":"Okay, let's run the classifier and see how well we do on our test data!"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a883bd2e-4e0c-9bb3-ce80-8e5b958ae1cc"},"outputs":[],"source":"tnb = TweetNBClassifier(df_train)\ntnb = tnb.fit()\npredict = tnb.predict(df_test)\nscore = tnb.score(predict,df_test.airline_sentiment.tolist())\nprint(score)"},{"cell_type":"markdown","metadata":{"_cell_guid":"6c38518b-5443-c492-10fb-f0a40179e1ef"},"source":"The score value suggests we correctly identify tweet sentiment 93% of the time. Not bad at all!"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}