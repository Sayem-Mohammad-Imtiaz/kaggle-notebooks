{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**このノートブックは[Introduction to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning)のコースです。 このノートのチュートリアルはこちら-> [this link](https://www.kaggle.com/dansbecker/underfitting-and-overfitting).**\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"## Recap\n最初のモデルを構築したので、今度はより良い予測をするためにツリーのサイズを最適化してみましょう。このセルを実行して、前のステップが終了したところで、コーディング環境を整えます。","metadata":{}},{"cell_type":"code","source":"# データの読み込みに使用したことのあるコード\nimport pandas as pd\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeRegressor\n\n\n# 読み込みファイル\niowa_file_path = '../input/home-data-for-ml-course/train.csv'\n\nhome_data = pd.read_csv(iowa_file_path)\n# 目的変数を作成し、それをyと呼ぶ\ny = home_data.SalePrice\n# Xをつくる\nfeatures = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\nX = home_data[features]\n\n# 検証データとトレーニングデータに分割\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n\n# モデルの定義\niowa_model = DecisionTreeRegressor(random_state=1)\n# モデルをfitする\niowa_model.fit(train_X, train_y)\n\n# 検証予測を行い、平均絶対誤差MAEを算出\nval_predictions = iowa_model.predict(val_X)\nval_mae = mean_absolute_error(val_predictions, val_y)\nprint(\"Validation MAE: {:,.0f}\".format(val_mae))\n\n# コードチェックを確認\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.machine_learning.ex5 import *\nprint(\"\\nSetup complete\")","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exercises\n関数 `get_mae` を自分で書くこともできるんですよ。今のところ、こちらで作ったものを使いましょう。これは、前のレッスンで読んだのと同じ関数です。以下のセルを実行するだけです。","metadata":{}},{"cell_type":"code","source":"def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n    model.fit(train_X, train_y)\n    preds_val = model.predict(val_X)\n    mae = mean_absolute_error(val_y, preds_val)\n    return(mae)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 1: 異なるツリーサイズの比較\n*max_leaf_nodes*に可能な値を入力し、以下の値を試みるループを書きます。\n\nmax_leaf_nodesの各値で*get_mae*関数を呼び出す。データに対して最も正確なモデルを与える`max_leaf_nodes`の値を選択できるように、何らかの方法で出力を保存してください。\n検証予測を行い、平均絶対誤差を算出\n","metadata":{}},{"cell_type":"code","source":"candidate_max_leaf_nodes = [5, 25, 50, 100, 250, 500]\n# candidate_max_leaf_nodesから理想的なツリーサイズを求めるループを書く\n_\n\n# max_leaf_nodesの最適な値を格納する（5、25、50、100、250、500のいずれかになる）\nbest_tree_size = ____\n\n# 答えを確認する\nstep_1.check()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 以下の行がヒントやソリューションコードになります。（ヒントを見たい場合は.hint()の行をコメントアウト、答えを見る場合は.solutionの行をコメントアウトしてください。\n# step_1.hint() \n# step_1.solution()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 2: 全データを使ってモデルをフィット\n最適なツリーサイズが先ほどわかりました。\nもし、このモデルを実際に使用するのであれば、すべてのデータを使用して、そのツリーサイズを維持することで、さらに精度の高いモデルにすることができます。 つまり、すべてのモデルを決定した今、検証データを用意する必要はないのです。\n検証予測を行い、平均絶対誤差を算出します\n","metadata":{}},{"cell_type":"code","source":"# 最適なサイズになるように引数を記入し、コメントアウトしてください。\n# final_model = DecisionTreeRegressor(____)\n\n# 最終の完成版モデルに合わせて、次の2行をコメントアウトしてください。\n# final_model.fit(____, ____)\n\n# Check your answer\nstep_2.check()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# step_2.hint()\n# step_2.solution()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"あなたはこのモデルをチューニングし、結果を改善しました。しかし、私たちはまだ決定木モデルを使用しており、最近の機械学習の基準ではあまりうまくいっていません。次のステップでは、ランダムフォレストを使ってモデルをさらに改善する方法を学びます。\n\n# Keep Going\n\nこちらをみてください-> **[Random Forests](https://www.kaggle.com/dansbecker/random-forests).**\n","metadata":{}},{"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [Learn Discussion forum](https://www.kaggle.com/learn-forum/161285) to chat with other Learners.*","metadata":{}}]}