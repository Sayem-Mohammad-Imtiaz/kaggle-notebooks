{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import torch\nfrom torch import autograd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import TensorDataset, DataLoader","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/boston-house-prices/housing.csv', sep='\\s+', header = None, names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'PRICE'])\ntrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn\nfrom sklearn import preprocessing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"names = train.columns\nnames","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = preprocessing.StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaled_df = scaler.fit_transform(train)\nscaled_df = pd.DataFrame(scaled_df, columns=names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(scaled_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_tensor = torch.tensor(scaled_df.values, dtype = torch.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_tensor.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features = train_tensor[:,:13]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels = train_tensor[:, 13]\ntrain_labels.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 15\ndataset = TensorDataset(train_features, train_labels)\ndata_iter = DataLoader(dataset, batch_size, shuffle = True)\n\nfor X, y in data_iter:\n    print(X, y)\n    print(X.dtype)\n    print(X.shape)\n    print(y.shape)\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = torch.nn.Sequential(torch.nn.Linear(13, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = torch.nn.MSELoss(reduction='mean')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainer = torch.optim.SGD(model.parameters(), lr = 0.001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 100\nfor epoch in range(1, num_epochs + 1):\n    for X, y in data_iter:\n        trainer.zero_grad()\n        l = loss(model.forward(X).reshape(-1), y)\n        l.backward()\n        trainer.step()\n    l = loss(model.forward(train_features).reshape(-1), train_labels)\n    if epoch % 5 == 0:\n        print('epoch %d, loss: %f' % (epoch, l.item()) , '|\\tw', model[0].weight.data, '|\\tb', model[0].bias.data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n = 1\ny_hat = model.forward(train_features[n])\nprint(\"y_hat: \", y_hat)\nprint(\"y: \", train_labels[n])\nprint(\"Error: \", y_hat.item() - train_labels[n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**MNIST**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import torchvision\nimport time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def transform(data):\n    data = torch.tensor(data, dtype = torch.float32)\n    return torch.floor(data / 128.).squeeze(axis = -1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mnist_train = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\nmnist_test = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mnist_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_lbls = mnist_train['label']\ntrain_lbls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(train_lbls)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features = mnist_train.drop('label', axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_tensor = transform(train_features.values)\ntrain_tensor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_tensor[0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lbls_tensor = torch.tensor(train_lbls.values, dtype = torch.float32)\nlbls_tensor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 256\ndataset_mnist = TensorDataset(train_tensor, lbls_tensor)\ntrain_iter = DataLoader(dataset_mnist, batch_size, shuffle = True)\ntest_iter = torch.utils.data.DataLoader(transform(mnist_test.values), 256)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = torch.nn.Sequential(torch.nn.Linear(784,10))\nloss = torch.nn.CrossEntropyLoss()\ntrainer2 = torch.optim.SGD(model.parameters(), lr = 0.001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 10\nfor epoch in range(0, num_epochs):\n    start, train_loss, train_acc, train_n, test_loss, test_acc, test_n = time.time(), 0., 0., 0, 0., 0., 0\n    \n    model.train()\n    for X, y in train_iter:\n        print(\"X: \", X)\n        print(\"y: \", y)\n        print(\"X shape:\", X.shape)\n        print(\"y shape:\", y.shape)\n        print(\"y dtype:\", y.dtype)\n        trainer2.zero_grad()\n        y_hat = model.forward(X)\n        print(\"y_hat: \", y_hat)\n        print(\"y_hat shape: \", y_hat.shape)\n        l = loss(y_hat, y)\n        l.backward()\n        trainer2.step()\n        train_loss += l.item()\n        train_acc += (y_hat.argmax(dim=1) == y).sum().item()\n        train_n += len(X)\n        \n    model.eval()\n    for X, y in test:\n        y_hat = model(X)\n        l = loss(y_hat, y)\n        test_loss += l.item()\n        test_acc += (y_hat.argmax(dim=1) == y).sum().item()\n        test_n += len(X)\n        \n    print(\"\"\"epoch {}, taked: {:.3f}\n    train -> loss: {:.3f}, acc: {:.3f}\n    test -> loss: {:.3f}, acc: {:.3f}\n    \"\"\".format(epoch, time.time() - start, train_loss / train_n, train_acc / train_n,\n              test_loss / test_n, test_acc / test_n))\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}