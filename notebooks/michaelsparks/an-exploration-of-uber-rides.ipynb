{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport folium\nfrom matplotlib import cm\nfrom folium import Map\nfrom folium.plugins import HeatMap","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import 2014 data\napril2014 = pd.read_csv('/Users.../uber-raw-data-apr14.csv')\nmay2014 = pd.read_csv('/Users.../uber-raw-data-may14.csv')\njun2014 = pd.read_csv('/Users.../uber-raw-data-jun14.csv')\njul2014 = pd.read_csv('/Users.../uber-raw-data-jul14.csv')\naug2014 = pd.read_csv('/Users.../uber-raw-data-aug14.csv')\nsep2014 = pd.read_csv('/Users.../uber-raw-data-sep14.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import 2015 data\ndf2015 = pd.read_csv('/Users/Sparks/Documents/Data Projects/Uber Rides/uber-raw-data-janjune-15.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#I know, from looking at the CSV files before downloading, that all the 2014 files have the same column headers, so I'm going to combine them. \ndf2014 = pd.concat([april2014, may2014, jun2014, jul2014, aug2014, sep2014], ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#exploring the 2014 data set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2014.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2014.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2014.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2014.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf2 = df2014.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#exploring the 2015 dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2015.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf2015.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#clean up column names\ndf2014.columns = ['timestamp', 'lat', 'lon', 'base']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#convert timestamp column to datetime data type\ndf2014['timestamp'] = pd.to_datetime(df2014['timestamp'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#add more specifics so we can plot by day of week, month, etc. \n\ndf2014['weekday'] = df2014['timestamp'].dt.day_name()\ndf2014['month'] = df2014['timestamp'].dt.month\ndf2014['day'] = df2014['timestamp'].dt.day\ndf2014['hour'] = df2014['timestamp'].dt.hour\ndf2014['minute'] = df2014['timestamp'].dt.minute\n\ndf2014","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#update columns names to remove capital letters\ndf2015.columns = ['dispatching_base_num', 'pickup_date', 'affiliated_base_num', 'locationID']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2015['pickup_date'] = pd.to_datetime(df2015['pickup_date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#add more specifics so we can plot by day of week, month, etc. \n\ndf2015['weekday'] = df2015['pickup_date'].dt.day_name()\ndf2015['month'] = df2015['pickup_date'].dt.month\ndf2015['day'] = df2015['pickup_date'].dt.day\ndf2015['hour'] = df2015['pickup_date'].dt.hour\ndf2015['minute'] = df2015['pickup_date'].dt.minute\n\ndf2015","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import the taxi pickup map so we can plot 2015 uber rides geographically\npickupnames = pd.read_csv('/Users/Sparks/Documents/Data Projects/Uber Rides/taxi_pickup_location.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualizing 2014 growth\nline2014 = df2014.groupby('month').count()['timestamp'].reset_index()\nline2014","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"growth2014 = (line2014['timestamp'].iloc[-1] - line2014['timestamp'].iloc[0]) / line2014['timestamp'].iloc[0] * 100\nprint(\"Uber rides grew \" + str(round(growth2014,2)) + \"%\" + \" btwn Apr and Sep 2014\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n_ = line2014.plot('month', 'timestamp', title='uber ride growth apr-sep 2014', legend=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#visualizing 2015 growth\nline2015 = df2015.groupby('month').count()['pickup_date'].reset_index()\nline2015","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"growth_2015 = (line2015['pickup_date'].iloc[-1] - line2015['pickup_date'].iloc[0]) / line2015['pickup_date'].iloc[0] * 100\nprint(\"Uber rides grew \" + str(round(growth_2015,2)) + \"%\" + \" btwn Jan and Jun 2015\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_style('darkgrid')\n_ = sns.lineplot(x=line2015['month'],y=line2015['pickup_date']).set_title('Uber rides jan through jun, 2015')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating a heatmap for 2015 pickups\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hmap = Map(location=[ 40.753621,-73.927080], zoom_start=10, tiles='OpenStreetMap')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#filter data to focus on one month\ndf5 = df2014[df2014['month'] == 5]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create lat/long list\npr=list(df5['lat'])\npa=list(df5['lon'])\npb = zip(pr,pa)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hm_wide = HeatMap(\n    pb,\n    min_opacity=0.2,\n    radius=5, \n    blur=15, \n    max_zoom=1,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#not sure why the heat points cover so much area outside of NYC, where we don't have data... \nhmap.add_child(hm_wide)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hmap = folium.Map()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hmap = Map(location=[ 40.753621, -73.927080], zoom_start=10, tiles='OpenStreetMap')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hm_wide = HeatMap(\n    pb,\n    min_opacity=0.2,\n    radius=5, \n    blur=1, \n    max_zoom=1,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#other heat map exploration was a bust\nhmap.add_child(hm_wide)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating a dictionary to map locationID to borough. used excel to concatenate. \nborough = { 1:'EWR',\n2:'Queens',\n3:'Bronx',\n4:'Manhattan',\n5:'Staten Island',\n6:'Staten Island',\n7:'Queens',\n8:'Queens',\n9:'Queens',\n10:'Queens',\n11:'Brooklyn',\n12:'Manhattan',\n13:'Manhattan',\n14:'Brooklyn',\n15:'Queens',\n16:'Queens',\n17:'Brooklyn',\n18:'Bronx',\n19:'Queens',\n20:'Bronx',\n21:'Brooklyn',\n22:'Brooklyn',\n23:'Staten Island',\n24:'Manhattan',\n25:'Brooklyn',\n26:'Brooklyn',\n27:'Queens',\n28:'Queens',\n29:'Brooklyn',\n30:'Queens',\n31:'Bronx',\n32:'Bronx',\n33:'Brooklyn',\n34:'Brooklyn',\n35:'Brooklyn',\n36:'Brooklyn',\n37:'Brooklyn',\n38:'Queens',\n39:'Brooklyn',\n40:'Brooklyn',\n41:'Manhattan',\n42:'Manhattan',\n43:'Manhattan',\n44:'Staten Island',\n45:'Manhattan',\n46:'Bronx',\n47:'Bronx',\n48:'Manhattan',\n49:'Brooklyn',\n50:'Manhattan',\n51:'Bronx',\n52:'Brooklyn',\n53:'Queens',\n54:'Brooklyn',\n55:'Brooklyn',\n56:'Queens',\n57:'Queens',\n58:'Bronx',\n59:'Bronx',\n60:'Bronx',\n61:'Brooklyn',\n62:'Brooklyn',\n63:'Brooklyn',\n64:'Queens',\n65:'Brooklyn',\n66:'Brooklyn',\n67:'Brooklyn',\n68:'Manhattan',\n69:'Bronx',\n70:'Queens',\n71:'Brooklyn',\n72:'Brooklyn',\n73:'Queens',\n74:'Manhattan',\n75:'Manhattan',\n76:'Brooklyn',\n77:'Brooklyn',\n78:'Bronx',\n79:'Manhattan',\n80:'Brooklyn',\n81:'Bronx',\n82:'Queens',\n83:'Queens',\n84:'Staten Island',\n85:'Brooklyn',\n86:'Queens',\n87:'Manhattan',\n88:'Manhattan',\n89:'Brooklyn',\n90:'Manhattan',\n91:'Brooklyn',\n92:'Queens',\n93:'Queens',\n94:'Bronx',\n95:'Queens',\n96:'Queens',\n97:'Brooklyn',\n98:'Queens',\n99:'Staten Island',\n100:'Manhattan',\n101:'Queens',\n102:'Queens',\n103:'Manhattan',\n104:'Manhattan',\n105:'Manhattan',\n106:'Brooklyn',\n107:'Manhattan',\n108:'Brooklyn',\n109:'Staten Island',\n110:'Staten Island',\n111:'Brooklyn',\n112:'Brooklyn',\n113:'Manhattan',\n114:'Manhattan',\n115:'Staten Island',\n116:'Manhattan',\n117:'Queens',\n118:'Staten Island',\n119:'Bronx',\n120:'Manhattan',\n121:'Queens',\n122:'Queens',\n123:'Brooklyn',\n124:'Queens',\n125:'Manhattan',\n126:'Bronx',\n127:'Manhattan',\n128:'Manhattan',\n129:'Queens',\n130:'Queens',\n131:'Queens',\n132:'Queens',\n133:'Brooklyn',\n134:'Queens',\n135:'Queens',\n136:'Bronx',\n137:'Manhattan',\n138:'Queens',\n139:'Queens',\n140:'Manhattan',\n141:'Manhattan',\n142:'Manhattan',\n143:'Manhattan',\n144:'Manhattan',\n145:'Queens',\n146:'Queens',\n147:'Bronx',\n148:'Manhattan',\n149:'Brooklyn',\n150:'Brooklyn',\n151:'Manhattan',\n152:'Manhattan',\n153:'Manhattan',\n154:'Brooklyn',\n155:'Brooklyn',\n156:'Staten Island',\n157:'Queens',\n158:'Manhattan',\n159:'Bronx',\n160:'Queens',\n161:'Manhattan',\n162:'Manhattan',\n163:'Manhattan',\n164:'Manhattan',\n165:'Brooklyn',\n166:'Manhattan',\n167:'Bronx',\n168:'Bronx',\n169:'Bronx',\n170:'Manhattan',\n171:'Queens',\n172:'Staten Island',\n173:'Queens',\n174:'Bronx',\n175:'Queens',\n176:'Staten Island',\n177:'Brooklyn',\n178:'Brooklyn',\n179:'Queens',\n180:'Queens',\n181:'Brooklyn',\n182:'Bronx',\n183:'Bronx',\n184:'Bronx',\n185:'Bronx',\n186:'Manhattan',\n187:'Staten Island',\n188:'Brooklyn',\n189:'Brooklyn',\n190:'Brooklyn',\n191:'Queens',\n192:'Queens',\n193:'Queens',\n194:'Manhattan',\n195:'Brooklyn',\n196:'Queens',\n197:'Queens',\n198:'Queens',\n199:'Bronx',\n200:'Bronx',\n201:'Queens',\n202:'Manhattan',\n203:'Queens',\n204:'Staten Island',\n205:'Queens',\n206:'Staten Island',\n207:'Queens',\n208:'Bronx',\n209:'Manhattan',\n210:'Brooklyn',\n211:'Manhattan',\n212:'Bronx',\n213:'Bronx',\n214:'Staten Island',\n215:'Queens',\n216:'Queens',\n217:'Brooklyn',\n218:'Queens',\n219:'Queens',\n220:'Bronx',\n221:'Staten Island',\n222:'Brooklyn',\n223:'Queens',\n224:'Manhattan',\n225:'Brooklyn',\n226:'Queens',\n227:'Brooklyn',\n228:'Brooklyn',\n229:'Manhattan',\n230:'Manhattan',\n231:'Manhattan',\n232:'Manhattan',\n233:'Manhattan',\n234:'Manhattan',\n235:'Bronx',\n236:'Manhattan',\n237:'Manhattan',\n238:'Manhattan',\n239:'Manhattan',\n240:'Bronx',\n241:'Bronx',\n242:'Bronx',\n243:'Manhattan',\n244:'Manhattan',\n245:'Staten Island',\n246:'Manhattan',\n247:'Bronx',\n248:'Bronx',\n249:'Manhattan',\n250:'Bronx',\n251:'Staten Island',\n252:'Queens',\n253:'Queens',\n254:'Bronx',\n255:'Brooklyn',\n256:'Brooklyn',\n257:'Brooklyn',\n258:'Queens',\n259:'Bronx',\n260:'Queens',\n261:'Manhattan',\n262:'Manhattan',\n263:'Manhattan',\n264:'Unknown'\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2015['borough'] = df2015['locationID'].map(borough)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#getting ready to visually explore 2015 pickups\ndf6 = df2015.groupby(['month', 'borough']).count()['locationID'].reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#clear out newark airport (not a borough) and staten island, which had very few pickups to start.\ndf6 = df6[(df6['borough'] != 'Unknown') & (df6['borough'] != 'EWR') & (df6['borough'] != 'Staten Island')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#preping data to look at % of rides that originate in each borough\npivot_df6 = df6.pivot(index='month', columns='borough', values='locationID')\n\n\npivot_df6['total'] = pivot_df6['Bronx'] + pivot_df6['Brooklyn'] + pivot_df6['Manhattan'] + pivot_df6['Queens']\n\n\npivot_df6['BRONX'] = pivot_df6['Bronx'] / pivot_df6['total']\npivot_df6['BROOKLYN'] = pivot_df6['Brooklyn'] / pivot_df6['total']\npivot_df6['MANHATTAN'] = pivot_df6['Manhattan'] / pivot_df6['total']\npivot_df6['QUEENS'] = pivot_df6['Queens'] / pivot_df6['total']\n\n\npivot_df6.drop(['Bronx', 'Brooklyn', 'Manhattan', 'Queens', 'total'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = pivot_df6.plot.bar(stacked=True, title='Manahtaan is the dominant borough, but Uber grew in Queens and Brooklyn')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#2015 journeys by week day\n\nweekdays_2015 = df2015.groupby(['weekday']).count()['dispatching_base_num'].reset_index()\nweekdays_2015","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weekdays = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n\nweekdays_2015.set_index('weekday').loc[weekdays].reset_index()\n\nweekdays_2015","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#to understand uber's impact on traffic and taxis in nyc, we need to know more than just how much it grew overall and where it grew. we need to know when. \n#do we glean anything from this way of viewing the data? not really... let's try something else\nweekdaymonth = df2015.pivot_table(index=['weekday', 'month'], values='dispatching_base_num', aggfunc='count')\n_ = weekdaymonth.plot(kind='bar', figsize=(8,8), title='2015 rides by weekday', legend=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#which day of the month saw the most rides? not really a pattern\nday_of_month = df2015.pivot_table(index=['day'], values='dispatching_base_num', aggfunc='count')\n_ = day_of_month.plot(kind='bar', figsize=(8,8), title='2015 rides by day of month', legend=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#it also doesn't seem to change much throughout the first half of the year, which we can see every from this very rough visualization\nday_of_month = df2015.pivot_table(index=['day','month'], values='dispatching_base_num', aggfunc='count')\n_ = day_of_month.plot(kind='bar', figsize=(8,8), title='2015 rides by day of month', legend=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#rides are pretty consistent throughout the month\nhour_of_day = df2015.pivot_table(index=['day'], values='dispatching_base_num', aggfunc='count')\n_ = hour_of_day.plot(kind='bar', figsize=(8,8), title='2015 rides by day of month', legend=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hour2015 = df2015[df2015['month'] == 6]\nhour2015 = hour2015.groupby(['day', 'hour', 'weekday'])['pickup_date'].count().reset_index()\n\nhour2015.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#calculating average rides per hour per day of the week\nhour2015avg = hour2015.groupby(['weekday', 'hour', 'pickup_date']).mean().reset_index()\n\nhour2015avg = hour2015avg.rename(columns = {'pickup_date':'average_rides'})\n\nhour2015avg = hour2015avg.sort_index()\nhour2015avg.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(8,8))\nax = fig.add_subplot(111)\n\n_ = sns.lineplot(ax=ax, x='hour', y='average_rides', hue='weekday', data=hour2015avg, err_style=None).set_title('rides per hour by weekday, june 2015')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nhour2014 = df2014[df2014['month'] == 6]\nhour2014 = hour2014.groupby(['day', 'hour', 'weekday'])['timestamp'].count().reset_index()\n\nhour2014.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hour2014avg = hour2014.groupby(['weekday', 'hour', 'timestamp']).mean().reset_index()\n\nhour2014avg = hour2014avg.rename(columns = {'timestamp':'average_rides'})\n\nhour2014avg = hour2014avg.sort_index()\nhour2014avg.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(8,8))\nax = fig.add_subplot(111)\n\n_ = sns.lineplot(ax=ax, x='hour', y='average_rides', hue='weekday', data=hour2014avg, err_style=None).set_title('rides per hour by weekday, june 2014')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#the biggest difference, aside from the raw numbers, is that friday and saturday see a huge bump in 2015 that wasn't there in 2014","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}