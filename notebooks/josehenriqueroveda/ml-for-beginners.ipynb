{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\nHello, in this notebook I'm going to show you how to use supervised learning in the task of identifying whether it is a benign or malignant breast cancer. Below, is shown the Data Science Process. It's based in it that i'm going to teach the step by step to reach the result. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"![](https://miro.medium.com/max/3870/1*eE8DP4biqtaIK3aIy1S2zA.png)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Code time:","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 1. Importing libraries\n\n**scikit-learn** is the most widely used Python library for machine learning. **pandas** is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool,\nbuilt on top of the Python programming language.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import sklearn\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Loading the data\n","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/breast-cancer-wisconsin-data/data.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Cleaning the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking if there are null values in the dataset\ndata.isnull()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Deleting 'Unnamed: 32' column\ndata.drop(\"Unnamed: 32\",axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Deleting 'id' column\ndata.drop(\"id\",axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Exploring the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Take a look to the data columns:\nlist(data.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Mapping diagnosis to integer values\ndata['diagnosis']=data['diagnosis'].map({'M':1,'B':0})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The data can be divided into \"mean\", \"se\" and \"worst\", so below it is done:**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"features_mean= list(data.columns[1:11])\nfeatures_se= list(data.columns[11:20])\nfeatures_worst=list(data.columns[21:31])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Getting the frequency of the breast cancer diagnosis:**\n* 1 (Malignant)\n* 0 (Benign)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style='darkgrid', font_scale=1.1)\nsns.countplot(data['diagnosis'],label=\"Count\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Analyzing data correlation\nA correlation matrix is a tabular data representing the ‘correlations’ between pairs of variables in a given data.\nEach row and column represents a variable, and each value in this matrix is the correlation coefficient between the variables represented by the corresponding row and column.\nThe Correlation matrix is an important data analysis metric that is computed to summarize data to understand the relationship between various variables and make decisions accordingly.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = data[features_mean].corr()\nplt.figure(figsize=(14,14))\nsns.heatmap(corr, cbar = True,  square = True, annot=True, fmt= '.2f',annot_kws={'size': 15},\n           xticklabels= features_mean, yticklabels= features_mean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Based on correlation heatmap, we can select some of the variables to be used on prediction\npred_var = ['texture_mean','radius_mean','smoothness_mean','concavity_mean','symmetry_mean']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.PairGrid(data, y_vars=pred_var, x_vars=['diagnosis'], aspect=0.8, height=3.0)\ng.map(sns.barplot, palette='muted')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Creating a model\n\nWe need to know how well it performs. To do this, the data is splitted in two parts: 1) a training dataset that we use for building the model, and 2) a test dataset that we use for testing the accuracy of our model. We do this with the use of the train_test_split function, which shuffles the dataset randomly, and by default extracts 75% of the cases as training data and 25% of the cases as test data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_target = data['diagnosis']\ndata_features = data.drop(['diagnosis'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting our dataset into training data and test data\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(data_features, data_target, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"X_train shape: \", X_train.shape)\nprint(\"y_train shape: \", y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"X_test shape: \", X_test.shape)\nprint(\"y_test shape: \", y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model: K-Nearest Neighbours\n\nKNN is a simple algorithm that stores all available cases and classifies new cases based on a similarity measure (e.g., distance functions).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"![](https://3.bp.blogspot.com/-In1TiknFHSg/XHaqqP8UzhI/AAAAAAAAGSY/0m6BSNsFKqIEDVJZyhSatsi7jL2Kb4pwwCLcBGAs/s1600/knn.jpg)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Building a model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# n_neighbors=1 is setting the number of nearest neighbours to 1.\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# build the model on the training set, i.e. X_train and y_train.\nknn.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model evaluation\nTesting dataset to evaluate the accuracy of the model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"KNN-1 Accuracy on training set:  {:.3f}\".format(knn.score(X_train, y_train)))\nprint(\"KNN-1 Accuracy on test set: {:.3f}\".format(knn.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The knn model with n_neighbors=1, has accuracy 100% on the training dataset. This means that it's over-fitting the training data.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Testing predictions using the model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# specify one new instance to be predicted\nX_new = np.array([[18.99,\n10.30,\n123.8,\n1001,\n0.119,\n0.26,\n0.30,\n0.15,\n0.24,\n0.08,\n1.095,\n0.9053,\n8.65,\n157.4,\n0.0064,\n0.04904,\n0.05373,\n0.01587,\n0.03003,\n0.0053,\n25.38,\n17.33,\n186.5,\n2019,\n0.1642,\n0.6656,\n0.7119,\n0.2654,\n0.4601,\n0.1189]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = knn.predict(X_new)\n\nprint(f\"Prediction: {'Malignant' if prediction == 1 else 'Benign'}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Improving the KNN model\n\nTrying different numbers of k nearest neighbours.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"KNN-4 - Accuracy on training set:  {:.3f}\".format(knn.score(X_train, y_train)))\nprint(\"KNN-4 - Accuracy on test set: {:.3f}\".format(knn.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There was an improvement in the accuracy of the model using 4 n_neighbors instead of 1.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = knn.predict(X_new)\n\nprint(f\"Prediction: {'Malignant' if prediction == 1 else 'Benign'}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model: Decision Tree\n\nIt uses a decision tree to go from observations about an item to conclusions about the item's target value.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"![](https://lh4.googleusercontent.com/v9UQUwaQTAXVH90b-Ugyw2_61_uErfYvTBtG-RNRNB_eHUFq9AmAN_2IOdfOETnbXImnQVN-wPC7_YzDgf7urCeyhyx5UZmuSwV8BVsV8VnHxl1KtgpuxDifJ4pLE23ooYXLlnc)\n\n*Basic Decision Tree example*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ntree = DecisionTreeClassifier(random_state=0)\ntree.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Decision Tree - Accuracy on training set: {:.3f}\".format(tree.score(X_train, y_train)))\nprint(\"Decision Tree - Accuracy on test set: {:.3f}\".format(tree.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The decision tree built has accuracy 100% on the training dataset. This means that our decision tree is over-fitting the training data.\nTo avoid overfitting (and hopefully improve the accuracy of the model on test data), we can stop before the entire tree is created. We can do this by setting the maximal depth of the tree.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tree = DecisionTreeClassifier(max_depth=3, random_state=12)\ntree.fit(X_train, y_train)\n\nprint(\"Decision Tree - Accuracy on training set: {:.3f}\".format(tree.score(X_train, y_train)))\nprint(\"Decision Tree - Accuracy on test set: {:.3f}\".format(tree.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The new decision tree has lower accuracy on the training dataset, but higher accuracy on the test dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = tree.predict(X_new)\n\nprint(f\"Prediction: {'Malignant' if prediction == 1 else 'Benign'}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Improving the Decision Tree model\n\nTrying different max_depth in the decision tree model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tree = DecisionTreeClassifier(max_depth=2, random_state=12)\ntree.fit(X_train, y_train)\n\nprint(\"Decision Tree - Accuracy on training set: {:.3f}\".format(tree.score(X_train, y_train)))\nprint(\"Decision Tree - Accuracy on test set: {:.3f}\".format(tree.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The new decision tree has lower accuracy on the training dataset, but higher accuracy on the test dataset. max_depth higher than this, has lesses accuracies.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Model: Random Forest\n\nRandom forests or random decision forests are an ensemble learning method for classification, regression and other tasks that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes or mean prediction of the individual trees.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"![](https://upload.wikimedia.org/wikipedia/commons/7/76/Random_forest_diagram_complete.png)\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nforest = RandomForestClassifier(n_estimators=1000, random_state=999, max_depth=3)\nforest.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Random Forest - Accuracy on training set: {:.3f}\".format(forest.score(X_train, y_train)))\nprint(\"Random Forest - Accuracy on test set: {:.3f}\".format(forest.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = forest.predict(X_new)\n\nprint(f\"Prediction: {'Malignant' if prediction == 1 else 'Benign'}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We can conclude that the Random Forest model proved to be the most accurate in the classification of breast cancer.\n\nThank you, this is a basic notebook from the stages of machine learning, if you liked it please vote.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}