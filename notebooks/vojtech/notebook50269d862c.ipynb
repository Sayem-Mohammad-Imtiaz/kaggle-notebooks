{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn as sk\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/us-airbnb-open-data/AB_US_2020.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(data.city.unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.city.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets first see if we can predict City from the Lat/Lon"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\n\ndef trainCityModel(X, y):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.6)\n    cityModel = DecisionTreeClassifier(min_samples_leaf = 25, max_depth = 25)\n    cityModel.fit(X_train, y_train)\n    print(f\"f1 of test: {f1_score(y_test, cityModel.predict(X_test), average = 'weighted')}\")\n    print(f\"f1 of train: {f1_score(y_train, cityModel.predict(X_train), average = 'weighted')}\")\n    return cityModel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cityModel = trainCityModel(y = data.city, X = data.loc[:, ['latitude', 'longitude']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x=data['latitude'], y=data['longitude'], hue=data['city'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x=data['latitude'], y=data['longitude'], hue=cityModel.predict(data.loc[:, ['latitude', 'longitude']]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We conclude that City can be freely dropped, as in principle we can predict it from the Coords\n\nNow we look into Room Type and Neighbourhoods"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.room_type.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.neighbourhood_group.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hoodGroupCityModel = trainCityModel(pd.get_dummies(data.loc[:, ['city']]), data.neighbourhood_group.fillna('Other neighborhoods'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cityHoodGroupModel = trainCityModel(pd.get_dummies(data.loc[:, ['neighbourhood_group']].fillna('Other neighborhoods')), data.city)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hoodGroupModel = trainCityModel(data.loc[:, ['latitude', 'longitude']], data.neighbourhood_group.fillna('Other neighborhoods'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.neighbourhood.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hoodModel = trainCityModel(data.loc[:, ['latitude', 'longitude']], data.neighbourhood.fillna('Unincorporated Areas'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.dummy import DummyRegressor\nfrom sklearn.metrics import mean_absolute_error\ndummyPriceRegressor = DummyRegressor()\ndummyPriceRegressor.fit(X = data, y = data.price) # we don't mind the leak here\nmean_absolute_error(data.price, dummyPriceRegressor.predict(data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\ndef trainNaiveRegressor(X, y, regressor = DecisionTreeRegressor(min_samples_leaf = 25, max_depth = 25), test_size = 0.6):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size)\n    regressor.fit(X_train, y_train)\n    print(f\"mae of test: {mean_absolute_error(y_test, regressor.predict(X_test))}\")\n    print(f\"mae of train: {mean_absolute_error(y_train, regressor.predict(X_train))}\")\n    return regressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"naiveCityPriceCorrelation = trainNaiveRegressor(pd.get_dummies(data.loc[:, ['city']]), data.price)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"naiveNGPriceCorrelation = trainNaiveRegressor(pd.get_dummies(data.loc[:, ['neighbourhood_group']].fillna('Other neighborhoods')), data.price)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"naiveHoodPriceCorrelation = trainNaiveRegressor(pd.get_dummies(data.loc[:, ['neighbourhood']].fillna('Unincorporated Areas')), data.price)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"geoClusters = 200\nfrom sklearn.cluster import KMeans\nclusteringModel = KMeans(n_clusters=geoClusters, init='k-means++')\ngeoClusterDummies = pd.get_dummies(clusteringModel.fit_predict(data.loc[:, ['latitude', 'longitude']]), prefix = 'geo')\ntrainNaiveRegressor(geoClusterDummies, data.price)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Neighbourhood Group seems very similar to city -- also predictable from the Geo cords, even though not directly corresponding\n\nNeighbourhood is harder to predict as it apparently has much more distinct values, and its kinda longer-tailed\n\nAll of the City, NG and Hood itself perform poorly when naively dummied and used to predict price; with 200-geo-clusters perfoming a tiny bit better. Therefore, we will drop those three.\n\nRoom type is just 4 categorial values, no need to think here."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.last_review.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data.last_review.isna()].number_of_reviews.sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1 = pd.get_dummies(data\\\n  .assign(days_since_last_review = (pd.to_datetime('2020-11-09') - pd.to_datetime(data.last_review.fillna('01/01/00'))).map(lambda x : x.days))\\\n  .drop(['name', 'host_name', 'city', 'neighbourhood', 'neighbourhood_group', 'last_review'], axis = 'columns')\\\n  .fillna({'reviews_per_month': 0})\n, columns = ['room_type'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we have gotten rid of all Object columns.\n\nWe will now get rid of those Numer ones which do not correspond to Ordinals: Id, host id, Geo\n\nId is clear dropper, Host Id we will consider dummification, Geo is for clustering & dummification"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(data1.id.unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hostCounts = data1.host_id.value_counts()\nhostCounts.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hostCounts.value_counts()[0:20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hostIdAggs = data1.groupby('host_id').agg({'host_id': ['count'], 'price': ['mean', 'std']})\nhostIdAggs[hostIdAggs.host_id['count'] > 1].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hostIdAggs.columns = hostIdAggs.columns.to_flat_index()\nhostIdAggs.drop([('price', 'std')], axis = 'columns').describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hostIdAggs.drop([('price', 'std')], axis = 'columns').corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dummyAvgPriceRegressor = DummyRegressor()\ndummyAvgPriceRegressor.fit(X = hostIdAggs, y = hostIdAggs[('price', 'mean')]) # we don't mind the leak here\nmean_absolute_error(hostIdAggs[('price', 'mean')], dummyPriceRegressor.predict(hostIdAggs))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"regressor = DecisionTreeRegressor(min_samples_leaf = 2, max_depth = 2)\nnaiveHousesToPrice = trainNaiveRegressor(X = hostIdAggs.loc[:, [('host_id', 'count')]], y = hostIdAggs[('price', 'mean')], regressor = regressor)\n\nfrom sklearn.tree import export_graphviz\nimport graphviz\n\ntreeGraph = export_graphviz(naiveHousesToPrice, out_file=None, feature_names=[('host_id', 'count')])\ngraphviz.Source(treeGraph)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bigHosts = hostCounts[hostCounts > 78].index # we are comitting a potential leak here, would have to be considered in temporal context\nmediumHosts = hostCounts[(hostCounts <= 78) & (hostCounts > 18)].index\nsmallishHosts = hostCounts[(hostCounts <= 18) & (hostCounts > 1)].index\nfirstTimers = hostCounts[hostCounts <= 1].index\nhostSizeConstructor = [(bigHosts, 'big'), (mediumHosts, 'medium'), (smallishHosts, 'smallish'), (firstTimers, 'firstTimer')]\nhostSizeFeature = pd.concat([pd.Series([element[1]]*len(element[0]), index = element[0]) for element in hostSizeConstructor], axis = 'rows')\nhostSizeFeature.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems that the number of listings of the Host does have some value. A decision tree was able to predict the average price with a little better performance than dummy -> we use that tree to derive buckets for the Feature\n\nWe have an explicit assumption here that this feature can be computed -- for example, this would be satisfied if the hosts have to submit entries only once and in a batch.\n\n*Post-hoc edit*: Uh-ok, later on I've found that the calculated host listings count is exactly the group by & sum feature...\n\nFurthermore, we simply re-use the 200-clusters for Geo"},{"metadata":{"trusted":true},"cell_type":"code","source":"hostSizeDummies = pd.get_dummies(hostSizeFeature, prefix = 'hostSize')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data2 = data1.join(geoClusterDummies).join(hostSizeDummies, on = 'host_id').drop(['latitude', 'longitude', 'host_id', 'id'], axis = 'columns')\ndata2.describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fullX = data2.drop(['price'], axis = 'columns')\nfullY = data2.price\nfirstFullAttempt = trainNaiveRegressor(X = fullX, y = fullY)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import eli5\nfrom eli5.sklearn import PermutationImportance\n\npermSampler = data2.sample(frac = 0.1)\npermSamplerX = permSampler.drop(['price'], axis = 'columns')\npermSamplerY = permSampler.price\n\nperm = PermutationImportance(firstFullAttempt).fit(permSamplerX, permSamplerY)\ndisplay(eli5.show_weights(perm, feature_names = fullX.columns.tolist()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"firstFullAttemptWithoutListingsCount = trainNaiveRegressor(X = fullX.drop('calculated_host_listings_count', axis = 'columns'), y = fullY)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import shap\n\nshapSamples = permSamplerX.sample(n = 10)\nexplainer = shap.TreeExplainer(firstFullAttempt)\nshapValues = explainer.shap_values(shapSamples)\nshap.initjs()\nshap.force_plot(explainer.expected_value[0], shapValues[0], shapSamples.iloc[0, :])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.force_plot(explainer.expected_value[0], shapValues[1], shapSamples.iloc[1, :])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.force_plot(explainer.expected_value[0], shapValues[2], shapSamples.iloc[2, :])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"redundantFeatures = ['hostSize_' + x[1] for x in hostSizeConstructor] + ['number_of_reviews']\nfirstFullAttemptWithoutRedundantFeatures = trainNaiveRegressor(X = fullX.drop(redundantFeatures, axis = 'columns'), y = fullY)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data2.loc[:, ['number_of_reviews', 'reviews_per_month']].corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A straightforward trained tree yields somehow better performance than dummy; but suffers from some train-test discrepancy.\n\nListings count turns out to be a significant feature; its omission drops performance despite those bucket variables still being there. Getting rid of the bucket variables and the total number of reviews (while keeping the fairly correlated reviews per month) yields a little smaller train-test performance discrepancy.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nrfAttempt_1 = trainNaiveRegressor(X = fullX, y = fullY, regressor = RandomForestRegressor(n_estimators = 8, max_depth = 30), test_size = 0.2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nrfAttempt_2 = trainNaiveRegressor(X = fullX, y = fullY, regressor = RandomForestRegressor(n_estimators = 16, max_depth = 24), test_size = 0.3)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nrfAttempt_3 = trainNaiveRegressor(X = fullX.drop(redundantFeatures, axis = 'columns'), y = fullY, regressor = RandomForestRegressor(n_estimators = 8, max_depth = 38), test_size = 0.2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\ngbAttempt_1 = trainNaiveRegressor(X = fullX, y = fullY, regressor = GradientBoostingRegressor(), test_size = 0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With Random Forests, the train-test performance discrepancy widens much more :/\n\nGradient Boosting, with default parameters, performs worse than a simple tree (but at least no discrepancy)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.compose import TransformedTargetRegressor\n\nscoringStrategy = 'neg_mean_absolute_error'\n\ndef evalModelPipeline(preproc, model, targetReg = True, X = fullX.drop(redundantFeatures, axis = 'columns'), y = fullY):\n    if targetReg:\n        model = TransformedTargetRegressor(regressor=model, transformer=MinMaxScaler())\n    pipeline = Pipeline(steps = [('preproc', preproc), ('model', model)])\n    scores = -1 * cross_val_score(pipeline, X, y,\n                              cv=5,\n                              scoring=scoringStrategy)\n    print(scores)\n    return scores\n\nstdPreproc = ColumnTransformer(transformers = [], remainder = StandardScaler())\nmmPreproc = ColumnTransformer(transformers = [], remainder = MinMaxScaler())\nnoop = ColumnTransformer(transformers = [], remainder = 'passthrough')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression, HuberRegressor\nevalModelPipeline(noop, LinearRegression(), targetReg = False)\nevalModelPipeline(stdPreproc, LinearRegression(), targetReg = False)\nevalModelPipeline(stdPreproc, LinearRegression())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evalModelPipeline(mmPreproc, LinearRegression(), targetReg = False)\nevalModelPipeline(mmPreproc, LinearRegression())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Oh, I guess I don't really know how to use Linear Regression :(\n\nWhy are the values off by multiple orders of magnitude is beyond my knowledge"},{"metadata":{"trusted":true},"cell_type":"code","source":"# this is rather just a sanity check\nevalModelPipeline(noop, DecisionTreeRegressor(max_depth = 32), targetReg = False)\nevalModelPipeline(mmPreproc, DecisionTreeRegressor(max_depth = 32), targetReg = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Interestingly enough, there are some non trivial variatons here... I wonder what is causing that."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}