{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport warnings \n\nwarnings.filterwarnings('ignore')\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-18T02:50:39.867459Z","iopub.execute_input":"2021-08-18T02:50:39.867806Z","iopub.status.idle":"2021-08-18T02:50:39.878071Z","shell.execute_reply.started":"2021-08-18T02:50:39.867775Z","shell.execute_reply":"2021-08-18T02:50:39.8771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"heart = pd.read_csv('/kaggle/input/heart-disease-uci/heart.csv')\nheart.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-18T02:50:40.862982Z","iopub.execute_input":"2021-08-18T02:50:40.863313Z","iopub.status.idle":"2021-08-18T02:50:40.883498Z","shell.execute_reply.started":"2021-08-18T02:50:40.863285Z","shell.execute_reply":"2021-08-18T02:50:40.882553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n","metadata":{"execution":{"iopub.status.busy":"2021-08-18T02:50:41.262802Z","iopub.execute_input":"2021-08-18T02:50:41.263212Z","iopub.status.idle":"2021-08-18T02:50:41.267351Z","shell.execute_reply.started":"2021-08-18T02:50:41.263177Z","shell.execute_reply":"2021-08-18T02:50:41.266375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X, y = heart.drop('target', axis=1), heart['target']\nX.shape, y.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-18T02:50:41.48243Z","iopub.execute_input":"2021-08-18T02:50:41.482779Z","iopub.status.idle":"2021-08-18T02:50:41.490973Z","shell.execute_reply.started":"2021-08-18T02:50:41.482719Z","shell.execute_reply":"2021-08-18T02:50:41.489763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" y = tf.reshape(y, shape=(303, 1))","metadata":{"execution":{"iopub.status.busy":"2021-08-18T02:50:41.982545Z","iopub.execute_input":"2021-08-18T02:50:41.98288Z","iopub.status.idle":"2021-08-18T02:50:41.988499Z","shell.execute_reply.started":"2021-08-18T02:50:41.98285Z","shell.execute_reply":"2021-08-18T02:50:41.98739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set random seed \ntf.random.set_seed(100)\n\n\n# create a model \n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Dense(4, activation='relu'),\n    tf.keras.layers.Dense(4, activation='relu'),\n\n \n\n\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(\n    loss = tf.keras.losses.BinaryCrossentropy(),\n    optimizer = tf.keras.optimizers.Adam(lr=0.0001),\n    metrics = ['accuracy']\n)\n\n\nmodel.fit(X, y, epochs=100, verbose=0)\nmodel.evaluate(X, y)","metadata":{"execution":{"iopub.status.busy":"2021-08-18T02:50:42.267555Z","iopub.execute_input":"2021-08-18T02:50:42.267904Z","iopub.status.idle":"2021-08-18T02:50:43.719728Z","shell.execute_reply.started":"2021-08-18T02:50:42.267871Z","shell.execute_reply":"2021-08-18T02:50:43.719048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Let' Normalise the data and then create a model","metadata":{}},{"cell_type":"code","source":"from sklearn.compose import make_column_transformer \nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder\nfrom sklearn.model_selection import train_test_split\n\n# create a  columns transformer \nct = make_column_transformer(\n    (MinMaxScaler(), ['age', 'trestbps', 'cp', 'chol', 'thalach', 'oldpeak', 'thal']))\n\n\n# create X and Y values \nX, y = heart.drop('target', axis=1), heart['target']\n#y = tf.reshape(y, shape = (len(y),1))\n# build our trian and test sets \n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n\n# fit the column transformer to our training data \nct.fit(X_train)\n\n# transforming training and test data \n\nX_train_normal = ct.transform(X_train)\nX_test_normal = ct.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-18T02:50:43.720876Z","iopub.execute_input":"2021-08-18T02:50:43.721249Z","iopub.status.idle":"2021-08-18T02:50:43.741032Z","shell.execute_reply.started":"2021-08-18T02:50:43.721222Z","shell.execute_reply":"2021-08-18T02:50:43.740097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"heart.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-08-18T02:50:43.742558Z","iopub.execute_input":"2021-08-18T02:50:43.742872Z","iopub.status.idle":"2021-08-18T02:50:43.755402Z","shell.execute_reply.started":"2021-08-18T02:50:43.742804Z","shell.execute_reply":"2021-08-18T02:50:43.754385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-18T02:50:43.757063Z","iopub.execute_input":"2021-08-18T02:50:43.75735Z","iopub.status.idle":"2021-08-18T02:50:43.767987Z","shell.execute_reply.started":"2021-08-18T02:50:43.757313Z","shell.execute_reply":"2021-08-18T02:50:43.766969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = tf.reshape(y_train, shape = (len(y_train),1))\ny_test = tf.reshape(y_test, shape = (len(y_test),1))\n","metadata":{"execution":{"iopub.status.busy":"2021-08-18T02:50:43.769275Z","iopub.execute_input":"2021-08-18T02:50:43.769593Z","iopub.status.idle":"2021-08-18T02:50:43.778967Z","shell.execute_reply.started":"2021-08-18T02:50:43.769559Z","shell.execute_reply":"2021-08-18T02:50:43.777858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set random seed \ntf.random.set_seed(100)\n\n\n# create a model \n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Dense(4, activation='relu'),\n    tf.keras.layers.Dense(4, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(\n    loss = tf.keras.losses.BinaryCrossentropy(),\n    optimizer = tf.keras.optimizers.Adam(),\n    metrics = ['accuracy']\n)\n\n\nmodel_history = model.fit(X_train_normal, y_train, epochs=100, verbose=0)","metadata":{"execution":{"iopub.status.busy":"2021-08-18T02:50:43.780033Z","iopub.execute_input":"2021-08-18T02:50:43.78029Z","iopub.status.idle":"2021-08-18T02:50:44.986167Z","shell.execute_reply.started":"2021-08-18T02:50:43.780265Z","shell.execute_reply":"2021-08-18T02:50:44.985425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(X_test_normal, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-18T02:50:44.987318Z","iopub.execute_input":"2021-08-18T02:50:44.987693Z","iopub.status.idle":"2021-08-18T02:50:45.131464Z","shell.execute_reply.started":"2021-08-18T02:50:44.987666Z","shell.execute_reply":"2021-08-18T02:50:45.130846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"history = pd.DataFrame(model_history.history)\nhistory","metadata":{"execution":{"iopub.status.busy":"2021-08-18T02:50:45.132879Z","iopub.execute_input":"2021-08-18T02:50:45.133241Z","iopub.status.idle":"2021-08-18T02:50:45.145583Z","shell.execute_reply.started":"2021-08-18T02:50:45.133215Z","shell.execute_reply":"2021-08-18T02:50:45.144625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-08-18T02:50:45.147009Z","iopub.execute_input":"2021-08-18T02:50:45.147266Z","iopub.status.idle":"2021-08-18T02:50:45.157213Z","shell.execute_reply.started":"2021-08-18T02:50:45.147241Z","shell.execute_reply":"2021-08-18T02:50:45.156083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplots(1,1, figsize=(16, 6))\nsns.lineplot(history.index, history.loss)\nsns.lineplot(history.index, history.accuracy)\nplt.legend(['loss', 'accuracy'])\nplt.xlabel('Epochs')\nplt.title(\"Loss Vs Accuracy\", size=22)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-18T02:50:45.15876Z","iopub.execute_input":"2021-08-18T02:50:45.159161Z","iopub.status.idle":"2021-08-18T02:50:45.380401Z","shell.execute_reply.started":"2021-08-18T02:50:45.159128Z","shell.execute_reply":"2021-08-18T02:50:45.379431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}