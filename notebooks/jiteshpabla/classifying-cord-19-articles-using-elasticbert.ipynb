{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Using Novel Language Models and elasticsearch to Effectively Identify Articles related to Therapeutics and Vaccines\n * Team: MD-Lab, ASU\n * Author: Jitesh Pabla, Email: jpabla1@asu.edu, Kaggle ID: jiteshpabla\n * Team Members: Rishab Banerjee, Hong Guan, Ashwin Karthik Ambalavanan, Mihir Parmar, Murthy Devarakonda\n * Email ID: loccapollo@gmail.com, hguan6@asu.edu, aambalav@asu.edu, mparmar3@asu.edu, Murthy.Devarakonda@asu.edu\n * Kaggle ID: loccapollo, hongguan, ashwinambal96, mihir3031, murthydevarakonda\n * This is a Team Submission\n * Here are the links to our teams Kernels:\n     - https://www.kaggle.com/jiteshpabla/scoring-cord-19-using-google-training-on-scibert/\n     - https://www.kaggle.com/ashwinambal96/scibert-based-article-identification\n     - https://www.kaggle.com/hongguan/micro-scorers-for-covid-19-open-challenge/\n     - https://www.kaggle.com/mihir3031/bert-sts-for-searching-relevant-research-papers\n     - https://www.kaggle.com/loccapollo/lexicon-based-similarity-scoring-with-bert-biobert\n     - The final ensembling that combines everything together: http://https://www.kaggle.com/hongguan/ensemble-model-for-covid-19-open-challenge/\n "},{"metadata":{},"cell_type":"markdown","source":"# Introduction\nThis repository deals with the \"cord19-vaccines-and-therapeutics\" dataset which is based on the [\"What do we know about vaccines and therapeutics?\"](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge/tasks?taskId=561) task of the COVID-19 Open Research Dataset Challenge (CORD-19)."},{"metadata":{},"cell_type":"markdown","source":"# Part 1: prepare a csv for elasticBERT"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dfm = pd.read_csv(\"/kaggle/input/CORD-19-research-challenge/metadata.csv\")\ndfm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fill the blanks with a placehonder character\ndfm = dfm.fillna(\"x\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Take only the title and abstract (only these 2 will be used for elasticBERT for now. A combination of title+journal and only abstacts were tried but by a manual analysis, title+abstract seems to work the best."},{"metadata":{"trusted":true},"cell_type":"code","source":"df2 = dfm[['title', 'abstract']]\n#make sure both coulms are strings\ndf2.title = df2.title.astype(str)\ndf2.abstract = df2.abstract.astype(str)\ndf2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"OUtput the final file to be used for elasticBERT"},{"metadata":{"trusted":true},"cell_type":"code","source":"import csv\ndf2.to_csv('metadata_out.csv', index=False, quotechar='\"', quoting=csv.QUOTE_NONNUMERIC)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Part 2: elasticBERT\n\nThe code for elasticBERT and the instructions for running it can be found here: [repository for the full team](https://github.com/md-labs/covid19-kaggle)\nor you could easily clone it form [elasticBERT standalone repository](https://github.com/jiteshpabla/elasticbert) and run it locally with the instructions given.\n\nThe code is based on docker and takes significant time to run, hence it has not been put into the kernel yet.\n\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"The goal is to find the most relevant articles related to \"vaccines\" and \"therapeutics\". So In the elasticBERT code, the queries I used are:\n* vaccines\n* coronavirus vaccine\n* coronavirus therapeutics\n* therapeutics\n\nThe first 1000 relevant articles are taken from each query."},{"metadata":{},"cell_type":"markdown","source":"ElasticBERT is basically uses any BERT model (here, BERT-cased-768 is used) to generate an output vector for each title+abstract combination for each sample in the metadata file.\n\nThen, it uses the same BERT model to generate a vector for the query and then calculates the cosine similarity between the query vector and the title+abstract vector for each sample to get the most relevant articles/samples.\n\nThis method helps run queries extremely fast and its main advantage is running many different queries to answer different questions (like the many questions in all of the CORD-19 tasks) is a streamlined fashion.\nBut currently, the focus is only on a few queries (as a part of only one CORD-19 task)."},{"metadata":{},"cell_type":"markdown","source":"# Part 3: converting elasticBERT scores to classes"},{"metadata":{},"cell_type":"markdown","source":"### part 3-a: loading and cleanup"},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_DIR = \"/kaggle/input/cord19-elasticbert-query-results/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vdf = pd.read_csv(DATA_DIR+\"BERT_vaccines.csv\")\ntdf = pd.read_csv(DATA_DIR+\"BERT_therapeutics.csv\")\nvdf2 = pd.read_csv(DATA_DIR+\"BERT_coronavirus vaccine.csv\")\ntdf2 = pd.read_csv(DATA_DIR+\"BERT_coronavirus therapeutics.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The output of elasticBERT needs to be cleaned up and the title and abstract need to be separated"},{"metadata":{"trusted":true},"cell_type":"code","source":"def cleanup(df):\n  df[['abstract','title']] = df._source.str.split(\"'title':\",expand=True)\n  df[\"title\"] = df.title.str[2:-2]\n  df[\"abstract\"] = df.abstract.str[14:-3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cleanup(vdf)\ncleanup(vdf2)\ncleanup(tdf)\ncleanup(tdf2)\nvdf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"get the titles from the metadata file"},{"metadata":{"trusted":true},"cell_type":"code","source":"metadf_title= dfm[[\"title\"]]\n#metadf_title = metadf_title.drop_duplicates()\nmetadf_title","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### part 3-b: For vaccine class"},{"metadata":{},"cell_type":"markdown","source":"merge the 2 vdf's and take max score"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"\nmerged_vdf = vdf.merge(vdf2, on=['title'], \n                   how='inner', indicator=True, suffixes=('', '_y'))\nmerged_vdf[\"score\"] = merged_vdf[[\"_score\", \"_score_y\"]].values.max(1)\nmerged_vdf.drop(list(merged_vdf.filter(regex='_y$')), axis=1, inplace=True)\nmerged_vdf = merged_vdf[[\"title\", \"score\"]]\nmerged_vdf.drop_duplicates(inplace=True)\nmerged_vdf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vdf_concat = pd.concat([vdf, vdf2])\n#vdf_concat = vdf_concat[[\"title\"]]\nvdf_concat.drop_duplicates(subset=[\"title\"], inplace=True)\nvdf_concat[\"score\"] = vdf_concat[\"_score\"]\nvdf_concat = vdf_concat[[\"title\", \"score\"]]\nvdf_concat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vdf_concat2 = vdf_concat.merge(merged_vdf, on =[\"title\"], how = 'outer' ,indicator=True).loc[lambda x : x['_merge']=='left_only']\nvdf_concat2[\"score\"] = vdf_concat2[\"score_x\"]\nvdf_concat2 = vdf_concat2[[\"title\", \"score\"]]\nvdf_concat2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vdf_final = pd.concat([vdf_concat2, merged_vdf])\nvdf_final.drop_duplicates(subset=[\"title\"],inplace=True)\nvdf_final","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### part 3-c: For therpeutics class"},{"metadata":{},"cell_type":"markdown","source":"merge the 2 tdf's and take max score"},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_tdf = tdf.merge(tdf2, on=['title'], \n                   how='inner', indicator=True, suffixes=('', '_y'))\nmerged_tdf[\"score\"] = merged_tdf[[\"_score\", \"_score_y\"]].values.max(1)\nmerged_tdf.drop(list(merged_tdf.filter(regex='_y$')), axis=1, inplace=True)\nmerged_tdf = merged_tdf[[\"title\", \"score\"]]\nmerged_tdf.drop_duplicates(inplace=True)\nmerged_tdf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tdf_concat = pd.concat([tdf, tdf2])\n#tdf_concat = tdf_concat[[\"title\"]]\ntdf_concat.drop_duplicates(subset=[\"title\"], inplace=True)\ntdf_concat[\"score\"] = tdf_concat[\"_score\"]\ntdf_concat = tdf_concat[[\"title\", \"score\"]]\ntdf_concat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tdf_concat2 = tdf_concat.merge(merged_tdf, on =[\"title\"], how = 'outer' ,indicator=True).loc[lambda x : x['_merge']=='left_only']\ntdf_concat2[\"score\"] = tdf_concat2[\"score_x\"]\ntdf_concat2 = tdf_concat2[[\"title\", \"score\"]]\ntdf_concat2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tdf_final = pd.concat([tdf_concat2, merged_tdf])\ntdf_final.drop_duplicates(subset=[\"title\"],inplace=True)\ntdf_final","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### part 3-d: Merging the 2 extracted classes with metadata"},{"metadata":{"trusted":true},"cell_type":"code","source":"metadf_final = metadf_title\nmetadf_final[\"class\"] = 0\nmetadf_final","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#the common ones between VACNNIES AND THERPEUTICS\nmerged_all = tdf_final.merge(vdf_final, on=['title'], \n                   how='inner', indicator=True, suffixes=('', '_y'))\nmerged_all.drop(list(merged_all.filter(regex='_y$')), axis=1, inplace=True)\n#merged_all.drop_duplicates(inplace=True)\nmerged_all","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is an overlap of articles between the \"vaccines\" and \"therapeutics\", our current classificiation ensemble bythe whole team does not cater to 2 samples having the same class (the \"both\" class) yet, so we split the 1268 samples into the 2 classes based on the maximum cosine similarity score."},{"metadata":{"trusted":true},"cell_type":"code","source":"x = y = 0\nfor i, row in metadf_final.iterrows():\n  if (row[\"title\"] in vdf_final.values) and (row[\"title\"] in tdf_final.values):\n    #vdf_final.loc[df['title'] == row[\"title\"]]\n    vi = vdf_final.index[vdf_final['title'] == row[\"title\"]].tolist()[0]\n    ti = tdf_final.index[tdf_final['title'] == row[\"title\"]].tolist()[0]\n    #print(vdf_final.iloc[vi].score, tdf_final.iloc[ti].score)\n    if vdf_final.iloc[vi].score >= tdf_final.iloc[ti].score:\n      metadf_final.loc[i,'class'] = 1\n      x = x+1\n    else:\n      metadf_final.loc[i,'class'] = 2\n      y = y+1\n  elif row[\"title\"] in vdf_final.values:\n    metadf_final.loc[i,'class'] = 1\n  elif row[\"title\"] in tdf_final.values:\n    metadf_final.loc[i,'class'] = 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"common articles split into virus and therapeutics respectively\")\nprint(x,y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The final output:"},{"metadata":{"trusted":true},"cell_type":"code","source":"metadf_final","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"(optinal) query the metadata fot see the final classes****"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"#rename column to support query syntax\nmetadf_final = metadf_final.rename(columns={\"class\": \"classif\"}, errors=\"raise\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metadf_final.query(\"`classif` == 1\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metadf_final.query(\"`classif` == 2\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}