{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as ex\n\n%matplotlib inline\nsns.set_style(\"darkgrid\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/daily-temperature-of-major-cities/city_temperature.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"### Looking At The Variables\n\n> This dataset provides Average Temprature for different Region, Country, State and City. The is time series format is also there so there are multiple ways to look at it. I'll try to divide my notebook into three parts, Univariate, Bivariate and Multivariate data visualizations.\n\n> This notebook won't provide answers to specific questions instead i'll try to create visualizations that'll help creating intuition about the data.\n\n> Also i'm assuming unit of measure is Celsius. (Correct me if i'm wrong ðŸ˜…)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Data Types**","execution_count":null},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Null Values**","execution_count":null},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Looks like there's a small error in Year column, minimum value is 200. It may be 2000 so replacing it should be a not the best idea but it'll help the visualization process a bit.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print (f\"Unique Years : {df.Year.unique()}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> So there are two anomalies in year column. 200 and 201 which maybe year 2000 and 2010. So i'll replace them.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"mask = df.Year == 200\ndf.loc[mask,\"Year\"] = 2000\n\nmask = df.Year == 201\ndf.loc[mask,\"Year\"] = 2010","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Another thing is day, which has minimum value of 0 i think it'a some sort of mistake so i'll replace it with 1.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Day.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"mask = df.Day == 0\ndf.loc[mask,\"Day\"] = 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Univariate Exploration\n\n> Starting with univariate exploration i'll try to create visualizations that will help us gain some abstract about the data.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print (f\"Total Regions : {df.Region.nunique()}\")\nprint (f\"Total Countries : {df.Country.nunique()}\")\nprint (f\"Total Cities : {df.City.nunique()}\")\n\nprint (f\"\\nWe have data of total {df.Year.nunique()} years starting from {df.Year.min()} to {df.Year.max()}.\")\nprint (f\"The temperature ranges from {df.AvgTemperature.min()} áµ’C to {df.AvgTemperature.max()} áµ’C\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Counting","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"regions = df.Region.value_counts()\n\nplt.figure(figsize=(12,4))\nsns.barplot(regions.values,regions.index,color=\"#3498db\")\nplt.title(\"Data Amount From Various Regions\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"> Most of the data comes from north america and and i assume it'll be from USA. And we have way less data for Austria / South Pacific.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"countries = df.Country.value_counts()\n\nplt.figure(figsize=(12,36))\nsns.barplot(countries.values,countries.index,color=\"#3498db\")\nplt.title(\"Data Amount From Various Countries\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> As per my assumption the biasness in the data is mostly because of US. Also we have close to no data for Serbia-Montenegro.\n\n> Now There are so many cities so instead of plotting a bar for every single city i'll plot only top 25 and bottom 25 cities from the data.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"cities = df.City.value_counts().sort_values(ascending=False)\nfig,axes = plt.subplots(2,1,figsize=(14,18))\n\nax = sns.barplot(cities.head(25).index,cities.head(25).values,color=\"#3498db\",ax=axes[0])\nax.set_xticklabels(ax.get_xticklabels(),rotation=60)\nax = sns.barplot(cities.tail(25).index,cities.tail(25).values,color=\"#3498db\",ax=axes[1])\nax.set_xticklabels(ax.get_xticklabels(),rotation=60);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> City with the most number of records is Washington and with the least records is Bonn. Now we have idea about regions coutries and cities let's look at the time data.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"years = df['Year'].value_counts()\n\nplt.figure(figsize=(14,6))\nsns.barplot(years.index,years.values,color=\"#3498db\")\nplt.title(\"Number Of Records For Every Year\")\nplt.xticks(rotation=45);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"> We have pretty much same amount of data for every year except 2020. So there's no biasness in here.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"months = df.Month.value_counts()\n\nplt.figure(figsize=(14,6))\nsns.barplot(months.index,months.values,color=\"#3498db\")\nplt.title(\"Number Of Records For Every Month\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"day = df.Day.value_counts()\n\nplt.figure(figsize=(14,6))\nsns.barplot(day.index,day.values,color=\"#3498db\")\nplt.title(\"Number Of Records For Every Day\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> I can say that there's no biasness in time data but still making assumtions based on time data for the whole world will be bad since most of the data is from US and north american countries. \n\n> Let's see Temperature distribution.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(14,6))\nsns.distplot(df.AvgTemperature)\nplt.title(\"Temperature Distribution\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Looking at the distribution it's almost normal accept for -100 $^{\\circ}$C since we have data from south pacific. So if we want to perform analysis based on some questions they should be specific for a region, country or a city maybe since data is polarizing for different places.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Bivariate Exploration\n\n> In this section i'll try to find relationships between different variables starting temperature over the years.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"temp = df[['Year','AvgTemperature']]\ngroup = temp.groupby(\"Year\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"mean_temp = group.mean()\nplt.figure(figsize=(14,5))\nsns.lineplot(mean_temp.index,mean_temp.AvgTemperature,color=\"#2ecc71\")\nplt.xticks(mean_temp.index,rotation=90)\nplt.title(\"Average Temperature For Every Year\");\n\nmax_temp = group.max()\nplt.figure(figsize=(14,5))\nsns.lineplot(max_temp.index,max_temp.AvgTemperature,color=\"#2ecc71\")\nplt.xticks(max_temp.index,rotation=90)\nplt.title(\"Maximum Temperature For Every Year\");\n\nmin_temp = group.min()\nplt.figure(figsize=(14,5))\nsns.lineplot(min_temp.index,min_temp.AvgTemperature,color=\"#2ecc71\")\nplt.xticks(min_temp.index,rotation=90)\nplt.title(\"Minimun Temperature For Every Year\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Average temperature throughout the year is increasing with every year but it has slight decrease after year 2017 in both year 2018 and 2019. And since the whole COVID-19 situation i think it will gradually decrease this year also.\n\n> Maximum temperature for every year shows no significant difference between years except for the year 2001 it had a little drop compared to other years.\n\n> Minmum temperature for every year hasn't changed at all it's been -99 $^{\\circ}$C for years. Maybe analyzing it for a certain region, country or city would be a better option.\n\n> Let's plot same for the months and see how the temprature changes during the year.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"temp = df[['Month','AvgTemperature']]\ngroup = temp.groupby(\"Month\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"mean_temp = group.mean()\nplt.figure(figsize=(14,5))\nsns.lineplot(mean_temp.index,mean_temp.AvgTemperature,color=\"#2ecc71\")\nplt.xticks(mean_temp.index,rotation=90)\nplt.title(\"Average Temperature For Every Month\");\n\nmax_temp = group.max()\nplt.figure(figsize=(14,5))\nsns.lineplot(max_temp.index,max_temp.AvgTemperature,color=\"#2ecc71\")\nplt.xticks(max_temp.index,rotation=90)\nplt.title(\"Maximum Temperature For Every Month\");\n\nmin_temp = group.min()\nplt.figure(figsize=(14,5))\nsns.lineplot(min_temp.index,min_temp.AvgTemperature,color=\"#2ecc71\")\nplt.xticks(min_temp.index,rotation=90)\nplt.title(\"Minimun Temperature For Every Month\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> As expected the average temperature for months throughout the yaer is a gaussian curve. \n\n> Also looking at maximum temperature for different insight won't make any sense since also a gaussian curve throughout the year. And nothing changes for minimum temperatures.\n\n> I don't think plotting the same graphs for day will give us any proper insight. so let's move on regions. Let's find out minimum,maximum and average temperatures for different regions.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"temp = df[['Region','Country','City','AvgTemperature']]\ngroup = temp.groupby(['Region'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"min_temp = group.mean()\nplt.figure(figsize=(14,5))\nsns.barplot(min_temp.index,min_temp.AvgTemperature,color=\"#2ecc71\")\nplt.xticks(rotation=60)\nplt.title(\"Average Temperature For Every Region\");\n\nrows = []\nfor region in group.groups.keys():\n    g = group.get_group(region)\n    rows.append(g[g.AvgTemperature.max() == g.AvgTemperature].values[0])\n    \nt = pd.DataFrame(rows,columns=['Region','Country','City','Temp'])\n\nplt.figure(figsize=(14,5))\np = sns.barplot(t.Region,t.Temp,color=\"#2ecc71\")\nplt.xticks(rotation=60)\nplt.title(\"Maximum Temperature For Every Region\");\n\nfor index, row in t.iterrows():\n    p.text(index,35, f\"{row.City}, {row.Country}\", color='#333', ha=\"center\",rotation=90)\n    \n    \n\nrows = []\nfor region in group.groups.keys():\n    g = group.get_group(region)\n    rows.append(g[g.AvgTemperature.min() == g.AvgTemperature].values[0])\n    \nt = pd.DataFrame(rows,columns=['Region','Country','City','Temp'])\n\nplt.figure(figsize=(14,5))\np = sns.barplot(t.Region,t.Temp,color=\"#2ecc71\")\nplt.xticks(rotation=60)\nplt.title(\"Minimum Temperature For Every Region\");\n\nfor index, row in t.iterrows():\n    p.text(index,-65, f\"{row.City}, {row.Country}\", color='#333', ha=\"center\",rotation=90)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"> Average temperature for every region is closely similar , europe being the lowest. I also put the name of country and city with both minimum and maximum temperature so it could give a more clear idea about that region.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"> Plotting the same for country or city would be too messy so for this notebook i'll move ahead.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Multivariate Exploration.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I'm mostly a deep learning guy and i'm just trying my hand in data analytics so any sort of comment would be helpful ðŸ˜„.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}