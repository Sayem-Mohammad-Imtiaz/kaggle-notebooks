{"cells":[{"metadata":{"_uuid":"86e1ca3a-86b8-4c83-ad53-a1572844b181","_cell_guid":"5b17b28d-31b4-4b9b-a33b-04dcec7fa2aa","trusted":true},"cell_type":"markdown","source":"# ***Training Support Vector Machines for Multiclass Classification ***","execution_count":null},{"metadata":{"_uuid":"e753a642-9d59-4050-ba4e-9b5cfe40f3d1","_cell_guid":"5119f6c3-082a-4b72-b631-783e69e84c28","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nfrom sklearn.utils import shuffle\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix,classification_report\nfrom sklearn.model_selection import cross_val_score, GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b9c1fc59-11b0-4154-9ca9-b86f9acd015b","_cell_guid":"ac127a99-4728-4236-869e-a28c390d83fc","trusted":true},"cell_type":"markdown","source":"### Load the Train and Test set","execution_count":null},{"metadata":{"_uuid":"8b5f17d2-88b8-4623-98f3-7d2dcbd6fee8","_cell_guid":"8287f19b-78ea-42f9-b7b3-0a6ce33897c3","trusted":true},"cell_type":"code","source":"train = shuffle(pd.read_csv(\"../input/train.csv\"))\ntest = shuffle(pd.read_csv(\"../input/test.csv\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"106b9e56-2b6c-444f-9c91-0742d3ef343c","_cell_guid":"b28c76f8-ea58-4fed-a72b-cb7a35e1e519","trusted":true},"cell_type":"markdown","source":"### Frequency Distribution of the Outome","execution_count":null},{"metadata":{"_uuid":"5daab790-5215-460c-a5d2-dbed157bc646","_cell_guid":"d0f19d44-3c8c-4464-87cc-3e5a0b9b88c6","trusted":true},"cell_type":"code","source":"#Frequency distribution of classes\"\ntrain_outcome = pd.crosstab(index=train[\"Activity\"],  # Make a crosstab\n                              columns=\"count\")      # Name the count column\n\ntrain_outcome","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"14776589-8514-4820-9e71-93fbe8dc7c30","_cell_guid":"49f51cdc-5650-41dd-8d80-ab94b7aa1387","trusted":true},"cell_type":"markdown","source":"### Visualizing Outcome Distribution","execution_count":null},{"metadata":{"_uuid":"42ab4b35-1b44-485f-9ba4-d5f860e86a05","_cell_guid":"41147226-4d43-41a9-9950-3ffc4338a9c2","trusted":true},"cell_type":"code","source":"temp = train[\"Activity\"].value_counts()\ndf = pd.DataFrame({'labels': temp.index,\n                   'values': temp.values})\n\n\nlabels = df['labels']\nsizes = df['values']\n\nx_pos = [i for i, _ in enumerate(labels)]\n\nplt.figure(1, [14, 6])\nplt.bar(x_pos, sizes,width=0.6)\nplt.xticks(x_pos, labels)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d58f5620-ccc2-412f-8be8-130fe32a48b2","_cell_guid":"7049b76a-83b0-4ea8-bc9c-3f9ffcf9c61e","trusted":true},"cell_type":"markdown","source":"### Normalize the Predictor(Feature Set) for SVM training","execution_count":null},{"metadata":{"_uuid":"2359631a-9fa0-40f1-925b-308cba0c675b","_cell_guid":"a0a8c377-7164-49fe-8fe2-6750d4073cdf","trusted":true},"cell_type":"code","source":"# Seperating Predictors and Outcome values from train and test sets\nX_train = pd.DataFrame(train.drop(['Activity','subject'],axis=1))\nY_train_label = train.Activity.values.astype(object)\n\nX_test = pd.DataFrame(test.drop(['Activity','subject'],axis=1))\nY_test_label = test.Activity.values.astype(object)\n\n# Dimension of Train and Test set \nprint(\"Dimension of Train set\",X_train.shape)\nprint(\"Dimension of Test set\",X_test.shape,\"\\n\")\n\n# Transforming non numerical labels into numerical labels\nfrom sklearn import preprocessing\nencoder = preprocessing.LabelEncoder()\n\n# encoding train labels \nencoder.fit(Y_train_label)\nY_train = encoder.transform(Y_train_label)\n\n# encoding test labels \nencoder.fit(Y_test_label)\nY_test = encoder.transform(Y_test_label)\n\n#Total Number of Continous and Categorical features in the training set\nnum_cols = X_train._get_numeric_data().columns\nprint(\"Number of numeric features:\",num_cols.size)\n#list(set(X_train.columns) - set(num_cols))\n\n\nnames_of_predictors = list(X_train.columns.values)\n\n# Scaling the Train and Test feature set \nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b671b50d-9d9a-4561-bbef-bd5fe5092e2e","_cell_guid":"71228955-8387-405b-b0ca-3227df0f6fea","trusted":true},"cell_type":"markdown","source":"### Hyperparameter tuning using grid search and cross validation","execution_count":null},{"metadata":{"_uuid":"fe252310-fa2a-4faa-93fd-fc7122b11192","_cell_guid":"39e8e941-88d7-4bab-9267-56aa1265fd92","trusted":true},"cell_type":"code","source":"'''\n#Libraries to Build Ensemble Model : Random Forest Classifier \n# Create the parameter grid based on the results of random search \nparams_grid = [{'kernel': ['rbf'], 'gamma': [1e-1, 1e-2, 1e-3, 1e-4],'C': [1, 10, 100, 1000]},\n               {'kernel': ['linear'], 'C': [1, 10, 100, 1000]},\n               {'kernel': ['poly'],'gamma': [1e-1, 1e-2, 1e-3, 1e-4], 'degree' : [3, 4, 5, 6], 'C': [1, 10, 100, 1000]},\n               {'kernel': ['sigmoid'],'gamma': [1e-1, 1e-2, 1e-3, 1e-4], 'C': [1, 10, 100, 1000]}]\n'''","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7ebea6ae-58e4-4b9b-9f5b-e2dd866b66b7","_cell_guid":"261bf07e-b314-4e62-a598-431a2cb9cd4a","trusted":true},"cell_type":"markdown","source":"### Training SVM model using radial kernel","execution_count":null},{"metadata":{"_uuid":"1b87cb1b-ca7e-44cb-8ca0-0b2e4c4b4ce8","_cell_guid":"ab95e3b3-1403-4783-b548-8f819e60ad2a","trusted":true},"cell_type":"code","source":"'''\n# Performing CV to tune parameters for best SVM fit \nsvm_model = GridSearchCV(SVC(), params_grid, cv=2, verbose=10, n_jobs=6)\nsvm_model.fit(X_train_scaled, Y_train)\n'''","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0f6af73b-ac85-4104-9079-5399ac6b38a2","_cell_guid":"e6ed5491-27a4-46cf-86ef-91fd9495f36e","trusted":true},"cell_type":"code","source":"final_model = SVC(kernel='rbf', gamma=0.001, C=1000)\nfinal_model.fit(X_train_scaled, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cd8ce291-e947-4808-8fc6-e87ec0ea7c54","_cell_guid":"177f3a7a-e455-420d-ad85-1b2fd1b889d8","trusted":true},"cell_type":"code","source":"Y_pred = final_model.predict(X_test_scaled)\nY_pred_label = list(encoder.inverse_transform(Y_pred))\n\nprint(\"Training set score for SVM: %f\" % final_model.score(X_train_scaled , Y_train))\nprint(\"Testing  set score for SVM: %f\" % final_model.score(X_test_scaled  , Y_test ))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"68731589-4536-490a-932f-abb2e79ec01d","_cell_guid":"602520e4-fa95-4312-9bf3-ecdc06c11310","trusted":true},"cell_type":"markdown","source":"### Confusion Matrix  and Accuracy Score","execution_count":null},{"metadata":{"_uuid":"3ca9e5da-ead8-40d6-a914-a560c6b71337","_cell_guid":"42235481-cb30-4ed4-bc1e-84921c7cbe7d","trusted":true},"cell_type":"code","source":"'''\n# View the accuracy score\nprint('Best score for training data:', svm_model.best_score_,\"\\n\") \n\n# View the best parameters for the model found using grid search\nprint('Best C:',svm_model.best_estimator_.C,\"\\n\") \nprint('Best Kernel:',svm_model.best_estimator_.kernel,\"\\n\")\nprint('Best Gamma:',svm_model.best_estimator_.gamma,\"\\n\")\n\nfinal_model = svm_model.best_estimator_\nY_pred = final_model.predict(X_test_scaled)\nY_pred_label = list(encoder.inverse_transform(Y_pred))\n'''","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d5cdacc5-8917-4907-ba11-1a52dd71ea3b","_cell_guid":"018ec41b-defb-4ceb-ad90-efd10ff4b173","trusted":true},"cell_type":"code","source":"# Making the Confusion Matrix\nprint(confusion_matrix(Y_test_label,Y_pred_label))\nprint(\"\\n\")\nprint(classification_report(Y_test_label,Y_pred_label))\n\nprint(\"Training set score for SVM: %f\" % final_model.score(X_train_scaled , Y_train))\nprint(\"Testing  set score for SVM: %f\" % final_model.score(X_test_scaled  , Y_test ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.utils.multiclass import unique_labels\n\n\ndef plot_confusion_matrix(y_true, y_pred, classes,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    \n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Compute confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    \n    # Only use the labels that appear in the data\n    classes = unique_labels(y_true, y_pred)\n    \n    \n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    fig, ax = plt.subplots(figsize=(10, 10))\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           # ... and label them with the respective list entries\n           xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n    # Rotate the tick labels and set their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n\n    # Loop over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1f0dc218-c00d-4e1a-b0f2-07f3afac9945","_cell_guid":"ecdc9294-4e7e-4491-8671-866af415f0c0","trusted":true},"cell_type":"code","source":"np.set_printoptions(precision=2)\n\n\n# Plot non-normalized confusion matrix\nplot_confusion_matrix(Y_test_label, Y_pred_label, classes=labels,\n                      title='Confusion matrix, without normalization')\n\n# Plot normalized confusion matrix\nplot_confusion_matrix(Y_test_label, Y_pred_label, classes=labels, normalize=True,\n                      title='Normalized confusion matrix')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}