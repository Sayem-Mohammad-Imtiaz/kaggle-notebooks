{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# import the necessary packages\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Dense\n\nclass TrafficSignNet:\n\t@staticmethod\n\tdef build(width, height, depth, classes):\n\t\t# initialize the model along with the input shape to be\n\t\t# \"channels last\" and the channels dimension itself\n\t\tmodel = Sequential()\n\t\tinputShape = (height, width, depth)\n\t\tchanDim = -1\n\n\t\t# CONV => RELU => BN => POOL\n\t\tmodel.add(Conv2D(8, (5, 5), padding=\"same\",\n\t\t\tinput_shape=inputShape))\n\t\tmodel.add(Activation(\"relu\"))\n\t\tmodel.add(BatchNormalization(axis=chanDim))\n\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n\t\t# first set of (CONV => RELU => CONV => RELU) * 2 => POOL\n\t\tmodel.add(Conv2D(16, (3, 3), padding=\"same\"))\n\t\tmodel.add(Activation(\"relu\"))\n\t\tmodel.add(BatchNormalization(axis=chanDim))\n\t\tmodel.add(Conv2D(16, (3, 3), padding=\"same\"))\n\t\tmodel.add(Activation(\"relu\"))\n\t\tmodel.add(BatchNormalization(axis=chanDim))\n\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n\t\t# second set of (CONV => RELU => CONV => RELU) * 2 => POOL\n\t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\"))\n\t\tmodel.add(Activation(\"relu\"))\n\t\tmodel.add(BatchNormalization(axis=chanDim))\n\t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\"))\n\t\tmodel.add(Activation(\"relu\"))\n\t\tmodel.add(BatchNormalization(axis=chanDim))\n\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n\t\t# first set of FC => RELU layers\n\t\tmodel.add(Flatten())\n\t\tmodel.add(Dense(128))\n\t\tmodel.add(Activation(\"relu\"))\n\t\tmodel.add(BatchNormalization())\n\t\tmodel.add(Dropout(0.5))\n\n\t\t# second set of FC => RELU layers\n\t\tmodel.add(Flatten())\n\t\tmodel.add(Dense(128))\n\t\tmodel.add(Activation(\"relu\"))\n\t\tmodel.add(BatchNormalization())\n\t\tmodel.add(Dropout(0.5))\n\n\t\t# softmax classifier\n\t\tmodel.add(Dense(classes))\n\t\tmodel.add(Activation(\"softmax\"))\n\n\t\t# return the constructed network architecture\n\t\treturn model","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"import pandas as pd\nMeta = pd.read_csv(\"../input/gtsrb-german-traffic-sign/Meta.csv\")\nTest = pd.read_csv(\"../input/gtsrb-german-traffic-sign/Test.csv\")\nTrain = pd.read_csv(\"../input/gtsrb-german-traffic-sign/Train.csv\")\nsignnames = pd.read_csv(\"../input/signnames/signnames.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# USAGE\n# python train.py --dataset gtsrb-german-traffic-sign --model output/trafficsignnet.model --plot output/plot.png\n\n# set the matplotlib backend so figures can be saved in the background\nimport matplotlib\nmatplotlib.use(\"Agg\")\n\n# import the necessary packages\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.metrics import classification_report\nfrom skimage import transform\nfrom skimage import exposure\nfrom skimage import io\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport argparse\nimport random\nimport os\n\ndef load_split(basePath, csvPath):\n\t# initialize the list of data and labels\n\tdata = []\n\tlabels = []\n\n\t# load the contents of the CSV file, remove the first line (since\n\t# it contains the CSV header), and shuffle the rows (otherwise\n\t# all examples of a particular class will be in sequential order)\n\trows = open(csvPath).read().strip().split(\"\\n\")[1:]\n\trandom.shuffle(rows)\n\n\t# loop over the rows of the CSV file\n\tfor (i, row) in enumerate(rows):\n\t\t# check to see if we should show a status update\n\t\tif i > 0 and i % 1000 == 0:\n\t\t\tprint(\"[INFO] processed {} total images\".format(i))\n\n\t\t# split the row into components and then grab the class ID\n\t\t# and image path\n\t\t(label, imagePath) = row.strip().split(\",\")[-2:]\n\n\t\t# derive the full path to the image file and load it\n\t\timagePath = os.path.sep.join([basePath, imagePath])\n\t\timage = io.imread(imagePath)\n\n\t\t# resize the image to be 32x32 pixels, ignoring aspect ratio,\n\t\t# and then perform Contrast Limited Adaptive Histogram\n\t\t# Equalization (CLAHE)\n\t\timage = transform.resize(image, (32, 32))\n\t\timage = exposure.equalize_adapthist(image, clip_limit=0.1)\n\n\t\t# update the list of data and labels, respectively\n\t\tdata.append(image)\n\t\tlabels.append(int(label))\n\n\t# convert the data and labels to NumPy arrays\n\tdata = np.array(data)\n\tlabels = np.array(labels)\n\n\t# return a tuple of the data and labels\n\treturn (data, labels)\n\n\ndataset = \"../input/gtsrb-german-traffic-sign\"\nmodel_path = \"../working/trafficsignnet.model\"\nplot = \"../working/plot.png\"\n\n# initialize the number of epochs to train for, base learning rate,\n# and batch size\nNUM_EPOCHS = 30\nINIT_LR = 1e-3\nBS = 64\n\n# load the label names\nlabelNames = open(\"../input/signnames/signnames.csv\").read().strip().split(\"\\n\")[1:]\nlabelNames = [l.split(\",\")[1] for l in labelNames]\n\n# derive the path to the training and testing CSV files\ntrainPath = os.path.sep.join([dataset, \"Train.csv\"])\ntestPath = os.path.sep.join([dataset, \"Test.csv\"])\n\n# load the training and testing data\nprint(\"[INFO] loading training and testing data...\")\n(trainX, trainY) = load_split(dataset, trainPath)\n(testX, testY) = load_split(dataset, testPath)\n\n# scale data to the range of [0, 1]\ntrainX = trainX.astype(\"float32\") / 255.0\ntestX = testX.astype(\"float32\") / 255.0\n\n# one-hot encode the training and testing labels\nnumLabels = len(np.unique(trainY))\ntrainY = to_categorical(trainY, numLabels)\ntestY = to_categorical(testY, numLabels)\n\n# account for skew in the labeled data\nclassTotals = trainY.sum(axis=0)\nclassWeight = classTotals.max() / classTotals\n\n# construct the image generator for data augmentation\naug = ImageDataGenerator(\n\trotation_range=10,\n\tzoom_range=0.15,\n\twidth_shift_range=0.1,\n\theight_shift_range=0.1,\n\tshear_range=0.15,\n\thorizontal_flip=False,\n\tvertical_flip=False,\n\tfill_mode=\"nearest\")\n\n# initialize the optimizer and model\nprint(\"[INFO] compiling model...\")\nopt = Adam(lr=INIT_LR, decay=INIT_LR / (NUM_EPOCHS * 0.5))\nmodel = TrafficSignNet.build(width=32, height=32, depth=3,\n\tclasses=numLabels)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n\tmetrics=[\"accuracy\"])\n\n# compile the model and train the network\nprint(\"[INFO] training network...\")\nH = model.fit_generator(\n\taug.flow(trainX, trainY, batch_size=BS),\n\tvalidation_data=(testX, testY),\n\tsteps_per_epoch=trainX.shape[0] // BS,\n\tepochs=NUM_EPOCHS,\n\tclass_weight=classWeight,\n\tverbose=1)\n\n# evaluate the network\nprint(\"[INFO] evaluating network...\")\npredictions = model.predict(testX, batch_size=BS)\nprint(classification_report(testY.argmax(axis=1),\n\tpredictions.argmax(axis=1), target_names=labelNames))\n\n# save the network to disk\nprint(\"[INFO] serializing network to '{}'...\".format(model))\nmodel.save(model_path)\n\n# plot the training loss and accuracy\nN = np.arange(0, NUM_EPOCHS)\nplt.style.use(\"ggplot\")\nplt.figure()\nplt.plot(N, H.history[\"loss\"], label=\"train_loss\")\nplt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(N, H.history[\"accuracy\"], label=\"train_acc\")\nplt.plot(N, H.history[\"val_accuracy\"], label=\"val_acc\")\nplt.title(\"Training Loss and Accuracy on Dataset\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss/Accuracy\")\nplt.legend(loc=\"lower left\")\nplt.savefig(plot)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install imutils","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# USAGE\n# python predict.py --model output/trafficsignnet.model --images gtsrb-german-traffic-sign/Test --examples examples\n\n# import the necessary packages\nfrom tensorflow.keras.models import load_model\nfrom skimage import transform\nfrom skimage import exposure\nfrom skimage import io\nfrom imutils import paths\nimport numpy as np\nimport argparse\nimport imutils\nimport random\nimport cv2\nimport os\n\n\nexample = \"../working\"\nimages_path = \"../input/gtsrb-german-traffic-sign/Test\" \n\n# load the traffic sign recognizer model\nprint(\"[INFO] loading model...\")\nmodel = load_model(model_path)\n\n# load the label names\nlabelNames = open(\"../input/signnames/signnames.csv\").read().strip().split(\"\\n\")[1:]\nlabelNames = [l.split(\",\")[1] for l in labelNames]\n\n# grab the paths to the input images, shuffle them, and grab a sample\nprint(\"[INFO] predicting...\")\nprint(images_path)\nimagePaths = list(paths.list_images(images_path))\nrandom.shuffle(imagePaths)\nimagePaths = imagePaths[:25]\n\n# loop over the image paths\nfor (i, imagePath) in enumerate(imagePaths):\n\t# load the image, resize it to 32x32 pixels, and then apply\n\t# Contrast Limited Adaptive Histogram Equalization (CLAHE),\n\t# just like we did during training\n\timage = io.imread(imagePath)\n\timage = transform.resize(image, (32, 32))\n\timage = exposure.equalize_adapthist(image, clip_limit=0.1)\n\n\t# preprocess the image by scaling it to the range [0, 1]\n\timage = image.astype(\"float32\") / 255.0\n\timage = np.expand_dims(image, axis=0)\n\n\t# make predictions using the traffic sign recognizer CNN\n\tpreds = model.predict(image)\n\tj = preds.argmax(axis=1)[0]\n\tlabel = labelNames[j]\n\n\t# load the image using OpenCV, resize it, and draw the label\n\t# on it\n\timage = cv2.imread(imagePath)\n\timage = imutils.resize(image, width=128)\n\tcv2.putText(image, label, (5, 15), cv2.FONT_HERSHEY_SIMPLEX,\n\t\t0.45, (0, 0, 255), 2)\n\n\t# save the image to disk\n\tp = os.path.sep.join([example, \"{}.png\".format(i)])\n\tcv2.imwrite(p, image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}