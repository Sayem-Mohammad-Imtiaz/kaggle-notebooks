{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\nStock market sentiment analysis is an evolving technique which can be effectively used to compliment fundamental, quantitative and technical analysis.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Business Understanding \n\nMarket sentiment is a qualitative measure of the attitude and mood of investors to financial markets in general, and specific sectors or assets in particular. Positive and negative sentiment drive price action, and also create trading and investment opportunities for active traders and long-term investorsÂ¶","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import the packages","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport seaborn as sns\nsns.set()\n%matplotlib inline\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score \nfrom sklearn.metrics import classification_report\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk import word_tokenize, WordNetLemmatizer\nimport nltk\nimport re \nnltk.download('wordnet')\n  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Load in the data\ndata = pd.read_csv(\"../input/stockmarket-sentiment-dataset/stock_data.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Read the data\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Sentiment Value count \ndata[\"Sentiment\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Plot the Sentiment value count \nsns.countplot(data[\"Sentiment\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Lenght of the Text using KDEplot\nlenght = data[\"Text\"].str.len()\nsns.kdeplot(lenght)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Checking for stopwords\nfrom nltk.corpus import stopwords\nstop_words=set(stopwords.words(\"english\"))\nprint(stop_words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_list = list()\nfor i in range(len(data)):\n    lip = data.Text[i].split()\n    for k in lip:\n        word_list.append(k)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter \nwordCounter = Counter(word_list)\ncountedWordDict = dict(wordCounter)\nsortedWordDict = sorted(countedWordDict.items(),key = lambda x : x[1],reverse=True)\nsortedWordDict[0:20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud\nwordList2 = \" \".join(word_list)\nstop_word_Cloud = set(stopwords.words(\"english\"))\nwordcloud = WordCloud(stopwords=stop_word_Cloud,max_words=2000,background_color=\"white\",min_font_size=3).generate_from_frequencies(countedWordDict)\nplt.figure(figsize=[20,10])\nplt.axis(\"off\")\nplt.imshow(wordcloud)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocesing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Replacing the negative one with zero so our model can predict well\ndata[\"Sentiment\"] = data[\"Sentiment\"].replace(-1,0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Lets check our data again\ndata[\"Sentiment\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# NLP Processing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## NlP Processing\nps = PorterStemmer()\nlemma = WordNetLemmatizer()\nstopwordSet = set(stopwords.words(\"english\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Clean the text \ntext_reviews = list()\nfor i in range(len(data)):\n    text = re.sub('[^a-zA-Z]',\" \",data['Text'][i])\n    text = text.lower()\n    text = word_tokenize(text,language=\"english\")\n    text = [lemma.lemmatize(word) for word in text if(word) not in stopwordSet]\n    text = \" \".join(text)\n    text_reviews.append(text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Create the (B.O.W) bag of word model\ncv = CountVectorizer(max_features = 1500)\nX = cv.fit_transform(text_reviews).toarray()\ny= data['Sentiment']\n\n## Split the dataset into Training and Test set\nX_train, X_test, y_train, y_test = train_test_split(X, y , test_size=0.2, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelling and Predicting","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Logistic Regression\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\nY_pred = logreg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, Y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_test, Y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Naives baye multinomial\nclf = MultinomialNB()\nclf.fit(X_train, y_train)\nY_pred = clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, Y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_test, Y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Random Forest\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, y_train)\nY_pred = random_forest.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, Y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_test, Y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion\n\nRandom forest and MultinomialNB produced the predictions with the highest accuracy, at 79%, while logistic regression scored 78%.\n\n","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}