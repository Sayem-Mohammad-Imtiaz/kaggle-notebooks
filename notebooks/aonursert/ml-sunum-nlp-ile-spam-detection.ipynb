{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Natural Language Processing ile Basit Spam Detection","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Natural Language Processing işlemini sağlayan kütüphaneyi ekliyoruz.\nimport nltk","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bu çalışmada kullanılacak 'stopwords' paketini indirmemizi sağlayan kod.\nnltk.download_shell()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Veri temizleme için gerekli veri bilimi kütüphanelerini ekliyoruz.\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Mesajları kullanmak için bir değişkene aldık.\nmessages = pd.read_csv(\"../input/sms-spam-collection-dataset/spam.csv\", encoding=\"ISO-8859-1\")\nmessages.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gereksiz kolonları sildik ve gerekli kolonlara daha açıklayıcı isimler verdik.\nmessages = messages[[\"v1\", \"v2\"]]\nmessages = messages.rename(columns={\"v1\": \"label\", \"v2\": \"message\"})\nmessages.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Burada spam tespiti için yararlı olabilecek mesajın uzunluğunu her mesaj için bir satır olarak ekledik.\nmessages[\"length\"] = messages[\"message\"].apply(len)\nmessages.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Görüldüğü üzere mesajın uzunluğu, mesajın spam olup olmadığını belirlemek için iyi bir yöntem.\n# Çünkü bu grafiklerle spam mesajların daha uzun olduğu sonucuna vardık.\nmessages.hist(column=\"length\", by=\"label\", bins=60, figsize=(12,4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Natural language process için datasetimizi hazırlıyoruz.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Öncelikle noktalama işaretlerini kaldırmak için gerekli kütüphaneyi ekliyoruz.\nimport string\nstring.punctuation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bunlar İngilizce'de stopword'ler ve bir mesajın spam ya da olup olmadığına dair çok bilgi vermiyor.\n# Yani sıklıkla kullanılan bu kelimeleri de kaldırıyoruz.\nfrom nltk.corpus import stopwords\nstopwords.words(\"english\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def text_process(mess):\n    \"\"\"\n    1. Noktalama işaretlerini kaldırıyoruz.\n    2. Sıklıkla kullanılan kelimeleri (stopwords) kaldırıyoruz.\n    3. Geriye temiz spam tespitinde kullanılabilecek cümleyi döndürüyoruz.\n    \"\"\"\n    nopunc = [char for char in mess if char not in string.punctuation]\n    nopunc = \"\".join(nopunc)\n    nostopwords = [word for word in nopunc.split() if word.lower() not in stopwords.words(\"english\")]\n    nostopwords = \" \".join(nostopwords)\n    return nostopwords","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"messages.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sonucu görmek için sadece ilk 5 cümleyi temizliyoruz.\nmessages[\"message\"].head(5).apply(text_process)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Daha sonra temizleme işlemini bütün sütuna uyguluyoruz.\nmessages[\"message\"] = messages[\"message\"].apply(text_process)\nmessages.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bundan sonra metin halindeki verimiz hazır, tahminleme yapabilmek için bunları tam sayı değerleriyle ifade etmeliyiz.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n# bow (Bag Of Words): Kelimelerin, tam sayı değerleriyle ifade edilmesi.\nbow_transformer = CountVectorizer(analyzer=text_process).fit(messages[\"message\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Örneğin veri setindeki 4. cümleyi tam sayılarla ifade ediyoruz.\nmess4 = messages[\"message\"][3]\nprint(mess4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bow4 = bow_transformer.transform([mess4])\nprint(bow4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Şimdi bütün mesajların tam sayı değerleriyle ifade edildiği veriyi elde ediyoruz.\nmessages_bow = bow_transformer.transform(messages[\"message\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sayılarla ifade edilen kelimelerin ağırlıklarını yani ne sıklıkla görüldüğünü hesaplamak için TfidfTransformer kullanıyoruz.\n# Bu bize spam mesajlarda ağırlıklı olarak hangi kelimelerin kullanıldığı ve\n# Normal mesajlarda ağırlıklı olarak hangi kelimelerin kullanıldığına dair bilgi veriyor.\nfrom sklearn.feature_extraction.text import TfidfTransformer\ntfidf_transformer = TfidfTransformer().fit(messages_bow)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Öncelikle veri setindeki 4. cümlenin kelimelerinin tam sayı değerlerinin ağırlıklarını buluyoruz.\ntfidf4 = tfidf_transformer.transform(bow4)\nprint(tfidf4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Şimdi bütün mesajların tam sayı değerlerinin ağırlıklarının ifade edildiği veriyi elde ediyoruz.\nmessages_tfidf = tfidf_transformer.transform(messages_bow)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tahminlemeye geçebiliriz.\nfrom sklearn.naive_bayes import MultinomialNB\nspam_detect_model = MultinomialNB().fit(messages_tfidf, messages[\"label\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spam_detect_model.predict(tfidf4)[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"messages[\"label\"][3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MultinomialNB kullanarak veri setimizi eğittik ve kelime 4 için doğru sonuç elde ettik.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ancak tam olarak düzgün tahminleme yapmak için veri setimizi train ve test halinde ikiye bölüyoruz.\nfrom sklearn.model_selection import train_test_split\nmsg_train, msg_test, lbl_train, lbl_test = train_test_split(messages[\"message\"], messages[\"label\"], test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ardından üstteki işlemleri Pipeline kullanarak tekrar tahminleme işlemine kadar yapıyoruz.\nfrom sklearn.pipeline import Pipeline\npipeline = Pipeline([\n    (\"bow\", CountVectorizer(analyzer=text_process)),\n    (\"tfidf\", TfidfTransformer()),\n    (\"classifier\", MultinomialNB())\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pipeline ile otomatikleştirilmiş işlemler sayesinde verimizi eğitiyoruz.\npipeline.fit(msg_train, lbl_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Daha sonra verimizi tahminliyoruz.\npredictions = pipeline.predict(msg_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tahminlerimizin ne kadar doğru olduğunu kontrol ediyoruz.\nfrom sklearn.metrics import classification_report\nprint(classification_report(lbl_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Oldukça güzel bir sonuç çıktı.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline.predict([msg_test.iloc[10]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"messages.iloc[10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tek bir 10. cümleyi tahminleme için de sonuç doğru çıktı.","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}