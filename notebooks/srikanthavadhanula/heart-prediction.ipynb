{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Heart Prediction","metadata":{}},{"cell_type":"markdown","source":"Importing required libraries ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Reading the dataset using pandas into heart dataframe","metadata":{}},{"cell_type":"code","source":"heart = pd.read_csv('heart.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"heart.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looking at the first few data points, we can say that all the columns are numerical\n\nLets cross check by looking into info() of the dataframe","metadata":{}},{"cell_type":"code","source":"heart.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All the columns are of type int64 except the slope, which is float64","metadata":{}},{"cell_type":"markdown","source":"From the above info() details, we can tell that there are no null values\n\nBut still lets take the advantage of null method in pandas and check","metadata":{}},{"cell_type":"code","source":"heart.isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now lets check the measures of central tendency and also percentails of each feature ","metadata":{}},{"cell_type":"code","source":"heart.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets see wheather the data is balanced or not ","metadata":{}},{"cell_type":"code","source":"print(\"percentage of target people having heart problem :\"+str(heart.target.value_counts()[1]/len(heart.target)))\nprint(\"percentage of target people not having heart problem :\"+str(heart.target.value_counts()[0]/len(heart.target)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Based on the above result, we can say that the data is balanced","metadata":{}},{"cell_type":"code","source":"features = [\"age\",\"sex\",\"cp\",\"trestbps\",\"chol\",\"fbs\",\"restecg\",\"thalach\",\"exang\",\"oldpeak\",\"slope\",\"ca\",\"thal\",\"target\"]\n\nkind_of_cat = [\"sex\",\"cp\",\"fbs\",\"restecg\",\"exang\",\"slope\",\"ca\",\"thal\"]\n\n# The above features have 3/4 kinds of values, so lets plot borplot using seaborn\n\nplt.figure(figsize = (16,15))\nloc = 1\nfor feature in kind_of_cat:\n    plt.subplot(3,3,loc)\n    plt.title(feature)\n    sns.barplot(x = feature, y = \"target\", data = heart)\n    loc = loc +1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outliers = [\"age\",\"trestbps\",\"chol\",\"thalach\",\"oldpeak\"]\n# Lets see if there are any outliers in these continious features\nplt.figure(figsize = (16,10))\nloc = 1\nfor feature in outliers:\n    plt.subplot(2,3,loc)\n    sns.boxplot(x = feature, data = heart)\n    loc = loc + 1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above figure, we can see that we have quite a few outliers for trestbps, chol and oldpeak and only one outlier for thalach","metadata":{}},{"cell_type":"markdown","source":"As of now we are not handling the outliers.\n\nIf we want to handle the outliers, we can simply replace all the outlier datapoints with the 100 higher bond and lower bond values","metadata":{}},{"cell_type":"code","source":"# Lets see the correlation of the features\n\nplt.figure(figsize = (16,10))\nsns.heatmap(heart.corr(), annot = True)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dividing the dependent and independent features\n\nX = heart.drop('target', axis = 1)\ny = heart['target']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets split the data into train and test using train_test_split\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 42)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"X_train :\"+str(X_train.shape))\nprint(\"y_train :\"+str(y_train.shape))\nprint(\"X_test :\"+str(X_test.shape))\nprint(\"y_test :\"+str(y_test.shape))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets perform both Logestic Regression and Descision Tree\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LR = LogisticRegression()\n\nLR.fit(X_train, y_train)\nLR_pred = LR.predict(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DTC = DecisionTreeClassifier()\n\nDTC.fit(X_train, y_train)\nDTC_pred = DTC.predict(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"accuracy score of LR is :\"+str(accuracy_score(y_test , LR_pred)))\nprint(\"accuracy score of DTC is :\"+str(accuracy_score(y_test , DTC_pred)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Logistic Regression model has given better score compared to Decision Tree classifier","metadata":{}}]}