{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# import libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\npd.set_option('display.max_columns', 100)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Import data set\n\ncars = pd.read_csv('../input/usedcarscatalog/cars.csv')\ncars.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We dont what the features (0 to 9) are for. Hence dropping these features.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cars = cars.drop(columns=['feature_0','feature_1','feature_2','feature_3','feature_4','feature_5','feature_6','feature_7','feature_8','feature_9'], axis=1)\ncars.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Step 1:Basic Data Quality Checks","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cars.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cars.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cars.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cars.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cars.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are only 10 Null values for \"Engine Capacity\". \n\nDropping these null values.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cars = cars.dropna()\ncars.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No Null Values. We can proceed with EDA Now.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Step 2: EDA","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**2.1 Visualizing Numerical Data**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate the age of the car\n\ncars['age'] = 2020 - cars['year_produced']\ncars.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# All numeric (float and int) variables in the dataset\ncars_numeric = cars.select_dtypes(include=['float64', 'int64'])\ncars_numeric.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation matrix\ncor = cars_numeric.corr()\ncor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Figure size\nplt.figure(figsize=(16,8))\n\n# Heatmap\nsns.heatmap(cor, cmap=\"YlGnBu\", annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we can see that \"Year Produced\" or \"age\" has highest correlation with the Price of the car.\n\nAlso it is correlated with Odometer Value, Number of photos uploaded by user, and engine capacity.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**2.2 Visualising Categorical Data**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25, 6))\n\nplt.subplot(1,3,1)\nplt1 = cars.manufacturer_name.value_counts().plot(kind='bar')\nplt.title('Companies Histogram')\nplt1.set(xlabel = 'Car company', ylabel='Frequency of company')\n\nplt.subplot(1,3,2)\nplt1 = cars.body_type.value_counts().plot(kind='bar')\nplt.title('Body Type')\nplt1.set(xlabel = 'Body Type', ylabel='Frequency of Body Type')\n\nplt.subplot(1,3,3)\nplt1 = cars.engine_type.value_counts().plot(kind='bar')\nplt.title('Engine Type Histogram')\nplt1.set(xlabel = 'Engine Type', ylabel='Frequency of Engine type')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Inference:**\n1. `Volkswagen` is preffered than other cars.\n2. `Sedan` seems to be the popular type.\n3.  Vehicles with `gasoline` are preffered.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30, 10))\n\ndf = pd.DataFrame(cars.groupby(['manufacturer_name'])['price_usd'].mean().sort_values(ascending = False))\ndf.plot.bar()\nplt.title('Company Name vs Average Price')\nplt.show()\n\ndf = pd.DataFrame(cars.groupby(['engine_fuel'])['price_usd'].mean().sort_values(ascending = False))\ndf.plot.bar()\nplt.title('Fuel Type vs Average Price')\nplt.show()\n\ndf = pd.DataFrame(cars.groupby(['body_type'])['price_usd'].mean().sort_values(ascending = False))\ndf.plot.bar()\nplt.title('Car Type vs Average Price')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Inference:**\n1. `Porsche and Jaguar` seems to have highest average price.\n2. `Hybrid` vehicles have high average price than both Diesel and Gasoline vehicles.\n3. `SUV` has the highest average price.\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**2.3 Binning Companies based on Average Price**\n\nWe have around 45 different Car Manufacturing Companies with Different Model Names. \nIf we create dummy variables for all these names, it will result in large number of coulmns which is not feasible for model building.\nHence, we will try and create different groups based on Average Price of the cars.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cars['price_usd'] = cars['price_usd'].astype('float64')\ntemp = cars.copy()\n\ntable = temp.groupby(['manufacturer_name'])['price_usd'].mean()\ntemp = temp.merge(table.reset_index(), how='left', on='manufacturer_name')\nbins = [0,10000,25000,50000]\ncars_bins = ['Budget','Medium', 'Highend']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cars['CarRange'] = pd.cut(temp['price_usd_y'], bins,  right=False, labels=cars_bins)\ncars.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**2.4 Dummy Variables**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## We will leave out variables like \"manufacturer_name\",\"model_name\",\"location region\" \n## We will be using CarsRange variable instead of these as discussed above.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cars_new = cars[['transmission','color','odometer_value','engine_fuel','engine_has_gas','engine_type','engine_capacity','body_type'\n                , 'has_warranty','state','drivetrain','is_exchangeable','number_of_photos', 'up_counter','duration_listed', 'age','CarRange','price_usd']]\ncars_new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define a function to generate dummy variables and merging it with data frame\n\ndef dummies(x,df):\n    temp = pd.get_dummies(df[[x]], drop_first=True)\n    df = pd.concat([df,temp], axis=1)\n    df.drop([x], axis=1, inplace=True)\n    return df\n\n# Apply function to the cars_new df\ncars_new = dummies('transmission', cars_new)\ncars_new = dummies('color', cars_new)\ncars_new = dummies('engine_fuel', cars_new)\ncars_new = dummies('engine_has_gas', cars_new)\ncars_new = dummies('engine_type', cars_new)\ncars_new = dummies('body_type', cars_new)\ncars_new = dummies('has_warranty', cars_new)\ncars_new = dummies('state', cars_new)\ncars_new = dummies('drivetrain', cars_new)\ncars_new = dummies('is_exchangeable', cars_new)\ncars_new = dummies('CarRange', cars_new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cars_new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cars_new.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Step 3 : Train Test Split","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndf_train, df_test = train_test_split(cars_new, train_size=0.7, random_state=42) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\nnum_vars= ['odometer_value', 'engine_capacity', 'number_of_photos','up_counter','duration_listed', 'age','price_usd']\ndf_train[num_vars] = scaler.fit_transform(df_train[num_vars])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# correlation\n\nplt.figure(figsize = (30, 25))\nsns.heatmap(df_train.corr(), annot = True, cmap=\"YlGnBu\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`Age, Odometer Value, Engine Capacity` are some of the high correaltion variables.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Step 4 : Model Building","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Model 1 : Linear Regression**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression\nimport statsmodels.api as sm \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dividing variables in to X and y\ny_train = df_train.pop('price_usd')\nX_train = df_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lm = LinearRegression()\nlm.fit(X_train, y_train)\nrfe = RFE(lm, 10)\nrfe = rfe.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list(zip(X_train.columns,rfe.support_,rfe.ranking_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.columns[rfe.support_]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Building model using statsmodel, for the detailed statistics**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_rfe = X_train[X_train.columns[rfe.support_]]\nX_train_rfe.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Building a model\n\ndef build_Lr_model(X,y):\n    X = sm.add_constant(X) #add constant\n    lm = sm.OLS(y,X).fit() #fit the model\n    print(lm.summary())\n    return X\n\ndef checkingVIF(X):\n    vif = pd.DataFrame()\n    vif['features'] = X.columns\n    vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n    vif['VIF'] = round(vif['VIF'], 2)\n    vif = vif.sort_values(by = \"VIF\", ascending = False)\n    return(vif)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**MODEL 1**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_1 = build_Lr_model(X_train_rfe, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"P values are less than 0.05. \n\nHence checking the VIF values.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"checkingVIF(X_train_1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Residual Analysis of Model**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lm = sm.OLS(y_train,X_train_1).fit()\ny_train_price = lm.predict(X_train_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the histogram of the error terms\nfig = plt.figure()\nsns.distplot((y_train - y_train_price), bins = 20)\nfig.suptitle('Error Terms', fontsize = 20)                  # Plot heading \nplt.xlabel('Errors', fontsize = 18)  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Error terms seem to be approximately normally distributed, so the assumption on the linear modeling seems to be fulfilled.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Prediction and Evaluation**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"num_vars= ['odometer_value', 'engine_capacity', 'number_of_photos','up_counter','duration_listed', 'age','price_usd']\ndf_test[num_vars] = scaler.fit_transform(df_test[num_vars])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dividing into X and y\ny_test = df_test.pop('price_usd')\nX_test = df_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now let's use our model to make predictions.\nX_train_1 = X_train_1.drop('const',axis=1)\n# Creating X_test_new dataframe by dropping variables from X_test\nX_train_1 = X_test[X_train_1.columns]\n\n# Adding a constant variable \nX_train_1 = sm.add_constant(X_train_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making predictions\ny_pred = lm.predict(X_train_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score \nr2_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**57% Accuracy is low for this model.**\n\nWe can train other models like Random Forest. Also we can try using polynomial features.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Model 2 . Linear Regression Using Polynomial Features**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.metrics import r2_score,mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"polynomial = PolynomialFeatures(degree=2)\npolynomial_model = polynomial.fit_transform(X)\n\nX_train, X_test, y_train, y_test = train_test_split(polynomial_model,y, train_size=0.7, random_state=42)\n\n# Build second LR model using polynomial features\nlr_model_2 = LinearRegression().fit(X_train,y_train)\n\n\n#PRedict the values\ny_train_pred = lr_model_2.predict(X_train)\n\n#Predict test values\ny_test_pred = lr_model_2.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(lr_model_2.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Using Polynomial Featurs, Accuracy increases upto 77% which is near good accuracy.**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Model 3 : Random Forest**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dividing into X and y\ny = cars_new.pop('price_usd')\nX = cars_new","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.7, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV\n\nrf = RandomForestRegressor()\n\nparam_grid = { \"criterion\" : [\"mse\"]\n              , \"min_samples_leaf\" : [1,5,1]\n              , \"min_samples_split\" : [1,5,1]\n              , \"max_depth\": [10]\n              , \"n_estimators\": [500]}\n\ngs = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\ngs = gs.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(gs.best_score_)\nprint(gs.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bp = gs.best_params_\nforest = RandomForestRegressor(criterion=bp['criterion'],\n                              min_samples_leaf=bp['min_samples_leaf'],\n                              min_samples_split=bp['min_samples_split'],\n                              max_depth=bp['max_depth'],\n                              n_estimators=bp['n_estimators'])\nforest.fit(X_train, y_train)\n\nprint('Score: %.2f' % forest.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We are getting accuracy of 88% using Random Forest Regressor which is pretty good accuracy.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"important_features = pd.Series(data=forest.feature_importances_,index=X_train.columns)\nimportant_features.sort_values(ascending=False,inplace=True)\nimportant_features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Summary:**\n1. As predicted in EDA, `Age` is an important factor in Car Price Prediction.\n2. `DriveTrain Font, Odometer Value, Engine Capacity` are also in top 5 Features for Price Prediction. In EDA, we have identified these as the important features.\n3. We have obtained 88% Accuracy using Random Forest.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}