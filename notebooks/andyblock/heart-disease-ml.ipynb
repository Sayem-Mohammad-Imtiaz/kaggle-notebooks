{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Predicting Heart Disease\nThis notebook uses several Python based Machine Leanrning and data science tools to predict whether a patient has heart disesase. This is not a diagnostic tool.\n\nThe following approach will be used\n1. Problem Definition (see above)\n2. Data Exploration\n3. Evaluation \n4. What features contribute most\n5. Modelling the data\n6. Validation and Improvement","metadata":{}},{"cell_type":"markdown","source":"Original data from: https://archive.ics.uci.edu/ml/datasets/heart+disease\n\nData in CSV form from: https://www.kaggle.com/ronitf/heart-disease-uci\n\nThe data has 76 total columns, however only 14 of them are used in published experiments. I will also be using this 14 column subset.\n\n1. age\n2. sex\n3. chest pain type (4 values)\n4. resting blood pressure\n5. serum cholestoral in mg/dl\n6. fasting blood sugar > 120 mg/dl\n7. resting electrocardiographic results (values 0,1,2)\n8. maximum heart rate achieved\n9. exercise induced angina\n10. oldpeak = ST depression induced by exercise relative to rest\n11. the slope of the peak exercise ST segment\n12. number of major vessels (0-3) colored by flourosopy\n13. thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n14. target","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"#EDA and plotting libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\n\n#Models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Model Evaluation\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom sklearn.metrics import plot_roc_curve","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"../input/heart-disease-uci/heart.csv\")\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"markdown","source":"### EDA Checklist\n\n1. What questions are we trying to solve?\n2. What kind of data do we have?\n3. What's missing?\n4. What are the outliers?","metadata":{}},{"cell_type":"code","source":"# What do the classes we're trying to predict look like?\nax = df[\"target\"].value_counts().plot(kind=\"bar\", color=[\"blue\", \"orange\"], title=\"Prevalence of Heart Disease in the data set\")\n\ndf[\"target\"].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It looks like the two classes are (relatively) even. 0 = no heart disease, 1 = heart disease. Can we do better than roughly a coinflip?","metadata":{}},{"cell_type":"markdown","source":"What kind of data do we have?","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This implies that all the columns are numeric. This is technically true, but some columns are categorically represented by numbers. 'cp' (chest pain) and 'thal' (Thalium stress test result) are categorical columns, and we'll need to encode them as such later on. ***** Categorical Transformation not implemented as of 4/12/21 at 11:43 PM, I completely forgot and now I am very tired. Should be fixed by this time on 4/13/21****","metadata":{}},{"cell_type":"markdown","source":"Any missing values?","metadata":{}},{"cell_type":"code","source":"df.isna().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"No missing values, which saves us a bit of imputing later on. ","metadata":{}},{"cell_type":"code","source":"df.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"How does heart disease scale with the sex of the patients in the study? Male = 1, Female = 0","metadata":{}},{"cell_type":"code","source":"pd.crosstab(df.target, df.sex)\npd.crosstab(df.target, df.sex).plot(kind=\"bar\", color=[\"blue\", \"orange\"], title=\"Prevalence of heart disease in Males vs. Females\")\nplt.ylabel(\"Occurences of heart disease\")\nplt.xlabel(\"0 - No Disease, 1 - Disease\")\nplt.legend([\"Female\", \"Male\"]);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If a patient in the dataset is female, there is a (72/24+72) = 75% chance that patient has heart disease. \nFor males (93/114+93) = 45% chance that a male in the dataset has heart disease.","metadata":{}},{"cell_type":"markdown","source":"## Age vs Max Heart Rate for Heart Disease","metadata":{}},{"cell_type":"markdown","source":"For the cell below, thalach is maximum heart rate achieved during the study","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,6))\n\n#Scatter plot with positive examples\nplt.scatter(df.age[df.target==1],\n           df.thalach[df.target==1], \n           color = [\"blue\"])\nplt.title(\"Maximum Heart Rate Achieved vs. Age of patients (Positive results)\")\n\n#Scatter with negative examples\nplt.scatter(df.age[df.target==0],\n           df.thalach[df.target==0],\n           color = [\"Orange\"])\n                    \n                    \n                    \nplt.title(\"Maximum Heart Rate Achieved vs. Age of patients (Negative results)\")\nplt.legend([\"Male\",\"Female\"])\nplt.xlabel(\"Age of patient\")\nplt.ylabel(\"Max heart rate achieved\");","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this case, it's tough to say that any correlation exists. There appears to be a general downward trend for both positve cases and negative cases.","metadata":{}},{"cell_type":"markdown","source":"## Does chest pain correlate to heart disease?","metadata":{}},{"cell_type":"code","source":"pd.crosstab(df.cp, df.target)\npd.crosstab(df.target, df.cp).plot(kind=\"bar\", color=[\"blue\", \"orange\", \"Red\", \"Green\"])\nplt.legend([\"Typical Angina\", \"Atypical Angina\", \"Non-Anginal\", \"Asymptomatic\"])\nplt.title(\"Occurences of heart disesase per chest pain type\");","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It looks like there are a lot of patients without heart disease who suffer from Angina, while the most common form of pain for those with heart disease is Non-Anginal Pain","metadata":{}},{"cell_type":"markdown","source":"### Correlation Matrix","metadata":{}},{"cell_type":"code","source":"corr_matrix = df.corr()\nplt.subplots(figsize=(15,10))\nax = sns.heatmap(corr_matrix, annot=True, fmt=\".2f\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Based on the correlation matrix, there are only a few features that don't correlate somewhat (positively or negatively). Maybe we can remove chol and fbs from the training and test data later? This is something to look into, at the very least.","metadata":{}},{"cell_type":"markdown","source":"# Now let's actually do some modelling","metadata":{}},{"cell_type":"code","source":"X = df.drop(\"target\", axis=1)\ny = df[\"target\"]\n\n#split data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# One Hot Encoding to handle categorical data","metadata":{}},{"cell_type":"code","source":"one_hot = OneHotEncoder(handle_unknown='ignore')\ncat_features = [\"cp\", \"thal\"]\ntransformer = ColumnTransformer([(\"one_hot\", one_hot, cat_features)], remainder=\"passthrough\")\nX_train_onehot = pd.DataFrame(transformer.fit_transform(X_train))\nX_test_onehot = pd.DataFrame(transformer.fit_transform(X_test))\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I'm going to scale the data to a 0-1 scale. While technically not needed for all algorithms, it doesn't hurt and will allow other algorithms to be used if we so choose. Be sure to scale train and test splits separately, to avoid leakage.","metadata":{}},{"cell_type":"code","source":"scaler = MinMaxScaler()\nX_train_scaled = pd.DataFrame(scaler.fit_transform(X_train_onehot))\nX_test_scaled = pd.DataFrame(scaler.fit_transform(X_test_onehot))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Testing on 3 different models\n1. K Nearest Neighbors\n2. Random Forest\n3. Logistic Regression\n\nScaling was really done for the sake of K Nearest Neighbors, which I believe requires some sort of scaling","metadata":{}},{"cell_type":"code","source":"models = {\"Logistic Regression\": LogisticRegression(),\n         \"KNN\": KNeighborsClassifier(),\n         \"Random Forest\": RandomForestClassifier()}\n\ndef fit_and_score(models, X_train, X_test, y_train, Y_test):\n    \"\"\"\n    Fit and scores given machine learning models on the given input data\n    \"\"\"\n    \n    #set random seed for reproducibility\n    np.random.seed(42)\n    #make dictionary to keeo scores\n    model_scores = {}\n    for name, model in models.items():\n        model.fit(X_train, y_train)\n        model_scores[name] = model.score(X_test, y_test)\n    return model_scores","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_scores = fit_and_score(models, X_train_scaled, X_test_scaled, y_train, y_test)\nmodel_scores","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Quick plot of these results","metadata":{}},{"cell_type":"code","source":"model_compare = pd.DataFrame(model_scores, index=[\"accuracy\"])\nmodel_compare.T.plot.bar();","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy is not necessarily the best measure of a model, but it isn't a waste of time to look at it either. Initially, this shows RandomForest doing the \"best\" and Logistic Regression doing the \"worst\". Now with a baseline, I can tune the models.","metadata":{}},{"cell_type":"markdown","source":"# Hyperparameter tuning","metadata":{}},{"cell_type":"code","source":"#Tuning KNN\ntrain_scores = []\ntest_scores = []\nnp.random.seed(42)\n#Create a different list for n neighbors\nneighbors = range(1,21)\nknn = KNeighborsClassifier()\n\n#loop over values for neighbors\nfor i in neighbors:\n    knn.set_params(n_neighbors=i)\n    \n    knn.fit(X_train_scaled, y_train)\n    \n    train_scores.append(knn.score(X_train_scaled, y_train))\n    \n    test_scores.append(knn.score(X_test_scaled, y_test))\n\nplt.plot(neighbors, train_scores, label = \"Train Score\")\nplt.plot(neighbors, test_scores, label = \"Test Score\")\nplt.legend();\nprint(f\"The max accuracy for KNN is {max(test_scores)*100:.2f}% \")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"By changing the number of neighbors, I'm able to improve the accuracy of the KNN algorithm a bit but not incredibly much. This is largely inefficient hyperparamter tuneing. We'll come back to this in a bit. Let's take a look at the other two models now.","metadata":{}},{"cell_type":"markdown","source":"# Using RandomizedSearchCV to tune hyperparameters","metadata":{}},{"cell_type":"code","source":"# create a hyperparameter grid for logisticRegression\n\nlog_reg_grid = {\"C\":np.logspace(-4, 4, 20),\n               \"solver\": [\"liblinear\"]}\n\n#create grid for RandomForest\n\nrf_grid = {\"n_estimators\":np.arange(10, 1000, 50),\n          \"max_depth\":[None, 3, 5, 10],\n          \"min_samples_split\":np.arange(2,20,2),\n          \"min_samples_leaf\": np.arange(1,20,2)}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Tune Logistic Regression\n\nnp.random.seed(42)\n\nrs_log_reg = RandomizedSearchCV(LogisticRegression(),\n                               param_distributions = log_reg_grid,\n                               cv=5, \n                               n_iter=20,\n                               verbose=True)\n#fit hyperparamter search model for Logistic Regression\nrs_log_reg.fit(X_train_scaled, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rs_log_reg.score(X_test_scaled, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It looks like just about the same score. Trying RandomForest now","metadata":{}},{"cell_type":"code","source":"np.random.seed(42)\n\nrs_rf = RandomizedSearchCV(RandomForestClassifier(), \n                          param_distributions=rf_grid, \n                          cv=5,\n                          n_iter=20,\n                          verbose=2)\nrs_rf.fit(X_train_scaled, y_train)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rs_rf.best_params_\nrs_rf.score(X_test_scaled, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Again, about the same score as before the tuning. This doesn't mean that tuning isn't going to help, just that it hasn't helped in this specific case","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}