{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Word embeddings lead to scientific discovery"},{"metadata":{},"cell_type":"markdown","source":"In this notebook, the abstracts in the CORD-19 corpus are used to build word embeddings with *Word2Vec*. Distances in the high-dimensional space mapped by *Word2Vec* reveal bits of knowledge around COVID-19. Examples include the **autonomous discovery** of the similarity between COVID-19 and SARS and MERS, of the radical difference between COVID-19 and seasonal flu, and of state-of-the-art trial therapies. The model developed here can become a valuable tool to explore the literature related to COVID-19."},{"metadata":{},"cell_type":"markdown","source":"This work was largely inspired by a recent [article](https://www.nature.com/articles/s41586-019-1335-8) on how scientific discovery (in that case of high-performance materials) is often latent in past literature and how Natural Language Processing can track hidden relationship that lead to invention. I, and other Kaggle users (see [this](https://www.kaggle.com/tarunpaparaju/covid-19-dataset-gaining-actionable-insights) or [this](https://www.kaggle.com/tylersuard/mat2vec-covid-papers-unexpected-word-asociations?scriptVersionId=30790274) notebooks, for example), thought that the same principle can be applied to the CORD-19 database."},{"metadata":{},"cell_type":"markdown","source":"## Method"},{"metadata":{},"cell_type":"markdown","source":"[This](https://www.kaggle.com/pierremegret/gensim-word2vec-tutorial) notebook is a great hands-on introduction to word embeddings and I have borrowed pieces of code from it."},{"metadata":{},"cell_type":"markdown","source":"## Reading the Abstracts"},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport pandas as pd\nfrom collections import defaultdict\nimport spacy\nimport en_core_web_sm\nimport numpy as np\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Abstracts are usually **less noisy** than the whole texts, because they are more concise and not redundant. This is why they are preferred in this analysis."},{"metadata":{"trusted":true},"cell_type":"code","source":"metadata=pd.read_csv(\"/kaggle/input/CORD-19-research-challenge/metadata.csv\")\nmetadata=metadata[metadata[\"abstract\"]==metadata[\"abstract\"]]\nprint(metadata.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cleaning the Abstracts"},{"metadata":{"trusted":true},"cell_type":"code","source":"nlp = en_core_web_sm.load(disable=['ner', 'parser']) # disabling Named Entity Recognition for speed\n\ndef cleaning(doc):\n    # Lemmatizes and removes stopwords\n    # doc needs to be a spacy Doc object\n    txt = [token.lemma_ for token in doc if not token.is_stop]\n    # Word2Vec uses context words to learn the vector representation of a target word,\n    # if a sentence is only one or two words long,\n    # the benefit for the training is very small\n    if len(txt) > 2:\n        return ' '.join(txt)\nbrief_cleaning = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower().replace(\"abstract\", \"\") for row in metadata['abstract'])\ntxt = [cleaning(doc) for doc in nlp.pipe(brief_cleaning, batch_size=5000, n_threads=-1)]\ndf_clean = pd.DataFrame({'clean': txt})\ndf_clean = df_clean.dropna().drop_duplicates()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Setting up bigrams:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from gensim.models.phrases import Phrases, Phraser\nsent = [row.split() for row in df_clean['clean']]\nphrases = Phrases(sent, min_count=30, progress_per=10000)\nbigram = Phraser(phrases)\nsentences = bigram[sent]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some checks:"},{"metadata":{"trusted":true},"cell_type":"code","source":"word_freq = defaultdict(int)\nfor sent in sentences:\n    for i in sent:\n        word_freq[i] += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MIN_COUNT=6\nDICT=[key for key in word_freq.keys() if word_freq[key]>MIN_COUNT]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"covid\" in DICT","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"import multiprocessing\n\nfrom gensim.models import Word2Vec\n\ncores = multiprocessing.cpu_count()\n\nw2v_model = Word2Vec(min_count=MIN_COUNT,\n                     window=2,\n                     size=200,\n                     sample=1e-4, \n                     alpha=0.01,\n                     min_alpha=0.0001, \n                     negative=15,\n                     workers=cores-1)\n\nw2v_model.build_vocab(sentences, progress_per=10000)\n\nw2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n\nw2v_model.init_sims(replace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploring the model"},{"metadata":{},"cell_type":"markdown","source":"Let's see if the model is reasonable. First of all, let's look at similarities:"},{"metadata":{"trusted":true},"cell_type":"code","source":"w2v_model.wv.most_similar(\"treatment\",topn=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok, this makes sense; most of the words related to \"treatment\" are **synonyms**."},{"metadata":{"trusted":true},"cell_type":"code","source":"w2v_model.wv.most_similar(positive=[\"china\"],topn=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Wow, my model has autonomously learned **Geography**; it knows that Taiwan is a country, as well as China, and that the provinces Hubei and Guangdong, and the cities Wuhan and Shenzhen are all in China."},{"metadata":{"trusted":true},"cell_type":"code","source":"w2v_model.wv.most_similar(positive=[\"oseltamivir\"],topn=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Great, the model seems to know that the antiviral **Oseltamivir** (commercial name **Tamiflu**) is a **Neuraminidase Inhibitor** (**NAI**), similar to **Zanamivir**, and that is given to patients in combination with antibiotics (**Vancomycin**, **Erythromycin**, **Fluoroquinolone**, **Clarithromycin**, ...). I didn't know that!"},{"metadata":{"trusted":true},"cell_type":"code","source":"w2v_model.wv.most_similar(positive=[\"malaria\"],topn=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It also \"knows\" that malaria is caused by the Protozoa *Plasmodium Falciparum* and *Plasmodium Vivax*."},{"metadata":{},"cell_type":"markdown","source":"## Fighting COVID-19"},{"metadata":{},"cell_type":"markdown","source":"Most related words to \"COVID\":"},{"metadata":{"trusted":true},"cell_type":"code","source":"w2v_model.wv.most_similar(positive=[\"covid\"],topn=10) #ncp=novel coronavirus pneumonia","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the [R&D Blueprint Report](https://apps.who.int/iris/bitstream/handle/10665/330680/WHO-HEO-RDBlueprint%28nCoV%29-2020.1-eng.pdf?ua=1) compiled by WHO on January 24th, 2020, it is suggested that the antiviral **Remdesivir** is the most promising candidate to treat COVID-19. If I look in the \"neighbourhood\" of this drug:"},{"metadata":{"trusted":true},"cell_type":"code","source":"w2v_model.wv.most_similar(positive=[\"remdesivir\"],topn=20) #recommended by WHO on Jan 24","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I find potential alternative candidates to fight COVID-19:\n- **Nitazoxanide** is a broad-spectrum antiviral [[source]](https://en.wikipedia.org/wiki/Nitazoxanide).\n- **Lopinavir**, **Ritonavir**, and **Darunavir** are used against HIV. On March, 17th 2020 the Italian Agency for Pharmaceuticals (AIFA) has allowed experimental treatment of COVID-19 with a combination of these two drugs [[source]](https://www.aifa.gov.it/-/azioni-intraprese-per-favorire-la-ricerca-e-l-accesso-ai-nuovi-farmaci-per-il-trattamento-del-covid-19).\n- **Favipiravir** is used against flu. On March, 23rd 2020 AIFA has started to consider experimental therapies with this drug in the most-hit regions in Italy [[source]](https://www.aifa.gov.it/-/favipiravir-aggiornamento-della-valutazione-della-cts), despite the very limited scientific evidence of its effectiveness.\n- **Sofosbuvir** is used against Hepatitis C. It has been suggested against COVID-19 [[source]](https://www.biorxiv.org/content/10.1101/2020.01.30.927574v1.full.pdf), but the scientific evidence is extremely limited.\n- **Umifenovir** (commercial name: Arbidol or Abidol) is also being studied against COVID-19, but AIFA has stated that there is no scientific evidence of it being effective against COVID-19 [[source]](https://www.aifa.gov.it/-/aifa-precisa-uso-umifenovir-su-covid-19-non-autorizzato-in-europa-e-usa-scarse-evidenze-scientifiche-sull-efficacia).\n- **Artesunate**, **Amodiaquine**, **Aminoquinaline**, and **Hydroxychloroquine** are antimalaria drugs. The latter has been approved for testing against COVID-19 on March, 17th 2020 by (AIFA) [[source]](https://www.aifa.gov.it/-/azioni-intraprese-per-favorire-la-ricerca-e-l-accesso-ai-nuovi-farmaci-per-il-trattamento-del-covid-19), and mentioned by Donald Trump [[source]](https://twitter.com/realDonaldTrump/status/1242120391054757900) and Elon Musk [[source]](https://twitter.com/elonmusk/status/1239776019856461824) on Twitter (please mind that neither of them is a medical doctor though!)\n"},{"metadata":{},"cell_type":"markdown","source":"## COVID-19 is NOT a simple flu"},{"metadata":{},"cell_type":"markdown","source":"Given this list of diseases:"},{"metadata":{"trusted":true},"cell_type":"code","source":"diseases=[\"covid\",\"coronavirus\",\"sars\",\"mers\",\"covid_pneumonia\",\"novel_coronavirus\",\"ncov\",\"cov\",\"coronavirus_sars\",\"sars_cov\",\"influenza\",\"seasonal_influenza\",\"h_n\",\"swine_flu\",\"avian_flu\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I have applied Principal Component Analysis to the 200-dimensional space mapped by *Word2Vec* to downfold it to 2D and plotted the components of each disease in this low-dimensional representation:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = w2v_model[diseases].T\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=2)\nresult = pca.fit_transform(X.T)\nplt.figure(figsize=(15,5))\nplt.scatter(result.T[0],result.T[1])\nplt.yticks(fontsize=14)\nplt.xticks(fontsize=14)\nplt.xlabel(\"Component 1\",fontsize=14)\nplt.ylabel(\"Component 2\",fontsize=14)\nfor i in range(0,len(diseases)):\n    plt.annotate(diseases[i],xy=(result.T[0][i],result.T[1][i]), xycoords='data',\n            xytext=(-15, 5), textcoords='offset points', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The plot nicely shows that **two** separate **clusters** form: one contains very bad respiratory illnesses (COVID, SARS, MERS), and the other less severe types of flu. Therefore, it can be concluded that COVID-19 is **NOT A COMMON FLU** and must not be underestimated."},{"metadata":{},"cell_type":"markdown","source":"## Conclusions"},{"metadata":{},"cell_type":"markdown","source":"Common knowledge related to COVID-19 stems out naturally from word embeddings produced from the CORD-19 database. Potential effective therapies being experimented are close in terms of distance in the high-dimensional space produced by Word2Vec, thus eventual new treatments can arise by exploring the **neighbourhood** of the therapies already in use."},{"metadata":{},"cell_type":"markdown","source":"Word embeddings also show unequivocally that the literature does not regard COVID-19 as a seasonal flu, suggesting that the **containment** precautions taken in many countries are largely **supported** by scientific evidence."},{"metadata":{},"cell_type":"markdown","source":"*To the patients, doctors and nurses all over the world: keep on fighting.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":4}