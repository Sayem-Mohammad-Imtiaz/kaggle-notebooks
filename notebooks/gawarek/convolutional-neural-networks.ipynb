{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport matplotlib.pyplot as plt\nimport csv\nimport os\nimport tensorflow as tf\nfrom scipy import misc\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convolution(img, f, w=1):\n    img_copy = np.copy(img)\n    size_x = img_copy.shape[0]\n    size_y = img_copy.shape[1]\n    for x in range(1,size_x-1):\n        for y in range(1,size_y-1):\n            convolution = 0.0\n            convolution = convolution + (img_copy[x - 1, y-1] * f[0][0])\n            convolution = convolution + (img_copy[x, y-1] * f[0][1])\n            convolution = convolution + (img_copy[x + 1, y-1] * f[0][2])\n            convolution = convolution + (img_copy[x-1, y] * f[1][0])\n            convolution = convolution + (img_copy[x, y] * f[1][1])\n            convolution = convolution + (img_copy[x+1, y] * f[1][2])\n            convolution = convolution + (img_copy[x-1, y+1] * f[2][0])\n            convolution = convolution + (img_copy[x, y+1] * f[2][1])\n            convolution = convolution + (img_copy[x+1, y+1] * f[2][2])\n            convolution = convolution * w\n            if(convolution<0):\n                convolution=0\n            if(convolution>255):\n                convolution=255\n            img[x, y] = convolution\n\ndef max_pooling(img):\n    size_x = img.shape[0]\n    size_y = img.shape[1]\n    new_x = int(size_x/2)\n    new_y = int(size_y/2)\n    new_img = np.zeros((new_x, new_y))\n    for x in range(0, size_x, 2):\n        for y in range(0, size_y, 2):\n            pixels = []\n            pixels.append(img[x, y])\n            pixels.append(img[x+1, y])\n            pixels.append(img[x, y+1])\n            pixels.append(img[x+1, y+1])\n            new_img[int(x/2),int(y/2)] = max(pixels)\n    return new_img\n\ndef avg_pooling(img):\n    size_x = img.shape[0]\n    size_y = img.shape[1]\n    new_x = int(size_x/2)\n    new_y = int(size_y/2)\n    new_img = np.zeros((new_x, new_y))\n    for x in range(0, size_x, 2):\n        for y in range(0, size_y, 2):\n            pixels = []\n            pixels.append(img[x, y])\n            pixels.append(img[x+1, y])\n            pixels.append(img[x, y+1])\n            pixels.append(img[x+1, y+1])\n            new_img[int(x/2),int(y/2)] = sum(pixels) / len(pixels)\n    return new_img\n\ndef demonstrate_conv_and_pooling(f):\n    img = misc.ascent()\n    fig = plt.figure(figsize=(20,6))\n    ax = fig.add_subplot(1,4,1)\n    ax.set_title('Original')\n    ax.imshow(img)\n    plt.legend()\n    ax = fig.add_subplot(1,4,2)\n    convolution(img, f)\n    ax.imshow(img)\n    ax.set_title('Convolution')\n    plt.legend()\n    ax = fig.add_subplot(1,4,3)\n    ax.imshow(max_pooling(img))\n    ax.set_title('Max pooling')\n    plt.legend()\n    ax = fig.add_subplot(1,4,4)\n    ax.imshow(avg_pooling(img))\n    ax.set_title('Avg pooling')\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Experiment with different values for fun effects.\n#f = [ [0, 1, 0], [1, -4, 1], [0, 1, 0]]\n#f = [ [1, 2, 3], [-1, -2, -3], [0, 1, 0]]\n#f = [ [0, 1, 2], [-1, 0, 1], [-2, -1, 0]]\nf = [ [-1, -2, -1], [0, 0, 0], [1, 2, 1]]\n#f = [ [-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]\n\nplt.gray()\n\ndemonstrate_conv_and_pooling(f)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def get_data(filename):\n    with open(filename) as file:        \n        csv_reader = csv.reader(file)  \n        next(csv_reader)  \n        \n        images = []\n        labels = []\n        \n        for row in csv_reader:\n            images.append(np.array(row[1:]).reshape(28, 28))\n            labels.append(row[0])\n\n    images = np.array(images).astype(np.float32) \n    labels = np.array(labels).astype(np.float32)\n    \n    return images, labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mnist_train = \"/kaggle/input/sign-language-mnist/sign_mnist_train/sign_mnist_train.csv\"\nmnist_test = \"/kaggle/input/sign-language-mnist/sign_mnist_test/sign_mnist_test.csv\"\ntraining_images, training_labels = get_data(mnist_train)\ntesting_images, testing_labels = get_data(mnist_test)\n\n# Keep these\nprint(training_images.shape)\nprint(training_labels.shape)\nprint(testing_images.shape)\nprint(testing_labels.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_data():\n    imgs = np.random.randint(training_images.shape[0], size=(4, 4))\n    fig = plt.figure(figsize=(20,20))\n    axarr = fig.subplots(4,4)\n    for i in range(4):\n        for j in range(4):\n            axarr[i,j].imshow(training_images[imgs[i,j]])\n            axarr[i,j].grid(False)\n\nplot_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_images=training_images / 255.0\ntraining_images=training_images.reshape(-1, 28, 28, 1)\ntesting_images=testing_images/255.0\ntesting_images=testing_images.reshape(-1, 28, 28, 1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_old = tf.keras.models.Sequential([\n    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n    tf.keras.layers.Dense(256, activation='relu'),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dense(25, activation='softmax')\n])\nmodel_old.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel_old.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_old = model_old.fit(training_images, training_labels, epochs=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loss_old = model_old.evaluate(testing_images, testing_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dense(25, activation='softmax')\n])\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(training_images, training_labels, epochs=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loss = model.evaluate(testing_images, testing_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(testing_labels[:100])\ndef visualize_filters(first_img, second_img, third_img, conv_number):\n    fig = plt.figure(figsize=(15,10))\n    axarr = fig.subplots(3,4)\n    from tensorflow.keras import models\n    layer_outputs = [layer.output for layer in model.layers]\n    activation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)\n    for x in range(0,4):\n        f1 = activation_model.predict(testing_images[first_img].reshape(1, 28, 28, 1))[x]\n        axarr[0,x].imshow(f1[0, : , :, conv_number], cmap='inferno')\n        axarr[0,x].grid(False)\n        f2 = activation_model.predict(testing_images[second_img].reshape(1, 28, 28, 1))[x]\n        axarr[1,x].imshow(f2[0, : , :, conv_number], cmap='inferno')\n        axarr[1,x].grid(False)\n        f3 = activation_model.predict(testing_images[third_img].reshape(1, 28, 28, 1))[x]\n        axarr[2,x].imshow(f3[0, : , :, conv_number], cmap='inferno')\n        axarr[2,x].grid(False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualize_filters(9, 14, 1, 31)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}