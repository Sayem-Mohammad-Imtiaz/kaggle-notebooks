{"cells":[{"metadata":{"trusted":true,"_uuid":"e2dd006bd75ea92ab73fdc85117140a297b3bfe2"},"cell_type":"code","source":"import pandas as pd\ntest  = pd.read_csv(\"https://s3.amazonaws.com/hackerday.datascience/112/test.csv\")  \ntrain = pd.read_csv(\"https://s3.amazonaws.com/hackerday.datascience/112/train.csv\") ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a1963d349d4c0973798d210f86f4b1e8d4e2fa6"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11efb647a912bf4f63b9d5095c8b77dc1e5adec7"},"cell_type":"code","source":"train.Activity.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9f0fae3451a63124d20be85b8038fa6eec8cefa"},"cell_type":"code","source":"train.shape,test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cbffb10a1233ef583b3aac92c64355fa0bdeb535"},"cell_type":"code","source":"test.Activity.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec28c1c45be32986456f5f1f5ba692c0735f2192"},"cell_type":"code","source":"# suffling data \nfrom sklearn.utils import shuffle\n\ntest  = shuffle(test)\ntrain = shuffle(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe9d471d6c274d0fed9718a0f956929e495ca2f1"},"cell_type":"code","source":"# separating data inputs and output lables \ntrainData  = train.drop('Activity' , axis=1).values\ntrainLabel = train.Activity.values\n\ntestData  = test.drop('Activity' , axis=1).values\ntestLabel = test.Activity.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"77e2f44e008a956feb31c39d3f73210d4aebae2e"},"cell_type":"code","source":"# encoding labels \nfrom sklearn import preprocessing\n\nencoder = preprocessing.LabelEncoder()\n\n# encoding test labels \nencoder.fit(testLabel)\ntestLabelE = encoder.transform(testLabel)\n\n# encoding train labels \nencoder.fit(trainLabel)\ntrainLabelE = encoder.transform(trainLabel)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"75b4dc3ee0dcb8da389018b5fa110bfa54554a34"},"cell_type":"code","source":"# target variable is categorical\n# IV's are num","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"6c0fb9d60f98d79ceb81d8c17ea479789c0b723c"},"cell_type":"code","source":"# classification models:\n# Decision tree\n# SVM\n# NN\n# RF\n# GBM\n# DNN\n# ANN\n# DNN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8d8f22c02acd4c62d1f498de6ee1b1e75129703a"},"cell_type":"code","source":"# applying supervised neural network using multi-layer preceptron \nimport sklearn.neural_network as nn \nmlpSGD  =  nn.MLPClassifier(hidden_layer_sizes=(90,)  \\\n                        , max_iter=1000 , alpha=1e-4  \\\n                        , solver='sgd' , verbose=10   \\\n                        , tol=1e-19 , random_state=1  \\\n                        , learning_rate_init=.001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b18910aa298d2b9d08375e517767096e06dfeac3"},"cell_type":"code","source":"mlpADAM =  nn.MLPClassifier(hidden_layer_sizes=(90,)  \\\n                        , max_iter=1000 , alpha=1e-4  \\\n                        , solver='adam' , verbose=10  \\\n                        , tol=1e-19 , random_state=1  \\\n                        , learning_rate_init=.001) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b6b0cf339309af6763d71a2870fa991b67cb38e7"},"cell_type":"code","source":"mlpLBFGS =  nn.MLPClassifier(hidden_layer_sizes=(90,)  \\\n                        , max_iter=1000 , alpha=1e-4  \\\n                        , solver='lbfgs' , verbose=10  \\\n                        , tol=1e-19 , random_state=1  \\\n                        , learning_rate_init=.001) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7104f0725d003448abf6fb654cd1b217045337ab"},"cell_type":"code","source":"nnModelSGD  = mlpSGD.fit(trainData , trainLabelE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"085411c137d908c3a502f6cf1a45f9a83983bc4e"},"cell_type":"code","source":"nnModelSGD  = mlpLBFGS.fit(trainData , trainLabelE)\nnnModelSGD","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d6c10772960c8596beff5b8b879fdecfb62d8324"},"cell_type":"code","source":"nnModelADAM = mlpADAM.fit(trainData , trainLabelE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a51a977a5dcf8892700519649dfefc8aa53528be"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sb\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a9885b70c3d6230b116a12911302469ebcfb10f5"},"cell_type":"code","source":"# load data\n#https://s3.amazonaws.com/hackerday.datascience/112/test.csv\n#https://s3.amazonaws.com/hackerday.datascience/112/train.csv\n\ntrain = pd.read_csv(\"https://s3.amazonaws.com/hackerday.datascience/112/train.csv\")\ntest = pd.read_csv(\"https://s3.amazonaws.com/hackerday.datascience/112/test.csv\")\nprint('Train Data', train.shape,'\\n', train.columns)\nprint('\\nTest Data', test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd090dcdece245b7e5b07c0b4d870794834cd0b1"},"cell_type":"code","source":"print('Train labels', train['Activity'].unique(), '\\nTest Labels', test['Activity'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"56013997edee131008a349120cb9fa916cadce66"},"cell_type":"code","source":"pd.crosstab(train.subject, train.Activity)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e4a847a87836c63a022a45dc3adfcf76d2e4751f"},"cell_type":"code","source":"sub15 = train.loc[train['subject']==1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dd8f0b365bbac6159c0e00ede3cfd97d09eb65b4"},"cell_type":"code","source":"sub15.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ad46ab1353268abcdc4fe5b5142fafb3c13f3ae"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1cd0de0e82cdda619a44132e509a903ab8ad7421"},"cell_type":"code","source":"train.subject.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"258edbb4b3da941df1f89121f56a9ca5375d90e4"},"cell_type":"code","source":"fig = plt.figure(figsize=(32,24))\nax1 = fig.add_subplot(221)\nax1 = sb.stripplot(x='Activity', y=sub15.iloc[:,0], data=sub15, jitter=True)\nax2 = fig.add_subplot(222)\nax2 = sb.stripplot(x='Activity', y=sub15.iloc[:,1], data=sub15, jitter=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5629a091bcd1e83d29816a17db59af375cf40272"},"cell_type":"code","source":"fig = plt.figure(figsize=(32,24))\nax1 = fig.add_subplot(221)\nax1 = sb.stripplot(x='Activity', y=sub15.iloc[:,2], data=sub15, jitter=True)\nax2 = fig.add_subplot(222)\nax2 = sb.stripplot(x='Activity', y=sub15.iloc[:,3], data=sub15, jitter=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2b2e611273f001487be8bd7733851d4ef5b03d77"},"cell_type":"code","source":"fig = plt.figure(figsize=(32,24))\nax1 = fig.add_subplot(221)\nax1 = sb.stripplot(x='Activity', y=sub15.iloc[:,4], data=sub15, jitter=True)\nax2 = fig.add_subplot(222)\nax2 = sb.stripplot(x='Activity', y=sub15.iloc[:,5], data=sub15, jitter=True)\nplt.show()\n\n# We need to check the spread as of activity column as it can have outliers which has to be\n# taken care if we are using standard levels models like random forest and decision tree\n# But for deep learning it will take care of outliers\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dde6e7dc0764bad5ae45b014eab7f762e5d2759b"},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ac8b5bb3597d2f9f9d0e13d23edc16fe7697ca6"},"cell_type":"code","source":"#https://s3.amazonaws.com/hackerday.datascience/112/test.csv\n#https://s3.amazonaws.com/hackerday.datascience/112/train.csv\ntrain_df = pd.read_csv(\"https://s3.amazonaws.com/hackerday.datascience/112/train.csv\")\ntest_df = pd.read_csv(\"https://s3.amazonaws.com/hackerday.datascience/112/test.csv\")\ntrain_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f93a82f9d161522228ac1823df8a4e58d05d0d1"},"cell_type":"code","source":"unique_activities = train_df.Activity.unique()\nprint(\"NUmber of unique activities: {}\".format(len(unique_activities)))\nreplacer = {}\nfor i, activity in enumerate(unique_activities):\n    replacer[activity] = i\ntrain_df.Activity = train_df.Activity.replace(replacer)\ntest_df.Activity = test_df.Activity.replace(replacer)\ntrain_df.head(10)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dcc0aff35e767a6b2684dfc2adaa6043271f30f4"},"cell_type":"code","source":"train_df = train_df.drop(\"subject\", axis=1)\ntest_df = test_df.drop(\"subject\", axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"02ef790b9733553f2e5ebb62c0a0b80ed6cea753"},"cell_type":"code","source":"def get_all_data():\n    train_values = train_df.values\n    test_values = test_df.values\n    np.random.shuffle(train_values)\n    np.random.shuffle(test_values)\n    X_train = train_values[:, :-1]\n    X_test = test_values[:, :-1]\n    y_train = train_values[:, -1]\n    y_test = test_values[:, -1]\n    return X_train, X_test, y_train, y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"51b91dd4b84d1029defb2bf2b492dfe77907b472"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nX_train, X_test, y_train, y_test = get_all_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c4445beeb2d580648bef62c31289403176423c4d"},"cell_type":"code","source":"model = LogisticRegression(C=10)#complexity parameter\nmodel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"14d3499a4c5756ae49e2a439a7a072bfebb9e250"},"cell_type":"code","source":"model = LogisticRegression()\nmodel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3530d470ac757bff2261bacb76c187ce12a9d314"},"cell_type":"code","source":"model.fit(X_train, y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0975ed9cb7f7bc0d1715bc7929fa48d43930ed63"},"cell_type":"code","source":"model.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"6506d1725476c275cc7904c0ce1d0af14a01588a"},"cell_type":"code","source":"#logistic regression : 87%","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"273c47c689faa8f3a5ceed75f7a5facd4ed646b6"},"cell_type":"code","source":"# Try some transformations\nfrom sklearn.decomposition import PCA\n\nX_train, X_test, y_train, y_test = get_all_data() #generating the training set\npca = PCA(n_components=200) # initializing the PCA\npca.fit(X_train) #applying PCA\nX_train = pca.transform(X_train) # transforming the dataset\nX_test = pca.transform(X_test)\n\nmodel.fit(X_train, y_train) #creating model\nmodel.score(X_test, y_test) #score\n# Worse performance, but trains faster","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"097a98914da1c9ef143f8a1a9d30a46244f95928"},"cell_type":"code","source":"# Scale features to be between -1 and 1\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\nX_train, X_test, y_train, y_test = get_all_data()\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)\n\nmodel.fit(X_train, y_train)\nmodel.score(X_test, y_test)\n# Better performance","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e3bcc1c60120200cfc260c795dbe8923a77eda84"},"cell_type":"code","source":"# Neural network\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.utils.np_utils import to_categorical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"66dcd85b76696126d784e38f6dff0712c5790b83"},"cell_type":"code","source":"X_train, X_test, y_train, y_test = get_all_data()\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca7287be62b5667d1d6e6f32f3837052aa481ff1"},"cell_type":"code","source":"n_input = X_train.shape[1] # number of features\nn_output = 6 # number of possible labels\nn_samples = X_train.shape[0] # number of training samples\nn_hidden_units = 40\nY_train = to_categorical(y_train)\nY_test = to_categorical(y_test)\nprint(Y_train.shape)\nprint(Y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e253565cc8f639bbb85f2348fa28b0d441d4690"},"cell_type":"code","source":"def create_model():\n    model = Sequential()\n    model.add(Dense(n_hidden_units,\n                    input_dim=n_input,\n                    activation=\"relu\"))\n    model.add(Dense(n_hidden_units,\n                    input_dim=n_input,\n                    activation=\"relu\"))\n    model.add(Dense(n_output, activation=\"softmax\"))\n    # Compile model\n    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"75d5f6f96bea824d1f702f43a3822eab7e58bb65"},"cell_type":"code","source":"estimator = KerasClassifier(build_fn=create_model, epochs=20, batch_size=10, verbose=False)\nestimator.fit(X_train, Y_train)\nprint(\"Score: {}\".format(estimator.score(X_test, Y_test)))\n# accuracy 88.7%","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b4e92e388f1a8dd09445df1734aa4ed8d1351cee"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nX_train, X_test, y_train, y_test = get_all_data()\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)\n\nmodel = RandomForestClassifier(n_estimators=500)\nmodel.fit(X_train, y_train)\nmodel.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6a88f7bf8b15d2377bdd51b1fd5ed8688183820"},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn.preprocessing import StandardScaler,LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.neighbors import KNeighborsClassifier\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.optimizers import SGD,Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bdfeedec7f7daa14e584a33fe24ae4f4b61e01df"},"cell_type":"code","source":"#Feature matrix\ntrain_data = train.iloc[:,:561].as_matrix()\ntest_data = test.iloc[:,:561].as_matrix()\n\ntrain_labels = train.iloc[:,562:].as_matrix()\ntest_labels = test.iloc[:,562:].as_matrix()\n\ntrain_labelss=np.zeros((len(train_labels),6))\ntest_labelss=np.zeros((len(test_labels),6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f6584beeee4815a35e3537f9c891d5f06fbdcab4"},"cell_type":"code","source":"for k in range (0,len(train_labels)):\n    if train_labels[k] =='STANDING':\n        train_labelss[k][0]=1\n    elif train_labels[k] =='WALKING':\n        train_labelss[k][1]=1\n    elif train_labels[k] =='WALKING_UPSTAIRS':\n        train_labelss[k][2]=1\n    elif train_labels[k] =='WALKING_DOWNSTAIRS':\n        train_labelss[k][3]=1\n    elif train_labels[k] =='SITTING':\n        train_labelss[k][4]=1\n    else:\n        train_labelss[k][5]=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dfa8cf1063c3378eb44c071f8d48fd5e85e7d9d6"},"cell_type":"code","source":"for k in range (0,len(test_labels)):\n    if test_labels[k] =='STANDING':\n        test_labelss[k][0]=1\n    elif test_labels[k] =='WALKING':\n        test_labelss[k][1]=1\n    elif test_labels[k] =='WALKING_UPSTAIRS':\n        test_labelss[k][2]=1\n    elif test_labels[k] =='WALKING_DOWNSTAIRS':\n        test_labelss[k][3]=1\n    elif test_labels[k] =='SITTING':\n        test_labelss[k][4]=1\n    else:\n        test_labelss[k][5]=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1e14c6320a34011bc40a482d40e50a911964e33a"},"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(64, activation='relu', input_dim=561))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(6, activation='softmax'))\n\nsgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])\nmodel.fit(train_data, train_labelss,nb_epoch=30,batch_size=128)\nscore = model.evaluate(test_data, test_labelss, batch_size=128)\nprint(score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b16ee696a86aa4549937887a1df549d216072cc"},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\nmodel.fit(train_data, train_labelss,nb_epoch=30,batch_size=128)\nscore = model.evaluate(test_data, test_labelss, batch_size=128)\nprint(score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b5401efc3aeeff7a17ba8088a773981f36409d9c"},"cell_type":"code","source":"###### Random Forest #######\ntrainData  = train.drop('Activity' , axis=1).values\ntrainLabel = train.Activity.values\n\ntestData  = test.drop('Activity' , axis=1).values\ntestLabel = test.Activity.values\n\nencoder = LabelEncoder()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"14a5e93ea27dd7869fbf8e1d0117c2970fd111cf"},"cell_type":"code","source":"# encoding test labels \nencoder.fit(testLabel)\ntestLabelEncoder = encoder.transform(testLabel)\n\n# encoding train labels \nencoder.fit(trainLabel)\ntrainLabelEncoder = encoder.transform(trainLabel)\n\nrf = RandomForestClassifier(n_estimators=200,  n_jobs=4, min_samples_leaf=10)    \n#train\nrf.fit(trainData, trainLabelEncoder)\n\ny_te_pred = rf.predict(testData)\n\nacc = accuracy_score(testLabelEncoder, y_te_pred)\nprint(\"Random Forest Accuracy: %.5f\" % (acc))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"583787990cb2368cb3530d732f4579748cf11e90"},"cell_type":"code","source":"##### K-Nearest Neighbors ######\nclf = KNeighborsClassifier(n_neighbors=24)\n\nknnModel = clf.fit(trainData , trainLabelEncoder)\ny_te_pred = clf.predict(testData)\n\nacc = accuracy_score(testLabelEncoder, y_te_pred)\nprint(\"K-Nearest Neighbors Accuracy: %.5f\" % (acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"856f940449a36fcb5363fd5f74f8d40130028af0"},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e04699fd9d58531eedf25d092ac87c1b010354c9"},"cell_type":"code","source":"print(\"Number of features in Train : \", train.shape[1])\nprint(\"Number of records  in Train : \",train.shape[0])\nprint(\"Number of features in Test  : \",test.shape[1])\nprint(\"Number of records  in Test  : \",test.shape[0])\n\ntrainData  = train.drop(['subject','Activity'] , axis=1).values\ntrainLabel = train.Activity.values\n\ntestData  = test.drop(['subject','Activity'] , axis=1).values\ntestLabel = test.Activity.values\n\nprint(\"Train Data shape  : \",trainData.shape)\nprint(\"Train Label shape : \",trainLabel.shape)\nprint(\"Test Data  shape  : \",testData.shape)\nprint(\"Test Label shape  : \",testLabel.shape)\n\nprint(\"Label examples: \")\nprint(np.unique(trainLabel))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8bc6c02383ae7c67f0ddac9211fb6ae9422c9ae4"},"cell_type":"code","source":"from sklearn import preprocessing\nfrom sklearn import utils\n\nltrain = preprocessing.LabelEncoder()\nltest = preprocessing.LabelEncoder()\n\ntrainLabel = ltrain.fit_transform(trainLabel)\ntestLabel  = ltest.fit_transform(testLabel)\n\nprint(np.unique(trainLabel))\nprint(np.unique(testLabel))\nprint(\"Train Label shape : \",trainLabel.shape)\nprint(\"Test Label shape  : \",testLabel.shape)\nprint(utils.multiclass.type_of_target(testLabel))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c37d4724f6f213a01e6e5a8a1d023032cdba3a0"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.utils import shuffle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e49b4e9eb4140fcc6ce7f9ea9cc4272ea1ff6f41"},"cell_type":"code","source":"t0 = time.clock()\n# Create the RFE object and compute a cross-validated score.\nsvc = SVC(kernel=\"linear\")\n# The \"accuracy\" scoring is proportional to the number of correct\n# classifications\nrfecv = RFECV(estimator=svc, step=1, cv=StratifiedKFold(6),\n              scoring='accuracy')\n# Before training the data it is convenient to shuffle the data in training\nnp.random.seed(1)\nprint(\"Labels before Shuffle\",testLabel[0:5])\ntestData,testLabel = shuffle(testData,testLabel)\ntrainData,trainLabel = shuffle(trainData,trainLabel)\nprint(\"Labels after Shuffle\",testLabel[0:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c6dd9252db66ea4973f9dd2ae4e3d2eb790412eb"},"cell_type":"code","source":"# train and fit data in the model\nrfecv.fit(trainData, trainLabel)\n\nprint(\"Optimal number of features : %d\" % rfecv.n_features_)\nprint(\"Processing time sec \",time.clock() - t0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"66a55f18b817fd88388d14cb0c0b7747d712a660"},"cell_type":"code","source":"# Plot number of features VS. cross-validation scores\nplt.figure(figsize=(32,12))\nplt.xlabel(\"Number of features selected\")\nplt.ylabel(\"Cross validation score (nb of correct classifications)\")\nplt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d61c814f2390cafe2026d288449f90414328b50c"},"cell_type":"code","source":"print('Accuracy of the SVM model on test data is ', rfecv.score(testData,testLabel) )\nprint('Ranking of features starting from the best estimated \\n',rfecv.ranking_)\n# if we mask the features to get only the best we get this\nbest_features = []\nfor ix,val in enumerate(rfecv.support_):\n    if val==True:\n        best_features.append(testData[:,ix])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b4e8b74ad52f38a2820d9845c421505752b54272"},"cell_type":"code","source":"from pandas.tools.plotting import scatter_matrix\nvisualize = pd.DataFrame(np.asarray(best_features).T)\nprint(visualize.shape)\nscatter_matrix(visualize.iloc[:,0:5], alpha=0.2, figsize=(16, 16), diagonal='kde')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"42a6f60cd171bea377e9b22e3bdad3eb028cf62f"},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom sklearn.utils import shuffle\nfrom sklearn.preprocessing import LabelBinarizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a44b4b830f139dc139ac3dd0e25af866763b65e"},"cell_type":"code","source":"train = shuffle(train)\ntest = shuffle(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"452af43c40e409bf6ecf160d62602cff0cf3b108"},"cell_type":"code","source":"train_features = train.iloc[:,:562].as_matrix()\ntest_features = test.iloc[:,:562].as_matrix()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"512a41edbd1dd4141effcf96d9a857d72dc83797"},"cell_type":"code","source":"binarizer = LabelBinarizer().fit(train['Activity'])\ntrain_labels = binarizer.transform(train.Activity)\ntest_labels = binarizer.transform(test.Activity)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b42cea21d15573713c61e3f0211743acdc952564"},"cell_type":"code","source":"def weight_variable(shape):\n    \n    return tf.Variable(tf.truncated_normal(shape, stddev=0.1))\n\ndef bias_variable(shape):\n    \n    return tf.Variable(tf.truncated_normal(shape, stddev=0.1))\n\ndef add_layer(inputs, input_size, output_size, activation=None):\n    \n    W = weight_variable([input_size, output_size])\n    b = bias_variable([output_size])\n    wxb = tf.matmul(inputs, W) + b\n    if activation:\n        \n        return activation(wxb)\n    \n    else:\n        \n        return wxb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c2523fc13a36960ca4b88cae486feb441bf9443d"},"cell_type":"code","source":"X = tf.placeholder(tf.float32, [None, 562])\nlayer1 = add_layer(X, 562, 1000, tf.nn.relu)\nlayer2 = add_layer(layer1, 1000, 300, tf.nn.relu)\nlayer3 = add_layer(layer2, 300, 50, tf.nn.relu)\noutput = add_layer(layer3, 50, 6)\n\ny_ = tf.placeholder(tf.float32, [None, 6])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca77988d7c33569de1f970c2a5c7039a6a06ef8a"},"cell_type":"code","source":"loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=output, logits=y_))\noptimizer = tf.train.GradientDescentOptimizer(0.001)\ntrain_step = optimizer.minimize(loss)\n\ncorrect = tf.equal(tf.argmax(output,1), tf.argmax(y_,1))\nscore = tf.reduce_mean(tf.cast(correct, \"float\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"70f9500b2a948b18e316cacde513db8a388700a9"},"cell_type":"code","source":"sess = tf.Session()\ninit = tf.initialize_all_variables()\nsess.run(init)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"848c8f56783975b45213e4f8185f0807af87902a"},"cell_type":"code","source":"for i in range(10000):\n    \n    batch = np.random.choice(train_features.shape[0], 100)\n    _, cost = sess.run([train_step, loss],  feed_dict = {X:train_features[batch], y_:train_labels[batch]})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5316c99abcbfdc847ba3fb8f2fb3e328c89992e3"},"cell_type":"code","source":"print(sess.run(score, feed_dict={X: test_features, y_: test_labels}))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1454801dd8227172b71d6fec2dfcc7a1738bc56b"},"cell_type":"code","source":"#seperating class label from the dataset\n\ntrainLabels= train.Activity.values\ntrainData=train.drop(\"Activity\",axis=1).values\n\ntestLabels= test.Activity.values\ntestData=test.drop(\"Activity\",axis=1).values\n\nprint(\"Class labels striped off the dataset\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8fdc1d2c61e7cae2bd66be0947b041864a5cc955"},"cell_type":"code","source":"#transforming non-numerical labels to numerical labels using sklearn.preprocessing.LabelEncoder\n\nfrom sklearn import preprocessing\nlabelEncoder= preprocessing.LabelEncoder()\n\nlabelEncoder.fit(trainLabels)\ntrainLabelsE=labelEncoder.transform(trainLabels)\n\nlabelEncoder.fit(testLabels)\ntestLabelsE=labelEncoder.transform(testLabels)\n\nprint(\"Labels Transformed and Encoded\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6430b2d2454e7190e287c261ef27327951ec9023"},"cell_type":"code","source":"#applying k-nearest neighbours\nfrom sklearn.neighbors import KNeighborsClassifier as knn\nimport numpy as np\n\nknnScoreDistance=np.zeros(51)\nknnScoreUniform=np.zeros(51)\n\nfor num in range(5,51):\n    knnclf = knn(n_neighbors=num, weights='distance')\n    knnModel = knnclf.fit(trainData , trainLabelsE)\n    knnScoreDistance[num]=knnModel.score(testData  , testLabelsE )\n    print(\"Testing  set score for KNN_Distance(k=%d): %f\" %(num,knnScoreDistance[num]))\n    \nfor num in range(5,51):\n    knnclf = knn(n_neighbors=num, weights='uniform')\n    knnModel = knnclf.fit(trainData , trainLabelsE)\n    knnScoreUniform[num]=knnModel.score(testData  , testLabelsE )\n    print(\"Testing  set score for KNN_Uniform(k=%d): %f\" %(num,knnScoreUniform[num]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"65f4db02fe635e9393e589e18ec2d45a73018c88"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nx=np.array(range(5,51))\n\nplt.plot(x,knnScoreDistance[5:])\nplt.plot(x,knnScoreUniform[5:])\nplt.xlabel(\"No of neighbors (K)\")\nplt.ylabel(\"Test Data Mean Accuracy\")\nplt.legend(['KNN_Distance','KNN_Uniform'])\nplt.show","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"92d5128319c81e2b6ee6a3c7d10734c551487975"},"cell_type":"code","source":"import itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"180601f032e70badca1a494a1671f24254dca0d4"},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score,confusion_matrix\n\ndecsnTreeClf= DecisionTreeClassifier(criterion='entropy')\ntree=decsnTreeClf.fit(trainData,trainLabelsE)\ntestPred=tree.predict(testData)\n\nacc= accuracy_score(testLabelsE,testPred)\ncfs = confusion_matrix(testLabelsE, testPred)\n\nprint(\"Accuracy: %f\" %acc)\n\nplt.figure()\nclass_names = labelEncoder.classes_\nplot_confusion_matrix(cfs, classes=class_names,\n                      title='DecisionTree Confusion Matrix, without normalization')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"163738b8a1916480e8fad4d2cadb4e11c5cdeaf2"},"cell_type":"code","source":"decsnTreeClf= DecisionTreeClassifier()\ntree=decsnTreeClf.fit(trainData,trainLabelsE)\ntestPred=tree.predict(testData)\n\nacc= accuracy_score(testLabelsE,testPred)\ncfs = confusion_matrix(testLabelsE, testPred)\n\nprint(\"Accuracy: %f\" %acc)\n\nplt.figure()\nclass_names = labelEncoder.classes_\nplot_confusion_matrix(cfs, classes=class_names,\n                      title='DecisionTree Confusion Matrix, without normalization')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a6937b20d5a7a4c9c1385d739465698d207bd62c"},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9885f8f0c5fde6fcbaa912e5ec223fb36afec29b"},"cell_type":"code","source":"X, y = train_df.iloc[:, 0:len(train_df.columns) - 1], train_df.iloc[:, -1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cfe0a4fab7e6753239f72bde8e3c06d9607a4f8a"},"cell_type":"code","source":"X_test, y_test = test_df.iloc[:, 0:len(test_df.columns) -1], test_df.iloc[:, -1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"09d9ff7b60b8f7a807843029edf7b136b46be016"},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.metrics import accuracy_score # for evaluation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c618ae27a1136bbfb0764179c72dd5761e5e25db"},"cell_type":"code","source":"classifiers = [\n    DecisionTreeClassifier(),\n    KNeighborsClassifier(7), # because there are 6 different labels\n    SVC(),\n    GaussianNB(),\n    QuadraticDiscriminantAnalysis()\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"50cd480cfd970c03f7aaccf40bf05f434c153627"},"cell_type":"code","source":"names = []\nscores = []\n\nfor clf in classifiers:\n    clf = clf.fit(X, y)\n    y_pred = clf.predict(X_test)\n    \n    names.append(clf.__class__.__name__)\n    scores.append(accuracy_score(y_pred, y_test))\n\nscore_df = pd.DataFrame({'Model': names, 'Score': scores}).set_index('Model')\nscore_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c371e94a9401b7b65633f725e96e09c6ccfa74b"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nax = score_df.plot.bar()\nax.set_xticklabels(score_df.index, rotation=45, fontsize=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce03d06d00736f0ad1e5438004c71d4221ae2146"},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nparameters = {\n    'kernel': ['linear', 'rbf', 'poly','sigmoid'],\n    'C': [100, 50, 20, 1, 0.1]\n}\n\nselector = GridSearchCV(SVC(), parameters, scoring='accuracy') # we only care about accuracy here\nselector.fit(X, y)\n\nprint('Best parameter set found:')\nprint(selector.best_params_)\nprint('Detailed grid scores:')\nmeans = selector.cv_results_['mean_test_score']\nstds = selector.cv_results_['std_test_score']\nfor mean, std, params in zip(means, stds, selector.cv_results_['params']):\n    print('%0.3f (+/-%0.03f) for %r' % (mean, std * 2, params))\n    print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"849e10065bf9a297058fb6b987e1ad4b6210e451"},"cell_type":"code","source":"clf = SVC(kernel='linear', C=100).fit(X, y)\ny_pred = clf.predict(X_test)\nprint('Accuracy score:', accuracy_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"a670d6f2da50037fc6ad6978092801fc11d25483"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"f056538e3ecc5a96c85b9b51bd4c7a6af1dfde2e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}