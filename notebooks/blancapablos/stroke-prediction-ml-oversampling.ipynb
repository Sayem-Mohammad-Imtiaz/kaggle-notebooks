{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Stroke prediction\n\nMy goal was to try to improve the very low F1 scores and to compensate the imbalance in the dataset. I'm a beginner so any feedback is much appreciated!","metadata":{}},{"cell_type":"markdown","source":"### Import dataset","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\ndf =  pd.read_csv('/kaggle/input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data analysis","metadata":{}},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.stroke.value_counts() # Dataset is imbalanced","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data cleansing","metadata":{}},{"cell_type":"code","source":"df.drop(\"id\", axis=1, inplace=True)\ndf = df.sample(frac = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Treatment of null values\n","metadata":{}},{"cell_type":"code","source":"\ndf['smoking_status'].replace('Unknown', np.nan, inplace=True)\ndf['bmi'].fillna(df['bmi'].mean(), inplace=True)\ndf['smoking_status'].fillna(df['smoking_status'].mode()[0], inplace = True)\n\n#df.dropna(inplace=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Encoding","metadata":{}},{"cell_type":"markdown","source":"### Label encoding for categorical features with 2 values","metadata":{}},{"cell_type":"code","source":"\nfrom sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\n\nlabel_features = ['ever_married','Residence_type']\ndf[label_features] = df[label_features].apply(le.fit_transform)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### One hot encoding for categorical features with >2 values","metadata":{}},{"cell_type":"code","source":"ohe_features = ['gender','work_type','smoking_status']\nfor feat in ohe_features:\n    df[feat] = pd.Categorical(df[feat])\n    df_dummies = pd.get_dummies(df[feat], prefix = feat + '_encoded',drop_first=True)\n    df.drop(feat, axis=1, inplace=True)\n    df = pd.concat([df, df_dummies], axis=1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train-test split","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_x, test_x, train_y, test_y = train_test_split(df.drop('stroke',axis=1), df['stroke'], test_size=0.33, random_state=42)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\ntrain_x = scaler.fit_transform(train_x)\ntest_x = scaler.transform(test_x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Oversampling\n","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nfrom imblearn.over_sampling import RandomOverSampler\n\nsm = SMOTE(random_state=2)\ntrain_x, train_y = sm.fit_resample(train_x, train_y)\n#os = RandomOverSampler(sampling_strategy = 1)\n#train_x, train_y = os.fit_resample(train_x, train_y)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test models","metadata":{}},{"cell_type":"code","source":"from sklearn import svm\nfrom sklearn.metrics import f1_score, roc_auc_score, confusion_matrix, accuracy_score\n\nsvc = svm.SVC()\nsvc.fit(train_x, train_y)\n\ny_pred = svc.predict(test_x)\nf1 = f1_score(test_y, y_pred,average=None)\nroc = roc_auc_score(test_y, y_pred)\ncm = confusion_matrix(test_y, y_pred) \n\nprint('SVM\\n')\nprint('Confusion matrix: \\n',cm,'\\n')\nprint('Accuracy Score: {:.5f} \\n'.format(accuracy_score(test_y, y_pred)))\nprint('ROC AUC Score: {:.5f} \\n'.format(roc))\nprint('F1: {:.5f} {:.5f} \\n'.format(f1[0], f1[1]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlog = LogisticRegression(class_weight='balanced')\nlog.fit(train_x, train_y)\n\ny_pred = log.predict(test_x)\nf1 = f1_score(test_y, y_pred,average=None)\nroc = roc_auc_score(test_y, y_pred)\ncm = confusion_matrix(test_y, y_pred) \n\nprint('Logistic Regression\\n')\nprint('Confusion matrix: \\n',cm,'\\n')\nprint('Accuracy Score: {:.5f} \\n'.format(accuracy_score(test_y, y_pred)))\nprint('ROC AUC Score: {:.5f} \\n'.format(roc))\nprint('F1: {:.5f} {:.5f} \\n'.format(f1[0], f1[1]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\ngnb = GaussianNB()\ngnb.fit(train_x,train_y)\n\ny_pred = gnb.predict(test_x)\nf1 = f1_score(test_y, y_pred,average=None)\nroc = roc_auc_score(test_y, y_pred)\ncm = confusion_matrix(test_y, y_pred) \n\nprint('Gaussian Naive Bayes\\n')\nprint('Confusion matrix: \\n',cm,'\\n')\nprint('Accuracy Score: {:.5f} \\n'.format(accuracy_score(test_y, y_pred)))\nprint('ROC AUC Score: {:.5f} \\n'.format(roc))\nprint('F1: {:.5f} {:.5f} \\n'.format(f1[0], f1[1]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\n\ntree_para = {'criterion':['gini','entropy'],'max_depth':[4,5,6,7,8,9,10,11,12,15,20,30,40,50,70,90,120,150]}\ntree = GridSearchCV(DecisionTreeClassifier(random_state=0,class_weight='balanced'), tree_para, cv=5)\ntree.fit(train_x, train_y)\n\ny_pred = tree.predict(test_x)\nf1 = f1_score(test_y, y_pred,average=None)\nroc = roc_auc_score(test_y, y_pred)\ncm = confusion_matrix(test_y, y_pred) \n\nprint('Decision Tree with Grid Search\\n')\nprint('Confusion matrix: \\n',cm,'\\n')\nprint('Accuracy Score: {:.5f} \\n'.format(accuracy_score(test_y, y_pred)))\nprint('ROC AUC Score: {:.5f} \\n'.format(roc))\nprint('F1: {:.5f} {:.5f} \\n'.format(f1[0], f1[1]))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier(random_state=0,class_weight='balanced_subsample')\nrfc.fit(train_x,train_y)\n\ny_pred = rfc.predict(test_x)\nf1 = f1_score(test_y, y_pred,average=None)\nroc = roc_auc_score(test_y, y_pred)\ncm = confusion_matrix(test_y, y_pred) \n\nprint('Random Forest\\n')\nprint('Confusion matrix: \\n',cm,'\\n')\nprint('Accuracy Score: {:.5f} \\n'.format(accuracy_score(test_y, y_pred)))\nprint('ROC AUC Score: {:.5f} \\n'.format(roc))\nprint('F1: {:.5f} {:.5f} \\n'.format(f1[0], f1[1]))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\nxgb = XGBClassifier(eval_metric='error',use_label_encoder=False)\nxgb.fit(train_x,train_y)\n\ny_pred = xgb.predict(test_x)\nf1 = f1_score(test_y, y_pred,average=None)\nroc = roc_auc_score(test_y, y_pred)\ncm = confusion_matrix(test_y, y_pred) \n\nprint('XGB\\n')\nprint('Confusion matrix: \\n',cm,'\\n')\nprint('Accuracy Score: {:.5f} \\n'.format(accuracy_score(test_y, y_pred)))\nprint('ROC AUC Score: {:.5f} \\n'.format(roc))\nprint('F1: {:.5f} {:.5f} \\n'.format(f1[0], f1[1]))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from imblearn.ensemble import BalancedRandomForestClassifier\n\nbrf = BalancedRandomForestClassifier(random_state=42)\nbrf.fit(train_x,train_y)\n\ny_pred = brf.predict(test_x)\nf1 = f1_score(test_y, y_pred,average=None)\nroc = roc_auc_score(test_y, y_pred)\ncm = confusion_matrix(test_y, y_pred) \n\nprint('Balanced Random Forest\\n')\nprint('Confusion matrix: \\n',cm,'\\n')\nprint('Accuracy Score: {:.5f} \\n'.format(accuracy_score(test_y, y_pred)))\nprint('ROC AUC Score: {:.5f} \\n'.format(roc))\nprint('F1: {:.5f} {:.5f} \\n'.format(f1[0], f1[1]))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feel free to give your feedback in the comments! :)\n","metadata":{}}]}