{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\nprint(os.listdir(\"../input\"))\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import skimage\nfrom skimage.morphology import square, diamond, disk\nfrom keras.datasets import mnist\n\ndef prepareData():\n    train = pd.read_csv('../input/mnist-in-csv/mnist_train.csv').values\n    X_train = np.array(train[:,1:])/255  \n    y_train =  np.array(train[:,0])\n\n    val = pd.read_csv('../input/mnist-in-csv/mnist_test.csv').values\n    X_val = np.array(val[:,1:])/255\n    y_val =  np.array(val[:,0])\n    \n    X_train2 = np.array(train[:,1:])/255\n    for i in range(X_train.shape[0]):\n        if(i%4 == 0): shape = square(1)\n        if(i%4 == 1): shape = diamond(1)\n        if(i%4 == 2): shape = disk(1)\n        if(i%4 == 3): shape = None\n        X_train2[i,:] = skimage.morphology.erosion(X_train[i,:].reshape(28,28), shape).reshape(1,784)\n    X_train = np.concatenate((X_train, X_train2))\n    y_train = np.concatenate((y_train, y_train))\n    \n    X_train2 = np.array(X_train)\n    for i in range(X_train.shape[0]):\n        X_train2[i,:] = X_train[i,:] * (1 + np.random.normal(0, 0.25))\n    X_train = np.concatenate((X_train, X_train2))\n    y_train = np.concatenate((y_train, y_train))\n\n    y_test = np.ravel(pd.read_csv(\"../input/x-mnist/Y_MNIST.csv\").values)\n    return (X_train, y_train, X_val, y_val)\n\ntest = pd.read_csv('../input/x-test-nearlymnist/x_test.csv')\nIndex = test['Index']\nX_test = test.values[:, 1:]/255\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e04199b806219e1965838bafad825f4e3bb740aa"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3790906a11437e0bc9253774c4e3d11935d4541a"},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Lambda, Flatten, Conv2D, MaxPooling2D, MaxPool2D\nfrom keras.layers import LeakyReLU\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.optimizers import Adam, RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom sklearn.model_selection import train_test_split\n\nnum_classes = 10\nbatch_size = 64\nepochs = 20\ninput_shape = (28, 28, 1)\n\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_normal',input_shape=input_shape))\nmodel.add(Conv2D(32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_normal'))\nmodel.add(MaxPool2D((2, 2)))\nmodel.add(Dropout(0.20))\nmodel.add(Conv2D(32, (3, 3), activation='relu',padding='same',kernel_initializer='he_normal'))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(64, (3, 3), activation='relu',padding='same',kernel_initializer='he_normal'))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(32, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\nmodel.add(Dense(num_classes, activation='softmax'))\n\n\nmodel.compile(optimizer=RMSprop(),\n             loss='categorical_crossentropy',\n             metrics=['accuracy'])\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.0001)\n\n\n#history=model.fit(X_train, train_labels, validation_split=0.05,\n#                 epochs=10, batch_size=200)\nmodel.save_weights('initial')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"53c69f8cfd17aecf3a45868b6b6f40034e3972d0"},"cell_type":"code","source":"%%time\nfrom keras.utils.np_utils import to_categorical #One hot \n(X_train, y_train, X_val, y_val) = prepareData()\n\nX_train = X_train.reshape(X_train.shape[0], 28, 28,1)\nX_val = X_val.reshape(X_val.shape[0], 28, 28,1)\nX_test = X_test.reshape(X_test.shape[0], 28, 28,1)\n\ny_train = to_categorical(y_train)\ny_val = to_categorical(y_val)\nprint(\"Data ready\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"79f5a11814224b56329c42356f9e2fdf0bf540ff"},"cell_type":"code","source":"#model.load_weights('initial')\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=20, # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.2, # Randomly zoom image \n        width_shift_range=0.20,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.20,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n        \ndatagen.fit(X_train)\n\nh = model.fit_generator(datagen.flow(X_train, y_train, batch_size = 2048),\n                              epochs = 100, validation_data = (X_val , y_val),\n                              steps_per_epoch=10,  # // batch_size\n                              callbacks=[learning_rate_reduction]), \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a1cbfa20f5581da091f8cedb38899322aa36920c","scrolled":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(y_train.argmax(axis =1 ), model.predict(X_train).argmax(axis = 1))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"425316d027aaf6a9b05fbcb6f28948aac9040aa8"},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy_score(y_train.argmax(axis =1 ), model.predict(X_train).argmax(axis = 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"05442d57966292cb3aebad3f9b1356e4a7d52d7f"},"cell_type":"code","source":"confusion_matrix(y_train.argmax(axis =1 ), model.predict(X_train).argmax(axis = 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"998c7d0b5eb5ed639146c90c05f25e9a4edeee7b"},"cell_type":"code","source":"confusion_matrix(y_test2.argmax(axis =1 ), model2.predict(X_test2).argmax(axis = 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"70209f6f6934040ff4f5d7e0a80f49cbc02191a9"},"cell_type":"code","source":"[doubts[x] for x in model2.predict(X_test2).argmax(axis=1).tolist()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2b7656819f7cf9abceeb91c8dd34b408a13278b1"},"cell_type":"code","source":"\ndef classifier(doubts, epochs = 3):\n    indices_train = y_train.argmax(axis = 1) == -1\n    indices_val = y_val.argmax(axis = 1) == -1\n\n    for doubt in doubts:\n        indices_train = np.logical_or(indices_train, y_train.argmax(axis = 1) == doubt)\n        indices_val = np.logical_or(indices_val, y_val.argmax(axis = 1) == doubt)\n\n    X_train2 = np.array(X_train[indices_train])\n    y_train2 = np.array(y_train[indices_train])[:,doubts]\n    X_val2 = np.array(X_val[indices_val])\n    y_val2 = np.array(y_val[indices_val])[:,doubts]\n    \n    num_classes = len(doubts)\n    input_shape = (28, 28, 1)\n\n    model2 = Sequential()\n    model2.add(Conv2D(32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_normal',input_shape=input_shape))\n    model2.add(Conv2D(32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_normal'))\n    model2.add(MaxPool2D((2, 2)))\n    model2.add(Dropout(0.20))\n    model2.add(Conv2D(32, (3, 3), activation='relu',padding='same',kernel_initializer='he_normal'))\n    model2.add(MaxPool2D(pool_size=(2, 2)))\n    model2.add(Dropout(0.25))\n    model2.add(Conv2D(64, (3, 3), activation='relu',padding='same',kernel_initializer='he_normal'))\n    model2.add(Dropout(0.25))\n    model2.add(Flatten())\n    model2.add(Dense(32, activation='relu'))\n    model2.add(BatchNormalization())\n    model2.add(Dropout(0.25))\n    model2.add(Dense(num_classes, activation='softmax'))\n\n    datagen = ImageDataGenerator(\n            featurewise_center=False,  # set input mean to 0 over the dataset\n            samplewise_center=False,  # set each sample mean to 0\n            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n            samplewise_std_normalization=False,  # divide each input by its std\n            zca_whitening=False,  # apply ZCA whitening\n            rotation_range=25, # randomly rotate images in the range (degrees, 0 to 180)\n            zoom_range = 0.20, # Randomly zoom image \n            width_shift_range=0.20,  # randomly shift images horizontally (fraction of total width)\n            height_shift_range=0.20,  # randomly shift images vertically (fraction of total height)\n            horizontal_flip=False,  # randomly flip images\n            vertical_flip=False)  # randomly flip images\n\n\n    model2.compile(optimizer=RMSprop(),\n                 loss='categorical_crossentropy',\n                 metrics=['accuracy'])\n\n    learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                                patience=3, \n                                                verbose=1, \n                                                factor=0.5, \n                                                min_lr=0.0001)\n    datagen.fit(X_train2)\n    h = model2.fit_generator(datagen.flow(X_train2, y_train2, batch_size = 1024),\n                                  epochs = epochs, validation_data = (X_val2 , y_val2),\n                                  steps_per_epoch=10,  # // batch_size\n                                  callbacks=[learning_rate_reduction]), \n    \n    return (model2, X_train2, y_train2, X_val2, y_val2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"db87d1946fdd998e3b03ce7b49edbc995fb376cf"},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\ny_pred_bagged = model.predict(X_test).argmax(axis=1)\ndoubtMap = [[1,2], [1,7], [4,9], [6,0], [7,2] ]\n#doubts:[(1,2), (1,7), (4,9), (0,6), (7,2) ]\nfor doubt in doubtMap:\n    (model2, X_train2, y_train2, X_val2, y_val2) = classifier(doubt, epochs = 20)\n    y_pred2 = np.array([doubt[x] for x in model2.predict(X_test).argmax(axis=1).tolist()])\n    for x in doubt: y_pred_bagged = np.where(y_pred_bagged==x, y_pred2, y_pred_bagged)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b33c7d615d7a7c9d61ec84ee55f35b92b1d722c6"},"cell_type":"code","source":"print(confusion_matrix(y_test2.argmax(axis =1 ), model2.predict(X_test2).argmax(axis = 1)))\ny_pred2 = np.array([doubtMap[2][x] for x in model2.predict(X_test).argmax(axis=1).tolist()])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f8ac9bb6f2e5091824eb8dcfe6e49e6b5fcbbae"},"cell_type":"code","source":"doubtMap[2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c52fb42c0d7198205c25ebcbb9d61bad5e022c38"},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test.argmax(axis = 1), y_pred_bagged)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d5d5105d54941a7f5c3e4d5b57d2585c0aec3d7"},"cell_type":"code","source":"#y_pred = model.predict(X_test).argmax(axis=1)\nconfusion_matrix(y_test.argmax(axis =1), y_pred_bagged)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1bda0bc20b7e1d684f8eb2dcec54243d811b2463"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a4e7d85f169713e7ee94a8fe836b0fd791864a4f"},"cell_type":"code","source":"confusion_matrix(y_test.argmax(axis =1), y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"712fb5da04e4fbca6fca760a82f43de93acfd373"},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test.argmax(axis = 1), np.where(y_pred == 2, y_pred2, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a6f2c842eb869e0d166b6e28d6c76b28b450ea49"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"76fa815070991cc7b2f30f3adc59e61cfb5edb8d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"08ab2f7f85948c3a52a9c0b348b3d5dc048d3ccf"},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Lambda, Flatten, Conv2D, MaxPooling2D, MaxPool2D\nfrom keras.layers import LeakyReLU\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.optimizers import Adam, RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom sklearn.model_selection import train_test_split\n\nnum_classes = 10\nbatch_size = 64\nepochs = 20\ninput_shape = (28, 28, 1)\n\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_normal',input_shape=input_shape))\nmodel.add(Dense(32, activation='relu', input_shape=input_shape))\nmodel.add(Flatten())\nmodel.add(Dense(num_classes, activation='softmax'))\n\n\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=30, # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.20, # Randomly zoom image \n        width_shift_range=0.20,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.20,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\n\nmodel.compile(optimizer=RMSprop(),\n             loss='categorical_crossentropy',\n             metrics=['accuracy'])\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.0001)\n\n\n#history=model.fit(X_train, train_labels, validation_split=0.05,\n#                 epochs=10, batch_size=200)\nmodel.save_weights('initial2')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5f212e67bae74c8d3d9b49884e8e69517447204e"},"cell_type":"code","source":"from keras.utils.np_utils import to_categorical #One hot \n\n\ndatagen.fit(X_train)\nh = model.fit_generator(datagen.flow(X_train, y_train, batch_size = batch_size),\n                              epochs = 50, validation_data = (X_test , y_test),\n                              steps_per_epoch=500,  # // batch_size\n                       ), \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"7ae55c66b4f5b18779d2d7c3c2e098b79b497b95"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"093f891912877c9220cf2532fc432258d4bfdcad"},"cell_type":"code","source":"wrong = [y_test.argmax(axis =1 ) != model.predict(X_test).argmax(axis = 1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e697b997a3a8d7f8f932cd9c51d45d167986a38"},"cell_type":"code","source":"X_wrong = X_test[wrong]\n#y_wrong = y_test.argmax(axis = 1)[wrong]\ny_wrong = y_pred[wrong]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"31cfbbe93e8d856e53987ac0e485fce92937fcf4"},"cell_type":"code","source":"images_and_labels = list(zip(X_wrong.reshape(-1,28,28), y_wrong))\nfor index, (image, label) in enumerate(images_and_labels[:20]):\n    plt.subplot(5,4,index+1)\n    plt.axis('off')\n    plt.imshow(image, plt.cm.gray_r, interpolation='nearest')\n    plt.title('Test: ' + str(label))\n    \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"42ad62fd0cd1992793bcef44d7d95196366bd758"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"12178dd2399478ddb64af3b8e0353a1793bdf011"},"cell_type":"code","source":"def shift(X, row = 1, col = 1):\n    X = np.array(X)\n    X = X.reshape((X.shape[0], 28, 28))\n    if(row>0):\n        X[:,row:28, :] = X[:, :28-row, :]\n        X[:,0:row, :] = 0\n    if(row<0):\n        X[:,:28+row,:] = X[:, -row:28, :]\n        X[:,28+row:,:] = 0\n        \n    if(col>0):\n        X[:,:,col:28] = X[:,:,:28-col]\n        X[:,:,0:col] = 0\n    if(col<0):\n        X[:,:,:28+col] = X[:,:,-col:28]\n        X[:,:,28+col:] = 0\n        \n    return X.reshape((X.shape[0], 784))\n\n\n\n(X_train, y_train, X_val, y_val, X_test, y_test) = prepareMNISTdata()\nX_train = shift(X_train, 3, -3)\ni = 5\nplt.imshow(X_train[i].reshape((28, 28)))\nprint(y_train[i])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c8beb07378ba58853df0dc0b839f7997b319b81"},"cell_type":"code","source":"np.concatenate((X_train, X_train)).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a2d9bd08095f21baab00d53de0ee15698ec4e84b"},"cell_type":"code","source":"train = pd.read_csv('../input/mnist-in-csv/mnist_train.csv').values\nX_train = np.array(train[:,1:])/255\nX_train2 = np.array(train[:,1:])/255\ny_train =  np.array(train[:,0])\n\nval = pd.read_csv('../input/mnist-in-csv/mnist_test.csv').values\nX_val = np.array(val[:,1:])/255\ny_val =  np.array(val[:,0])\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"19c34210c6d424d40383637348f55990faf62438"},"cell_type":"code","source":"pd.read_csv('../input/mnist-in-csv/mnist_train.csv').head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd4d944b661337e76f819038e9a9d35cc2249f1a"},"cell_type":"code","source":"0.7 + np.random.random()/2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"409ca25e52596df200e249f66a1490d7b33f2a96"},"cell_type":"code","source":"X_train.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1623a967342413b0b9c33a90d9540e8f94f21764"},"cell_type":"code","source":"import pandas as pd\n#y_pred = model.predict(X_test).argmax(axis = 1)\ny_pred = y_pred_bagged\nimages_and_labels = list(zip(X_test.reshape(-1,28,28), y_pred))\nfor index, (image, label) in enumerate(images_and_labels[:8]):\n    plt.subplot(2,4,index+1)\n    plt.axis('off')\n    plt.imshow(image, plt.cm.gray_r, interpolation='nearest')\n    plt.title('Test: ' + str(label))\n    \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd37262d4dd3d1457958c07a085f577e0540ef61"},"cell_type":"code","source":"d = {'Index': Index, 'Labels': y_pred}\ndf = pd.DataFrame(data=d)\ndf.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a5a7036d68684cd0a0f9335ef983cebcd5745b77"},"cell_type":"code","source":"from IPython.display import HTML\nimport pandas as pd\nimport numpy as np\nimport base64\n\n# function that takes in a dataframe and creates a text link to  \n# download it (will only work for files < 2MB or so)\ndef create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n    csv = df.to_csv(index = False)\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\n# create a link to download the dataframe\ncreate_download_link(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dcdbd090509b23fc741e3e0a417c6dfd19bf7255"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}