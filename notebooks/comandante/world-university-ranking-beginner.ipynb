{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data=pd.read_csv(\"../input/cwurData.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2f9d94a1a2cc8e5ef68e55e4b86da398ea01493e"},"cell_type":"markdown","source":"**Data Exploration and Visualization**"},{"metadata":{"trusted":true,"_uuid":"cb5b8942653674a5e0a74efc1e89e41a3d0ef4e2"},"cell_type":"code","source":"data.info() # Memory and data types used","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b3d37e1a52d889dc2812f8d7084580a567d588d3"},"cell_type":"code","source":"data.head(10) #head function calls default  first 5 samples.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c959c5358e87de36d1741f50a57b8c031359026"},"cell_type":"code","source":"data.tail() #Last 5 samples.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"909158eff25e46c714d6f90e2124a3673105d3fe"},"cell_type":"code","source":"data.shape  # Row-Column","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"77bf2a42f18ea7cafa821c633a74be3dd48931ff"},"cell_type":"code","source":"data.describe() # Only Numeric Statistics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8248883d04a4f31ca6064095a2a854f48ed1e87a"},"cell_type":"code","source":"data.columns # Column names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"06bee99c514fee5ed94a24ed3d1716d5fba43d21"},"cell_type":"code","source":"data.isnull().sum() # Missing values control ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"26d930f86f578e173f8300ff42b96a41a7742a84","scrolled":true},"cell_type":"code","source":"data.corr() # Indicates the presence, direction and intensity of the relationship between the two variables","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d8864d43d76ae9ad59ac42f807d5d2908a3e228d"},"cell_type":"markdown","source":"Best Positive correlation is between **world_rank** and** broad_impact** =**0.94** <br/>\nBest Negative correlation is between ** score** and **quality_of_faculty** = -**0.69**"},{"metadata":{"trusted":true,"_uuid":"c41a5c6f26a052e3ff80ef02026b720011201a46"},"cell_type":"code","source":"#Correlation heatmap\nf,ax= plt.subplots(figsize=(18,18))\nsns.heatmap(data.corr(),annot=True,linewidths=.6,fmt='.2f',ax=ax) #annot=True :Visible numbers \nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"00e54adda84ea5ec7a293ef8ee55f4e5f1944124"},"cell_type":"markdown","source":"There is a large number of positive correlation between the sections in the data set. That means that when one section increases and the other increases in the same direction."},{"metadata":{"trusted":true,"_uuid":"e99f446b1ec6ba51618206733332277dea1b68aa"},"cell_type":"code","source":"data.cov() #Covaryans ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b9c7bad4f62f302a84ecebc9b46b26fed9bae78"},"cell_type":"code","source":"#Line plot\nplt.plot(data.score,data.world_rank,color='blue',label='world_rank',alpha=0.7)\nplt.plot(data.score,data.patents,color='red',label='patents',alpha=0.7)\nplt.plot(data.score,data.quality_of_faculty,color='green',label='quality_of_faculty',alpha=0.7)\nplt.legend()\nplt.xlabel('Score')\nplt.ylabel('y axis')\nplt.title('Line plot')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"67962e533eb64b975b8ad22f6bf4cc5cc53a534c"},"cell_type":"code","source":"#Scatter plot\ndata.plot(kind='scatter',x='world_rank',y='patents',alpha=0.5,color='blue')\nplt.xlabel('world_rank')\nplt.ylabel('patents')\nplt.title('world_rank - patents Scatter Plot')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6fed15104912b2fbaa45c3c2485a74335b06a2a7"},"cell_type":"code","source":"#Histogram \ndata.score.plot(kind='hist',bins=40,figsize=(15,15),color='green')\nplt.show()\n#Score frequency ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"25b4edf6db14f68d7400dcde4de39ca5c4d7270a"},"cell_type":"code","source":"#Boxplot\nplt.figure()\nplt.boxplot(data.score, 0, 'gD')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0643d4e72016ca21ef1ac38b9602402f69aa30e9"},"cell_type":"code","source":"#Score frequency and the change of outliers according to years\ndf = data[data.year.isin(data.year.value_counts().head(10).index)]\n\nsns.boxplot(\n    x='year',\n    y='score',\n    data=df\n)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"789911f3ecc5d6c80645033b827177042c1b6601"},"cell_type":"code","source":"P = np.percentile(data.score, [10, 100])\nP","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true,"_uuid":"3d1da5353d50997ce8574e38af3493a1a64e4f18"},"cell_type":"code","source":"data[(data['year']==2012)& (data['score']>=85) & (data['country']=='USA')].sort_values('score',axis=0,ascending=False) #Filtering and ordering by score\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ef0866e990d9c5f5f273af410b5af74c7e9917f7"},"cell_type":"code","source":"data['country'].unique() #Unique method doesn't show the same country again.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a6074c6789edf5394b8e6b4460cd066a4a0e7a54"},"cell_type":"code","source":"filter_1=data['year']==2012\nfilter_2=data['score']<45\nfilter_3=data['country']=='United Kingdom'\ndata[filter_1 & filter_2 & filter_3]\n#List of universities in the United Kingdom that were below 45 scores in 2012","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a40c492f9d3921154213f818f8b3f04e96a02b4"},"cell_type":"code","source":"#Let's add a new feature\nscore_average=sum(data.score) /len(data.score)\nmedian=data.score.median()\ndata['score_level']=['high' if i>score_average else 'Average'if median<i<=score_average else 'Low' for i in data.score]\ndata1=data.head()\ndata2=data.tail()\nconc_data_row=pd.concat([data1,data2],axis=0,ignore_index=True) # axis=0 adds dataframes in row\n#Let's see the data again.\nconc_data_row","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cb578fad780bab9acbc96e612c33bf69959d46f6"},"cell_type":"markdown","source":"**Exploratory Data Analysis**"},{"metadata":{"trusted":true,"_uuid":"20bbe03dd1e7704b3a458c368c9a604de1365216"},"cell_type":"code","source":"#For example lets look frequency of country types\nprint(data['country'].value_counts(dropna=False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe8ca243c4794ef75cdf4f4d7d37cd4405270a98"},"cell_type":"code","source":"data.describe() #ignore null entries and not number features\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9ccc807e79248471e0ba319d90602b80928e46c9"},"cell_type":"markdown","source":"**TIDY DATA**"},{"metadata":{"trusted":true,"_uuid":"4a85b56f196b025ca8fe35756a843b45f14201ee"},"cell_type":"code","source":"data_new=data.head(10)\ndata_new","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2c7ec0e6d25c23720e99215915bd98eb0e09891"},"cell_type":"code","source":"#melt function\n#frame : DataFrame\n#id_vars : tuple, list, or ndarray, optional\n#Column(s) to use as identifier variables.\n#value_vars : tuple, list, or ndarray, optional\n#Column(s) to unpivot. If not specified, uses all columns that are not set as id_vars.\nmelted=pd.melt(frame=data_new,id_vars='institution',value_vars=['score','patents'])\nmelted","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7d880d8d84914dc787d04291db418e5861dee233"},"cell_type":"markdown","source":"**PIVOTING DATA** <br/>\n  Reverse of melting."},{"metadata":{"trusted":true,"_uuid":"d1a00d23b31a1412eea067292df6eec7b22ec0b6"},"cell_type":"code","source":"#Index is name\n#Column to use to make new frame’s columns.\n#values:Column(s) to use for populating new frame’s values. \n#If not specified, all remaining columns will be used and the result will have hierarchically indexed columns.\n#Return reshaped DataFrame organized by given index / column values.\nmelted.pivot(index='institution',columns='variable',values='value')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8d9c262a3e464fc3ac1c1726bd57e20e6106d0a1"},"cell_type":"markdown","source":"**CONCATENATING DATA** <br/>\nTo concatenate two or more  data sets means to stack one \"on top\" of the other into a single  data set. \n "},{"metadata":{"trusted":true,"_uuid":"1e964b232f8eb853d8bf94eb6a05ee73ff811ec3"},"cell_type":"code","source":"#Lets make a sample\ndata1=data.head()\ndata2=data.tail()\nconc_data_row=pd.concat([data1,data2],axis=0,ignore_index=True) # axis=0 adds dataframes in row\nconc_data_row","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ccd548644d90099755f4f305afa5c3904d8389d"},"cell_type":"code","source":"data1=data['institution'].head(7)\ndata2=data['world_rank'].head(7)\nconc_data_col=pd.concat([data1,data2],axis=1) # axis=1 : adds dataframes in column\nconc_data_col","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1779f9d33bcec5e516ee64b1deed67815fc3447f"},"cell_type":"code","source":"#Let's see the distribution of countries by groupby method.\ndata.groupby(\"country\").size()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b9ba03da21e4b3a975aa32ed759c3a327ba5280c"},"cell_type":"markdown","source":"**DATA TYPES** <br/>\nThere are  5 basic data types: object(string),boolean,integer,float and categorical"},{"metadata":{"trusted":true,"_uuid":"379f8a273910268890977a43b8811fb2372f7b17"},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c6fc82388dad01aab807d253f846d21efd9067d1"},"cell_type":"code","source":"#Convert object(str) to categorical and int to float\ndata['country']=data['country'].astype('category')\ndata['quality_of_faculty']=data['quality_of_faculty'].astype('float')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ac44b3ee095bca8d717820a2eec9a64df12b95ac"},"cell_type":"code","source":"data.dtypes\n#country converted from object to categorical\n#quality_of_faculty converted from int to float","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e9c609567a2eaf6aea53705f65eb38a8c45b1647"},"cell_type":"markdown","source":"**MISSING DATA and TESTING WITH ASSERT** <br/>\n   \n   How do we handle missing data :\n*  Removing entire observations containing one or more unknown values\n* Filling in unknown values with the most frequent values\n* Filling in unknown values by exploring correlations\n* Filling in unknown values by exploring similarities between cases"},{"metadata":{"trusted":true,"_uuid":"17bd499a7ad9daf2a32e8a85709dbf15b66a1596"},"cell_type":"code","source":"#Let's look at  does World University Ranking data have non value\ndata.isnull().sum() # Missing values control","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7040c1eac69d1b09ee642fa23c3ffd3a07ee573d"},"cell_type":"code","source":"#Copy the data, opening a new memory\ndata1=data.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"58e126067ac27928b7a8a834d7c22d32a4324564"},"cell_type":"code","source":"#Convert categorical(str) to object again.\ndata1['country']=data1['country'].astype('object')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c92d026710b24ade58aece9b679f53ee9fa4b0b"},"cell_type":"code","source":"#Let's drop the broad_impact feature\ndata1_target = data1.broad_impact\ndata1_predictors = data1.drop(['broad_impact'], axis=1)\n\n# For the sake of keeping the example simple, we'll use only numeric predictors. \ndata1_numeric_predictors = data1_predictors.select_dtypes(exclude=['object'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"450bd166f85b45de250e6a368d4fe924dc8489c5"},"cell_type":"code","source":"data1_numeric_predictors #Only numeric features and non null","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"67bdb593ff1b9d3d034b648eba31127cf4d0f873"},"cell_type":"markdown","source":"**K-FOLD CROSS VALİDATİON**"},{"metadata":{"trusted":true,"_uuid":"b3e6b3e812204e2ab49c61552e29641902cfa966"},"cell_type":"code","source":"from sklearn.model_selection import KFold\n#Sample dataset\nds = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6])\n\n#K-Fold Cross Validation\nkfold = KFold(3, True, 1)\n\n#Return on the folds\nfor egitim, test in kfold.split(ds):\n    print('egitim: %s, test: %s' % (ds[egitim], ds[test]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e8ae4a588647884596e5c8ed744fae6688a2902"},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metrics import roc_curve, roc_auc_score\nfrom sklearn import model_selection\n\n#We select attribute values for training\nX = data1_numeric_predictors.iloc[:, :-1].values\n\n#We select attribute values for classification\n#I selected score_level feature\nY = data.iloc[: ,-1].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e02b5c18536ad56747dbf8156c367ec35c4b372d"},"cell_type":"code","source":"Y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c75d1fb660a816472d77b0208e020202679c184"},"cell_type":"code","source":"#Separation of training and test data sets\nvalidation_size = 0.20\nseed = 7\nX_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f4688efcafb4dbd9fd5eedb9f3df9dc7213fa507"},"cell_type":"markdown","source":"**CREATION OF NAIVE BAYES MODEL**"},{"metadata":{"trusted":true,"_uuid":"21d7f628a35b9a85f87b4a51472e335fbea9fafc"},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nmodel = GaussianNB()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"06bf2aaa81d088c0b295b7b4de4cd8d1feff5868"},"cell_type":"code","source":"#Calculation of ACC with K-fold cross validation of NB model\nscoring = 'accuracy'\nkfold = model_selection.KFold(n_splits=10, random_state=seed)\ncv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"de43a629fbf20f8cd6cdb0c179cf20a80cfaea3c"},"cell_type":"code","source":"cv_results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bcb8700d40809817335ce9dbab678c70428dc536"},"cell_type":"code","source":"msg = \"%f (%f)\" % (cv_results.mean(), cv_results.std())\nmsg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"50782f99dd0b0d3f2b4499f9bde26c262a37ecbb"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n\nmodel.fit(X_train, Y_train)\n\nY_pred = model.predict(X_test)\n\n# Summary of the predictions made by the classifier\nprint(classification_report(Y_test, Y_pred))\nprint(confusion_matrix(Y_test, Y_pred))\n# Accuracy score\nfrom sklearn.metrics import accuracy_score\nprint(\"ACC: \",accuracy_score(Y_pred,Y_test))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5004deb0ee35b1e915e721099b916f223bdcaaec"},"cell_type":"markdown","source":"**Accuracy** :  Accuracy is the most intuitive performance measure and it is simply a ratio of correctly predicted observation to the total observations. One may think that, if we have high accuracy then our model is best. Yes, accuracy is a great measure but only when you have symmetric datasets where values of false positive and false negatives are almost same. Therefore, you have to look at other parameters to evaluate the performance of your model. For our model, we have got 0.909 which means our model is approx. 90% accurate.\n\nAccuracy = TP+TN/TP+FP+FN+TN\n\n**Precision** : Precision is the ratio of correctly predicted positive observations to the total predicted positive observations.  High precision relates to the low false positive rate. We have got Average=0.86 , Low=0.95, high=0.88  precision which is pretty good.\n\nPrecision = TP/TP+FP\n\n**Recall** (Sensitivity) -:  Recall is the ratio of correctly predicted positive observations to the all observations in actual class - We have got Average=0.85 , Low=0.94 , high=0.91 recall  which is good for this model as it’s above 0.5.\n\nRecall = TP/TP+FN\n\n**F1 score**  :  F1 Score is the weighted average of Precision and Recall. Therefore, this score takes both false positives and false negatives into account. Intuitively it is not as easy to understand as accuracy, but F1 is usually more useful than accuracy, especially if you have an uneven class distribution. Accuracy works best if false positives and false negatives have similar cost. If the cost of false positives and false negatives are very different, it’s better to look at both Precision and Recall. In our case, F1 score : Average=0.86, Low=0.95 ,high=0.89 \n\nF1 Score = 2*(Recall * Precision) / (Recall + Precision)\n\n"},{"metadata":{"_uuid":"1355c35b6087a63632a59203655ef2f2434fa7d5"},"cell_type":"markdown","source":"**Multiple Linear Regression** <br/>\n\nMultiple linear regression is the most common form of linear regression analysis.  As a predictive analysis, the multiple linear regression is used to explain the relationship between one continuous dependent variable and two or more independent variables.  The independent variables can be continuous or categorical .\n"},{"metadata":{"trusted":true,"_uuid":"14bb24df9a4150a603736c8ee095a61d76e93e77"},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad0946bcd4d50ccc43a17487e829d09bc7e5a7d8"},"cell_type":"code","source":"x=data1_numeric_predictors.iloc[:,[0,1,2,3,4,5,6,7,8,10]].values #all features except score\ny=data1_numeric_predictors.score.values.reshape(-1,1) #Score\n#fitting data\nmultiple_linear_regression=LinearRegression()\nmultiple_linear_regression.fit(x,y)\n\nprint(\"b0 :\",multiple_linear_regression.intercept_) #Intercept\nprint(\"b1,b2,b3,b4,b5,b6,b7,b8,b9,b10 :\",multiple_linear_regression.coef_) #coefficients","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}