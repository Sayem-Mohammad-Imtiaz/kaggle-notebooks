{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-26T18:12:22.477236Z","iopub.execute_input":"2021-05-26T18:12:22.477585Z","iopub.status.idle":"2021-05-26T18:12:22.487156Z","shell.execute_reply.started":"2021-05-26T18:12:22.477553Z","shell.execute_reply":"2021-05-26T18:12:22.486173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import chi2_contingency, normaltest","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:12:22.490972Z","iopub.execute_input":"2021-05-26T18:12:22.491238Z","iopub.status.idle":"2021-05-26T18:12:22.499138Z","shell.execute_reply.started":"2021-05-26T18:12:22.491206Z","shell.execute_reply":"2021-05-26T18:12:22.498294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **I. Wybór tematu i zbioru danych**\n\nDo wykonania projektu zdecydowałem się wykorzystać język Python. Jako środowisko notatnik Kaggle, a jako bazę danych E-commerce shipping Data.\n\nPowyższy zbiór danych posiada następujące kolumny:\n* **ID:** numer identyfikacyjny klientów.\n* **Warehouse block:** Firma posiada duży Magazyn, który jest podzielony na bloki takie jak A, B, C, D, E.\n* **Mode of shipment:** Firma wysyła produkty na wiele sposobów, np. Drogą morską, lotniczą i drogową.\n* **Customer care calls:** Liczba połączeń wykonanych z zapytania o zapytanie o przesyłkę.\n* **Customer rating:** firma wystawiła ocenę od każdego klienta. 1 to najniższa (najgorsza), 5 to najwyższa (najlepsza).\n* **Cost of the product:** Koszt produktu w dolarach amerykańskich.\n* **Prior purchases:** liczba wcześniejszych zakupów.\n* **Product importance:** Firma sklasyfikowała produkt pod kątem różnych parametrów, takich jak niski, średni, wysoki.\n* **Gender:** mężczyzna i kobieta.\n* **Discount offered:** Rabat oferowany na ten konkretny produkt.\n* **Weight in gms:** jest to waga w gramach.\n* **Reached on time:** Jest to zmienna docelowa, gdzie 1 oznacza, że produkt NIE został dostarczony na czas, a 0 oznacza, że został dostarczony na czas.\n\n**Cel analizy**\nWybrano trzy hipotezy, które zostaną sprawdzone w poniższej pracy. Każda z hipotez została oparta o inną zmienną zależną.\n\n**Hipoteza 1:** Przedmioty o wyższym priorytecie, droższe i transportowane drogą lotniczą zostają dostarczone na czas.\n\n**Hipoteza 2:** Osoby chętniej dają wyższe wyniki w zależności od obsługi klienta i jakości usług.\n\n**Hipoteza 3:** Badanie wysokości zniżek zaproponowanym klientom w zależności od ich płci, kosztów produktu i historii ich zakupów.","metadata":{}},{"cell_type":"markdown","source":"# **II. Czyszczenie i analiza danych**","metadata":{}},{"cell_type":"code","source":"#Wczytanie bazy danych do lokalnej zmiennej\ndata = pd.read_csv(\"../input/customer-analytics/Train.csv\")\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:12:22.500586Z","iopub.execute_input":"2021-05-26T18:12:22.500834Z","iopub.status.idle":"2021-05-26T18:12:22.53418Z","shell.execute_reply.started":"2021-05-26T18:12:22.500809Z","shell.execute_reply":"2021-05-26T18:12:22.533233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Przed podjęciem pracy nad danym, zestawem danych należy przebadać, czy dane nie posiadają braków.","metadata":{}},{"cell_type":"code","source":"data.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:12:22.535388Z","iopub.execute_input":"2021-05-26T18:12:22.535636Z","iopub.status.idle":"2021-05-26T18:12:22.545839Z","shell.execute_reply.started":"2021-05-26T18:12:22.535613Z","shell.execute_reply":"2021-05-26T18:12:22.544863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Wybrany zestaw danych nie posiada, żadnych braków.","metadata":{}},{"cell_type":"markdown","source":"1. Opracuj podstawowe statystyki dla każdej zmiennej ilościowej.\n\nDla wybranego zbioru zmienne ilościowe obejmują kolumny:\nCustomer_care_calls, Cost_of_the_Product, Prior_purchuases, Discount_offered, Weight_in_gms. I te kolumny zostaną poddane analizie statystycznej","metadata":{}},{"cell_type":"code","source":"quant_col = ['Customer_care_calls', 'Cost_of_the_Product', 'Prior_purchases','Discount_offered', 'Weight_in_gms']\nquant_stats = data[quant_col].agg([\"count\",\"mean\",\"median\",\"min\", \"max\", \"std\", \"var\",])\nquant_stats = quant_stats.append(data[quant_col].mode().rename(index={0:\"mode\"}))\nquant_stats","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:12:22.547324Z","iopub.execute_input":"2021-05-26T18:12:22.54773Z","iopub.status.idle":"2021-05-26T18:12:22.579542Z","shell.execute_reply.started":"2021-05-26T18:12:22.547693Z","shell.execute_reply":"2021-05-26T18:12:22.578662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2. Opracuj tabele liczności dla każdej zmiennej jakościowej z hipotez\n\nDo zbadania hipotez wykorzystane zostaną zmienne jakościowe z kolumn: 'Warehouse_block', 'Mode_of_Shipment','Product_importance' oraz 'Gender'. Poniżej przedstawione zostaną tabele liczności dla wartości tych zmiennych w formie histogramów","metadata":{}},{"cell_type":"code","source":"quali_cols = ['Warehouse_block', 'Mode_of_Shipment','Product_importance', 'Gender', 'Customer_rating']\nfig, axes = plt.subplots(len(quali_cols), 1, figsize=(10,30))\nfor i, col in enumerate(quali_cols):\n    axes[i].set_title(f\"Wykres rozkładu liczności dla {col}\")\n    sns.histplot(data[col], ax=axes[i])\n    print(f\"\"\"Dla kolumny {col} tabela liczności wygląda następująco:\\n\\n\\n{pd.DataFrame(data[col].value_counts())}\\n\"\"\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:12:22.580973Z","iopub.execute_input":"2021-05-26T18:12:22.581367Z","iopub.status.idle":"2021-05-26T18:12:23.280149Z","shell.execute_reply.started":"2021-05-26T18:12:22.581329Z","shell.execute_reply":"2021-05-26T18:12:23.279228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Na powyższych histogramach można zauważyć, że dane dostarczone do analizy posiadają zbliżony do siebie rozkład prawdopodobieństwa dla płci oraz oceny klientów. Dla kolumny Warehouse_block widzimy, że dane zawierają taką samą ilość zamówień pochodzących z bloków A,B,C oraz D. Z bloku F natomiast pochodzi ok. 2 razy więcej zamowień niż z pozostałych. Na kolejnym histogramie (Mode_of_shipement) można zauważyć analogiczną sytuację, gdzie paczki są rzadziej dostarczane samolotem i drogą lądową niż statkiem. Można sprawdzić jak dostarczane są pazcki z każdego bloku.","metadata":{}},{"cell_type":"code","source":"sns.histplot(x=data[\"Mode_of_Shipment\"],hue=data[\"Warehouse_block\"])\ndata[[\"Mode_of_Shipment\", \"Warehouse_block\", \"ID\"]].groupby([\"Warehouse_block\", \"Mode_of_Shipment\"]).count()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:12:23.281361Z","iopub.execute_input":"2021-05-26T18:12:23.281632Z","iopub.status.idle":"2021-05-26T18:12:23.499826Z","shell.execute_reply.started":"2021-05-26T18:12:23.281607Z","shell.execute_reply":"2021-05-26T18:12:23.498821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Jak widać z każdego bloku paczki wychodzą w podobnym stosunku co do rodzaju środka transportu 1:1:5 (Fliht:Road:Ship)","metadata":{}},{"cell_type":"markdown","source":"Dla hipotezy 1 sporządzono tabele wielodzielcze dla zmeinnych jakościowych względem kolumny Reached_on_time","metadata":{}},{"cell_type":"code","source":"for col in quali_cols:\n    print(pd.crosstab(data[col], data[\"Reached.on.Time_Y.N\"], normalize=\"index\"))\n    print(\"\\n\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:12:23.502052Z","iopub.execute_input":"2021-05-26T18:12:23.502313Z","iopub.status.idle":"2021-05-26T18:12:23.577842Z","shell.execute_reply.started":"2021-05-26T18:12:23.502286Z","shell.execute_reply":"2021-05-26T18:12:23.576816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Patrząc na sporządzone tabele wielodzielcze dla hipotezy 1, ciężko zauważyć zależność zmiennych jakościowych od powodzenia dostarczenia przesyłki na czas. W każdym przypadku jest to stosunek ok. 40%-60% paczek dostarczonych na czas od niedostarczonych. Wyjątkiem od tej reguły są paczki o wysokim priorytecie, gdzie stosunek paczek dostarczonych na czas do paczek niedostarczonych na czas wynosi 35%-65%. ","metadata":{}},{"cell_type":"markdown","source":"Poniżej wizyalizacja wyników","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(len(quali_cols), 1, figsize=(10,30))\nfor i, col in enumerate(quali_cols):\n    axes[i].set_title(f\"Wykres histogramu skategoryzowanego {col}\")\n    #sns.histplot(data = data, x=data[\"Reached.on.Time_Y.N\"], hue=col, ax=axes[i])\n    sns.histplot(data = data, x=data[col], hue=\"Reached.on.Time_Y.N\", ax=axes[i], multiple=\"dodge\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:12:23.580104Z","iopub.execute_input":"2021-05-26T18:12:23.580496Z","iopub.status.idle":"2021-05-26T18:12:24.557218Z","shell.execute_reply.started":"2021-05-26T18:12:23.580442Z","shell.execute_reply":"2021-05-26T18:12:24.556234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dla hipotezy 2 sporządzono tabele wielodzielcze dla zmeinnych jakościowych względem kolumny 'Customer_rating'","metadata":{}},{"cell_type":"code","source":"for col in quali_cols[:-1]:\n    print(pd.crosstab(data[col], data['Customer_rating'], normalize=\"index\"))\n    print(\"\\n\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:12:24.558582Z","iopub.execute_input":"2021-05-26T18:12:24.558942Z","iopub.status.idle":"2021-05-26T18:12:24.628467Z","shell.execute_reply.started":"2021-05-26T18:12:24.558905Z","shell.execute_reply":"2021-05-26T18:12:24.627608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Podobnie jak w cześniejszym przypadku nie można zauważyć zależności pomiędzy zmiennymi jakościowymi, a opiniami klientów. Jesteśmy w stanie zobaczyć rozkład jednostajny udziałów każdej z kategorii dla ocen klientów.","metadata":{}},{"cell_type":"markdown","source":"Poniżej wizualizacja wyników","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(len(quali_cols[:-1]), 1, figsize=(10,30))\nfor i, col in enumerate(quali_cols[:-1]):\n    axes[i].set_title(f\"Wykres histogramu skategoryzowanego {col}\")\n    #sns.histplot(data = data, x=data[\"Reached.on.Time_Y.N\"], hue=col, ax=axes[i])\n    sns.histplot(data = data, x=data[col], hue=\"Customer_rating\", ax=axes[i], multiple=\"dodge\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:12:24.629573Z","iopub.execute_input":"2021-05-26T18:12:24.629853Z","iopub.status.idle":"2021-05-26T18:12:26.384063Z","shell.execute_reply.started":"2021-05-26T18:12:24.629826Z","shell.execute_reply":"2021-05-26T18:12:26.383257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dla hipotezy 3 sporządzono tabele wielodzielcze dla zmeinnych jakościowych względem kolumny 'Discount_offered'. Z powodu, że kolumna \"Discount_offered\" zawiera różne wartości to, aby jaśniej i bardziej zrozumiale przedstawić dane, wartości te zostały zamknięte w 3 równych przedziałach pomiędzy wartością minimum 0 a maksimum 65 (wartości z wcześniejszej analizy zmiennych ilościowych).","metadata":{}},{"cell_type":"code","source":"hipo_3 = data.copy()\nhipo_3.Discount_offered = hipo_3.Discount_offered.astype(str)\nhipo_3.Discount_offered.values[data[\"Discount_offered\"].values < 17] = \"<17\"\nhipo_3.Discount_offered.values[(data[\"Discount_offered\"].values < 34) & (data[\"Discount_offered\"].values >= 17)] = \"17<=x<34\"\nhipo_3.Discount_offered.values[(data[\"Discount_offered\"].values < 51) & (data[\"Discount_offered\"].values >= 34)] = \"34<=x<51\"\nhipo_3.Discount_offered.values[(data[\"Discount_offered\"].values <= 65) & (data[\"Discount_offered\"].values >= 51)] = \"51<=x<=65\"\n\nfor col in quali_cols:\n    print(pd.crosstab(hipo_3[col], hipo_3['Discount_offered'], normalize=\"index\"))\n    print(\"\\n\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:12:26.385274Z","iopub.execute_input":"2021-05-26T18:12:26.385533Z","iopub.status.idle":"2021-05-26T18:12:26.476803Z","shell.execute_reply.started":"2021-05-26T18:12:26.385509Z","shell.execute_reply":"2021-05-26T18:12:26.475973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dla hipotezy 3 i przygotowanej tabeli wielodzielczej, również jak w poprzednich przykładach nie widać większej zależności pomięzy zmiennymi jakościowymi a rodzajem zniżki. Wszystkie są na podobnym poziomie","metadata":{}},{"cell_type":"markdown","source":"Poniżej wizualizacja wyników","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(len(quali_cols), 1, figsize=(10,30))\nfor i, col in enumerate(quali_cols):\n    axes[i].set_title(f\"Wykres histogramu skategoryzowanego {col}\")\n    #sns.histplot(data = data, x=data[\"Reached.on.Time_Y.N\"], hue=col, ax=axes[i])\n    sns.histplot(data = hipo_3, x=hipo_3[col], hue='Discount_offered', ax=axes[i], multiple=\"dodge\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:12:26.477952Z","iopub.execute_input":"2021-05-26T18:12:26.4782Z","iopub.status.idle":"2021-05-26T18:12:27.78422Z","shell.execute_reply.started":"2021-05-26T18:12:26.478169Z","shell.execute_reply":"2021-05-26T18:12:27.783549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"5. Wykonanie macierzy korelacji","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15,10))\nsns.heatmap(data.corr(), annot=True, ax=ax)\ndata.corr()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:12:27.785325Z","iopub.execute_input":"2021-05-26T18:12:27.785622Z","iopub.status.idle":"2021-05-26T18:12:28.332245Z","shell.execute_reply.started":"2021-05-26T18:12:27.785592Z","shell.execute_reply":"2021-05-26T18:12:28.331234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Wykluczając kolumny ID, możemy zauważyć, że słaba korelacja występuje dla par zmiennych:\n\n* Weight_in_gms i Customer_care_calls (-0.28) - jest to słaba ujemna korelacja co oznacza, że wraz ze wzrostem jednej zmiennej druga maleje. Oznaczałoby to, że wraz ze wzrostem wagi spada zainteresowanie sprzedawcy o satysfakcję klienta co wydaje się nielogiczne, więc możemy odrzucić tą parę.\n* Weight_in_gms i Discount_offered (-0.38) - jest to słaba ujemna korelacja, która oznaczałaby, że sprzedawca obiecuje mniejsze zniżki na cięższe produkty. Jest to możliwy scenariusz, ponieważ lżejsze przedmioty zajmują mniej miejsca, przez co spadają koszty wysyłki i możliwe jest, że sprzedawca będzie oferował za takie przedmioty większe zniżki.\n* Weight_in_gms i Reached_on_time (-0.27) - jest to słaba ujemna korelacja, która oznaczałaby, że cięższe przesyłki częściej zostają dostarczone na czas. Jest to możliwy scenariusz, ponieważ cięższe przeysłki mogą kosztować więcej przez co sprzedawca przykłada więcej uwagi takim przesyłkom. Niestety hipoteza ta nie jest prawdziwa, ponieważ patrząc następnie na korelację kosztu produktu z dostarczaniem przesyłek widać, że nie są one skorelowane.\n* Discount_offered i Reached_on_time (0.4) - jest to słaba dodatnia korelacja, która oznaczałaby, że im większa jest zniżka na przeysłkę tym częściej przesyłki zostają dostarczone. Może to być korelacja pozorna, ponieważ ciężko znaleźć logiczne wytłumaczenie takiego stanu rzeczy.\n* Customer_care_call i Cost_of_the_Product (0.32) - jest to słaba dodatnia korelacja, która oznaczałaby, że im większa cena produktu tym chętniej sprzedawca, dba o klienta. Jest to logiczne wytłumaczenie tej korelacji.\n\nZ powyższych wymienionych korelacji jedyną, która wydaje się mieć logiczne wytłumaczenie jest korelacja pomiędzy Customer_care_call i Cost_of_the_Product. Reszta wydaje się być korelacją pozorną.","metadata":{}},{"cell_type":"markdown","source":"7. Test niezależności przy użyciu testu chi^2 przy założeniu poziomu istotności alfa = 0.05, zakładając za hipotezę zerową, że zmienne są niezależne.","metadata":{}},{"cell_type":"markdown","source":"Na samym początku sprawdzimy niezależność każdej z kolumn względem kolumny \"Reached.on.Time_Y.N\" (hipoteza 1)","metadata":{}},{"cell_type":"code","source":"cols_to_drop = [\"ID\", \"Reached.on.Time_Y.N\"]\nfor col in data.columns:\n    if col not in cols_to_drop:\n        contigency = pd.crosstab(data[col], data[\"Reached.on.Time_Y.N\"])\n        chi,p_value,degrees_of_freedom , expected_freq = chi2_contingency(contigency)\n        print(f\"Dla kolumny {col} wartość p testu niezależności wynosi {p_value}\")\n        if p_value <= 0.05:\n            print(f\"Wartość p jest mniejsza dla założonego poziomu istotności co pozwala na odrzucenie hipotezy zerowej - zmienne są zależne\\n\")\n        else:\n            print(f\"Wartość p jest większa dla założonego poziomu istotności co potwierdza hipotezę zerową - zmienne są niezależne\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:12:28.333353Z","iopub.execute_input":"2021-05-26T18:12:28.333635Z","iopub.status.idle":"2021-05-26T18:12:28.512975Z","shell.execute_reply.started":"2021-05-26T18:12:28.333607Z","shell.execute_reply":"2021-05-26T18:12:28.512161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"W wyniku testu niezależności dla hipotezy pierwszej uzyskaliśmy informację, że zmienne Customer_care_calls, Cost_of_the_Product, Prior_purchases, Product_importance, Discount_offered i Weight_in_gms są zależne ze zmienną jakościową Reached.on.Time_Y.N\nNastępnie przeprowadzamy taki sam test dla hipotezy drugiej.","metadata":{}},{"cell_type":"code","source":"cols_to_drop = [\"ID\", \"Customer_rating\"]\nfor col in data.columns:\n    if col not in cols_to_drop:\n        contigency = pd.crosstab(data[col], data[\"Customer_rating\"])\n        chi,p_value,degrees_of_freedom , expected_freq = chi2_contingency(contigency)\n        print(f\"Dla kolumny {col} wartość p testu niezależności wynosi {p_value}\")\n        if p_value <= 0.05:\n            print(f\"Wartość p jest mniejsza dla założonego poziomu istotności co pozwala na odrzucenie hipotezy zerowej - zmienne są zależne\\n\")\n        else:\n            print(f\"Wartość p jest większa dla założonego poziomu istotności co potwierdza hipotezę zerową - zmienne są niezależne\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:12:28.514311Z","iopub.execute_input":"2021-05-26T18:12:28.514714Z","iopub.status.idle":"2021-05-26T18:12:28.725604Z","shell.execute_reply.started":"2021-05-26T18:12:28.514675Z","shell.execute_reply":"2021-05-26T18:12:28.724583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"W wyniku testu niezależności dla hipotezy drugiej uzyskaliśmy informację, że wszystkie zmienne są niezależne ze zmienną jakościową Customer_rating\nNa samym końcu przeprowadzamy ten sam test dla trzeciej ostatniej hipotezy.","metadata":{}},{"cell_type":"code","source":"cols_to_drop = [\"ID\", \"Discount_offered\"]\nfor col in data.columns:\n    if col not in cols_to_drop:\n        contigency = pd.crosstab(data[col], data[\"Discount_offered\"])\n        chi,p_value,degrees_of_freedom , expected_freq = chi2_contingency(contigency)\n        print(f\"Dla kolumny {col} wartość p testu niezależności wynosi {p_value}\")\n        if p_value <= 0.05:\n            print(f\"Wartość p jest mniejsza dla założonego poziomu istotności co pozwala na odrzucenie hipotezy zerowej - zmienne są zależne\\n\")\n        else:\n            print(f\"Wartość p jest większa dla założonego poziomu istotności co potwierdza hipotezę zerową - zmienne są niezależne\\n\")\n","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:12:28.727065Z","iopub.execute_input":"2021-05-26T18:12:28.727445Z","iopub.status.idle":"2021-05-26T18:12:29.115179Z","shell.execute_reply.started":"2021-05-26T18:12:28.727404Z","shell.execute_reply":"2021-05-26T18:12:29.114135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"W wyniku testu niezależności dla hipotezy trzeciej uzyskaliśmy informację, że zmienne Customer_care_calls, Prior_purchases, Product_importance, Weight_in_gms i Reached.on.Time_Y.N są zależne ze zmienną jakościową Discount_offered\n\n8. Wykonaj wykresy ramka-wąsy dla wszystkich zmiennych ilościowych z hipotez.\n    Wybierz dwie pary zmiennych (ilościowa-jakościowa) i wykonaj wykresy","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(len(quant_col),1,  figsize=(10,30))\nfor i, col in enumerate(quant_col):\n    axes[i].set_title(f\"Wykres pudełkowy kolumny {col}\")\n    #sns.histplot(data = data, x=data[\"Reached.on.Time_Y.N\"], hue=col, ax=axes[i])\n    sns.boxplot(data = data, x=data[col], ax=axes[i], orient = \"h\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:12:29.116648Z","iopub.execute_input":"2021-05-26T18:12:29.116985Z","iopub.status.idle":"2021-05-26T18:12:29.655254Z","shell.execute_reply.started":"2021-05-26T18:12:29.116955Z","shell.execute_reply":"2021-05-26T18:12:29.65436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Wykresy pudełkowe pozwalają lepiej zapoznać sie z rozkładem zmiennych w zespole danych oraz dodatkowo pozwalają w łatwy sposób zauważyć wartości odstające w postaci punktów wystających poza wąsy (punkty te znajdują się w zakresach kwantyli 0-25 oraz 75-100). Jednak zawsze przed zakwalifikowaniem jakiś danych do wartości odstających należy się zastanowić, co powinno się z nimi zrobić i czy wpływają one w dużym stopniu negatywnie na modele predykcyjne.\n    W przypadku Prior_purchases mamy doczynienia z 1003 wartościami odstającymi. Możemy przyglądnąć się tym przesyłkom.","metadata":{}},{"cell_type":"code","source":"data[data[\"Prior_purchases\"]>=6]","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:12:29.656364Z","iopub.execute_input":"2021-05-26T18:12:29.656624Z","iopub.status.idle":"2021-05-26T18:12:29.681809Z","shell.execute_reply.started":"2021-05-26T18:12:29.656599Z","shell.execute_reply":"2021-05-26T18:12:29.680857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Z wcześniejszych analiz wiemy, że Prior_purchuases nie mają większej korelacji z innymi zmiennymi, jednak nie chcąc tracić 1003 rekordów zdecydowano się na zastąpienie wartości Prior_purchases większych bądź równych 6 przez losową wartość w przedziale <2,5>","metadata":{}},{"cell_type":"code","source":"import random\ndata.loc[data[\"Prior_purchases\"] >= 6,\"Prior_purchases\"] = data[\"Prior_purchases\"].apply(lambda x: random.randrange(2,5))","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:12:29.683322Z","iopub.execute_input":"2021-05-26T18:12:29.683707Z","iopub.status.idle":"2021-05-26T18:12:29.705824Z","shell.execute_reply.started":"2021-05-26T18:12:29.68367Z","shell.execute_reply":"2021-05-26T18:12:29.704883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sprawdzamy jak zmienił się rozkład zmiennych","metadata":{}},{"cell_type":"code","source":"sns.boxplot(data = data, x=data[\"Prior_purchases\"], orient = \"h\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:12:29.707378Z","iopub.execute_input":"2021-05-26T18:12:29.7077Z","iopub.status.idle":"2021-05-26T18:12:29.814941Z","shell.execute_reply.started":"2021-05-26T18:12:29.707668Z","shell.execute_reply":"2021-05-26T18:12:29.813991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Następnym wykresem, gdzie występują wartości odstające to \"Discount_offered\". Jednak w tym przypadku zdecydowano zostawić te wartości, ponieważ mimo, że znacząco odstają od reszty to zawierają bardzo istotną informację, która nie wynika z błędu pomiarowego. Mozemy się przyjrzeć tym wartościom.","metadata":{}},{"cell_type":"code","source":"data[data[\"Discount_offered\"]>20]","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:12:29.816139Z","iopub.execute_input":"2021-05-26T18:12:29.816375Z","iopub.status.idle":"2021-05-26T18:12:29.836763Z","shell.execute_reply.started":"2021-05-26T18:12:29.816352Z","shell.execute_reply":"2021-05-26T18:12:29.835971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Do wykonania wykresów pudełkowych skategoryzowanych wybrano pary:\nZmienna jakościowa: Reached.on.Time_Y.N, Zmienna ilościowa: Cost_of_the_product\nZmienna jakościowa: Product_improtance, Zmianna ilościowa: Cost_of_the_product","metadata":{}},{"cell_type":"code","source":"sns.boxplot(data = data, x=\"Reached.on.Time_Y.N\", y = \"Cost_of_the_Product\", orient=\"v\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:12:29.839761Z","iopub.execute_input":"2021-05-26T18:12:29.840031Z","iopub.status.idle":"2021-05-26T18:12:29.956219Z","shell.execute_reply.started":"2021-05-26T18:12:29.840003Z","shell.execute_reply":"2021-05-26T18:12:29.955294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(data = data, x=\"Product_importance\", y = \"Cost_of_the_Product\", orient=\"v\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:12:29.958554Z","iopub.execute_input":"2021-05-26T18:12:29.958933Z","iopub.status.idle":"2021-05-26T18:12:30.098199Z","shell.execute_reply.started":"2021-05-26T18:12:29.958892Z","shell.execute_reply":"2021-05-26T18:12:30.097194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Obserwując skategoryzowane wykresy pudełkowe można zauważyć, że nie ma większych róznic pomiędzy poszzcególnymi kategoriami, a zmiennymi ilościowymi","metadata":{}},{"cell_type":"markdown","source":"9. Wykonaj test normalny dla zmiennych - oznacz wartości odstające \n\nNa samym początku sporządzono wykresy rozkładu wartości zmiennych ilościowych, aby sprawdzić czy dana analiza jest potrzebna i przydatna do analizy.","metadata":{}},{"cell_type":"code","source":"\nfig, axes = plt.subplots(len(quali_cols), 1, figsize=(10,30))\nfor i, col in enumerate(quant_col):\n    axes[i].set_title(f\"Wykres rozkładu liczności dla {col}\")\n    sns.histplot(data[col], ax=axes[i], kde=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:12:30.099834Z","iopub.execute_input":"2021-05-26T18:12:30.10026Z","iopub.status.idle":"2021-05-26T18:12:31.786423Z","shell.execute_reply.started":"2021-05-26T18:12:30.100219Z","shell.execute_reply":"2021-05-26T18:12:31.785498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, col in enumerate(quant_col):\n    print(f\"Wartość p dla testu normalnego dla kolumny {col} wynosi {normaltest(data[col].values).pvalue}\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:12:31.78763Z","iopub.execute_input":"2021-05-26T18:12:31.787908Z","iopub.status.idle":"2021-05-26T18:12:31.802763Z","shell.execute_reply.started":"2021-05-26T18:12:31.787881Z","shell.execute_reply":"2021-05-26T18:12:31.801949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Jak widać dla każdej kolumny zmiennej ilościowej nie posiadamy rozkładu normalnego. Jest to cecha tego zbioru danych i nie powinno się zmieniać jego wartości, aby rozkład zmiennych był bliski do rozkładu normalnego. Niestety z tego powodu nie możemy stosować parametrycznych metod statystycznych w celu przewidywania zmiennych zależnych.","metadata":{}},{"cell_type":"markdown","source":"# **III Indukcja drzew decyzyjnych**","metadata":{}},{"cell_type":"markdown","source":"1. Utwórz drzewo klasyfikacyjne dla zmiennej jakościowej. Jeśli zmienna zależna jest ilościowa, utwórz drzewo regresyjne.\n\nDo sprawdzenia hipotezy pierwszej dotyczącej dostarczenia przesyłek na czas wybrano następujące zmienne niezależne:\n* Discount_offered\n* Weight_in_gms\n* Product_importance\n\n\nDzięki obserwacjom z podpunktu drugiego. Zrezygnowano ze zmiennej dotyczącej rodzaju środku transportu, oraz kosztu produktu ponieważ, zbadana korelacja oraz test niezależnosć wskazały niestotność tych zmiennych na badaną zmienną zależną.","metadata":{}},{"cell_type":"code","source":"# improtowanie potrzebnych bibliotek\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, plot_confusion_matrix, precision_recall_fscore_support\npd.options.mode.chained_assignment = None\n\n# oddzielenie potrzebnych danych\nhipo_1_data = data[[\"Discount_offered\", \"Weight_in_gms\", \"Product_importance\"]]\nhipo_1_y = data[\"Reached.on.Time_Y.N\"]\n\n# jedna ze zmiennych (\"Product_importance\") to zmienna jakościowa w postaci, słów. \n#Aby algorytm mógł przetworzyć te dane, należy zamienić je na postać liczbową. \n#Z racji tego, że są to zmienne typu uporządkowanego możemy je zmapować od najniżej do najwyżeszj\n\ndecode = {\n    \"low\" : 1,\n    \"medium\" : 2,\n    \"high\" : 3\n}\n\nhipo_1_data.loc[:, \"Product_importance\"] = hipo_1_data.Product_importance.map(decode).values\n\n# rozdzielenie danych na sety treningowe i testowe\nX_train, X_test, y_train, y_test = train_test_split(hipo_1_data, hipo_1_y, train_size=0.7, random_state=1)\nX_train\n\n# ładowanie modelu\ntree_model = DecisionTreeClassifier(min_samples_leaf=200)\n\n# trenowanie modelu\ntree_model.fit(X_train, y_train)\n\n# sprawdzanie dokłądności modelu na danych testowych\n\npreds = tree_model.predict(X_test)\nacc = accuracy_score(y_test, preds)\nprint(f\"Dokładność modelu wynosi {100*acc:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:12:31.80442Z","iopub.execute_input":"2021-05-26T18:12:31.80473Z","iopub.status.idle":"2021-05-26T18:12:31.831208Z","shell.execute_reply.started":"2021-05-26T18:12:31.804702Z","shell.execute_reply":"2021-05-26T18:12:31.83035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2. Określ ważność predyktorów z użyciem wykresu.","metadata":{}},{"cell_type":"code","source":"var_importances = tree_model.feature_importances_\nstd = np.std(var_importances,axis=0)\nindices = np.argsort(var_importances)\nplt.figure()\nplt.title(\"Ważność predyktorów\")\nplt.barh(range(hipo_1_data.shape[1]), var_importances[indices],\n       color=\"r\", xerr=std, align=\"center\")\nplt.yticks(range(hipo_1_data.shape[1]), hipo_1_data.columns)\nplt.ylim([-1, hipo_1_data.shape[1]])\nplt.grid(b=True)\nplt.xlim(0, 1)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:12:31.832299Z","iopub.execute_input":"2021-05-26T18:12:31.832569Z","iopub.status.idle":"2021-05-26T18:12:31.94495Z","shell.execute_reply.started":"2021-05-26T18:12:31.832543Z","shell.execute_reply":"2021-05-26T18:12:31.944029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(25,20))\nplot_tree(tree_model, filled=True, rounded=True, feature_names=X_train.columns, class_names=[\"On Time\",\"Not on Time\"])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:12:31.946141Z","iopub.execute_input":"2021-05-26T18:12:31.946413Z","iopub.status.idle":"2021-05-26T18:12:34.439101Z","shell.execute_reply.started":"2021-05-26T18:12:31.946385Z","shell.execute_reply":"2021-05-26T18:12:34.438162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Reguły:\n\nReguła 1: przesyłki, którym udzielono więcej niż 10,5% rabatu nie docierały na czas. Jest to relatywnie szybka konkuzja bo została ona podjęta już z samego korzenia. Wartość gini równa 0 sugeruje, że wszystkie dane, gdzie zniżka wynosiła ponad 10,5% były zaklasyfikowane jako przesyłki, które nie zostały dostarczone na czas. Mogło tak być, właśnie dlatego, że firma dawała zniżki na produkty, których dostawa się opóźniała. Im większe opóźnienie tym większa zniżka. \n\nWsparcie tej reguły wynosi:\n1842/7699 * 100% = 23,93%\n\nUfność tej reguły wynosi:\n1842/7699 * 100% = 23,93%\n\nReguła 2: Przesyłki, którym udzielono mniej lub równo 10,5% rabatu oraz, które ważą mniej niż 4005,5g ale więcej niż 2003,5g nie docierały na czas. Konkluzja ta została podjęta w węźle 3 i również charakteryzuje się bardzo niską wartością gini (0.076) co implikuej, że większość próbek (około 92%) spełniająca tą regułę nie zostaje dostarczona na czas.\n\nWsparcie tej reguły wynosi:\n201/7699 * 100% = 2,61%\n\nUfność tej reguły wynosi:\n201/462 * 100% = 43,51%\n\nŻadne inne reguły nie są na tyle wyraziste, żeby je wymienić\n\n","metadata":{}},{"cell_type":"code","source":"plot_confusion_matrix(tree_model, X_test, y_test, display_labels=[\"Not on time\", \"On Time\"])\nprecission, recall, f_score, support = precision_recall_fscore_support(y_test, preds)\nprint(f\"Dokładność (precission) modelu podczas określania czy dana przesyłka dotrze do adresata wynosi {precission[1]:.2f}, natomiast rozpoznanie ilość (recall) dla tej klasy wynosi {recall[1]:.2f}\")\nprint(f\"Oznacza to, że {100 * precission[1]:.2f}% paczek, które zostały sklasyfikowane jako paczki dostaczonych na czas zostało poprawnie sklasyfikowanych, a {100 * recall[1]:.2f}% wszystkich paczek dostarczonych na czas zostało poprawnie sklasyfikowanych.\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:12:34.440277Z","iopub.execute_input":"2021-05-26T18:12:34.440553Z","iopub.status.idle":"2021-05-26T18:12:34.590414Z","shell.execute_reply.started":"2021-05-26T18:12:34.440525Z","shell.execute_reply":"2021-05-26T18:12:34.58953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Analizując wyniki predykcji drzewa decyzyjnego jesteśmy w stanie potwierdzić hipotezę, że to czy przesyłki zostały dostarczone na czas zależą od założonych zmiennych objaśniających. Dokładność modelu została określona na poziomie około 70% co jest bardzo dobrym wynikiem patrząc na bardzo słabe zależności pomiędzy zmiennymi objaśniającymi a zmienną objaśnianą oraz patrząc na rodzaj dostarczonych zmiennych (brak przewidywalnego rozkładu zmiennych).Dodatkowo następnie sprawdzone precission i recall pokazują, że model spełnia swoje założenia w formie zadowalającej. Przeprowadzając dodatkową optymalizację możnaby było uzyskać jeszcze lepsze wyniki i poprawienie wartości recall, jednakże biorąc pod uwagę dostarczone dane wyniki są zadowalające.","metadata":{}},{"cell_type":"markdown","source":"Do sprawdzenia hipotezy drugiej dotyczącej wpływu na oceny klientów wybrano następujące zmienne niezależne:\n\n* Cost_of_the_Product\n* Customer_care_calls\n\nZmienne zależne wybrano dzięki obserwacjom z podpunktu drugiego. Zmienna Cost_of_the_product wykazywała słabą korelację ze zmienną niezależną, natomiast Customer_care_calls zostało wybrane jako dodatkowa zmienna. Tą hipotezę bardzo trudno udowodnić z powodu braku zależnosci zmeinnej jakosciowej z innymi zmiennymi","metadata":{}},{"cell_type":"code","source":"# oddzielenie potrzebnych danych\nhipo_2_data = data[[\"Cost_of_the_Product\", \"Customer_care_calls\"]]\nhipo_2_y = data[\"Customer_rating\"]\n\n\n# rozdzielenie danych na sety treningowe i testowe\nX_train, X_test, y_train, y_test = train_test_split(hipo_2_data, hipo_2_y, train_size=0.7, random_state=1)\n\n# ładowanie modelu\ntree_model = DecisionTreeClassifier(min_samples_leaf=500)\n\n# trenowanie modelu\ntree_model.fit(X_train, y_train)\n\n# sprawdzanie dokłądności modelu na danych testowych\n\npreds = tree_model.predict(X_test)\nacc = accuracy_score(y_test, preds)\nprint(f\"Dokładność modelu wynosi {100*acc:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:12:34.591924Z","iopub.execute_input":"2021-05-26T18:12:34.592302Z","iopub.status.idle":"2021-05-26T18:12:34.611141Z","shell.execute_reply.started":"2021-05-26T18:12:34.592261Z","shell.execute_reply":"2021-05-26T18:12:34.610231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2. Określ ważność predyktorów z użyciem wykresu.","metadata":{}},{"cell_type":"code","source":"var_importances = tree_model.feature_importances_\nstd = np.std(var_importances,axis=0)\nindices = np.argsort(var_importances)\nplt.figure()\nplt.title(\"Ważność predyktorów\")\nplt.barh(range(hipo_2_data.shape[1]), var_importances[indices],\n       color=\"r\", xerr=std, align=\"center\")\nplt.yticks(range(hipo_2_data.shape[1]), hipo_2_data.columns)\nplt.ylim([-1, hipo_2_data.shape[1]])\nplt.grid(b=True)\nplt.xlim(0, 1)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:12:34.6125Z","iopub.execute_input":"2021-05-26T18:12:34.61302Z","iopub.status.idle":"2021-05-26T18:12:34.718045Z","shell.execute_reply.started":"2021-05-26T18:12:34.612978Z","shell.execute_reply":"2021-05-26T18:12:34.717082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"3. Odczytaj i sformalizuj na podstawie drzewa 3-5 reguł dla najbardziej wyrazistych klas \n    lub dla liści o najmniejszej wariancji (dla każdej hipotezy).","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(25,20))\nplot_tree(tree_model, filled=True, rounded=True, feature_names=X_train.columns, class_names=[\"1\",\"2\", \"3\", \"4\", \"5\"])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:12:34.719061Z","iopub.execute_input":"2021-05-26T18:12:34.719301Z","iopub.status.idle":"2021-05-26T18:12:36.088177Z","shell.execute_reply.started":"2021-05-26T18:12:34.719278Z","shell.execute_reply":"2021-05-26T18:12:36.08752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"4. Oceń pewność (prawdopodobieństwo) i wsparcie tych reguł (w drzewie regresyjnym oceń wariancję w liściach).","metadata":{}},{"cell_type":"markdown","source":"Z powodu słabej zależnosci pomiędzy zmiennymi wyjaśniającymi, a zmienną objaśnianą wygenerowane drzewo osiągnęło bardzo małą dokładnośc jak i regóły, które zostały wygenerowane mają bardzo niską czystość (współczynnik gini na poziomie 0,8). Jednakże, na potrzeby zadania wybrano reguły:\n\n**Reguła 1:** Produkty, które kosztują mniej bądź równo 157,5 zostały oceniane przez klientów na 4.\n\nWsparcie tej reguły wynosi:\n854/7699 * 100% = 11,09%\n\nUfność tej reguły wynosi:\n854/1492 * 100% = 57,24%\n\n**Reguła 2:** Produkty, które kosztują mniej bądź równo 245,5 oraz w sprawie których wykonano mniej niż 4 telefony zostały oceniane przez klientów na 1.\n\nWsparcie tej reguły wynosi:\n532/7699 * 100% = 6,91%\n\nUfność tej reguły wynosi:\n532/1126 * 100% = 47,25%\n\n\n**Reguła 3:** Produkty, które kosztują mniej bądź równo 245,5 oraz w sprawie których wykonano więcej niż 3 telefony zostały oceniane przez klientów na 5.\n\nWsparcie tej reguły wynosi:\n594/7699 * 100% = 7,72%\n\nUfność tej reguły wynosi:\n532/1126 * 100% = 52,75%","metadata":{}},{"cell_type":"code","source":"display_labels=[\"1\",\"2\", \"3\", \"4\", \"5\"]\nplot_confusion_matrix(tree_model, X_test, y_test, display_labels=display_labels)\nprecission, recall, f_score, support = precision_recall_fscore_support(y_test, preds)\nfor i, label in enumerate(display_labels):\n    print(f\"Dokładność (precission) modelu podczas określania czy dana przesyłka zostanie oceniona na {label} wynosi {precission[i]:.2f}, natomiast rozpoznanie ilość (recall) dla tej klasy wynosi {recall[i]:.2f}\")\n    print(f\"Oznacza to, że {100 * precission[i]:.2f}% paczek, które zostały sklasyfikowane jako ocenione na {label} zostało poprawnie sklasyfikowanych, a {100 * recall[i]:.2f}% wszystkich paczek sklasyfikowanych jako ocenione na {label} zostało poprawnie sklasyfikowanych.\\n\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:12:36.089162Z","iopub.execute_input":"2021-05-26T18:12:36.089551Z","iopub.status.idle":"2021-05-26T18:12:36.300875Z","shell.execute_reply.started":"2021-05-26T18:12:36.089512Z","shell.execute_reply":"2021-05-26T18:12:36.299887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Analizując wyniki drzew decyzyjnych dla hipotezy drugiej należy ją odrzucić. Model radzi sobie bardzo słabo (podobne prawdopodobieństwo można by było uzyskać losując liczby przy pomocy generatora, bądź kostki). Wyniki potwierdza dodatkowo wykonana macierz klasyfikacji i wylizcone z niej parametry. Dodatkowo reguły drzewa decyzyjnego są obarczone bardzo dużą niepewnością.","metadata":{}},{"cell_type":"markdown","source":"Do sprawdzenia hipotezy trzeciej dotyczącej wpływu na zastosowaną zniżkę wybrano zmienne niezależne:\n\n* Reached.on.Time_Y.N\n* Weight_in_gms\n* Customer_care_calls\n\nZmienne zależne wybrano dzięki obserwacjom z podpunktu drugiego. W tym wypadku mamy doczynienia z przewidywania wartości dlatego, należy wykorzystać drzewo regresyjne.","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import r2_score\n\n\n# oddzielenie potrzebnych danych\nhipo_3_data = data[[\"Reached.on.Time_Y.N\", \"Weight_in_gms\", \"Customer_care_calls\"]]\nhipo_3_y = data[\"Discount_offered\"]\n\n\n# rozdzielenie danych na sety treningowe i testowe\nX_train, X_test, y_train, y_test = train_test_split(hipo_3_data, hipo_3_y, train_size=0.7, random_state=1)\n\n# ładowanie modelu\ntree_model = DecisionTreeRegressor(min_samples_leaf=500)\n\n# trenowanie modelu\ntree_model.fit(X_train, y_train)\n\n# sprawdzanie dokłądności modelu na danych testowych\n\npreds = tree_model.predict(X_test)\nr2score = r2_score(y_test, preds)\nprint(f\"Współczynnik zbieżności wynosi {((1 - r2score) * 100):.2f}% - Dopasowanie modelu jest tym lepsze im bardziej współczynnik zbieżności jest bliżej 0%\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:12:36.302359Z","iopub.execute_input":"2021-05-26T18:12:36.30275Z","iopub.status.idle":"2021-05-26T18:12:36.324055Z","shell.execute_reply.started":"2021-05-26T18:12:36.30271Z","shell.execute_reply":"2021-05-26T18:12:36.323256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2. Określ ważność predyktorów z użyciem wykresu.","metadata":{}},{"cell_type":"code","source":"var_importances = tree_model.feature_importances_\nstd = np.std(var_importances,axis=0)\nindices = np.argsort(var_importances)\nplt.figure()\nplt.title(\"Ważność predyktorów\")\nplt.barh(range(hipo_3_data.shape[1]), var_importances[indices],\n       color=\"r\", xerr=std, align=\"center\")\nplt.yticks(range(hipo_3_data.shape[1]), hipo_3_data.columns)\nplt.ylim([-1, hipo_3_data.shape[1]])\nplt.grid(b=True)\nplt.xlim(0, 1)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:12:36.325688Z","iopub.execute_input":"2021-05-26T18:12:36.326056Z","iopub.status.idle":"2021-05-26T18:12:36.435392Z","shell.execute_reply.started":"2021-05-26T18:12:36.326019Z","shell.execute_reply":"2021-05-26T18:12:36.434529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"3. Odczytaj i sformalizuj na podstawie drzewa 3-5 reguł dla najbardziej wyrazistych klas \n    lub dla liści o najmniejszej wariancji (dla każdej hipotezy).","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(25,20))\nplot_tree(tree_model, filled=True, rounded=True, feature_names=X_train.columns)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:12:36.436908Z","iopub.execute_input":"2021-05-26T18:12:36.437279Z","iopub.status.idle":"2021-05-26T18:12:37.736013Z","shell.execute_reply.started":"2021-05-26T18:12:36.437239Z","shell.execute_reply":"2021-05-26T18:12:37.7354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"4. Oceń pewność (prawdopodobieństwo) i wsparcie tych reguł (w drzewie regresyjnym oceń wariancję w liściach).","metadata":{}},{"cell_type":"markdown","source":"Zamiast wariancji sklearn wykorzystuje MSE (Mean Square Error) do określenia jakości drzewa. Jak widać lewa część drzewa wygląda bardzo dobrze (MSE w liściach na niskim poziomie ok 300-400) co wskazuje na bardzo dobre dopasowanie średniej wartości w liściach do wartości rzeczywistych. Prawa strona drzewa natomiast posiada bardzo wysokie wartośći MSE (na poziomie około 8000) co powoduje, że drzewo jest bardzo mało wiarygodne jeżeli bedziemy chcieli przewidywać wartości zaoferowanych zniżek dla paczek które ważą więcej niż 4000g. Potwierdza to wartośc dopasowania modelu (51,99%) wskazując, że model jest dobrze dopasowany tylko w połowie. Dlatego hipotezę tą można przyjąć tylko dla paczek poniżej wagi 4000g. Dla całej populacji należu odrzucić hipotezę.","metadata":{}},{"cell_type":"markdown","source":"# **IV. Analiza skupień:**\n\n1. Wybierz zmienne do analizy - uzasadnij.\n\nDo wykonania analizy skupień wybrano zmienne:\n\n* Gender\n* Weight_in_gms\n* Cost_of_the_Product\n\nCelem analizy jest sprawdzenie, czy jesteśmy w stanie wyznaczyć jakieś konkretne grupy produktów kupowanych przez konsumentów różnych płci w zależności od ich masy i kosztów produktu.","metadata":{}},{"cell_type":"code","source":"# improtowanie potrzebnych bibliotek\nfrom sklearn.cluster import KMeans\npd.options.mode.chained_assignment = None\nfrom sklearn.decomposition import PCA\n\ndecode = {\n    \"M\" : 0,\n    \"F\" : 1,\n}\n\n# oddzielenie potrzebnych danych\ncluster_data = data[[\"Weight_in_gms\", \"Gender\", \"Cost_of_the_Product\"]]\ncluster_data.loc[:, \"Gender\"] = cluster_data.Gender.map(decode).values\n\nsse = []\n\n# ładowanie modelu\nfor k in range(1,11):\n    cluster_model = KMeans(n_clusters=k)\n    cluster_model.fit(cluster_data)\n    sse.append(cluster_model.inertia_)\n    \n# sprawdzanie jaką wartość k wybrać - metoda łokcia\n\nplt.style.use(\"fivethirtyeight\")\nplt.plot(range(1, 11), sse)\nplt.xticks(range(1, 11))\nplt.xlabel(\"Wartość k\")\nplt.ylabel(\"SSE\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:12:37.736916Z","iopub.execute_input":"2021-05-26T18:12:37.737248Z","iopub.status.idle":"2021-05-26T18:12:54.217922Z","shell.execute_reply.started":"2021-05-26T18:12:37.737224Z","shell.execute_reply":"2021-05-26T18:12:54.216974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Jak widać na powyższym wykresie najrozsądniejsza ilość klastrów jaką powinno się wybrać jest 2.\nDo automatycznego doboru ilości klastrów można wykorzystać silhouette coefficient score.\n\nSilhouette Coefficient jest obliczany przy użyciu średniej odległości wewnątrz klastra (a) i średniej odległości do najbliższego klastra (b) dla każdej próbki. Współczynnik sylwetki dla próbki to (b - a) / max (a, b). Aby wyjaśnić, b to odległość między próbką a najbliższą gromadą, której próbka nie jest częścią. Zwróć uwagę, że silhouette coefficient jest definiowany tylko wtedy, gdy liczba etykiet wynosi 2 <= n_labels <= n_samples - 1.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import silhouette_score\n\nsil_score_max = -1\nbest_n_clusters = 0\n\nfor k in range(2,11):\n  cluster_model = KMeans(n_clusters = k)\n  labels = cluster_model.fit_predict(cluster_data)\n  sil_score = silhouette_score(cluster_data, labels)\n  print(f\"Średnia wartość silhouette score dla {k} klastrów wynosi {sil_score}\")\n  if sil_score > sil_score_max:\n    sil_score_max = sil_score\n    best_n_clusters = k\n    \nprint(f\"Najlepsza ilość klastrów to: {best_n_clusters}\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:12:54.219233Z","iopub.execute_input":"2021-05-26T18:12:54.219593Z","iopub.status.idle":"2021-05-26T18:13:30.419457Z","shell.execute_reply.started":"2021-05-26T18:12:54.219564Z","shell.execute_reply":"2021-05-26T18:13:30.418465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Automatyczny wybór ilości klastrów metodą silhouette score również wskazuje na 2 klastry","metadata":{}},{"cell_type":"code","source":"cluster_model = KMeans(n_clusters = best_n_clusters)\n# trenowanie modelu\nresult = cluster_model.fit_predict(cluster_data)\n\nlabels = cluster_model.labels_\n\nresult_data = cluster_data.copy()\nresult_data[\"labels\"] = labels\n\nresults_0 = cluster_data[result_data.labels == 0]\nresults_1 = cluster_data[result_data.labels == 1]","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:13:30.421017Z","iopub.execute_input":"2021-05-26T18:13:30.421663Z","iopub.status.idle":"2021-05-26T18:13:31.579715Z","shell.execute_reply.started":"2021-05-26T18:13:30.421622Z","shell.execute_reply":"2021-05-26T18:13:31.578817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Analiza klastra 1:","metadata":{}},{"cell_type":"code","source":"results_0.describe()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:13:31.580847Z","iopub.execute_input":"2021-05-26T18:13:31.581109Z","iopub.status.idle":"2021-05-26T18:13:31.600266Z","shell.execute_reply.started":"2021-05-26T18:13:31.581083Z","shell.execute_reply":"2021-05-26T18:13:31.599631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Analiza klastra 2:","metadata":{}},{"cell_type":"code","source":"results_1.describe()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:13:31.601208Z","iopub.execute_input":"2021-05-26T18:13:31.601613Z","iopub.status.idle":"2021-05-26T18:13:31.619685Z","shell.execute_reply.started":"2021-05-26T18:13:31.60158Z","shell.execute_reply":"2021-05-26T18:13:31.618747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Z powodu jednolitego rozkładu zmiennych badanie skupień nie przynosi dodatkowych informacji, ponieważ metody typu najniższych sąsiadów dzielą te zbiory na podobne klatry o podobnym wyglądzie. Jedyna różnica pomiędzy klastrami jest w wadze produktów, gdzie pierwszy klaster skupia w sobie produkty, które ważą powyżej 3330 gramów, a drugi klaster te produkty, które ważą miej niż 3330 gramów. Patrząc na płeć konsumentów, bądź koszt produktów, to nie ma ona wpływu na grupy produktów.","metadata":{}},{"cell_type":"markdown","source":"4. Analiza skupień metodą EM.","metadata":{}},{"cell_type":"code","source":"# załadowanie modułu do analizy metodą EM\nfrom sklearn.mixture import GaussianMixture\n\n# wczytanie modelu z dwoma klastrami\nem_model = GaussianMixture(n_components=2, random_state=0)\n\nlabels = em_model.fit_predict(cluster_data)\n\n#labels = em_model.labels_\n\nresult_data = cluster_data.copy()\nresult_data[\"labels\"] = labels\n\nresults_0 = cluster_data[result_data.labels == 0]\nresults_1 = cluster_data[result_data.labels == 1]","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:13:31.620989Z","iopub.execute_input":"2021-05-26T18:13:31.621525Z","iopub.status.idle":"2021-05-26T18:13:31.808757Z","shell.execute_reply.started":"2021-05-26T18:13:31.621471Z","shell.execute_reply":"2021-05-26T18:13:31.807716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Analiza klastra 1:","metadata":{}},{"cell_type":"code","source":"results_0.describe()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:13:31.810053Z","iopub.execute_input":"2021-05-26T18:13:31.810585Z","iopub.status.idle":"2021-05-26T18:13:31.830809Z","shell.execute_reply.started":"2021-05-26T18:13:31.810547Z","shell.execute_reply":"2021-05-26T18:13:31.829857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Analiza klastra 2:","metadata":{}},{"cell_type":"code","source":"results_1.describe()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:13:31.832123Z","iopub.execute_input":"2021-05-26T18:13:31.832647Z","iopub.status.idle":"2021-05-26T18:13:31.853638Z","shell.execute_reply.started":"2021-05-26T18:13:31.832605Z","shell.execute_reply":"2021-05-26T18:13:31.852639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Porównując wyniki pomiędzy analizą skupień metodą K-najbliższych sąsiadów a metodą EM, można zauważyć niewielkie różnice. Analiza metodą EM podzieliła zbiór danych głównie ze względu na masę produkt (dla klastra 1 produkty ciężkie w przedziale wagowym od 2655g do 7846g, a dla klastra 2 od 1001g do 2697g), ale w odróżnieniu od K-najbliższych sąsiadów wzięła również pod uwagę koszt produktu, gdzie klaster 2 jest nieco bardziej przesunięty w prawą stronę i średnia wartość wynosi dla niego 216, natomiast dla klastra 1 wynosi 206","metadata":{}},{"cell_type":"code","source":"# rysowanie wykresu dla każdej zmiennej \nimport scipy.stats as stats\nimport math\n\nfor col in results_1:\n    mu_0 = results_0[col].mean()\n    variance_0 = results_0[col].var()\n    mu_1 = results_1[col].mean()\n    variance_1 = results_1[col].var()\n    sigma_0 = math.sqrt(variance_0)\n    sigma_1 = math.sqrt(variance_1)\n    x_0 = np.linspace(mu_0 - 3*sigma_0, mu_0 + 3*sigma_0, 100)\n    x_1 = np.linspace(mu_1 - 3*sigma_1, mu_1 + 3*sigma_1, 100)\n    plt.figure(figsize=(8,5))\n    plt.title(f\"Wykres dystrybucji zmiennych w klastrach dla zmiennej {col}\")\n    plt.plot(x_0, stats.norm.pdf(x_0, mu_0, sigma_0))\n    plt.plot(x_1, stats.norm.pdf(x_1, mu_1, sigma_1))\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:13:31.85498Z","iopub.execute_input":"2021-05-26T18:13:31.855505Z","iopub.status.idle":"2021-05-26T18:13:32.277911Z","shell.execute_reply.started":"2021-05-26T18:13:31.855449Z","shell.execute_reply":"2021-05-26T18:13:32.277113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Przeprowadzona powyżej analiza pokazuje, że nie jest możliwe wyznaczenie konkrentych grup produktów kupowanych przez kobiety bądź mężczyzny.","metadata":{}},{"cell_type":"markdown","source":"# **V. Wybrany algorytm data mining**\n\n\nJako dodatkowy algorytm wybrano sieci neuronowe implementowane przy pomocy biblioteki tensorflow. Model ten został wybrany, ponieważ sieci neuronowe są szeroko wykorzystywane w data science, a sam bardzo mało pracowałem na tym typie modeli. Z tego powodu podjąłem decyzję o zastosowaniu tego modelu w ostatnim podpunkcie tego projektu.","metadata":{}},{"cell_type":"code","source":"# zapisywanie danych w postaci tensora\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nhipo_1_data = data[[\"Discount_offered\", \"Weight_in_gms\", \"Product_importance\"]]\nhipo_1_y = data[\"Reached.on.Time_Y.N\"]\n\ndecode = {\n    \"low\" : 1,\n    \"medium\" : 2,\n    \"high\" : 3\n}\n\nhipo_1_data.loc[:, \"Product_importance\"] = hipo_1_data.Product_importance.map(decode).values\n\n# rozdzielenie danych na sety treningowe i testowe\nX_train, X_test, y_train, y_test = train_test_split(hipo_1_data, hipo_1_y, train_size=0.7, random_state=1)\n\nmodel = keras.models.Sequential([\n    layers.Input(shape=(X_train.shape[1],)),\n    layers.Dense(10, activation=\"relu\"),\n    layers.Dropout(0.2),\n    layers.Dense(10, activation=\"relu\"),\n    layers.Dense(2, activation=\"softmax\")\n])\n\nmodel.compile(optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\",\n             metrics=[\"accuracy\"])\n\nmodel.build()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:13:32.279136Z","iopub.execute_input":"2021-05-26T18:13:32.27938Z","iopub.status.idle":"2021-05-26T18:13:32.330667Z","shell.execute_reply.started":"2021-05-26T18:13:32.279356Z","shell.execute_reply":"2021-05-26T18:13:32.329644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Model jaki zbudowałem składa się z 5 warstw:\n\n1. Warstwa wejściowa - składa się z 3 neuronów (po jednym na każdą zmienną)\n2. Pierwsza warstwa wewnętrzna - składa się z 10 neuronów, każdy połączony z neuronami z warstwy wejściowej. Zastosowano w nim funkcję aktywacyjną relu. Neuron z funkcją aktywacji ReLU przyjmuje dowolne wartości rzeczywiste jako swoje wejście (a), ale aktywuje się tylko wtedy, gdy te wejście (a) są większe niż 0.\n3. Druga warstwa wewnętrzna - warstwa przejściowa, która losowo ustawia jednostki wejściowe na 0 z częstotliwością na każdym kroku podczas treningu, co pomaga zapobiegać nadmiernemu dopasowaniu. Wejścia nie ustawione na 0 są skalowane w górę o 1 / (1 - stawka) tak, że suma wszystkich wejść pozostaje niezmieniona.\n4. Trzecia warstwa wewnętrzna - składa się z 10 neuronów, który każdy połączony jest z neuronem drugiej warstwy wewnętrznej. W warstwie tej zastosowaną funkcję aktywacyjną relu.\n5. Warstwa wyjściowa - składa się z dwóch neuronów, który każdy jest połączony z trzecią warstwą wewnętrzną. Zastosowano tutaj funkcję aktywacyjną softmax, która przetwarza wartości na końcu neuronów i zamienia je na wartości między 0 a 1\n\nDodatkowo sieć została zbudowana z określeniem optymalizatora Adam, który implementuje wykładniczą średnią ruchomą gradientów, aby skalować tempo uczenia. Utrzymuje wykładniczo malejącą średnią poprzednich gradientów. Adam jest wydajny obliczeniowo i ma bardzo małe wymagania dotyczące pamięci. Adam Optimizer jest jednym z najpopularniejszych algorytmów optymalizacji zstępowania gradientu.\n    Oprócz optymalizatora jako funkcję kosztów wybrano sparse_categorical_crossentropy, a do pomiarów jakości sieci wyprano parametr accuracy.\n    \n![Relu function](https://www.google.com/url?sa=i&url=https%3A%2F%2Fmedium.com%2F%40toprak.mhmt%2Factivation-functions-for-deep-learning-13d8b9b20e&psig=AOvVaw3EEzpecG9FyBlkDr96vWuF&ust=1622138854520000&source=images&cd=vfe&ved=0CAIQjRxqFwoTCOCRq6P45_ACFQAAAAAdAAAAABAJ)    ","metadata":{}},{"cell_type":"code","source":"#trenowanie modelu\nhistory = model.fit(X_train, y_train, validation_split=0.33, epochs=20)\n# summarize history for accuracy\nplt.figure(figsize=(8,5))\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Dokładność modelu')\nplt.ylabel('Dokładność')\nplt.xlabel('Epoka')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.figure(figsize=(8,5))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Funkcja kosztów modelu')\nplt.ylabel('Strata')\nplt.xlabel('Epoka')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:13:32.331725Z","iopub.execute_input":"2021-05-26T18:13:32.331966Z","iopub.status.idle":"2021-05-26T18:13:38.071319Z","shell.execute_reply.started":"2021-05-26T18:13:32.331943Z","shell.execute_reply":"2021-05-26T18:13:38.070268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Jak widać po powyższym przykładzie model osiągnął nieco gorsze wyniki jeżeli chodzi o dokładność porównując do modelu drzewa. Widać spore skoki jeżeli chodzi dokładność modelu oraz o wartosć funkcji kosztu. Może to oznaczać, że są duże zmiany jeżeli chodzi o wartości niektórych zmiennych, które rozstrajają model. ZAby temu zaradzić, możemy przeprowadzić standaryzację cech.","metadata":{}},{"cell_type":"code","source":"from sklearn import preprocessing","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:13:38.072583Z","iopub.execute_input":"2021-05-26T18:13:38.07284Z","iopub.status.idle":"2021-05-26T18:13:38.076876Z","shell.execute_reply.started":"2021-05-26T18:13:38.072814Z","shell.execute_reply":"2021-05-26T18:13:38.075698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = preprocessing.StandardScaler()\nX_train_scal = scaler.fit_transform(X_train)\nX_test_scal = scaler.transform(X_test)\n\n#trenowanie modelu\nhistory = model.fit(X_train, y_train, validation_split=0.33, epochs=20)\n# summarize history for accuracy\nplt.figure(figsize=(8,5))\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Dokładność modelu')\nplt.ylabel('Dokładność')\nplt.xlabel('Epoka')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.figure(figsize=(8,5))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Funkcja kosztów modelu')\nplt.ylabel('Strata')\nplt.xlabel('Epoka')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:13:38.077863Z","iopub.execute_input":"2021-05-26T18:13:38.07815Z","iopub.status.idle":"2021-05-26T18:13:43.224422Z","shell.execute_reply.started":"2021-05-26T18:13:38.078124Z","shell.execute_reply":"2021-05-26T18:13:43.223583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Jak widać standaryzacja delikatnie poprawiła rozrzut pomiędzy wartościami i zmniejszyła ilosć skoków wartości funkcji kosztów oraz funkcji dokładności modelu jeżeli chodzi o dane treningowe. Dodatkowo funckja dużo szybciej osiągneła optimum.","metadata":{}},{"cell_type":"code","source":"model.evaluate(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:13:43.225487Z","iopub.execute_input":"2021-05-26T18:13:43.22574Z","iopub.status.idle":"2021-05-26T18:13:43.356217Z","shell.execute_reply.started":"2021-05-26T18:13:43.225714Z","shell.execute_reply":"2021-05-26T18:13:43.355387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Porównując modele drzewa decyzyjnego i sieci neuronowej w celu potwierdzenia hipotezy 1 model drzewa sprawdzał się dużo lepiej niż sieć neuronowa nie (różnica o 10%). Oznacza to, że nie zawsze skomplikowane rozwiązania są dobre dla każdego rozwiązania. W sytuacji, kiedy jest niewielka korelacja zmiennych, a rozkłady nie są normalne modele nieparametryczne mogą sprawdzać się lepiej niż modele parametryczne. Jednakże hipotezę można potwierdzić przy wykorzystaniu modelu sieci neuronowej.","metadata":{}},{"cell_type":"markdown","source":"# **VI. Zakończenie**\n\n**Projekt został wykonany przez *Remigiusz Pomorskiego***","metadata":{}}]}