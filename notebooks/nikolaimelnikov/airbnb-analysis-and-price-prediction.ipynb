{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/us-airbnb-open-data/AB_US_2020.csv')\n\ndata.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.set_index('id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import folium\nfrom sklearn.cluster import KMeans\n\nMapModel = data[['latitude', 'longitude']]\n\n# Instantiate the clustering model and visualizer\nmodel = KMeans()\n\nkmeans = KMeans(n_clusters = 15, random_state=42).fit(MapModel)\nkmeans.cluster_centers_\n\ncluster_map = folium.Map([41.8781, -87.6298], zoom_start=4)\nfor i in range(kmeans.cluster_centers_.shape[0]):\n    num = sum(kmeans.labels_ == i)\n    folium.CircleMarker([kmeans.cluster_centers_[i,0], kmeans.cluster_centers_[i,1]],\n                        radius=15,\n                        popup=str(num) + ' Listings Associated with this Cluster',\n                        fill_color=\"#3db7e4\", # divvy color\n                        ).add_to(cluster_map)\ncluster_map","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Numeric Features Distribution Analysis\nnumeric_features = data.select_dtypes(include=['int64','float64']).columns\nnominal_features = data.select_dtypes(include=['object'])\nnumeric_features=numeric_features.delete(0)\nfig, axes = plt.subplots(nrows=2, ncols=4)\naux = 0\nfig.set_figheight(15)\nfig.set_figwidth(25)\nfor row in axes:\n    for col in row:\n        data[numeric_features[aux]].plot(kind='kde',ax=col)\n        col.set_title(numeric_features[aux] +' Distribution',fontsize=16,fontweight='bold')\n        aux+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing Outliers !!!\nlower_bound = .25\nupper_bound = .75\niqr = data[data['price'].between(data['price'].quantile(lower_bound), data['price'].quantile(upper_bound), inclusive=True)]\niqr = iqr[iqr['number_of_reviews'] > 0]\niqr = iqr[iqr['calculated_host_listings_count'] < 10]\niqr = iqr[iqr['number_of_reviews'] < 200]\niqr = iqr[iqr['minimum_nights'] < 10]\niqr = iqr[iqr['reviews_per_month'] < 5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=iqr.copy()\ndel iqr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_list = ['name','neighbourhood_group','host_id','host_name','last_review']\ndata.drop(data[drop_list], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### categorizing data\nto_categorical_list = ['neighbourhood','room_type','city']\nfor i in to_categorical_list:\n    data[i]=data[i].astype('category')\n    \nfrom sklearn.preprocessing import LabelEncoder\nlabelencoder = LabelEncoder()\nfor i in to_categorical_list:\n    data[i] = labelencoder.fit_transform(data[i])\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.drop(['price'], axis=1)\ny = data['price']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBRegressor\nfrom sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\nparams = {\n        'min_child_weight': [1, 5, 10],\n        'gamma': [0.5, 1, 1.5, 2, 5],\n        'subsample': [0.6, 0.8, 1.0,2],\n        'colsample_bytree': [0.6, 0.8, 1.0],\n        'max_depth': [3, 4, 5]\n        }\nxgb = XGBRegressor()\nrs = RandomizedSearchCV(xgb, param_distributions=params, n_iter=5, n_jobs=-1, cv=5, verbose=3, random_state=42 )\nrs.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred0 = rs.best_estimator_.predict(X_train)\ny_pred = rs.best_estimator_.predict(X_test)\nprint(rs.best_params_)\nprint(np.sqrt(mean_squared_error(y_train, y_pred0)))\nprint(np.sqrt(mean_squared_error(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# FROM this code get best params which are:\n# n_estimators=70, min_samples_leaf=4, max_features='log2', bootstrap=False\n\nfrom sklearn.ensemble import RandomForestRegressor\n\"\"\"\nn_estimators = [int(x) for x in np.arange(start = 10, stop = 100, step = 10)]\nmax_features = [0.5,'auto', 'sqrt','log2']\nmin_samples_leaf = [1, 2, 4]\nbootstrap = [True, False]\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\n#First create the base model to tune\nm = RandomForestRegressor()\n#Fit the random search model\nm_random = RandomizedSearchCV(estimator = m, param_distributions = random_grid, n_iter = 15, cv = 5, verbose=2, random_state=42, n_jobs = -1)\nm_random.fit(X_train, y_train)\nm_random.best_params_\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m = RandomForestRegressor(n_estimators=70, min_samples_leaf=4, max_features='log2', bootstrap=False)\nm.fit(X_train, y_train)\ny_pred_rf = m.predict(X_test)\nprint(np.sqrt(mean_squared_error(y_test, y_pred_rf)))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}