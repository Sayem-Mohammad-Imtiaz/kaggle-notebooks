{"cells":[{"metadata":{},"cell_type":"markdown","source":"# <center>Board Game Review Rating Predictor","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Name: Steeven Pereira<br>\nID: 1001759481\n\n<h1>Summary:</h1><br>\nText analysis is an important part of AI technology that uses Natural Language Processing to transform unstructured text into Normalized, Structured data suitable for Machine Learning algorithms. There are a lot of different techniques which can convert raw textual data into meaningfull information by performing certain mathematical computations that convert the text data into numerical data. The aim of this project was to build a prediction model that can effectively predict the rating of a board game review. The rating predictor model was trained on the 'comment' column of the 'bgg-13m-reviews' file. The main challenge of this project was handling the large scale data and creating a prediction model that can be deployed on cloud to provide the predicted output in good time. The textual data was cleaned by removing the 'urls', 'emojis', and other special characters that were redundant for the classification model. Stopwords were also removed from the data. Since the data to be feed to the machine learning model was of string datatype, it had to be converted to a format suitable for the prediction model. Tfid vectorization was used to transform the data. Range Accuracy was also computed with a buffer of 1. The data was trained on four classification algorithms namely: <ul><li>Ridge Classifier</li><li>Multinomial Naive Bayes Classifier</li><li>Linear SVC Classifier</li><li>Ensemble</li></ul><br>\nThe accuracy obtained in each model: <ul><li>Ridge Classifier: 31.94%</li><li>Multinomial Naive Bayes Classifier: 30.7%</li><li>Linear SVC Classifier: 30.8%</li><li>Ensemble: 31.72%</li></ul><br>\nMean Square Error in each model: <ul><li>Ridge Classifier: 1.65</li><li>Multinomial Naive Bayes Classifier: 1.72</li><li>Linear SVC Classifier: 1.73</li><li>Ensemble: 1.61</li></ul><br>\nTime to develop each model: <ul><li>Ridge Classifier: 9min 4s</li><li>Multinomial Naive Bayes Classifier: 1.42s</li><li>Linear SVC Classifier: 2h 19min 55s</li><li>Ensemble: 8min 50s</li></ul><br>\nSince some of the models take a lot of time to develop the model it would be difficult to run the model and obtain output on the server. So all the models were saved using joblib and only required to be loaded while predicting a review on the web UI. The web UI was created using Flask and hosted using Heroku.\n<br>\n<h1>Dataset Description</h1>\n\nThe dataset was obtained from BoardGameGeek Reviews on Kaggle. The dataset was created from the data collected from boardgamegeek.com and divided into 3 files. For this project only the 'bgg-13m-reviews' file was used that consists of the 'comment' column and the rating column required for the machine learning model.The dataset consisted of approximately 13.6M data values. However some of the data values in the 'comment' column were empty. Such data values were removed from the dataset and the data was scaled down to approximately 2.6M data values. The dataset was cleaned and transform to create vectors to feed as input to the classifier models. \n<br>\n<h1>Aim of the project</h1>\n\nThe main aim of the project is to predict the rating of a game review based on the review provided as input. The purpose of this project is handling large scale data and understanding the working of classification algorithms. Also creating a web User Interface and hosting it on cloud. \n<br>\n<h2>Ridge Classifier</h2>\n\nRidge classifier is a classification algorithm that uses ridge regression to classify multi-nomial values. For multi-class classification, n_class classifiers are trained in a one-versus-all approach.\n<br>\n<h2>Multinomial Naive-Bayes Classifier</h2>\n\nMultinomial Naive-Bayes classifier is a naive bayes classifier for multi-nomial values. It is suitable for multi-class classification with discrete features. The multi-nomial distribution works for fractional count such as tfidf as well.\n<br>\n<h2>Linear SVC Classifier</h2>\n\nLinear SVC classifier is a Support Vector Machine classifier for multi-nomial values. The objective of a Linear Support Vector Classifier is to fit to the data you provide, returning a \"best fit\" hyperplane that divides, or categorizes, your data. After that getting the hyperplane, you can then feed some features to your classifier to see what the \"predicted\" class is. \n<br>\n<h2>Ensemble</h2>\nEnsembel model's are a technique of machine learning in which several machine learning models are combined to create a single classifier model to decrease loss and improve the accuracy of the model. In this project a Voting Classifier is built by combining Ridge Classifier and Multinomial Naive Bayes Classifier.<br>\n<h2>TF-IDF Vectorizer</h2>\n\nTF-IDF stands for term frequency inverse document frequency. It transforms text into feature vectors that are provided as input to the classifier model. It is a statistical measure that computes how relevant a particular word is in the document. Tf-idf is calculated by multiplying two values: frequency of a word appearing in a document, and the inverse document frequency of the word across a set of documents. <br>\n<br>\n<h1><b>Difference from reference</b></h1><br>\n\nhttps://github.com/vivekk09/Board-Game-Review-Prediction-ML-Project/blob/master/Board%20Game%20Review%20Prediction.ipynb\n<br>\nIn the above reference, the model was created using different attributes that contained different datatypes. For my project I have created the model based on the 'comment' column of the dataset. So in order to pass the input to the model the data had to be transformed. Tf-idf vectorization was used to convert the string data into vecctors maaking it a suitable input for the classifier model. In the references the dataset consisted of 80K reviews and the models used were Linear Regression and Random Forest. Since the dataset for this project was more than 30 times the dataset in the reference using Linear Regression or Random Forest was time-consuming and also the output in this project has multi-nomial values. Thus I have used Ridge Classifier, Multinomial Naive Bayes, Linear SVC and Voting Classifier for creating the model. The challenge in this project was creating the web UI and hosting on the server. Based on the accuracy, range accuracy and mean square error of all the classifier models the web server was designed using the Ridge Classifier. Since it was time consuming to fit the classifier on the web server i used joblib to save the model.\n<br>\n<h1>Video Link:</h1><br>\n\n[Click Here](https://www.youtube.com/watch?v=NtPtIP394v4)\n<br>\n<h1>Github:</h1><br>\n\n[Click Here](https://github.com/steeven1001759481/ratingpredictor)\n<br>\n<h1>Web Demo:</h1><br>\n\n[Click Here](https://ratingprediction.herokuapp.com/)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Loading the libraries required for loading dataset and visualization \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport seaborn as sns\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session#loading the dataset using pandas library\ndf = pd.read_csv('../input/boardgamegeek-reviews/bgg-13m-reviews.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Shuffle the Dataset\ndf = df.sample(frac=1)\nlen(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Drop the data values where the 'comment' column is empty. ","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"df.dropna(subset=['comment'], inplace=True)\nlen(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Histogram of the rating column that is used as class attribute</b><br>\nWe can see that almost 700K reviews have 7 rating that is the highest frequency. The cummulative frequency of ratings 1, 2, and 3 is less than 120K. \n","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.hist(df['rating'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cleaning the dataset<br>\n<ul>\n    <li>removing emoji's</li>\n    <li>removing url</li>\n    <li>removing special characters</li>\n    ","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"import emoji\nimport re\ndef clean_data(text):\n    url = re.compile(r'https?://\\S+|www\\.\\S+')\n    emoji_pattern = re.compile(\"[\"\n    u\"\\U0001F600-\\U0001F64F\"  \n    u\"\\U0001F300-\\U0001F5FF\"  \n    u\"\\U0001F680-\\U0001F6FF\"  \n    u\"\\U0001F1E0-\\U0001F1FF\"  \n    u\"\\U00002702-\\U000027B0\"\n    u\"\\U000024C2-\\U0001F251\"\n    \"]+\", flags=re.UNICODE)\n    text = re.sub(r'\\n',' ', text) \n    text = re.sub('\\s+', ' ', text).strip() \n    return emoji_pattern.sub(r'', text)\n    return url.sub(r'',text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df['comment'] = df['comment'].apply(clean_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tf-idf Vectorization and removing stopwords.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn import feature_extraction\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\ncount_vectorizer = feature_extraction.text.TfidfVectorizer(stop_words='english')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Top 15 words before removing stopwords\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ndef get_top_n_words(corpus, n=None):\n    vec = CountVectorizer().fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]\ncommon_words = get_top_n_words(df['comment'], 15)\n\nlangs=[]\nstudents=[]\nfor word, freq in common_words:\n    langs.append(word)\n    students.append(freq)\nimport matplotlib.pyplot as plt\nfig = plt.figure()\nax = fig.add_axes([0,0,1,1])\nax.bar(langs,students)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Top 15 words after removing stopwords","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"def get_top_n_words(corpus, n=None):\n    vec = CountVectorizer(stop_words = 'english').fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]\ncommon_words = get_top_n_words(df['comment'], 15)\nlangs=[]\nstudents=[]\nfor word, freq in common_words:\n    langs.append(word)\n    students.append(freq)\nfig = plt.figure()\nax = fig.add_axes([0,0,1,1])\nax.bar(langs,students)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Store the review in X and the rating i.e. the class label in y\nX = df['comment'].values\ny = df['rating'].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The rating column contains 8202 unique values. It contains float values which will be rounded.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"len(df['rating'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y = np.round(y)\nlen(df['rating'].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Split the dataset into 80-20 train test split","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"split_size = 520000\nX_train = X[:-split_size]\ny_train = y[:-split_size]\n\nX_test = X[-split_size:]\ny_test = y[-split_size:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create vectors for the train data","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"train_vectors = count_vectorizer.fit_transform(X_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create vectors for the test data","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"test_vectors = count_vectorizer.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classifier Model","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"#Load the required libraries\nimport sklearn\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import LinearSVC\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn import metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import roc_curve","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def range_accuracy_metric(actual, predicted):\n    correct = 0\n    for i in range(len(actual)):\n        if actual[i] == predicted[i] or actual[i] == (predicted[i]+1) or actual[i] == (predicted[i]-1) :\n            correct += 1\n    return correct / float(len(actual)) * 100.0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Ridge Classifier</h2>\n<br>Fit the Ridge classifier model on the train data    ","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\nclf = RidgeClassifier()\nclf.fit(train_vectors, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predicting the values of the test set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ny_pred = np.round(clf.predict(test_vectors))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Accuracy on Ridge Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = accuracy_score(np.round(y_pred), np.round(y_test))\nprint('Accuracy on Ridge Classifier : {} %'.format(acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"range_ridge_score=range_accuracy_metric(y_test, np.round(y_pred))\nprint('Range Accuracy on Ridge Classifier : {} %'.format(range_ridge_score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mean Square error on Ridge Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"mse1 = mean_squared_error(y_test, y_pred, squared=False)\nmse1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(metrics.classification_report(np.round(y_test), np.round(y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Multinomial Naive Bayes Classifier</h2>\n<br>Fit the Multinomial Naive Bayes classifier model on the train data    ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nclf2 = MultinomialNB()\nclf2.fit(train_vectors, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predicting the values of the test set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ny_pred_nb = np.round(clf2.predict(test_vectors))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Accuracy on Multinomial Naive Bayes Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"acc2 = accuracy_score(y_pred_nb, np.round(y_test))\nprint('Range Accuracy on Multinomial Naive Bayes : {} %'.format(acc2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"range_MNB_score=range_accuracy_metric(y_test, np.round(y_pred_nb))\nprint('Range Accuracy on Multinomial Naive Bayes : {} %'.format(range_MNB_score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mean Square error on Multinomial Naive Bayes Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"mse2 = mean_squared_error(y_test, np.round(y_pred_nb), squared=False)\nmse2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(metrics.classification_report(np.round(y_test), np.round(y_pred_nb)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Linear SVC</h2>\n<br>Fit the Linear SVC model on the train data    ","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\nclf3 = LinearSVC()\nclf3.fit(train_vectors, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predicting the values of the test set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ny_pred_svc = np.round(clf3.predict(test_vectors))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Accuracy on Linear SVC","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"acc3 = accuracy_score(y_pred_svc, np.round(y_test))\nprint('Range Accuracy on Linear SVC : {} %'.format(acc3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"range_svc_score=range_accuracy_metric(y_test, np.round(y_pred_svc))\nprint('Range Accuracy on Linear SVC : {} %'.format(range_svc_score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mean Square error on Linear SVC","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"mse3 = mean_squared_error(y_test, np.round(y_pred_svc), squared=False)\nmse3","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(metrics.classification_report(np.round(y_test), np.round(y_pred_svc)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Voting Classifier</h2>\n<br>Fit the ensemble model on the train data    ","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\nfrom sklearn.ensemble import VotingClassifier\nestimators = []\nestimators.append(('ridge', clf))\nestimators.append(('MNB', clf2))\n# create the ensemble model\nensemble = VotingClassifier(estimators)\nensemble.fit(train_vectors, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predicting the values of the test set","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"y_pred_ensemble = np.round(ensemble.predict(test_vectors))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Accuracy on Ensemble model\n","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"acc4 = accuracy_score(y_pred_ensemble, np.round(y_test))\nprint('Range Accuracy on Ensemble model : {} %'.format(acc4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"range_ensemble_score=range_accuracy_metric(y_test, np.round(y_pred_ensemble))\nprint('Range Accuracy on Ensemble model : {} %'.format(range_ensemble_score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mean Square error on Ensemble","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"mse4 = mean_squared_error(y_test, y_pred_ensemble, squared=False)\nmse4","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(metrics.classification_report(np.round(y_test), np.round(y_pred_ensemble)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Accuracy vs Range Accuracy","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"labels = ['Ridge', 'MultinomialNB', 'LinearSVC', 'Ensemble']\naccuracy = np.round([acc*100, acc2*100, acc3*100, acc4*100])\nrange_accuracy = np.round([range_ridge_score, range_MNB_score, range_svc_score, range_ensemble_score])\n\nx = np.arange(len(labels))  # the label locations\nwidth = 0.3  # the width of the bars\n\nfig, ax = plt.subplots()\nrects1 = ax.bar(x - width/2, accuracy, width, label='Accuracy')\nrects2 = ax.bar(x + width/2, range_accuracy, width, label='Range Accuracy')\n\n# Add some text for labels, title and custom x-axis tick labels, etc.\nax.set_ylabel('Accuracy')\nax.set_title('Accuracy vs Range Accuracy')\nax.set_xticks(x)\nax.set_xticklabels(labels)\nax.legend()\n\n\ndef autolabel(rects):\n    for rect in rects:\n        height = rect.get_height()\n        ax.annotate('{}'.format(height),\n                    xy=(rect.get_x() + rect.get_width() / 2, height),\n                    xytext=(0, 3),  # 3 points vertical offset\n                    textcoords=\"offset points\",\n                    ha='center', va='bottom')\nautolabel(rects1)\nautolabel(rects2)\nfig.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on the results of the above bar graph, the Web UI was developed with the Ridge Classifier for predicting the rating.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Save the models using joblib ","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.externals import joblib\njoblib.dump(clf, 'ridge_model.sav')\njoblib.dump(count_vectorizer, 'vector.sav')\njoblib.dump(clf2, 'multi_naive_bayes.sav')\njoblib.dump(clf3, 'linear_SVC.sav')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"References:<br><ul>\n    <li>https://pythonprogramming.net/linear-svc-example-scikit-learn-svm-python/</li>\n    <li>https://www.kaggle.com/jvanelteren/boardgamegeek-reviews</li>\n    <li>https://www.boardgamegeek.com/</li>\n    <li>https://github.com/vivekk09/Board-Game-Review-Prediction-ML-Project/blob/master/Board%20Game%20Review%20Prediction.ipynb</li>\n    <li>https://towardsdatascience.com/a-complete-exploratory-data-analysis-and-visualization-for-text-data-29fb1b96fb6a</li>\n    <li>https://matplotlib.org/3.2.1/gallery/lines_bars_and_markers/barchart.html#sphx-glr-gallery-lines-bars-and-markers-barchart-py</li>\n        <li>https://blog.statsbot.co/ensemble-learning-d1dcd548e936</li>","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.7 (tensorflow)","language":"python","name":"tensorflow"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"}},"nbformat":4,"nbformat_minor":1}