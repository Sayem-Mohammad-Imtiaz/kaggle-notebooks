{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# What is a Tree?\n\nAt its simplest form a Tree can be construed as multiple if/else statements through which each row from the data is passed to check all the features to decide/classify which category the row belongs.\n\n# Tensorfow Decision Forests\n\nTensorflow Decision forests are a family of machine learning algorithms with quality and speed competitive with (and often favorable to) neural networks, especially when you’re working with tabular data. They’re built from many decision trees, which makes them easy to use and understand - and you can take advantage of a plethora of interpretability tools and techniques that already exist today.\n\n- It provides a slew of state-of-the-art Decision Forest training and serving algorithms such as random forests, gradient-boosted trees, CART, (Lambda)MART, DART, Extra Trees, greedy global growth, oblique trees, one-side-sampling, categorical-set learning, random categorical learning, out-of-bag evaluation and feature importance, and structural feature importance.\n\n- This library can serve as a bridge to the rich TensorFlow ecosystem by making it easier for you to integrate tree-based models with various TensorFlow tools, libraries, and platforms such as TFX.\n\nFor more info please check -> https://blog.tensorflow.org/2021/05/introducing-tensorflow-decision-forests.html","metadata":{}},{"cell_type":"markdown","source":"### To Demonstrate TF Decision Forests we use Stroke Prediction Dataset","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.rcParams[\"figure.figsize\"] = (12, 8)\nplt.rcParams['axes.titlesize'] = 16\nplt.style.use('seaborn-whitegrid')\nsns.set_palette('Set3')\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-01T08:30:56.915562Z","iopub.execute_input":"2021-06-01T08:30:56.915958Z","iopub.status.idle":"2021-06-01T08:30:57.022644Z","shell.execute_reply.started":"2021-06-01T08:30:56.915923Z","shell.execute_reply":"2021-06-01T08:30:57.021713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv')\nprint(df.shape)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-01T08:30:58.904551Z","iopub.execute_input":"2021-06-01T08:30:58.904957Z","iopub.status.idle":"2021-06-01T08:30:58.953297Z","shell.execute_reply.started":"2021-06-01T08:30:58.904922Z","shell.execute_reply":"2021-06-01T08:30:58.952483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-01T08:30:59.321511Z","iopub.execute_input":"2021-06-01T08:30:59.322007Z","iopub.status.idle":"2021-06-01T08:30:59.34318Z","shell.execute_reply.started":"2021-06-01T08:30:59.32196Z","shell.execute_reply":"2021-06-01T08:30:59.341617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['bmi'].isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-01T08:04:55.846902Z","iopub.execute_input":"2021-06-01T08:04:55.847215Z","iopub.status.idle":"2021-06-01T08:04:55.852278Z","shell.execute_reply.started":"2021-06-01T08:04:55.847159Z","shell.execute_reply":"2021-06-01T08:04:55.851595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 201 null values in feature 'bmi'\n\nUsually if we are to use sklearn RandomForest we would have to impute the NaNs, scale the features and convert categorical to numerical features before procedding with fitting the model. In TF DF we can straight away fit the model as demonstrated below","metadata":{}},{"cell_type":"markdown","source":"#### First install tensorflow_decision_forests package","metadata":{}},{"cell_type":"code","source":"!pip install tensorflow_decision_forests -q","metadata":{"execution":{"iopub.status.busy":"2021-06-01T08:31:04.540046Z","iopub.execute_input":"2021-06-01T08:31:04.540439Z","iopub.status.idle":"2021-06-01T08:31:12.410703Z","shell.execute_reply.started":"2021-06-01T08:31:04.540406Z","shell.execute_reply":"2021-06-01T08:31:12.409399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### We split the datasset into training and validation set","metadata":{}},{"cell_type":"code","source":"train_df, valid_df = train_test_split(df, test_size = 0.2, shuffle = True, random_state = 42)\ntrain_df.shape, valid_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-01T08:31:12.413082Z","iopub.execute_input":"2021-06-01T08:31:12.413426Z","iopub.status.idle":"2021-06-01T08:31:12.424884Z","shell.execute_reply.started":"2021-06-01T08:31:12.413392Z","shell.execute_reply":"2021-06-01T08:31:12.424045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### First step is to convert the pandas dataframe format to tensorflow decision forests format as below","metadata":{}},{"cell_type":"code","source":"import tensorflow_decision_forests as tfd\n\ntrain_tf = tfd.keras.pd_dataframe_to_tf_dataset(train_df, label = 'stroke')","metadata":{"execution":{"iopub.status.busy":"2021-06-01T08:31:12.428626Z","iopub.execute_input":"2021-06-01T08:31:12.428911Z","iopub.status.idle":"2021-06-01T08:31:12.465177Z","shell.execute_reply.started":"2021-06-01T08:31:12.428884Z","shell.execute_reply":"2021-06-01T08:31:12.46415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Below are the available models in Tensorflow Decision Forest","metadata":{}},{"cell_type":"code","source":"tfd.keras.get_all_models()","metadata":{"execution":{"iopub.status.busy":"2021-06-01T08:31:12.466381Z","iopub.execute_input":"2021-06-01T08:31:12.466648Z","iopub.status.idle":"2021-06-01T08:31:12.473166Z","shell.execute_reply.started":"2021-06-01T08:31:12.466622Z","shell.execute_reply":"2021-06-01T08:31:12.471872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#We first demo using RandomForest\n#Define the required model\nmodel = tfd.keras.RandomForestModel()\n\n#Train the model\nmodel.fit(x = train_tf)","metadata":{"execution":{"iopub.status.busy":"2021-06-01T08:31:12.475796Z","iopub.execute_input":"2021-06-01T08:31:12.476234Z","iopub.status.idle":"2021-06-01T08:31:14.162407Z","shell.execute_reply.started":"2021-06-01T08:31:12.476191Z","shell.execute_reply":"2021-06-01T08:31:14.161081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-01T08:31:14.163765Z","iopub.execute_input":"2021-06-01T08:31:14.164099Z","iopub.status.idle":"2021-06-01T08:31:14.170196Z","shell.execute_reply.started":"2021-06-01T08:31:14.164069Z","shell.execute_reply":"2021-06-01T08:31:14.16932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Evluatate the model using the validation data","metadata":{}},{"cell_type":"code","source":"valid_tf = tfd.keras.pd_dataframe_to_tf_dataset(valid_df, label = 'stroke')\n\nmodel.compile(metrics = [\"accuracy\"])\nev = model.evaluate(valid_tf)","metadata":{"execution":{"iopub.status.busy":"2021-06-01T08:31:14.171766Z","iopub.execute_input":"2021-06-01T08:31:14.172193Z","iopub.status.idle":"2021-06-01T08:31:14.424339Z","shell.execute_reply.started":"2021-06-01T08:31:14.17216Z","shell.execute_reply":"2021-06-01T08:31:14.423504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The first entry that model.evaluate returns is the BinaryCrossEntropyLoss\n- The second entry is the eval metric we supplied while compiling the model (accuracy)","metadata":{}},{"cell_type":"code","source":"print(f\"BinaryCross Entropy Loss: {ev[0]}\")\nprint(f\"Accuracy: {ev[1]}\")\n\n#Save model\nmodel.save('./stoke_model')","metadata":{"execution":{"iopub.status.busy":"2021-06-01T08:31:14.425511Z","iopub.execute_input":"2021-06-01T08:31:14.425987Z","iopub.status.idle":"2021-06-01T08:31:15.934876Z","shell.execute_reply.started":"2021-06-01T08:31:14.425945Z","shell.execute_reply":"2021-06-01T08:31:15.933752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training Logs Plot","metadata":{}},{"cell_type":"code","source":"logs = model.make_inspector().training_logs()\nplt.plot([log.num_trees for log in logs], [log.evaluation.accuracy for log in logs])\nplt.xlabel(\"Number of trees\")\nplt.ylabel(\"Out-of-bag accuracy\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-01T08:31:15.936778Z","iopub.execute_input":"2021-06-01T08:31:15.937162Z","iopub.status.idle":"2021-06-01T08:31:16.142069Z","shell.execute_reply.started":"2021-06-01T08:31:15.93713Z","shell.execute_reply":"2021-06-01T08:31:16.141107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Importance","metadata":{}},{"cell_type":"code","source":"inspector = model.make_inspector()\nprint(f\"Available variable importances:\")\nfor importance in inspector.variable_importances().keys():\n    print(importance)","metadata":{"execution":{"iopub.status.busy":"2021-06-01T08:31:43.507697Z","iopub.execute_input":"2021-06-01T08:31:43.508354Z","iopub.status.idle":"2021-06-01T08:31:45.656223Z","shell.execute_reply.started":"2021-06-01T08:31:43.508315Z","shell.execute_reply":"2021-06-01T08:31:45.655104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mean decrease in AUC of the class 1 vs the others.\ninspector.variable_importances()[\"NUM_AS_ROOT\"]","metadata":{"execution":{"iopub.status.busy":"2021-06-01T08:31:45.658068Z","iopub.execute_input":"2021-06-01T08:31:45.658661Z","iopub.status.idle":"2021-06-01T08:31:47.807809Z","shell.execute_reply.started":"2021-06-01T08:31:45.658616Z","shell.execute_reply":"2021-06-01T08:31:47.806724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Explainability","metadata":{}},{"cell_type":"code","source":"with open('./plot_model.html', 'w') as f:\n    f.write(tfd.model_plotter.plot_model(model))","metadata":{"execution":{"iopub.status.busy":"2021-06-01T08:34:13.434417Z","iopub.execute_input":"2021-06-01T08:34:13.434791Z","iopub.status.idle":"2021-06-01T08:34:13.452474Z","shell.execute_reply.started":"2021-06-01T08:34:13.434763Z","shell.execute_reply":"2021-06-01T08:34:13.451552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import IFrame\n\nIFrame('./plot_model.html', width = 900, height = 700)","metadata":{"execution":{"iopub.status.busy":"2021-06-01T08:36:36.904804Z","iopub.execute_input":"2021-06-01T08:36:36.905159Z","iopub.status.idle":"2021-06-01T08:36:36.911552Z","shell.execute_reply.started":"2021-06-01T08:36:36.905127Z","shell.execute_reply":"2021-06-01T08:36:36.910545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The model starts with bmi >=26.75 and then branches off to check hypertension and age to decide which class it belongs to\n- if age >= 72.5 and bmi >= 31, the model decides more class 1 compared to other nodes","metadata":{}},{"cell_type":"markdown","source":"#### We now use GradientBoostTree model for the same dataset with some parameter tuning","metadata":{}},{"cell_type":"code","source":"model_gb = tfd.keras.GradientBoostedTreesModel(\n    num_trees = 300,\n    growing_strategy = \"BEST_FIRST_GLOBAL\",\n    max_depth = 12,\n    split_axis = \"SPARSE_OBLIQUE\",\n    )\n\nmodel_gb.fit(train_tf)\nmodel_gb.compile(metrics = [\"accuracy\"])\nev = model_gb.evaluate(valid_tf)\n\nprint(f\"BinaryCross Entropy Loss: {ev[0]}\")\nprint(f\"Accuracy: {ev[1]}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-01T08:06:44.229028Z","iopub.status.idle":"2021-06-01T08:06:44.229507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_gb.make_inspector().variable_importances()","metadata":{"execution":{"iopub.status.busy":"2021-06-01T08:06:44.230556Z","iopub.status.idle":"2021-06-01T08:06:44.23098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Let us check Sklearn RandomForest for comparision","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-01T08:06:44.231752Z","iopub.status.idle":"2021-06-01T08:06:44.232176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df.drop(['id', 'stroke'], axis = 1)\ny = df['stroke'].copy()","metadata":{"execution":{"iopub.status.busy":"2021-06-01T08:06:44.232963Z","iopub.status.idle":"2021-06-01T08:06:44.233402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_cols = [c for c in X.columns if X[c].dtype in ['int64', 'float64']]\ncat_cols = [c for c in X.columns if c not in num_cols]\nnum_cols, cat_cols","metadata":{"execution":{"iopub.status.busy":"2021-06-01T08:06:44.234213Z","iopub.status.idle":"2021-06-01T08:06:44.234637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### NaN Imputation","metadata":{}},{"cell_type":"code","source":"for c in num_cols:\n    X[c] = X[c].fillna(X[c].mean())","metadata":{"execution":{"iopub.status.busy":"2021-06-01T08:06:44.235631Z","iopub.status.idle":"2021-06-01T08:06:44.236061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Scaling\n\nfrom sklearn.preprocessing import StandardScaler\n\nstd = StandardScaler()\n\nX[num_cols] = std.fit_transform(X[num_cols])","metadata":{"execution":{"iopub.status.busy":"2021-06-01T08:06:44.237028Z","iopub.status.idle":"2021-06-01T08:06:44.237464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Label Encoding Categorical Features","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nlbl = LabelEncoder()\n\nfor c in cat_cols:\n    lbl.fit(X[c])\n    X[c] = lbl.transform(X[c])","metadata":{"execution":{"iopub.status.busy":"2021-06-01T08:06:44.238375Z","iopub.status.idle":"2021-06-01T08:06:44.238799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Xtrain, Xvalid, ytrain, yvalid = train_test_split(X, y, test_size = 0.2, random_state = 42)\nfrom sklearn.ensemble import RandomForestClassifier\n\nclf = RandomForestClassifier()","metadata":{"execution":{"iopub.status.busy":"2021-06-01T08:06:44.239715Z","iopub.status.idle":"2021-06-01T08:06:44.240142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf.fit(Xtrain, ytrain)\npreds = clf.predict(Xvalid)\n\nfrom sklearn.metrics import accuracy_score\n\nprint(f\"Accuracy: {accuracy_score(yvalid, preds)}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-01T08:06:44.241014Z","iopub.status.idle":"2021-06-01T08:06:44.241451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for name, importance in zip(df.columns, clf.feature_importances_):\n    print(name, '-->', importance)","metadata":{"execution":{"iopub.status.busy":"2021-06-01T08:06:44.242365Z","iopub.status.idle":"2021-06-01T08:06:44.242789Z"},"trusted":true},"execution_count":null,"outputs":[]}]}