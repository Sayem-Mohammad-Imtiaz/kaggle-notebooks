{"cells":[{"metadata":{"_uuid":"234dc52bb9549e83e0d15134932d98a94668234a","_cell_guid":"282e4969-fcc1-42fb-98a4-790310b3d6d3"},"source":"This is the second day of the 5-Day Regression Challenge. You can find the first day's challenge [here](https://www.kaggle.com/rtatman/regression-challenge-day-1). Today, we’re going to learn how to fit a model to data and how to make sure we haven’t violated any of the underlying assumptions. First, though, you need a tiny bit of background:\n____\n\n**Regression formulas in R**\n\nIn R, regression is expressed using a specific type of object called a formula. This means that the syntax for expressing a regression relationship is the same across packages that use formula objects. The general syntax for a formula looks like this:\n\n    Output ~ input\n\nIf you think that more than one input might be affecting your output (for example that both the amount of time spent exercising and the number of calories consumed might affect changes in someone’s weight) you can represent that with this notation:\n\n\tOutput ~ input1 + input2\n    \nWe'll talk about how to know which inputs you should include later on: for now, let's just stick to picking inputs based on questions that are interesting to you. (Figuring out how to turn a quesiton into a \n\n**What are these “residuals” everyone keeps talking about?**\n\nA residual is just how far off a model is for a single point. So if our model predicts that a 20 pound cantaloupe should sell for eight dollars and it actually sells for ten dollars, the residual for that data point would be two dollars. Most models will be off by at least a little bit for pretty much all points, but you want to make sure that there’s not a strong pattern in your residuals because that suggests that your model is failing to capture some underlying trend in your dataset.\n____\n\nToday, we're going to practice fitting a regression model to our data and examining the residuals to see if our model is a good representation of our data.\n\n___\n\n<center>\n[**You can check out a video that goes with this notebook by clicking here.**](https://www.youtube.com/embed/3C8SxyD8C7I)\n","cell_type":"markdown"},{"metadata":{"_uuid":"72649db2fc382d9639f94da23c687b61726cf04b","_cell_guid":"58cd1596-f45b-4fb6-99cc-dd7b7152da74"},"source":"## Example: Kaggle data science survey\n___\n\nFor our example today, we're going to use the Kaggle we’re going to use the 2017 Kaggle ML and Data Science Survey. I’m interested in seeing if we can predict the salary of data scientists based on their age. My intuition is that older data scientists, who are probably more experienced, will have higher salaries.\n\nBecause salary is a count value (you're usually paid in integer increments of a unit of currency, and hopefully you shouldn't be being paid a negative amount), we're going to model this with a Poisson regression. \n\nBefore we train a model, however, we need to set up our environment. I'm going to read in two datasets: the Kaggle Data Science Survey for the example and the Stack Overflow Developer Survey for you to work with. ","cell_type":"markdown"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"aa4ab90b6d4207aacce6673edb525439a2ecb852","_kg_hide-output":false,"_cell_guid":"9c296d41-7665-4318-9f3d-365b3743e35b"},"source":"# libraries\nlibrary(tidyverse)\nlibrary(boot) #for diagnostic plots\n\n# read in data\nkaggle <- read_csv(\"../input/kaggle-survey-2017/multipleChoiceResponses.csv\")\nstackOverflow <- read_csv(\"../input/so-survey-2017/survey_results_public.csv\")","cell_type":"code"},{"metadata":{"_uuid":"1034eee95c8e480519b16d42386745595ee8ecae","_cell_guid":"b818a1af-cc61-4a4f-9234-44292790b3be"},"source":"Now that we've got our environment set up, I'm going to do a tiny bit of data cleaning. First, I only want to look at rows where we have people who have reported having compensation of more than 0 units of currency. (There are many different currencies in the dataset, but for simplicity I'm going to ignore them.)","cell_type":"markdown"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"71daccaca52e978225a9a24ad870f325040c1e5f","_cell_guid":"3ff70e68-0bc4-4323-b1ed-295d02887742"},"source":"# do some data cleaning\nhas_compensation <- kaggle %>%\n    filter(CompensationAmount > 0) %>% # only get salaries of > 0\n    mutate(CleanedCompensationAmount = str_replace_all(CompensationAmount,\"[[:punct:]]\", \"\")) %>%\n    mutate(CleanedCompensationAmount = as.numeric(CleanedCompensationAmount)) \n\n# the last two lines remove puncutation (some of the salaries has commas in them)\n# and make sure that salary is numeric","cell_type":"code"},{"metadata":{"_uuid":"39dd1ea6735a51205591349271f73e9b10972b1a","_cell_guid":"0a460662-1676-4ac7-8ffa-44d594cce15b"},"source":"Alright, now we're ready to fit our model! To do this, we need to pass the function glm() a formula with the columns we're interested in, the name of the dataframe (so it knows where the columns are from) and the family for our model. Remember from earlier that our formula should look like this:\n\n    Output ~ input\n    \nWe're also predicting a count value, as discussed above, so we want to make sure the family is Poisson.","cell_type":"markdown"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"a748a503eaf88fd47e12c44a46c01a553cbdebc5","_cell_guid":"a1e23134-b6ae-42e0-be26-372bea2d797a"},"source":"# poisson model to predict salary by age\nmodel <- glm(CleanedCompensationAmount ~ Age, data = has_compensation, family = poisson)","cell_type":"code"},{"metadata":{"_uuid":"558483c0acbcf974de3eba25e1a0bf4cd02fb6b2","_cell_guid":"bc48b84d-9007-48c0-aa36-39fab1c5dded"},"source":"We'll talk about how to examine and interpret a model tomorrow. For now, we want to make sure that it's a good fit for our data and problem. To do this, let's use some diagnostic plots.  ","cell_type":"markdown"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"a76c5c8b6936f2f9645013597e48cf11dc0c44f1","_cell_guid":"48769f1c-81c9-4a18-b682-7ea596f85f2c"},"source":"# diagnostic plots\nglm.diag.plots(model)","cell_type":"code"},{"metadata":{"_uuid":"e5ce1294d9d12611e9192e9832d8ddbb7ab473df","_cell_guid":"630aa1f2-3842-4031-87dd-1b5f4f91e5ec"},"source":"All of these diagnostic plots are plotting residuals, or how much our model is off for a specific prediction. Spoiler alert: all of these plots are showing us big warning signs for this model! Here's what they should look like:\n\n* **Residuals vs Linear predictor**: You want this to look like a shapeless cloud. If there are outliers it means you've gotten some things very wrong, and if there's a clear pattern it usually means you've picked the wrong type of model. (For logistic regression, you can just ignore this plot. It's checking if the residuals are normally distributed, and logistic regression doesn't assume that they will be.)\n* **Quantiles of standard normal vs. ordered deviance residuals**: For this plot you want to see the residuals lined up along the a diagonal line that goes from the bottom left to top right. If they're strongly off that line, especially in one corner, it means you have a strong skew in your data. (For logistic regression you can ignore this plot too.)\n* **Cook's distance vs. h/(1-h)**: Here, you want your data points to be clustered near zero. If you have a data point that is far from zero (on either axis) it means that it's very influential and that one point is dramatically changing your analysis.\n* **Cook's distance vs. case**: In this plot, you want your data to be mostly around zero on the y axis. The x axis just tells you what row in your dataframe the observation is taken from. Points that are outliers on the y axis are changing your model a lot and should probably be removed (unless you have a good reason to include them).\n\nBased on these diagnostic plots, we should definitely not trust this model. There are a small handful of very influential points that are drastically changing our model. Remember, we didn't convert all the currencies to the same currency, so we're probably seeing some weirdnesses due to including a currency like the Yen, which is worth roughly one one-hundredth of a dollar. \n\nWith that in mind, let's see how the plots change when we remove any salaries above 200,000. ","cell_type":"markdown"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"ed52f745f37da4690d2a6d43b543642a2abddc4a","_cell_guid":"9f62edca-3acf-42b0-91cd-1601d53c030d"},"source":"# remove compensation values above 150,000\nhas_compensation <- has_compensation %>%\n    filter(CleanedCompensationAmount < 150000)\n\n# linear model to predict salary by age\nmodel <- glm(CleanedCompensationAmount ~ Age, data = has_compensation, family = poisson)\n\n# diagnostic plots\nglm.diag.plots(model)","cell_type":"code"},{"metadata":{"_uuid":"65ab4917cccfb98124a7b4f61fc5cfe50aa44291","_cell_guid":"c266788b-2834-4abf-b750-f3e3ee5e28a8"},"source":"Now our plots looks much better! Our residuals are more-or-less randomly distributed (which is what the first two plots tell us) and while we still have one outstanding influential point, we can tell by comparing the Cook statistics from the first and second set of plots that it's waaaaaaaayyy less influential than the outliers we got rid of. \n\nOur first model would probably not have been very informative for a new set of observations. Our second model is more likely to be helpful. \n\nAs a final step, we can fit & plot a model to our data, like we did yesterday to see if our hunch about age and salary was correct.","cell_type":"markdown"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"8def2ab983d01d3c2fbd517a5846e66b6bffa8c6","_cell_guid":"fdc78029-62f1-4045-9574-fa33629d1a5e"},"source":"# plot & add a regression line\nggplot(has_compensation, aes(x = Age, y = CleanedCompensationAmount)) + # draw a \n    geom_point() + # add points\n    geom_smooth(method = \"glm\", # plot a regression...\n    method.args = list(family = \"poisson\")) # ...from the binomial family","cell_type":"code"},{"metadata":{"_uuid":"9628c9d327406c9883ec2dd90ce250bdb964a706","_cell_guid":"f3f971fa-3018-47c1-a9b7-47de2f3d3beb"},"source":"It looks like we were right about older data scientists making more. It does look like there are some outliers in terms of age, which we could remove with further data cleaning (which you're free to do if you like). First, however, why don't you try your hand at fitting a model and using diagnostic plots to check it out?","cell_type":"markdown"},{"metadata":{"_uuid":"88f2044aea7313119366ee7e76b96eebcb71306e","_cell_guid":"4dd0fe85-1c6b-4bc5-8ed4-fb4d8e5c2c06"},"source":"## Your turn!\n___\n\nNow it's your turn to come up with a model and check it out using diagnostic plots!\n\n1. Pick a question to answer to using the Stack Overflow dataset. (You may want to check out the \"survey_results_schema.csv\" file to learn more about the data.) Pick a variable to predict and one varaible to use to predict it.\n2. Fit a GLM model of the appropriate family. (Check out [yesterday's challenge](https://www.kaggle.com/rtatman/regression-challenge-day-1) if you need a refresher.\n3. Plot diagnostic plots for your model. Does it seem like your model is a good fit for your data? Are the residuals normally distributed (no patterns in the first plot and the points in the second plot are all in a line)? Are there any influential outliers?\n4. Plot your two variables & use \"geom_smooth\" and the appropriate family to fit and plot a model\n5. Optional: If you want to share your analysis with friends or to ask for help, you’ll need to make it public so that other people can see it.\n    * Publish your kernel by hitting the big blue “publish” button. (This may take a second.)\n    * Change the visibility to “public” by clicking on the blue “Make Public” text (right above the “Fork Notebook” button).\n    * Tag your notebook with 5daychallenge","cell_type":"markdown"},{"metadata":{"_uuid":"0b2b31fbcea4f0562377881e7ef8b8cc4329e2c5","_cell_guid":"b199f580-a489-42d0-af72-615cf9ce3b0c"},"source":"# Python :)\n","cell_type":"markdown"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"755b8e10340b53b53253be90c2a0662ec8c90d79","_cell_guid":"d864f104-4fd2-4d66-9d33-8cbb2c543c35"},"source":"#Import the libraries\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nimport matplotlib.pyplot as plt\n#Read the data\ndf = pd.read_csv(\"../input/so-survey-2017/survey_results_public.csv\", encoding='utf8')      ","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"6be8407d7f82db2183b0e538742e3e08dfc6ca36","_kg_hide-output":false,"_cell_guid":"35b0dc18-b620-4e36-b8a5-bfa9ba5954b4"},"source":"# overview of data\n#df.describe()\ndf.head()","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"9a0acab48682e608a8fb0bb50c709e13c6d8f28a","collapsed":true,"_kg_hide-input":true,"_kg_hide-output":true,"_cell_guid":"95ac33a1-e364-4874-b64c-cf1ee31d5b4d"},"source":"companysize = df['CompanySize']\ncompanysize.fillna(0, inplace = True)\noptions = companysize.unique()\noptions = options[1:-2]\noptions","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"725f902c82c730e88660707c5d22e419594d2f4d","_cell_guid":"a761c170-952f-44b5-82ee-e8808b3a69b6"},"source":"","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"b33b65bfa527468645e29096b7a720f16934e407","_cell_guid":"73dd2b49-1a4c-4bcf-8194-2a3670df95ac"},"source":"","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"afb5ea169cafd5634764601732187bbcfc4898e5","_cell_guid":"79b3fc24-3ab3-4aa2-9089-36e569a078db"},"source":"","cell_type":"code"},{"metadata":{"_uuid":"3d72c59ddc43972b54a32170f1fca5f38330049e","_cell_guid":"07a53b1b-8af8-4ee8-a8d7-c4625bdbc7cf"},"source":"1. predict job satisfaction with home/remote\n2.predict satisfaction with country\n3.formal education and job satisfaction\n4.expected salary and no. of years in coding","cell_type":"markdown"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"94aa6137edcf8227248a8fd9ce6f4cc62208da23","_cell_guid":"2c151503-ce5e-47bb-a8ff-ebd8ba3b9925"},"source":"# to fill NaN values with 0 and convert it into numeric\nclean_salary = df['Salary']\nclean_salary.fillna(0,inplace = True)\nclean_salary = pd.to_numeric(clean_salary)\n# selecting values which are greater than 0\n#clean_salary = clean_salary[clean_salary>0]","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"a0a8bdbd4f438adcfd7b80563d11ccba5640a534","_kg_hide-output":true,"_cell_guid":"cb3dd88b-66dc-44ab-8dad-1ccda3b21da9"},"source":"#cleaning Years program column\ndf['YearsProgram'].value_counts()\nyearsprogram = df['YearsProgram']\nyearsprogram.fillna(0,inplace = True)\n","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"a83ef6a630739e8794dac7e59b1b342dc33fcc5f","_cell_guid":"090b0f62-468a-4cca-bd51-92f9b183a7d3"},"source":"#cleaning hours per week column\ndf['HoursPerWeek'].value_counts()\nclean_hours = df['HoursPerWeek']\nclean_hours.fillna(0,inplace = True)\nclean_hours = pd.to_numeric(clean_hours)","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"fecfca73b1a9c4cf3cc1736c18aeb1c6831884f0","_cell_guid":"17115001-1b54-4784-831d-164f57d8087d"},"source":"# Applying Regressor model\nx =clean_hours[:, np.newaxis]\ny = clean_salary\nreg = LinearRegression()\nreg.fit(x,y)\ny_pred = reg.predict(x)\nplt.scatter(x, y)\nplt.plot(x, y_pred, color='blue', linewidth=3)","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"1f44cc4ead4895fe3aabcbfd285c769ad85d68ae","collapsed":true,"_kg_hide-input":true,"_kg_hide-output":true,"_cell_guid":"969efdb7-13d6-44f0-bea2-a784a80e0044"},"source":"from statsmodels.genmod.generalized_estimating_equations import GEE\nfrom statsmodels.genmod.cov_struct import (Exchangeable,\n    Independence,Autoregressive)\nfrom statsmodels.genmod.families import Poisson\n\nfam = Poisson()\nind = Independence()\nmodel1 = GEE.from_formula(\"y ~ age + trt + base\", \"subject\", data, cov_struct=ind, family=fam)\nresult1 = model1.fit()\nprint(result1.summary())","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"699029c1661655a33582aec07eb996127d3b7fde","_cell_guid":"1067c2be-e0d7-47e6-984c-8d1ff0e379a8"},"source":"","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"6c88154bf8fa79867fee9a377a69957067aa32df","_cell_guid":"d3978f56-da41-4275-8e8d-4e5c6ec99b38"},"source":"","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"530080ad9451c4ad411ea09df5cde8b956500990","_cell_guid":"cb934c10-4da7-4ec3-af94-75d7c8a8c890"},"source":"","cell_type":"code"},{"metadata":{"_uuid":"705d478da3ebb89a039bd69bc51363b853a423c3","_cell_guid":"cfd54f2e-6061-4a3e-8bae-1a8feeaf4183"},"source":"Want more? Ready for a different dataset? [This notebook](https://www.kaggle.com/rtatman/datasets-for-regression-analysis/) has additional dataset suggestions for you to practice regression with. ","cell_type":"markdown"}],"nbformat_minor":1,"nbformat":4,"metadata":{"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"},"language_info":{"name":"python","file_extension":".py","codemirror_mode":{"version":3,"name":"ipython"},"version":"3.6.3","nbconvert_exporter":"python","mimetype":"text/x-python","pygments_lexer":"ipython3"}}}