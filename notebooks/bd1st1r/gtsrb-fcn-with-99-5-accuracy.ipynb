{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport cv2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_csv = pd.read_csv(\"/kaggle/input/gtsrb-german-traffic-sign/Test.csv\",skiprows = 0)\ntrain_csv = pd.read_csv(\"/kaggle/input/gtsrb-german-traffic-sign/Test.csv\",skiprows = 0)\n\n\nIMG_WIDTH = 30\nIMG_HEIGHT = 30","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_images = []\ntest_labels = []\n\nlabel_coll = set()\n\nfor _,row in test_csv.iterrows():\n    filename = row[\"Path\"]\n    label = row[\"ClassId\"]\n    path = f\"/kaggle/input/gtsrb-german-traffic-sign/{filename}\"\n    img = cv2.imread(path, 1)\n    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n    test_images.append(img)\n    test_labels.append(int(label))\n    label_coll.add(label)\n\ntest_labels = tf.keras.utils.to_categorical(test_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images = []\ntrain_labels = []\n\nfor _,row in train_csv.iterrows():\n    filename = row[\"Path\"]\n    label = row[\"ClassId\"]\n    path = f\"/kaggle/input/gtsrb-german-traffic-sign/{filename}\"\n    img = cv2.imread(path, 1)\n    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n    train_images.append(img)\n    train_labels.append(int(label))\n\ntrain_labels = tf.keras.utils.to_categorical(train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_labels = len(label_coll)\n\nDROPOUT_RATE_SP = 0.3\nDROPOUT_RATE = 0.3\nBATCH_SIZE = 5\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.Sequential()\n\n# initialize with He Normal\ninitializer = tf.keras.initializers.HeNormal()\n\n#Input layer block convolution - batch normalization - dropout - relu\nmodel.add(tf.keras.layers.Conv2D(filters = 30, kernel_size = 3, kernel_initializer=initializer, input_shape=(30, 30, 3)))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.SpatialDropout2D(rate = DROPOUT_RATE_SP))\nmodel.add(tf.keras.layers.Activation('relu'))\n\n# block 2 downsampling - batch normalization - dropout - relu\nmodel.add(tf.keras.layers.Conv2D(filters = 30, kernel_size = 2, strides = 2, kernel_initializer = initializer))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.SpatialDropout2D(rate = DROPOUT_RATE_SP))\nmodel.add(tf.keras.layers.Activation('relu'))\n\n# block 3 convolution - batch normalization - dropout - relu\nmodel.add(tf.keras.layers.Conv2D(filters = 30, kernel_size = 3, kernel_initializer=initializer))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dropout(0.3))\nmodel.add(tf.keras.layers.Activation('relu'))\n\n# block 4 downsampling - batch normalization - dropout - relu\nmodel.add(tf.keras.layers.Conv2D(filters = num_labels, kernel_size = 2, strides = 2, kernel_initializer=initializer))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dropout(DROPOUT_RATE))\nmodel.add(tf.keras.layers.Activation('relu'))\n\n# block 5 convolution - batch normalization - dropout - relu\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Conv2D(filters = num_labels, kernel_size = 3, kernel_initializer=initializer))\nmodel.add(tf.keras.layers.Dropout(DROPOUT_RATE))\nmodel.add(tf.keras.layers.Activation('relu'))\n\n# block 6 downsampling - batch normalization - dropout - relu\nmodel.add(tf.keras.layers.Conv2D(filters = num_labels, kernel_size = 2, strides = 2, kernel_initializer=initializer))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dropout(DROPOUT_RATE))\nmodel.add(tf.keras.layers.Activation('relu'))\n\n# block 7 downsampling - batch normalization - relu\nmodel.add(tf.keras.layers.Conv2D(filters = num_labels, kernel_size = 2, strides = 2, kernel_initializer=initializer))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Activation('relu'))\n\n# output layer 1-convolution - softmax\nmodel.add(tf.keras.layers.Conv2D(filters = num_labels, kernel_size = 1))\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Softmax())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" # show summary of layers and corresponding outputs\nmodel.summary()\n\n# optimizer\noptimizer = tf.keras.optimizers.Adagrad(learning_rate=0.02, initial_accumulator_value=0.1, epsilon=1e-06)\n\nmodel.compile(\noptimizer=optimizer,\nloss=\"categorical_crossentropy\",\nmetrics=[\"accuracy\"]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_accuracy = 0\ncount_lower = 0\n\nwhile (True):\n        # Fit model on training data\n        model.fit(np.asarray(train_images), np.asarray(train_labels), epochs=5, batch_size = BATCH_SIZE)\n\n        # Evaluate neural network performance\n        accuracy = model.evaluate(np.asarray(test_images),  np.asarray(test_labels), verbose=2)[1]\n        if accuracy > max_accuracy:\n            count_lower = 0\n            model.save(\"gtsrb_fcn\")\n            max_accuracy = accuracy\n        else: \n            if count_lower > 4: \n                break\n            count_lower += 1\n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}