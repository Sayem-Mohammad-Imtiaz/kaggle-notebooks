{"cells":[{"cell_type":"markdown","metadata":{},"source":"### Here we try to predict if two person would result a match and give some importance featurues"},{"cell_type":"markdown","metadata":{},"source":"Load data"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\n%matplotlib inline\ndata_df = pd.read_csv(\"../input/Speed Dating Data.csv\", encoding=\"ISO-8859-1\")\ndata_df.head()"},{"cell_type":"markdown","metadata":{},"source":"There are Nan values in both 'field' and 'field_cd', but there are some entries that 'field' is filled but with 'filed_cd' empty, so we convert them here"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"print(\"Numer of ppl did not fill field:\", sum(pd.isnull(data_df['field'])))\nprint(\"Numer of ppl did not fill field_cd:\", sum(pd.isnull(data_df['field_cd'])))\nprint(\"Number of ppl did not fill career:\", sum(pd.isnull(data_df['career'])))\n\n# convert all filled field to field code\nf_fcd = data_df[['field','field_cd']].drop_duplicates() # get all listed filed name and its code\nnan_ind = pd.isnull(f_fcd).any(1).nonzero()[0] # row has Nan\nf_fcd.drop(f_fcd.index[nan_ind],inplace=True) # remove rows that has Nan\n\nfcd_ind = pd.isnull(data_df['field_cd']).nonzero()[0] # row where 'field_cd' is Nan\ndata_ind = data_df.index\nn = 0\nfor i in fcd_ind:\n    field_i = data_df.loc[data_ind[i], 'field']\n    f_cd = f_fcd[f_fcd['field']==field_i]['field_cd'].values\n    if pd.isnull(f_cd) == 0: # if the person did not leave 'field' empty\n        n += 1\n        data_df.loc[data_ind[i], 'field_cd'] = f_cd[0]\nprint(\"Done converting with {} filed_cd added!\".format(n))"},{"cell_type":"markdown","metadata":{},"source":"We will only use some relevant and avaliable features"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# note 'career_c' is incomplete and needs to add\n# And also 'attr5_1', 'sinc5_1', 'intel5_1', 'fun5_1', 'amb5_1' are not filled \nuse_features = ['iid', 'gender', 'pid', 'match', 'samerace', 'age_o', 'race_o', \\\n                 'pf_o_att', 'pf_o_sin', 'pf_o_int','pf_o_fun', 'pf_o_amb', 'pf_o_sha',\\\n                 'age', 'field_cd', 'race', 'imprace', 'imprelig', 'goal', 'date', 'go_out', 'sports',\\\n                 'tvsports', 'exercise', 'dining', 'museums', 'art', 'hiking', 'gaming', 'clubbing',\\\n                 'reading', 'tv', 'theater', 'movies', 'concerts', 'music', 'shopping', 'yoga', 'exphappy',\\\n                 'attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1', 'attr2_1', 'sinc2_1',\\\n                 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1', 'attr3_1', 'sinc3_1','fun3_1', 'intel3_1', 'amb3_1']\nData_df = data_df[use_features]"},{"cell_type":"markdown","metadata":{},"source":"build the vector that contains the information both for the male and female"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# first get rid off any rows contain Nan value\ninds = pd.isnull(Data_df).any(1).nonzero()[0] # row index that contains Nan\nprint(\"number of rows contain Nan:\", len(inds))\nData_df= Data_df.drop(Data_df.index[inds])\n# notice pid is float, so we change it to int\nData_df['pid'] = Data_df['pid'].astype(int)\nData_df['iid'] = Data_df['iid'].astype(int)\n\nmdata_df = Data_df[Data_df['gender']==1]\nfdata_df = Data_df[Data_df['gender']==0]\nprint(mdata_df.shape)\nprint(fdata_df.shape)\nsame1 = []\nfor i in mdata_df.pid.values:\n    if i not in fdata_df.iid.values:\n        same1.append(i)\nprint(\"some guy's partener is not found in fdata:\", list(set(same1)))\nsame2 = []\nfor i in fdata_df.pid.values:\n    if i not in mdata_df.iid.values:\n        same2.append(i)\nprint(\"some girl's partener is not found in mdata:\", list(set(same2)))\n\n# male features in combination\ncmfeatures = ['iid', 'pid', 'match', 'samerace', 'age', 'field_cd', 'race', 'imprace', 'imprelig', 'goal', 'date', 'go_out',\\\n             'sports', 'tvsports', 'exercise', 'dining', 'museums', 'art', 'hiking', 'gaming', 'clubbing',\\\n             'reading', 'tv', 'theater', 'movies', 'concerts', 'music', 'shopping', 'yoga', 'exphappy',\\\n             'attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1', 'attr2_1', 'sinc2_1',\\\n             'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1', 'attr3_1', 'sinc3_1','fun3_1', 'intel3_1', 'amb3_1']\nnew_mdata = mdata_df[cmfeatures]\n# female features in combination\ncffeatures = [cmfeatures[0]] + cmfeatures[4:]\nnew_fdata = fdata_df[cffeatures].drop_duplicates()\nnew_data = pd.DataFrame.copy(new_mdata)\nnew_fdata.columns = [i+'_f' for i in cffeatures] # rename the feature name of female"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"df = pd.DataFrame()\nfor i in new_mdata.index.values:\n    m_info = new_mdata.loc[i,:]\n    pid = new_mdata.loc[i,'pid'] # this is the (female)partener's ID\n    f_ind = new_fdata.iid_f==pid\n    if sum(f_ind) !=0: # append only if the pid is found in female iid\n        f_info_df = new_fdata[f_ind]\n        f_info = f_info_df.loc[f_info_df.index[0],:]\n        combined = m_info.append(f_info)\n        df = df.append(combined,ignore_index=True)\n# now drop features that we do not need for prediction\ndrop_features = ['iid', 'pid', 'iid_f']\nprint(\"Done making data for pairs\")\npair_df = df.drop(drop_features,axis=1)\npair_df.head()"},{"cell_type":"markdown","metadata":{},"source":"Now let us build the model, first, and see the number of each class(0 = no, 1 = yes)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"pair_train = pair_df.drop('match',axis=1)\npair_label = pair_df['match']\nprint(\"total training data size:\", pair_df.shape)\npd.Series.value_counts(pair_label)"},{"cell_type":"markdown","metadata":{},"source":"we will use a tuned xgb model"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import xgboost as xgb\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn import cross_validation, metrics   #Additional scklearn functions\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.grid_search import GridSearchCV   #Performing grid search\n\nimport matplotlib.pylab as plt\n%matplotlib inline\nfrom matplotlib.pylab import rcParams\nrcParams['figure.figsize'] = 22, 4\n\nfrom time import time\n\n# create train and test data\ntrain_data, test_data = train_test_split(pair_df, test_size=0.1, random_state=42, stratify=pair_df['match'])\npredictors = [x for x in pair_df.columns if x not in ['match']]\nprint(\"train shape:\", train_data.shape)\nprint(\"test shape:\", test_data.shape)"},{"cell_type":"markdown","metadata":{},"source":"### Train our model!"},{"cell_type":"markdown","metadata":{},"source":"(see details :http://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"def modelfit(alg, dtrain, dtest, predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=20):\n    t1 = time()\n    if useTrainCV:\n        xgb_param = alg.get_xgb_params()\n        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain['match'].values)\n        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n            metrics=['auc'], early_stopping_rounds=early_stopping_rounds, stratified=True)#, show_progress=False)\n        alg.set_params(n_estimators=cvresult.shape[0])\n\n    #Fit the algorithm on the data\n    alg.fit(dtrain[predictors], dtrain['match'],eval_metric=['auc'])\n        \n    #Predict training set:\n    dtrain_predictions = alg.predict(dtrain[predictors])\n    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n    #Predict test set:\n    dtest_predictions = alg.predict(dtest[predictors])\n    dtest_predprob = alg.predict_proba(dtest[predictors])[:,1]\n    \n    t2 = time()    \n    #Print model report:\n    print(\"\\nModel Report (took {0:.2f}sec)\".format(t2-t1))\n    print(\"The result params is:\\n\", alg.get_xgb_params())\n    print(\"Train Accuracy: {0:.2f}%\".format(metrics.accuracy_score(dtrain['match'].values, dtrain_predictions)))\n    print(\"Train AUC Score: {0:.4f}\".format(metrics.roc_auc_score(dtrain['match'], dtrain_predprob)))\n    print(\"Test Accuracy: {0:.2f}%\".format(metrics.accuracy_score(dtest['match'].values, dtest_predictions)))\n    print(\"Test AUC Score: {0:.4f}\".format(metrics.roc_auc_score(dtest['match'], dtest_predprob)))\n    \n    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n    feat_imp.plot(kind='bar', title='Feature Importances')\n    plt.ylabel('Feature Importance Score')\n    return dtest_predprob, feat_imp"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"clf = XGBClassifier(learning_rate =0.01,\n                     n_estimators=5000,\n                     max_depth=7,\n                     min_child_weight=12,\n                     gamma=0.,\n                     subsample=0.85,\n                     colsample_bytree=0.85,\n                     reg_alpha=0.,\n                     objective= 'binary:logistic',\n                     nthread=4,\n                     scale_pos_weight=1,\n                     seed=27)\nresult = modelfit(clf, train_data, test_data, predictors)"},{"cell_type":"markdown","metadata":{},"source":"First 10 important features: (importance in descending order)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"print(result[1].index.values[:10])"},{"cell_type":"markdown","metadata":{},"source":"Least 10 important features: (importance in ascending order)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"print(list(result[1].index.values[-10:])[::-1])"},{"cell_type":"markdown","metadata":{},"source":"### To evaluate how good our model is, plot ROC"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from sklearn.metrics import roc_curve, auc\nrcParams['figure.figsize'] = 10, 8\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(test_data['match'], result[0])\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.2f'% roc_auc)\nplt.plot([0,1],[0,1],'r--')\nplt.legend(loc='lower right')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()"},{"cell_type":"markdown","metadata":{},"source":"Although our model does predict the outcome of the match, but AUC score is 0.768 which means our model is not the best yet or fair.(see more about auc_roc: https://datamize.wordpress.com/2015/01/24/how-to-plot-a-roc-curve-in-scikit-learn/ and http://gim.unmc.edu/dxtests/roc3.htm)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}