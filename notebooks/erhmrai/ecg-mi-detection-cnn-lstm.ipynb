{"cells":[{"metadata":{"_uuid":"6347f253-f118-4188-bb95-ead8a02ae3e9","_cell_guid":"3ec7f218-b68a-4e14-9849-4cd2afa3d5fa","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4e797230-1faa-4ba0-a513-ece5969a2c4b","_cell_guid":"26b3477c-4ede-481d-aafa-972b215f2513","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nimport tensorflow as tf\nfrom tensorflow.compat.v1 import ConfigProto\nfrom tensorflow.compat.v1 import InteractiveSession\n\n\nconfig = ConfigProto()\nconfig.gpu_options.allow_growth = True\nsession = InteractiveSession(config=config)\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as mcolors\nimport matplotlib\nimport seaborn as sns\n\nimport random\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nimport torch.nn as nn\nimport sklearn\n\nimport torch.nn.functional as F\nimport itertools\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\nfrom tqdm import tqdm\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import classification_report, confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"35f9da3e-2f8d-460c-b06d-6326a110dee8","_cell_guid":"602166a6-4a7c-4d11-81ea-9de25224514c","trusted":true},"cell_type":"code","source":"mit_train_df = pd.read_csv(\"/kaggle/input/heartbeat/mitbih_train.csv\", header=None)\nmit_test_df = pd.read_csv(\"/kaggle/input/heartbeat/mitbih_test.csv\", header=None)\n\nprint(mit_train_df.shape)\nprint(mit_test_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"63bc3154-e4e5-4307-86f4-9e452c393808","_cell_guid":"d684f9c4-add3-42af-a87a-b2f133d6d6ae","trusted":true},"cell_type":"code","source":"ptb_n_df = pd.read_csv(\"/kaggle/input/heartbeat/ptbdb_normal.csv\", header=None)\nptb_ab_df = pd.read_csv(\"/kaggle/input/heartbeat/ptbdb_abnormal.csv\", header=None)\n\nprint(ptb_n_df.shape)\nprint(ptb_ab_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ptb_df=pd.concat([ptb_n_df, ptb_ab_df], axis=0)\nptb_df.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cb2cdbe2-44c0-497d-bc7a-a4bc336bd6a0","_cell_guid":"13a34608-6a84-4629-b6d2-133ba09e0292","trusted":true},"cell_type":"code","source":"mit_df=pd.concat([mit_train_df, mit_test_df], axis=0)\nmit_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(mit_df[mit_df.columns[-1]].unique())\nprint(ptb_df[ptb_df.columns[-1]].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ptb_df.iloc[:, 187] = ptb_df.iloc[:, 187].map({0:0, 1: 5})\ndf = pd.concat([mit_df, ptb_df], axis=0)\n\ntrain_classes={0:\"N\",\n            1:\"S\",\n            2:\"V\",\n            3:\"F\",\n            4:\"Q\",\n            5:\"M\"}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df[df.columns[-1]].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\ndf_0=df[df[187]==0]\ndf_1=df[df[187]==1]\ndf_2=df[df[187]==2]\ndf_3=df[df[187]==3]\ndf_4=df[df[187]==4]\ndf_5=df[df[187]==5]\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.iloc[:, 187] = df.iloc[:, 187].map({0:0,1:0,2:0,3:0,4:0,5:1})\n#df = pd.concat([mit_df, ptb_df], axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df[df.columns[-1]].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"equilibre=df[187].value_counts()\nprint(equilibre)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train=pd.concat([df_0,df_1,df_2,df_3,df_4])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_0.shape,df_1.shape,df_2.shape,df_3.shape,df_4.shape,df_5.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a1a7b775-8770-4df4-bae8-64cea8398245","_cell_guid":"fc5b3037-896e-473a-84aa-69579721bb77","trusted":true},"cell_type":"code","source":"train_df, test_df = train_test_split(df, test_size=0.2, stratify=df[187], random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"44a100a5-ee93-48cd-8fca-070a180012cd","_cell_guid":"e2df476e-ee47-42d4-b283-e10c1459ebc0","trusted":true},"cell_type":"code","source":"train_df.shape, test_df.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"350b9b88-dcc7-470f-96f3-df5edcb90305","_cell_guid":"e7461af0-228b-4424-a4c6-60d809f10d8d","trusted":true},"cell_type":"code","source":"train_x = np.array(train_df[train_df.columns[0:-1]], dtype=np.float32)\ntrain_y = np.array(train_df[train_df.columns[-1:]], dtype=np.float32)\n\ntest_x = np.array(train_df[test_df.columns[0:-1]], dtype=np.float32)\ntest_y = np.array(train_df[test_df.columns[-1:]], dtype=np.float32)\n\nprint(\"print train set is : x = {} y = {}\".format(train_x.shape, train_y.shape))\nprint(\"print test set is : x = {} y = {}\".format(test_x.shape, test_y.shape))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"74823b48-8ee6-4200-aa65-634e02f43de5","_cell_guid":"acfc9278-cd24-415c-86d1-be315c8f625c","trusted":true},"cell_type":"code","source":"print(train_df[train_df.columns[-1]].unique())\nprint(train_df[test_df.columns[-1]].unique())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7fa7eebf-2916-4610-b381-b9716da8b023","_cell_guid":"e14b5063-334d-4505-9f95-316e30c8141b","trusted":true},"cell_type":"code","source":"#x_train_tl.shape, y_train_tl.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5428cf03-f1b8-4581-b36d-44ffbe045a5e","_cell_guid":"e5ea0836-43db-4bdc-aba4-3ca525d4d7e9","trusted":true},"cell_type":"code","source":"#x_train_over.shape, y_train_over.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7b58cd26-9601-4b9b-bfa4-c9220ade960f","_cell_guid":"ee48de69-df18-4c47-b029-31ee94f3213c","trusted":true},"cell_type":"code","source":"train_df[187]=train_df[187].astype(int)\nequilibre=train_df[187].value_counts()\nprint(equilibre)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8754463e-fc43-4429-bf2d-7d1892d6308c","_cell_guid":"37671fa0-1d5d-4159-af8c-b2a903356e22","trusted":true},"cell_type":"code","source":"test_df[187]=test_df[187].astype(int)\nequilibre=test_df[187].value_counts()\nprint(equilibre)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7a483f66-4506-48c1-96d4-67cc1906493e","_cell_guid":"3097016b-45d8-4aec-84a7-de7521c460ae","trusted":true},"cell_type":"code","source":"#import collections, numpy","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3e4dd822-0682-4709-92c5-a43c392ede3a","_cell_guid":"31840d45-3de2-48d1-a5aa-0d92a1805920","trusted":true},"cell_type":"code","source":"#ht=np.count_nonzero(y_train_over == 1, axis=0)\n#collections.Counter(y_train_over)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7ff53fc3-a9ad-4c62-b27a-0706da4feedf","_cell_guid":"c9189bb2-6f40-4727-b2de-f63a1f97e771","trusted":true},"cell_type":"code","source":"# Return difference array\ndef return_diff_array_table(array, dur):\n  for idx in range(array.shape[1]-dur):\n    before_col = array[:,idx]\n    after_col = array[:,idx+dur]\n    new_col = ((after_col - before_col)+1)/2\n    new_col = new_col.reshape(-1,1)\n    if idx == 0:\n      new_table = new_col\n    else :\n      new_table = np.concatenate((new_table, new_col), axis=1)\n#For concat add zero padding\n  padding_array = np.zeros(shape=(array.shape[0],dur))\n  new_table = np.concatenate((padding_array, new_table), axis=1)\n  return new_table\n#Concat\ndef return_merge_diff_table(df, diff_dur):\n  fin_table = df.reshape(-1,187,1,1)\n  for dur in diff_dur:\n    temp_table = return_diff_array_table(df, dur)\n    fin_table = np.concatenate((fin_table, temp_table.reshape(-1,187,1,1)), axis=2)\n  return fin_table\n\n#Use \"stratify\" option\nx_train, x_val, y_train, y_val = train_test_split(train_x, train_y, test_size=0.2, stratify=train_y)\n\n#Add Data\nx_train = return_merge_diff_table(df=x_train, diff_dur=[1])\nx_val = return_merge_diff_table(df=x_val, diff_dur=[1])\n\nprint(x_train.shape, y_train.shape, x_val.shape, y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6b48465f-9c64-41b9-9118-dc1b5b8ce655","_cell_guid":"9af132a1-a904-4a21-bfb4-05dac766a7b0","trusted":true},"cell_type":"code","source":"#For see a model's result\ndef return_result(model, x_train, x_test, y_train, y_test):\n    y_pred = model.predict(x_test)\n    train_pred = model.predict(x_train)\n    pred_list=[]\n    for x in y_pred:\n        pred_list.append(np.argmax(x))\n    train_pred_list=[]\n    for x in train_pred:\n        train_pred_list.append(np.argmax(x))\n    test_mat = confusion_matrix(y_test, pred_list)\n    train_mat = confusion_matrix(y_train, train_pred_list)\n    print(\"In train\")\n    print(accuracy_score(y_train, train_pred_list))\n    print(train_mat)\n    print(\"In test\")\n    print(accuracy_score(y_test, pred_list))\n    print(test_mat)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e9a027ae-0388-4ac4-83aa-da629e43b672","_cell_guid":"33e4fcb9-ac94-4bd3-bb91-ff1741c5ff0d","trusted":true},"cell_type":"code","source":"def return_model1():\n    input_tens = tf.keras.Input(shape=(187,2,1))\n    x = tf.keras.layers.Conv2D(256, kernel_size=(10,2), strides=(5,1),padding='valid')(input_tens)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.Dropout(rate=0.5)(x)\n    x = tf.keras.layers.Conv2D(512, kernel_size=(5,1), padding='valid')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.Dropout(rate=0.5)(x)\n    x = tf.keras.layers.Conv2D(512, kernel_size=(5,1), padding='valid')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.Dropout(rate=0.5)(x)\n    x = tf.keras.layers.Conv2D(128, kernel_size=(5,1), padding='valid')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.Dropout(rate=0.5)(x)\n    x = tf.keras.layers.Conv2D(64, kernel_size=(5,1), padding='valid')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dense(2, activation=\"softmax\")(x)\n    model = tf.keras.Model(inputs=input_tens, outputs=x)\n    model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n    print(model.summary())\n    return model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"73fba9f3-22c5-45cd-8272-be30c4eb366f","_cell_guid":"8eeae076-ad6c-4629-8129-6c7599f0ceb8","trusted":true},"cell_type":"code","source":"model1 = return_model1()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"014cbb1e-98e2-4dbb-8e73-369023122e39","_cell_guid":"d2d2828a-b750-4410-8bd1-d01072d7cdb9","trusted":true},"cell_type":"code","source":"#For saving best model\ncheckpoint_path_best = \"./best_acc_v01.ckpt\"\ncp_callback_best = tf.keras.callbacks.ModelCheckpoint(checkpoint_path_best,monitor=\"val_accuracy\",save_weights_only=True,verbose=1,save_best_only=True)\n\nhist_ptb=model1.fit(x_train,y_train, epochs=200, batch_size=128, validation_data=(x_val,y_val),callbacks=[cp_callback_best])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b79c1119-f2a6-431d-8d53-16f6380ef8aa","_cell_guid":"f06db5d4-63d4-48a7-8a7f-e6ea5c7b9239","trusted":true},"cell_type":"code","source":"df1 = pd.DataFrame(hist_ptb.history)\ndf1.to_csv(\"train_1.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3ce807ec-ecd1-43be-886d-68e813465fc1","_cell_guid":"08d80575-477f-431a-aab6-806456ca3ef6","trusted":true},"cell_type":"code","source":"\nplt.style.available","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"190b75bd-2599-4f16-9153-67cc789e738d","_cell_guid":"a2840718-dddb-4877-8709-b601de7b1bec","trusted":true},"cell_type":"code","source":"def plot(s):\n\n    with plt.style.context(s):\n        print(s)\n        fig, ax = plt.subplots(figsize=(12, 6))\n        plt.plot(df1[\"accuracy\"],  marker='o', label=\"Training Acc\")\n        plt.plot(df1[\"val_accuracy\"],  marker='o', label=\"Validation Acc\")\n        plt.xticks(np.arange(0, 101, 10.0),fontsize=14,fontweight=\"bold\")\n        plt.yticks(fontsize=14,fontweight=\"bold\")\n        plt.ylabel('accuracy', fontsize=14,fontweight=\"bold\")\n        plt.xlabel('epochs', fontsize=14,fontweight=\"bold\")\n        plt.title(\"Accuracy history using CNN\",fontweight=\"bold\")\n        plt.legend()\n        #plt.savefig(f\"auc_history.svg\",format=\"svg\",bbox_inches='tight', pad_inches=0.2)\n        #plt.savefig(f\"auc_history.png\", format=\"png\",bbox_inches='tight', pad_inches=0.2) \n        plt.show()\n        print()\n        \nfor s in plt.style.available:\n    plot(s);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with plt.style.context(\"seaborn-poster\"):\n    fig, ax = plt.subplots(figsize=(12, 5))\n    plt.plot(df1[\"loss\"],  marker='o', label=\"Training Loss\")\n    plt.plot(df1[\"val_loss\"],  marker='o', label=\"Validation Loss\")\n    plt.xticks(np.arange(0, 201, 20),fontweight='bold')\n    plt.yticks(fontweight='bold')\n    plt.ylabel('loss', fontsize=14,fontweight='bold')\n    plt.xlabel('epochs', fontsize=14,fontweight='bold')\n    plt.title(\"Loss history using CNN\", fontweight='bold')\n    plt.legend()\n    #plt.savefig(f\"loss_history.svg\",format=\"svg\",bbox_inches='tight', pad_inches=0.2)\n    #plt.savefig(f\"loss_history.png\", format=\"png\",bbox_inches='tight', pad_inches=0.2) \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"41a5875a-f890-4bb7-8b83-0a9fc277769a","_cell_guid":"b8491cdc-e9b6-4106-8533-2301989dd685","trusted":true},"cell_type":"code","source":"with plt.style.context(\"fivethirtyeight\"):\n    fig, ax = plt.subplots(figsize=(12, 5))\n    plt.plot(df1[\"loss\"],  marker='o', label=\"Training Loss\")\n    plt.plot(df1[\"val_loss\"],  marker='o', label=\"Validation Loss\")\n    plt.xticks(np.arange(0, 201, 20),fontweight='bold')\n    plt.yticks(fontweight='bold')\n    plt.ylabel('loss', fontsize=18, fontweight='bold')\n    plt.xlabel('epochs', fontsize=18, fontweight='bold')\n    plt.title(\"Loss history\", fontweight='bold')\n    plt.legend()\n    #plt.savefig(f\"loss_history.svg\",format=\"svg\",bbox_inches='tight', pad_inches=0.2)\n    #plt.savefig(f\"loss_history.png\", format=\"png\",bbox_inches='tight', pad_inches=0.2) \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with plt.style.context(\"seaborn-poster\"):\n    fig, ax = plt.subplots(figsize=(12, 5))\n    plt.plot(df1[\"accuracy\"],  marker='o', label=\"Training Acc\")\n    plt.plot(df1[\"val_accuracy\"],  marker='o', label=\"Validation Acc\")\n    plt.xticks(np.arange(0, 201, 20), fontweight='bold')\n    plt.yticks(fontweight='bold')\n    plt.ylabel('Accuracy', fontsize=18, fontweight='bold')\n    plt.xlabel('epochs', fontsize=18, fontweight='bold')\n    plt.title(\"Accuracy history using CNN\", fontweight='bold')\n    plt.legend()\n    #plt.savefig(f\"auc_history.svg\",format=\"svg\",bbox_inches='tight', pad_inches=0.2)\n    #plt.savefig(f\"auc_history.png\", format=\"png\",bbox_inches='tight', pad_inches=0.2) \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c54d0618-480a-42fc-a021-7994decc8fba","_cell_guid":"af676a5c-34f9-43af-b518-427fe3e997ca","trusted":true},"cell_type":"code","source":"with plt.style.context(\"fivethirtyeight\"):\n    fig, ax = plt.subplots(figsize=(12, 5))\n    plt.plot(df1[\"accuracy\"],  marker='o', label=\"Training Acc\")\n    plt.plot(df1[\"val_accuracy\"],  marker='o', label=\"Validation Acc\")\n    plt.xticks(np.arange(0, 201, 20),fontweight='bold')\n    plt.yticks(fontweight='bold')\n    plt.ylabel('Accuracy', fontsize=18, fontweight='bold')\n    plt.xlabel('epochs', fontsize=18, fontweight='bold')\n    plt.title(\"Accuracy history\", fontweight='bold')\n    plt.legend()\n    #plt.savefig(f\"loss_history.svg\",format=\"svg\",bbox_inches='tight', pad_inches=0.2)\n    #plt.savefig(f\"loss_history.png\", format=\"png\",bbox_inches='tight', pad_inches=0.2) \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"df90db9c-e3f1-412e-a579-0b2fa9e3eaaf","_cell_guid":"b8c57548-9b48-42ec-98dd-13a9d85aab59","trusted":true},"cell_type":"code","source":"return_result(model1, x_train=x_train, x_test=x_val, y_train=y_train, y_test=y_val)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fc10c685-c767-49bc-8d83-b65ae55dfcec","_cell_guid":"a2e2f443-383e-4380-a1ab-6f67ebd1cd38","trusted":true},"cell_type":"code","source":"def return_model2():\n    input_tens = tf.keras.Input(shape=(187,2,1))\n    x = tf.keras.layers.Conv2D(256, kernel_size=(10,2), strides=(5,1),padding='valid')(input_tens)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.Dropout(rate=0.5)(x)\n    x = tf.keras.layers.Conv2D(512, kernel_size=(5,1), padding='valid')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.Dropout(rate=0.5)(x)\n    x = tf.keras.layers.Conv2D(512, kernel_size=(5,1), padding='valid')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.Dropout(rate=0.5)(x)\n    x = tf.keras.layers.Reshape((x.shape[1], x.shape[3]))(x)\n    x = tf.keras.layers.LSTM(64)(x)\n    x = tf.keras.layers.Dense(2, activation=\"softmax\")(x)\n    model = tf.keras.Model(inputs=input_tens, outputs=x)\n    model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n    print(model.summary())\n    return model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3e141fd0-c1ad-4f6d-897c-d06dbf211db7","_cell_guid":"18859970-83a6-4176-be8b-739e69e01d00","trusted":true},"cell_type":"code","source":"model2 = return_model2()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"03e46cc2-4432-42e2-8c86-e3dc58d9c2fe","_cell_guid":"f7fb80a6-6e75-4ea6-b1c3-a1439377b9fb","trusted":true},"cell_type":"code","source":"checkpoint_path_best2 = \"./best_acc_v02.ckpt\"\ncp_callback_best2 = tf.keras.callbacks.ModelCheckpoint(checkpoint_path_best2, monitor=\"val_accuracy\", save_weights_only=True, verbose=1, save_best_only=True)\n\nhist_2=model2.fit(x_train,y_train, epochs=200, batch_size=128, validation_data=(x_val,y_val), callbacks=[cp_callback_best2])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3f5b1c9b-54ee-4f70-b361-9490f41aa13f","_cell_guid":"2f754ede-ccca-4376-bfe3-ff22d31db662","trusted":true},"cell_type":"code","source":"df2 = pd.DataFrame(hist_2.history)\ndf2.to_csv(\"train_2.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"91b00cc4-e716-4a63-aa22-7c7a631dae18","_cell_guid":"405c334f-4703-44b9-b5c2-e90f18b1189c","trusted":true},"cell_type":"code","source":"def plot(s):\n\n    with plt.style.context(s):\n        print(s)\n        fig, ax = plt.subplots(figsize=(18, 5))\n        plt.plot(df2[\"accuracy\"],  marker='o', label=\"Training Acc\")\n        plt.plot(df2[\"val_accuracy\"],  marker='o', label=\"Validation Acc\")\n        plt.xticks(np.arange(0, 50, 5.0))\n        plt.ylabel('accuracy', fontsize=14)\n        plt.xlabel('epochs', fontsize=14)\n        plt.title(\"Accuracy history\")\n        plt.legend()\n        #plt.savefig(f\"auc_history.svg\",format=\"svg\",bbox_inches='tight', pad_inches=0.2)\n        #plt.savefig(f\"auc_history.png\", format=\"png\",bbox_inches='tight', pad_inches=0.2) \n        plt.show()\n        print()\n        \nfor s in plt.style.available:\n    plot(s);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7c7f0e46-c490-4952-8e22-f870b3d7cb6a","_cell_guid":"f5658bc4-bf7f-40cf-a4c6-c5bae7f9e542","trusted":true},"cell_type":"code","source":"with plt.style.context(\"fivethirtyeight\"):\n    fig, ax = plt.subplots(figsize=(12, 5))\n    plt.plot(df2[\"accuracy\"],  marker='o', label=\"Training Acc\")\n    plt.plot(df2[\"val_accuracy\"],  marker='o', label=\"Validation Acc\")\n    plt.xticks(np.arange(0, 201, 20),fontweight='bold')\n    plt.yticks(fontweight='bold')\n    plt.ylabel('Accuracy', fontsize=18, fontweight='bold')\n    plt.xlabel('epochs', fontsize=18, fontweight='bold')\n    plt.title(\"Accuracy history using CNN+LSTM\", fontweight='bold')\n    plt.legend()\n    #plt.savefig(f\"loss_history.svg\",format=\"svg\",bbox_inches='tight', pad_inches=0.2)\n    #plt.savefig(f\"loss_history.png\", format=\"png\",bbox_inches='tight', pad_inches=0.2) \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"68fcc4c5-0d69-478e-9ff1-300c1b2c25fb","_cell_guid":"f8867572-5921-475d-b433-13b5ae1cbe46","trusted":true},"cell_type":"code","source":"with plt.style.context(\"fivethirtyeight\"):\n    fig, ax = plt.subplots(figsize=(12, 5))\n    plt.plot(df2[\"loss\"],  marker='o', label=\"Training Loss\")\n    plt.plot(df2[\"val_loss\"],  marker='o', label=\"Validation Loss\")\n    plt.xticks(np.arange(0, 101, 20),fontweight='bold')\n    plt.yticks(fontweight='bold')\n    plt.ylabel('loss', fontsize=18, fontweight='bold')\n    plt.xlabel('epochs', fontsize=18, fontweight='bold')\n    plt.title(\"Loss history using CNN+LSTM\", fontweight='bold')\n    plt.legend()\n    #plt.savefig(f\"loss_history.svg\",format=\"svg\",bbox_inches='tight', pad_inches=0.2)\n    #plt.savefig(f\"loss_history.png\", format=\"png\",bbox_inches='tight', pad_inches=0.2) \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"501c407d-b544-4dc0-8e3e-0ced558764ae","_cell_guid":"35bf77e7-67db-4ad2-a42b-53a9e315ee7a","trusted":true},"cell_type":"code","source":"return_result(model1, x_train=x_train, x_test=x_val, y_train=y_train, y_test=y_val)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"029d9ef7-f1c9-4da2-bba5-2e4a5e3752e8","_cell_guid":"d5134a53-b8ef-4b36-9bd1-0329aa3b3737","trusted":true},"cell_type":"code","source":"#ENSEMBLE\nmodel1.load_weights(checkpoint_path_best)\nmodel2.load_weights(checkpoint_path_best2)\n\nreturn_result(model1, x_train=x_train, x_test=x_val, y_train=y_train, y_test=y_val)\nreturn_result(model2, x_train=x_train, x_test=x_val, y_train=y_train, y_test=y_val)\n\ntest_input = np.array(test_df[test_df.columns[0:-1]], dtype=np.float32)\ntest_target = np.array(test_df[test_df.columns[-1:]], dtype=np.float32)\n\ntest_input = return_merge_diff_table(df=test_input, diff_dur=[1])\n\nprint(test_input.shape, test_target.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"87624a2b-feec-4823-bbfb-cedfffcdd164","_cell_guid":"0d832c6a-e877-4437-8901-cd16db8873ab","trusted":true},"cell_type":"code","source":"pred_1 = model1.predict(test_input)\npred_2 = model2.predict(test_input)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fbab6433-16b9-474f-843e-5e9bf9b1a138","_cell_guid":"4a4faf05-b848-469d-9a74-1c65911f37a7","trusted":true},"cell_type":"code","source":"pred_tot1 = pred_1\n\npred_idx_list=[]\nfor pred in pred_tot1:\n    pred_idx_list.append(np.argmax(pred))\n    \npred_idx_arr = np.array(pred_idx_list, dtype=np.float32)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b7032f2f-58c4-455f-a658-eaf5f18fd1c4","_cell_guid":"b7ab9f6b-ab71-4aa3-a2ab-8f2c0c995a7f","trusted":true},"cell_type":"code","source":"print(accuracy_score(test_target, pred_idx_arr))\nprint(confusion_matrix(test_target, pred_idx_arr))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"528d85a5-908c-4455-9b9e-3f461c112e1d","_cell_guid":"6165c6d7-fce9-48ad-bb56-fb4800108085","trusted":true},"cell_type":"code","source":"pred_tot2 = pred_2\n\npred_idx_list=[]\nfor pred in pred_tot2:\n    pred_idx_list.append(np.argmax(pred))\n    \npred_idx_arr = np.array(pred_idx_list, dtype=np.float32)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2a79dda5-2555-4a9c-b2af-6b51b877383c","_cell_guid":"f623ecad-9074-40e1-bace-2762048f0a4d","trusted":true},"cell_type":"code","source":"print(accuracy_score(test_target, pred_idx_arr))\nprint(confusion_matrix(test_target, pred_idx_arr))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"04762c7d-b874-439d-9f98-a2c5117e1e99","_cell_guid":"7ee1c80f-3a97-4997-9ec5-815e4c59ccf8","trusted":true},"cell_type":"code","source":"pred_tot = (pred_1+pred_2)/2\n\npred_idx_list=[]\nfor pred in pred_tot:\n    pred_idx_list.append(np.argmax(pred))\n    \npred_idx_arr = np.array(pred_idx_list, dtype=np.float32)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"db50d4f9-27a2-4bd9-ab23-0444384c4149","_cell_guid":"c57aec50-74b5-4d6a-8ce7-da4bc25538f2","trusted":true},"cell_type":"code","source":"print(accuracy_score(test_target, pred_idx_arr))\nprint(confusion_matrix(test_target, pred_idx_arr))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import the SMOTETomek.\nfrom imblearn.combine import SMOTETomek\n\n# create the  object with the desired sampling strategy.\nsmotemek = SMOTETomek(sampling_strategy='auto')\n\n# fit the object to our training data.\nx_train_smt, y_train_smt = smotemek.fit_sample(train_x, train_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Return difference array\ndef return_diff_array_table(array, dur):\n  for idx in range(array.shape[1]-dur):\n    before_col = array[:,idx]\n    after_col = array[:,idx+dur]\n    new_col = ((after_col - before_col)+1)/2\n    new_col = new_col.reshape(-1,1)\n    if idx == 0:\n      new_table = new_col\n    else :\n      new_table = np.concatenate((new_table, new_col), axis=1)\n#For concat add zero padding\n  padding_array = np.zeros(shape=(array.shape[0],dur))\n  new_table = np.concatenate((padding_array, new_table), axis=1)\n  return new_table\n#Concat\ndef return_merge_diff_table(df, diff_dur):\n  fin_table = df.reshape(-1,187,1,1)\n  for dur in diff_dur:\n    temp_table = return_diff_array_table(df, dur)\n    fin_table = np.concatenate((fin_table, temp_table.reshape(-1,187,1,1)), axis=2)\n  return fin_table\n\n#Use \"stratify\" option\nx_train, x_val, y_train, y_val = train_test_split(x_train_smt, y_train_smt, test_size=0.15, stratify=y_train_smt)\n\n#Add Data\nx_train = return_merge_diff_table(df=x_train, diff_dur=[1])\nx_val = return_merge_diff_table(df=x_val, diff_dur=[1])\n\nprint(x_train.shape, y_train.shape, x_val.shape, y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#For see a model's result\ndef return_result(model, x_train, x_test, y_train, y_test):\n    y_pred = model.predict(x_test)\n    train_pred = model.predict(x_train)\n    pred_list=[]\n    for x in y_pred:\n        pred_list.append(np.argmax(x))\n    train_pred_list=[]\n    for x in train_pred:\n        train_pred_list.append(np.argmax(x))\n    test_mat = confusion_matrix(y_test, pred_list)\n    train_mat = confusion_matrix(y_train, train_pred_list)\n    print(\"In train\")\n    print(accuracy_score(y_train, train_pred_list))\n    print(train_mat)\n    print(\"In test\")\n    print(accuracy_score(y_test, pred_list))\n    print(test_mat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"  def return_model3():  \n    input_tens = tf.keras.Input(shape=(187,2,1))\n    x = tf.keras.layers.Conv2D(256, kernel_size=(10,2), strides=(5,1),padding='valid')(input_tens)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.Dropout(rate=0.5)(x)\n    x = tf.keras.layers.Conv2D(512, kernel_size=(5,1), padding='valid')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.Dropout(rate=0.5)(x)\n    x = tf.keras.layers.Conv2D(512, kernel_size=(5,1), padding='valid')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.Dropout(rate=0.5)(x)\n    x = tf.keras.layers.Conv2D(128, kernel_size=(5,1), padding='valid')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.Dropout(rate=0.5)(x)\n    x = tf.keras.layers.Conv2D(64, kernel_size=(5,1), padding='valid')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dense(2, activation=\"softmax\")(x)\n    model = tf.keras.Model(inputs=input_tens, outputs=x)\n    model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n    print(model.summary())\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model3 = return_model3()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#For saving best model\ncheckpoint_path_best3 = \"./best_acc_v03.ckpt\"\ncp_callback_best3 = tf.keras.callbacks.ModelCheckpoint(checkpoint_path_best3,monitor=\"val_accuracy\",save_weights_only=True,verbose=1,save_best_only=True)\n\nhist3=model3.fit(x_train,y_train, epochs=200, batch_size=128, validation_data=(x_val,y_val),callbacks=[cp_callback_best3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"return_result(model3, x_train=x_train, x_test=x_val, y_train=y_train, y_test=y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df3 = pd.DataFrame(hist3.history)\ndf3.to_csv(\"train3.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_metrics(history, metric_list=['loss', 'auc'],figsize=(12, 10)):\n    with plt.style.context(\"seaborn-poster\"):\n        fig, axes = plt.subplots(len(metric_list), 1, sharex='col', figsize=(22, len(metric_list)*4))\n        axes = axes.flatten()\n        plt.yticks(fontweight='bold')\n        \n        \n        for index, metric in enumerate(metric_list):\n            axes[index].plot(history['%s' % metric], marker='o', label='Train %s' % metric)\n            axes[index].plot(history['val_%s' % metric], marker='o', label='Validation %s' % metric)\n            axes[index].legend(loc='best')\n            axes[index].set_title(metric,fontsize=18,fontweight='bold')\n            plt.yticks(fontweight='bold')\n\n        plt.xlabel('Epochs',fontsize=18,fontweight='bold')\n        plt.xticks(fontweight='bold')\n        plt.yticks(fontweight='bold')\n        sns.despine()\n        #plt.savefig(f\"full_history.svg\",format=\"svg\",bbox_inches='tight', pad_inches=0.2)\n        #plt.savefig(f\"full_history.png\", format=\"png\",bbox_inches='tight', pad_inches=0.2) \n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_metrics(df3, metric_list=['loss', 'accuracy'], figsize=(12, 10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot(s):\n\n    with plt.style.context(s):\n        print(s)\n        fig, ax = plt.subplots(figsize=(18, 5))\n        plt.plot(df3[\"accuracy\"],  marker='o', label=\"Training Acc\")\n        plt.plot(df3[\"val_accuracy\"],  marker='o', label=\"Validation Acc\")\n        plt.xticks(np.arange(0, 201, 20), fontweight='bold')\n        plt.yticks(fontweight='bold')\n        plt.ylabel('Accuracy', fontsize=14,fontweight='bold' )\n        plt.xlabel('epochs', fontsize=14, fontweight='bold')\n        plt.title(\"Accuracy History using SMOTE+Tomek+CNN\",fontweight='bold')\n        plt.legend()\n        #plt.savefig(f\"auc_history.svg\",format=\"svg\",bbox_inches='tight', pad_inches=0.2)\n        #plt.savefig(f\"auc_history.png\", format=\"png\",bbox_inches='tight', pad_inches=0.2) \n        plt.show()\n        print()\n        \nfor s in plt.style.available:\n    plot(s);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with plt.style.context(\"seaborn-poster\"):\n    fig, ax = plt.subplots(figsize=(12, 5))\n    plt.plot(df3[\"loss\"],  marker='o', label=\"Training Loss\")\n    plt.plot(df3[\"val_loss\"],  marker='o', label=\"Validation Loss\")\n    plt.xticks(np.arange(0, 201, 20),fontweight='bold')\n    plt.yticks(fontweight='bold')\n    plt.ylabel('loss', fontsize=18, fontweight='bold')\n    plt.xlabel('epochs', fontsize=18, fontweight='bold')\n    plt.title(\"Loss history using SMOTE+Tomek+CNN\", fontweight='bold')\n    plt.legend()\n    #plt.savefig(f\"loss_history.svg\",format=\"svg\",bbox_inches='tight', pad_inches=0.2)\n    #plt.savefig(f\"loss_history.png\", format=\"png\",bbox_inches='tight', pad_inches=0.2) \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with plt.style.context(\"seaborn-poster\"):\n    fig, ax = plt.subplots(figsize=(12, 5))\n    plt.plot(df3[\"accuracy\"],  marker='o', label=\"Training Acc\")\n    plt.plot(df3[\"val_accuracy\"],  marker='o', label=\"Validation Acc\")\n    plt.xticks(np.arange(0, 201, 20),fontweight='bold')\n    plt.yticks(fontweight='bold')\n    plt.ylabel('Accuracy', fontsize=18, fontweight='bold')\n    plt.xlabel('epochs', fontsize=18, fontweight='bold')\n    plt.title(\"Accuracy history using SMOTE+Tomek+CNN\", fontweight='bold')\n    plt.legend()\n    #plt.savefig(f\"loss_history.svg\",format=\"svg\",bbox_inches='tight', pad_inches=0.2)\n    #plt.savefig(f\"loss_history.png\", format=\"png\",bbox_inches='tight', pad_inches=0.2) \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model3.load_weights(checkpoint_path_best3)\n#model4.load_weights(checkpoint_path_best2)\n\n#return_result(model1, x_train=x_train, x_test=x_val, y_train=y_train, y_test=y_val)\n#return_result(model4, x_train=x_train, x_test=x_val, y_train=y_train, y_test=y_val)\n\ntest_input = np.array(test_df[test_df.columns[0:-1]], dtype=np.float32)\ntest_target = np.array(test_df[test_df.columns[-1:]], dtype=np.float32)\n\ntest_input = return_merge_diff_table(df=test_input, diff_dur=[1])\n\nprint(test_input.shape, test_target.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_3 = model3.predict(test_input)\npred_tot3 = pred_3\n\npred_idx_list=[]\nfor pred in pred_tot3:\n    pred_idx_list.append(np.argmax(pred))\n    \npred_idx_arr = np.array(pred_idx_list, dtype=np.float32)\nprint(accuracy_score(test_target, pred_idx_arr))\nprint(confusion_matrix(test_target, pred_idx_arr))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def return_model4():\n    input_tens = tf.keras.Input(shape=(187,2,1))\n    x = tf.keras.layers.Conv2D(256, kernel_size=(10,2), strides=(5,1),padding='valid')(input_tens)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.Dropout(rate=0.5)(x)\n    x = tf.keras.layers.Conv2D(512, kernel_size=(5,1), padding='valid')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.Dropout(rate=0.5)(x)\n    x = tf.keras.layers.Conv2D(512, kernel_size=(5,1), padding='valid')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.Dropout(rate=0.5)(x)\n    x = tf.keras.layers.Reshape((x.shape[1], x.shape[3]))(x)\n    x = tf.keras.layers.LSTM(64)(x)\n    x = tf.keras.layers.Dense(2, activation=\"softmax\")(x)\n    model = tf.keras.Model(inputs=input_tens, outputs=x)\n    model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n    print(model.summary())\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model4=return_model4()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#For saving best model\ncheckpoint_path_best4 = \"./best_acc_v04.ckpt\"\ncp_callback_best4 = tf.keras.callbacks.ModelCheckpoint(checkpoint_path_best4, monitor=\"val_accuracy\", save_weights_only=True, verbose=1, save_best_only=True)\n\nhist4=model4.fit(x_train,y_train, epochs=200, batch_size=128, validation_data=(x_val,y_val), callbacks=[cp_callback_best4])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df4 = pd.DataFrame(hist4.history)\ndf4.to_csv(\"train_4.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot(s):\n\n    with plt.style.context(s):\n        print(s)\n        fig, ax = plt.subplots(figsize=(18, 5))\n        plt.plot(df3[\"accuracy\"],  marker='o', label=\"Training Acc\")\n        plt.plot(df3[\"val_accuracy\"],  marker='o', label=\"Validation Acc\")\n        plt.xticks(np.arange(0, 201, 20), fontweight='bold')\n        plt.yticks(fontweight='bold')\n        plt.ylabel('Accuracy', fontsize=14,fontweight='bold' )\n        plt.xlabel('epochs', fontsize=14, fontweight='bold')\n        plt.title(\"Accuracy History using SMOTE+Tomek+CNN+LSTM\",fontweight='bold')\n        plt.legend()\n        #plt.savefig(f\"auc_history.svg\",format=\"svg\",bbox_inches='tight', pad_inches=0.2)\n        #plt.savefig(f\"auc_history.png\", format=\"png\",bbox_inches='tight', pad_inches=0.2) \n        plt.show()\n        print()\n        \nfor s in plt.style.available:\n    plot(s);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with plt.style.context(\"seaborn-poster\"):\n    fig, ax = plt.subplots(figsize=(12, 5))\n    plt.plot(df4[\"loss\"],  marker='o', label=\"Training Loss\")\n    plt.plot(df4[\"val_loss\"],  marker='o', label=\"Validation Loss\")\n    plt.xticks(np.arange(0, 201, 20),fontweight='bold')\n    plt.yticks(fontweight='bold')\n    plt.ylabel('loss', fontsize=18, fontweight='bold')\n    plt.xlabel('epochs', fontsize=18, fontweight='bold')\n    plt.title(\"Loss history using SMOTE+Tomek+CNN+LSTM\", fontweight='bold')\n    plt.legend()\n    #plt.savefig(f\"loss_history.svg\",format=\"svg\",bbox_inches='tight', pad_inches=0.2)\n    #plt.savefig(f\"loss_history.png\", format=\"png\",bbox_inches='tight', pad_inches=0.2) \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with plt.style.context(\"seaborn-poster\"):\n    fig, ax = plt.subplots(figsize=(12, 5))\n    plt.plot(df4[\"accuracy\"],  marker='o', label=\"Training Acc\")\n    plt.plot(df4[\"val_accuracy\"],  marker='o', label=\"Validation Acc\")\n    plt.xticks(np.arange(0, 201, 20),fontweight='bold')\n    plt.yticks(fontweight='bold')\n    plt.ylabel('Accuracy', fontsize=18, fontweight='bold')\n    plt.xlabel('epochs', fontsize=18, fontweight='bold')\n    plt.title(\"Accuracy history using SMOTE+Tomek+CNN+LSTM\", fontweight='bold')\n    plt.legend()\n    #plt.savefig(f\"loss_history.svg\",format=\"svg\",bbox_inches='tight', pad_inches=0.2)\n    #plt.savefig(f\"loss_history.png\", format=\"png\",bbox_inches='tight', pad_inches=0.2) \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_metrics(history, metric_list=['loss', 'auc'],figsize=(12, 10)):\n    with plt.style.context(\"seaborn-poster\"):\n        fig, axes = plt.subplots(len(metric_list), 1, sharex='col', figsize=(22, len(metric_list)*4))\n        axes = axes.flatten()\n        \n        \n        for index, metric in enumerate(metric_list):\n            axes[index].plot(history['%s' % metric], marker='o', label='Train %s' % metric)\n            axes[index].plot(history['val_%s' % metric], marker='o', label='Validation %s' % metric)\n            axes[index].legend(loc='best')\n            axes[index].set_title(metric,fontsize=18,fontweight='bold')\n            plt.yticks(fontweight='bold')\n\n        plt.xlabel('Epochs',fontsize=18,fontweight='bold')\n        plt.xticks(fontweight='bold')\n        \n        sns.despine()\n        #plt.savefig(f\"full_history.svg\",format=\"svg\",bbox_inches='tight', pad_inches=0.2)\n        #plt.savefig(f\"full_history.png\", format=\"png\",bbox_inches='tight', pad_inches=0.2) \n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_metrics(df4, metric_list=['loss', 'accuracy'], figsize=(12, 10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"return_result(model4, x_train=x_train, x_test=x_val, y_train=y_train, y_test=y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model4.load_weights(checkpoint_path_best4)\n#model4.load_weights(checkpoint_path_best2)\n\n#return_result(model1, x_train=x_train, x_test=x_val, y_train=y_train, y_test=y_val)\n#return_result(model4, x_train=x_train, x_test=x_val, y_train=y_train, y_test=y_val)\n\ntest_input = np.array(test_df[test_df.columns[0:-1]], dtype=np.float32)\ntest_target = np.array(test_df[test_df.columns[-1:]], dtype=np.float32)\n\ntest_input = return_merge_diff_table(df=test_input, diff_dur=[1])\n\nprint(test_input.shape, test_target.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_4 = model4.predict(test_input)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_tot4 = pred_4\n\npred_idx_list=[]\nfor pred in pred_tot4:\n    pred_idx_list.append(np.argmax(pred))\n    \npred_idx_arr = np.array(pred_idx_list, dtype=np.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(accuracy_score(test_target, pred_idx_arr))\nprint(confusion_matrix(test_target, pred_idx_arr))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_tot = (pred_3+pred_4)/2\n\npred_idx_list=[]\nfor pred in pred_tot:\n    pred_idx_list.append(np.argmax(pred))\n    \npred_idx_arr = np.array(pred_idx_list, dtype=np.float32)\nprint(accuracy_score(test_target, pred_idx_arr))\nprint(confusion_matrix(test_target, pred_idx_arr))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_tot_f = (pred_1+pred_2+pred_3+pred_4)/4\n\npred_idx_list=[]\nfor pred in pred_tot_f:\n    pred_idx_list.append(np.argmax(pred))\n    \npred_idx_arr = np.array(pred_idx_list, dtype=np.float32)\nprint(accuracy_score(test_target, pred_idx_arr))\nprint(confusion_matrix(test_target, pred_idx_arr))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}