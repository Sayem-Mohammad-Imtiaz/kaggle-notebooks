{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport sklearn\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport keras\nimport theano\nimport tensorflow\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder,OneHotEncoder\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom sklearn.metrics import confusion_matrix ,classification_report\nfrom keras.wrappers.scikit_learn import KerasClassifier\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read Data\ncust = pd.read_csv(\"../input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explore Dataset\nprint('Dimensions:{}'.format(cust.shape))\nprint(cust.dtypes)\ncust.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Preprocessing**"},{"metadata":{},"cell_type":"markdown","source":"\"Total Charges\" feature is expected to be numeric but it\nis saved as  an 'object'. Searching for null or empty values."},{"metadata":{"trusted":true},"cell_type":"code","source":"cust.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\"Total Charges\" Feature has zero null values. Inspect if there are observations with blank values."},{"metadata":{"trusted":true},"cell_type":"code","source":"null_values=cust[cust['TotalCharges'] == ' ']\nnull_values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 'blank' values in \"Total charges\" . There are 11 observations in total. The amount of observations is small,deleting them will not cause problems in our analysis."},{"metadata":{"trusted":true},"cell_type":"code","source":"cust.drop(cust[(cust['TotalCharges'] == ' ')].index,inplace=True)\nnull_values=cust[cust['TotalCharges'] == ' ']\nnull_values\ncust['TotalCharges']=cust['TotalCharges'].astype('float64')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, lets do some changes into the raw data set:\n\n* drop CustomerID feature \n* encode categorical features \n* split the dataset into train and test set\n* Scale all features to have the same min and max values.\n\nApplying these steps will help the classifier perform better."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove Columns Customerid.\n\ncust.drop(['customerID'],axis=1,inplace=True)\n\n\n# Encode target feature as \"Yes\"=1 and \"No\"=0\n\ncust['Churn'].replace({\"Yes\":1,\"No\":0},inplace=True)\n\n#Encoding categorical data\nd=cust.select_dtypes(include=['object'])\nd=pd.get_dummies(d,prefix_sep='_',drop_first=True)\ncust=cust.iloc[:,[1,4,17,18,19]]\ncust=pd.concat([cust,d],axis=1)\ncust['TotalCharges'].astype('float64')\n\n\n\n# Splitting the dataset into Training and Test Set\n\nX=cust.drop(['Churn'],axis=1)\ny=cust['Churn']\n\nX_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.3,random_state=80)\n\nprint('Dimensions of the training feature table: {}'.format(X_train.shape))\nprint('Dimensions of the training target vector: {}'.format(y_train.shape))\nprint('Dimensions of the test feature table: {}'.format(X_test.shape))\nprint('Dimensions of the test target vector: {}'.format(y_test.shape))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Feature Scaling\nscal=StandardScaler()\nX_train=scal.fit_transform(X_train)\nX_test=scal.fit_transform(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****ทดลองปรับแต่ง****"},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = Sequential()\n\nclassifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = 30))\nclassifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu'))\nclassifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'tanh'))\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n                   \nclassifier.fit(X_train, y_train, batch_size = 10, nb_epoch = 100)\n\ny_pred = classifier.predict(X_test)\ny_pred = (y_pred > 0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"\\nAccuracy ========== >>>  81.06%\\n\")\n\n#classification report\nprint (\"\\nClassification Report\\n\")\nprint (classification_report(y_test, y_pred))\n\nconf_arr =confusion_matrix(y_test, y_pred)\nnorm_conf = []\nfor i in conf_arr:\n    a = 0\n    tmp_arr = []\n    a = sum(i, 0)\n    for j in i:\n        tmp_arr.append(float(j)/float(a))\n    norm_conf.append(tmp_arr)\n\nfig = plt.figure()\nplt.clf()\nax = fig.add_subplot(1,2,1)\nax.set_aspect(1)\nres = ax.imshow(np.array(norm_conf), cmap=plt.cm.jet, \n                interpolation='nearest')\n\nwidth, height = conf_arr.shape\n\nfor x in range(width):\n    for y in range(height):\n        ax.annotate(str(conf_arr[x][y]), xy=(y, x), \n                    horizontalalignment='center',\n                    verticalalignment='center')\n## confusion matrix\nplt.title(\"Confusion Matrix\")\nplt.xticks(range(width), ['positive','negative'])\nplt.yticks(range(height), ['positive','negative'])\nplt.show()\n\n\nfrom sklearn.metrics import roc_curve, auc\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nplt.title('Receiver Operating Characteristic')\nplt.plot(false_positive_rate, true_positive_rate, 'b',label='AUC = %0.2f'% roc_auc)\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')\nplt.xlim([-0.1,1.2])\nplt.ylim([-0.1,1.2])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\n\n\n##gini coefficient\nGini_coefficient=2*roc_auc - 1\nprint(\"Gini_coefficient from the ROC curve is \\n\",Gini_coefficient)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Artificial Neural Networks**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# First Neural Network\n\ndef nn_classifier():\n    nn = Sequential()\n    nn.add(Dense(output_dim=16,init='uniform',activation='relu',input_dim=30)) # Initial Input and First hidden Layer\n    nn.add(Dropout(p = 0.1)) #Dropout Reg\n    nn.add(Dense(output_dim=16,init='uniform',activation='relu')) # Second hidden Layer\n    nn.add(Dropout(p = 0.1)) #Dropout Reg\n    nn.add(Dense(output_dim=1,init='uniform',activation='sigmoid')) # Output Layer\n    nn.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n    return nn\n\nnn = KerasClassifier(build_fn= nn_classifier,batch_size= 5 ,nb_epoch=1000)\n\nacc = cross_val_score(estimator  = nn, X = X_train, y = y_train, cv = 10, n_jobs = -1)\nprint(\"Mean Accuracy : {}\".format(acc.mean()))\nprint(\"Variance : {}\".format(acc.std()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****Tuning Neural Network parameters****"},{"metadata":{"trusted":true},"cell_type":"code","source":"def nn_classifier(optimizer):\n    nn = Sequential()\n    nn.add(Dense(output_dim=16,init='uniform',activation='relu',input_dim=30)) # Initial Input and First hidden Layer\n    nn.add(Dropout(p = 0.1)) #Dropout Reg\n    nn.add(Dense(output_dim=16,init='uniform',activation='relu')) # Second hidden Layer\n    nn.add(Dropout(p = 0.1)) #Dropout Reg\n    nn.add(Dense(output_dim=1,init='uniform',activation='sigmoid')) # Output Layer\n    nn.compile(optimizer=optimizer,loss='binary_crossentropy',metrics=['accuracy'])\n    return nn\nnn = KerasClassifier(build_fn= nn_classifier)\nparameters = {'batch_size' : [20, 33 ], \n              'nb_epoch' : [100, 300],\n              'optimizer': ['adam','rmsprop']}\ngs = GridSearchCV(estimator = nn,\n                 param_grid = parameters,\n                 scoring = 'accuracy',\n                 cv = 10)\n\n\ngs = gs.fit( X_train, y_train)\nopt_param = gs.best_params_\nopt_acc = gs.best_score_\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Optimal Parameters : {}\".format(opt_param))\nprint(\"Optimal Accuracy : {}\".format(opt_acc))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}