{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns # visualization\nimport matplotlib.pyplot as plt \n\n!pip install pandas-bokeh\nimport pandas_bokeh\npandas_bokeh.output_notebook()\npd.set_option('plotting.backend', 'pandas_bokeh')\nfrom bokeh.models import ColumnDataSource\nfrom bokeh.models.widgets import DataTable, TableColumn\n\nfrom sklearn.preprocessing import OneHotEncoder \nfrom sklearn import preprocessing\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\n\nfrom sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, VotingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import svm\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, roc_curve, auc, plot_roc_curve\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Table of Contents\n* [Analyzing the Data](#analyze)\n* [Visualization](#viz)\n    - [Correlation Between Variables](#corr)\n    - [Pandas Bokeh](#pandas_bokeh)\n* [Data Preperation](#prep)\n    - [One Hot Encoding](#1hot)\n    - [Standardization](#standard)\n    - [Feature Selection](#feature_select)\n* [Modeling](#model)\n    - [Building the models](#bob_the_builder)\n    - [Model Selection](#americas_next_top_model)\n* [Conclusion](#section-three)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"analyze\"></a>\n# Analyzing the Data\nFirst taking a look at some rows of the data and looking at the variable terms:\n1. age - age in years\n\n2. sex - sex <br>\n    1 = male <br>\n    0 = female\n\n3. cp - chest pain type <br>\n    0 = typical angina <br>\n    1 = atypical angina <br>\n    2 = non-anginal pain <br>\n    3 = asymptomatic\n\n4. trestbps - resting blood pressure (in mm Hg on admission to the hospital)\n\n5. chol - serum cholestoral in mg/dl\n\n6. fbs - fasting blood sugar > 120 mg/dl  <br>\n    1 = true <br>\n    0 = false\n\n7. restecg - resting electrocardiographic results  <br>\n    0 = normal <br>\n    1 = having ST-T <br>\n    2 = hypertrophy\n\n8. thalach - maximum heart rate achieved\n\n9. exng - exercise induced angina <br>\n    1 = yes <br>\n    0 = no\n\n10. oldpeak - ST depression induced by exercise relative to rest\n\n11. slp - the slope of the peak exercise ST segment <br>\n    1 = upsloping<br>\n    2 = flat<br>\n    3 = downsloping\n\n12. caa - number of major vessels (0-3) colored by flourosopy\n\n13. thall <br>\n    1 = fixed defect<br>\n    2 = normal<br>\n    3 = reversable defect\n    \n14. output - the predicted attribute - diagnosis of heart disease (angiographic disease status) <br>\n    Value 0 = < diameter narrowing<br>\n    Value 1 = > 50% diameter narrowing","metadata":{}},{"cell_type":"code","source":"heart = pd.read_csv('../input/heart-attack-analysis-prediction-dataset/heart.csv')\ndisplay(heart.head(3))\ndisplay(heart.describe())","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Slight bias by having more datapoints with a heart attack diagnosis than not.","metadata":{}},{"cell_type":"code","source":"heart[['age','output']].groupby(['output']).count().rename(columns = {'age':'count of output values'})","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Less females in the dataset, and they are significantly more likely to have a heart attack diagnosis.","metadata":{}},{"cell_type":"code","source":"heart[[\"sex\", \"output\"]].groupby(['sex'], as_index=False).agg(['count', 'mean'])","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Correlation between the output and the independent variables:","metadata":{}},{"cell_type":"code","source":"heart.corr()[['output']].multiply(100).T.applymap('{:.2f}%'.format)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"viz\"></a>\n# Visualization","metadata":{}},{"cell_type":"markdown","source":"<a id=\"corr\"></a>\n## Correlation Between Variables","metadata":{}},{"cell_type":"code","source":"f = plt.figure(figsize=(12, 12))\nplt.matshow(heart.corr(), fignum=f.number)\nplt.xticks(range(heart.select_dtypes(['number']).shape[1]), heart.select_dtypes(['number']).columns, fontsize=14, rotation=45)\nplt.yticks(range(heart.select_dtypes(['number']).shape[1]), heart.select_dtypes(['number']).columns, fontsize=14)\ncb = plt.colorbar()\ncb.ax.tick_params(labelsize=14)\nplt.title('Correlation Matrix', fontsize=16);","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"https://pandas.pydata.org/pandas-docs/stable/user_guide/style.html","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"corr = heart.corr()\ncorr.style.background_gradient(cmap='coolwarm').set_precision(2)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the heatmaps we can see that there is some multicollinearity between the variables, i.e. correlation between the independent variables. It is worth making note of so we can handle it with regularization in our models below. ","metadata":{}},{"cell_type":"code","source":"sns.pairplot(heart, hue=\"output\")","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Pairplot shows a lot of information that it can be hard to process it all. Something that stood out to me is that instead of missing data we have 0's in some rows where that isn't valid for the column such as 'slp' and 'thall'. ","metadata":{}},{"cell_type":"markdown","source":"<a id=\"pandas_bokeh\"></a>\n## Pandas Bokeh\nI'm a big fan of interactive plots so I love bokeh. To make things easier, there is a pandas-bokeh library available. See the documention here: https://github.com/PatrikHlobil/Pandas-Bokeh","metadata":{}},{"cell_type":"code","source":"def thall_rename(thall):\n    if thall==0:\n        return 'Unknown'\n    if thall==1:\n        return 'Fixed Defect'\n    if thall==2:\n        return 'Normal'\n    return 'Reversable Defect'\n\ndef output_rename(output):\n    if output==0:\n        return '0 - Non-critical Patient'\n    else:\n        return '1 - Heart Attack Diagnosis'\n\n###############\n# Data Prep \n###############\ndf = heart.copy()\ndf.thall = df.thall.apply(lambda x: thall_rename(x))\ndf.output = df.output.apply(lambda x: output_rename(x))\n\ndf = df.filter(['thalachh','age','thall','output'])#.groupby(['thall']).count()#.agg(['mean','count'])\n\n###############\n# Making the Plot \n###############\ndata_table = DataTable(\n    columns=[TableColumn(field=Ci, title=Ci) for Ci in df.columns],\n    source=ColumnDataSource(df),\n    width=300,\n    height=300,\n)\n\np_scatter = df.plot_bokeh.scatter(\n    x=\"age\",\n    y=\"thalachh\",\n    category=\"output\",\n    title=\"Correlation between Age/Thalachh values to Heart Attack Diagnosis\",\n    show_figure=False,\n)\npandas_bokeh.plot_grid([[data_table, p_scatter]], plot_width=350, plot_height=450)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = heart.copy()\ndf = df.filter(['thall','output'])\ndf.thall = df.thall.apply(lambda x: thall_rename(x))\ndf['1 - Heart Attack Diagnosis'] = df.output #df[df['output'] == 1].filter('output')\ndf = df.rename(columns = {'output': '0 - Non-critical Patient'})\ndf[\"0 - Non-critical Patient\"] = df[\"0 - Non-critical Patient\"].replace({0:1, 1:0})\ndf = df.groupby('thall').count()\n\n\np_stacked_bar = df.plot_bokeh.bar(\n    ylabel=\"Price per Unit [â‚¬]\",\n    title=\"Fruit prices per Year\",\n    stacked=True,\n    alpha=0.6)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"prep\"></a>\n# Data Preparation for Modeling\n<a id=\"1hot\"></a>\n## One Hot Encoding\nSince there are a lot of predictors that have numeric values, but are truly categories (e.g. Female [0] vs Male [1]), I'm going to use one hot encoding so that the machine learning algortithms don't try to use the order of the numbers as an attribute of significance (i.e. treat a higher number as more significant as a lower number). \n\nhttps://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html","metadata":{}},{"cell_type":"markdown","source":"Variables that are categories: 'sex', 'cp', 'fbs', 'restecg', 'exng', 'slp', 'caa', 'thall'","metadata":{}},{"cell_type":"code","source":"heart_categories = heart[['sex', 'cp', 'fbs', 'restecg', 'exng', 'slp', 'caa', 'thall']]\n\nenc = OneHotEncoder()\nenc.fit(heart_categories)\nonehotlabels = enc.transform(heart_categories).toarray()\n\n#enc.inverse_transform(onehotlabels) # To convert them back to the original shape\n\ncolumns = enc.get_feature_names(['sex', 'cp', 'fbs', 'restecg', 'exng', 'slp', 'caa', 'thall'])\nheart_categories = pd.DataFrame(onehotlabels, columns=columns)\n\nheart = heart.drop(['sex', 'cp', 'fbs', 'restecg', 'exng', 'slp', 'caa', 'thall'], axis=1)\nheart = heart.join(heart_categories)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"heart.head()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"feature_select\"></a>\n## Feature Selection","metadata":{}},{"cell_type":"markdown","source":"There is one duplicate row so I removed that:","metadata":{}},{"cell_type":"code","source":"#display(heart[heart.duplicated()])\nheart = heart.drop_duplicates()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Keeping the k=23 best predictors to reduce noise.","metadata":{}},{"cell_type":"code","source":"y = np.ravel(heart[['output']])\nX = heart.loc[:, heart.columns != 'output']\nX = SelectKBest(chi2, k=23).fit_transform(X, y)\n\ndisplay(heart.corr()[['output']].multiply(100).abs().sort_values(by = ['output']).applymap('{:.2f}%'.format).T)\n\ntemp = pd.DataFrame(X).merge(pd.DataFrame(y), left_index=True, right_index=True)\ndisplay(temp.corr()[['0_y']].multiply(100).abs().sort_values(by = ['0_y']).applymap('{:.2f}%'.format).T)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"split\"></a>\n## Splitting the data\nGoing with the classic kfold cross validation to split the data.\n\nKnowing nothing about the data collection process, it is not really safe to assume i.i.d. though so a future test could be using special techniques for grouped data - https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators-for-grouped-data","metadata":{}},{"cell_type":"markdown","source":"<a id=\"standardize\"></a>\n## Standarizing the Data\nUsing sklearn's StandardScaler to scale the data <br>\nhttps://scikit-learn.org/stable/modules/preprocessing.html","metadata":{}},{"cell_type":"code","source":"scaler = preprocessing.StandardScaler().fit(X)\nX = scaler.transform(X)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"model\"></a>\n# Modeling\n<a id=\"bob_the_builder\"></a>\n## Building the models\n\nI tried several combinations of the following sklearn models: <br>\n    <li>RandomForestClassifier\n    <li>LogisticRegression\n    <li>SVC\n    <li>GradientBoostingClassifier","metadata":{}},{"cell_type":"code","source":"rfc1 = RandomForestClassifier()\nrfc2 = RandomForestClassifier(n_estimators=500)\nrfc3 = RandomForestClassifier(n_estimators=1000)\nrfc4 = RandomForestClassifier(criterion='entropy')\nrfc5 = RandomForestClassifier(n_estimators=500, criterion='entropy')\n\nlgc1 = LogisticRegression()\nlgc2 = LogisticRegression(penalty='none')\nlgc3 = LogisticRegression(solver='liblinear')\nlgc4 = LogisticRegression(solver='newton-cg')\nlgc5 = LogisticRegression(solver='saga', max_iter=500)\nlgc6 = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=.1, max_iter=500)\nlgc7 = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=.5, max_iter=500)\nlgc8 = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=.9, max_iter=500)\n\nsvm1 = svm.SVC()\nsvm2 = svm.SVC(C=.1)\nsvm3 = svm.SVC(C=.5)\nsvm4 = svm.SVC(C=2)\nsvm5 = svm.SVC(kernel = 'linear')\nsvm6 = svm.SVC(kernel = 'poly')\nsvm7 = svm.SVC(kernel = 'sigmoid')\n\ngbc1 = GradientBoostingClassifier()\ngbc2 = GradientBoostingClassifier(learning_rate = 0.05, max_depth=2, n_estimators=50)\ngbc3 = GradientBoostingClassifier(learning_rate = 0.05, max_depth=2, n_estimators=60)\ngbc4 = GradientBoostingClassifier(loss = 'exponential')\ngbc5 = GradientBoostingClassifier(loss = 'exponential', learning_rate = .05, max_depth=2, n_estimators = 50)\ngbc6 = GradientBoostingClassifier(loss = 'exponential', learning_rate = .05, max_depth=2, n_estimators = 60)\n\nmodels = [rfc1, rfc2, rfc3, rfc4, rfc5,\n          lgc1, lgc2, lgc3, lgc4, lgc5, lgc6, lgc7, lgc8,\n          svm1, svm2, svm3, svm4, svm5, svm6, svm7,\n          gbc1, gbc2, gbc3, gbc4, gbc5, gbc6]","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"americas_next_top_model\"></a>\n## Model Selection\nThere are _**a lot**_ of ways to measure how well a model is performing. I'm going to focus on the following:\n<li>Accuracy = # of Correct Predictions / Total Predictions <br>\n<li>Sensitivity (True Positive Rate) = TP / (FN + TP)  <br>\n<li>Specificity (True Negative Rate) = TN / (FP + TN) <br>\n<li>F1 Score = 2 * ( 1 / ((1/precision) + (1/recall)) )  <br>\n    \n<br>\nI used KFold cross validation with 5 folds to help account for the randomness in the data.\n   \n   ","metadata":{}},{"cell_type":"code","source":"'''\nCompare several models to see which performs the best.\n\nRETURNS:\n    model_df - pandas dataframe with the mean scores for each model.\n    \nPARAMETERS:\n    model_arr (REQ) - list of models to compare.\n    X_train (REQ) - independent variables for the training data\n    y_train (REQ) - dependent variables for the training data\n    num_of_folds (OPT) - number of times to perform KFold cross validation. Default is 5.\n'''\ndef compare_models(model_arr, X_train, y_train, num_of_folds = 5):\n    assert (model_arr is not None),\"Must provide a list of models to test.\"\n    assert (X_train is not None and isinstance(X_train,(np.ndarray))),\"Must provide X_train as a numpy array.\"\n    assert (y_train is not None and isinstance(y_train,(np.ndarray))),\"Must provide y_train as a numpy array.\"\n\n    kf = KFold(n_splits = num_of_folds)\n    accuracy_dict = {}\n    sensitivity_dict = {}\n    specificity_dict = {}\n    f1_dict = {}\n\n    for train_index, test_index in kf.split(X_train):\n\n        k_X_train = X_train[train_index]\n        k_y_train = y_train[train_index]\n        k_X_test = X_train[test_index]\n        k_y_test = y_train[test_index]\n\n        for model in model_arr:\n    \n            model.fit(k_X_train, k_y_train)\n            y_pred = model.predict(k_X_test)\n            accuracy = accuracy_score(y_pred, k_y_test)\n\n            cm = confusion_matrix(k_y_test, y_pred)\n            tn = cm[0][0]\n            fp = cm[0][1]\n            fn = cm[1][0]\n            tp = cm[1][1]\n            sensitivity = tp / (fn + tp)\n            specificity = tn / (fp + tn)\n            f1 = f1_score(k_y_test, y_pred)\n\n            try:\n                accuracy_dict[model] = np.append(accuracy_dict[model], accuracy)\n                sensitivity_dict[model] = np.append(sensitivity_dict[model], sensitivity)\n                specificity_dict[model] = np.append(specificity_dict[model], specificity)\n                f1_dict[model] = np.append(f1_dict[model], f1)\n            except KeyError:\n                accuracy_dict[model] = np.array(accuracy)\n                sensitivity_dict[model] = np.array(sensitivity)\n                specificity_dict[model] = np.array(specificity)\n                f1_dict[model] = np.array(f1)\n    \n    \n    # Compile the score dictionaries into a pandas dataframe.\n    \n    model_df = pd.DataFrame(columns = ['model', 'accuracy', 'sensitivity', 'specificity', 'f1'])\n    \n    for model in model_arr:\n        accuracy = accuracy_dict[model].mean() * 100\n        sensitivity = sensitivity_dict[model].mean() * 100\n        specificity = specificity_dict[model].mean() * 100\n        f1 = f1_dict[model].mean() * 100\n        \n        row = {'model' : model,\n               'accuracy' : accuracy,\n               'sensitivity' : sensitivity,\n               'specificity' : specificity,\n               'f1' : f1}\n                \n        model_df = model_df.append(row, ignore_index=True)\n    \n    return (model_df)\n\n\nmodel_df = compare_models(model_arr = models, X_train=X_train, y_train=y_train).sort_values('accuracy', ascending=False)\npd.set_option(\"precision\", 2)\ndisplay(model_df)\nmodel_df.describe()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plotting the ROC for the top 3 models:","metadata":{}},{"cell_type":"code","source":"model_list = model_df.model.tolist()\ntop_x_models = 3\n\nfor i in range(top_x_models):\n    model = model_list[i]\n    plot_roc_curve(model, X_test, y_test)  \n    plt.show() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally, lets combine the best models and have them vote to make a prediction: ","metadata":{}},{"cell_type":"code","source":"vc = VotingClassifier(estimators=[('svm', svm2), ('rf', rfc4), ('lr', lgc1), ('gb',gbc5)], voting='hard')\nvc.fit(X_train,y_train)\ny_pred = vc.predict(X_test)\naccuracy_score(y_pred, y_test)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(y_test, y_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=vc.classes_)\ndisp.plot() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"fin\"></a>\n## Fin! \nThank you for reading my notebook, feedback is much appreciated!","metadata":{}}]}