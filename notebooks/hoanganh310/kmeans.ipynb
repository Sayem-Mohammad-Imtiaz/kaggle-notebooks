{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport glob\nimport json\n\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-28T15:22:41.465617Z","iopub.execute_input":"2021-06-28T15:22:41.465996Z","iopub.status.idle":"2021-06-28T15:22:41.471748Z","shell.execute_reply.started":"2021-06-28T15:22:41.465966Z","shell.execute_reply":"2021-06-28T15:22:41.470624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"root_path = '/kaggle/input/CORD-19-research-challenge/'\nmetadata_path = f'{root_path}/metadata.csv'\nmeta_df = pd.read_csv(metadata_path, dtype={\n    'pubmed_id': str,\n    'Microsoft Academic Paper ID': str, \n    'doi': str\n})\nmeta_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T15:22:41.47312Z","iopub.execute_input":"2021-06-28T15:22:41.473411Z","iopub.status.idle":"2021-06-28T15:22:59.578495Z","shell.execute_reply.started":"2021-06-28T15:22:41.473383Z","shell.execute_reply":"2021-06-28T15:22:59.577539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_json = ! ls $root_path/document_parses/pdf_json\nall_json = [root_path + \"document_parses/pdf_json/\" + s for s in all_json]\nprint(len(all_json))\nall_json = all_json[:5000]\nprint(len(all_json))","metadata":{"execution":{"iopub.status.busy":"2021-06-28T15:26:45.151864Z","iopub.execute_input":"2021-06-28T15:26:45.152261Z","iopub.status.idle":"2021-06-28T15:26:46.272075Z","shell.execute_reply.started":"2021-06-28T15:26:45.152232Z","shell.execute_reply":"2021-06-28T15:26:46.270702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FileReader:\n    def __init__(self, file_path):\n        with open(file_path) as file:\n            content = json.load(file)\n            self.paper_id = content['paper_id']\n            self.abstract = []\n            self.body_text = []\n            # Abstract\n            for entry in content['abstract']:\n                self.abstract.append(entry['text'])\n            # Body text\n            for entry in content['body_text']:\n                self.body_text.append(entry['text'])\n            self.abstract = '\\n'.join(self.abstract)\n            self.body_text = '\\n'.join(self.body_text)\n    def __repr__(self):\n        return f'{self.paper_id}: {self.abstract[:200]}... {self.body_text[:200]}...'\nfirst_row = FileReader(all_json[0])\nprint(first_row)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T15:26:48.374164Z","iopub.execute_input":"2021-06-28T15:26:48.374547Z","iopub.status.idle":"2021-06-28T15:26:48.385532Z","shell.execute_reply.started":"2021-06-28T15:26:48.374516Z","shell.execute_reply":"2021-06-28T15:26:48.384503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nall_json_clean = list()\nfor idx, entry in tqdm(enumerate(all_json), total=len(all_json)):\n    try:\n        content = FileReader(entry)\n    except Exception as e:\n        continue  # invalid paper format, skip\n    \n    if len(content.body_text) == 0:\n        continue\n    \n    all_json_clean.append(all_json[idx])\n    \nall_json = all_json_clean\nlen(all_json)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T15:26:50.993888Z","iopub.execute_input":"2021-06-28T15:26:50.99423Z","iopub.status.idle":"2021-06-28T15:26:57.99122Z","shell.execute_reply.started":"2021-06-28T15:26:50.994202Z","shell.execute_reply":"2021-06-28T15:26:57.990229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_breaks(content, length):\n    data = \"\"\n    words = content.split(' ')\n    total_chars = 0\n\n    # add break every length characters\n    for i in range(len(words)):\n        total_chars += len(words[i])\n        if total_chars > length:\n            data = data + \"<br>\" + words[i]\n            total_chars = 0\n        else:\n            data = data + \" \" + words[i]\n    return data","metadata":{"execution":{"iopub.status.busy":"2021-06-28T15:34:47.096252Z","iopub.execute_input":"2021-06-28T15:34:47.096641Z","iopub.status.idle":"2021-06-28T15:34:47.102907Z","shell.execute_reply.started":"2021-06-28T15:34:47.096607Z","shell.execute_reply":"2021-06-28T15:34:47.101865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\ndict_ = {'paper_id': [], 'doi':[], 'abstract': [], 'body_text': [], 'authors': [], 'title': [], 'journal': [], 'abstract_summary': []}\nfor idx, entry in tqdm(enumerate(all_json), total = len(all_json)):\n    \n    try:\n        content = FileReader(entry)\n    except Exception as e:\n        continue  # invalid paper format, skip\n    \n    # get metadata information\n    meta_data = meta_df.loc[meta_df['sha'] == content.paper_id]\n    # no metadata, skip this paper\n    if len(meta_data) == 0:\n        continue\n    if len(content.body_text) == 0:\n        continue\n    dict_['abstract'].append(content.abstract)\n    dict_['paper_id'].append(content.paper_id)\n    dict_['body_text'].append(content.body_text)\n    \n    # also create a column for the summary of abstract to be used in a plot\n    if len(content.abstract) == 0: \n        # no abstract provided\n        dict_['abstract_summary'].append(\"Not provided.\")\n    elif len(content.abstract.split(' ')) > 100:\n        # abstract provided is too long for plot, take first 300 words append with ...\n        info = content.abstract.split(' ')[:100]\n        summary = get_breaks(' '.join(info), 40)\n        dict_['abstract_summary'].append(summary + \"...\")\n    else:\n        # abstract is short enough\n        summary = get_breaks(content.abstract, 40)\n        dict_['abstract_summary'].append(summary)\n        \n    # get metadata information\n    meta_data = meta_df.loc[meta_df['sha'] == content.paper_id]\n    \n    try:\n        # if more than one author\n        authors = meta_data['authors'].values[0].split(';')\n        if len(authors) > 2:\n            # more than 2 authors, may be problem when plotting, so take first 2 append with ...\n            dict_['authors'].append(get_breaks('. '.join(authors), 40))\n        else:\n            # authors will fit in plot\n            dict_['authors'].append(\". \".join(authors))\n    except Exception as e:\n        # if only one author - or Null valie\n        dict_['authors'].append(meta_data['authors'].values[0])\n    \n    # add the title information, add breaks when needed\n    try:\n        title = get_breaks(meta_data['title'].values[0], 40)\n        dict_['title'].append(title)\n    # if title was not provided\n    except Exception as e:\n        dict_['title'].append(meta_data['title'].values[0])\n    \n    # add the journal information\n    dict_['journal'].append(meta_data['journal'].values[0])\n    \n    # add doi\n    dict_['doi'].append(meta_data['doi'].values[0])\n    \ndf_covid = pd.DataFrame(dict_, columns=['paper_id', 'doi', 'abstract', 'body_text', 'authors', 'title', 'journal', 'abstract_summary'])\ndf_covid.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T15:34:50.006647Z","iopub.execute_input":"2021-06-28T15:34:50.007018Z","iopub.status.idle":"2021-06-28T15:42:09.882805Z","shell.execute_reply.started":"2021-06-28T15:34:50.006989Z","shell.execute_reply":"2021-06-28T15:42:09.881749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df_covid.sample(2000, random_state=42)\ndel df_covid","metadata":{"execution":{"iopub.status.busy":"2021-06-28T15:48:17.849272Z","iopub.execute_input":"2021-06-28T15:48:17.849686Z","iopub.status.idle":"2021-06-28T15:48:17.858724Z","shell.execute_reply.started":"2021-06-28T15:48:17.849648Z","shell.execute_reply":"2021-06-28T15:48:17.85764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dropna(inplace=True)\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T15:48:19.836195Z","iopub.execute_input":"2021-06-28T15:48:19.836755Z","iopub.status.idle":"2021-06-28T15:48:19.88779Z","shell.execute_reply.started":"2021-06-28T15:48:19.836721Z","shell.execute_reply":"2021-06-28T15:48:19.886714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install langdetect","metadata":{"execution":{"iopub.status.busy":"2021-06-28T15:48:21.950197Z","iopub.execute_input":"2021-06-28T15:48:21.950816Z","iopub.status.idle":"2021-06-28T15:48:29.611165Z","shell.execute_reply.started":"2021-06-28T15:48:21.950768Z","shell.execute_reply":"2021-06-28T15:48:29.610063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nfrom langdetect import detect\nfrom langdetect import DetectorFactory\n\n# set seed\nDetectorFactory.seed = 0\n\n# hold label - language\nlanguages = []\n\n# go through each text\nfor ii in tqdm(range(0,len(df))):\n    # split by space into list, take the first x intex, join with space\n    text = df.iloc[ii]['body_text'].split(\" \")\n    \n    lang = \"en\"\n    try:\n        if len(text) > 50:\n            lang = detect(\" \".join(text[:50]))\n        elif len(text) > 0:\n            lang = detect(\" \".join(text[:len(text)]))\n    # ught... beginning of the document was not in a good format\n    except Exception as e:\n        all_words = set(text)\n        try:\n            lang = detect(\" \".join(all_words))\n        # what!! :( let's see if we can find any text in abstract...\n        except Exception as e:\n            \n            try:\n                # let's try to label it through the abstract then\n                lang = detect(df.iloc[ii]['abstract_summary'])\n            except Exception as e:\n                lang = \"unknown\"\n                pass\n    \n    # get the language    \n    languages.append(lang)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T15:48:59.837724Z","iopub.execute_input":"2021-06-28T15:48:59.838112Z","iopub.status.idle":"2021-06-28T15:49:14.0249Z","shell.execute_reply.started":"2021-06-28T15:48:59.838081Z","shell.execute_reply":"2021-06-28T15:49:14.023943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pprint import pprint\n\nlanguages_dict = {}\nfor lang in set(languages):\n    languages_dict[lang] = languages.count(lang)\n    \nprint(\"Total: {}\\n\".format(len(languages)))\npprint(languages_dict)\ndf['language'] = languages","metadata":{"execution":{"iopub.status.busy":"2021-06-28T15:50:43.722147Z","iopub.execute_input":"2021-06-28T15:50:43.722613Z","iopub.status.idle":"2021-06-28T15:50:43.729723Z","shell.execute_reply.started":"2021-06-28T15:50:43.722577Z","shell.execute_reply":"2021-06-28T15:50:43.728879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df[df['language'] == 'en'] \ndf.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T15:50:46.098155Z","iopub.execute_input":"2021-06-28T15:50:46.098484Z","iopub.status.idle":"2021-06-28T15:50:46.124974Z","shell.execute_reply.started":"2021-06-28T15:50:46.098456Z","shell.execute_reply":"2021-06-28T15:50:46.123583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_lg-0.2.4.tar.gz  ","metadata":{"execution":{"iopub.status.busy":"2021-06-28T15:51:02.36581Z","iopub.execute_input":"2021-06-28T15:51:02.366191Z","iopub.status.idle":"2021-06-28T15:52:21.811286Z","shell.execute_reply.started":"2021-06-28T15:51:02.366164Z","shell.execute_reply":"2021-06-28T15:52:21.810492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#NLP \nimport spacy\nfrom spacy.lang.en.stop_words import STOP_WORDS\nimport en_core_sci_lg","metadata":{"execution":{"iopub.status.busy":"2021-06-28T15:52:29.584652Z","iopub.execute_input":"2021-06-28T15:52:29.585007Z","iopub.status.idle":"2021-06-28T15:52:30.625618Z","shell.execute_reply.started":"2021-06-28T15:52:29.584975Z","shell.execute_reply":"2021-06-28T15:52:30.624656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import string\n\npunctuations = string.punctuation\nstopwords = list(STOP_WORDS)\nstopwords[:10]","metadata":{"execution":{"iopub.status.busy":"2021-06-28T15:52:41.092716Z","iopub.execute_input":"2021-06-28T15:52:41.093215Z","iopub.status.idle":"2021-06-28T15:52:41.098857Z","shell.execute_reply.started":"2021-06-28T15:52:41.093172Z","shell.execute_reply":"2021-06-28T15:52:41.09818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"custom_stop_words = [\n    'doi', 'preprint', 'copyright', 'peer', 'reviewed', 'org', 'https', 'et', 'al', 'author', 'figure', \n    'rights', 'reserved', 'permission', 'used', 'using', 'biorxiv', 'medrxiv', 'license', 'fig', 'fig.', \n    'al.', 'Elsevier', 'PMC', 'CZI'\n]\n\nfor w in custom_stop_words:\n    if w not in stopwords:\n        stopwords.append(w)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T15:52:43.668701Z","iopub.execute_input":"2021-06-28T15:52:43.669315Z","iopub.status.idle":"2021-06-28T15:52:43.675449Z","shell.execute_reply.started":"2021-06-28T15:52:43.669268Z","shell.execute_reply":"2021-06-28T15:52:43.674633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Parser\nparser = en_core_sci_lg.load(disable=[\"tagger\", \"ner\"])\nparser.max_length = 7000000\n\ndef spacy_tokenizer(sentence):\n    mytokens = parser(sentence)\n    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n    mytokens = [ word for word in mytokens if word not in stopwords and word not in punctuations ]\n    mytokens = \" \".join([i for i in mytokens])\n    return mytokens","metadata":{"execution":{"iopub.status.busy":"2021-06-28T15:52:45.62495Z","iopub.execute_input":"2021-06-28T15:52:45.625609Z","iopub.status.idle":"2021-06-28T15:52:53.877363Z","shell.execute_reply.started":"2021-06-28T15:52:45.625558Z","shell.execute_reply":"2021-06-28T15:52:53.87662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tqdm.pandas()\ndf[\"processed_text\"] = df[\"body_text\"].progress_apply(spacy_tokenizer)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T15:52:56.575455Z","iopub.execute_input":"2021-06-28T15:52:56.576037Z","iopub.status.idle":"2021-06-28T16:02:30.425899Z","shell.execute_reply.started":"2021-06-28T15:52:56.576002Z","shell.execute_reply":"2021-06-28T16:02:30.42494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\ndef vectorize(text, maxx_features):\n    \n    vectorizer = TfidfVectorizer(max_features=maxx_features)\n    X = vectorizer.fit_transform(text)\n    return X","metadata":{"execution":{"iopub.status.busy":"2021-06-28T16:02:45.546546Z","iopub.execute_input":"2021-06-28T16:02:45.546879Z","iopub.status.idle":"2021-06-28T16:02:46.40545Z","shell.execute_reply.started":"2021-06-28T16:02:45.546852Z","shell.execute_reply":"2021-06-28T16:02:46.404561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = df['processed_text'].values\nmax_features = 2**12\n\nX = vectorize(text, max_features)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T16:02:48.030558Z","iopub.execute_input":"2021-06-28T16:02:48.03089Z","iopub.status.idle":"2021-06-28T16:02:52.195333Z","shell.execute_reply.started":"2021-06-28T16:02:48.030862Z","shell.execute_reply":"2021-06-28T16:02:52.194398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.decomposition import PCA\n\npca = PCA(n_components=0.95, random_state=42)\nX_reduced= pca.fit_transform(X.toarray())\nX_reduced.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-28T16:02:55.152032Z","iopub.execute_input":"2021-06-28T16:02:55.152372Z","iopub.status.idle":"2021-06-28T16:02:59.843504Z","shell.execute_reply.started":"2021-06-28T16:02:55.152344Z","shell.execute_reply":"2021-06-28T16:02:59.842547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.cluster import MiniBatchKMeans\nfrom sklearn.cluster import KMeans","metadata":{"execution":{"iopub.status.busy":"2021-06-28T16:03:01.625211Z","iopub.execute_input":"2021-06-28T16:03:01.625575Z","iopub.status.idle":"2021-06-28T16:03:01.775017Z","shell.execute_reply.started":"2021-06-28T16:03:01.625546Z","shell.execute_reply":"2021-06-28T16:03:01.774215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\nfrom scipy.spatial.distance import cdist\n\n# run kmeans with many different k\ndistortions = []\nK = range(2, 30)\nfor k in K:\n    k_means = KMeans(n_clusters=k, random_state=42).fit(X_reduced)\n    k_means.fit(X_reduced)\n    distortions.append(sum(np.min(cdist(X_reduced, k_means.cluster_centers_, 'euclidean'), axis=1)) / X.shape[0])\n    #print('Found distortion for {} clusters'.format(k))","metadata":{"execution":{"iopub.status.busy":"2021-06-28T16:03:04.519973Z","iopub.execute_input":"2021-06-28T16:03:04.520326Z","iopub.status.idle":"2021-06-28T16:10:27.273261Z","shell.execute_reply.started":"2021-06-28T16:03:04.520297Z","shell.execute_reply":"2021-06-28T16:10:27.271922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_line = [K[0], K[-1]]\nY_line = [distortions[0], distortions[-1]]\n\n# Plot the elbow\nplt.plot(K, distortions, 'b-')\nplt.plot(X_line, Y_line, 'r')\nplt.xlabel('k')\nplt.ylabel('Distortion')\nplt.title('The Elbow Method showing the optimal k')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T16:13:41.036575Z","iopub.execute_input":"2021-06-28T16:13:41.037141Z","iopub.status.idle":"2021-06-28T16:13:41.211234Z","shell.execute_reply.started":"2021-06-28T16:13:41.037107Z","shell.execute_reply":"2021-06-28T16:13:41.210321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k = 27\nkmeans = KMeans(n_clusters=k, random_state=42)\ny_pred = kmeans.fit_predict(X_reduced)\ndf['y'] = y_pred","metadata":{"execution":{"iopub.status.busy":"2021-06-28T16:13:58.203977Z","iopub.execute_input":"2021-06-28T16:13:58.20435Z","iopub.status.idle":"2021-06-28T16:14:09.726555Z","shell.execute_reply.started":"2021-06-28T16:13:58.204317Z","shell.execute_reply":"2021-06-28T16:14:09.722635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.manifold import TSNE\n\ntsne = TSNE(verbose=1, perplexity=50)  # Changed perplexity from 100 to 50 per FAQ\nX_embedded = tsne.fit_transform(X.toarray())","metadata":{"execution":{"iopub.status.busy":"2021-06-28T16:14:38.450767Z","iopub.execute_input":"2021-06-28T16:14:38.451109Z","iopub.status.idle":"2021-06-28T16:14:48.699945Z","shell.execute_reply.started":"2021-06-28T16:14:38.451081Z","shell.execute_reply":"2021-06-28T16:14:48.698989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport seaborn as sns\n\n# sns settings\nsns.set(rc={'figure.figsize':(15,15)})\n\n# colors\npalette = sns.color_palette(\"bright\", 1)\n\n# plot\nsns.scatterplot(X_embedded[:,0], X_embedded[:,1], palette=palette)\nplt.title('t-SNE with no Labels')\nplt.savefig(\"t-sne_covid19.png\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T16:14:54.860801Z","iopub.execute_input":"2021-06-28T16:14:54.861293Z","iopub.status.idle":"2021-06-28T16:14:55.3889Z","shell.execute_reply.started":"2021-06-28T16:14:54.861263Z","shell.execute_reply":"2021-06-28T16:14:55.387931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\n# sns settings\nsns.set(rc={'figure.figsize':(13,9)})\n\n# colors\npalette = sns.hls_palette(27, l=.4, s=.9)\n\n# plot\nsns.scatterplot(X_embedded[:,0], X_embedded[:,1], hue=y_pred, legend='full', palette=palette)\nplt.title('t-SNE with Kmeans Labels')\nplt.savefig(\"improved_cluster_tsne.png\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T16:15:42.049325Z","iopub.execute_input":"2021-06-28T16:15:42.049713Z","iopub.status.idle":"2021-06-28T16:15:43.813669Z","shell.execute_reply.started":"2021-06-28T16:15:42.049681Z","shell.execute_reply":"2021-06-28T16:15:43.812361Z"},"trusted":true},"execution_count":null,"outputs":[]}]}