{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score\nfrom sklearn.model_selection import KFold # This library will help split our data into KFolds\nfrom scipy.stats import randint\nfrom sklearn.model_selection import KFold \nfrom sklearn.tree import DecisionTreeClassifier #Decision Tree Classifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nimport time\n\nimport statsmodels.api as sm \n\n\n\n# Data: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\ndf = pd.read_csv('../input/breast-cancer-wisconsin-data/data.csv') \n\n# Check shape of dataframe\ndf.shape\n\n#lets check the data info\ndf.info()","metadata":{"_uuid":"acc1ea0c-e0fe-4bd1-bc9f-983ca38a4893","_cell_guid":"9ca58d30-7ec3-4491-89f2-4ddb714d0478","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-06T20:22:23.179399Z","iopub.execute_input":"2021-06-06T20:22:23.179836Z","iopub.status.idle":"2021-06-06T20:22:25.372072Z","shell.execute_reply.started":"2021-06-06T20:22:23.179785Z","shell.execute_reply":"2021-06-06T20:22:25.370534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checcking for ids that show up multiple times in the dataset.\n# This could skew any results\ncounts = pd.DataFrame(df.id.value_counts())\ncounts = counts[counts.id > 1]\n\nduplicates = list(counts.index)\nprint(f'Duplicate IDs: {len(duplicates)}')\n\ndf = df[~df.id.isin(duplicates)]","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:06.705886Z","iopub.execute_input":"2021-05-26T07:28:06.706232Z","iopub.status.idle":"2021-05-26T07:28:06.730878Z","shell.execute_reply.started":"2021-05-26T07:28:06.706187Z","shell.execute_reply":"2021-05-26T07:28:06.730005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop 'id' column that is no longer necessary.\ndf.drop(columns=['Unnamed: 32', 'id'], inplace=True)\nprint(df.columns)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:22:39.279986Z","iopub.execute_input":"2021-06-06T20:22:39.280376Z","iopub.status.idle":"2021-06-06T20:22:39.289951Z","shell.execute_reply.started":"2021-06-06T20:22:39.280343Z","shell.execute_reply":"2021-06-06T20:22:39.288414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Change the \"malignant\" diagnosis column from 2/4 to 0/1 for benign/malignant\ndf.diagnosis = [1 if i == 'M' else 0 for i in df.diagnosis]\n\n\ndf.info()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:22:44.418944Z","iopub.execute_input":"2021-06-06T20:22:44.419392Z","iopub.status.idle":"2021-06-06T20:22:44.441293Z","shell.execute_reply.started":"2021-06-06T20:22:44.419355Z","shell.execute_reply":"2021-06-06T20:22:44.440229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lets describe our dataset\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:22:53.356868Z","iopub.execute_input":"2021-06-06T20:22:53.357208Z","iopub.status.idle":"2021-06-06T20:22:53.46704Z","shell.execute_reply.started":"2021-06-06T20:22:53.35718Z","shell.execute_reply":"2021-06-06T20:22:53.465816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lets check for the distribution of our features\ndf.radius_mean.plot.hist()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:29:01.048994Z","iopub.execute_input":"2021-05-26T07:29:01.049372Z","iopub.status.idle":"2021-05-26T07:29:01.257848Z","shell.execute_reply.started":"2021-05-26T07:29:01.049334Z","shell.execute_reply":"2021-05-26T07:29:01.25682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.texture_mean.plot.hist()\n","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:29:08.44913Z","iopub.execute_input":"2021-05-26T07:29:08.449463Z","iopub.status.idle":"2021-05-26T07:29:08.600204Z","shell.execute_reply.started":"2021-05-26T07:29:08.449433Z","shell.execute_reply":"2021-05-26T07:29:08.599269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.perimeter_mean.plot.hist()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:29:11.547782Z","iopub.execute_input":"2021-05-26T07:29:11.548085Z","iopub.status.idle":"2021-05-26T07:29:11.694861Z","shell.execute_reply.started":"2021-05-26T07:29:11.548058Z","shell.execute_reply":"2021-05-26T07:29:11.694122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#What are their counts?\ndf.diagnosis.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:23:08.047224Z","iopub.execute_input":"2021-06-06T20:23:08.047669Z","iopub.status.idle":"2021-06-06T20:23:08.058707Z","shell.execute_reply.started":"2021-06-06T20:23:08.047633Z","shell.execute_reply":"2021-06-06T20:23:08.057441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split data into training and holdout set\nX = df.drop('diagnosis', axis = 1)\ny = df.diagnosis\n\n\n# We would be splitting dataset into train and test, then using the train set for cross validation\n# Initial train test split \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 1)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:23:47.41196Z","iopub.execute_input":"2021-06-06T20:23:47.4124Z","iopub.status.idle":"2021-06-06T20:23:47.422045Z","shell.execute_reply.started":"2021-06-06T20:23:47.412363Z","shell.execute_reply":"2021-06-06T20:23:47.420633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Logistics Regression\n\nstart = time.time()\n#instead of tunnibg manually, i would use the gridsearchcv to tune for my best paramentrs\nestimator = Pipeline( [('scale', StandardScaler()),\n                      ('clf', LogisticRegression(penalty = 'l1', solver = 'liblinear', random_state = 1))] )\nlogit_grid = {'clf__C': np.logspace(-2, 1, 20),\n       'clf__max_iter': np.linspace(1000,10000,10)}\n\nmodel_logit = GridSearchCV(estimator, logit_grid, cv = 10, scoring = 'accuracy', n_jobs = -1)\nmodel_logit.fit(X_train, y_train)\n\nend = time.time()\nTtime = end - start\nprint(Ttime)\n\nmodel_logit.best_params_\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-25T17:57:59.758145Z","iopub.execute_input":"2021-05-25T17:57:59.758444Z","iopub.status.idle":"2021-05-25T17:58:11.436134Z","shell.execute_reply.started":"2021-05-25T17:57:59.758417Z","shell.execute_reply":"2021-05-25T17:58:11.435158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = time.time()\n# lets tune to obtain the best threshold that would predict my our model      \nthresholds=np.linspace(0,1,50)\n#Remove the first and last position in the threshold candidate values:\nthresholds=np.delete(thresholds,[0,49])\nFPR_list=np.zeros(len(thresholds))\nAccuracy_list=np.zeros(len(thresholds))\nYouden_list=np.zeros(len(thresholds))\nkfold = KFold(n_splits = 5, shuffle = True, random_state = 1) # Think of this as instantiating the folds\n\n#Looping through values in the thresholds and folds:\nfor train_index, valid_index in kfold.split(X_train):\n    X_training, y_training=X_train.iloc[train_index], y_train.iloc[train_index]\n    X_valid, y_valid=X_train.iloc[valid_index], y_train.iloc[valid_index]\n    model_logit.fit(X_training, y_training)\n    pred_prob=model_logit.predict_proba(X_valid)\n    for i,value in enumerate(thresholds):\n        #For each value of threshol\n        yhat=np.where(pred_prob[:,1] > value, 1, 0)\n        confmat=confusion_matrix(y_valid, yhat, labels=[1,0])\n        TP = confmat[0,0]\n        FN = confmat[0,1]\n        FP = confmat[1,0]\n        TN = confmat[1,1]\n        sensitivity = TP / (TP + FN)\n        specificity = TN / (TN + FP)\n        #Calculate FPR\n        FPR = FP / (FP + TN) # False Positive Rate\n        #Calculate accuracy\n        Acc = (TP + TN) / sum(sum(confmat))\n        #Calculate Youden index\n        Youden=sensitivity + specificity -1\n        FPR_list[i]=FPR_list[i] + FPR\n        Accuracy_list[i]=Accuracy_list[i] +Acc\n        Youden_list[i]=Youden_list[i] + Youden      \n        \n\n#Find the threshold values that satisfy the conditions:      \nthresh_1 =thresholds[np.argmin(FPR_list)]\nthresh_2 =thresholds[np.argmax(Accuracy_list)]\nthresh_3 =thresholds[np.argmax(Youden_list)]\n\nend = time.time()\nTtime = end - start\nprint(Ttime)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T17:58:11.437704Z","iopub.execute_input":"2021-05-25T17:58:11.438008Z","iopub.status.idle":"2021-05-25T17:58:57.924062Z","shell.execute_reply.started":"2021-05-25T17:58:11.43798Z","shell.execute_reply":"2021-05-25T17:58:57.923196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#building our confusion matrix using the youden tunes the best\ny_prob_logit = model_logit.predict_proba(X_test)[:,1]\n#Minimize FPR threshold value:\nyhat_logit = np.where(y_prob_logit > thresh_3,1,0)\nconfmat_logit = confusion_matrix(y_test,yhat_logit,labels=[1,0])\nconfmat_logit","metadata":{"execution":{"iopub.status.busy":"2021-05-25T17:58:57.925514Z","iopub.execute_input":"2021-05-25T17:58:57.925886Z","iopub.status.idle":"2021-05-25T17:58:57.93704Z","shell.execute_reply.started":"2021-05-25T17:58:57.925842Z","shell.execute_reply":"2021-05-25T17:58:57.935986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Random forest\n#lets tune for a randon forest model, i was going to tune with boostrap but this prooved to long, so i would use the default\nstart = time.time()\n\nrf_grid = {'n_estimators': np.linspace(100, 500, 5, dtype = int), \n          'max_leaf_nodes': np.arange(5, 10),\n           'min_samples_leaf' : range(2, 10),\n          'max_features': ['auto','sqrt']}\nmodel_RF = GridSearchCV(RandomForestClassifier(random_state = 1),\n                    param_grid = rf_grid, cv = 10, n_jobs = -1, scoring = 'accuracy')\nmodel_RF.fit(X_train, y_train)\n\nmodel_RF.best_params_\n\nend = time.time()\nTtime = end - start\nprint(Ttime)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T17:58:57.938701Z","iopub.execute_input":"2021-05-25T17:58:57.939063Z","iopub.status.idle":"2021-05-25T18:16:02.966254Z","shell.execute_reply.started":"2021-05-25T17:58:57.939031Z","shell.execute_reply":"2021-05-25T18:16:02.965036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# In[23]:\nstart = time.time()\n# lets tune to obtain the best threshold that would predict my our model      \nthresholds=np.linspace(0,1,50)\n#Remove the first and last position in the threshold candidate values:\nthresholds=np.delete(thresholds,[0,49])\nFPR_list=np.zeros(len(thresholds))\nAccuracy_list=np.zeros(len(thresholds))\nYouden_list=np.zeros(len(thresholds))\nkfold = KFold(n_splits = 5, shuffle = True, random_state = 1) # Think of this as instantiating the folds\n\n#Looping through values in the thresholds and folds:\nfor train_index, valid_index in kfold.split(X_train):\n    X_training, y_training=X_train.iloc[train_index], y_train.iloc[train_index]\n    X_valid, y_valid=X_train.iloc[valid_index], y_train.iloc[valid_index]\n    model_logit.fit(X_training, y_training)\n    pred_prob=model_logit.predict_proba(X_valid)\n    for i,value in enumerate(thresholds):\n        #For each value of threshol\n        yhat=np.where(pred_prob[:,1] > value, 1, 0)\n        confmat=confusion_matrix(y_valid, yhat, labels=[1,0])\n        TP = confmat[0,0]\n        FN = confmat[0,1]\n        FP = confmat[1,0]\n        TN = confmat[1,1]\n        sensitivity = TP / (TP + FN)\n        specificity = TN / (TN + FP)\n        #Calculate FPR\n        FPR = FP / (FP + TN) # False Positive Rate\n        #Calculate accuracy\n        Acc = (TP + TN) / sum(sum(confmat))\n        #Calculate Youden index\n        Youden=sensitivity + specificity -1\n        FPR_list[i]=FPR_list[i] + FPR\n        Accuracy_list[i]=Accuracy_list[i] +Acc\n        Youden_list[i]=Youden_list[i] + Youden     \n\nend = time.time()\nTtime = end - start\nprint(Ttime)\n\n#Find the threshold values that satisfy the conditions:      \nthreshRF_1 =thresholds[np.argmin(FPR_list)]\nthreshRF_2 =thresholds[np.argmax(Accuracy_list)]\nthreshRF_3 =thresholds[np.argmax(Youden_list)]\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:16:02.967738Z","iopub.execute_input":"2021-05-25T18:16:02.968054Z","iopub.status.idle":"2021-05-25T18:16:49.24429Z","shell.execute_reply.started":"2021-05-25T18:16:02.968023Z","shell.execute_reply":"2021-05-25T18:16:49.24323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# In[24]:\n#building our confusion matrix \ny_prob_RF = model_RF.predict_proba(X_test)[:,1]\n#Minimize FPR threshold value:\nyhat_RF = np.where(y_prob_RF > threshRF_2,1,0)\nconfmat_RF = confusion_matrix(y_test,yhat_RF,labels=[1,0])\nconfmat_RF","metadata":{"execution":{"iopub.status.busy":"2021-05-25T18:16:49.245702Z","iopub.execute_input":"2021-05-25T18:16:49.246107Z","iopub.status.idle":"2021-05-25T18:16:49.305804Z","shell.execute_reply.started":"2021-05-25T18:16:49.246063Z","shell.execute_reply":"2021-05-25T18:16:49.304876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#bagging\nstart = time.time()\n# now lets tune for a bagged tree with three parameters\nbag_grid = {'n_estimators': np.linspace(100,500,5, dtype = int),\n           'max_depth':range(2, 10),\n           'min_samples_leaf' : range(2, 15)}\n\nmodel_bag = GridSearchCV(RandomForestClassifier(max_features = None, random_state = 1), \n                      param_grid = bag_grid, cv = 10, n_jobs = -1, scoring = 'accuracy')\nmodel_bag.fit(X_train, y_train)\n\nmodel_bag.best_params_\n\nend = time.time()\nTtime = end - start\nprint(Ttime)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:29:47.76318Z","iopub.execute_input":"2021-05-26T07:29:47.763541Z","iopub.status.idle":"2021-05-26T07:58:15.98007Z","shell.execute_reply.started":"2021-05-26T07:29:47.763507Z","shell.execute_reply":"2021-05-26T07:58:15.97913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = time.time()\n# lets tune to obtain the best threshold that would predict my our model      \nthresholds=np.linspace(0,1,50)\n#Remove the first and last position in the threshold candidate values:\nthresholds=np.delete(thresholds,[0,49])\nFPR_list=np.zeros(len(thresholds))\nAccuracy_list=np.zeros(len(thresholds))\nYouden_list=np.zeros(len(thresholds))\nkfold = KFold(n_splits = 5, shuffle = True, random_state = 1) # Think of this as instantiating the folds\n\n#Looping through values in the thresholds and folds:\nfor train_index, valid_index in kfold.split(X_train):\n    X_training, y_training=X_train.iloc[train_index], y_train.iloc[train_index]\n    X_valid, y_valid=X_train.iloc[valid_index], y_train.iloc[valid_index]\n    model_bag.fit(X_training, y_training)\n    pred_prob=model_bag.predict_proba(X_valid)\n    for i,value in enumerate(thresholds):\n        #For each value of threshol\n        yhat=np.where(pred_prob[:,1] > value, 1, 0)\n        confmat=confusion_matrix(y_valid, yhat, labels=[1,0])\n        TP = confmat[0,0]\n        FN = confmat[0,1]\n        FP = confmat[1,0]\n        TN = confmat[1,1]\n        sensitivity = TP / (TP + FN)\n        specificity = TN / (TN + FP)\n        #Calculate FPR\n        FPR = FP / (FP + TN) # False Positive Rate\n        #Calculate accuracy\n        Acc = (TP + TN) / sum(sum(confmat))\n        #Calculate Youden index\n        Youden=sensitivity + specificity -1\n        FPR_list[i]=FPR_list[i] + FPR\n        Accuracy_list[i]=Accuracy_list[i] +Acc\n        Youden_list[i]=Youden_list[i] + Youden     \n\nend = time.time()\nTtime = end - start\nprint(Ttime)\n\n#Find the threshold values that satisfy the conditions:      \nthreshbag_1 =thresholds[np.argmin(FPR_list)]\nthreshbag_2 =thresholds[np.argmax(Accuracy_list)]\nthreshbag_3 =thresholds[np.argmax(Youden_list)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#building our confusion matrix \ny_prob_bag = model_bag.predict_proba(X_test)[:,1]\n#Minimize FPR threshold value:\nyhat_bag =np.where(y_prob_bag > threshbag_1,1,0)\nconfmat_bag = confusion_matrix(y_test,yhat_bag,labels=[1,0])\nconfmat_bag    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#using the Boosted Tree, tunning using the three parameters for gradient boosting\nstart = time.time()\n\ngboost_grid = {'n_estimators': np.linspace(100, 1000, 10, dtype = int), 'max_depth': [1,2,3,4],\n               'learning_rate': np.arange(0.01, 0.1, 0.01)}\nmodel_gboost = GridSearchCV(GradientBoostingClassifier(min_samples_leaf = 10, random_state = 1),\n                    param_grid = gboost_grid, cv = 10, n_jobs = -1, scoring = 'accuracy')\nmodel_gboost.fit(X_train, y_train)\n\nmodel_gboost.best_params_\nend = time.time()\nTtime = end - start\nprint(Ttime)\n\n# In[48]:\n\nstart = time.time()\n# lets tune to obtain the best threshold that would predict my our model      \nthresholds=np.linspace(0,1,50)\n#Remove the first and last position in the threshold candidate values:\nthresholds=np.delete(thresholds,[0,49])\nFPR_list=np.zeros(len(thresholds))\nAccuracy_list=np.zeros(len(thresholds))\nYouden_list=np.zeros(len(thresholds))\nkfold = KFold(n_splits = 5, shuffle = True, random_state = 1) # Think of this as instantiating the folds\n\n#Looping through values in the thresholds and folds:\nfor train_index, valid_index in kfold.split(X_train):\n    X_training, y_training=X_train.iloc[train_index], y_train.iloc[train_index]\n    X_valid, y_valid=X_train.iloc[valid_index], y_train.iloc[valid_index]\n    model_gboost.fit(X_training, y_training)\n    pred_prob=model_gboost.predict_proba(X_valid)\n    for i,value in enumerate(thresholds):\n        #For each value of threshol\n        yhat=np.where(pred_prob[:,1] > value, 1, 0)\n        confmat=confusion_matrix(y_valid, yhat, labels=[1,0])\n        TP = confmat[0,0]\n        FN = confmat[0,1]\n        FP = confmat[1,0]\n        TN = confmat[1,1]\n        sensitivity = TP / (TP + FN)\n        specificity = TN / (TN + FP)\n        #Calculate FPR\n        FPR = FP / (FP + TN) # False Positive Rate\n        #Calculate accuracy\n        Acc = (TP + TN) / sum(sum(confmat))\n        #Calculate Youden index\n        Youden=sensitivity + specificity -1\n        FPR_list[i]=FPR_list[i] + FPR\n        Accuracy_list[i]=Accuracy_list[i] +Acc\n        Youden_list[i]=Youden_list[i] + Youden      \n        \nend = time.time()\nTtime = end - start\nprint(Ttime)\n\n#Find the threshold values that satisfy the conditions:      \nthreshgb_1 =thresholds[np.argmin(FPR_list)]\nthreshgb_2 =thresholds[np.argmax(Accuracy_list)]\nthreshgb_3 =thresholds[np.argmax(Youden_list)]\n\n# In[48]:\n#building our confusion matrix using yoden threshold\ny_prob_gboost = model_gboost.predict_proba(X_test)[:,1]\n#Minimize FPR threshold value:\nyhat_gboost =np.where(y_prob_gboost > threshgb_3,1,0)\nconfmat_gboost = confusion_matrix(y_test,yhat_gboost,labels=[1,0])\nconfmat_gboost","metadata":{"execution":{"iopub.status.busy":"2021-06-06T20:23:51.107933Z","iopub.execute_input":"2021-06-06T20:23:51.108347Z","iopub.status.idle":"2021-06-06T23:11:39.392007Z","shell.execute_reply.started":"2021-06-06T20:23:51.108309Z","shell.execute_reply":"2021-06-06T23:11:39.390613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #### check for accuracy on the train and test set?\n\nprint(f'Train Accuracy for logit model : {model_logit.score(X_train,y_train):.4f}')\nprint (f'Test Accuracy for logist model - : {model_logit.score(X_test,y_test):.4f}')\n\n\nprint(f'Train Accuracy for bagged model : {model_bag.score(X_train,y_train):.4f}')\nprint (f'Test Accuracy for bagged model - : {model_bag.score(X_test,y_test):.4f}')\n\nprint(f'Train Accuracy for Random Forest model : {model_RF.score(X_train,y_train):.4f}')\nprint (f'Test Accuracy for Randon Forest model - : {model_RF.score(X_test,y_test):.4f}')\n\nprint(f'Train Accuracy for Boosting model : {model_gboost.score(X_train,y_train):.4f}')\nprint (f'Test Accuracy for Boosting model - : {model_gboost.score(X_test,y_test):.4f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lets check for the auc of all the models\n\n# AUC values\nprint(roc_auc_score(y_test, y_prob_logit))\nprint(roc_auc_score(y_test, y_prob_tree))\nprint(roc_auc_score(y_test, y_prob_RF))\nprint(roc_auc_score(y_test, y_prob_gboost))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lets check for the classification of all the models\n\n# classification report\nprint(\"classification report for logistics model\")\nprint(classification_report(y_test, yhat_logit))\n\nprint('classification report of random forest model is')\nprint(classification_report(y_test, yhat_RF))\n\nprint('classification report for bagged tree') \nprint(classification_report(y_test, yhat_bag))\n      \nprint('classification report for gradient boosting is')\nprint(classification_report(y_test, yhat_gboost))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Important features\nimportance = pd.DataFrame({'feature':X.columns.values,  'importance_2': model_bag.best_estimator_.feature_importances_, \n                           'importance_3': model_RF.best_estimator_.feature_importances_,\n                           'importance_4': model_gboost.best_estimator_.feature_importances_ })\nimportance.sort_values(by = ['importance_2'], ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}