{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-09T16:26:19.017691Z","iopub.execute_input":"2021-08-09T16:26:19.018054Z","iopub.status.idle":"2021-08-09T16:26:19.026615Z","shell.execute_reply.started":"2021-08-09T16:26:19.018026Z","shell.execute_reply":"2021-08-09T16:26:19.025574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# This is a Simple and Direct code for Logistic Classification with the KNN Classifier.\n\nIn this workbook we are going to learn how quickly with minimum data insights we can create a data model that can predict our Classification problem data sets\n\nNote :- We will import the Libraries as when required so you can undesrtand use of each library.\n\nLet's get Started...","metadata":{}},{"cell_type":"markdown","source":"# First Step : Data ","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/advertising/advertising.csv')\ndf.describe","metadata":{"execution":{"iopub.status.busy":"2021-08-09T16:40:48.849478Z","iopub.execute_input":"2021-08-09T16:40:48.849832Z","iopub.status.idle":"2021-08-09T16:40:48.873931Z","shell.execute_reply.started":"2021-08-09T16:40:48.849801Z","shell.execute_reply":"2021-08-09T16:40:48.872898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Data looks good but we require few more information before creating our prediction model.\n\nWhat are data types ?","metadata":{}},{"cell_type":"code","source":"df.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-08-09T16:40:53.26717Z","iopub.execute_input":"2021-08-09T16:40:53.267527Z","iopub.status.idle":"2021-08-09T16:40:53.275621Z","shell.execute_reply.started":"2021-08-09T16:40:53.267497Z","shell.execute_reply":"2021-08-09T16:40:53.274953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I think there is a Timestamp coloumn which contains the Date&Time data. So we will convert that to have a correct data types.","metadata":{}},{"cell_type":"code","source":"df['Timestamp']=pd.to_datetime(df['Timestamp'])\ndf['Timestamp'] = (df['Timestamp'] - df['Timestamp'].min())\ndf.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-08-09T16:40:57.290886Z","iopub.execute_input":"2021-08-09T16:40:57.291229Z","iopub.status.idle":"2021-08-09T16:40:57.302445Z","shell.execute_reply.started":"2021-08-09T16:40:57.291201Z","shell.execute_reply":"2021-08-09T16:40:57.301417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now data seems Good....\nBut Are there any null value in the data ? Let us check....","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-08-09T16:41:02.253969Z","iopub.execute_input":"2021-08-09T16:41:02.254317Z","iopub.status.idle":"2021-08-09T16:41:02.266883Z","shell.execute_reply.started":"2021-08-09T16:41:02.254287Z","shell.execute_reply":"2021-08-09T16:41:02.265503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Perfect..! No null values\nHey wait, we can build a Model with object data type columns link City, Country.\nWe need to convert them...","metadata":{}},{"cell_type":"code","source":"df = pd.get_dummies(df, columns=['City'],dtype=float)\ndf = pd.get_dummies(df, columns=['Country'],dtype=float)","metadata":{"execution":{"iopub.status.busy":"2021-08-09T16:41:05.479159Z","iopub.execute_input":"2021-08-09T16:41:05.47966Z","iopub.status.idle":"2021-08-09T16:41:05.517492Z","shell.execute_reply.started":"2021-08-09T16:41:05.47963Z","shell.execute_reply":"2021-08-09T16:41:05.516614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Second Step : Data Preparation (Inputs & Outputs)\n\nAs we have already prepare the dataset ready now we will have devide/desect the data for further analysis.","metadata":{}},{"cell_type":"markdown","source":"Now, we will create two variables X - containing the our Features for our Modem & y- contains the Outcome we require to give the Model to learn from. Simple,the prediction values.","metadata":{}},{"cell_type":"code","source":"X=df.drop(columns=['Clicked on Ad','Ad Topic Line','Timestamp'])\ny=df['Clicked on Ad']\nX.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-08-09T16:46:28.619296Z","iopub.execute_input":"2021-08-09T16:46:28.619669Z","iopub.status.idle":"2021-08-09T16:46:28.636221Z","shell.execute_reply.started":"2021-08-09T16:46:28.619639Z","shell.execute_reply":"2021-08-09T16:46:28.635111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If we analyse the Feature (X),\n\nIt could easily be undesrtood that having 1211 features for 1000 examples is not a good scenario to train Logistic regression Model.\n\nHere, we required to identify the Features that have the maximum impact for our Target classification output. For this, we will be using the SelectKbest from the SKlearn.\n\nWe will have only first 10 most usable features to train our model.","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nbest=SelectKBest(score_func=chi2, k=100)\nfit1=best.fit(X,y)\ndata_scores=pd.DataFrame(fit1.scores_)\ndata_columns=pd.DataFrame(X.columns)\nscores=pd.concat([data_columns,data_scores],axis=1)\nscores.columns=['Feature','Score']\nprint(scores.nlargest(10,'Score'))","metadata":{"execution":{"iopub.status.busy":"2021-08-09T16:53:46.463449Z","iopub.execute_input":"2021-08-09T16:53:46.463796Z","iopub.status.idle":"2021-08-09T16:53:47.63535Z","shell.execute_reply.started":"2021-08-09T16:53:46.463766Z","shell.execute_reply":"2021-08-09T16:53:47.632609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Wow, we have worked hard for Countries and cities but in comparison to other features we can negelect them.\n\nWhy? You may ask...\n\nAnswer is, if we will train a Model considering the features do not have any importance for prediction may have adverse effects on our predictions. The Precision and F1 score of the final result will be affected.\n\nSo we will limit our features (X) to first Four. ","metadata":{}},{"cell_type":"code","source":"X=X[['Daily Time Spent on Site', 'Age', 'Area Income', 'Daily Internet Usage']]\nX.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-09T17:00:03.414489Z","iopub.execute_input":"2021-08-09T17:00:03.414832Z","iopub.status.idle":"2021-08-09T17:00:03.432601Z","shell.execute_reply.started":"2021-08-09T17:00:03.414802Z","shell.execute_reply":"2021-08-09T17:00:03.431404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"Before creating a Model, we must have to devide the data for Training and Testing datasets so that after creating a Model we can check the performace our Model.\n\ntrain_test_split is the most common option for that, Right !","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.37, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-09T17:03:14.757776Z","iopub.execute_input":"2021-08-09T17:03:14.758176Z","iopub.status.idle":"2021-08-09T17:03:14.76717Z","shell.execute_reply.started":"2021-08-09T17:03:14.758142Z","shell.execute_reply":"2021-08-09T17:03:14.766073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As you can see that all our features are raning from different values like,\n1.Area Income have values raning in - Five Digit\n2. Daily Time Spent on Site - Two Digit\n3. Age - Two Digit\n4. Daily Internet Usage - Three Digit\n\nSo, we have to first Scale them to 0 to 1 considering the Maximum & Minimum values we have in that perticular coloumn dataset..","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-09T17:09:09.709546Z","iopub.execute_input":"2021-08-09T17:09:09.710173Z","iopub.status.idle":"2021-08-09T17:09:09.714573Z","shell.execute_reply.started":"2021-08-09T17:09:09.710136Z","shell.execute_reply":"2021-08-09T17:09:09.713966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Third Step : Create a First KNN Model ","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, classification_report\n\nknn = KNeighborsClassifier(n_neighbors=1)\nmodel = knn.fit(X_train, y_train)\nknn_predict = knn.predict(X_test)\nknn_conf_matrix = confusion_matrix(y_test, knn_predict)\nknn_acc_score = accuracy_score(y_test, knn_predict)\nprint(\"confusion matrix\")\nprint(knn_conf_matrix)\nprint(\"\\n\")\nprint(\"Accuracy of k-NN Classification:\",knn_acc_score*100,'\\n')\nprint(classification_report(y_test, knn_predict))","metadata":{"execution":{"iopub.status.busy":"2021-08-09T17:11:16.084035Z","iopub.execute_input":"2021-08-09T17:11:16.084426Z","iopub.status.idle":"2021-08-09T17:11:16.122537Z","shell.execute_reply.started":"2021-08-09T17:11:16.084393Z","shell.execute_reply":"2021-08-09T17:11:16.121675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Yes, We have successfully created a KNNModel with Good accurancy, Precision & F1 Score. \n\nQuestion is, Can we improve ?\n\nAnswer is, yea we can...","metadata":{}},{"cell_type":"markdown","source":"# Fourth Step : Improving the Model / Tunning the Model\n\nHere, we will only tune the Model based on K neighbour numbers..","metadata":{}},{"cell_type":"markdown","source":"What if we change the value of the K neighbours ?\n\nTo answer this, we will write below code to identify the impact on Error improvement with values of K neighbour from 1 to 20. \n\nWe will append the values of Error to have cumulative data of Error rates. ","metadata":{}},{"cell_type":"code","source":"error_rate = []\n\nfor i in range(1,20):\n    \n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train,y_train)\n    pred_i = knn.predict(X_test)\n    error_rate.append(np.mean(pred_i != y_test))","metadata":{"execution":{"iopub.status.busy":"2021-08-09T17:17:42.029904Z","iopub.execute_input":"2021-08-09T17:17:42.030274Z","iopub.status.idle":"2021-08-09T17:17:42.37724Z","shell.execute_reply.started":"2021-08-09T17:17:42.030243Z","shell.execute_reply":"2021-08-09T17:17:42.3762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, we will plot the data Error rate to identify the best suitable values of the K neighbour to have best results.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure(figsize=(10,6))\n\nplt.plot(range(1,20),error_rate,color='green', linestyle='dashed', marker='o',\n         markerfacecolor='red', markersize=5)\nplt.title('Error Rate vs. K Value')\nplt.xlabel('K')\nplt.ylabel('Error Rate')","metadata":{"execution":{"iopub.status.busy":"2021-08-09T17:20:44.352116Z","iopub.execute_input":"2021-08-09T17:20:44.352476Z","iopub.status.idle":"2021-08-09T17:20:44.592443Z","shell.execute_reply.started":"2021-08-09T17:20:44.352446Z","shell.execute_reply":"2021-08-09T17:20:44.591516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"By looking at the above graph, \n\nIt was noted that we have received minimum error at k neighbour value 7 and after that the error value is just oscilating and not going any further down.\n\nSo, We will select 7 as our luck number for KNN classifier..","metadata":{}},{"cell_type":"markdown","source":"# Fifith Step : Recreating a KNN Model","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors=7)\nmodel = knn.fit(X_train, y_train)\nknn_predict = knn.predict(X_test)\nknn_conf_matrix = confusion_matrix(y_test, knn_predict)\nknn_acc_score = accuracy_score(y_test, knn_predict)\nprint(\"confusion matrix\")\nprint(knn_conf_matrix)\nprint(\"\\n\")\nprint(\"Accuracy of k-NN Classification:\",knn_acc_score*100,'\\n')\nprint(classification_report(y_test, knn_predict))","metadata":{"execution":{"iopub.status.busy":"2021-08-09T17:24:44.928426Z","iopub.execute_input":"2021-08-09T17:24:44.928777Z","iopub.status.idle":"2021-08-09T17:24:44.96203Z","shell.execute_reply.started":"2021-08-09T17:24:44.928745Z","shell.execute_reply":"2021-08-09T17:24:44.960934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So final Conclusion is,\n\nBefore tunning: the Model Accuracy of k-NN Classification: 94.05405405405406\n\nAfter tunning: the Model Accuracy of k-NN Classification: 95.4054054054054\n\n# So We get increment of 1.35% in final results for just tunning the one parameter.\n\nThank You for reaching this far.\n\nIf you require any further information please give it in Comment.\n","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}