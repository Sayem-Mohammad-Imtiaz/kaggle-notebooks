{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# -*- coding: utf-8 -*-\n\"\"\"\n\nRef: https://www.kaggle.com/alexpengxiao/preprocessing-model-averaging-by-xgb-lgb-1-39\nAbout Random Projection:\n    https://turi.com/learn/userguide/feature-engineering/random_projection.html\n\nObjectives:\n        i)   Using pandas and sklearn for modeling\n        ii)  Feature engineering\n                  a) Using statistical measures\n                  b) Using Random Projections\n                  c) Using clustering\n                  d) USing interaction variables\n       iii)  Feature selection\n                  a) Using derived feature importance from modeling\n                  b) Using sklearn FeatureSelection Classes\n        iv)  One hot encoding of categorical variables\n         v)  Classifciation using Decision Tree and RandomForest\n\nObservations:\n    1. DTree accuracy has gone from 67% (all features) to 78.12% (13 feature) to 76.9% (20 features)\n    2. Rforest accuracy has gone from 78.3% (all features) to 79.6% (13 feature) to 80.2% (20 features)\n    3. Rforest accuracy is peaking at accuracy of 79.6%    \n\"\"\"\n# 1.0 Clear memory\n%reset -f   ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# 1.1 Call data manipulation libraries\nimport pandas as pd\nimport numpy as np\n# 1.2 Feature creation libraries\nfrom sklearn.random_projection import SparseRandomProjection as sr  # Projection features\nfrom sklearn.cluster import KMeans                    # Cluster features\nfrom sklearn.preprocessing import PolynomialFeatures  # Interaction features\n# 1.3 For feature selection\n# Ref: http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import mutual_info_classif  # Selection criteria\n# 1.4 Data processing\n# 1.4.1 Scaling data in various manner\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, scale\n# 1.4.2 Transform categorical (integer) to dummy\nfrom sklearn.preprocessing import OneHotEncoder\n# 1.5 Splitting data\nfrom sklearn.model_selection import train_test_split\n# 1.6 Decision tree modeling\n# http://scikit-learn.org/stable/modules/classes.html#module-sklearn.tree\n# http://scikit-learn.org/stable/modules/tree.html#tree\nfrom sklearn.tree import  DecisionTreeClassifier as dt\n# 1.7 RandomForest modeling\nfrom sklearn.ensemble import RandomForestClassifier as rf\n# 1.8 Plotting libraries to plot feature importance\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"51410126ad59995830cd8296850b3123b4d39a38"},"cell_type":"code","source":"import os, time, gc\n# General purpose, operating system, time and garbage collection utilities\n################## AA. Reading data from files and exploring ####################\n# 2.0 Set working directory and read file\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"696e024b8a48672f04f1d3f1b413f47d76e1d29a"},"cell_type":"code","source":"# 2.1 Read train/test files\nheart = pd.read_csv(\"../input/heart.csv\")\npd.options.display.max_columns = 300\n# 2.2 Look at data\nheart.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6bafcaff0359c16714d0d52fe606248a47fc9ce2"},"cell_type":"code","source":"heart.shape ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dad9a6f624dc118d1484bb46759a329242e4c39f"},"cell_type":"code","source":"# 2.3 Data types\nheart.dtypes.value_counts()   # All 13 features are integers except target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a24be9c14ac26a7fa785c7096671c7bf87dd4c45"},"cell_type":"code","source":"# 2.4 Target classes are almost balanced\nheart.target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d0bc25228ee2e29a555d864c34dfc0122f28541"},"cell_type":"code","source":"# 3. split the data\nX_train, X_test, y_train, y_test = train_test_split(heart.drop('target', 1), heart['target'], test_size = 0.3, random_state=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0881050987f6e30bbcedca1b6e9a35249ba51026"},"cell_type":"code","source":"# 3.1 Check the splits\nX_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4fcab1cdf2d623678d2913577fb45470f507fd9a"},"cell_type":"code","source":"X_test.shape  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f5ef84f2a3fc089f609e30e65e79435f26b83a6c"},"cell_type":"code","source":"y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b3f4b37eb429f33c68fb1637b12468e0f625e3e1"},"cell_type":"code","source":"y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"079807331619e816815928f2a262dfa770875ecd"},"cell_type":"code","source":"# 3.2 Check if there are Missing values? None\nX_train.isnull().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf455f078b5a0be6acf4c1b331e940dbca8984d9"},"cell_type":"code","source":"X_test.isnull().sum().sum() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a122568cf7b1e0430d688e717775e87981c9dc0"},"cell_type":"code","source":"############################ BB. Feature Engineering #########################\n############################ Using Statistical Numbers #####################\n#  4. Feature 1: Row sums of features 1:13. More successful\n#                when data is binary.\nX_train['sum'] = X_train.sum(numeric_only = True, axis=1)  # numeric_only= None is default","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f5b3639ce4a6e6c974a3439a320430ea1f6e4a5b"},"cell_type":"code","source":"X_test['sum'] = X_test.sum(numeric_only = True,axis=1)     # New colum Sum is added across rows so it is axis 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0384e96a642bbefd1c35accbe434b116195c823a"},"cell_type":"code","source":"# 4.1 Assume that value of '0' in a cell implies missing feature\n#     Transform train and test dataframes\n#     replacing '0' with NaN\n#     Use pd.replace()\ntmp_train = X_train.replace(0, np.nan)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2100f78310d0f5ca21cef25d90224f53b36d3cf6"},"cell_type":"code","source":"tmp_test = X_test.replace(0,np.nan)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"27d8c6a18ad8b37c6a8e00dc54c0776e59525859"},"cell_type":"code","source":"# 4.2 Check if tmp_train is same as train or is a view\n#     of train? That is check if tmp_train is a deep-copy\ntmp_train is X_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"50b9ed4a59a7bf389be58d3942d316cfb233ea04"},"cell_type":"code","source":"tmp_train._is_view","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"44968f25719fa7ac366e489d032a2c9e063de652"},"cell_type":"code","source":"# 4.3 Check if 0 has been replaced by NaN\ntmp_train.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5f62ec9c3335932c688d36cfc73f0e59cf7bed2"},"cell_type":"code","source":"tmp_test.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"77d6f444702d8e7a2682cec983f90eac837132c6"},"cell_type":"code","source":"# 5. Feature 2 : For every row, how many features exist\n#                that is are non-zero/not NaN.\n#                Use pd.notna()\ntmp_train.notna().head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd7280c124dbf431c6e055638c3e5f92139a3a67"},"cell_type":"code","source":"X_train[\"count_not0\"] = tmp_train.notna().sum(axis = 1) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"70f70f133845b035ea7494a2911531641842e086"},"cell_type":"code","source":"X_test['count_not0'] = tmp_test.notna().sum(axis = 1) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6335a28fb81b1cd4b556b03e8cff329c26c9f1da"},"cell_type":"code","source":"# 6. Similary create other statistical features\n#    Feature 3\n#    Pandas has a number of statistical functions\n#    Ref: https://pandas.pydata.org/pandas-docs/stable/reference/frame.html#computations-descriptive-stats\nfeat = [ \"var\", \"median\", \"mean\", \"std\", \"max\", \"min\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0049c3d4860c61a21a2aac7c07e35cf8750d86e"},"cell_type":"code","source":"for i in feat:\n    X_train[i] = tmp_train.aggregate(i,  axis =1)\n    X_test[i]  = tmp_test.aggregate(i,axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ab2d2a94049f7571a94dd3e3950607857ba6bdf"},"cell_type":"code","source":"# 7 Delete not needed variables and release memory\ndel(tmp_train)\ndel(tmp_test)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ecf9139f7a5d95c5921759ce71d4fab6594cbf3a"},"cell_type":"code","source":"# 7.1 So what do we have finally\nX_train.shape                # 212 X (13 + 8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a1439a383365db90ae7d442028b3bdb2cd9aa63"},"cell_type":"code","source":"X_train.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f211e5123a9cfd47fb561334b4a9b03dafd9c44e"},"cell_type":"code","source":"X_test.shape ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"72fc70a5fa5e33daa2cb0543fd0c2c4b8b10c303"},"cell_type":"code","source":"X_test.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3dfcdf59cdea07cf706d29542ab9017497ad6c08"},"cell_type":"code","source":"# 8. Store column names of our data somewhere\n#     We will need these later (at the end of this code)\ncolNames = X_train.columns.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"86d1456185f8b2ac6de0ed7f15a53749b2b7858d"},"cell_type":"code","source":"colNames","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f0d0685b6f0e050b16d1e6043dc0be0e08a38187"},"cell_type":"code","source":"################ Feature creation Using Random Projections ##################\n# 9. Random projection is a fast dimensionality reduction feature\n#     Also used to look at the structure of data\n\n# 10. Generate features using random projections\n#     First stack train and test data, one upon another\ntmp = pd.concat([X_train,X_test],\n                axis = 0,            # Stack one upon another (rbind)\n                ignore_index = True\n                )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7bd8296243f17d1c74fe9ad21140a9942a2c1a3a"},"cell_type":"code","source":"# 10.1\ntmp.shape     # 303 X 21","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf458785392ac5a0135e523861cd8cd18d6aa444"},"cell_type":"code","source":"# 10.2 Transform tmp t0 numpy array\n#      Henceforth we will work with array only\ntmp = tmp.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29f8e392a5bda16849ce305e93f6edf2f061679f"},"cell_type":"code","source":"tmp.shape       # (303, 21)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ead70819dc51dad8e01ff2114600d0431c78f4dc"},"cell_type":"code","source":"# 11. Let us create 5 random projections/columns\n#     This decision, at present, is arbitrary\nNUM_OF_COM = 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"810254c189bfe2960ffcc22500d9ece64f342d69"},"cell_type":"code","source":"# 11.1 Create an instance of class\nrp_instance = sr(n_components = NUM_OF_COM)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"83de1bcc1f01d109687595c1ca728e53fbda38d3"},"cell_type":"code","source":"# 11.2 fit and transform the (original) dataset\n#      Random Projections with desired number\n#      of components are returned\nrp = rp_instance.fit_transform(tmp[:, :13])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9597966e2fea96651c330ce3783bb627e6c01b0f"},"cell_type":"code","source":"# 11.3 Look at some features\nrp[: 5, :  3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5f243fe7d2078ced672f7b4b2efd46acdee51738"},"cell_type":"code","source":"# 11.4 Create some column names for these columns\n#      We will use them at the end of this code\nrp_col_names = [\"r\" + str(i) for i in range(5)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c66a8dee862c110e0b63429b4ec8fcfcf4aeed30"},"cell_type":"code","source":"rp_col_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0aa369b48543936e99a433c83a9aa7e8dffbe5ab"},"cell_type":"code","source":"############################ Feature creation using kmeans ####################\n######################Can be skipped without loss of continuity################\n# 12. Before clustering, scale data\n# 12.1 Create a StandardScaler instance\nse = StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f81dfa592ecb4d52b7b91ecd1ab182fa0829504a"},"cell_type":"code","source":"# 12.2 fit() and transform() in one step\ntmp = se.fit_transform(tmp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c665a605f08207a2f301cc0f67060885113a92d"},"cell_type":"code","source":"# 12.3\ntmp.shape               # 303 X 21 (an ndarray)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd67a4eb5729e2ae1a22625c10fef2eb0d60d3b3"},"cell_type":"code","source":"# 13. Perform kmeans using 13 features.\n#     No of centroids is no of classes in the 'target'\ncenters = y_train.nunique()    # 2 unique classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"37a8140150a7c4dbad7da23575b95218b3bb66c6"},"cell_type":"code","source":"centers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c37d9319d605b99d489422071788cc4fb2a253f3"},"cell_type":"code","source":"# 14.1 Begin clustering\nstart = time.time()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c41aa495c47cd6932adba2aeb6ca5f38076fd783"},"cell_type":"code","source":"# 14.2 First create object to perform clustering\nkmeans = KMeans(n_clusters=centers, # How many\n                n_jobs = 2)         # Parallel jobs for n_init","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68f80b156acca6619ef71f47de46cc23ed7632f2"},"cell_type":"code","source":"# 14.3 Next train the model on the original data only\nkmeans.fit(tmp[:, : 13])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"39c53185a62d652d25a5cbfef082ae68fe40c8a0"},"cell_type":"code","source":"end = time.time()\n(end-start)/60.0 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"be68ede0a69436a7fa3fc62f5219040d3df78d34"},"cell_type":"code","source":"# 15 Get clusterlabel for each row (data-point)\nkmeans.labels_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ebbbf1a969973fd53121859d8ee0a18524f5ac74"},"cell_type":"code","source":"kmeans.labels_.size   # 303","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6a33f647b2adc3ee719004cb8c2dcc2ecf86df57"},"cell_type":"code","source":"# 16. Cluster labels are categorical. So convert them to dummy\n# 16.1 Create an instance of OneHotEncoder class\nohe = OneHotEncoder(sparse = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bac447974f7b1eaface864a03304f208690f8353"},"cell_type":"code","source":"# 16.2 Use ohe to learn data\n#      ohe.fit(kmeans.labels_)\nohe.fit(kmeans.labels_.reshape(-1,1))     # reshape(-1,1) recommended by fit()\n                                          # '-1' is a placeholder for actual","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b41c86e86fbd007774942dff2e7d22471c30d5c"},"cell_type":"code","source":"# 16.3 Transform data now\ndummy_clusterlabels = ohe.transform(kmeans.labels_.reshape(-1,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"db7f0ec8c607531da33a988b45f1ebbc625e5d55"},"cell_type":"code","source":"dummy_clusterlabels.shape    # 303 X 2 (as many as there are classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7992c64de114ce09365a84fa79589a3c8929b5a1"},"cell_type":"code","source":"# 16.4 We will use the following as names of new nine columns\n#      We need them at the end of this code\n\nk_means_names = [\"k\" + str(i) for i in range(2)]\nk_means_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2e92147fa8b0322f06220a7214f55a794725e08d"},"cell_type":"code","source":"############################ Interaction features #######################\n# 15. Will require lots of memory if we take large number of features\n#     Best strategy is to consider only impt features\ndegree = 2\npoly = PolynomialFeatures(degree,                 # Degree 2\n                          interaction_only=True,  # Avoid e.g. square(a)\n                          include_bias = False    # No constant term\n                          )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3232019829ffd174b192baeecb4b65ddb98a4e14"},"cell_type":"code","source":"# 15.1 Consider only first 5 features\n#      fit and transform\ndf =  poly.fit_transform(tmp[:, : 5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"728b09cc7dad1206ca860144b046a86aa38184b8"},"cell_type":"code","source":"df.shape     # 303 X 15","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"76943fc07cd26a151e62574addc5e1b3808c228b"},"cell_type":"code","source":"# 15.2 Generate some names for these 15 columns\npoly_names = [ \"poly\" + str(i)  for i in range(15)]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"845b9c62edee2b49840c360a5463235c25e662ac"},"cell_type":"code","source":"################# concatenate all features now ##############################\n# 16 Append now all generated features together\n# 16 Append random projections, kmeans and polynomial features to tmp array\ntmp.shape          # 303 X 21","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"38f75fd48e80a948f0b489a849dc0d33209d4130"},"cell_type":"code","source":"#  16.1 If variable, 'dummy_clusterlabels', exists, stack kmeans generated\n#       columns also else not. 'vars()'' is an inbuilt function in python.\n#       All python variables are contained in vars().\nif ('dummy_clusterlabels' in vars()):               #\n    tmp = np.hstack([tmp,rp,dummy_clusterlabels, df])\nelse:\n    tmp = np.hstack([tmp,rp, df])       # No kmeans      <==","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0583ada6a76de779ec22421a7696616992208479"},"cell_type":"code","source":"tmp.shape          # 303 X 43   If no kmeans: (303, 21)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f29174d470fc43ad7917c8504297d45ad793175f"},"cell_type":"code","source":"# 16.2 Separate train and test\nX = tmp[: X_train.shape[0], : ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4be87a7341a5194653cb57c09de3fbf094d7bafe"},"cell_type":"code","source":"X.shape                             # 212 X 43 if no kmeans: (212, 21)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc09ddaf4bc7cfb9c47a620c02802277316c91b1"},"cell_type":"code","source":"# 16.3\ntest = tmp[X_train.shape[0] :, : ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"130516f679c8870dbd84800b39c4e9666b6e50d6"},"cell_type":"code","source":"test.shape                         #  91 X 43; if no kmeans: (91, 21)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f00c6c13eb163c35f2940909780a0ceac41170de"},"cell_type":"code","source":"# 16.4 Delete tmp\ndel tmp\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0b52d2711714ca1e8888f02beb545e293a38667a"},"cell_type":"code","source":"################## Model building #####################\n# 17. Split train into training and validation dataset\nX_train, X_test, y_train, y_test = train_test_split(\n                                                    X,\n                                                    y_train,\n                                                    test_size = 0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"246ef0edbc7a74c3166f9e5b5a2728584c1163ff"},"cell_type":"code","source":"X_train.shape  # 148 X 43","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"80cda830700b0ce637fdafa1ad071a567cec0948"},"cell_type":"code","source":"X_test.shape   # 64 X 43","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"045ca7f032f8ce66a7cc7c64828df03e05e0a5db"},"cell_type":"code","source":"# 18 Decision tree classification\n# 18.1 Create an instance of class\nclf = dt(min_samples_split = 5,\n         min_samples_leaf= 5\n        )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"85bc29fa6a4bd32087e7aef4f732a048fdf132fc"},"cell_type":"code","source":"start = time.time()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b2a3eb73c4a504b019af1484e73845f989ec90b"},"cell_type":"code","source":"# 18.2 Fit/train the object on training data\n#      Build model\nclf = clf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d9a506e6fc6a93d4454780d79512f2f10203d4a"},"cell_type":"code","source":"end = time.time()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0ba89bcac2b228a026195ecaa8db723172491b46"},"cell_type":"code","source":"(end-start)/60","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"de46cae2f8458370917bf6762ffefec55df74373"},"cell_type":"code","source":"# 18.3 Use model to make predictions\nclasses = clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b7d38427290eec3cf60f49e62576da655aaeafd8"},"cell_type":"code","source":"# 18.4 Check accuracy\n(classes == y_test).sum()/y_test.size   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf313f213350bf1d30e122420cba954698e6a55e"},"cell_type":"code","source":"# 19. Instantiate RandomForest classifier\nclf = rf(n_estimators=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d28981e72b6ef05db86d182fc034065e01c36978"},"cell_type":"code","source":"# 19.1 Fit/train the object on training data\n#      Build model\nstart = time.time()\nclf = clf.fit(X_train, y_train)\nend = time.time()\n(end-start)/60  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3933a09a06fab6f414b3dbd5380c00c75f2794ea"},"cell_type":"code","source":"# 19.2 Use model to make predictions\nclasses = clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4bd9c34067a071e8f280c7dc424e62aa5a37148d"},"cell_type":"code","source":"# 19.3 Check accuracy\n(classes == y_test).sum()/y_test.size     # 0.796875","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"46ba5cb7cbec9de70ca9ff534687f42d6cecd0d1"},"cell_type":"code","source":"################## Feature selection #####################\n##****************************************\n## Using feature importance given by model\n##****************************************\n# 20. Get feature importance\nclf.feature_importances_        # Column-wise feature importance","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52c69045cfacdac445fc617e763f8757fd9fd27c"},"cell_type":"code","source":"clf.feature_importances_.size   # 43","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b00a250cd1f50836c5363f6397ae9c17c3d31f68"},"cell_type":"code","source":"# 20.1 To our list of column names, append all other col names\n#      generated by random projection, kmeans (onehotencoding)\n#      and polynomial features\n#      But first check if kmeans was used to generate features\n\nif ('dummy_clusterlabels' in vars()):       # If dummy_clusterlabels labels are defined\n    colNames = list(colNames) + rp_col_names+ k_means_names + poly_names\nelse:\n    colNames = colNames = list(colNames) + rp_col_names +  poly_names      # No kmeans      <==","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aabeeec6ff3b2f2f5f918e474b0316cd9ad6f772"},"cell_type":"code","source":"# 20.1.1 So how many columns?\nlen(colNames)           # 43 with kmeans else 21","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11f1d4e066cbc07baafb9f2651c07d9977649d39"},"cell_type":"code","source":"# 20.2 Create a dataframe of feature importance and corresponding\n#      column names. Sort dataframe by importance of feature\nfeat_imp = pd.DataFrame({\n                   \"importance\": clf.feature_importances_ ,\n                   \"featureNames\" : colNames\n                  }\n                 ).sort_values(by = \"importance\", ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b6b74187e67b19e5506df859cc278bb9bc8bc32e"},"cell_type":"code","source":"feat_imp.shape                   # 43 X 2 ; without kmeans: (21,2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a003903c35e27f3401f9ce313d6539dc8bc9d2f"},"cell_type":"code","source":"feat_imp.head(30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b6109ff8c17e2faadf887af0c0ee99937e236e44"},"cell_type":"code","source":"# 20.3 Plot feature importance for first 30 features\ng = sns.barplot(x = feat_imp.iloc[  : 30 ,  1] , y = feat_imp.iloc[ : 30, 0])\ng.set_xticklabels(g.get_xticklabels(),rotation=90)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}