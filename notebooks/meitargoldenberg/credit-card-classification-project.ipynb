{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data information","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Dataset Information:**\nThis dataset contains information on default payments, \ndemographic factors, credit data, history of payment, and bill statements of credit card clients in Taiwan from April 2005 to September 2005. \n\n---\n**Dependent Variable:**\n* Dependent Variable (y_pred) : default.payment.next.month\n* Classes: 1=yes (78%) , 0=no (22%)\n* Question: Will the Client be able to pay next month bill?\n---\n**Content:**\n\nThere are 25 basic variables:\n\n* ID: ID of each client.\n\n* LIMIT_BAL: Amount of given credit in NT dollars (includes individual and family/supplementary credit.\n\n* SEX: Gender (1=male, 2=female)\n\n* EDUCATION: (1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown)\n\n* MARRIAGE: Marital status (1=married, 2=single, 3=others,0=others)\n\n* AGE: Age in years\n\n* PAY_0: Repayment status in September, 2005 (-2 = No payment needed, 0= Rolling credit, -1=pay duly, 1=payment delay for one month, 2=payment delay for two months, â€¦ 8=payment delay for eight months, 9=payment delay for nine months and above)\n\n* PAY_2: Repayment status in August, 2005 (scale same as above)\n\n* PAY_3: Repayment status in July, 2005 (scale same as above)\n\n* PAY_4: Repayment status in June, 2005 (scale same as above)\n\n* PAY_5: Repayment status in May, 2005 (scale same as above)\n\n* PAY_6: Repayment status in April, 2005 (scale same as above)\n\n* BILL_AMT1: Amount of bill statement in September, 2005 (NT dollar)\n\n* BILL_AMT2: Amount of bill statement in August, 2005 (NT dollar)\n\n* BILL_AMT3: Amount of bill statement in July, 2005 (NT dollar)\n\n* BILL_AMT4: Amount of bill statement in June, 2005 (NT dollar)\n\n* BILL_AMT5: Amount of bill statement in May, 2005 (NT dollar)\n\n* BILL_AMT6: Amount of bill statement in April, 2005 (NT dollar)\n\n* PAY_AMT1: Amount of previous payment in September, 2005 (NT dollar)\n\n* PAY_AMT2: Amount of previous payment in August, 2005 (NT dollar)\n\n* PAY_AMT3: Amount of previous payment in July, 2005 (NT dollar)\n\n* PAY_AMT4: Amount of previous payment in June, 2005 (NT dollar)\n\n* PAY_AMT5: Amount of previous payment in May, 2005 (NT dollar)\n\n* PAY_AMT6: Amount of previous payment in April, 2005 (NT dollar)\n\n* default.payment.next.month: Default payment (1=yes, 0=no)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# EDA","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Import & files export","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# General tools\nimport pandas as pd\nimport numpy as np\nimport statistics as stat\nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set(style=\"ticks\", color_codes=True)\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.feature_selection import SelectKBest, f_classif,chi2\nfrom itertools import product\nfrom sklearn.model_selection import train_test_split as split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_curve, roc_auc_score\nimport math\nimport statsmodels.formula.api as smf\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.externals.six import StringIO\nfrom IPython.display import Image\nimport pydot\nfrom sklearn import metrics\n\n# For transformations and predictions\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import VotingClassifier, BaggingClassifier,AdaBoostClassifier, GradientBoostingClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Imprt file to df\ncredit = pd.read_csv(\"/kaggle/input/default-of-credit-card-clients-dataset/UCI_Credit_Card.csv\")\ncredit.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"credit.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Unique values per each feature\ncredit.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decribe of Data set\ncredit.describe(include='all').T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Features Creation[](http://)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### First Steps","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# renaming field PAY_0 to PAY_1\ncredit.rename(columns={\"PAY_0\": \"PAY_1\",\"default.payment.next.month\":\"default\"},inplace=True)\n\n# Aggregating Unknown educations type\neducation_dict = {2:3,3:2,4:0,5:0,6:0}\ncredit.EDUCATION.replace(education_dict,inplace=True)\n\n# Adding field names descriptions\ncredit[\"SEX_desc\"] = credit[\"SEX\"].replace({1: \"Male\", 2: \"Female\"})\ncredit[\"EDUCATION_desc\"] = credit[\"EDUCATION\"].replace({0:\"Other\",1:\"Graduate School\", 2:\"High School\",3:\"University\"})\ncredit[\"MARRIAGE_desc\"] = credit[\"MARRIAGE\"].replace({1: \"Married\", 2: \"Single\",0:\"Other\",3:\"Other\"})\n\n#----------------------------------------------------------\n#???\ncredit[\"cum_pay\"]=credit[\"PAY_AMT1\"]+credit[\"PAY_AMT2\"]+credit[\"PAY_AMT3\"]+credit[\"PAY_AMT4\"]+credit[\"PAY_AMT5\"]\ncredit[\"cum_bill\"]=(credit[\"BILL_AMT2\"]+credit[\"BILL_AMT3\"]+credit[\"BILL_AMT4\"]+credit[\"BILL_AMT5\"]+credit[\"BILL_AMT6\"])\n\ncredit[\"percent_paid\"]=(credit[\"cum_pay\"]/credit[\"cum_bill\"])\n(credit[\"percent_paid\"]).replace([np.inf, -np.inf], np.nan,inplace=True)\ncredit[\"percent_paid\"].fillna(0,inplace=True)\ncredit[\"percent_paid\"]=round(credit[\"percent_paid\"],2)\n#------------------------------------------------------------\n# Concatenating all PAY Fields into 1 Field (3\\6 months)\ncredit['con']=credit['PAY_1'].astype(str) +\";\" +credit['PAY_2'].astype(str)+\";\" +credit['PAY_3'].astype(str) +\";\" +credit['PAY_4'].astype(str)+\";\" +credit['PAY_5'].astype(str)+\";\" +credit['PAY_6'].astype(str) \ncredit['con_3_months'] = credit['PAY_1'].astype(str) +\";\" +credit['PAY_2'].astype(str)+\";\" +credit['PAY_3'].astype(str)\n\ndelay = ['PAY_1','PAY_2','PAY_3','PAY_4','PAY_5','PAY_6']\ncredit[\"max_delay\"]=credit[delay].max(axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Aggregated Features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Recognizing Rolling credit of the 6 months using PAY_i = 0\nroll_dict =  {'1':lambda row: int(row[\"PAY_1\"] == 0),\n              '2':lambda row: int(row[\"PAY_2\"] == 0),\n              '3':lambda row: int(row[\"PAY_3\"] == 0),\n              '4':lambda row: int(row[\"PAY_4\"] == 0),\n              '5':lambda row: int(row[\"PAY_5\"] == 0),\n              '6':lambda row: int(row[\"PAY_6\"] == 0)}\n\nfor k,v in roll_dict.items():\n   c = 'Roll_PAY_{}'.format(k)\n   credit[c] = credit.apply(v,axis=1)\n\n# Qnt of rolls over 3/6 months\ncredit['Total_Roll'] =  credit['Roll_PAY_1'] + credit['Roll_PAY_2'] + credit['Roll_PAY_3'] + credit['Roll_PAY_4'] + credit['Roll_PAY_5'] + credit['Roll_PAY_6']\ncredit['Three_Months_Roll'] =  credit['Roll_PAY_1'] + credit['Roll_PAY_2'] + credit['Roll_PAY_3']\n#-------------------------------------------------------------\n# Counting Amount of delays in 3\\6 Months\nTotal_Delays = lambda row: int(row[\"PAY_1\"]>0)+int(row[\"PAY_2\"]>0)+int(row[\"PAY_3\"]>0)+int(row[\"PAY_4\"]>0)+int(row[\"PAY_5\"]>0)+int(row[\"PAY_6\"]>0)\nThree_Months_Delays = lambda row: int(row[\"PAY_1\"]>0)+int(row[\"PAY_2\"]>0)+int(row[\"PAY_3\"]>0)\n                                                                         \ncredit['Total_Delays'] = credit.apply(Total_Delays,axis=1)\ncredit['Three_Months_Delays'] = credit.apply(Three_Months_Delays,axis=1)\n#-------------------------------------------------------------\n# Calculating the Trends\n# we calculate the trend in the status, every month we calculate the status today minus the best ever for the client (the min is the best)\ndict={'1':lambda row: min(int(row[\"PAY_2\"]),int(row[\"PAY_3\"]),int(row[\"PAY_4\"]),int(row[\"PAY_5\"]),int(row[\"PAY_6\"])),\n      '2':lambda row: min(int(row[\"PAY_3\"]),int(row[\"PAY_4\"]),int(row[\"PAY_5\"]),int(row[\"PAY_6\"])),\n      '3':lambda row: min(int(row[\"PAY_4\"]),int(row[\"PAY_5\"]),int(row[\"PAY_6\"])),\n      '4':lambda row: min(int(row[\"PAY_5\"]),int(row[\"PAY_6\"])),\n      '5':lambda row: int(row[\"PAY_6\"])}\n\nfor k,v in dict.items():\n   b = 'trend_{}'.format(k) #minus is a good trend\n   c = 'PAY_{}'.format(k)\n   credit['max_Step1'] = credit.apply(v,axis=1)\n   credit['max_Step2'] = credit['max_Step1'].replace(-2,-1)\n   credit[b] = credit[c].replace(-2,-1) - credit['max_Step2']\n  \n#credit.drop(['max_Step1','max_Step2'],axis=1,inplace=True)\n\n# The mean of the trends for 3\\6 Months\ncredit['mean_trend'] = credit[['trend_1','trend_2','trend_3','trend_4','trend_5']].mean(axis=1)\ncredit['mean_trend_3_months'] = credit[['trend_1','trend_2']].mean(axis=1)\n#--------------------------------------------------------------\n# Deviations of Last 3/6 months\n# (All bills of [n months]) / Limit balance* [n months]\n\nDeviation = lambda row: (int(row[\"BILL_AMT1\"]) + int(row[\"BILL_AMT2\"]) + int(row[\"BILL_AMT3\"]) + int(row[\"BILL_AMT4\"]) + int(row[\"BILL_AMT5\"]) + int(row[\"BILL_AMT6\"])) / (int(row[\"LIMIT_BAL\"]) * 6)\nDeviation_3_months = lambda row: (int(row[\"BILL_AMT1\"]) + int(row[\"BILL_AMT2\"]) + int(row[\"BILL_AMT3\"])) / (int(row[\"LIMIT_BAL\"]) * 3)\n\ncredit['Deviation'] = credit.apply(Deviation,axis=1)\ncredit['Deviation_3_months'] = credit.apply(Deviation_3_months,axis=1)\n#----------------------------------------------------------------\n# 5 fields of ratio between the payment and the bill (How much we paid from bill).\nfor i in range(1,6):\n  a,b,c = 'Pay_from_Bill_{}'.format(i) , 'PAY_AMT{}'.format(i) , 'BILL_AMT{}'.format(i+1)\n  credit[a] = credit[b] / credit[c]\n  credit[a].replace([np.inf, -np.inf], np.nan,inplace=True)\n  credit[a].fillna(0,inplace=True)\n\ncredit['mean_pay_from_Bill'] = credit[['Pay_from_Bill_1','Pay_from_Bill_2','Pay_from_Bill_3','Pay_from_Bill_4','Pay_from_Bill_5']].mean(axis=1)\n#------------------------------------------------------------------\n# Counting How many times paid less from the bill for (3\\6 months)\ncount_out_of_bill = lambda row: int(row[\"Pay_from_Bill_1\"]<1)+int(row[\"Pay_from_Bill_2\"]<1)+int(row[\"Pay_from_Bill_3\"]<1)+int(row[\"Pay_from_Bill_4\"]<1)+int(row[\"Pay_from_Bill_5\"]<1)\ncount_out_of_bill_3_months = lambda row: int(row[\"Pay_from_Bill_1\"]<1)+int(row[\"Pay_from_Bill_2\"]<1)+int(row[\"Pay_from_Bill_3\"]<1)\n                                                                         \ncredit['count_out_of_bill'] = credit.apply(count_out_of_bill,axis=1)\ncredit['count_out_of_bill_3_months'] = credit.apply(count_out_of_bill_3_months,axis=1)\n#-------------------------------------------------------------------\n# Standard deviation pay to bill - std(all payments) / std(all bills)\ncredit['std_pay_to_bill_temp1'] = credit[[\"PAY_AMT1\",\"PAY_AMT2\",\"PAY_AMT3\",\"PAY_AMT4\",\"PAY_AMT5\"]].std(axis=1)\ncredit['std_pay_to_bill_temp2'] =  credit[[\"BILL_AMT2\",\"BILL_AMT3\",\"BILL_AMT4\",\"BILL_AMT5\",\"BILL_AMT6\"]].std(axis=1)\n\ndef value_0(row):\n  if row.loc['std_pay_to_bill_temp2'] ==0:\n    return 0\n  else:\n    return row.loc['std_pay_to_bill_temp1'] / row.loc['std_pay_to_bill_temp2']\n  \ncredit['std_pay_to_bill'] = credit.apply(value_0,axis=1)\n\ncredit.drop(['std_pay_to_bill_temp1','std_pay_to_bill_temp2'],axis=1,inplace=True)\n#-------------------------------------------------------------------\n# trend Pay_from_Bill_1         [Pay_from_Bill_1 / (avg of all other pay from bill)]\ncredit['trend_pay_from_bill_1'] = credit[[\"Pay_from_Bill_2\",\"Pay_from_Bill_3\",\"Pay_from_Bill_4\",\"Pay_from_Bill_5\"]].mean(axis=1)\n#--------------------------------------------------------------------\n# quantile trend Pay_from_Bill_1         [Pay_from_Bill_1 / (quantile of all other pay from bill)]\ncredit[\"quantile_pay_from_bill_1\"] = credit[\"Pay_from_Bill_1\"] / credit[[\"Pay_from_Bill_2\",\"Pay_from_Bill_3\",\"Pay_from_Bill_4\",\"Pay_from_Bill_5\"]].quantile(axis=1)\n#--------------------------------------------------------------------\n# PAY_AMT6 / mean(PAY_AMT1-6)\ncredit['mean_pay_temp'] = credit[[\"PAY_AMT1\",\"PAY_AMT2\",\"PAY_AMT3\",\"PAY_AMT4\",\"PAY_AMT5\"]].mean(axis=1)\ncredit['pay6_mean_1_to_6'] = credit['PAY_AMT6'] / credit['mean_pay_temp']\n\ncredit.drop(['mean_pay_temp'],axis=1,inplace=True)\n#---------------------------------------------------------------------\n# std(PAY_AMT1-5) / mean(PAY_AMT1-6)\ncredit['stdev_pay_temp'] = credit[[\"PAY_AMT1\",\"PAY_AMT2\",\"PAY_AMT3\",\"PAY_AMT4\",\"PAY_AMT5\"]].std(axis=1)\ncredit['avg_pay_temp'] = credit[[\"PAY_AMT1\",\"PAY_AMT2\",\"PAY_AMT3\",\"PAY_AMT4\",\"PAY_AMT5\",\"PAY_AMT6\"]].mean(axis=1)\ncredit['std_to_mean_pays'] = credit['stdev_pay_temp'] / credit['avg_pay_temp']\n\ncredit.drop(['stdev_pay_temp','avg_pay_temp'],axis=1,inplace=True)\n#-----------------------------------------------------------------------\n# stdev(BILL_AMT_1-6) / mean(BILL_AMT_1-6)\ncredit['stdev_bill_temp'] = credit[[\"BILL_AMT1\",\"BILL_AMT2\",\"BILL_AMT3\",\"BILL_AMT4\",\"BILL_AMT5\",\"BILL_AMT6\"]].std(axis=1)\ncredit['mean_bill_temp'] = credit[[\"BILL_AMT1\",\"BILL_AMT2\",\"BILL_AMT3\",\"BILL_AMT4\",\"BILL_AMT5\",\"BILL_AMT6\"]].mean(axis=1)\ncredit['std_to_mean_bill'] = credit['stdev_bill_temp'] / credit['mean_bill_temp'] # change the name to the opposite\n\ncredit.drop(['stdev_bill_temp','mean_bill_temp'],axis=1,inplace=True)\n#------------------------------------------------------------------------\n# replacing nan\\inf values with zero\ncredit.replace([np.inf, -np.inf], np.nan,inplace=True)\ncredit.fillna(0,inplace=True)\n#------------------------------------------------------------------------\n# Changing education values\neducation_dict = {2:3,3:2,4:0,5:0,6:0}\ncredit.EDUCATION.replace(education_dict,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Flag Fields for Outliers","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# No bills for all 6 months\nno_bill = credit[(credit.BILL_AMT1==0)&(credit.BILL_AMT2==0) & (credit.BILL_AMT3==0)&(credit.BILL_AMT4==0)&(credit.BILL_AMT5==0)&(credit.BILL_AMT6==0)]\nno_bill['group'] = 0\n\ndef no_bill(row):\n  if ((row['BILL_AMT1']==0)&(row['BILL_AMT2']==0)&(row['BILL_AMT3']==0)&(row['BILL_AMT4']==0)&(row['BILL_AMT5']==0)&(row['BILL_AMT6']==0)):\n    return 1\n  else:\n    return 0\ncredit['no_bill_flag'] = credit.apply(no_bill, axis=1)\ncredit.no_bill_flag.value_counts()  \n#----------------------------------------------------------\n# Total bills is lower then zero\ncredit['Total_Bills_LIMIT_BAL'] = (credit.BILL_AMT1 + credit.BILL_AMT2 + credit.BILL_AMT3 + credit.BILL_AMT4 + credit.BILL_AMT5 + credit.BILL_AMT6) / (credit.LIMIT_BAL)\ncredit['group'] = 0\ntest_2 = credit[credit.Total_Bills_LIMIT_BAL < 0]\n\ndef Total_bills(row):\n    if row['Total_Bills_LIMIT_BAL'] < 0:\n      return 1\n    else:\n      return 0\n\ncredit['Total_Bills_LIMIT_BAL_flag'] = credit.apply(Total_bills, axis=1)\n\ncredit.drop(['Total_Bills_LIMIT_BAL','group'],axis=1,inplace=True)\n#---------------------------------------------------------\n# Total Pay \\ Total Bills is lower than 0\\higher than 1\n# credit['Total_of_Total'] = (credit.cum_pay)/(credit.cum_bill)\ncredit['group'] = 0\ntest_3 = credit[(credit.percent_paid < 0)]\ntest_3.groupby('group')['default'].sum() / test_3.groupby('group')['default'].count()\n\ndef Total_of_Total_zero(row):\n    if row['percent_paid'] < 0:\n      return 1\n    else:\n      return 0\n\ncredit['Total_of_Total_zero_flag'] = credit.apply(Total_of_Total_zero, axis=1)\n\n#-----------------------------------------------------------------------------------------------------\n\ncredit['group'] = 0\ntest_4 = credit[(credit.percent_paid > 1) ]\ntest_4=test_4.groupby('group')['default'].sum() / test_4.groupby('group')['default'].count()\n\ndef Total_of_Total_one(row):\n    if row['percent_paid'] > 1:\n      return 1\n    else:\n      return 0\n\ncredit['Total_of_Total_one_flag'] = credit.apply(Total_of_Total_zero, axis=1)\ncredit.drop(['group'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Account Ranking","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating Account rate using the 6 PAY fields and by metric\n\n# 1. Converting PAY values into sutible rank\ndict_convert={0:1,-2:1.3,-1:1.4,1:2.5,2:3,3:6,4:6,5:6,6:6,7:6,8:6}\n\ncredit['PAY_LM'] = credit['PAY_1']\ncredit.PAY_LM.replace(dict_convert,inplace=True)\n\nfor i in range(1,7):\n  def metric_prep(row):\n    a = {v for k, v in dict_convert.items() if row.loc['PAY_{}'.format(i)] == k}\n    a = str(a)\n    return float(a.replace('{','').replace('}',''))\n  credit['metric_prep_{}'.format(i)] = credit.apply(metric_prep,axis=1)\n  \n# 2. Creating unique data frame with all combinations of PAY fields\nunique_values = credit[['metric_prep_1','metric_prep_2','metric_prep_3','metric_prep_4','metric_prep_5','metric_prep_6']].drop_duplicates()\nunique_values['Rate_key'] =  unique_values['metric_prep_1'].astype(str) +\";\" +unique_values['metric_prep_2'].astype(str) +\";\" +unique_values['metric_prep_3'].astype(str) +\";\" +unique_values['metric_prep_4'].astype(str) +\";\" +unique_values['metric_prep_5'].astype(str) +\";\" +unique_values['metric_prep_6'].astype(str)\ncredit['Rate_key']=credit['metric_prep_1'].astype(str) +\";\" +credit['metric_prep_2'].astype(str)+\";\" +credit['metric_prep_3'].astype(str) +\";\" +credit['metric_prep_4'].astype(str)+\";\" +credit['metric_prep_5'].astype(str)+\";\" +credit['metric_prep_6'].astype(str) \n\n# 3. Taking the main combinations (with most of the data) and use them as comparison group\nrate1 = [1,1,1,1,1,1]             #  0 0 0 0 0 0 10.4%  9821 obs\nrate2 = [1.3,1.3,1.3,1.3,1.3,1.3] # -2-2-2-2-2-2 13.4%  2109 obs\nrate3 = [1.4,1.4,1.4,1.4,1.4,1.4] # -1-1-1-1-1-1 14.2%  1992 obs\nrate4 = [2.5,1.3,1.3,1.3,1.3,1.3] # 1-2-2-2-2-2  36%     651 obs\nrate5 = [5,5,5,5,5,5]             # 2 2 2 2 2 2  77.5%   530 obs\n\n# 4. Using euclidean distance metric + weights over months\nweights = [6/21,5/21,4/21,3/21,2/21,1/21]\n\ndef euclidean_distance(pt1,pt2):\n  distance = 0\n  for i,j in zip(range(len(pt1)),weights) :\n    distance += j * (pt1[i] - pt2[i]) ** 2\n  return distance ** 0.5  \n  return distance\n\n# 5. Converting unique_values df into list and than running each row and comparing it combination to the 5 ratings.\n# We'll take the closest rate by using min func (the min distnace) and than tag the row to the closest rate\ns=[]\nfor row in unique_values.values.tolist():\n  Rate_1 = (euclidean_distance(row,rate1))\n  Rate_2 = (euclidean_distance(row,rate2))\n  Rate_3 = (euclidean_distance(row,rate3))\n  Rate_4 = (euclidean_distance(row,rate4))\n  Rate_5 = (euclidean_distance(row,rate5))\n\n  dict={'Rate_1':Rate_1,'Rate_2':Rate_2,'Rate_3':Rate_3,'Rate_4':Rate_4,'Rate_5':Rate_5}\n  s.append(list(dict.keys())[list(dict.values()).index(min(dict.values()))])\n\n# 6. Merge between data frames\n# 6.1 Converting data from list into df (and this how it looks like)\nRating_df = pd.DataFrame(data=s, index=None, columns=None, dtype=None, copy=False)\nRating_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 6.2 Join between the tag (Rate_i) to it's relevant key (using index as the key)\nunique_values.reset_index(inplace=True)\nfull_Rating_df = unique_values.join(Rating_df)\n\nfull_Rating_df.drop(['index','metric_prep_1','metric_prep_2','metric_prep_3','metric_prep_4','metric_prep_5','metric_prep_6'],axis=1,inplace=True)\nfull_Rating_df.rename(columns={0:\"score_rate\"},inplace=True)\n# And this is how it looks after the join\nfull_Rating_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 6.3 Join between the main df (credit) and the tagging data frame (full_Rating_df)\ncredit_rank = credit.merge(full_Rating_df,left_on='Rate_key',right_on='Rate_key',how='left')\ncredit_rank.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 7 Validating the new tagging field\n# 7.1 Ratio for default\ncredit_rank.groupby('score_rate')['default'].sum() / credit_rank.groupby('score_rate')['default'].count()\n\n#7.2 Values Amount\nexample=credit_rank[(credit_rank.score_rate=='Rate_5')]\nexample.con.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Rounding ratio fields","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Rounding the values for ration features\ncredit_rank[\"Deviation2\"]=round(credit_rank[\"Deviation\"],3)\ncredit_rank[\"AGE1\"]=round(credit_rank[\"AGE\"]/10,0)\ncredit_rank[\"AGE_round\"]=round(credit_rank[\"AGE\"]/5,0)\ncredit_rank['Deviation_round']=round(credit_rank['Deviation2']*10)\ncredit_rank['Deviation_round'].value_counts()\ncredit_rank['Pay_from_Bill_1_round']=round(credit_rank['Pay_from_Bill_1']*10) \ncredit_rank['Pay_from_Bill_1_round'].value_counts()\ncredit_rank['mean_pay_from_Bill_round']=round(credit_rank['mean_pay_from_Bill']*10) \ncredit_rank['mean_pay_from_Bill_round'].value_counts() \ncredit_rank['trend_pay_from_bill_round']=round(credit_rank['trend_pay_from_bill_1']*10) \ncredit_rank['trend_pay_from_bill_round'].value_counts().head(20) \n\ncredit_rank[\"dev*limit_bal_\"]=(credit_rank[\"Deviation2\"]*credit_rank[\"LIMIT_BAL\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dummy variables & drop fields","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping unnecesary fields\ncredit_rank.drop(['cum_pay','cum_bill','AGE','BILL_AMT1','max_Step1','max_Step2','mean_trend_3_months','Deviation','Deviation_3_months','Pay_from_Bill_1',\n                  'mean_pay_from_Bill','std_pay_to_bill','trend_pay_from_bill_1','quantile_pay_from_bill_1','pay6_mean_1_to_6','std_to_mean_pays','std_to_mean_bill',\n                  'Deviation2','AGE1'],axis=1,inplace=True)\n\n# Dropping unnecesary fields\ncredit_rank.drop(['ID','PAY_1','PAY_2','PAY_3','PAY_4','PAY_5','PAY_6','BILL_AMT2','BILL_AMT3','BILL_AMT4','BILL_AMT5','BILL_AMT6',\n                  'PAY_AMT1','PAY_AMT2','PAY_AMT5','PAY_AMT3','PAY_AMT4','PAY_AMT6','SEX','EDUCATION','MARRIAGE','con','con_3_months',\n                  'Roll_PAY_2','Roll_PAY_3','Roll_PAY_4','Roll_PAY_5','Roll_PAY_6',\n                  'trend_2','trend_3','trend_4','trend_5',\n                  'Pay_from_Bill_2','Pay_from_Bill_3','Pay_from_Bill_4','Pay_from_Bill_5',\n                  'metric_prep_1','metric_prep_2','metric_prep_3','metric_prep_4','metric_prep_5','metric_prep_6','Rate_key',\n                  ],axis=1,inplace=True)\n#--------------------------------------------------------------------------------\n# Dummies\n# Creating Dummies for logistic regression \\ KNN\ncredit_rank_1 = credit_rank.copy() # for decision tree \n\nSEX_field = pd.get_dummies(credit_rank.SEX_desc,prefix='SEX').iloc[:,1:]\ncredit_rank = pd.concat([credit_rank,SEX_field],axis=1)\n\nEDUCATION_field = pd.get_dummies(credit_rank.EDUCATION_desc,prefix='EDUCATION').iloc[:,1:]\ncredit_rank = pd.concat([credit_rank,EDUCATION_field],axis=1)\n\nMARRIAGE_field = pd.get_dummies(credit_rank.MARRIAGE_desc,prefix='MARRIAGE').iloc[:,1:]\ncredit_rank = pd.concat([credit_rank,MARRIAGE_field],axis=1)\n\nscore_rate_field = pd.get_dummies(credit_rank.score_rate,prefix='score_rate').iloc[:,1:]\ncredit_rank = pd.concat([credit_rank,score_rate_field],axis=1)\n\n\n# for decision tree / random forest\nSEX_field = pd.get_dummies(credit_rank_1.SEX_desc,prefix='SEX')\ncredit_rank_1 = pd.concat([credit_rank_1,SEX_field],axis=1)\n\nEDUCATION_field = pd.get_dummies(credit_rank_1.EDUCATION_desc,prefix='EDUCATION')\ncredit_rank_1 = pd.concat([credit_rank_1,EDUCATION_field],axis=1)\n\nMARRIAGE_field = pd.get_dummies(credit_rank_1.MARRIAGE_desc,prefix='MARRIAGE')\ncredit_rank_1 = pd.concat([credit_rank_1,MARRIAGE_field],axis=1)\n\nscore_rate_field = pd.get_dummies(credit_rank_1.score_rate,prefix='score_rate')\ncredit_rank_1 = pd.concat([credit_rank_1,score_rate_field],axis=1)\n\ncredit_rank_1.drop(['SEX_desc','EDUCATION_desc','MARRIAGE_desc','score_rate'],axis=1,inplace=True)\ncredit_rank.drop(['SEX_desc','EDUCATION_desc','MARRIAGE_desc','score_rate'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Graphic Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_1 = credit[credit['default'] == 1]\ndf_0 = credit[credit['default'] == 0]\nx_field = 'LIMIT_BAL'\ntitle = 'LIMIT_BAL Distribution'\n#plt.xlim(0, 10) \nax = sns.distplot(round(df_0[x_field],0), kde=False, label = 'No Default')\nax = sns.distplot(round(df_1[x_field],0), kde=False, label = 'Default')\nax.set_title(title)\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_1 = credit[credit['default'] == 1]\ndf_0 = credit[credit['default'] == 0]\nx_field = 'max_delay'\ntitle = 'max_delay Distribution'\n#plt.xlim(-1, 2) \nax = sns.distplot(round(df_0[x_field],0), kde=False, label = 'No Default')\nax = sns.distplot(round(df_1[x_field],0), kde=False, label = 'Default')\nax.set_title(title)\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"credit[\"limit_1000\"]=credit[\"LIMIT_BAL\"]/1000\n(credit.groupby('limit_1000')['default'].sum() / credit.groupby('limit_1000')['default'].count()).plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"credit.groupby('PAY_1')['default'].count().plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Histogram\ncredit[['AGE','EDUCATION','MARRIAGE','LIMIT_BAL',\n        'BILL_AMT1','BILL_AMT2','BILL_AMT3',\n        'BILL_AMT4','BILL_AMT5','PAY_1','PAY_2','PAY_3',\n        'PAY_4','PAY_5','PAY_6']].hist(figsize=(30, 30),color=(\"c\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #???\n\n# # Pairplot graph\n# # I checked the default 0/1 and changed 0-->1 1--->0\n# # can we use delete to drop credit_3 at the end?\n\n\n# credit[\"def_desc\"] = credit[\"default\"].replace({0: \"no-def\", 1: \"def\"})\n\n# a = sns.pairplot(credit[['LIMIT_BAL','PAY_1','BILL_AMT1','PAY_AMT1','def_desc',\n#                        'Total_Roll','Total_Delays','mean_trend','Deviation']],hue='def_desc')\n                       \n# a.fig.set_size_inches(22,22)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Comparing defaults classes by main metrics\nprint(credit.groupby('default')[['Total_Delays','Three_Months_Delays',\n                                 'Total_Roll','Three_Months_Roll',\n                                 'mean_trend','mean_trend_3_months',\n                                 'Deviation','Deviation_3_months',\n                                 'mean_pay_from_Bill',\n                                 'count_out_of_bill','count_out_of_bill_3_months']].agg(['mean','min','max']).T)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Comparing default classes by mean_pay_from_Bill & Deviation (size = mean_trend)\n# # only score_rate_Rate_4 group\n# try1=credit_rank_1[credit_rank_1['score_rate_Rate_4']==1]\n\n# fig = plt.figure(figsize=(20, 8))#, dpi=80)\n# ax = fig.gca()\n# plt.style.use('seaborn')\n# ss1=[(s+1)*100 for s in try1['mean_trend']]\n# cs= try1['default'].replace(1,'red').replace(0,'yellow')\n# scatter=ax.scatter(x='Deviation', y='mean_pay_from_Bill',data=try1,s=ss1,c=cs,alpha=0.8,edgecolor='black',linewidth=1)\n\n# handles, labels=scatter.legend_elements(prop='sizes')\n# labels = sorted(try1[try1.mean_trend > 0]['mean_trend'].unique())\n\n# plt.legend(handles,labels,title='mean_trend')\n\n# ax.set_ylim((0,2))\n# ax.set_xlim((0,0.5))\n# ax.set_xlabel('Deviation')\n# ax.set_ylabel('mean_pay_from_Bill')\n# ax.set_title('Default_by {} and {}'.format('Deviation','mean_pay_from_Bill'))\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Comparing default classes by mean_pay_from_Bill & Deviation (size = mean_trend)\nfig = plt.figure(figsize=(20, 8))#, dpi=80)\nax = fig.gca()\nplt.style.use('seaborn')\nss1=[(s+1)*100 for s in credit['mean_trend']]\ncs= credit['default'].replace(1,'red').replace(0,'yellow')\nscatter=ax.scatter(x='Deviation', y='mean_pay_from_Bill',data=credit,s=ss1,c=cs,alpha=0.8,edgecolor='black',linewidth=1)\n\nhandles, labels=scatter.legend_elements(prop='sizes')\nlabels = sorted(credit[credit.mean_trend > 0]['mean_trend'].unique())\n\nplt.legend(handles,labels,title='mean_trend')\n\nax.set_ylim((-1,5))\nax.set_xlim((-0.05,2))\nax.set_xlabel('Deviation')\nax.set_ylabel('mean_pay_from_Bill')\nax.set_title('Default_by {} and {}'.format('Deviation','mean_pay_from_Bill'))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Comparing default classes by PAY_AMT1 & Deviation (size = mean_trend)\n\nfig = plt.figure(figsize=(20, 8))#, dpi=80)\nax = fig.gca()\nplt.style.use('seaborn')\ncredit_p=credit[(credit.PAY_AMT1<350000)&(credit.Deviation<3)]\nss1=[(s+1)*100 for s in credit_p['mean_trend']]\ncs= credit_p['default'].replace(1,'red').replace(0,'yellow')\n\nscatter=ax.scatter(x='Deviation', y='PAY_AMT1',data=credit_p,s=ss1,c=cs,alpha=0.8,edgecolor='black',linewidth=1)\n\nhandles, labels=scatter.legend_elements(prop='sizes')\nlabels = sorted(credit_p[credit_p.mean_trend > 0]['mean_trend'].unique())\n\nplt.legend(handles,labels,title='mean_trend')\n\nax.set_xlabel('Deviation')\nax.set_ylabel('PAY_AMT1')\nax.set_title('Default_by {} and {}'.format('Deviation','PAY_AMT1'))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Comparing default classes by mean_trend & Deviation (size = Total_Roll)\nfig = plt.figure(figsize=(20, 8))#, dpi=80)\nax = fig.gca()\nplt.style.use('seaborn')\nss = (credit['Total_Roll']+1)*100\ncs= credit['default'].replace(1,'red').replace(0,'yellow')\n\nscatter=ax.scatter(x='Deviation', y='mean_trend',data=credit,s=ss,c=cs,alpha=0.8,edgecolor='black',linewidth=1)\nhandles, labels=scatter.legend_elements(prop='sizes')\nlabels=['0','1','2','3','4','5','6']\nplt.legend(handles,labels,title='Total_Roll')\n\n#ax.set_ylim((-1,2))\nax.set_xlim((-0.05,3))\nax.set_xlabel('Deviation')\nax.set_ylabel('mean_trend')\nax.set_title('Default_by {} and {}'.format('Deviation','mean_trend'))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Default total rolls by default (1 or 0)\ncredit.hist(column='Total_Roll',by='default',color='c',sharex=True,sharey=True,figsize=(10,5),bins=7,histtype='bar',density='True')\nplt.xlabel('Total_Roll')\nplt.suptitle('default_Total_Roll', x=1, y=1.1, ha='center', fontsize='xx-large')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# default deviation by default (1 or 0)\ncredit.hist(column='mean_trend_3_months',by='default',bins=10,color='magenta',sharex=True,sharey=True,figsize=(10,5),histtype='bar')\nplt.suptitle('default_mean_trend_3_months', x=.5, y=1.1, ha='center', fontsize='xx-large')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot - % of Default zero and Total Qnt by Education\neducation_percent=credit[(credit.EDUCATION_desc == \"Graduate School\") | (credit.EDUCATION_desc == \"High School\") |  (credit.EDUCATION_desc == \"University\")].groupby('EDUCATION_desc')['default'].sum()/ credit[(credit.EDUCATION_desc == \"Graduate School\") | (credit.EDUCATION_desc == \"High School\") |  (credit.EDUCATION_desc == \"University\")].groupby('EDUCATION_desc')['default'].count()\n\nfig, ax1 = plt.subplots(figsize=(15, 5))\n\neducation_percent.plot(secondary_y=True, marker='d')\ncredit[(credit.EDUCATION_desc == \"Graduate School\") | (credit.EDUCATION_desc == \"High School\") |  (credit.EDUCATION_desc == \"University\")].groupby('EDUCATION_desc')['default'].count().plot(kind='bar',color=\"pink\")\n\nplt.title(\"% of Default zeo by EDUCATION (Qnt and mean)\")\nplt.figure(figsize=(15,4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot - % of Default zero and Total Qnt by MARRIAGE\ncredit_1 = credit[(credit.MARRIAGE_desc != \"Other\") & (credit.MARRIAGE_desc != \"0\")]\neducation_percent=credit_1.groupby('MARRIAGE_desc')['default'].sum() / credit_1.groupby('MARRIAGE_desc')['default'].count()\n\nfig, ax1 = plt.subplots(figsize=(15, 5))\n\neducation_percent.plot(secondary_y=True, marker='d')\ncredit_1.groupby('MARRIAGE_desc')['default'].count().plot(kind='bar',color=\"pink\")\n\nplt.title(\"% of Default zeo by MARRIAGE (Qnt and mean)\")\nplt.figure(figsize=(15,4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot - % of Default zero and Total Qnt by Gender\neducation_percent=credit.groupby('SEX_desc')['default'].sum() / credit.groupby('SEX_desc')['default'].count()\n\nfig, ax1 = plt.subplots(figsize=(15, 5))\n\neducation_percent.plot(secondary_y=True, marker='d')\ncredit.groupby('SEX_desc')['default'].count().plot(kind='bar',color=\"pink\")\n\nplt.title(\"% of Default zeo by GENDER (Qnt and mean)\")\nplt.figure(figsize=(15,4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate correlations for the prediction field:default\ncorr = credit.corr()\ncorr['default'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlations by all fields\nsns.set(style=\"ticks\") #white, dark, whitegrid, darkgrid, ticks\nf, ax = plt.subplots(figsize=(25, 25))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, s=80, l=55, n=9,as_cmap=True)\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"delays_pay1_percent = credit.groupby(['Total_Delays','count_out_of_bill'])['default'].sum() / credit.groupby(['Total_Delays','count_out_of_bill'])['default'].count()\ndelays_pay1_percent = delays_pay1_percent.to_frame()\ndelays_pay1_percent.rename(columns={\"default\":\"Prob_default_1\"},inplace=True)\ndelays_pay1_percent.reset_index(level=[0,1], inplace=True)\n\nsns.heatmap(pd.crosstab(delays_pay1_percent.Total_Delays, delays_pay1_percent.count_out_of_bill, values=delays_pay1_percent.Prob_default_1, aggfunc='mean'),cmap=\"BuPu\", annot=True, cbar=False)\n\nplt.title('Probability for default 1 by Total_Delays & count_out_of_bill',x=0.5, y=0.7, ha='center',fontsize='xx-large')\n#delays_pay1_percent","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature reduction","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Initial steps","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting data to X and y\nX = credit_rank_1.drop('default', axis=1)\ny = credit_rank_1['default']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Variance treshold test","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"num_X = X.select_dtypes(include=[np.number])\n\n# We chose variance of 5% as indicator\nselector = VarianceThreshold(0.02)\nselector.fit_transform(num_X)\n\n# The new df without dropped the fields\nnew_columns = num_X.columns[selector.get_support()]\nnew_num_X = num_X[new_columns]\n\n# Suggested fields to remove\nprint(\"These are the fields the VarianceThreshold suggested to remove:\\n\")\nprint(set(new_num_X.columns)^set(credit_rank_1.drop(['default'],axis=1).columns))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking  default precentages for the suggested fields to remove\nprint(\"Checking  default precentages for the suggested fields to remove:\\n\")\nprint(credit_rank_1.groupby('Total_of_Total_zero_flag')['default'].sum() / credit_rank_1.groupby('Total_of_Total_zero_flag')['default'].count())\nprint(\"\\n-------------------------------\\n\")\nprint(credit_rank_1.groupby('EDUCATION_Other')['default'].sum() / credit_rank_1.groupby('EDUCATION_Other')['default'].count())\nprint(\"\\n-------------------------------\\n\")\nprint(credit_rank_1.groupby('MARRIAGE_Other')['default'].sum() / credit_rank_1.groupby('MARRIAGE_Other')['default'].count())\nprint(\"\\n-------------------------------\\n\")\nprint(credit_rank_1.groupby('Total_of_Total_one_flag')['default'].sum() / credit_rank_1.groupby('Total_of_Total_one_flag')['default'].count())\nprint(\"\\n-------------------------------\\n\")\nprint(credit_rank_1.groupby('Total_Bills_LIMIT_BAL_flag')['default'].sum() / credit_rank_1.groupby('Total_Bills_LIMIT_BAL_flag')['default'].count())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# After the VarianceThreshold of 5% thete were 3 fields that it told us to delte.\n# We decide to delete only the field of MARRIAGE_Other because only in that field we see a big differance in the default.\n\ncredit_rank.drop(['MARRIAGE_Other','Total_Bills_LIMIT_BAL_flag','Total_of_Total_one_flag','Total_of_Total_zero_flag'],axis=1,inplace=True)\ncredit_rank_1.drop(['MARRIAGE_Other','Total_Bills_LIMIT_BAL_flag','Total_of_Total_one_flag','Total_of_Total_zero_flag'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## f test for quantity features selection","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# List of chosen features and thier P_value grades\nf_x=X[['trend_1','mean_trend','dev*limit_bal_']]\n#f_x=X[X.columns[[0,1,2,3,4,5,11,15,16,17,18,19,20,23,24,25,26,27,28,29]]] # maybe pay1 and mean_trend trend1 are categogial with minus we have to scale to delete the minus\nf_x.head()\n\nfclass=f_classif(f_x,y)\np_values1=pd.Series(fclass[1],index=f_x.columns)\np_values1.sort_values(ascending=True,inplace=True)\n\nprint(\"List of quntity fields with sorted P_value grades:\\n\")\nprint(p_values1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Chi square test for categorial features selection","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Categorial field will be tested by Chi square test\n# 12 13 14 are <0\nchi_x=X[['Total_Delays','Three_Months_Delays','Total_Roll','Three_Months_Roll','count_out_of_bill','count_out_of_bill_3_months']]#,'trend_1','mean_trend']]\n#chi_x=X[X.columns[[7,8,9,10,11,21,22,30,31,32,33,34,35,36,37,38,39,40,41,42]]]\nchis2=chi2(chi_x,y)\n\np_values=pd.Series(chis2[1],index=chi_x.columns)\np_values.sort_values(ascending=True,inplace=True)\n\nprint(\"List of categorial fields with sorted P_value grades:\\n\")\np_values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Machine Learning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting data to X and y\nX = credit_rank_1.drop('default', axis=1)\ny = credit_rank_1.default","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Choosing the most relevant features\nselected = X#.drop('Pay_from_Bill_1_round',axis=1)\n\n#Using Feature Scaling\nScaler = StandardScaler().fit(selected)\nselected_Scaled = pd.DataFrame(Scaler.transform(selected), columns=selected.columns)\n\n# Splitting data to train and test\n# X_train, X_test, y_train, y_test = split(selected_Scaled,y,train_size=0.7,random_state=12345,stratify=y)\nX_train, X_test, y_train, y_test = split(selected_Scaled,y,train_size=0.7,random_state=12345,stratify=y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic Regression model\n\nlog_reg = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1, fit_intercept=True, intercept_scaling=1, class_weight='balanced', random_state=12345,\n                   max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None,solver='newton-cg')\n\n# fitting X_train and y_train\nlogistic=log_reg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Coefficient & intercept values\nprint(\"coef=\",list(logistic.coef_))\nprint(\"\\n******************************\\n\")\nprint(selected.columns)\nprint(\"\\n*******************************\\n\")\nprint(\"intercept= \",logistic.intercept_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cross validation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using cross validation for testing the train data\nLogistic_CV = StratifiedShuffleSplit(n_splits=7, train_size=0.7, test_size=0.3)\n\n# We chose to use roc_auc score for testing our model\nscores = cross_val_score(logistic, X_train, y_train, cv=Logistic_CV, scoring='roc_auc')\n\n# The 7 cross validation scores\nprint(\"Scores : \" + (7 * \" {:.3f} \").format( *scores))\n\n# mean score of the 7 cross validation\nmean_scores = \"%.3f\" % stat.mean(scores)\nprint(\"Mean Scores: \" ,mean_scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prediction using X_train\ny_train_pred = logistic.predict(X_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Test Scores","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_pred = logistic.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_true=y_test,\n                      y_pred=y_test_pred)\npd.DataFrame(cm, \n             index=log_reg.classes_, \n             columns=log_reg.classes_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using classification report for checking precision,recall,f1-score,support\nprint(classification_report(y_true=y_test,y_pred=y_test_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using predict proba to check the probabilty of each row for default\ny_test_pred_proba = pd.DataFrame(logistic.predict_proba(X_test), columns=logistic.classes_)\n\n# Checking rows our model predicted as default 0 but actualy are deault 1\nAA=y_test_pred_proba.join(X_test).join(y_test)\nAA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ROC scores by TPR,FPR,Treshold\ny_test_desc = y_test.replace(1,'default').replace(0,'no-default')\n\nscores = logistic.predict_proba(X_test)[:, 1]\n\nfpr_log, tpr_log, thresholds_log = roc_curve(y_test_desc, scores, pos_label='default')\nres_LR = pd.DataFrame({'FPR': fpr_log, 'TPR': tpr_log, 'Threshold': thresholds_log})\nres_LR[['TPR', 'FPR', 'Threshold']][::200]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ROC Plot Graph\nplt.plot(fpr_log, tpr_log, '-o')\nplt.title('ROC')\nplt.xlabel('FPR (False Positive Rate = 1-specificity)')\nplt.ylabel('TPR (True Positive Rate = sensitivity)')\nplt.xlim([0, 1])\nplt.ylim([0, 1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# AUC Score\nround(roc_auc_score(y_test_desc=='default', scores),4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Grid search","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Choosing the Hyper-Parameters values for grid search\nLR_params_gs = {'solver':        ['lbfgs', 'newton-cg', 'sag', 'saga'],\n                'C':             [0.01,0.05,0.1,1,10,100,500,1000],\n                'multi_class':   ['auto','multinomial'],\n                'class_weight':  ['None','balanced'],\n                'fit_intercept': [True, False]}\n\n# Fitting the grid search\nlogistic_reg_gs = GridSearchCV(logistic, LR_params_gs, cv=7,scoring='roc_auc')\nlogistic_reg_gs.fit(X_train, y_train)\n\n# Best parameters\nprint(\"Best parameters:\", logistic_reg_gs.best_params_)\nprint(\"\\n*******************************************************************\\n\")\n# Train & Test scores\nprint('Train Score: ',logistic_reg_gs.score(X_train, y_train))\nprint('Test Score: ',logistic_reg_gs.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Decision Trees","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting data to X and y\nX = credit_rank_1.drop('default', axis=1)\ny = credit_rank_1.default\n#------------------------------------------\n# Choosing the most relevant features\nselected=X[['Three_Months_Delays','PAY_LM','dev*limit_bal_','LIMIT_BAL','Total_Delays','count_out_of_bill',\t'mean_trend','max_delay','EDUCATION_Graduate School','Total_Roll','no_bill_flag',\t'trend_1','AGE_round','Deviation_round']]\n\n# Splitting data to train and test\nX_train, X_test, y_train, y_test = split(selected,y,train_size=0.7,random_state=12345,stratify=y) # selected instead of X\n#------------------------------------------\n# Decision Tree model\nDT = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=6, min_samples_split=2, min_samples_leaf=70, \nmin_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, \nmin_impurity_split=None, class_weight='balanced', presort='deprecated', ccp_alpha=0.0)\n\n# fitting X_train and y_train\nDecision_Tree = DT.fit(X_train, y_train)\n#-------------------------------------------\n# Decision Tree visualization\ndef visualize_tree(model, md=5, width=1800):\n    dot_data = StringIO()  \n    export_graphviz(model, out_file=dot_data, feature_names=X_train.columns, max_depth=md)\n    graph = pydot.graph_from_dot_data(dot_data.getvalue())[0]  \n    return Image(graph.create_png(), width=width)\n\nvisualize_tree(Decision_Tree, md=3, width=1800)\n#-------------------------------------------\ndef get_feature_importance(clsf, ftrs):\n    imp = clsf.feature_importances_.tolist()\n    feat = ftrs\n    result = pd.DataFrame({'feat':feat,'score':imp})\n    result = result.sort_values(by=['score'],ascending=False)\n    return result\n\nget_feature_importance(Decision_Tree, X_train.columns)\n#---------------------------------------------","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cross validation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using cross validation for testing the train data\nDecision_Tree_CV = StratifiedShuffleSplit(n_splits=7, train_size=0.7, test_size=0.3)\n\n# We chose to use roc_auc score for testing our model\nscores = cross_val_score(Decision_Tree, X_train, y_train, cv=Decision_Tree_CV, scoring='roc_auc')\n\n# The 7 cross validation scores\nprint(\"Scores : \" + (7 * \" {:.3f} \").format( *scores))\n\n# mean score of the 7 cross validation\nmean_scores = \"%.3f\" % stat.mean(scores)\nprint(\"Mean Scores: \" ,mean_scores)\n\ncm = confusion_matrix(y_true=y_train,\n                      y_pred=y_train_pred)\nprint(cm)\n\npd.DataFrame(cm, \n             index=DT.classes_, \n             columns=DT.classes_)\n\nprint(classification_report(y_true=y_train,y_pred=y_train_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prediction using X_train\ny_train_pred = Decision_Tree.predict(X_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Test scors","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_pred = Decision_Tree.predict(X_test)\n#-------------------------------------------\ncm = confusion_matrix(y_true=y_test,\n                      y_pred=y_test_pred)\npd.DataFrame(cm, \n             index=DT.classes_, \n             columns=DT.classes_)\n#-------------------------------------------\n# Using classification report for checking precision,recall,f1-score,support\nprint(classification_report(y_true=y_test,y_pred=y_test_pred))\n#------------------------------------------\n# Using predict proba to check the probabilty of each row for default\ny_test_pred_proba = pd.DataFrame(Decision_Tree.predict_proba(X_test), columns=Decision_Tree.classes_)\n\n# Checking rows our model predicted as default 0 but actualy are deault 1\nAA=y_test_pred_proba.join(X_test).join(y_test)\nAA.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ROC scores by TPR,FPR,Treshold\ny_test_desc = y_test.replace(1,'default').replace(0,'no-default')\n\nscores = Decision_Tree.predict_proba(X_test)[:, 1]\n\nfpr_DT, tpr_DT, thresholds_DT = roc_curve(y_test_desc, scores, pos_label='default')\nres_DT = pd.DataFrame({'FPR': fpr_DT, 'TPR': tpr_DT, 'Threshold': thresholds_DT})\nres_DT[['TPR', 'FPR', 'Threshold']][::5]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ROC Plot Graph\nplt.plot(fpr_DT, tpr_DT, '-o')\nplt.title('ROC')\nplt.xlabel('FPR (False Positive Rate = 1-specificity)')\nplt.ylabel('TPR (True Positive Rate = sensitivity)')\nplt.xlim([0, 1])\nplt.ylim([0, 1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# AUC Score\nround(roc_auc_score(y_test_desc=='default', scores),3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Grid search","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Choosing the Hyper-Parameters values for grid search\nDT_params_gs = {  'max_depth':           [3,4,5,6,7,8], \n                   'min_samples_split':   [2,5,10,20], \n                   'min_samples_leaf':    [25,50,70], \n                   'class_weight':        ['balanced']}\n\n# Fitting the grid search\nDecision_Tree_gs = GridSearchCV(Decision_Tree, DT_params_gs, cv=3,scoring='roc_auc')\nDecision_Tree_gs.fit(X_train, y_train)\n\n# Best parameters\nprint(\"Best parameters:\", Decision_Tree_gs.best_params_)\nprint(\"\\n*******************************************************************\\n\")\n# Train & Test scores\nprint('Train Score: ',Decision_Tree_gs.score(X_train, y_train))\nprint('Test Score: ',Decision_Tree_gs.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## KNN","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting data to X and y\nX = credit_rank.drop('default', axis=1)\ny = credit_rank.default","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Choosing the most relevant features\nselected=X[['Three_Months_Delays','PAY_LM','dev*limit_bal_','LIMIT_BAL','Total_Delays','count_out_of_bill',\t'mean_trend','max_delay','Total_Roll','no_bill_flag','trend_1']]\n\n# Using Feature Scaling \nScaler = StandardScaler().fit(selected)\nselected_Scaled = pd.DataFrame(Scaler.transform(selected), columns=selected.columns)\n\n# Splitting data to train and testselected_Scaled\nX_train, X_test, y_train, y_test = split(selected_Scaled,y,train_size=0.7,random_state=12345,stratify=y) # selected instead of X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Knn model\nKNN = KNeighborsClassifier(metric='minkowski', n_neighbors= 500, p= 1)\n\n# fitting X_train and y_train\nKNN_fit = KNN.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cross validation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using cross validation for testing the train data\nKnn_CV = StratifiedShuffleSplit(n_splits=7, train_size=0.7, test_size=0.3)\n\n# We chose to use roc_auc score for testing our model\nscores = cross_val_score(KNN_fit, X_train, y_train, cv=Knn_CV, scoring='roc_auc')\n\n# The 7 cross validation scores\nprint(\"Scores : \" + (7 * \" {:.3f} \").format( *scores))\n\n# mean score of the 7 cross validation\nmean_scores = \"%.3f\" % stat.mean(scores)\nprint(\"Mean Scores: \" ,mean_scores)\n\ncm = confusion_matrix(y_true=y_train,\n                      y_pred=y_train_pred)\nprint(cm)\n\npd.DataFrame(cm, \n             index=KNN.classes_, \n             columns=KNN.classes_)\n\nprint(classification_report(y_true=y_train,y_pred=y_train_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prediction using X_train\ny_train_pred = KNN_fit.predict(X_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Test Scores","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_pred = KNN_fit.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_true=y_test,\n                      y_pred=y_test_pred)\npd.DataFrame(cm, \n             index=KNN_fit.classes_, \n             columns=KNN_fit.classes_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using classification report for checking precision,recall,f1-score,support\nprint(classification_report(y_true=y_test,y_pred=y_test_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# accuracy score\nround(accuracy_score(y_true=y_test,y_pred=y_test_pred),3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using predict proba to check the probabilty of each row for default\ny_test_pred_proba = pd.DataFrame(KNN_fit.predict_proba(X_test), columns=KNN_fit.classes_)\n\n# Checking rows our model predicted as default 0 but actualy are deault 1\nAA=y_test_pred_proba.join(X_test).join(y_test)\nAA.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ROC scores by TPR,FPR,Treshold\ny_test_desc = y_test.replace(1,'default').replace(0,'no-default')\n\nscores = KNN_fit.predict_proba(X_test)[:, 1]\n\nfpr_KNN, tpr_KNN, thresholds_KNN = roc_curve(y_test_desc, scores, pos_label='default')\nres_KNN = pd.DataFrame({'FPR': fpr_KNN, 'TPR': tpr_KNN, 'Threshold': thresholds_KNN})\nres_KNN[['TPR', 'FPR', 'Threshold']]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ROC Plot Graph\nplt.plot(fpr_KNN, tpr_KNN, '-o')\nplt.title('ROC')\nplt.xlabel('FPR (False Positive Rate = 1-specificity)')\nplt.ylabel('TPR (True Positive Rate = sensitivity)')\nplt.xlim([0, 1])\nplt.ylim([0, 1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# AUC Score\nround(roc_auc_score(y_test_desc=='default', scores),3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Grid Search","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Choosing the Hyper-Parameters values for grid search\nKNN_params_gs = {'n_neighbors':  [1,5,10,25,50,100,500,1000],\n                 'metric':       ['minkowski', 'hamming', 'cosine'],\n                 'p':            [1,2,3]}         # p = 2 is euclidean (p = 1 is manhattan)\n\n# Fitting the grid search\nKNN_params_gs = GridSearchCV(KNN_fit, KNN_params_gs, cv=2,scoring='roc_auc')\nKNN_params_gs.fit(X_train, y_train)\n\n# Best parameters\nprint(\"Best parameters:\", KNN_params_gs.best_params_)\nprint(\"\\n*******************************************************************\\n\")\n# Train & Test scores\nprint('Train Score: ',KNN_params_gs.score(X_train, y_train))\nprint('Test Score: ',KNN_params_gs.score(X_test, y_test))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## AUC Graph - 3 Models comparison","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# ROC Plot Graph\nplt.plot(fpr_log, tpr_log, '-o')\nplt.plot(fpr_DT, tpr_DT, '-o')\nplt.plot(fpr_KNN, tpr_KNN, '-o')\nplt.title('ROC')\nplt.xlabel('FPR (False Positive Rate = 1-specificity)')\nplt.ylabel('TPR (True Positive Rate = sensitivity)')\nplt.xlim([0, 1])\nplt.ylim([0, 1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Ensemble methods","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Voting","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# The 3 models with their best Hyper Parameters\nclf1 = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1, fit_intercept=True, intercept_scaling=1, class_weight='balanced', random_state=12345,\n       max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None,solver='newton-cg')\n\nclf2 = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=6, min_samples_split=2, min_samples_leaf=70, \n       min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, \n       min_impurity_split=None, class_weight='balanced', presort='deprecated', ccp_alpha=0.0)\n\nclf3 = KNeighborsClassifier(metric='minkowski', n_neighbors= 500, p= 1)\n\nclassifiers = [('LR', clf1), ('DT', clf2), ('KNN', clf3)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fitting the voting model (voting=hard)\nclf_voting = VotingClassifier(estimators=classifiers,\n                              voting='hard')\nclf_voting.fit(X_train, y_train)\n\n# Scores:\ny_test_desc = y_test.replace(1,'default').replace(0,'no-default')\nscores = clf_voting.predict(X_test)\n\nprint()\nprint(\"--------------------------------------------------------------------\")\nprint()\nprint(\"Test AUC Score: \",round(roc_auc_score(y_test_desc=='default', scores),3))\nprint()\nprint(\"--------------------------------------------------------------------\")\nprint()\nprint(\"Confusion Matrix:\")\ncm = confusion_matrix(y_true=y_test,y_pred=scores)\nprint(pd.DataFrame(cm, index=DT.classes_, columns=DT.classes_))\nprint()\nprint(\"--------------------------------------------------------------------\")\nprint()\nprint(\"Classification Report:\")\nprint(classification_report(y_true=y_test,y_pred=y_test_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fitting the voting model (voting=soft)\nclf_voting = VotingClassifier(estimators=classifiers,\n                              voting='soft')\nclf_voting.fit(X_train, y_train)\n\n# Scores:\ny_test_desc = y_test.replace(1,'default').replace(0,'no-default')\nscores = clf_voting.predict(X_test)\n\nprint()\nprint(\"--------------------------------------------------------------------\")\nprint()\nprint(\"Test AUC Score: \",round(roc_auc_score(y_test_desc=='default', scores),3))\nprint()\nprint(\"--------------------------------------------------------------------\")\nprint()\nprint(\"Confusion Matrix:\")\ncm = confusion_matrix(y_true=y_test,y_pred=scores)\nprint(pd.DataFrame(cm, index=DT.classes_, columns=DT.classes_))\nprint()\nprint(\"--------------------------------------------------------------------\")\nprint()\nprint(\"Classification Report:\")\nprint(classification_report(y_true=y_test,y_pred=y_test_pred))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Bagging","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#bagging scores func\ndef bagging_scores(clf):\n  clf_bagging = BaggingClassifier(base_estimator=clf, n_estimators=100)\n  clf_bagging.fit(X_train, y_train)\n  \n  #Scores:\n  y_test_desc = y_test.replace(1,'default').replace(0,'no-default')\n  scores = clf_bagging.predict(X_test)\n  print()\n  print(\"--------------------------------------------------------------------\")\n  print()\n  print(\"Test AUC Score: \",round(roc_auc_score(y_test_desc=='default', scores),3))\n  print()\n  print(\"--------------------------------------------------------------------\")\n  print()\n  print(\"Confusion Matrix:\")\n  cm = confusion_matrix(y_true=y_test,y_pred=scores)\n  print(pd.DataFrame(cm, index=DT.classes_, columns=DT.classes_))\n  print()\n  print(\"--------------------------------------------------------------------\")\n  print()\n  print(\"Classification Report:\")\n  print(classification_report(y_true=y_test,y_pred=y_test_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using the function for the 3 Models:\nprint(\"======================================================================\")\nprint(\"Logistic Regression Bagging Score:\")\nprint(\"======================================================================\")\nbagging_scores(clf1)\nprint(\"======================================================================\")\nprint(\"Decision Tree Bagging Score:\")\nprint(\"======================================================================\")\nbagging_scores(clf2)\nprint(\"======================================================================\")\nprint(\"KNN Bagging Score:\")\nprint(\"======================================================================\")\n#bagging_scores(clf3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Boosting methods","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### AdaBoost","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def adaboost_scores(clf):\n  clf_adaboost = AdaBoostClassifier(base_estimator=clf,n_estimators=200,learning_rate=0.01)\n  clf_adaboost.fit(X_train, y_train)\n\n  #Scores:\n  y_test_desc = y_test.replace(1,'default').replace(0,'no-default')\n  scores = clf_adaboost.predict(X_test)\n  print()\n  print(\"--------------------------------------------------------------------\")\n  print()\n  print(\"Test AUC Score: \",round(roc_auc_score(y_test_desc=='default', scores),3))\n  print()\n  print(\"--------------------------------------------------------------------\")\n  print()\n  print(\"Confusion Matrix:\")\n  cm = confusion_matrix(y_true=y_test,y_pred=scores)\n  print(pd.DataFrame(cm, index=DT.classes_, columns=DT.classes_))\n  print()\n  print(\"--------------------------------------------------------------------\")\n  print()\n  print(\"Classification Report:\")\n  print(classification_report(y_true=y_test,y_pred=y_test_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using the function for the 3 Models:\nprint(\"======================================================================\")\nprint(\"Logistic Regression Bagging Score:\")\nprint(\"======================================================================\")\nadaboost_scores(clf1)\nprint(\"======================================================================\")\nprint(\"Decision Tree Bagging Score:\")\nprint(\"======================================================================\")\nadaboost_scores(clf2)\nprint(\"======================================================================\")\nprint(\"KNN Bagging Score:\")\nprint(\"======================================================================\")\n#adaboost_scores(clf3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Geadient boosting","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_GB = GradientBoostingClassifier(max_depth=3, n_estimators=200, learning_rate=0.01)\nclf_GB.fit(X_train, y_train)\n\n#Scores:\ny_test_desc = y_test.replace(1,'default').replace(0,'no-default')\nscores = clf_GB.predict(X_test)\nprint()\nprint(\"--------------------------------------------------------------------\")\nprint()\nprint(\"Test AUC Score: \",round(roc_auc_score(y_test_desc=='default', scores),3))\nprint()\nprint(\"--------------------------------------------------------------------\")\nprint()\nprint(\"Confusion Matrix:\")\ncm = confusion_matrix(y_true=y_test,y_pred=scores)\nprint(pd.DataFrame(cm, index=DT.classes_, columns=DT.classes_))\nprint()\nprint(\"--------------------------------------------------------------------\")\nprint()\nprint(\"Classification Report:\")\nprint(classification_report(y_true=y_test,y_pred=y_test_pred))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}