{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Introduction","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Regression Project - NYC Airbnb data**\n\nThe project is about Airbnb NYC transactions.\n\nThe data was takken from Kaggle\n\nThe prediction variable is log price per night.\n\nThe project process:\n\n1. import packages and data frame creation\n2. EDA Process (80% of time)\n3. Investigatin data\n4. Machine learning(20% time):\n\n* Using 3 Models: Linear Regression,Decision Trees and KNN.\n* Trying to improve each model\n* Checking the Test RMSE\n\n5. Conclusion- Choosing the best model based on Test RMSE","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# First Steps","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"code","source":"# General tools\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime as dt \n\n# For transformations and predictions\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.linear_model import LinearRegression\nfrom scipy.optimize import curve_fit\nfrom sklearn.tree import DecisionTreeRegressor, export_graphviz\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import pairwise_distances\n\n# For the tree visualization\nimport pydot\nfrom IPython.display import Image\nfrom sklearn.externals.six import StringIO\n\n# For scoring\nfrom sklearn.metrics import mean_squared_log_error as msle\nfrom sklearn.metrics import mean_squared_error as mse\n\n\n# For validation\nfrom sklearn.model_selection import train_test_split as split\n\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\n\nif 'google.colab' in sys.modules:\n    from google.colab import files\n    uploaded = files.upload()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nyc= pd.read_csv('nyc.csv')\nnyc.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. EDA Process","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing zero or negative prices\nnyc = nyc[nyc.log_price > 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing bad data\ndef drop_zeros(nyc):\n    return nyc.loc[nyc.beds * nyc.accommodates * nyc.bathrooms * nyc.bedrooms != 0]\nzeros_dropper = FunctionTransformer(drop_zeros, validate=False)\n\nnyc = zeros_dropper.fit_transform(nyc) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Changing True\\False field into 1\\0 values\ncleaning_fee_dict = {True:1,False:0}\nhost_identity_verified_dict={'t':1,'f':0}\ninstant_bookable_dict={'t':1,'f':0}\n\nnyc.cleaning_fee.replace(cleaning_fee_dict,inplace=True)\nnyc.host_identity_verified.replace(host_identity_verified_dict,inplace=True)\nnyc.instant_bookable.replace(instant_bookable_dict,inplace=True)\n#nyc.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating Date\\Year and delta dates between first review and last review\n\nnyc['date_host'] = pd.to_datetime(nyc.host_since)\nnyc['year_host'] = nyc['date_host'].dt.year\n\nnyc['date_end'] = pd.to_datetime(nyc.last_review)\nnyc['year_end'] = nyc['date_end'].dt.year\n\nnyc['date_start'] = pd.to_datetime(nyc.first_review)\nnyc['year_start'] = nyc['date_start'].dt.year\n\nnyc['delta_dates'] = (nyc['date_end']-nyc['date_start'])\n\nnyc['delta_dates']=nyc['delta_dates'].dt.days\n\nnyc.drop(['date_host','date_end','date_start','date_host'],axis=1,inplace=True)\n\n#nyc.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping irelevant fields\nnyc.drop(['id','description','host_has_profile_pic','name','thumbnail_url','first_review','host_since','last_review','city','zipcode','host_response_rate'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting Bed Type field to Real bed or Other\nprint(nyc.groupby('bed_type')['log_price'].count())\n\nnyc.groupby('bed_type')['log_price'].mean().plot.bar()\n\ndef bed_group_func(row):\n  if row.loc['bed_type'] == 'Real Bed':\n    return 1\n  else:\n    return 0\n\nnyc['real_bed'] = nyc.apply(bed_group_func, axis=1)\n\nnyc.drop('bed_type',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cancellation Policy field (Removing values with fiew data)\nprint(nyc.cancellation_policy.value_counts())\n\nnyc = nyc[nyc.cancellation_policy != ('super_strict_30')]\nnyc = nyc[nyc.cancellation_policy != ('super_strict_60')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nyc['cancellation_policy'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Changing Property type field to property_group (after creating high level values using dictionary)\nprint(nyc.property_type.value_counts())\n\nproperty_type_dict1 = {'Apartment':['Condominium','Loft','Serviced apartment','Guest suite'],\n         'House':['Vacation home','Villa','Townhouse','In-law','Casa particular'],\n         'Hotel1':['Dorm','Hostel','Guesthouse'],\n         'Hotel2':['Boutique hotel','Bed & Breakfast'],\n         'Timeshare':['Timeshare'],\n         'Other':['Island','Castle','Yurt','Hut','Chalet','Treehouse',\n                  'Earth House','Tipi','Cave','Train','Parking Space','Lighthouse',\n                 'Tent','Boat','Cabin','Camper/RV','Bungalow']\n        }\n\nproperty_type_dict2 = {i : k for k, v in property_type_dict1.items() for i in v}\n\nnyc['property_group'] = nyc['property_type'].replace(property_type_dict2)\n\nnyc.drop('property_type',axis=1,inplace=True)\n\nprint('---------------------------------------')\nprint(nyc['property_group'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding price per room field (For neighnourhood price level)\nnyc['price_per_room'] = nyc['log_price'] / nyc['bedrooms']\n\nnyc.neighbourhood.value_counts().head(30).plot.bar(color=(.0, 0.4, 0.9, 1))\n\nneighbourhood_avg_price = nyc[['neighbourhood','price_per_room']].groupby('neighbourhood')['price_per_room'].mean().sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neighbourhood_avg_price.replace(np.inf, np.nan,inplace=True)\nneighbourhood_avg_price.fillna(neighbourhood_avg_price.mean(),inplace=True)\n\nprint(neighbourhood_avg_price.sort_values(ascending=False))\nprint('---------------------------------------')\nprint(neighbourhood_avg_price.describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neighbourhood_class_df = neighbourhood_avg_price.to_frame()\ntype(neighbourhood_class_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting neighbourhoods to Levels\ndef neigbourhood_class(row):\n  if row['price_per_room'] >=0 and row['price_per_room'] <= 3.683610:\n    return 1\n  elif row['price_per_room'] > 3.6836100 and row['price_per_room'] <= 3.868928:\n    return 2\n  elif row['price_per_room'] >3.868928 and row['price_per_room'] <= 4.194452: \n    return 3\n  else:\n    return 4\n  \nneighbourhood_class_df['neigbourhood_level'] = neighbourhood_class_df.apply(neigbourhood_class,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neighbourhood_class_df.sort_values(by='neigbourhood_level',ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neighbourhood_class_df.drop('price_per_room',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Joining between the Main Data Frame and the  neighbourhood_class data frame to get neighbourhood class\nnyc = nyc.join(neighbourhood_class_df,on='neighbourhood')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using Longtitude and Latitude fields to create 0-1 scale (North to South / West to East)\n\nplt.scatter(nyc.longitude,nyc.latitude,c = nyc.log_price)\nplt.xlabel(\"longitude\")\nplt.ylabel(\"latitude\")\nplt.title('log_price on Map', x=0.5, y=1.05, ha='center', fontsize='xx-large')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nyc.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4, figsize=(15,10),\n    c=\"log_price\", cmap=plt.get_cmap(\"jet\"), colorbar=True,\n    sharex=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The Formulas are:\n# 1. (latitude - min_latitude) / (max_latitude - min_latitude)\n# 2. (longitude - min_longitude) / (max_longitude - min_longitude)\n\nnyc['latitude_north'] = (nyc.latitude - nyc.latitude.min()) / (nyc.latitude.max() - nyc.latitude.min())\nnyc['longitude_east'] = (nyc.longitude - nyc.longitude.min()) / (nyc.longitude.max() - nyc.longitude.min())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distance from time Square\nnyc['distance_to_t_squre'] = np.sqrt((40.758896-nyc['latitude'])**2+(-73.985130-nyc['longitude'])**2)\n\nnyc_num_2 = nyc[['distance_to_t_squre','log_price']].select_dtypes(include=np.number)\nsns.pairplot(nyc_num_2, height=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distance from central train\nnyc['distance_to_c_train'] = np.sqrt((40.752655-nyc['latitude'])**2+(-73.977295-nyc['longitude'])**2)\n\nnyc_num_2 = nyc[['distance_to_c_train','log_price']].select_dtypes(include=np.number)\nsns.pairplot(nyc_num_2, height=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distance from Wall Street\nnyc['distance_to_w_street']=np.sqrt((40.706005-nyc['latitude'])**2+(-74.008827-nyc['longitude'])**2)\n\nnyc_num_2 = nyc[['distance_to_w_street','log_price']].select_dtypes(include=np.number)\nsns.pairplot(nyc_num_2, height=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nyc.drop(['latitude','longitude'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking null values\n\nnyc.info()\n\nnyc.dropna(subset=['bathrooms','host_identity_verified','bedrooms','beds'],inplace=True)\nprint('--------------------------------------------------')\nnyc.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Changing amenities field to booleans seperated fields\n\nl=list(nyc['amenities'])\nl=[[word.strip('[\" ]') for word in row[1:-1].split(',')] for row in list(nyc['amenities'])]\ncols = set(word for row in l  for word in row)\namenities_df=pd.DataFrame(columns=cols)\nprint(cols)\namenities_df = pd.DataFrame(columns=cols)\nfor row_idx in range(len(l)):\n    for col in cols:\n        amenities_df.loc[row_idx,col]=int(col in l[row_idx])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"amenities_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Building a new field aggregating fields from amenities_df\n# The new fields will be: kitchen, accesibility, Electricity_and_Technology, facilities, kids_friendly, security, services\n\namenities_group_df = pd.DataFrame()\n#--------------------------------------\namenities_group_df['kitchen'] = amenities_df['Kitchen']+amenities_df['Breakfast']+amenities_df['Cooking basics']+amenities_df['Cooking basics']+amenities_df['BBQ grill']+amenities_df['Oven']+amenities_df['Coffee maker']+amenities_df['Microwave']+amenities_df['Refrigerator']+amenities_df['Dishwasher']\namenities_group_df['accesibility'] = amenities_df['Free parking on premises']+amenities_df['Wide clearance to bed']+amenities_df['smooth pathway to front door']+amenities_df['Ground floor access']+amenities_df['Lake access']+amenities_df['Wheelchair accessible']+amenities_df['Wide clearance to shower & toilet']+amenities_df['Wide hallway clearance']+amenities_df['Wide doorway']+amenities_df['Accessible-height toilet']+amenities_df['Step-free access']+amenities_df['Well-lit path to entrance']+amenities_df['Waterfront']+amenities_df['Free parking on street']+amenities_df['Disabled parking spot']+amenities_df['Accessible-height bed']+amenities_df['Private entrance']+amenities_df['Elevator']\namenities_group_df['Elect_Tech'] = amenities_df['Wide entryway']+amenities_df['Air conditioning']+amenities_df['Ethernet connection']+amenities_df['Cable TV']+amenities_df['Internet']+amenities_df['EV charger']+amenities_df['Baby monitor']+amenities_df['TV']+amenities_df['Wireless Internet']+amenities_df['Pocket wifi']+amenities_df['Washer']+amenities_df['Dryer']+amenities_df['Keypad']+amenities_df['Game console']+amenities_df['Washer / Dryer']+amenities_df['Hair dryer']\namenities_group_df['facilities'] = amenities_df['Private living room']+amenities_df['Air purifier']+amenities_df['Handheld shower head']+amenities_df['Hot water kettle']+amenities_df['Extra pillows and blankets']+amenities_df['Hot tub']+amenities_df['Pets live on this property']+amenities_df['Heating']+amenities_df['Dishes and silverware']+amenities_df['Patio or balcony']+amenities_df['Bed linens']+amenities_df['First aid kit']+amenities_df['Crib']+amenities_df['Flat']+amenities_df['Laptop friendly workspace']+amenities_df['Buzzer/wireless intercom']+amenities_df['Firm mattress']+amenities_df['Iron']+amenities_df['Changing table']+amenities_df['Hangers']+amenities_df['Roll-in shower with chair']+amenities_df['Gym']+amenities_df['Outlet covers']+amenities_df['Essentials']+amenities_df['Private bathroom']+amenities_df['Baby bath']+amenities_df['Bathtub']+amenities_df['Shampoo']+amenities_df['Beachfront']+amenities_df['Single level home']+amenities_df['Hot water']+amenities_df['High chair']+amenities_df['Bathtub with shower chair']+amenities_df['Pool']+amenities_df['Fixed grab bars for shower & toilet']+amenities_df['Room-darkening shades']+amenities_df['Beach essentials']+amenities_df['Garden or backyard']\namenities_group_df['kids_friendly'] = amenities_df['Babysitter recommendations']+amenities_df['Family/kid friendly']+amenities_df['Children’s books and toys']+amenities_df['Children’s dinnerware']\namenities_group_df['security'] = amenities_df['Window guards']+amenities_df['Stair gates']+amenities_df['Fireplace guards']+amenities_df['Doorman']+amenities_df['Carbon monoxide detector']+amenities_df['Smoke detector']+amenities_df['Table corner guards']+amenities_df['Fire extinguisher']+amenities_df['Lock on bedroom door']+amenities_df['Smart lock']+amenities_df['Lockbox']\namenities_group_df['services'] = amenities_df['Ski in/Ski out']+amenities_df['Cleaning before checkout']+amenities_df['Long term stays allowed']+amenities_df['Other pet(s)']+amenities_df['Cat(s)']+amenities_df['Self Check-In']+amenities_df['24-hour check-in']+amenities_df['Host greets you']+amenities_df['Luggage dropoff allowed']+amenities_df['Pack ’n Play/travel crib']+amenities_df['Pets allowed']+amenities_df['Suitable for events']+amenities_df['Safety card']+amenities_df['Indoor fireplace']+amenities_df['Dog(s)']+amenities_df['Smoking allowed']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"amenities_group_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"amenities_group_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This field will use to join between nyc data frame and amenities_group data frame\nnyc['join_key'] = range(0,len(nyc))\nnyc.index = nyc['join_key']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Joining between the main data set and the data set based on amenities field\nnyc_j = nyc.join(amenities_group_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nyc_j.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Keeping Data Frame before Dummies\nnyc_before_dummies_df = nyc_j\nnyc_before_dummies_2_df = nyc_j","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating Dummy Variables to string fields\n\nroom_dummies = pd.get_dummies(nyc_j.room_type,prefix='room').iloc[:,1:]\nnyc_j = pd.concat([nyc_j,room_dummies],axis=1)\n\ncancellation_dummies = pd.get_dummies(nyc_j.cancellation_policy,prefix='cancellation').iloc[:,1:]\nnyc_j = pd.concat([nyc_j,cancellation_dummies],axis=1)\n\nproperty_dummies = pd.get_dummies(nyc_j.property_group,prefix='property').iloc[:,1:]\nnyc_j = pd.concat([nyc_j,property_dummies],axis=1)\n\nbedrooms_dummies = pd.get_dummies(nyc_j.bedrooms,prefix='bedrooms').iloc[:,1:]\nnyc_j = pd.concat([nyc_j,bedrooms_dummies],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nyc_j.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping original fields after dummies\nnyc_j.drop(['bedrooms','amenities','room_type','cancellation_policy','neighbourhood','property_group','join_key','price_per_room'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# New Data Frame without losing the first dummy variable (For decision tree)\nroom_dummies = pd.get_dummies(nyc_before_dummies_df.room_type,prefix='room').iloc[:,:]\nnyc_before_dummies_df = pd.concat([nyc_before_dummies_df,room_dummies],axis=1)\n\ncancellation_dummies = pd.get_dummies(nyc_before_dummies_df.cancellation_policy,prefix='cancellation').iloc[:,:]\nnyc_before_dummies_df = pd.concat([nyc_before_dummies_df,cancellation_dummies],axis=1)\n\nproperty_dummies = pd.get_dummies(nyc_before_dummies_df.property_group,prefix='property').iloc[:,:]\nnyc_before_dummies_df = pd.concat([nyc_before_dummies_df,property_dummies],axis=1)\n\nnyc_before_dummies_df.drop(['amenities','room_type','cancellation_policy','neighbourhood','property_group','join_key','price_per_room'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nyc_j.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Investigating the Date","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Histogram of nyc data frame\nnyc_j.hist(figsize=(10, 10),color=(\"c\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pair plot of nyc data frame\nnyc_num = nyc_j.select_dtypes(include=np.number)\nsns.pairplot(nyc_num, height=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Log price Correlations matrix\ncorr_matrix = nyc_j.corr()\ncorr_matrix[\"log_price\"].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using correlation graph\nfig, ax = plt.subplots(figsize =(20, 20)) \ncorr = nyc_j.corr()\ncax = ax.matshow(corr,cmap='coolwarm', vmin=-1, vmax=1)\nfig.colorbar(cax)\nticks = np.arange(0,len(nyc_j.columns),1)\nax.set_xticks(ticks)\nplt.xticks(rotation=90)\nax.set_yticks(ticks)\nax.set_xticklabels(nyc_j.columns)\nax.set_yticklabels(nyc_j.columns)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Log price by accommodates pair plot\nnyc_num_accommodates = nyc[['log_price','accommodates']]#.select_dtypes(include=np.number)\nsns.pairplot(nyc_num_accommodates, height=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Log price by beds pair plot\nnyc_num_beds = nyc[['log_price','beds']]#.select_dtypes(include=np.number)\nsns.pairplot(nyc_num_beds, height=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Machine Learning","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 4.1 Linear Regression","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Try 1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"nyc_j.dropna(inplace=True)\nnyc_before_dummies_df.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting the data to X and y\nX = nyc_j.drop('log_price', axis=1)\ny = nyc_j.log_price\n\n# Splitting data to train and test\nX_train, X_test, y_train, y_test = split(X,y,train_size=0.7,random_state=12345)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using Scikitlearn Linear regression & fit func\nlinear_model_1 = LinearRegression()\nlinear_model_1.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# list of linear regression coefficient\nlist(zip(X_train.columns, linear_model_1.coef_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"linear_model_1.coef_[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y pred based on training set\ny_train_pred = linear_model_1.predict(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Comparing between y_train and y_train_pred\nax = sns.scatterplot(x=y_train, y=y_train_pred)\nax.plot(y_train, y_train, 'r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the train set RMSE\nmse(y_train, y_train_pred)**0.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking results on the test set\ny_test_pred = linear_model_1.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Comparing between y_test and y_test_pred\nax = sns.scatterplot(x=y_test, y=y_test_pred)\nax.plot(y_test, y_test, 'r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking test set RMSE\nmse(y_test, y_test_pred)**0.5","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Linear Regression - Try 2 (Removing anomalous dots)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing anomalous dots\ncols=['accommodates',\t'bathrooms'\t,'cleaning_fee',\t'number_of_reviews',\t'review_scores_rating',\t'beds'\t,'year_host']\n\nfor col in cols:\n    if nyc_j[col].dtype == 'float64':\n        std = nyc_j[col].std()\n        ave = nyc_j[col].mean()\n        nyc_j = nyc_j.loc[nyc_j[col].between(ave-3.6*std, ave+3.6*std)]\n        print(f'processing {col:10} --> {nyc_j.shape[0]:5} nyc_j remain')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting the data\nX = nyc_j.drop('log_price', axis=1)\ny = nyc_j.log_price\n\nX_train, X_test, y_train, y_test = split(X,y,train_size=0.7,random_state=12345)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"linear_model_2 = LinearRegression().fit(X_train, y_train)\nlist(zip(X_train.columns, linear_model_2.coef_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y train prediction\ny_train_pred = linear_model_2.predict(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y train vs y train pred\nax = sns.scatterplot(x=y_train, y=y_train_pred)\nax.plot(y_train, y_train, 'r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training RMSE\nmse(y_train, y_train_pred)**0.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y test prediction\ny_test_pred = linear_model_2.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y test vs y test pred\nax = sns.scatterplot(x=y_test, y=y_test_pred)\nax.plot(y_test, y_test, 'r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Testing RMSE\nmse(y_test, y_test_pred)**0.5","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Linear Regression Try 3 (Using stepwise)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# stepwise\nimport statsmodels.api as sm\n\ndef stepwise_selection(X, y, \n                       initial_list=[], \n                       threshold_in=0.01, \n                       threshold_out = 0.05, \n                       verbose=True):\n    \"\"\" Perform a forward-backward feature selection \n    based on p-value from statsmodels.api.OLS\n    Arguments:\n        X - pandas.DataFrame with candidate features\n        y - list-like with the target\n        initial_list - list of features to start with (column names of X)\n        threshold_in - include a feature if its p-value < threshold_in\n        threshold_out - exclude a feature if its p-value > threshold_out\n        verbose - whether to print the sequence of inclusions and exclusions\n    Returns: list of selected features \n    Always set threshold_in < threshold_out to avoid infinite looping.\n    See https://en.wikipedia.org/wiki/Stepwise_regression for the details\n    \"\"\"\n    included = list(initial_list)\n    while True:\n        changed=False\n        # forward step\n        excluded = list(set(X.columns)-set(included))\n        new_pval = pd.Series(index=excluded)\n        for new_column in excluded:\n            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n            new_pval[new_column] = model.pvalues[new_column]\n        best_pval = new_pval.min()\n        if best_pval < threshold_in:\n            best_feature = new_pval.argmin()\n            included.append(best_feature)\n            changed=True\n            if verbose:\n                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n\n        # backward step\n        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n        # use all coefs except intercept\n        pvalues = model.pvalues.iloc[1:]\n        worst_pval = pvalues.max() # null if pvalues is empty\n        if worst_pval > threshold_out:\n            changed=True\n            worst_feature = pvalues.argmax()\n            included.remove(worst_feature)\n            if verbose:\n                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n        if not changed:\n            break\n    return included\n\nresult = stepwise_selection(X, y)\n\nprint('resulting features:')\nprint(result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = X[['kids_friendly', 'room_Private room', 'distance_to_t_squre', 'room_Shared room', 'accommodates', 'neigbourhood_level', 'Elect_Tech', 'distance_to_w_street', 'bathrooms', 'distance_to_c_train', 'review_scores_rating', 'bedrooms_3.0', 'bedrooms_2.0', 'bedrooms_4.0', 'longitude_east', 'year_end', 'property_Hotel2', 'property_House', 'number_of_reviews', 'year_start', 'property_Timeshare', 'latitude_north', 'bedrooms_5.0', 'beds', 'accesibility', 'bedrooms_7.0', 'bedrooms_6.0', 'property_Other', 'year_host', 'real_bed']]\ny = nyc_j.log_price","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = split(X,y,train_size=0.7,random_state=12345)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"linear_model_3 = LinearRegression().fit(X_train, y_train)\nlist(zip(X_train.columns, linear_model_2.coef_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y train prediction\ny_train_pred = linear_model_3.predict(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y train vs y train pred\nax = sns.scatterplot(x=y_train, y=y_train_pred)\nax.plot(y_train, y_train, 'r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training RMSE\nmse(y_train, y_train_pred)**0.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y test prediction\ny_test_pred = linear_model_3.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y test vs y test pred\nax = sns.scatterplot(x=y_test, y=y_test_pred)\nax.plot(y_test, y_test, 'r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Testing RMSE\nmse(y_test, y_test_pred)**0.5","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4.2 Decision Trees","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Try 1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting data to X and y\nX = nyc_before_dummies_df.drop('log_price', axis=1)\ny = nyc_before_dummies_df.log_price","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting data to train and test\nX_train, X_test, y_train, y_test = split(X,y,train_size=0.7,random_state=12345)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The descision tree model\ndt_model_1 = DecisionTreeRegressor(max_depth=5)\ndt_model_1.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualization Tree\ndef visualize_tree(model, md=3):\n    dot_data = StringIO()  \n    export_graphviz(model, out_file=dot_data, feature_names=X_train.columns, max_depth=md)\n    graph = pydot.graph_from_dot_data(dot_data.getvalue())[0]  \n    return Image(graph.create_png(), width=1800) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualize_tree(dt_model_1, 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train Prediction\ny_train_pred = dt_model_1.predict(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.scatterplot(x=y_train, y=y_train_pred)\nax.plot(y_train, y_train, 'r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Training RMSE\nmse(y_train, y_train_pred)**0.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test Prediction\ny_test_pred = dt_model_1.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.scatterplot(x=y_test, y=y_test_pred)\nax.plot(y_test, y_test, 'r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test RMSE\nmse(y_test, y_test_pred)**0.5","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Try 2 - Removing anomalous dots & checking for Hyper Parameters","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_model = nyc_before_dummies_df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing anomalous dots\ncols=['accommodates',\t'bathrooms'\t,'cleaning_fee',\t'number_of_reviews',\t'review_scores_rating',\t'beds'\t,'year_host']\n\nfor col in cols:\n    if sub_model[col].dtype == 'float64':\n        std = nyc_j[col].std()\n        ave = nyc_j[col].mean()\n        sub_model = sub_model.loc[sub_model[col].between(ave-3.6*std, ave+3.6*std)]\n        print(f'processing {col:10} --> {sub_model.shape[0]:5} sub_model remain')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_X = sub_model.drop('log_price', axis=1)\nsub_y = sub_model.log_price\n\nsub_X_train, sub_X_test, sub_y_train, sub_y_test = split(sub_X, sub_y, train_size=0.7,random_state=12345)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# max_depth check\ncomplexity = range (2, 50 , 1)\nscores = pd.DataFrame(index=complexity, columns=['train', 'test'])\n\nfor leafs in complexity:\n    model = DecisionTreeRegressor(max_leaf_nodes=leafs).fit(sub_X_train, sub_y_train)\n    \n    sub_y_train_pred = model.predict(sub_X_train)\n    scores.loc[leafs, 'train'] = mse(sub_y_train_pred, sub_y_train) ** 0.5\n    \n    sub_y_test_pred = model.predict(sub_X_test)\n    scores.loc[leafs, 'test'] = mse(sub_y_test_pred, sub_y_test) ** 0.5\n\nscores.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# min_samples_leaf check\ncomplexity = range (1, 50 , 5)\nscores = pd.DataFrame(index=complexity, columns=['train', 'test'])\n\nfor comp in complexity:\n    model = DecisionTreeRegressor(min_samples_leaf=comp).fit(sub_X_train, sub_y_train)\n    \n    sub_y_train_pred = model.predict(sub_X_train)\n    scores.loc[comp, 'train'] = mse(sub_y_train_pred, sub_y_train) ** 0.5\n    \n    sub_y_test_pred = model.predict(sub_X_test)\n    scores.loc[comp, 'test'] = mse(sub_y_test_pred, sub_y_test) ** 0.5\n\nscores.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# max_leaf_nodes check\ncomplexity = range (2, 70 , 1)\nscores = pd.DataFrame(index=complexity, columns=['train', 'test'])\n\nfor comp in complexity:\n    model = DecisionTreeRegressor(max_leaf_nodes=comp).fit(sub_X_train, sub_y_train)\n    \n    sub_y_train_pred = model.predict(sub_X_train)\n    scores.loc[comp, 'train'] = mse(sub_y_train_pred, sub_y_train) ** 0.5\n    \n    sub_y_test_pred = model.predict(sub_X_test)\n    scores.loc[comp, 'test'] = mse(sub_y_test_pred, sub_y_test) ** 0.5\n\nscores.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Improving Hyper parameters\nl_max_depth = [2,3,4,5,6,7,8,9,10]\nl_min_samples_leaf = [20,25,30,35,40,45,50]\nl_min_impurity_decrease = [0.001,0.002,0.003,0.004,0.005]\nmax_leaf_nodes= [40,45,50,55,60]\n\nfrom itertools import product\n\nscores = []\nfor i, (md, msl, mid, mln) in enumerate(product(l_max_depth, l_min_samples_leaf, l_min_impurity_decrease,max_leaf_nodes)):\n    sub_model = DecisionTreeRegressor(max_depth=md, min_samples_leaf=msl, min_impurity_decrease=mid, max_leaf_nodes=mln)\n    sub_model.fit(sub_X_train, sub_y_train)\n    y_train_pred = sub_model.predict(sub_X_train)\n    train_score = mse(sub_y_train, sub_y_train_pred)**0.5\n    y_test_pred = sub_model.predict(sub_X_test)\n    test_score = mse(sub_y_test, sub_y_test_pred)**0.5\n    scores.append((md, msl, mid, mln,train_score, test_score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted(scores, key=lambda x: x[3], reverse=False) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt_model_2 = DecisionTreeRegressor(max_leaf_nodes=12, max_depth=8, min_samples_leaf=150, min_impurity_decrease=0.002).fit(sub_X_train, sub_y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def visualize_tree(model, md=5):\n    dot_data = StringIO()  \n    export_graphviz(model, out_file=dot_data, feature_names=X_train.columns, max_depth=md)\n    graph = pydot.graph_from_dot_data(dot_data.getvalue())[0]  \n    return Image(graph.create_png(), width=1200) \n\nvisualize_tree(dt_model_2, 7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_y_train_pred = dt_model_2.predict(sub_X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.scatterplot(x=sub_y_train, y=sub_y_train_pred)\nax.plot(y_train, y_train, 'r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RMSE = mse(sub_y_train, sub_y_train_pred)**0.5\nRMSE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_y_test_pred = dt_model_2.predict(sub_X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.scatterplot(x=sub_y_test, y=sub_y_test_pred)\nax.plot(y_test, y_test, 'r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RMSE = mse(sub_y_test, sub_y_test_pred)**0.5\nRMSE","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4.3 KNN Model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Try 1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting data to X and y\nX = nyc_j.drop('log_price', axis=1)\ny = nyc_j.log_price","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting data to train and test\nX_train, X_test, y_train, y_test = split(X, y, train_size=0.7, random_state=314159)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using feature scaling\nmy_scaler = StandardScaler().fit(X_train)\nX_train_scaled = pd.DataFrame(my_scaler.transform(X_train), columns=X_train.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Building the model\nknn_model_1 = KNeighborsRegressor().fit(X_train_scaled, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train Prediction\ny_train_pred = knn_model_1.predict(X_train_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y_train vs y_train_pred\nax = sns.scatterplot(x=y_train, y=y_train_pred)\nax.plot(y_train, y_train, 'r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train RMSE\nRMSE = mse(y_train, y_train_pred)**0.5\nRMSE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scaling X test\nX_test_scaled = my_scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y Test prediction\ny_test_pred = knn_model_1.predict(X_test_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.scatterplot(x=y_test, y=y_test_pred)\nax.plot(y_test, y_test, 'r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RMSE = mse(y_test, y_test_pred)**0.5\nRMSE","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Try 2 - Choosing the K and dropping anomalous rows","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing anomalous dots\ncols=['accommodates',\t'bathrooms'\t,'cleaning_fee',\t'number_of_reviews',\t'review_scores_rating',\t'beds'\t,'year_host']\n\nfor col in cols:\n    if nyc_j[col].dtype == 'float64':\n        std = nyc_j[col].std()\n        ave = nyc_j[col].mean()\n        nyc_j = nyc_j.loc[nyc_j[col].between(ave-3.6*std, ave+3.6*std)]\n        print(f'processing {col:10} --> {nyc_j.shape[0]:5} nyc_j remain')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Choosing the best KNN\nRMSE = []\nfor num in range(1, 12):\n    knn_model_1 = KNeighborsRegressor(n_neighbors=num).fit(X_train, y_train)\n    y_test_pred = knn_model_1.predict(X_test)\n    RMSE1 = mse(y_test, y_test_pred)**0.5\n    RMSE.append(RMSE1)\n\n    print(num,'-',RMSE1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting data to X and y\nX = nyc_j.drop('log_price', axis=1)\ny = nyc_j.log_price","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting data to train and test\nX_train, X_test, y_train, y_test = split(X, y, train_size=0.7, random_state=314159)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using feature scaling\nmy_scaler = StandardScaler().fit(X_train)\nX_train_scaled = pd.DataFrame(my_scaler.transform(X_train), columns=X_train.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Building the model\nknn_model_2 = KNeighborsRegressor(n_neighbors=10).fit(X_train_scaled, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train Prediction\ny_train_pred = knn_model_2.predict(X_train_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y_train vs y_train_pred\nax = sns.scatterplot(x=y_train, y=y_train_pred)\nax.plot(y_train, y_train, 'r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train RMSE\nRMSE = mse(y_train, y_train_pred)**0.5\nRMSE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scaling X test\nX_test_scaled = my_scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y Test prediction\ny_test_pred = knn_model_2.predict(X_test_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#y_test vs y_test_pred\nax = sns.scatterplot(x=y_test, y=y_test_pred)\nax.plot(y_test, y_test, 'r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test RMSE\nRMSE = mse(y_test, y_test_pred)**0.5\nRMSE","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Try 3 - Changing weight to distance (Default=Uniform) and using K=10","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting data to X and y\nX = nyc_j.drop('log_price', axis=1)\ny = nyc_j.log_price","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting data to train and test\nX_train, X_test, y_train, y_test = split(X, y, train_size=0.7, random_state=314159)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using feature scaling\nmy_scaler = StandardScaler().fit(X_train)\nX_train_scaled = pd.DataFrame(my_scaler.transform(X_train), columns=X_train.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Building the model\nknn_model_3 = KNeighborsRegressor(n_neighbors=10,weights='distance').fit(X_train_scaled, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train Prediction\ny_train_pred = knn_model_3.predict(X_train_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scaling X test\nX_test_scaled = my_scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y Test prediction\ny_test_pred = knn_model_3.predict(X_test_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#y_test vs y_test_pred\nax = sns.scatterplot(x=y_test, y=y_test_pred)\nax.plot(y_test, y_test, 'r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test RMSE\nRMSE = mse(y_test, y_test_pred)**0.5\nRMSE","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Conclusions","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"TEST RMSE:\n\nLinear Regression:\n\nLinear Regression try 1 - 0.34436456895591605\n\nLinear Regression try 2 - 0.34436456895591605\n\nLinear Regression try 3 - 0.3440292214619928\n\nDecision Trees:\n\nDecision Trees try 1 - 0.3567719793832864\n\nDecision Trees try 2 - 0.3639217173982088\n\nKNN:\n\nKNN Try 1 - 0.37266015133144564\n\nKNN Try 2 - 0.35106469798714157\n\nKNN Try 3 - 0.34845669081517083\n\nThe best Model for our data: Linear Regression try 3 (After removing anomalous dots and using stepwise)","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}