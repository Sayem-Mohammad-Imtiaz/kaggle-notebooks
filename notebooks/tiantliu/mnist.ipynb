{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input/digit-recognizer\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\nimport matplotlib.image as mpimg\nimport warnings\nwarnings.filterwarnings('ignore')\nimport seaborn as sns\n%matplotlib inline\n\nnp.random.seed(2)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2d0a08f72f7ef7e02a32ec7f2431790996904771"},"cell_type":"markdown","source":"### 读入数据"},{"metadata":{"_kg_hide-output":true,"trusted":true,"_uuid":"36e5c8ce3955b3c13d815c7c70ce0e968d89077f"},"cell_type":"code","source":"train = pd.read_csv('../input/digit-recognizer/train.csv')\ntest = pd.read_csv('../input/digit-recognizer/test.csv')\nprint(train.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a10a694237555cbb645471dabbf1b5434af73733"},"cell_type":"code","source":"VALIDATION_SIZE = 2000\nLEARNING_RATE = 1e-4\nTRAINING_ITERATIONS = 2500\nDROPOUT = 0.5\nBATCH_SIZE = 50","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"92d441aa676e0f8ff2bd4f08a87823daa4207585"},"cell_type":"code","source":"y_train = train['label']\ny_train = pd.get_dummies(y_train).values\nlabels = y_train.astype(np.uint8)\nprint(y_train.shape[0])\nprint(y_train[10])\nimages = train.iloc[:,1:].values.astype(np.float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df68df69e358ddf68b4b2d2887ad90c5da3c33c0"},"cell_type":"code","source":"images = np.multiply(images,1.0/255.0)\nprint('images({0[0]},{0[1]})'.format(images.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c8d3a388259a90ee0d8f0f99a2d236cd18ffcc46"},"cell_type":"code","source":"image_size = images.shape[1]\nprint(image_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"30fb756e31a3b7a897feeb0aa7b05c9458c742f7"},"cell_type":"code","source":"labels_flat = train.iloc[:,0].values.ravel()\nprint('labels_flat({0})'.format(len(labels_flat)))\nprint ('labels_flat[{0}] => {1}'.format(10,labels_flat[10]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7e0c85f533455cb9b70ac5791898a2df29e84822"},"cell_type":"code","source":"labels_count = np.unique(labels_flat).shape[0]\n\nprint('labels_count => {0}'.format(labels_count))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"22f8964d5c5d80f5f552ad522e4489ca6a52bd24"},"cell_type":"code","source":"validation_images = images[:VALIDATION_SIZE]\nvalidation_labels = y_train[:VALIDATION_SIZE]\n\ntrain_images = images[VALIDATION_SIZE:]\ntrain_labels = y_train[VALIDATION_SIZE:]\nprint(train_images.shape)\nprint(validation_images.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ab1dfc3ed3b3e3ea8e8890465f6b335272797ba6"},"cell_type":"code","source":"def weight_variable(shape):\n    Weights = tf.Variable(tf.truncated_normal(shape,stddev = 0.1))\n    return Weights\n\ndef biases_variable(shape):\n    biases = tf.Variable(tf.constant(0.1,shape=shape))\n    return biases\n\ndef conv2d(x,W):\n    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')\n\ndef max_pool_2x2(x):\n    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5d156de3f1f609f789c20a5872538586f5f96d77"},"cell_type":"code","source":"# 第一层\nW_conv1 = weight_variable([5,5,1,32])\nb_conv1 = biases_variable([32])\n\nx = tf.placeholder('float',shape = [None,784])\ny_ = tf.placeholder('float',shape = [None,10])\n\n# (4000,28,28,1)\nimage = tf.reshape(x,[-1,28,28,1])\n\nh_conv1 = tf.nn.relu(conv2d(image,W_conv1) + b_conv1)\nprint(h_conv1.get_shape())  # 4000,28,28,32\nh_pool1 = max_pool_2x2(h_conv1) # 4000,14,14,32\nprint(h_pool1.get_shape())\n\nlayer1 = tf.reshape(h_conv1,(-1,28,28,4,8))\nlayer1 = tf.transpose(layer1,(0,3,1,4,2))\nlayer1 = tf.reshape(layer1,(-1,28*4,28*8))\n\nW_conv2 = weight_variable([5,5,32,64])\nb_cov2 = biases_variable([64])\n\nh_conv2 = tf.nn.relu(conv2d(h_pool1,W_conv2) + b_cov2)\nprint(h_conv2.get_shape())  # 4000,14,14,64\nh_pool2 = max_pool_2x2(h_conv2)\nprint(h_pool2.get_shape()) # 4000,7,7,64\n\nlayer2 = tf.reshape(h_conv2,(-1,14,14,4,16))\nlayer2 = tf.reshape(layer2,(0,3,1,4,2))\nlayer2 = tf.reshape(layer2,(-1,14*4,14*16))\n\nW_fc1 = weight_variable([7 * 7 * 64,1024])\nb_fc1 = biases_variable([1024])\n\nh_pool2_flat = tf.reshape(h_pool2,[-1,7 * 7 * 64])\nh_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1) + b_fc1)\nprint(h_fc1.get_shape())\n\nkeep_prob = tf.placeholder('float')\nh_fc1_drop = tf.nn.dropout(h_fc1,keep_prob)\n\nW_fc2 = weight_variable([1024,10])\nb_fc2 = biases_variable([10])\ny = tf.nn.softmax(tf.matmul(h_fc1,W_fc2) + b_fc2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68954777def6645fcfa11abd9bf959610a28a7d5"},"cell_type":"code","source":"#cost function\ncross_entroy = - tf.reduce_sum(y_ * tf.log(y))\n\ntrain_step = tf.train.AdamOptimizer(LEARNING_RATE).minimize(cross_entroy)\n\ncorrect_prediction = tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction,'float'))\n\npredict = tf.argmax(y,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0dbec084b97b5bb6862ad68b8774b4da684b11fa"},"cell_type":"code","source":"epochs_completed = 0\nindex_in_epoch = 0\nnumber_examples = train_images.shape[0]\n\ndef next_batch(batch_size):\n    global train_images\n    global train_labels\n    global index_in_epoch\n    global epochs_completed\n    \n    start = index_in_epoch\n    index_in_epoch += batch_size\n    \n    if index_in_epoch > number_examples:\n        #finished epoch\n        epochs_completed += 1\n        #shuffle data\n        perm = np.arange(number_examples)\n        np.random.shuffle(perm)\n        train_images = train_images[perm]\n        train_labels = train_labels[perm]\n        #start next epoch\n        start = 0\n        index_in_epoch = batch_size\n        assert batch_size <= number_examples\n    end = index_in_epoch\n    return train_images[start:end],train_labels[start:end]\nprint(\"DONE\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9aa80d910e5e8e673302d35b71ebedba8bd2ff5c"},"cell_type":"code","source":"init = tf.global_variables_initializer()\nsess = tf.InteractiveSession()\nsess.run(init)\n\ntrain_accuracies = []\nvalidation_accuracies = []\nx_range = []\n\ndisplay_step = 1\n\nfor i in range(TRAINING_ITERATIONS):\n    batch_xs,batch_ys = next_batch(BATCH_SIZE)\n    \n    if i % display_step == 0 or (i+1) == TRAINING_ITERATIONS:\n        train_accuracy = accuracy.eval(feed_dict={\n            x:batch_xs,\n            y_:batch_ys,\n            keep_prob:1.0\n        })\n        if(VALIDATION_SIZE):\n            validation_accuracy = accuracy.eval(feed_dict={\n                x:validation_images[0:BATCH_SIZE],\n                y_:validation_labels[0:BATCH_SIZE],\n                keep_prob:1.0\n            })\n            print(\"train_accuracy / validation_accuracy => %.2f / %.2f for step %d\"%(train_accuracy,validation_accuracy,i))\n            validation_accuracies.append(validation_accuracy)\n        else:\n            print(\"train_accuracy => %.4f for step %d\"%(train_accuracy,i))\n        train_accuracies.append(train_accuracy)\n        x_range.append(i)\n        \n        if i%(display_step) == 0 and i:\n            display_step *= 10\n    sess.run(train_step,feed_dict={\n        x:batch_xs,\n        y_:batch_ys,\n        keep_prob:DROPOUT\n    })\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b1c423c6b39937e4f84451b82c17f26e6a1a9f8e"},"cell_type":"code","source":"if (VALIDATION_SIZE):\n    validation_accuracy = accuracy.eval(feed_dict = {\n        x:validation_images,\n        y_:validation_labels,\n        keep_prob:1.0\n    })\n    print(\"Validation_accuracy => %.4f\"%validation_accuracy)\n    plt.plot(x_range,train_accuracies,'-b',label = 'Training')\n    plt.plot(x_range,validation_accuracies,'-g',label = 'Validation')\n    plt.legend(loc = \"lower right\",frameon = False)\n    plt.ylim(ymax = 1.1)\n    plt.xlabel('step')\n    plt.ylabel('accuracy')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc36dc0b419566e3b5af779b1229f16b514b360e"},"cell_type":"code","source":"test_images = pd.read_csv('../input/digit-recognizer/test.csv').values\ntest_images = test_images.astype(np.float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8de4e0ba67fd7a5f66677c064871948e9649368c"},"cell_type":"code","source":"# convert from [0:255] => [0.0:1.0]\ntest_images = np.multiply(test_images, 1.0 / 255.0)\n\nprint('test_images({0[0]},{0[1]})'.format(test_images.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"301145d1aa0f980fc9e9770499507fa20d846e93"},"cell_type":"code","source":"# predict test set\n#predicted_lables = predict.eval(feed_dict={x: test_images, keep_prob: 1.0})\n\n# using batches is more resource efficient\npredicted_lables = np.zeros(test_images.shape[0])\nfor i in range(0,test_images.shape[0]//BATCH_SIZE):\n    predicted_lables[i*BATCH_SIZE : (i+1)*BATCH_SIZE] = predict.eval(feed_dict={x: test_images[i*BATCH_SIZE : (i+1)*BATCH_SIZE], \n                                                                                keep_prob: 1.0})\n\n\nprint('predicted_lables({0})'.format(len(predicted_lables)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b350b6398f7aceecab483d514a56af2d36bfbcf"},"cell_type":"code","source":"# output test image and prediction\ndisplay(test_images[10])\nprint ('predicted_lables[{0}] => {1}'.format(10,predicted_lables[10]))\n\n# save results\nnp.savetxt('submission.csv', \n           np.c_[range(1,len(test_images)+1),predicted_lables], \n           delimiter=',', \n           header = 'ImageId,Label', \n           comments = '', \n           fmt='%d')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8eb4926ca783599ef478a34d6f9e8cdd0d262285"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}