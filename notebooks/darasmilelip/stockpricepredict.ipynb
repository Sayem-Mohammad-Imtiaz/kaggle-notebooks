{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, GRU, Bidirectional, LSTM\nfrom keras.optimizers import SGD\nimport math\nfrom sklearn.metrics import mean_squared_error\nimport keras","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_gru_network():\n    regressorGRU = Sequential()\n    # First GRU layer with Dropout regularisation\n    \n    regressorGRU.add(GRU(units = 30, return_sequences = False, input_shape=(1,2), activation='tanh'))\n    regressorGRU.add(Dropout(0.3))\n    \n    # The output layer\n    regressorGRU.add(Dense(units=1))\n    return regressorGRU","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = make_gru_network()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='rmsprop', loss='mean_squared_error')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = np.array([1,2,2,3,3,4,4,5])\ny_train = np.array([\n    3,\n    4,\n    5,\n    6\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = x_train.reshape(4,1,2)\nx_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x_train, y_train, epochs = 30, batch_size = 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_set = np.array([[[1,2]]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.predict(test_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load dataset from csv file\ndataset = pd.read_csv('../historical_stock_prices.csv', index_col='date', parse_dates=['date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Separate train/test\ntrainSet = dataset['2015':'2017'].sort_values(by=['ticker','date'])\ntestSet = dataset['2018':].sort_values(by=['ticker','date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"trainSet.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# All symbols\nsymbols = trainSet.ticker.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"timesteps = 60\ndef make_samples(\n    data_1,\n    s):\n    \n    stop_append = {}\n    for i in prediction_intervals:\n        stop_append.update({i:False}) \n    l = len(data_1)\n    \n    for i in range(timesteps, l):\n        x_1 = data_1[i-timesteps: i, 0]\n        for j in stop_append:\n            if not stop_append[j]:\n                if i+j-1 < l:\n                    y = data_1[i+j-1,0]\n                    y = y.reshape(-1,1)\n                    x_1 = x_1.reshape(-1,1)\n                    \n                    sc = MinMaxScaler(feature_range=(0,1))\n                    sc.partial_fit(x_1)\n                    sc.partial_fit(y)\n                    \n                    train_set[s]['x_1'][j].append(sc.transform(x_1))\n                    train_set[s]['y'][j].append(sc.transform(y))\n                    \n                    if y == data_1[l-1,0]:\n                        stop_append[j] =True","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Define train_set\ntrain_set = {}\nprediction_intervals = [1,3,5,10]\nt = 1\nfor s in symbols:\n    train_set.update({s:{\n        'x_1':{},\n        'y':{},\n    }})\n    for i in prediction_intervals:\n        train_set[s]['x_1'][i] = []\n        train_set[s]['y'][i] = []\n            \n    data_1 = trainSet.loc[trainSet['ticker'] == s][['adj_close']].values\n        \n    make_samples(\n        data_1, \n        s)\n    if t == 2000:\n        break\n    t += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Define earlystopping callback function\nes = keras.callbacks.EarlyStopping(monitor='val_loss',patience=5, mode='min', restore_best_weights=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def make_gru_network():\n    regressorGRU = Sequential()\n    # First GRU layer with Dropout regularisation\n    \n    regressorGRU.add(GRU(units = 30, return_sequences = False, input_shape=(1,60), activation='tanh'))\n    regressorGRU.add(Dropout(0.3))\n    \n    # The output layer\n    regressorGRU.add(Dense(units=1))\n    return regressorGRU","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Training model with one feature in train_set\nmodel = {}\nmodel_history = {}\nfor i in prediction_intervals:\n    model[i] = make_gru_network()\n    model[i].compile(optimizer='rmsprop', loss='mean_squared_error')\n    \n    n_epoch = 100\n    x_train = []\n    y_train = []\n    \n    for s in train_set:\n        for j in range (0, len(train_set[s]['x_1'][i])):\n            x = [\n                train_set[s]['x_1'][i][j],\n            ]\n            x_train.append(x)\n        for j in train_set[s]['y'][i]:\n            y_train.append(j)\n    X_train, Y_train = np.array(x_train), np.array(y_train)\n    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2])\n    Y_train = Y_train.reshape(Y_train.shape[0])\n    \n    print(X_train.shape, Y_train.shape)\n    print('Fitting prediction interval {}  model'.format(i))\n    model_history[i] = model[i].fit(X_train, Y_train, epochs = n_epoch, batch_size = 6000, \n                                    validation_split = 0.3,callbacks=[es])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"for i in prediction_intervals:\n    plt.plot(model_history[i].history['val_loss'])\n    plt.plot(model_history[i].history['loss'])\n    plt.title('Model Loss of Interval {}'.format(i))\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['val_loss', 'loss'], loc='upper right')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test our model"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Calculate Mean squared_error\ndef return_mse(test,predicted):\n    mse = mean_squared_error(test, predicted)\n    return mse","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Plotting graph\ndef plotting_graph(y_test, y_pred, ticker, des):\n    plt.plot(y_test, color='green', label='Actual adj_close value')\n    plt.plot(y_pred, color='red', label='Predicted adj_close value')\n    plt.title('Prediction of {} on {}'.format(ticker, des))\n    plt.xlabel('Time steps')\n    plt.ylabel('adj_close value')\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Define test_set\ndef make_test_data(s):\n    scaler = {s:{}}\n    test_set = {s:{}}\n    test_set.update({s:{\n            'x_1':{},\n            'y':{},\n        }})\n    for i in prediction_intervals:\n            test_set[s]['x_1'][i] = []\n            test_set[s]['y'][i] = []\n            scaler[s][i] = []\n\n    data_1 = testSet.loc[testSet['ticker'] == s][['adj_close']].values\n    \n    stop_append = {}\n    for i in prediction_intervals:\n        stop_append.update({i:False}) \n    l = len(data_1)\n\n    for i in range(timesteps, l):\n        x_1 = data_1[i-timesteps: i, 0]\n        for j in stop_append:\n            if not stop_append[j]:\n                if i+j-1 < l:\n                    y = data_1[i+j-1,0]\n                    y = y.reshape(-1,1)\n                    x_1 = x_1.reshape(-1,1)\n                    \n                    sc = MinMaxScaler(feature_range=(0,1))\n                    sc.partial_fit(x_1)\n                    sc.partial_fit(y)\n                    scaler[s][j].append(sc)\n                    \n                    test_set[s]['x_1'][j].append(sc.transform(x_1))\n                    test_set[s]['y'][j].append(y)\n                    \n                    if y == data_1[l-1,0]:\n                        stop_append[j] =True\n                    \n    return test_set, scaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def make_prediction(data, s, scaler):\n    mse_val = {}\n    y_true_val = {}\n    y_pred_val = {}\n    \n    for i in prediction_intervals:\n        x_test = []\n        for j in range (0, len(data[s]['x_1'][i])):\n            x = [\n                data[s]['x_1'][i][j],\n            ]\n            x_test.append(x)\n\n        X_test = np.array(x_test)\n        X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2])\n        \n        result = model[i].predict(X_test)\n        \n        y_pred = []\n        for j in range(0,len(result)):\n            y = result[j]\n            y = y.reshape(-1,1)\n            k = scaler[s][i][j].inverse_transform(y)\n            y_pred.append(k[0][0])\n                    \n        y_test = data[s]['y'][i]\n        y_true = np.array(y_test)\n        y_true = y_true.reshape(y_true.shape[0])\n    \n        y_true_val[i] = y_true\n        y_pred_val[i] = y_pred\n\n        mse_val[i] = return_mse(y_true, y_pred) \n    return y_true_val, y_pred_val, mse_val","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predicting test sample"},{"metadata":{"trusted":false},"cell_type":"code","source":"s = 'AAPL'\ndata, sc = make_test_data(s)\ny_true_val, y_pred_val, mse_val = make_prediction(data, s, sc)\n\nfor i in mse_val:\n    print('Test Set -> MSE of {} inveral {}: {}'.format(s, i, mse_val[i]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"for i in prediction_intervals:\n    plotting_graph(y_true_val[i], y_pred_val[i], s, 'Test Set interval {}'.format(i))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MSE of 5 symbols"},{"metadata":{"trusted":false},"cell_type":"code","source":"test_symbols = ['A', 'ACER', 'MSFT', 'ABC', 'AAPL']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"all_mse = {}\nfor s in test_symbols:\n    all_mse[s] = {}\n    data, sc = make_test_data(s)\n    y_true_val, y_pred_val, mse_val = make_prediction(data, s, sc)\n    for i in prediction_intervals:\n        all_mse[s][i] = mse_val[i]\n        all_mse[s][i] = mse_val[i]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"all_mse_1 = []\nall_mse_3 = []\nall_mse_5 = []\nall_mse_10 = []\nfor s in all_mse:\n    all_mse_1.append(round(all_mse[s][1], 2))\n    all_mse_3.append(round(all_mse[s][3], 2))\n    all_mse_5.append(round(all_mse[s][5], 2))\n    all_mse_10.append(round(all_mse[s][10], 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# MSE of interval 1\nall_mse_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# MSE of interval 3\nall_mse_3","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# MSE of interval 5\nall_mse_5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MSE of interval 10\nall_mse_10","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat":4,"nbformat_minor":1}