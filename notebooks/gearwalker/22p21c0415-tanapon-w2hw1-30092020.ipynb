{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom math import sqrt\nfrom sklearn.svm import SVR\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, SGDRegressor, ARDRegression\nfrom sklearn.ensemble import AdaBoostRegressor, BaggingRegressor, RandomForestRegressor\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/solar-power-generation-data/Plant_1_Generation_Data.csv\")\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sensor data from the plant. It's showing only from 1 source per plant\ndf2 = pd.read_csv(\"../input/solar-power-generation-data/Plant_1_Weather_Sensor_Data.csv\")\ndf2\n#pd.unique(df2.SOURCE_KEY)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['DATE_TIME'] = pd.to_datetime(df['DATE_TIME'])  \ndf2['DATE_TIME'] = pd.to_datetime(df2['DATE_TIME'])  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract datetime to time of the day features (0.0 - 24.0 hour float format)\ndf['TIME'] = df['DATE_TIME'].dt.hour + df['DATE_TIME'].dt.minute / 60\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Every plant has many sources. Every sources has their own characteristic.\n# For more percise, we separated dataset for each source.\n\nsource_list = pd.unique(df['SOURCE_KEY'])\nprint(source_list)\n\ntarget_source = '1BY6WEcLGh8j5v7'\n\n# we selected dataset from 1 source\ndataset = df[df.SOURCE_KEY==target_source]\ndataset.reset_index(drop=True, inplace=True)\nprint(dataset.shape)\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Join yield table witn sensor table via datetime-index \ndataset=dataset.merge(df2,on=\"DATE_TIME\", how='inner')\nprint(f\"Null checking:\\n{dataset.isnull().sum()}\")\ndataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop unformated colume\ndataset = dataset.drop(['DATE_TIME', 'PLANT_ID_x', 'SOURCE_KEY_x', 'PLANT_ID_y', 'SOURCE_KEY_y'], axis=1)\ndataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature engineering: Calculate delta-yield per 15 min.\ndataset['DELTA_YIELD'] = dataset['TOTAL_YIELD'].diff().fillna(0)\n\n# Feature engineering: Calculate moving average delta-yield.\ndataset['MA_4'] = dataset['DELTA_YIELD'].rolling(window=4).mean().fillna(0) # 1 Hour MA\ndataset['MA_96'] = dataset['DELTA_YIELD'].rolling(window=69).mean().fillna(0) # 1 Day MA\n\n#dataset = dataset.round(4)\n\ndataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# shuffle dataset in-place and reset the index (increase distribution)\n#dataset = dataset.sample(frac=1).reset_index(drop=True)\n#dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split data to 10 fold\ndata_fold = []\nfor i in range(0,10):\n    f = dataset.iloc[i::10, :]\n    data_fold.append(f)\ndata_fold[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# select features for training\n#col_X = ['DC_POWER','AC_POWER','TIME','AMBIENT_TEMPERATURE','MODULE_TEMPERATURE','IRRADIATION','MA_4','MA_96']\ncol_X = ['TIME','DC_POWER','MODULE_TEMPERATURE']\ncol_y = ['DELTA_YIELD']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models_name = ['LinearRegression','Ridge', 'Lasso', 'ElasticNet', 'SGDRegressor','AdaBoostRegressor', 'BaggingRegressor', 'RandomForestRegressor']\n\nmodels = []\nmodels.append(LinearRegression())\nmodels.append(Ridge(alpha=1.0))\nmodels.append(Lasso(alpha=0.1,max_iter=2000))\nmodels.append(ElasticNet(random_state=0,max_iter=2000000))\nmodels.append(SGDRegressor(max_iter=1000, tol=1e-3))\nmodels.append(AdaBoostRegressor(random_state=0, n_estimators=100))\nmodels.append(BaggingRegressor(base_estimator=SVR(),n_estimators=10, random_state=0))\nmodels.append(RandomForestRegressor(max_depth=5, random_state=0))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, m in enumerate(models):\n    print(f\"[{models_name[i]}] Predict 15 min instance yield from current data.\")\n    for f in range(0,10):\n        #X = data_fold[f].loc[:, col_X].values\n        #y = data_fold[f].loc[:, col_y].values.ravel()\n        \n        X = data_fold[f][col_X]\n        y = data_fold[f][col_y]\n        \n        # Normalize\n        X =(X-X.min())/(X.max()-X.min())\n        y =(y-y.min())/(y.max()-y.min())\n        \n        y = y.values.ravel()\n\n        # split into train test sets\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n\n        m.fit(X_train, y_train)\n        y_pred = m.predict(X_test)\n        print(f\"Fold({f}) RMSE : {sqrt(mean_squared_error(y_test, y_pred))}\")\n    print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}