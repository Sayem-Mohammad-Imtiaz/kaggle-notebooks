{"cells":[{"metadata":{},"cell_type":"markdown","source":"- <a href='#1'>1. Data</a>\n    - <a href='#1.1'>1.1. Data overview</a>\n- <a href='#2'>2. Data Cleansing</a>\n- <a href='#3'>3. Exploratory Analysis</a>\n    - <a href='#3.1'>3.1.Churn Ratio Comparison</a>\n    - <a href='#3.2'>3.2. Frequency Distribution of Tenure</a>\n    - <a href='#3.3'>3.3. Frequency Distribution of Targets</a>\n    - <a href='#3.4'>3.4. Distribution Plot of Monthly and Total Charges </a>\n- <a href='#4'>4. Data Preprocessing</a>\n    - <a href='#4.1'>4.1. Deal with Categorical Variables</a>\n    - <a href='#4.2'>4.2. Scaling and Splitting</a>\n- <a href='#5'>5. Logistic Regression Model</a>\n- <a href='#6'>6. Random Forest Classifier</a>\n    - <a id='6.1'>6.1. Number of Leaf Nodes- Grid Search</a>\n    - <a id='6.2'>6.2. Predictions</a>\n- <a href='#7'>7. Decision Tree Regression</a>\n- <a href='#8'>8. Decision Tree Regression</a>\n    - <a href='#8.1'>8.1. Decision Tree</a>\n- <a href='#9'>9. Random Forest Regression</a> "},{"metadata":{},"cell_type":"markdown","source":"# <a id='1'>1.Data</a>"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nraw_data = pd.read_csv(\"../input/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\nraw_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='1.1'>1.1. Data overview</a>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"raw_data.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" # <a id='2'>2. Data Cleansing</a>"},{"metadata":{"trusted":true,"collapsed":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"#mapping senior citizen 1 to yes and 0 to no for visulization purposes and check info to identify data types\nraw_data['SeniorCitizen']=raw_data['SeniorCitizen'].map({1:'Yes', 0:'No'})\nraw_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_kg_hide-output":true},"cell_type":"code","source":"#Seems No null values but some elements in TotalCharges columns are spaces (''), those do not not showup as nulls \nraw_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"# change '' to NaN\nraw_data_with_nan  = raw_data.replace(' ', np.nan)\n# now we have 11 null elements\nraw_data_with_nan.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_kg_hide-output":true},"cell_type":"code","source":"#mising values (null) percentage is small(0.15%). We can drop all those rows\nprint (\"Missing Values Percentage: {}%\".format(11/raw_data_with_nan.shape[0]*100))\ndata_no_mv = raw_data_with_nan.dropna(axis=0)\n#change data type of TotalCharges, object to float for further analysis \ndata_no_mv['TotalCharges'] = data_no_mv['TotalCharges'].astype(float)\n\n#customer id does not effect on analysis. It will drop from the dataset\ndata_no_mv_no_id = data_no_mv.drop(['customerID'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" # <a id='3'>3. Exploratory Analysis</a>"},{"metadata":{},"cell_type":"markdown","source":"## <a id='3.1'>3.1.Churn Ratio Comparison</a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\n#collect all columns with datatype 'Object'\nobject_cols = list(data_no_mv_no_id.select_dtypes(include=['object']).columns)\n#remove \"Churn\" column\nobject_cols.remove('Churn')\nfig, axes = plt.subplots(4, 4, figsize=(20, 20), sharex=True)\ni=0\nfor colname in object_cols:\n  i=i+1\n  ax1 = fig.add_subplot(4,4,i)\n  sns.countplot(x='Churn', hue=colname, data=data_no_mv_no_id)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='3.2'>3.2. Frequency Distribution of Tenure</a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(20,5))\ntenure_count = data_no_mv_no_id['tenure'].value_counts()\nsns.barplot(tenure_count.index, tenure_count.values, alpha=0.9)\nplt.title('Frequency distribution of Tenures', fontsize='17')\nplt.xlabel('Number of months', fontsize='15')\nplt.ylabel('Number of occurences',fontsize='15')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='3.3'>3.3. Frequency Distribution of Targets</a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"churn_count = data_no_mv_no_id['Churn'].value_counts()\nplt.figure(figsize=(4,2))\nplt.bar(churn_count.index,churn_count.values)\nplt.xlabel('Churn')\nplt.ylabel('Number of occurences')\nplt.title('frequency of target values')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='3.4'>3.4. Distribution Plot of Monthly Charges</a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"sns.distplot(data_no_mv_no_id['MonthlyCharges'])\nplt.show()\nsns.distplot(data_no_mv_no_id['TotalCharges'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a id='4'>4. Data Preprocessing</a>"},{"metadata":{},"cell_type":"markdown","source":"## <a id='4.1'>4.1. Deal with Categorical Variables</a>"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# change categorical variables to numerical variables (one-hot). Drop first column for each \n# category to avoid extra correlinearity.\ndata_pre_processed = pd.get_dummies(data_no_mv_no_id,drop_first=True)\n#separate input and targets\ninputs = data_pre_processed.drop('Churn_Yes', axis=1)\ntargets = data_pre_processed['Churn_Yes']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='4.2'>4.2. Scaling and Splitting</a>"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# Import the scaling module to scale data\nfrom sklearn.preprocessing import StandardScaler\n# Create a scaler object\nscaler = StandardScaler()\n# Fit the inputs (calculate the mean and standard deviation feature-wise)\nscaler.fit(inputs)\n# scale input data\ninputs_scaled = scaler.transform(inputs)\n# Import the module for the split\nfrom sklearn.model_selection import train_test_split\n# Split the variables with an 80-20 split and some random state \nx_train, x_test, y_train, y_test = train_test_split(inputs_scaled, targets, test_size=0.2, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a id='5'>5. Logistic Regression Model</a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlog_model = LogisticRegression()\n#fit data to logistic model\nlog_model.fit(x_train,y_train)\n# get prediction on train data itself to measure the performance of the model \ny_hat = log_model.predict(x_train)\n#import confusion matrix\nfrom sklearn.metrics import confusion_matrix\n#create confusion matrix on train data\nprint('confusion matrix for training data = ', confusion_matrix(y_hat,y_train))\n#import accurracy score \nfrom sklearn.metrics import accuracy_score\n#compute accuray score of model on training data\nprint('acuracy score for training data = ', accuracy_score(y_hat,y_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#prediction on test data \npredictions = log_model.predict(x_test)\nprint('confusion matrix for test data = ', confusion_matrix(predictions,y_test))\nlogistic_acc = accuracy_score(predictions,y_test)\nprint('acuracy score for training data = ',logistic_acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" # <a id='6'>6. Random Forest Classifier</a>"},{"metadata":{},"cell_type":"markdown","source":" ## <a id='6.1'>6.1. Number of Leaf Nodes- Grid Search</a>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nleaf_nodes_list = range(2,400)\nscore_list = []\nfor n_nodes in leaf_nodes_list:\n  rf_clf = RandomForestClassifier( max_leaf_nodes=n_nodes)\n  scores = cross_val_score(rf_clf, inputs, targets, scoring = \"neg_mean_squared_error\", cv=10)\n  score_list.append(-scores.mean())\nprint('minimum validation error = ',min(score_list))\nrfc_leaf_node = leaf_nodes_list[score_list.index(min(score_list))]\nprint('minimum error reaches for the number of leaf_nodes = ', rfc_leaf_node)\nplt.plot(leaf_nodes_list,score_list)\nplt.xlabel('Number of leaf nodes',fontsize=15)\nplt.ylabel('Validation Score',fontsize=15)\nplt.title('Random Forest Model',fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n#pre-test shows minmum between 50 and 200\nleaf_nodes_list = range(50,200)\nscore_list = []\nstd_list=[]\nfor n_nodes in leaf_nodes_list:\n    rf_clf = RandomForestClassifier( max_leaf_nodes=n_nodes)\n    scores = cross_val_score(rf_clf, inputs, targets, scoring = \"neg_mean_squared_error\", cv=10)\n    score_list.append(-scores.mean())\n    std_list.append(scores.std())\nprint('minimum validation error = ',min(score_list))\nrfc_min_score_leaf_node = leaf_nodes_list[score_list.index(min(score_list))]\nprint('minimum error reaches for the number of leaf_nodes = ', rfc_min_score_leaf_node )\nprint('minimum validation std = ',min(std_list))\nrfc_min_std_leaf_node=leaf_nodes_list[std_list.index(min(std_list))]\nprint('minimum std reaches for the number of leaf_nodes = ', rfc_min_std_leaf_node)\nfig, axes = plt.subplots(1, 2, figsize=(15, 5), sharex=False)\nfig.tight_layout()\nax1 = fig.add_subplot(1,2,1)\nplt.plot(leaf_nodes_list,score_list)\nplt.xlabel('Number of leaf nodes',fontsize=15)\nplt.title('Mean Validation Score',fontsize=15)\nax1 = fig.add_subplot(1,2,2)\nplt.plot(leaf_nodes_list,std_list)\nplt.xlabel('Number of leaf nodes',fontsize=15)\nplt.title('STD of Validation Score',fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ## <a id='6.2'>6.2. Predictions</a>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"Tree_x_train, Tree_x_test, Tree_y_train, Tree_y_test = train_test_split(inputs, targets, test_size=0.3, random_state=15)\nrf_clf = RandomForestClassifier(random_state=30,max_leaf_nodes=rfc_min_score_leaf_node)\n#fit data to random forest model\nrf_clf.fit(Tree_x_train,Tree_y_train)\n#make predictions of train data itself\nrf_clf_hat = rf_clf.predict(Tree_x_test)\nprint('Prediction with the leaf node corresponding to the minimum validation score')\n#accuracy score\ndisplay(accuracy_score(rf_clf_hat,Tree_y_test))\n#confusion matrix\nprint(confusion_matrix(rf_clf_hat,Tree_y_test))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"Tree_x_train, Tree_x_test, Tree_y_train, Tree_y_test = train_test_split(inputs, targets, test_size=0.3, random_state=15)\nrf_clf = RandomForestClassifier(random_state=30,max_leaf_nodes=rfc_min_std_leaf_node)\n#fit data to random forest model\nrf_clf.fit(Tree_x_train,Tree_y_train)\n#make predictions of train data itself\nrf_clf_hat = rf_clf.predict(Tree_x_test)\nprint('Prediction with the leaf node corresponding to the minimum standard diviation of validation score')\n#accuracy score\ndisplay(accuracy_score(rf_clf_hat,Tree_y_test))\n#confusion matrix\nprint(confusion_matrix(rf_clf_hat,Tree_y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a id='7'>7. Decision Tree Classifier</a>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nleaf_nodes_list = range(2,100)\nscore_list = []\nfor n_nodes in leaf_nodes_list:\n  dt_clf = DecisionTreeClassifier( max_leaf_nodes=n_nodes)\n  scores = cross_val_score(dt_clf, inputs, targets, scoring = \"neg_mean_squared_error\", cv=10)\n  score_list.append(-scores.mean())\nprint('minimum validation error = ',min(score_list))\ndtc_leaf_node = leaf_nodes_list[score_list.index(min(score_list))]\nprint('minimum error reaches for the number of leaf_nodes = ', dtc_leaf_node)\nplt.plot(leaf_nodes_list,score_list)\nplt.xlabel('Number of leaf nodes',fontsize=15)\nplt.ylabel('Validation Score',fontsize=15)\nplt.title('Decission Tree Classifier')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dt_clf = DecisionTreeClassifier(random_state = 1, max_leaf_nodes=dtc_leaf_node)\n#fit data to the decision tree model\ndt_clf.fit(Tree_x_train,Tree_y_train)\n#make a prediction\ndt_clf_hat= dt_clf.predict(Tree_x_test)\nprint('predictions using the number of leaf nodes corresponding to the minimum validation score ')\n#accuray score\nprint('accuary score = ' ,accuracy_score(Tree_y_test,dt_clf_hat))\n#confusion matrix\nprint('confusion matrix = ',confusion_matrix(dt_clf_hat,Tree_y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" # <a id='8'>8. Decision Tree Regression</a>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import cross_val_score\nleaf_nodes_list = range(2,100)\nscore_list = []\nfor n_nodes in leaf_nodes_list:\n  dec_tree_model = DecisionTreeRegressor( max_leaf_nodes=n_nodes)\n  scores = cross_val_score(dec_tree_model, inputs, targets, scoring = \"neg_mean_squared_error\", cv=10)\n  score_list.append(-scores.mean())\nprint('minimum validation error = ',min(score_list))\ndtr_leaf_node = leaf_nodes_list[score_list.index(min(score_list))]\nprint('minimum error reaches for the number of leaf_nodes = ', dtr_leaf_node)\nplt.plot(leaf_nodes_list,score_list)\nplt.xlabel('Number of leaf nodes',fontsize=15)\nplt.ylabel('Validation Score',fontsize=15)\nplt.title('Decission Tree Regressor')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dt_reg = DecisionTreeRegressor(random_state = 1, max_leaf_nodes=dtr_leaf_node)\n#fit data to the decision tree model\ndt_reg.fit(Tree_x_train,Tree_y_train)\n#make a prediction\ndt_reg_hat= dt_reg.predict(Tree_x_test).round()\nprint('predictions using the number of leaf nodes corresponding to the minimum validation score ')\n#accuray score\nprint('accuracy score = ', accuracy_score(Tree_y_test,dt_reg_hat.round()))\n#confusion matrix\nprint('confusion matrix = ' ,confusion_matrix(dt_reg_hat.round(),Tree_y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ## <a id='8.1'>8.1. Decision Tree</a>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"feature_cols = list(inputs.columns)\nfrom sklearn.tree import export_graphviz\nfrom sklearn import tree\nfrom graphviz import Source\nfrom IPython.display import SVG,display\n\ngraph = Source(tree.export_graphviz(dt_reg,out_file=None,\n                                        rounded=True,proportion = False,\n                                        feature_names = feature_cols, \n                                        precision  = 2,\n                                        class_names=[\"Not churn\",\"Churn\"],\n                                        filled = True                         \n                                       )\n                  )\n\ndisplay(graph)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" # <a id='9'>9. Random Forest Regression</a> "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nleaf_nodes_list = range(2,200)\nscore_list = []\nfor n_nodes in leaf_nodes_list:\n  rf_reg = RandomForestRegressor( max_leaf_nodes=n_nodes)\n  scores = cross_val_score(rf_reg, inputs, targets, scoring = \"neg_mean_squared_error\", cv=10)\n  score_list.append(-scores.mean())\nprint('minimum validation error = ',min(score_list))\nrfr_leaf_node = leaf_nodes_list[score_list.index(min(score_list))]\nprint('minimum error reaches for the number of leaf_nodes = ', rfr_leaf_node)\nplt.plot(leaf_nodes_list,score_list)\nplt.xlabel('Number of leaf nodes',fontsize=15)\nplt.ylabel('Validation Score',fontsize=15)\nplt.title('Random Forest Regressor',fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"rf_reg = RandomForestRegressor(random_state=1,max_leaf_nodes=rfr_leaf_node)\n#fit data to random forest model\nrf_reg.fit(Tree_x_train,Tree_y_train)\n#make predictions \nrf_reg_hat = rf_reg.predict(Tree_x_test)\nprint('predictions using the number of leaf nodes corresponding to the minimum validation score ')\n#accuracy score\nprint('accuracy socre = ',accuracy_score(rf_reg_hat.round(),Tree_y_test))\n#confusion matrix\nprint('confusion matrix = ',confusion_matrix(rf_reg_hat.round(),Tree_y_test))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}