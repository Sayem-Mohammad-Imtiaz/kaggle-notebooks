{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split,cross_val_score\nfrom sklearn.feature_selection import SelectKBest,chi2,f_regression\nfrom sklearn.linear_model import LogisticRegression,LogisticRegressionCV\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import r2_score,mean_absolute_error,accuracy_score,confusion_matrix,classification_report\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n%config Completer.use_jedi = False\n\nscale = StandardScaler()\ndf = pd.read_csv('/kaggle/input/bank-marketing-campaigns-dataset/bank-additional-full.csv',sep=\";\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.select_dtypes('object')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['y'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.replace('unknown',np.NaN)\ndf['y'] = df['y'].apply(lambda x: 1 if x=='yes' else (0 if x=='no' else None))\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def one_hot_encoder(df,columns,prefixes):\n    df = df.copy()\n    for column,prefix in zip(columns,prefixes):\n        dummies = pd.get_dummies(df[column],prefix=prefix)\n        df = pd.concat([df,dummies],axis=1)\n        df = df.drop(column,axis=1)\n    return df\n\ndef ordinal_encoder(df,columns,orderings):\n    df = df.copy()\n    for column,ordering in zip(columns,orderings):\n        df[column] = df[column].apply(lambda x:ordering.index(x)) \n    return df\n    \n#binary encoder\ndef binary_encoder(df, columns, positive_values):\n    df = df.copy()\n    for column, positive_value in zip(columns, positive_values):\n        df[column] = df[column].apply(lambda x: 1 if x == positive_value else x)\n        df[column] = df[column].apply(lambda x: 0 if str(x) != 'nan' else x)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nominal_features = ['job','marital','education','day_of_week','month','poutcome']\nprefixes = ['j','m','e','d','mo','p']\n\ndf = one_hot_encoder(df,nominal_features,prefixes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_features = ['default','housing','loan','contact']\npositive_values = ['yes','yes','yes','cellular']\n# df = binary_encoder(df,binary_features,positive_values)\nbinVal = {'yes':1,'no':0}\ncontVal = {'cellular':1,'telephone':0}\ndf['housing'].replace(binVal,inplace=True)\ndf['default'].replace(binVal,inplace=True)\ndf['loan'].replace(binVal,inplace=True)\ndf['contact'].replace(contVal,inplace=True)\n# df['housing'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Filling Missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()\nprint(df['housing'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in ['default','housing','loan']:\n    df[column] = df[column].fillna(df[column].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"missing values are: {}\".format(df.isna().sum().sum()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Splitting / Scaling Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df['y']\nX = df.drop(columns='y').copy()\n\ntrainX,testX,trainY,testY = train_test_split(X,y,random_state=36,stratify=y,test_size=0.25)\n#Scaling X\ntrainX = scale.fit_transform(trainX)\ntestX = scale.fit_transform(testX)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Features Selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df['y'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_feature = SelectKBest(k=\"all\").fit(trainX,trainY)\nscores = pd.DataFrame(best_feature.scores_)\ncolumns = pd.DataFrame(X.columns)\nbestFeatures = pd.concat([columns,scores],axis=1)\nbestFeatures.columns = ['Feature','Score']\nbestFeatures = bestFeatures.sort_values(by=\"Score\",ascending=False)\nbestFeatures","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Applying ML Algorithms"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_acc_scores = {}\ndef predictionResult(testY,pred,model):\n    conf_mat = confusion_matrix(testY,pred)\n    correct = conf_mat[0,0]+conf_mat[1,1]\n    wrong = conf_mat.sum() - correct\n    mae = mean_absolute_error(testY,pred)\n    acc_score = accuracy_score(testY,pred)\n    model_acc_scores[model] = {'correct':correct,'wrong':wrong,'mae':mae,'accuracy_score':acc_score}\n    print(\"{} {} {}\".format(\"-\"*20,model,\"-\"*20))\n    print(\"Model predicted {} correct and {} wrong\".format(correct,wrong))\n    print(\"Mean Absolute Error is: {}\".format(round(mae*100,2)))\n    print(\"Accuracy Score is: {}\".format(round(acc_score*100,2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LogisticRegression(max_iter=200).fit(trainX,trainY)\ncv_score = cross_val_score(model,trainX,trainY,cv=10)\npred = model.predict(testX)\nprint(\"Cross val score is: {}%\".format(round(cv_score.mean()*100,2)))\npredictionResult(testY,pred,\"LogisticRegression\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LogisticRegressionCV(cv=10,max_iter=320).fit(trainX,trainY)\npred = model.predict(testX)\npredictionResult(testY,pred,\"LogisticRegressionCV\")\nreport = classification_report(testY,pred)\nprint(report)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = RandomForestClassifier().fit(trainX,trainY)\ncv_score = cross_val_score(model,trainX,trainY,cv=10)\npred = model.predict(testX)\nprint(\"Cross val score is: {}%\".format(round(cv_score.mean()*100,2)))\npredictionResult(testY,pred,\"RandomForestClassifier\")\nreport = classification_report(testY,pred)\nprint(report)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = DecisionTreeClassifier().fit(trainX,trainY)\ncv_score = cross_val_score(model,trainX,trainY,cv=10)\npred = model.predict(testX)\nprint(\"Cross val score is: {}%\".format(round(cv_score.mean()*100,2)))\npredictionResult(testY,pred,\"DecisionTreeClassifier\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = KNeighborsClassifier(n_neighbors=23).fit(trainX,trainY)\ncv_score = cross_val_score(model,trainX,trainY,cv=10)\npred = model.predict(testX)\nprint(\"Cross val score is: {}%\".format(round(cv_score.mean()*100,2)))\npredictionResult(testY,pred,\"KNeighborsClassifier\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = GaussianNB().fit(trainX,trainY)\ncv_score = cross_val_score(model,trainX,trainY,cv=10)\npred = model.predict(testX)\nprint(\"Cross val score is: {}%\".format(round(cv_score.mean()*100,2)))\npredictionResult(testY,pred,\"GaussianNB\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res = pd.DataFrame(model_acc_scores)\nres.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}