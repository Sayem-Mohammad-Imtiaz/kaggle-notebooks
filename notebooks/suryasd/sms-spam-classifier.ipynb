{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Problem Statement**\n### Building a model to classify the spam messages using TF – IDF, Naïve Bayes & other NLP techniques.\n","metadata":{}},{"cell_type":"markdown","source":"### Importing the Dataset","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\ndf = pd.read_csv(\"../input/sms-spam-collection-dataset/spam.csv\" , encoding=\"ISO-8859-1\")\ndf = df[['v1', 'v2']]\ndf = df.rename(columns = {'v1': 'label', 'v2': 'message'})\ndf.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **EDA**\n### Checking the count of spam and ham messages","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize = (10,6))\nsns.countplot(data=df, x='label')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Checking the length of each messages","metadata":{}},{"cell_type":"code","source":"df['length'] = df['message'].apply(lambda x: len(x) - x.count(\" \"))\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Histogarm to check the frequency of spam and ham messages with respect to length\n\n#### As we can see length of most of the ham messages are in between 25-75 and most of the spam messages are in between 100 - 150\n#### so length is also a feature to classify spam & ham messages","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 5))\nbins = np.linspace(0, 200, 40)\nplt.hist(df[df['label']=='ham']['length'], bins, alpha=0.5, label='ham')\nplt.hist(df[df['label']=='spam']['length'], bins, alpha=0.5, label='spam')\nplt.legend(loc='upper left')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Checking the percentage of punctuation in each sentences","metadata":{}},{"cell_type":"code","source":"import string\n\ndef count_punct(text):\n#     count = sum([1 for char in text if char in string.punctuation])\n    \n    count=0\n    for char in text:\n        if char in string.punctuation:\n            count+=1\n    \n    return round(count/(len(text) - text.count(\" \")), 3)*100\n\ndf['punct%'] = df['message'].apply(lambda x: count_punct(x))\n\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Histogarm to check the frequency of spam and ham messages with respect to percentage of punctuation\n#### As we can see most of the spam messages have punctuation percentage 0-10% but most of the ham messages have punctuation percentage beyond 10%\n#### so we will the feature too to our model","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 5))\nbins = np.linspace(0, 50, 40)\nplt.hist(df[df['label']=='ham']['punct%'], bins, alpha=0.5, label='ham')\nplt.hist(df[df['label']=='spam']['punct%'], bins, alpha=0.5, label='spam')\nplt.legend(loc='upper right')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Cleaning & preprocessing\n* Removing the number, punctuation & other characters\n* Lowerig the sentences\n* Stemming\n* Removing stop-words","metadata":{}},{"cell_type":"code","source":"#Data cleaning and preprocessing\nimport re\nimport nltk\nnltk.download('stopwords')\n\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nps = PorterStemmer()\ncorpus = []\nfor i in range(0, len(df)):\n    review = re.sub('[^a-zA-Z]', ' ', df['message'][i])\n    review = review.lower()\n    review = review.split()\n    \n    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n    review = ' '.join(review)\n    corpus.append(review)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Creating the TF - IDF model","metadata":{}},{"cell_type":"code","source":"# Creating the Bag of Words model\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ncv = TfidfVectorizer()\nX = cv.fit_transform(corpus).toarray()\n\ny=pd.get_dummies(df['label'])\ny=y.iloc[:,1].values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Adding other feature like length of a sentence and percentage of punctuation in a sentence to the model","metadata":{}},{"cell_type":"code","source":"X_features = pd.concat([df['length'],df['punct%'],pd.DataFrame(X)], axis=1)\nX_features.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Splitting the dataset","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_features, y, test_size = 0.20, random_state = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training model using Naive bayes classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nspam_detect_model = MultinomialNB().fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prediction on test dataset","metadata":{}},{"cell_type":"code","source":"y_pred=spam_detect_model.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Accuracy checking by confusion matrix","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nconfusion_m = confusion_matrix(y_test,y_pred)\n\nfrom sklearn.metrics import accuracy_score\naccuracy = accuracy_score(y_test,y_pred)\n\naccuracy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Creating Bag of words model to check the accuracy","metadata":{}},{"cell_type":"code","source":"# Creating the Bag of Words model\nfrom sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(max_features=2500)\nX = cv.fit_transform(corpus).toarray()\n\ny=pd.get_dummies(df['label'])\ny=y.iloc[:,1].values\n\nX_features = pd.concat([df['length'],df['punct%'],pd.DataFrame(X)], axis=1)\nX_features.head()\n\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_features, y, test_size = 0.20, random_state = 0)\n\n# Training model using Naive bayes classifier\n\nfrom sklearn.naive_bayes import MultinomialNB\nspam_detect_model = MultinomialNB().fit(X_train, y_train)\n\ny_pred=spam_detect_model.predict(X_test)\n\nfrom sklearn.metrics import confusion_matrix\nconfusion_m = confusion_matrix(y_test,y_pred)\n\nfrom sklearn.metrics import accuracy_score\naccuracy = accuracy_score(y_test,y_pred)\n\naccuracy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### As we can see BOW model gives more accuracy than TF - IDF model","metadata":{}},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n\ncf_train_matrix = confusion_matrix(y_test,y_pred)\nplt.figure(figsize=(10,8))\nsns.heatmap(cf_train_matrix, annot=True, fmt='d')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}