{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Loading the data."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/hr-analytics-job-change-of-data-scientists/aug_train.csv')\ntest=pd.read_csv('/kaggle/input/hr-analytics-job-change-of-data-scientists/aug_test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.drop(['enrollee_id'],axis=1)\n# Saving enrollee_id for SUBMISSION FILE \ntest_id=test['enrollee_id']\ntest=test.drop(['enrollee_id'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Checking for null values."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in train:\n    print(col,len(train[col].unique()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature engineering - 'CITY' by one hot encoding - top variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.city.value_counts().sort_values(ascending=False).head(10)\ntop10=[x for x in train.city.value_counts().sort_values(ascending=False).head(10).index]\nfor label in top10:\n    train[label]=np.where(train['city']==label,1,0)\ntrain[['city']+top10].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for label in top10:\n    test[label]=np.where(test['city']==label,1,0)\ntest[['city']+top10].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test=test.drop('city',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.drop('city',axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pre-processing for other columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"test['gender'] = test['gender'].map({'Female':int(0),'Male':int(1) ,'Other':int(-1),'nan':int(-1)})\ntrain['gender'] = train['gender'].map({'Female':int(0),'Male':int(1) ,'Other':int(-1),'nan':int(-1)})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['relevent_experience'] = test['relevent_experience'].map({'Has relevent experience':int(2),'No relevent experience':int(0)})\ntrain['relevent_experience'] = train['relevent_experience'].map({'Has relevent experience':int(2),'No relevent experience':int(0)})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subset_df_1 = train[train[\"target\"] > 0]\ncolumn_count_1 = subset_df_1.enrolled_university.value_counts()\nprint(column_count_1.head())\n\nsubset_df_0 = train[train[\"target\"] < 1]\ncolumn_count_0 = subset_df_0.enrolled_university.value_counts()\nprint(column_count_0.head())\n\nprint(column_count_1['no_enrollment']/(column_count_0['no_enrollment']+column_count_1['no_enrollment']))\nprint(column_count_1['Full time course']/(column_count_0['Full time course']+column_count_1['Full time course']))\nprint(column_count_1['Part time course']/(column_count_0['Part time course']+column_count_1['Part time course']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['enrolled_university'] = test['enrolled_university'].map({'no_enrollment':int(0),'Part time course':int(1),'Full time course':int(2)})\ntrain['enrolled_university'] = train['enrolled_university'].map({'no_enrollment':int(0),'Part time course':int(1),'Full time course':int(2)})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['education_level'] = test['education_level'].map({'Primary School':int(-2),'High School':int(-1),'nan':int(0),'Graduate':int(0),'Masters':int(2),'Phd':int(3)})\ntrain['education_level'] = train['education_level'].map({'Primary School':int(-2),'High School':int(-1),'nan':int(0),'Graduate':int(0),'Masters':int(2),'Phd':int(3)})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['major_discipline'] = test['major_discipline'].map({'STEM':int(-1) ,'Business Degree':int(0), 'Arts':int(1) ,'Humanities':int(2) ,'No Major':int(3) ,'Other':int(4)})\ntrain['major_discipline'] = train['major_discipline'].map({'STEM':int(-1) ,'Business Degree':int(0), 'Arts':int(1) ,'Humanities':int(2) ,'No Major':int(3) ,'Other':int(4)})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['experience'] = test['experience'].map({'>20':int(20), '15':int(15),  '5':int(5), '<1':int(-1), '11':int(11), \n                                               '13':int(13), '7':int(7), '17':int(17),\n                                               '2':int(7), '16':int(16), '1':int(1), '4':int(4), '10':int(10),\n                                               '14':int(14), '18':int(18),'19':int(19), '12':int(12), '3':int(3), \n                                               '6':int(6), '9':int(9), '8':int(8), '20':int(20)})\n\ntrain['experience'] = train['experience'].map({'>20':int(20), '15':int(15),  '5':int(5), '<1':int(-1), '11':int(11), \n                                               '13':int(13), '7':int(7), '17':int(17),\n                                               '2':int(7), '16':int(16), '1':int(1), '4':int(4), '10':int(10),\n                                               '14':int(14), '18':int(18),'19':int(19), '12':int(12), '3':int(3), \n                                               '6':int(6), '9':int(9), '8':int(8), '20':int(20)})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['company_size'] = test['company_size'].map({'50-99':int(0), '<10':int(-1), '10000+':int(1), '5000-9999':int(2), \n                                                   '1000-4999':int(3), '10/49':int(4), '100-500':int(5),'500-999':int(6)})\n\ntrain['company_size'] = train['company_size'].map({'50-99':int(0), '<10':int(-1), '10000+':int(1), '5000-9999':int(2), \n                                                   '1000-4999':int(3), '10/49':int(4), '100-500':int(5),'500-999':int(6)})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['company_type'] = test['company_type'].map({'Pvt Ltd':int(0), 'Funded Startup':int(-1), 'Early Stage Startup':int(2), 'Other':int(3),'Public Sector':int(4), 'NGO':int(5)})\ntrain['company_type'] = train['company_type'].map({'Pvt Ltd':int(0), 'Funded Startup':int(-1), 'Early Stage Startup':int(2), 'Other':int(3),'Public Sector':int(4), 'NGO':int(5)})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['last_new_job'] = test['last_new_job'].map({'1':int(-1), '>4':int(0), 'never':int(1), '4':int(4), '3':int(3), '2':int(2)})\n\ntrain['last_new_job'] = train['last_new_job'].map({'1':int(-1), '>4':int(0), 'never':int(1), '4':int(4), '3':int(3), '2':int(2)})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Filling NaN values using MICE."},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\n\nmice_imputer = IterativeImputer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['gender'] = mice_imputer.fit_transform(train[['gender']])\ntrain['gender'] = round(train['gender'])\n\ntrain['education_level'] = mice_imputer.fit_transform(train[['education_level']])\ntrain['education_level'] = round(train['education_level'])\n\ntrain['enrolled_university']= mice_imputer.fit_transform(train[['enrolled_university']])\ntrain['enrolled_university'] = round(train['enrolled_university'])\n\ntrain['experience']= mice_imputer.fit_transform(train[['experience']])\ntrain['experience'] = round(train['experience'])\n\ntrain['company_size']= mice_imputer.fit_transform(train[['company_size']])\ntrain['company_size'] = round(train['company_size'])\n\ntrain['company_type']= mice_imputer.fit_transform(train[['company_type']])\ntrain['company_type'] = round(train['company_type'])\n\ntrain['last_new_job']= mice_imputer.fit_transform(train[['last_new_job']])\ntrain['last_new_job'] = round(train['last_new_job'])\n\ntrain['major_discipline']= mice_imputer.fit_transform(train[['major_discipline']])\ntrain['major_discipline'] = round(train['major_discipline'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['gender'] = mice_imputer.fit_transform(test[['gender']])\ntest['gender'] = round(test['gender'])\n\ntest['education_level'] = mice_imputer.fit_transform(test[['education_level']])\ntest['education_level'] = round(test['education_level'])\n\ntest['enrolled_university']= mice_imputer.fit_transform(test[['enrolled_university']])\ntest['enrolled_university'] = round(test['enrolled_university'])\n\ntest['experience']= mice_imputer.fit_transform(test[['experience']])\ntest['experience'] = round(test['experience'])\n\ntest['company_size']= mice_imputer.fit_transform(test[['company_size']])\ntest['company_size'] = round(test['company_size'])\n\ntest['company_type']= mice_imputer.fit_transform(test[['company_type']])\ntest['company_type'] = round(test['company_type'])\n\ntest['last_new_job']= mice_imputer.fit_transform(test[['last_new_job']])\ntest['last_new_job'] = round(test['last_new_job'])\n\ntest['major_discipline']= mice_imputer.fit_transform(test[['major_discipline']])\ntest['major_discipline'] = round(test['major_discipline'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Splitting data into x and y."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train=train['target']\nx_train=train.drop('target',axis=1)\nx_test=test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Testing algos. using pip-line."},{"metadata":{"trusted":true},"cell_type":"code","source":"# pipe\nfrom sklearn.pipeline import Pipeline\n\n# ML classifier model Evaluation\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\n\n# scaling\nfrom sklearn.preprocessing import StandardScaler\n\n\n# ML classifier\nfrom sklearn.tree import DecisionTreeClassifier\nimport sklearn.model_selection as ms\nfrom sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_pipe = Pipeline(steps =[ ('std_scale',StandardScaler()), (\"RF\",RandomForestClassifier(random_state=0,max_depth= 10, max_features= 5,min_samples_leaf= 30, min_samples_split= 100, n_estimators= 500))])\nrf_pipe.fit(x_train,y_train)\n\ndt_pipe = Pipeline(steps =[ ('_std_scale',StandardScaler()), (\"DT\",DecisionTreeClassifier(criterion='gini',max_features=10, max_depth=10, min_samples_leaf=15, min_samples_split=100,random_state=0)) ])\ndt_pipe.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predict the x_test."},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = dt_pipe.predict_proba(x_test)\npredict = predict[:, 1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Testing on trainng data."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_predict = dt_pipe.predict_proba(x_train)\ntrain_predict = train_predict[:, 1]\ntrain_predict= np.where(train_predict > 0.5, 1, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Decissoin Tree classification_report on train_set')\nprint(' ')\nprint(classification_report(y_train, train_predict))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission file."},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({'enrollee_id':test_id,'target':predict})\nsubmission.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}