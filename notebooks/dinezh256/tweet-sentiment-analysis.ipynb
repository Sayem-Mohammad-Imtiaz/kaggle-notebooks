{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Importing Packages and Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Importing required packages\n\nimport numpy as np # for linear algebra\nimport pandas as pd # for data processing, CSV file\nimport matplotlib.pyplot as plt # data visualization library\n%matplotlib inline\nimport seaborn as sns # interactive visualization library built on top on matplotlib\n\ndata = pd.read_csv('/kaggle/input/train.csv') # importing training data","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Checking the head of the data\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(data[data.label == 0]), 'Non-Hatred Tweets')\nprint(len(data[data.label == 1]), 'Hatred Tweets')\n# Class distribution in this data seems to be imbalanced.\n# F1 score should be used fot model performance evaluation in such situation. ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing different libraries for analysis, processing and classification\nimport nltk\nfrom sklearn import re #regular expression for text processing\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer #word stemmer class\nlemma = WordNetLemmatizer()\nfrom wordcloud import WordCloud, STOPWORDS\nfrom nltk import FreqDist\n\n# Vectorizers\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression #classification model\nfrom sklearn.metrics import confusion_matrix, classification_report, f1_score # performance evaluation criteria","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preprocessing the tweet column"},{"metadata":{"trusted":true},"cell_type":"code","source":"def normalizer(tweet):\n    tweets = \" \".join(filter(lambda x: x[0]!= '@' , tweet.split()))\n    tweets = re.sub('[^a-zA-Z]', ' ', tweets)\n    tweets = tweets.lower()\n    tweets = tweets.split()\n    tweets = [word for word in tweets if not word in set(stopwords.words('english'))]\n    tweets = [lemma.lemmatize(word) for word in tweets]\n    tweets = \" \".join(tweets)\n    return tweets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['normalized_text'] = data.tweet.apply(normalizer)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Extracting words with hashtag for further analysis**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_hashtag(tweet):\n    tweets = \" \".join(filter(lambda x: x[0]== '#', tweet.split()))\n    tweets = re.sub('[^a-zA-Z]',' ',  tweets)\n    tweets = tweets.lower()\n    tweets = [lemma.lemmatize(word) for word in tweets]\n    tweets = \"\".join(tweets)\n    return tweets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['hashtag'] = data.tweet.apply(extract_hashtag)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Exploratory Data Analysis**\n\n**To Create Cloud of words for all words and hatred words**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# all tweets \nall_words = \" \".join(data.normalized_text)\n#print(all_words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hatred tweets\nhatred_words = \" \".join(data[data['label']==1].normalized_text)\n#print(hatred_words)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### All tweets cloudword"},{"metadata":{"trusted":true},"cell_type":"code","source":"wordcloud = WordCloud(height=800, width=800, max_font_size = 110, stopwords=STOPWORDS, background_color='black')\nwordcloud = wordcloud.generate(all_words)\nplt.figure(figsize = (10,7))\nplt.imshow(wordcloud, interpolation = \"bilinear\")\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Hatred tweets cloudword"},{"metadata":{"trusted":true},"cell_type":"code","source":"wordcloud = WordCloud(height=800, width=800, max_font_size = 110, stopwords=STOPWORDS, background_color='black')\nwordcloud = wordcloud.generate(hatred_words)\nplt.figure(figsize = (10,7))\nplt.imshow(wordcloud, interpolation = \"bilinear\")\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Analysing Hashtag words\n\n**plotting the most common hashtag used in tweets**\n**all hashtag \nhatred hashtag**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# from nltk import FreqDist\nfreq_all_hashtag = FreqDist(list(\" \".join(data.hashtag).split())).most_common(12)\nfreq_all_hashtag","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_hatred_hashtag = FreqDist(list(\" \".join(data[data['label']==1]['hashtag']).split())).most_common(12)\nfreq_hatred_hashtag","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"allhashtag = pd.DataFrame(freq_all_hashtag, columns=['words', 'frequency'])\nhatredhashtag = pd.DataFrame(freq_hatred_hashtag, columns=['words', 'frequency'])\nprint(allhashtag.head())\nprint(hatredhashtag.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='words', y='frequency', data=allhashtag)\nplt.xticks(rotation = 45)\nplt.title('all hashtag words frequency')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='words', y='frequency', data=hatredhashtag)\nplt.xticks(rotation = 45)\nplt.title('hatred hashtag words frequency')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to create sparse matrix corpus is created to pass to vectorizer\ncorpus = []\nfor i in range(0,len(data.id)):\n    corpus.append(data['normalized_text'][i])\n#corpus","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv = CountVectorizer(stop_words=stopwords.words('english'))\ncv.fit(corpus)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating dense matrix\nX = cv.transform(corpus).toarray()\ny = data.iloc[:,1].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classification\n\n**Logistic Regression (Linear Model)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier1 = LogisticRegression(C=10)\nclassifier1.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifier1.predict(X_test)\ny_prob = classifier1.predict_proba(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(set(data.label)))\n    plt.xticks(tick_marks, set(data.label), rotation=0)\n    plt.yticks(tick_marks, set(data.label))\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test, y_pred)\nprint(f1_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\nprint(cm)\nplot_confusion_matrix(cm)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Checking with TF-IDF vectorizer**\n\n*** Unigram, bi gram is used wih min_df = 10***"},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf = TfidfVectorizer(ngram_range=(1,3), min_df=10, stop_words=stopwords.words('english'))\nX1 = tfidf.fit_transform(corpus)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y, test_size=0.33, random_state=42)\nclassifier2 = LogisticRegression(C=10)\nclassifier2.fit(X1_train, y1_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y1_pred = classifier2.predict(X1_test)\ny1_prob = classifier2.predict_proba(X1_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm1 = confusion_matrix(y1_test, y1_pred)\nprint(f1_score(y1_test, y1_pred))\nprint(classification_report(y1_test, y1_pred))\nprint(cm1)\nplot_confusion_matrix(cm1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**A maximum f1 score of 0.63 is achieved at threshold of 0.5. Thus tweet with probability greater than or equal to 0.5 will be classified as hatred**\n\n**Since class distribution is imabalance we cannot use accuracy as model performance evaluation method.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"threshold = np.arange(0.1,0.9,0.1)\nscore = [f1_score(y1_test, ((y1_prob[:,1] >= x).astype(int))) for x in threshold]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(threshold, score)\nplt.xlabel('Threshold Probability')\nplt.ylabel('F1 score')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Performing classification model on our test data** "},{"metadata":{"trusted":true},"cell_type":"code","source":"data2 = pd.read_csv('/kaggle/input/test.csv')\ndata2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data2['normalized_text'] = data2['tweet'].apply(normalizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data2.head()\n# creating corpus\ncorpus_test = []\nfor i in range(0, len(data2.id)):\n    corpus_test.append(data2.normalized_text[i])\n#corpus_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Test_X = tfidf.transform(corpus_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_Y = classifier2.predict(Test_X)\nprob_Y = classifier2.predict_proba(Test_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data2['pred_label'] = pred_Y\nscores = (prob_Y[:,1] >= 0.5).astype(int)\ndata2['score'] = scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data2[data2.pred_label == 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = True\nwhile(x):\n    tweet = input(\"\\nTweet Something : \")\n    if tweet == \"exit\":\n        x = False\n        break\n    prediction = classifier2.predict(tfidf.transform([tweet]))\n    if (prediction == [0]):\n        print('Non-hatred Tweet')\n    else:\n        print('Hatred Tweet')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}