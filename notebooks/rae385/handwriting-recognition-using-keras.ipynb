{"cells":[{"metadata":{"_uuid":"c9aab9de954f337c46de52407f4a1159185bc42a"},"cell_type":"markdown","source":"**Handwriting Recognition using Keras**\n\nThis kernal will focus on trying to build a neural network that can correctly identify handwritten digits. The [MNIST](http://http://yann.lecun.com/exdb/mnist/) database of handwritten digits is a widely used dataset for tutorials into deep learning. The image data is in the form of 28 x 28 grayscale pixels (784 pixels overall) along with labels for the correct identification of that image. The training set has 60K samples while the test set had 10K samples. Here are some examples of the data we are working with:\n\n![](https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png)\n\nLearning how to code artificial neural networks is hard, especially if you are a curious high school student with limited resources and experience. But we can utilize specialized packages such as Keras to make our lives much easier. With its high level framework, programming neural networks have never been easier with Keras! Unlike Tensorflow (another package used by Google) you don't have to manually code the linear algebra and the required activation functions and optimizers.\n\nThis specific neural network will take in an input of 784 pixels of the image into the hidden layer of 512 neurons that will output into 10 neurons (one for each digit). Note that the layout of the network is not exactly specific, but rather random, as you can have as many hidden layers as you want with varied amount of neurons in each layer.\n\n![](https://cdn-images-1.medium.com/max/1200/1*RGV6Bb3ChmVWsA8Q6Qth6Q.png)\n\nSidenote: make sure to run all the previous code blocks (shift + enter) before progressing into another code block. Also don't let the code scare you!"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"#packages\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.optimizers import RMSprop\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n#data processing\nmnist_train = pd.read_csv('../input/mnist_train.csv')\nmnist_test = pd.read_csv('../input/mnist_test.csv')\n\ntrain_images = mnist_train.iloc[:, 1:].values\ntrain_labels = mnist_train.iloc[:, :1].values\ntest_images = mnist_test.iloc[:, 1:].values\ntest_labels = mnist_test.iloc[:, :1].values\n\n#normalize the data\ntrain_images = train_images.astype('float32')\ntest_images = test_images.astype('float32')\ntrain_images /= 255   \ntest_images /= 255\n\n#one hot encoding\ntrain_labels = keras.utils.to_categorical(train_labels, 10)\ntest_labels = keras.utils.to_categorical(test_labels, 10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9e9740fb90c267156c7a3ff36814afe20ef06c05"},"cell_type":"markdown","source":"The code above was just for setting up the data in a way that it can be fed into the model. The following couple of blocks are the outlines of the network. As you can see, coding the network in this case only takes 5 lines of code (excluding the summary function and the additional spaces from indents). \n\nWarning: the code block following this next one is the one that trains the model. Training is a computationally expensive step and might take a while depending on your computer's specs. Of course, this example is a pretty basic one and everything will most likely be fine."},{"metadata":{"trusted":true,"_uuid":"c373883c09c3106c532ad1ffc105bc4902d3daed","_kg_hide-output":true},"cell_type":"code","source":"#network topography\nmodel = Sequential()\nmodel.add(Dense(512, activation = 'relu', input_shape=(784,)))\nmodel.add(Dense(10, activation = 'softmax'))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5fab60932e188a96e79872e787e4c10b92389ba3","_kg_hide-output":true},"cell_type":"code","source":"#compiling model and training\nmodel.compile(loss='categorical_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])\nz = model.fit(train_images, train_labels, \n                   batch_size=100,\n                   epochs=10,\n                   verbose=2,\n                   validation_data=(test_images, test_labels))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1e931fb3a7523557779757782cd59a0abde45487"},"cell_type":"markdown","source":"Pretty neatâ€“getting to see your model learning and getting better at identifying handwritten digits. This model on its 10th epoch is 99% accurate on its training data. Now click the following code block to see the accuracy of the network on the testing set."},{"metadata":{"trusted":true,"_uuid":"294a0a47bb9d7a3994d24c2593ccff26137e682c","_kg_hide-output":true},"cell_type":"code","source":"score = model.evaluate(test_images, test_labels, verbose=0)\nprint(\"Test Accuracy: \", score[1]*100, \"%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bbff6b65cf4e7eab31893145d2ac1cd02f5ae407","_kg_hide-output":true},"cell_type":"code","source":"#visualize the model working\ndef predict_test_sample(x):\n    label = test_labels[x].argmax(axis=0)\n    image = test_images[x].reshape([28,28])\n    test_image = test_images[x,:].reshape(1,784)\n    prediction = model.predict(test_image).argmax()\n    plt.title(\"Sample %d  Prediction: %d Label: %d\" % (x, prediction, label))\n    plt.imshow(image, cmap=plt.get_cmap('gray_r'))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"81ebb9b1491d9f9feaa556b75edb1bd7280ba77f"},"cell_type":"markdown","source":"Use the fuction defined above and specify the parameter as a number of test sample (0-9999) to test the model and visulize the results."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"a4053815bc678fa10db54b61a573227941390edb","_kg_hide-output":true},"cell_type":"code","source":"#test the model using the function defined above\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"484aa0ffa709eb5fb1f842fe95483c792202ec8a"},"cell_type":"markdown","source":"We see that the model is pretty accurate in its predictions. But we should try to look at samples  that the model mistakenly identified. Run the next code block to see the inaccurate predictions made by our neural network for the first 500 test samples."},{"metadata":{"trusted":true,"_uuid":"6c900ac192d41794e52601067a04fbe285b86c69","_kg_hide-output":true},"cell_type":"code","source":"for x in range(500):\n    image = test_images[x,:].reshape(1,784)\n    prediction = model.predict(image).argmax()\n    label = test_labels[x].argmax()\n    if (prediction != label):\n        plt.title(\"Sample %d  Prediction: %d Label: %d\" % (x, prediction, label))\n        plt.imshow(image.reshape([28,28]), cmap=plt.get_cmap('gray_r') )\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3903f9dddce16bc796ce28ff456b4c140ad6ded6"},"cell_type":"markdown","source":"As you can see some people have horrible handwriting, it is no wonder that the neural network has problems with several of the samples. The network also has few loopholes in which it got something wrong even if the handwriting wasn't half bad. Overall this is a pretty good artificial neural network, especially considering that it is pretty basic.\n\nMade by rae385, for Coppell High School AI Club\n\nNote: this model is based off of a [tutorial](https://sundog-education.com/deep-learning/) I found online by Frank Kane."},{"metadata":{"trusted":true,"_uuid":"4d0b89c171d5f92ac5b52ed67da9d92760da394f"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}