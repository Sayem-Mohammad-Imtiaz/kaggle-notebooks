{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"7e5b5802-f908-ac4e-87f6-89d37edfeeed"},"source":"A Keras CNN to classify set A. As many files lacked classification, and I wasn't happy with the classification on the other files, I have re-labelled all files and obtained good results on this set."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a4164221-e4cd-a4b6-3105-728b92b79402"},"outputs":[],"source":"import numpy as np\nfrom scipy.io import wavfile\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport pandas as pd\nfrom scipy.signal import decimate"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6a96e14a-3452-34f1-f32d-8a29bf4688cd"},"outputs":[],"source":"from keras.models import Sequential\nfrom keras.layers import Conv1D, MaxPool1D, GlobalAvgPool1D, Dropout, BatchNormalization, Dense\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f392b235-02db-97d1-c2d6-869f7689d8a6"},"outputs":[],"source":"INPUT_LIB = '../input/'\nSAMPLE_RATE = 44100"},{"cell_type":"markdown","metadata":{"_cell_guid":"84fc95d4-fd22-0b18-b1ad-ad518fd1ecb6"},"source":"## Load the data\nWe will need to preprocess the unclassified data, as they are marked NaN and also have incorrect file names. For now, we will also make all time series have equal length. We will do all this by defining element wise functions, that we can pass to Pandas."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"80517cc2-4829-6638-d9aa-3f32f3e48a70"},"outputs":[],"source":"def clean_filename(fname, string):   \n    file_name = fname.split('/')[1]\n    if file_name[:2] == '__':        \n        file_name = string + file_name\n    return file_name"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3b8b23a9-99b7-5d2a-3866-500735fa07ca"},"outputs":[],"source":"def load_wav_file(name, path):\n    _, b = wavfile.read(path + name)\n    assert _ == SAMPLE_RATE\n    return b"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8739900a-c3ae-6d48-6d69-1cf06dff926d"},"outputs":[],"source":"def zero_pad(arr, length):\n    \"\"\"Adds zeros to end of numpy array, for total length len, and makes datatype float.\n    Not used currently.\"\"\"\n    result = np.zeros((length, ), dtype='float')\n    result[:len(arr)] = arr\n    return result"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"100cf856-64e3-678d-f4bb-96bb072b2d77"},"outputs":[],"source":"def repeat_to_length(arr, length):\n    \"\"\"Repeats the numpy 1D array to given length, and makes datatype float\n    Needs adjustment to preserve phase, and could also be optimized\"\"\"\n    result = np.empty((length, ), dtype = 'float32')\n    l = len(arr)\n    pos = 0\n    while pos + l <= length:\n        result[pos:pos+l] = arr\n        pos += l\n    if pos < length:\n        result[pos:length] = arr[:length-pos]\n    return result"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9abd650c-ebc1-d5ae-9dbd-0417ffbea338"},"outputs":[],"source":"file_info = pd.read_csv(INPUT_LIB + 'set_a.csv')\nnew_info = pd.DataFrame({'file_name' : file_info['fname'].apply(clean_filename, \n                                                                string='Aunlabelledtest'),\n                         'target' : file_info['label'].fillna('unclassified')})   \nnew_info['time_series'] = new_info['file_name'].apply(load_wav_file, \n                                                      path=INPUT_LIB + 'set_a/')    \nnew_info['len_series'] = new_info['time_series'].apply(len)  "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c4e01839-98f8-016f-c42e-be9cf89f4620"},"outputs":[],"source":"MAX_LEN = max(new_info['len_series'])\nCLASSES = ['artifact', 'normal', 'murmur']\nCODE_BOOK = {x:i for i,x in enumerate(CLASSES)}   \nNB_CLASSES = len(CLASSES)"},{"cell_type":"markdown","metadata":{"_cell_guid":"3b7bfb65-be64-3c58-3cf3-cdac499de4a3"},"source":"## Convert data to numpy arrays\nLet's leave the unclassified files for validation, and make a training set of the others. We will zero-pad the time series at the end to make the all the same length, then collect all in 2D numpy arrays, that can be used for neural network training."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dda2dd6d-d6a2-0db1-3a7c-18b3d2f65c7d"},"outputs":[],"source":"new_info['time_series'] = new_info['time_series'].apply(repeat_to_length, length=MAX_LEN) \nx_train = np.stack(new_info.loc[new_info['target'] \n                                != 'unclassified']['time_series'].values, axis=0)\nx_test = np.stack(new_info.loc[new_info['target'] \n                               == 'unclassified']['time_series'].values, axis=0)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a267d4df-9ddd-f866-cdd4-cff2097218f7"},"outputs":[],"source":"#At least here in the kernel, we don't need this fine time resoluton, so we downsample it first.\nx_train = decimate(x_train, 8, axis=1, zero_phase=True)\nx_train = decimate(x_train, 8, axis=1, zero_phase=True)\nx_train = decimate(x_train, 4, axis=1, zero_phase=True)\nx_test = decimate(x_test, 8, axis=1, zero_phase=True)\nx_test = decimate(x_test, 8, axis=1, zero_phase=True)\nx_test = decimate(x_test, 4, axis=1, zero_phase=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"63a7d151-dfb1-f802-ae89-417a2e61aff6"},"outputs":[],"source":"#Scale each observation to zero mean and unit variance.\n#For a neural net, we also need a channel axis at the end.\nx_train = ((x_train - np.mean(x_train, axis=1).reshape(-1,1)) / \n           np.std(x_train, axis=1).reshape(-1,1))\nx_test = ((x_test - np.mean(x_test, axis=1).reshape(-1,1)) / \n          np.std(x_test, axis=1).reshape(-1,1))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b503e0fe-c727-ca33-d25f-46448fa5ffe0"},"outputs":[],"source":"x_train = x_train[:,:,np.newaxis]\nx_test = x_test[:,:,np.newaxis]"},{"cell_type":"markdown","metadata":{"_cell_guid":"92a55b3f-04f7-b672-1a97-03a7ed824c0c"},"source":"Now, as explained in another [notebook][1], I will not use the classification from new_info['target'] but instead my own labels, with three classes 0=artifact, 1=normal/extrahls, and 2=murmur.\n\n\n  [1]: https://www.kaggle.com/toregil/d/kinguistics/heartbeat-sounds/misclassified-files-in-set-a/editnb \"notebook\""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a873a112-1452-3d4a-9b3f-f227df62613e"},"outputs":[],"source":"train_labels = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 2, \n                1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, \n                2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, \n                1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1]\n\ntest_labels = [0, 2, 1, 1, 1, 1, 1, 1, 0, 2, 0, 1, 1, 1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, \n               0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2c972e57-eaac-46ec-c937-62ca57731d07"},"outputs":[],"source":"def one_hot(labels, nb_classes=None):\n    if nb_classes is None:\n        nb_classes = max(labels) + 1\n    else:\n        assert nb_classes > max(labels)\n    result = np.zeros((len(labels), nb_classes), dtype=\"int\")\n    for i, l in enumerate(labels):\n        result[i, l] = 1\n    return result"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"97df701f-26c0-2bc2-fe63-c6352d8e00b5"},"outputs":[],"source":"y_train = one_hot(train_labels, 3)\ny_test = one_hot(test_labels, 3)"},{"cell_type":"markdown","metadata":{"_cell_guid":"e3f3cf03-ee0e-5db8-382b-ec69ce47c7c5"},"source":"##Train the model"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"75ca2f52-9bc3-2f65-15c6-279b31bc823c"},"outputs":[],"source":"model = Sequential()\nmodel.add(Conv1D(filters=4, kernel_size=11, activation='relu', input_shape=x_train.shape[1:]))\nmodel.add(MaxPool1D(strides=4))\nmodel.add(BatchNormalization())\nmodel.add(Conv1D(filters=8, kernel_size=11, activation='relu'))\nmodel.add(MaxPool1D(strides=4))\nmodel.add(BatchNormalization())\nmodel.add(Conv1D(filters=16, kernel_size=11, activation='relu'))\nmodel.add(MaxPool1D(strides=4))\nmodel.add(BatchNormalization())\nmodel.add(Conv1D(filters=128, kernel_size=11, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Conv1D(filters=128, kernel_size=1, activation='relu'))\nmodel.add(Dropout(0.75))\nmodel.add(GlobalAvgPool1D())\nmodel.add(Dense(3, activation='softmax'))"},{"cell_type":"markdown","metadata":{"_cell_guid":"f1551e66-8131-db8e-22f1-6f8300293adf"},"source":"This version of the net has 40.000 parameters, and I suspect it will overfit our dataset of 124 time series. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7d39e984-ed9c-c3c3-1941-418fd00421c8"},"outputs":[],"source":"def batch_generator(x_train, y_train, batch_size):\n    \"\"\"\n    Rotates the time series randomly in time\n    \"\"\"\n    x_batch = np.empty((batch_size, x_train.shape[1], x_train.shape[2]), dtype='float32')\n    y_batch = np.empty((batch_size, y_train.shape[1]), dtype='float32')\n    full_idx = range(x_train.shape[0])\n    \n    while True:\n        batch_idx = np.random.choice(full_idx, batch_size)\n        x_batch = x_train[batch_idx]\n        y_batch = y_train[batch_idx]\n    \n        for i in range(batch_size):\n            sz = np.random.randint(x_batch.shape[1])\n            x_batch[i] = np.roll(x_batch[i], sz, axis = 0)\n     \n        yield x_batch, y_batch"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"15bf1459-d424-cf33-150d-25b13bf78fe8"},"outputs":[],"source":"weight_saver = ModelCheckpoint('set_a_weights.h5', monitor='val_loss', \n                               save_best_only=True, save_weights_only=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"058ffb50-5b58-9887-cb3b-8eb11dc1815e"},"outputs":[],"source":"model.compile(optimizer=Adam(2e-5), loss='categorical_crossentropy', metrics=['accuracy'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f5a1e08c-d013-e145-8037-a5381bc379ab"},"outputs":[],"source":"hist = model.fit_generator(batch_generator(x_train, y_train, 8),\n                   epochs=40, steps_per_epoch=1000,\n                   validation_data = (x_test, y_test),\n                   callbacks=[weight_saver],\n                   verbose=2)"},{"cell_type":"markdown","metadata":{"_cell_guid":"14b1b34a-d6c1-b015-9395-f582b6b1b5cc"},"source":"## Evaluation"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d4172b5d-bc2d-9c01-2f7c-8956047a6596"},"outputs":[],"source":"plt.plot(hist.history['loss'], color='b')\nplt.plot(hist.history['val_loss'], color='r')\nplt.show()\nplt.plot(hist.history['acc'], color='b')\nplt.plot(hist.history['val_acc'], color='r')\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"85a84d48-2357-8f7f-1598-c27108ff539e"},"outputs":[],"source":"y_hat = model.predict(x_test)\nnp.set_printoptions(precision=2, suppress=True)\nfor i in range(3):\n    plt.plot(y_hat[:,i])\n    plt.plot(y_test[:,i])\n    plt.show()\nprint(CLASSES)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"26f8f49d-79d2-7430-f04f-895598e9047d"},"outputs":[],"source":"y_pred = np.argmax(y_hat, axis=1)\ny_true = np.argmax(y_test, axis=1)\nfor i in range(len(y_true)):\n    if y_pred[i] != y_true[i]:\n        print(\"Index: {}, Pred: {}, True: {}\".format(i, CLASSES[y_pred[i]], CLASSES[y_true[i]]))\n        plt.plot(x_test[i])\n        plt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"0b44d7f7-9df9-eeed-7ec1-8a9cc38508ec"},"source":"Not too bad. I'd be grateful if someone could double check my labelling."},{"cell_type":"markdown","metadata":{"_cell_guid":"7b7a673b-b8dc-52a8-4fd9-bb7c6c4c0681"},"source":"I'll be back when I checked set B."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"71120b26-32d4-ff9e-828b-5b082796b118"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}