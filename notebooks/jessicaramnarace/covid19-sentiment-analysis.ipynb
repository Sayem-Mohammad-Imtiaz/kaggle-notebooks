{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Twitter Sentiment Analysis of Covid-19   \n* Coronavirus disease (COVID-19) is an infectious disease caused by a newly discovered coronavirus.   \n* There are worldwide curfews, quarantines and lockdown established to prevent further spread of the virus.   \n* The basic agenda for this project is to use the #tags and other twitter components to analyse the behaviour of the indian citizens towards the overall situation of the lockdown.\n\n\n### Timeline of lockdown :\nPhase 1 : 25 March – 14 April   \nPhase 2 : 15 April – 3 May   \nPhase 3 : 4 May – 17 May   \nPhase 4 : 18 May – 31 May   \nPhase 5 : 1 June – 30 June     \n\nWe will be analyzing the tweets on 16th April,2020 i.e a day after Phase-2 was declared.\n\n### A simple web-app using Streamlit is deployed for displaying the visualizations. : https://covid19-sentiment-analysis.herokuapp.com/    \n\nThe source code and dataset for the same can be found here : https://github.com/kartik-mohan/Covid19-Sentiment-Analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Importing Packages","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom wordcloud import WordCloud,STOPWORDS\nstopwords = set(STOPWORDS)\n\nfrom textblob import TextBlob\n\nimport re\n\nfrom collections import Counter\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reading Data","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Reading data\ndf=pd.read_csv('/kaggle/input/coronavirus-covid19-tweets-late-april/2020-04-16 Coronavirus Tweets.CSV')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# display columns\ndf.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cleaning Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# dropping columns\ntweet = df.copy()\ntweet.drop(['status_id','user_id','screen_name','source','reply_to_status_id','reply_to_user_id','is_retweet','place_full_name','place_type','reply_to_screen_name','is_quote','followers_count','friends_count','account_lang','account_created_at','verified'],axis=1, inplace = True)\ntweet.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# filtering data with 'country_code = IN' and 'language = en'\ntweet =tweet[(tweet.country_code == \"IN\") & (tweet.lang == \"en\")].reset_index(drop = True)\ntweet.drop(['country_code','lang'],axis=1,inplace=True)\ntweet.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# created_at column\ntweet[\"created_at\"] = tweet[\"created_at\"].apply(lambda i:(int(i.split(\"T\")[1].split(\":\")[0])+int(i.split(\"T\")[1].split(\":\")[1])/60))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# shape\ntweet.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check missing values\ntweet.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data preprocessing\nfor i in range(tweet.shape[0]) :\n    tweet['text'][i] = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|(#[A-Za-z0-9]+)\", \" \", tweet['text'][i]).split()).lower()\ntweet['text'].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Top 5 most favourited tweets:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fav = tweet[['favourites_count','text']].sort_values('favourites_count',ascending = False)[:5].reset_index()\nfor i in range(5):\n    print(i,']', fav['text'][i],'\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Top 5 most retweeted tweets:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"retweet = tweet[['retweet_count','text']].sort_values('retweet_count',ascending = False)[:5].reset_index()\nfor i in range(5):\n    print(i,']', retweet['text'][i],'\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Number of Tweets/Hour","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(1, figsize=(10,6))\nplt.hist(tweet[\"created_at\"],bins = 24);\nplt.xlabel('Hours',size = 15)\nplt.ylabel('No. of Tweets',size = 15)\nplt.title('No. of Tweets per Hour',size = 15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Word Cloud : ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_wordcloud(data , title = None):\n    wordcloud = WordCloud(background_color='black',stopwords=stopwords,max_words=200,max_font_size=40).generate(str(data))\n  \n    fig = plt.figure(1, figsize=(15, 15))\n    plt.axis('off')\n    plt.title(title, size = 25)\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.show()\n\nshow_wordcloud(tweet['text'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The following words can be seen: covid, fear, chinese, starving, strategy.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Removing Stopwords","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"stopwords","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Removing Stop Words\ntweet['text'] = tweet['text'].apply(lambda tweets: ' '.join([word for word in tweets.split() if word not in stopwords]))\ntweet['text'].head() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Analyzing Text for Sentiment","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Analyzing text using TextBlob to predict the sentiment of the text and categorise it as 'Positive', 'Negative' or 'Neutral'.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tweet['sentiment'] = ' '\ntweet['polarity'] = None\nfor i,tweets in enumerate(tweet.text) :\n    blob = TextBlob(tweets)\n    tweet['polarity'][i] = blob.sentiment.polarity\n    if blob.sentiment.polarity > 0 :\n        tweet['sentiment'][i] = 'positive'\n    elif blob.sentiment.polarity < 0 :\n        tweet['sentiment'][i] = 'negative'\n    else :\n        tweet['sentiment'][i] = 'neutral'\ntweet.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(tweet.sentiment.value_counts())\nsns.countplot(x='sentiment', data = tweet);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Sentiment Distribution","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.distplot(tweet['polarity'], bins=30)\nplt.title('Sentiment Distribution',size = 15)\nplt.xlabel('Polarity',size = 15)\nplt.ylabel('Frequency',size = 15)\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Using Word Clouds to see the higher fequency words from each sentiment","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pos = tweet['text'][tweet['sentiment'] == 'positive']\nshow_wordcloud(pos , 'POSITIVE')\n\nneg = tweet['text'][tweet['sentiment'] == 'negative']\nshow_wordcloud(neg , 'NEGATIVE')\n\nneutral = tweet['text'][tweet['sentiment'] == 'neutral']\nshow_wordcloud(neutral , 'NEUTRAL')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count = pd.DataFrame(tweet.groupby('sentiment')['favourites_count'].sum())\ncount.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Most frequently appearing words","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"words = []\nwords = [word for i in tweet.text for word in i.split()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freq = Counter(words).most_common(30)\nfreq = pd.DataFrame(freq)\nfreq.columns = ['word', 'frequency']\nfreq.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10, 10))\nsns.barplot(y=\"word\", x=\"frequency\",data=freq);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweet.to_csv('tweet.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion  \nWe can conclude that mostly people have a positive and neutral sentiment towards the start of Lockdown-2.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Big data project start\n#Analysis of United Sates US \n#Analysis of Canada CN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#to view country codes needed first start by making a copy of the datset then dropping columns\ncountry_view = df.copy()\ncountry_view.drop(['status_id','user_id','screen_name','source','reply_to_status_id','reply_to_user_id','is_retweet','place_full_name','place_type','reply_to_screen_name','is_quote','followers_count','friends_count','account_lang','account_created_at','verified'],axis=1, inplace = True)\ncountry_view.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#to view country codes needed\ncountry_view = country_view.dropna()\ncountry_view.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#update stop words for better word cloud data \nstopwords.update([\"https\", \"name\", \"dtype\", \"text\", \"she\", \"whether\", \"ft\", \"in\"])\nstopwords","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create a new dataset that houses all data for US \nus_dataset = pd.DataFrame(df[(df.country_code == \"US\") & (df.lang == \"en\")])\nus_dataset.to_csv('us_data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create a new dataset that houses all data for CN \ncn_dataset = pd.DataFrame(df[(df.country_code == \"CN\") & (df.lang == \"en\")])\ncn_dataset.to_csv('cn_data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#view contents of us_data file \nus_dataset = pd.read_csv('./us_data.csv')\nus_dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"us_dataset.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making a copy of the dataset and dropping columns from us_dataset \nus_tweet = us_dataset.copy()\nus_tweet.drop(['status_id','user_id','screen_name','source','reply_to_status_id','reply_to_user_id','is_retweet','place_full_name','place_type','reply_to_screen_name','is_quote','followers_count','friends_count','account_lang','account_created_at','verified'],axis=1, inplace = True)\nus_tweet.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"us_tweet.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data preprocessing to make text uniform \nfor i in range(us_tweet.shape[0]) :\n    us_tweet['text'][i] = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|(#[A-Za-z0-9]+)\", \" \", us_tweet['text'][i]).split()).lower()\nus_tweet['text'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Removing Stop Words\nus_tweet['text'] = us_tweet['text'].apply(lambda tweets: ' '.join([word for word in tweets.split() if word not in stopwords]))\nus_tweet['text'].head() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#first word cloud showing data without sentiment \ndef show_wordcloud(data , title = None):\n    \n    wordcloud = WordCloud(background_color='black',stopwords=stopwords,max_words=200,max_font_size=40).generate(str(data))\n  \n    fig = plt.figure(1, figsize=(15, 15))\n    plt.axis('off')\n    plt.title(title, size = 25)\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.show()\n\nshow_wordcloud(us_tweet['text'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sentiment analysis of positive negative and neutral on us_tweet dataset\nus_tweet['sentiment'] = ' '\nus_tweet['polarity'] = None\nfor i,tweets in enumerate(us_tweet.text) :\n    blob = TextBlob(tweets)\n    us_tweet['polarity'][i] = blob.sentiment.polarity\n    if blob.sentiment.polarity > 0 :\n        us_tweet['sentiment'][i] = 'positive'\n    elif blob.sentiment.polarity < 0 :\n        us_tweet['sentiment'][i] = 'negative'\n    else :\n        us_tweet['sentiment'][i] = 'neutral'\nus_tweet.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#chart representation of sentiment for US\nprint(us_tweet.sentiment.value_counts())\nsns.countplot(x='sentiment', data = us_tweet);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# word cloud representation of sentiment analysis for US \npos = us_tweet['text'][us_tweet['sentiment'] == 'positive']\nshow_wordcloud(pos , 'POSITIVE')\n\nneg = us_tweet['text'][us_tweet['sentiment'] == 'negative']\nshow_wordcloud(neg , 'NEGATIVE')\n\nneutral = us_tweet['text'][us_tweet['sentiment'] == 'neutral']\nshow_wordcloud(neutral , 'NEUTRAL')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}