{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load the Library"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_recall_curve\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Read The Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_file_path = '../input/heart-disease-uci/heart.csv'\ndata_df = pd.read_csv(data_file_path)\n\n#To get information on the number of entries and the datatypes of the features\ndata_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To check the missing value"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To check how many of them are suffering from heart disease"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data_df['target'])\nplt.title('Countplot of Target')\nplt.xlabel('target')\nplt.ylabel('Patients')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Split into training and test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = data_df[\"target\"].values\nx = data_df.drop([\"target\"], axis = 1)\nfrom sklearn.preprocessing import StandardScaler\nss = StandardScaler()\nx = ss.fit_transform(x)\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are checking of 20 nearest neibhour to be caused with KNN algorithm"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = data_df[\"target\"].values\nx = data_df.drop([\"target\"], axis = 1)\nfrom sklearn.preprocessing import StandardScaler\nss = StandardScaler()\nx = ss.fit_transform(x)\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.3) # 70% training and 30% test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Evaluate the training and testing scores for up to 20 nearest neighbors"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_score = []\ntest_score = []\nk_vals = []\n\nfor k in range(1, 21):\n    k_vals.append(k)\n    knn = KNeighborsClassifier(n_neighbors = k)\n    knn.fit(X_train, y_train)\n    \n    tr_score = knn.score(X_train, y_train)\n    train_score.append(tr_score)\n    \n    te_score = knn.score(X_test, y_test)\n    test_score.append(te_score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To evaluate the max test score"},{"metadata":{"trusted":true},"cell_type":"code","source":"max_test_score = max(test_score)\ntest_scores_ind = [i for i, v in enumerate(test_score) if v == max_test_score]\nprint('Max test score {} and k = {}'.format(max_test_score * 100, list(map(lambda x: x + 1, test_scores_ind))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thus, we have obtained the optimum value of k to be 15,16 or 19 with a score of 82.41. We will finalize one of these values and fit the model accordingly"},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(3)\nknn.fit(X_train, y_train)\nknn.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we are implementing the confusion matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = knn.predict(X_test)\nconfusion_matrix(y_test,y_pred)\npd.crosstab(y_test, y_pred, rownames = ['Actual'], colnames =['Predicted'], margins = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hence we have calculated the final accuacy given below with the help of heart disease dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"KNN Prediction for algorithm processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 2)  # n_neighbors means k\nknn.fit(X_train, y_train)\nprediction = knn.predict(X_test)\n\nprint(\"{} NN Score: {:.2f}%\".format(2, knn.score(X_test, y_test)*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scoreList = []\nfor i in range(1,20):\n    knn = KNeighborsClassifier(n_neighbors = i)  # n_neighbors means k\n    knn.fit(X_train, y_train)\n    scoreList.append(knn.score(X_test, y_test))\n    \nplt.plot(range(1,20), scoreList)\nplt.xticks(np.arange(1,20,1))\nplt.xlabel(\"K value\")\nplt.ylabel(\"Score\")\nplt.show()\n\nacc = max(scoreList)*100\n\nprint(\"Maximum KNN Score is {:.2f}%\".format(acc))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}