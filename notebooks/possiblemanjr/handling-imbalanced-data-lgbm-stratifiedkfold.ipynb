{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Libraries\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\nfrom sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, roc_curve\nfrom sklearn.preprocessing import StandardScaler , Binarizer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nimport xgboost as xgb\nfrom time import time\nimport os, sys, gc, warnings, random, datetime\nimport math\nwarnings.filterwarnings('ignore')\nfrom sklearn.model_selection import StratifiedKFold , KFold\n# from ngboost import NGBRegressor\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Import Data","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_pickle(\"/kaggle/input/loan-condition-eda-data-cleansing/df_for_use.pkl\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Utilities","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_clf_eval(y_test, pred):\n    confusion = confusion_matrix(y_test, pred)\n    accuracy = accuracy_score(y_test , pred)\n    precision = precision_score(y_test, pred)\n    recall = recall_score(y_test,pred)\n    f1 = f1_score(y_test, pred)\n    auc = roc_auc_score(y_test, pred)\n    print('Confusion Matrix')\n    print(confusion)\n    print('Auccuracy : {0:.4f}, Precision : {1:.4f} , Recall : {2:.4f} , F1_Score : {3:.4f}, ROC_AUC_Score : {4:.4f}'.format(accuracy , precision, recall, f1, auc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"thresholds = {0.3,0.35, 0.4, 0.45, 0.50, 0.55, 0.60}\n\ndef get_eval_by_threshold(y_test, pred_proba_c1, thresholds):\n    for custom_threshold in thresholds:\n        binarizer = Binarizer(threshold = custom_threshold).fit(pred_proba_c1)\n        custom_predict = binarizer.transform(pred_proba_c1)\n        print('threshold:', custom_threshold)\n        get_clf_eval(y_test, custom_predict)\n\n## get_eval_by_threshold(y_test, pred_proba[:,1].reshape(-1,1), thresholds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### train_test_split (Stratify)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop('loan_condition_cat', axis=1)\ny = df['loan_condition_cat']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2 , random_state = 2020, stratify = y)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### LightGBM Without Fold","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### No Fold (Using GPU)\n\nstart = time.time()\n\nlgbm_clf = LGBMClassifier( n_estimators = 3000, random_state = 2020)\nevals = [(X_test, y_test)]\nlgbm_clf.fit(X_train, y_train, early_stopping_rounds = 100, eval_metric = 'auc' , eval_set = evals, verbose = 50)\nlgbm_roc_score = roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:,1], average = 'macro')\nprint( 'ROC_AUC : {0:.4f}'.format(lgbm_roc_score))\n\nprint(\"Runtime :\", time.time() - start)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### LightGBM with Startified 5 Fold / apply to previous train_test_split data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop('loan_condition_cat', axis=1)\ny = df['loan_condition_cat']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2 , random_state = 2020, stratify = y)\n\n\nfrom lightgbm import LGBMClassifier\n\nfrom time import time\nparams_lgb={'boosting_type':'gbdt',\n           'objective': 'binary',\n           'random_state':2020,\n           'metric':'auc'\n           }\n\nk_fold=5\nkf=StratifiedKFold(n_splits=k_fold,shuffle=True, random_state=2020)\ntraining_start_time = time()\naucs=[]\ny_preds = np.zeros(X_test.shape[0])\n\nfor fold, (trn_idx,val_idx) in enumerate(kf.split(X_train,y_train)):\n    start_time = time()\n    print('Training on fold {}'.format(fold + 1))\n    trn_data = lgb.Dataset(X_train.iloc[trn_idx], label=y_train.iloc[trn_idx])\n    val_data = lgb.Dataset(X_train.iloc[val_idx], label=y_train.iloc[val_idx])\n    clf = lgb.train(params_lgb, trn_data, num_boost_round=10000, valid_sets = [trn_data, val_data], \n                    verbose_eval=200, early_stopping_rounds=200)\n    aucs.append(clf.best_score['valid_1']['auc'])\n    print('Fold {} finished in {}'.format(fold + 1, str(datetime.timedelta(seconds=time() - start_time))))\n    y_preds += clf.predict(X_test) / 5\n    \n    \n    \nprint('-' * 30)\nprint('Training is completed!.')\nprint(\"\\n## Mean CV_AUC_Score : \", np.mean(aucs))\nprint('Total training time is {}'.format(str(datetime.timedelta(seconds=time() - training_start_time))))\n# print(clf.best_params_)\nprint('-' * 30)\n\n\n# pred_rf = clf.predict(X_test)\nauc = roc_auc_score(y_test,y_preds)\nprint(' ROC_AUC_Score : {0:.4f}'.format (auc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### LightGBM with Startified 5 Fold / Entire Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop('loan_condition_cat', axis=1)\ny = df['loan_condition_cat']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2 , random_state = 2020, stratify = y)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from time import time\nparams_lgb={'boosting_type':'gbdt',\n           'objective': 'binary',\n           'random_state':2020,\n           'metric':'auc'}\n\nk_fold=5\nkf=StratifiedKFold(n_splits=k_fold,shuffle=True, random_state=2020)\ntraining_start_time = time()\naucs=[]\n\nfor fold, (trn_idx,val_idx) in enumerate(kf.split(X,y)):\n    start_time = time()\n    print('Training on fold {}'.format(fold + 1))\n    trn_data = lgb.Dataset(X.iloc[trn_idx], label=y.iloc[trn_idx])\n    val_data = lgb.Dataset(X.iloc[val_idx], label=y.iloc[val_idx])\n    clf = lgb.train(params_lgb, trn_data, num_boost_round=10000, valid_sets = [trn_data, val_data], \n                    verbose_eval=200, early_stopping_rounds=200)\n    aucs.append(clf.best_score['valid_1']['auc'])\n    print('Fold {} finished in {}'.format(fold + 1, str(datetime.timedelta(seconds=time() - start_time))))\n    \nprint('-' * 30)\nprint('Training is completed!.')\nprint(\"\\n## Mean CV_AUC_Score : \", np.mean(aucs))\nprint('Total training time is {}'.format(str(datetime.timedelta(seconds=time() - training_start_time))))\n# print(clf.best_params_)\nprint('-' * 30)\n\n# X_test = test_df.drop('loan_condition_cat', axis=1)\n# y_test = test_df['loan_condition_cat']\n\n# pred_rf = clf.predict(X_test)\n# auc = roc_auc_score(y_test,pred_rf)\n# print(' ROC_AUC_Score : {0:.4f}'.format (auc))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}