{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Price prediction for Airbnb host in Madrid\n\nThis kernel is about how to solve a predictive regression problem, as it was used as a test for ML Deployment with a RestAPI.\n\n## Goal\n\n- Predict price to guide future our actual Airbnb host in Madrid about what price they have to put on the market.\n- Model evaluated models on Root-Mean-Squared-Error (RMSE. \n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport time\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom scipy import stats\nfrom scipy.stats import norm, skew\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import PowerTransformer, LabelEncoder\nfrom sklearn.model_selection import train_test_split, GridSearchCV, KFold\nfrom sklearn.linear_model import Lasso, Ridge\nfrom lightgbm import LGBMRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/madrid-airbnb-data/listings.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seed = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = train_test_split(df, test_size=0.2, random_state=seed, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Cleaning"},{"metadata":{},"cell_type":"markdown","source":"### Missing data"},{"metadata":{"trusted":true},"cell_type":"code","source":"total = train.isnull().sum().sort_values(ascending=False)\npercent = (train.isnull().sum()/train.isnull().count()).sort_values(ascending=False)\n\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(23)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Only reviews are missing and they are not important because I only want to know the house characteristics to predict price."},{"metadata":{"trusted":true},"cell_type":"code","source":"def missing_data(data):\n    \n    missing_datatypes = [j for i in data.columns for j in ['-','?','--','@','NA','NaN','na','Na',' '] \n                         if j in data[i].unique()]\n\n    if len(missing_datatypes) > 0 and data.isnull().values.any() == False:\n        print(set(missing_datatypes))\n\n    elif len(missing_datatypes) > 0 and data.isnull().values.any() == True:\n        missing_datatypes.append('NaN')\n        print(set(missing_datatypes))\n\n    elif len(missing_datatypes) == 0 and data.isnull().values.any() == True:\n        print('NaN')\n\n    else:\n        print('No missing data founded')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_data(train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Drop unnecessary columns"},{"metadata":{},"cell_type":"markdown","source":"To keep the model and input data simple. Don't need review information: just room/flat characteristics."},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[['neighbourhood_group', 'neighbourhood', 'room_type', 'minimum_nights', 'price']]\ntest = test[['neighbourhood_group', 'neighbourhood', 'room_type', 'minimum_nights', 'price']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Analysis"},{"metadata":{},"cell_type":"markdown","source":"### Data distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_distribution = train.hist(figsize=(5,5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(train['price'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(train['price'], plot=plt)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Correlations"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.corr()['price'].sort_values().drop('price')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#correlation matrix\nf, ax = plt.subplots(figsize = (12, 9))\nsns.heatmap(train.corr(),annot = False, vmax=.8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(train, height = 1.5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"var = 'minimum_nights'\ndata = pd.concat([train['price'], train[var]], axis=1)\ndata.plot.scatter(x=var, y='price', alpha=0.3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Need to encode the categorical variables to have a better view of the correlations."},{"metadata":{},"cell_type":"markdown","source":"## Feature engineering"},{"metadata":{},"cell_type":"markdown","source":"### Transform variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_distribution = train.hist(figsize=(5, 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(train['price'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(train['price'], plot=plt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train.drop(['price'], axis=1)\ny_train = train['price'].values\n\nX_test = test.drop(['price'], axis=1)\ny_test= test['price'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Because price have zero/negative values, I use a power transform which accept them.\n\nnum_cols = X_train._get_numeric_data().columns.tolist()\n\npt = PowerTransformer(method='yeo-johnson')\n\nX_train[num_cols]= pt.fit_transform(X_train[num_cols])\nX_test[num_cols]= pt.transform(X_test[num_cols])\n\ny_train = pt.fit_transform(y_train.reshape(-1, 1))\ny_test = pt.transform(y_test.reshape(-1, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_distribution = X_train.hist(figsize=(5,5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_plot = train.copy()\n\ny_train_plot['price'] = y_train\n\nsns.distplot(y_train_plot['price'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(y_train_plot['price'], plot=plt)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Label encoding categorical features"},{"metadata":{"trusted":true},"cell_type":"code","source":"le = LabelEncoder()\n\ncat_cols_train = X_train.select_dtypes(include=['string', 'object']).columns.tolist()\n\ncat_cols_test = X_test.select_dtypes(include=['string', 'object']).columns.tolist()\n\n\nfor col in cat_cols_train:\n    X_train[col] = le.fit_transform(X_train[col].astype('string'))\n\n# I fit the test dataset because it contains previously unseen labels in the train dataset\nfor col in cat_cols_test:\n    X_test[col] = le.fit_transform(X_test[col].astype('string'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train['price'] = y_train.ravel().tolist()\n\nX_train.drop(X_train[(X_train['price']<-4)].index, inplace=True)\n\ny_train = X_train['price']\n\nX_train.drop('price', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature importance"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X_train, y_train.values, random_state = seed)\n\nmodel = Lasso(alpha=0.02)\nmodel.fit(X_train,y_train)\n\nplt.figure(figsize=(10,10))\n\nmodel_ft_imp = pd.DataFrame(data=model.coef_,columns=['FeatureImp'], index = X_train.columns).sort_values(by='FeatureImp', ascending=False)\n\nmodel_ft_imp_nonzero = model_ft_imp[model_ft_imp['FeatureImp'] != 0]\n\nsns.barplot(x=model_ft_imp_nonzero['FeatureImp'], y=model_ft_imp_nonzero.index, palette=\"Reds\")\n\nplt.title('Lasso Feature importance', fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Negative correlation can be also useful."},{"metadata":{},"cell_type":"markdown","source":"## Model"},{"metadata":{},"cell_type":"markdown","source":"I use a custom function to tune hyperparametters and also apply K-Fold Cross Validation. I did not use Random forest or XGBoost because they give me problems in combination with K-Fold."},{"metadata":{"trusted":true},"cell_type":"code","source":"def estimator_params(X,y):\n\n    estimator_params = []\n    score = []    \n    Time = []\n\n    estimators = [GradientBoostingRegressor(),\n                   LGBMRegressor(),\n                   Ridge(),\n                   Lasso()]\n\n\n    params = [ {'max_depth':[5,10,15], \n                'min_samples_split':[10, 50, 100],\n                'learning_rate':[0.01,0.1,0.5], \n                'max_features':['sqrt'],\n                'random_state': [seed]},\n                            \n               {'num_leaves': [5,10,20], \n                'max_depth': [None, 5, 10, 20], \n                'learning_rate': [0.01,0.1,0.5], \n                'n_estimators': [10, 50, 100],\n                'random_state': [seed]},\n    \n                {'alpha': [5, 10, 20, 50,100],\n                'tol': [0.5,0.9],\n                'random_state': [seed]},\n             \n                {'alpha' : [0.1, 1],\n                 'max_iter': [1000, 2000],\n                 'random_state': [seed]}]\n    \n    # KFold\n    \n    kf = KFold(n_splits = 5, shuffle=True, random_state = seed)\n    \n    cv_params = {'cv': kf, 'scoring': 'neg_root_mean_squared_error', 'verbose': 0}\n\n\n    # GridSearchCV\n    \n    for estimator,param in zip(estimators, params):\n        start = time.time()\n        \n        grid_solver = GridSearchCV(estimator, param_grid = param, **cv_params).fit(X_train, y_train)\n\n        estimator_params.append(grid_solver.best_estimator_)\n        score.append(-(grid_solver.best_score_))\n        stop = time.time()\n        print('{} optimization finished'.format(str(estimator)))\n        print()\n        Time.append(stop-start)\n        \n    global estimator_params_df\n    \n    estimator_params_df = pd.DataFrame(columns = ['Estimator_params','Score_RMSE','Time'])\n    estimator_params_df['Estimator_params']= estimator_params\n    estimator_params_df['Score_RMSE'] = score\n    estimator_params_df['Time']= Time\n    \n    return estimator_params_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"estimator_params(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"estimator_params_df['Estimator_params'][1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I select LGBMRegressor because the time difference is high and the error difference is low and I want a fast model for the API."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LGBMRegressor(max_depth=10, num_leaves=20, random_state=0)\n\nmodel.fit(X_train,y_train)\n\npredictions = model.predict(X_test)\n\n# Reversing the power transformation\npredictions = pt.inverse_transform(predictions.reshape(-1,1))\n\npredictions = np.around(predictions,2).ravel().tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}