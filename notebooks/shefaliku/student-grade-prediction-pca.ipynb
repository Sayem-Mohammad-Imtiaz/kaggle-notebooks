{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"186ac19976f69256c51db257ec768c00186b0b8e"},"cell_type":"markdown","source":"The data were obtained in a survey of students math and portuguese language courses in secondary school. It contains a lot of interesting social, gender and study information about students. "},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n%matplotlib inline\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nfrom sklearn import metrics\nfrom sklearn import linear_model\nfrom sklearn.model_selection import train_test_split\nimport time","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bd4c1b41a72044e7e8945947f163b38ead02261b"},"cell_type":"markdown","source":"\nRead student dataset for subject Math and Portuguese"},{"metadata":{"trusted":true,"_uuid":"abe108213b063368c50520551b0ddac7c7ed5021"},"cell_type":"code","source":"student_mat= pd.read_csv(\"../input/student-mat.csv\")\nstudent_por= pd.read_csv(\"../input/student-por.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"caf411a10b17413da6168be9893de110231f9d8d"},"cell_type":"code","source":"#It show some basic statistical details like percentile, mean, std etc.\nstudent_mat.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"82562c8726b53484708f1b12040c6783d7e0cc5b"},"cell_type":"code","source":"student_por.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9f53b98614f2964af77fb4f4f1fa076c0175fc7e"},"cell_type":"markdown","source":"Merge both datasets"},{"metadata":{"trusted":true,"_uuid":"8d1857f0485e626f8a6036f3df02c546d41e1185"},"cell_type":"code","source":"student_data = pd.merge(student_mat,student_por,how=\"outer\")\nstudent_data.head()\n#student_data.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3871c38ef726a99dd9b9c5011924fa32a728cf64"},"cell_type":"markdown","source":"Check columns with dtype as object "},{"metadata":{"trusted":true,"_uuid":"354a0aaf94c66db615f7eec8d4a0cbbe04c6f4e9"},"cell_type":"code","source":"col_str = student_data.columns[student_data.dtypes == object]\ncol_str","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5596b52aeb75c413c296070bdb182964b16419d6"},"cell_type":"markdown","source":"The basic strategy is to convert each category value into a new column and assign a 1 or 0 (True/False) value to the column. This has the benefit of not weighting a value improperly. Simplest one is using pandas' .get_dummies() method to support one- hot encoding."},{"metadata":{"trusted":true,"_uuid":"3201fa23bd869869fa74766ccd01c11552cd095d"},"cell_type":"code","source":"student_data = pd.get_dummies(student_data, columns = col_str, drop_first = True)\nstudent_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2804df2f6b3e9fbe0f483b161c003555398d482d"},"cell_type":"code","source":"print(student_data[[\"G1\",\"G2\",\"G3\"]].corr())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0659dc2e23a33940f5251e3d135eefedb198ca49"},"cell_type":"markdown","source":"Since, G1,G2,G3 have very high correlation, we can drop G1,G2"},{"metadata":{"trusted":true,"_uuid":"7a6570a8dca04becefffc78902eddf15b0659dcb"},"cell_type":"code","source":"student_data.drop(axis = 1,labels= [\"G1\",\"G2\"])\nstudent_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8dc9276e0069f736081a66da306004bd8c6aeb21"},"cell_type":"code","source":"label = student_data[\"G3\"].values\npredictors = student_data.drop(axis = 1,labels= [\"G3\"]).values\nstudent_data.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d48b06338f6fd0d1bcd6bcf13460761e23a568db"},"cell_type":"code","source":"#Using Linear Regression to predict grades\nlr = linear_model.LinearRegression()\nlr_score= cross_val_score(lr, predictors, label, cv=5)\nprint(\"LR Model Cross Validation score : \" + str(lr_score))\nprint(\"LR Model Cross Validation Mean score : \" + str(lr_score.mean()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b7eba5008147745b543cf36506638d3fb9653a08"},"cell_type":"code","source":"#Using PCA\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=len(student_data.columns)-1)\npca.fit(predictors)\nvariance_ratio = pca.explained_variance_ratio_\npca.explained_variance_.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"97f55b2b76c20993a5a13bbc5d99a883da52c610"},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nvariance_ratio_cum_sum=np.cumsum(variance_ratio)\nprint(variance_ratio_cum_sum)\nplt.plot(variance_ratio_cum_sum)\nplt.xlabel('Number of components')\nplt.ylabel('Cumulative explained variance')\nplt.annotate('10',xy=(10,.90))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5ea0b14f3b668ee3c42a18930497d2a550e5faa5"},"cell_type":"markdown","source":"This cumilative explained variance graph helps us to choose the number of desired principal components.\n90% variation in the data is explaining by the first 10 principal components "},{"metadata":{"trusted":true,"_uuid":"6b694d7bb90fcc4e73634c12102e08947052f27c"},"cell_type":"code","source":"# individual explained variance\nplt.figure(figsize=(10, 5))\n\nplt.bar(range(41),pca.explained_variance_, alpha=0.5,label='individual explained variance')\nplt.ylabel('Explained variance ratio')\nplt.xlabel('Principal components')\nplt.legend(loc='best')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"085d7d0f1ab2733ab2d1e46a54ff9c4a4bfe216e"},"cell_type":"markdown","source":"PCA transforms a set of correlated variables into a set of linearly uncorrelated variables called principal components, we can check the correlarion with a heat map of correlation matrix"},{"metadata":{"trusted":true,"_uuid":"77d860a285767a72b9495a871b1f9544d8971d01"},"cell_type":"code","source":"#correlation between the variables after transforming the data with PCA is 0\nimport seaborn as sns\ncorrelation = pd.DataFrame(PCA().fit_transform(predictors)).corr()\nsns.heatmap(correlation, vmax=1, square=True,cmap='viridis')\nplt.title('Correlation between different features')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c0ef418d37ccd843fb3d38c791934639258dd0a2"},"cell_type":"code","source":"#Looking at above plot I'm taking 10 variables\npca = PCA(n_components=10)\npca.fit(predictors)\nTransformed_vector =pca.fit_transform(predictors)\nprint(Transformed_vector)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ca569b98537fd48585eac0d07d62215787542f7"},"cell_type":"code","source":"#correlation between the variables after transforming the data with PCA is 0\nimport seaborn as sns\ncorrelation = pd.DataFrame(Transformed_vector).corr()\nsns.heatmap(correlation, vmax=1, square=True,cmap='viridis')\nplt.title('Correlation between different features')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3f0e4118f0a4628eac10a36571924e69404b92ff"},"cell_type":"markdown","source":"\ncheck the performance after considering the first 10 principal components"},{"metadata":{"trusted":true,"_uuid":"25fdc250d65708122d2543d4b598d70648f03682"},"cell_type":"code","source":"lr_pca = linear_model.LinearRegression()\nlr_pca_score = cross_val_score(lr_pca, Transformed_vector, label, cv=5)\nprint(\"PCA Model Cross Validation score : \" + str(lr_pca_score))\nprint(\"PCA Model Cross Validation Mean score : \" + str(lr_pca_score.mean()))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}