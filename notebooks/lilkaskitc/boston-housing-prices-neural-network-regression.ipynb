{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n\nfrom keras import models\nfrom keras import layers\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-23T02:44:40.949383Z","iopub.execute_input":"2021-07-23T02:44:40.950086Z","iopub.status.idle":"2021-07-23T02:44:40.971957Z","shell.execute_reply.started":"2021-07-23T02:44:40.950025Z","shell.execute_reply":"2021-07-23T02:44:40.970974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\ndata = pd.read_csv(\"../input/boston-house-prices/housing.csv\", header=None, delimiter=r\"\\s+\", names=column_names)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T02:29:48.338865Z","iopub.execute_input":"2021-07-23T02:29:48.339355Z","iopub.status.idle":"2021-07-23T02:29:48.355607Z","shell.execute_reply.started":"2021-07-23T02:29:48.33932Z","shell.execute_reply":"2021-07-23T02:29:48.354742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T02:29:48.357336Z","iopub.execute_input":"2021-07-23T02:29:48.35782Z","iopub.status.idle":"2021-07-23T02:29:48.382553Z","shell.execute_reply.started":"2021-07-23T02:29:48.357784Z","shell.execute_reply":"2021-07-23T02:29:48.381838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"code","source":"y = data[\"MEDV\"]\nX = data.drop(labels = [\"MEDV\"],axis = 1) \ntrain_data, test_data, train_targets, test_targets = train_test_split(X, y, test_size = 0.2, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T02:33:08.850178Z","iopub.execute_input":"2021-07-23T02:33:08.850604Z","iopub.status.idle":"2021-07-23T02:33:08.858506Z","shell.execute_reply.started":"2021-07-23T02:33:08.850568Z","shell.execute_reply":"2021-07-23T02:33:08.857803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train_data.shape\n#test_data.shape\ntrain_targets","metadata":{"execution":{"iopub.status.busy":"2021-07-23T02:33:09.087074Z","iopub.execute_input":"2021-07-23T02:33:09.087458Z","iopub.status.idle":"2021-07-23T02:33:09.09632Z","shell.execute_reply.started":"2021-07-23T02:33:09.087424Z","shell.execute_reply":"2021-07-23T02:33:09.095121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Normalizing\nmean = train_data.mean(axis=0)\ntrain_data -= mean\nstd = train_data.std(axis=0)\ntrain_data /= std\ntest_data -= mean\ntest_data /= std","metadata":{"execution":{"iopub.status.busy":"2021-07-23T02:33:13.135164Z","iopub.execute_input":"2021-07-23T02:33:13.135574Z","iopub.status.idle":"2021-07-23T02:33:13.165166Z","shell.execute_reply.started":"2021-07-23T02:33:13.135542Z","shell.execute_reply":"2021-07-23T02:33:13.164139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"def build_model():\n    model = models.Sequential()\n    model.add(layers.Dense(64, activation='relu', input_shape=(train_data.shape[1],)))\n    model.add(layers.Dense(64, activation='relu'))\n    model.add(layers.Dense(1))\n    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-07-23T02:35:21.369745Z","iopub.execute_input":"2021-07-23T02:35:21.370171Z","iopub.status.idle":"2021-07-23T02:35:21.376754Z","shell.execute_reply.started":"2021-07-23T02:35:21.370127Z","shell.execute_reply":"2021-07-23T02:35:21.3757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## K-fold validation","metadata":{}},{"cell_type":"code","source":"k = 4\nnum_val_samples = len(train_data) // k\nnum_epochs = 100\nall_scores = []\n\nfor i in range(k):\n    print('processing fold #', i)\n    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n    partial_train_data = np.concatenate(\n        [train_data[:i * num_val_samples],\n        train_data[(i + 1) * num_val_samples:]],\n        axis=0)\n    partial_train_targets = np.concatenate(\n        [train_targets[:i * num_val_samples],\n        train_targets[(i + 1) * num_val_samples:]],\n        axis=0)\n    model = build_model()\n    model.fit(partial_train_data, partial_train_targets,\n        epochs=num_epochs, batch_size=1, verbose=0)\n    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n    all_scores.append(val_mae)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-23T02:37:05.602852Z","iopub.execute_input":"2021-07-23T02:37:05.603297Z","iopub.status.idle":"2021-07-23T02:38:36.664443Z","shell.execute_reply.started":"2021-07-23T02:37:05.603258Z","shell.execute_reply":"2021-07-23T02:38:36.663398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#all_scores\nnp.mean(all_scores)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T02:41:00.941623Z","iopub.execute_input":"2021-07-23T02:41:00.942195Z","iopub.status.idle":"2021-07-23T02:41:00.947149Z","shell.execute_reply.started":"2021-07-23T02:41:00.942134Z","shell.execute_reply":"2021-07-23T02:41:00.946427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 500 epochs with log\nnum_epochs = 500\nall_mae_histories = []\nfor i in range(k):\n    print('processing fold #', i)\n    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n    partial_train_data = np.concatenate(\n        [train_data[:i * num_val_samples],\n        train_data[(i + 1) * num_val_samples:]],\n        axis=0)\n    partial_train_targets = np.concatenate(\n        [train_targets[:i * num_val_samples],\n        train_targets[(i + 1) * num_val_samples:]],\n        axis=0)\n    model = build_model()\n    history = model.fit(partial_train_data, partial_train_targets,\n                        validation_data=(val_data, val_targets),\n                        epochs=num_epochs, batch_size=1, verbose=0)\n    mae_history = history.history['val_mae']\n    all_mae_histories.append(mae_history)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T02:49:30.674646Z","iopub.execute_input":"2021-07-23T02:49:30.675041Z","iopub.status.idle":"2021-07-23T03:00:43.525379Z","shell.execute_reply.started":"2021-07-23T02:49:30.675006Z","shell.execute_reply":"2021-07-23T03:00:43.524437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"average_mae_history = [\nnp.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]","metadata":{"execution":{"iopub.status.busy":"2021-07-23T03:00:43.526857Z","iopub.execute_input":"2021-07-23T03:00:43.52714Z","iopub.status.idle":"2021-07-23T03:00:43.54033Z","shell.execute_reply.started":"2021-07-23T03:00:43.527114Z","shell.execute_reply":"2021-07-23T03:00:43.539216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(range(1, len(average_mae_history) + 1), average_mae_history)\nplt.xlabel('Epochs')\nplt.ylabel('Validation MAE')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T03:00:43.542311Z","iopub.execute_input":"2021-07-23T03:00:43.542715Z","iopub.status.idle":"2021-07-23T03:00:43.708161Z","shell.execute_reply.started":"2021-07-23T03:00:43.542672Z","shell.execute_reply":"2021-07-23T03:00:43.707041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def smooth_curve(points, factor=0.9):\n    smoothed_points = []\n    for point in points:\n        if smoothed_points:\n            previous = smoothed_points[-1]\n            smoothed_points.append(previous * factor + point * (1 - factor))\n        else:\n            smoothed_points.append(point)\n    return smoothed_points\nsmooth_mae_history = smooth_curve(average_mae_history[10:])\nplt.plot(range(1, len(smooth_mae_history) + 1), smooth_mae_history)\nplt.xlabel('Epochs')\nplt.ylabel('Validation MAE')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T03:03:30.453766Z","iopub.execute_input":"2021-07-23T03:03:30.454125Z","iopub.status.idle":"2021-07-23T03:03:30.599384Z","shell.execute_reply.started":"2021-07-23T03:03:30.454096Z","shell.execute_reply":"2021-07-23T03:03:30.598718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluate on test set","metadata":{}},{"cell_type":"code","source":"model = build_model()\nmodel.fit(train_data, train_targets,\nepochs=80, batch_size=16, verbose=0)\ntest_mse_score, test_mae_score = model.evaluate(test_data, test_targets)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T03:05:59.790657Z","iopub.execute_input":"2021-07-23T03:05:59.791056Z","iopub.status.idle":"2021-07-23T03:06:02.246481Z","shell.execute_reply.started":"2021-07-23T03:05:59.791024Z","shell.execute_reply":"2021-07-23T03:06:02.245504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_mae_score","metadata":{"execution":{"iopub.status.busy":"2021-07-23T03:06:02.247903Z","iopub.execute_input":"2021-07-23T03:06:02.248168Z","iopub.status.idle":"2021-07-23T03:06:02.253076Z","shell.execute_reply.started":"2021-07-23T03:06:02.248142Z","shell.execute_reply":"2021-07-23T03:06:02.252251Z"},"trusted":true},"execution_count":null,"outputs":[]}]}