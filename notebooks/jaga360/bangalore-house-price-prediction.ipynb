{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1= pd.read_csv(\"../input/bengaluru-house-price-data/Bengaluru_House_Data.csv\")\ndf1.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# removing particular columns\n# removing null values also because comparing to total data points null points is \n# only 3 to 5 percent\n\ndf2=df1.copy()\ndf2.drop(['area_type','availability','society'],axis=1,inplace=True)\ndf2.dropna(inplace=True)\ndf2.reset_index(inplace=True, drop=True)\ndf2.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preprocessing size column\n\ndf2['size'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# changing size column from string to numeric \n\ndf2['size']=df2['size'].apply(lambda x : float(x.split(' ')[0]))\ndf2.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preprocessing total_sqft attribute\n# analysing what types of values are there and displaying only range like values\n\ndef is_float(x):\n    try:\n        float(x)\n    except:\n        return False\n    \n    return True\n\n# ~ negation symbol interchanges boolean values \n\ndf2[~df2['total_sqft'].apply(is_float)]","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# converting range like values in string to numeric values\n# range value is converted to mean value\n\n# values with different units (eg: \"50 sq meters\") converted to none so that\n# later it is removed from the dataframe\n\ndef convertSqftToNum(x):\n    tokens=x.split('-')\n    if len(tokens)==2:\n        return (float(tokens[0])+float(tokens[1]))/2\n    try:\n        return float(x)\n    except:\n        return None\n    \ndf2['total_sqft']=df2['total_sqft'].apply(convertSqftToNum)\ndf2.dropna(inplace=True)\ndf2.reset_index(inplace=True,drop=True)\ndf2.head(10)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# grouping by location and calculating how many values are there within one location\n\ndf2['location']=df2['location'].apply(lambda x : x.strip())\nlocation_count=df2.groupby(\"location\")[\"location\"].agg(\"count\").sort_values()\nlocation_count","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# there are too many unique values in location which is not great for any conversion\n# methods like one-hot encoding.\n\n# so checkLocation function groups them based on no.of datapoints per location using some\n# threshold\n\ndef check_location(x):\n    if location_count[x] <= 10:\n        return 'others'\n    else:\n        return x\n    \ndf2['location']=df2['location'].apply(check_location)\nlocation_count=df2.groupby(\"location\")[\"location\"].count()\nlocation_count","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.head(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Outlier Detection","metadata":{}},{"cell_type":"code","source":"# assuming threshold is 300 sqft per bedroom in a house below that is unlikely\n\ndf2[df2[\"total_sqft\"]/ df2[\"size\"] < 300 ]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# As the anomalies are less compared to total data points we can remove it\n\ndf2 =  df2[~ (df2[\"total_sqft\"]/ df2[\"size\"] < 300) ]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# added new attribute price_per_sqft to remove outliers\n# data points lies between one sd is retained remaining are removed within each city\n\ndf2[\"price_per_sqft\"]=df2[\"price\"]*100000 / df2[\"total_sqft\"]\n\ndef remove_pps_outliers(df):\n    df_out= pd.DataFrame()\n    for city, subdf in df.groupby(\"location\"):\n        m=np.mean(subdf[\"price_per_sqft\"])\n        sd=np.std(subdf[\"price_per_sqft\"])\n        temp_df= subdf[(subdf[\"price_per_sqft\"] > (m-sd)) & (subdf[\"price_per_sqft\"] < (m+sd))]\n        df_out=pd.concat([df_out,temp_df], ignore_index=True)\n    return df_out\n\nprint(df2.shape)\ndf2=remove_pps_outliers(df2)\nprint(df2.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# removing outliers based on bathrooms \n# assuming threshold is n+1 bathrooms for n bedrooms\n\ndf2=df2[df2[\"bath\"] < df2[\"size\"]+2 ]\nprint(df2.shape)\n\n# dropping th pps feature becoz it is added only to remove outliers and it is a reduncacy\ndf2=df2.drop(\"price_per_sqft\", axis=1)\ndf2.reset_index(inplace=True,drop=True)\ndf2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# converting location feature to numeric using one hot encoding\ndummies= pd.get_dummies(df2.location)\ndf3= pd.concat([df2, dummies], axis=1)\ndf3=df3.drop([\"location\", 'balcony'], axis=1)\ndf3.reset_index(inplace=True,drop=True)\ndf3.head()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df3.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=df3.drop('price',axis=1)\ny=df3['price']\n\nprint(len(X),len(y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Building","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\n\n#models which we are going to test it so there would be 10 total models.\n\nalgos={\n    \n    \"linear_regression\":{\n        \"model\":LinearRegression(),\n        \"params\":{\n            'normalize':[True,False]\n        }\n    },\n    \n    \"lasso\":{\n        \"model\":Lasso(),\n        \"params\":{\n            'alpha':[1,2],\n            'selection':['random','cyclic']\n        }\n    },\n    \n    \"decision_tree\":{\n        \"model\":DecisionTreeRegressor(),\n        \"params\":{\n            'criterion':['mse','friedman_mse'],\n            'splitter':['best','random']\n            \n        }\n    }\n    \n}\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import ShuffleSplit\n\nscores=[]\ncv = ShuffleSplit(n_splits=5, test_size=.25, random_state=0)\n\nfor algo_name , algo in algos.items():\n    model=algo['model']\n    params=algo['params']\n    gs=GridSearchCV(model,params,cv=cv,return_train_score=False)\n    gs.fit(X,y)\n    scores.append({\n        'model':algo_name,\n        'best_score':gs.best_score_,\n        'best_params':gs.best_params_\n    })\n\n    \nscores=pd.DataFrame(scores,columns=['model','best_score','best_params'])\nscores","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from the above scores we conclude that linear_regression with normalized parameter= true\n#is the best among the models we trained \n\nmdl = LinearRegression(normalize=True)\nmdl.fit(X,y)\n\ndef predict_price(location,sqft,bath,bhk):\n       \n    # creating x instance from the given details\n    x=np.zeros(len(X.columns))\n    x[0]=bhk\n    x[1]=sqft\n    x[2]=bath\n    loc_index=np.where(X.columns == location)[0][0]\n    x[loc_index]=1\n    return mdl.predict([x])\n ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_price(\"Indira Nagar\",1000,2,2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_price(\"1st Block Jayanagar\",1000,2,2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exporting model","metadata":{}},{"cell_type":"code","source":"import pickle\n\nwith open('house_price_prediction.pickle','wb') as f:\n    pickle.dump(mdl,f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\n\n# exporting the columns so that it is used in server side code\ncolumns={\n    'data_columns':[ col for col in X.columns]\n}\n\nwith open('house_prediction_columns.json','w') as f:\n    f.write(json.dumps(columns))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}