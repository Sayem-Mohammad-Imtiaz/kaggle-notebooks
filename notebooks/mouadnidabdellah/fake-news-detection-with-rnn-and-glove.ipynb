{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Fake news detection","metadata":{}},{"cell_type":"code","source":"# Importig standard Libraries \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport seaborn as sns\n\n# Train / Test split\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\n\n#!pip install wordcloud\nfrom wordcloud import WordCloud,STOPWORDS\n\n# Import the natural language toolkit library \n#!pip install nltk\nimport nltk\n#nltk.download(\"punkt\")\n#nltk.download(\"stopwords\")\nfrom nltk.corpus import stopwords\n\n# Text tokenization\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# Importing Metrics\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\n\n# Loading the model and Ploting its architecture.\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.utils import plot_model\n\n#Ploting the confusion matrix\nfrom sklearn.metrics import confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2021-07-28T11:30:34.786967Z","iopub.execute_input":"2021-07-28T11:30:34.78755Z","iopub.status.idle":"2021-07-28T11:30:41.94755Z","shell.execute_reply.started":"2021-07-28T11:30:34.787463Z","shell.execute_reply":"2021-07-28T11:30:41.946562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Importing the ISOT dataset files**","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\n\n# read the csv files\nd_true = pd.read_csv(\"/kaggle/input/fake-and-real-news-dataset/True.csv\")\nd_fake = pd.read_csv(\"/kaggle/input/fake-and-real-news-dataset/Fake.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-07-28T11:30:41.94901Z","iopub.execute_input":"2021-07-28T11:30:41.949293Z","iopub.status.idle":"2021-07-28T11:30:44.60138Z","shell.execute_reply.started":"2021-07-28T11:30:41.949267Z","shell.execute_reply":"2021-07-28T11:30:44.600412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1. EDA & DATA PREPROCESSING","metadata":{}},{"cell_type":"code","source":"d_true.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T11:30:44.603177Z","iopub.execute_input":"2021-07-28T11:30:44.603557Z","iopub.status.idle":"2021-07-28T11:30:44.631732Z","shell.execute_reply.started":"2021-07-28T11:30:44.603524Z","shell.execute_reply":"2021-07-28T11:30:44.630715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d_true.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T11:30:44.633484Z","iopub.execute_input":"2021-07-28T11:30:44.633909Z","iopub.status.idle":"2021-07-28T11:30:44.777557Z","shell.execute_reply.started":"2021-07-28T11:30:44.633869Z","shell.execute_reply":"2021-07-28T11:30:44.776501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d_fake.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T11:30:44.778742Z","iopub.execute_input":"2021-07-28T11:30:44.779008Z","iopub.status.idle":"2021-07-28T11:30:44.790826Z","shell.execute_reply.started":"2021-07-28T11:30:44.778983Z","shell.execute_reply":"2021-07-28T11:30:44.789718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d_fake.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T11:30:44.792238Z","iopub.execute_input":"2021-07-28T11:30:44.79258Z","iopub.status.idle":"2021-07-28T11:30:44.90046Z","shell.execute_reply.started":"2021-07-28T11:30:44.792551Z","shell.execute_reply":"2021-07-28T11:30:44.899433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# add a column with the name label that has value 1 for reliable news and 0 for fake news\n\nd_true[\"label\"] = 1\nd_fake[\"label\"] = 0","metadata":{"execution":{"iopub.status.busy":"2021-07-28T11:30:44.903193Z","iopub.execute_input":"2021-07-28T11:30:44.903484Z","iopub.status.idle":"2021-07-28T11:30:44.908513Z","shell.execute_reply.started":"2021-07-28T11:30:44.903458Z","shell.execute_reply":"2021-07-28T11:30:44.907707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**True Dataset's WordCloud**","metadata":{}},{"cell_type":"code","source":"# plot the true dataset's wordcloud using top 500 words\n\nplt.figure(figsize = (15,15))\nwc = WordCloud(max_words = 500 , width = 1000 , height = 500, background_color=\"rgba(255, 255, 255, 0)\", stopwords = STOPWORDS).generate(\" \".join(d_true.text))\nplt.imshow(wc , interpolation = 'bilinear')\nplt.axis('off')\n#plt.savefig(\"../True dataset's world cloud.png\", bbox_inches='tight')","metadata":{"execution":{"iopub.status.busy":"2021-07-28T11:30:44.911827Z","iopub.execute_input":"2021-07-28T11:30:44.912246Z","iopub.status.idle":"2021-07-28T11:31:20.27892Z","shell.execute_reply.started":"2021-07-28T11:30:44.912205Z","shell.execute_reply":"2021-07-28T11:31:20.277991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**fake Dataset's WordCloud**","metadata":{}},{"cell_type":"code","source":"# plot the true dataset's wordcloud using top 500 words\n\nplt.figure(figsize = (15,15))\nwc = WordCloud(max_words = 500 , width = 1000 , height = 500 , background_color=\"rgba(255, 255, 255, 0)\", stopwords = STOPWORDS).generate(\" \".join(d_fake.text))\nplt.imshow(wc)\nplt.axis('off')\n#plt.savefig(\"../Fake dataset's world cloud.png\", bbox_inches='tight')","metadata":{"execution":{"iopub.status.busy":"2021-07-28T11:31:20.280532Z","iopub.execute_input":"2021-07-28T11:31:20.280967Z","iopub.status.idle":"2021-07-28T11:31:59.755972Z","shell.execute_reply.started":"2021-07-28T11:31:20.280937Z","shell.execute_reply":"2021-07-28T11:31:59.75508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Concatenate the title with the article text\n\nd_true['text'] = d_true['title'] +\" \"+ d_true['text']\nd_fake['text'] = d_fake['title'] +\" \"+ d_fake['text']","metadata":{"execution":{"iopub.status.busy":"2021-07-28T11:31:59.757492Z","iopub.execute_input":"2021-07-28T11:31:59.758076Z","iopub.status.idle":"2021-07-28T11:31:59.881273Z","shell.execute_reply.started":"2021-07-28T11:31:59.758038Z","shell.execute_reply":"2021-07-28T11:31:59.880561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# drop the unnecessary columns\n\nd_true.drop([\"title\", \"subject\", \"date\"], axis=1, inplace= True)\nd_fake.drop([\"title\", \"subject\", \"date\"], axis=1, inplace= True)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T11:31:59.882437Z","iopub.execute_input":"2021-07-28T11:31:59.882901Z","iopub.status.idle":"2021-07-28T11:31:59.891549Z","shell.execute_reply.started":"2021-07-28T11:31:59.882872Z","shell.execute_reply":"2021-07-28T11:31:59.890647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# concatenate the two dataframes and shuffle the result\n\ndata = pd.concat([d_true, d_fake], axis=0, ignore_index = True)\ndata = shuffle(data)\n\ndata = data.reset_index(drop= True)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T11:31:59.892874Z","iopub.execute_input":"2021-07-28T11:31:59.89319Z","iopub.status.idle":"2021-07-28T11:31:59.920048Z","shell.execute_reply.started":"2021-07-28T11:31:59.893154Z","shell.execute_reply":"2021-07-28T11:31:59.919138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check if there is any null values\n\ndata.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T11:31:59.921203Z","iopub.execute_input":"2021-07-28T11:31:59.9215Z","iopub.status.idle":"2021-07-28T11:31:59.934247Z","shell.execute_reply.started":"2021-07-28T11:31:59.92145Z","shell.execute_reply":"2021-07-28T11:31:59.933396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-28T11:31:59.935546Z","iopub.execute_input":"2021-07-28T11:31:59.935831Z","iopub.status.idle":"2021-07-28T11:31:59.943273Z","shell.execute_reply.started":"2021-07-28T11:31:59.935805Z","shell.execute_reply":"2021-07-28T11:31:59.942623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check the data distribution\n\ndata.label.value_counts().plot(kind='bar', color=['b', 'g'])","metadata":{"execution":{"iopub.status.busy":"2021-07-28T11:31:59.944442Z","iopub.execute_input":"2021-07-28T11:31:59.944911Z","iopub.status.idle":"2021-07-28T11:32:00.108352Z","shell.execute_reply.started":"2021-07-28T11:31:59.944881Z","shell.execute_reply":"2021-07-28T11:32:00.107395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check the number of articles in each type (fake or true)\n# 0 for fake and 1 for true\n\ndata.label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T11:32:00.109482Z","iopub.execute_input":"2021-07-28T11:32:00.109751Z","iopub.status.idle":"2021-07-28T11:32:00.117459Z","shell.execute_reply.started":"2021-07-28T11:32:00.109726Z","shell.execute_reply":"2021-07-28T11:32:00.11669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting the number of words in texts\n\nfig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,10))\ntext_len=data[data['label']==0]['text'].str.split().map(lambda x: len(x))\nax1.hist(text_len,color='SkyBlue')\nax1.set_title('Fake news texts')\n\ntext_len=data[data['label']==1]['text'].str.split().map(lambda x: len(x))\nax2.hist(text_len,color='PeachPuff')\nax2.set_title('Real news texts')\nfig.suptitle('Number of Words in texts')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T11:32:00.118727Z","iopub.execute_input":"2021-07-28T11:32:00.119102Z","iopub.status.idle":"2021-07-28T11:32:03.069993Z","shell.execute_reply.started":"2021-07-28T11:32:00.119064Z","shell.execute_reply":"2021-07-28T11:32:03.069027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### TEXT PROCESSING WITH THE NLTK LIBRARY","metadata":{}},{"cell_type":"code","source":"# defining a function that takes care of cleaning stopwords and punctuations using nltk library.\nstop_words = set(stopwords.words('english'))\ndef process(text):\n    \"\"\"Converting the texts into lowercase characters and removing punctuations and stopwords using the nltk library.\"\"\"\n    text = text.lower()\n    words = nltk.word_tokenize(text)\n    new_words= [word for word in words if word.isalnum() and word not in stop_words]\n    text = \" \".join(new_words)\n    return text","metadata":{"execution":{"iopub.status.busy":"2021-07-28T11:32:03.071938Z","iopub.execute_input":"2021-07-28T11:32:03.072374Z","iopub.status.idle":"2021-07-28T11:32:03.083974Z","shell.execute_reply.started":"2021-07-28T11:32:03.072333Z","shell.execute_reply":"2021-07-28T11:32:03.083009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cleaning the text and seperating the target(label) variable and the feature(text) variable.\ndata = shuffle(data)\n\ndata['text'] = data['text'].apply(process)\nX = data['text'].to_frame()\nY = data['label'].to_frame()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T11:32:03.08546Z","iopub.execute_input":"2021-07-28T11:32:03.085761Z","iopub.status.idle":"2021-07-28T11:35:49.272479Z","shell.execute_reply.started":"2021-07-28T11:32:03.085733Z","shell.execute_reply":"2021-07-28T11:35:49.271791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ploting the number of words after removing stopwords\ntext_len=X['text'].str.split().map(lambda x: len(x))\nplt.hist(text_len,color='SkyBlue')\nplt.title('number of words')","metadata":{"execution":{"iopub.status.busy":"2021-07-28T11:35:49.27358Z","iopub.execute_input":"2021-07-28T11:35:49.274111Z","iopub.status.idle":"2021-07-28T11:35:51.164753Z","shell.execute_reply.started":"2021-07-28T11:35:49.274075Z","shell.execute_reply":"2021-07-28T11:35:51.164042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculating the average number of words in the texts in order to use it as the length of sequences.\n# Calculting the number of unique words in order to pass it as argument to the tensorflow tokenizer.\n\nAvg_len = text_len.mean()\nAvg_len = round(Avg_len)\nlst = []\nfor i in X['text']:\n    tmp = i.split()\n    lst.extend(tmp)\nlst = set(lst)\nVocab_size = len(lst)\nprint(\"the average number of words in the texts is : \", Avg_len)\nprint(\"the texts contains\", Vocab_size, \"unique words\")","metadata":{"execution":{"iopub.status.busy":"2021-07-28T11:35:51.165944Z","iopub.execute_input":"2021-07-28T11:35:51.166462Z","iopub.status.idle":"2021-07-28T11:35:53.153428Z","shell.execute_reply.started":"2021-07-28T11:35:51.166423Z","shell.execute_reply":"2021-07-28T11:35:53.152503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. TEXT TOKENIZATION","metadata":{}},{"cell_type":"code","source":"tokenizer = Tokenizer(num_words=Vocab_size)\ntokenizer.fit_on_texts(X['text'])\nsequences = tokenizer.texts_to_sequences(X['text'])\n\nword_index = tokenizer.word_index\nprint('Found %s unique tokens.' % len(word_index))","metadata":{"execution":{"iopub.status.busy":"2021-07-28T11:35:53.154524Z","iopub.execute_input":"2021-07-28T11:35:53.1548Z","iopub.status.idle":"2021-07-28T11:36:07.533299Z","shell.execute_reply.started":"2021-07-28T11:35:53.154773Z","shell.execute_reply":"2021-07-28T11:36:07.532201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# padding the sequences created by the tokenizer using the the average number of words in the texts + 2 = 235 as the maxlen.\n# also setting up the truncation and the padding to be at the end of the sequence.\n\ndata = pad_sequences(sequences, maxlen=Avg_len+2, padding='post', truncating='post')","metadata":{"execution":{"iopub.status.busy":"2021-07-28T11:36:07.537121Z","iopub.execute_input":"2021-07-28T11:36:07.537402Z","iopub.status.idle":"2021-07-28T11:36:09.204853Z","shell.execute_reply.started":"2021-07-28T11:36:07.537374Z","shell.execute_reply":"2021-07-28T11:36:09.204093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. Spliting the data into train / test sets","metadata":{}},{"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(data, Y, test_size=0.25, random_state=25)\nprint(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T11:36:09.206289Z","iopub.execute_input":"2021-07-28T11:36:09.206582Z","iopub.status.idle":"2021-07-28T11:36:09.233879Z","shell.execute_reply.started":"2021-07-28T11:36:09.206557Z","shell.execute_reply":"2021-07-28T11:36:09.232915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4. Using GloVe for Word Embeddings","metadata":{}},{"cell_type":"code","source":"# Import tensor representations for words\n# GloVe is an unsupervised learning algorithm for obtaining vector representations for words\n\nembeddings_index = {};\nwith open(\"/kaggle/input/glove6b100dtxt/glove.6B.100d.txt\", encoding=\"utf8\") as f:\n    for line in f:\n        values = line.split();\n        word = values[0];\n        coefs = np.asarray(values[1:], dtype='float32');\n        embeddings_index[word] = coefs;\nprint(len(coefs))\n\nembeddings_matrix = np.zeros((Vocab_size+1, 100));\nfor word, i in word_index.items():\n    embedding_vector = embeddings_index.get(word);\n    if embedding_vector is not None:\n        embeddings_matrix[i] = embedding_vector;\n","metadata":{"execution":{"iopub.status.busy":"2021-07-28T11:44:29.014872Z","iopub.execute_input":"2021-07-28T11:44:29.015262Z","iopub.status.idle":"2021-07-28T11:44:45.880973Z","shell.execute_reply.started":"2021-07-28T11:44:29.015229Z","shell.execute_reply":"2021-07-28T11:44:45.880259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(embeddings_matrix.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T11:44:45.88224Z","iopub.execute_input":"2021-07-28T11:44:45.882503Z","iopub.status.idle":"2021-07-28T11:44:45.887268Z","shell.execute_reply.started":"2021-07-28T11:44:45.88248Z","shell.execute_reply":"2021-07-28T11:44:45.886357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5. Building the architecture of the model","metadata":{}},{"cell_type":"code","source":"# Building the architecture of the model\n     \nmodel = tf.keras.Sequential([\n    tf.keras.layers.Embedding(len(word_index)+1, 100, weights=[embeddings_matrix], trainable = False),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n    tf.keras.layers.Dense(32, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T11:44:45.888583Z","iopub.execute_input":"2021-07-28T11:44:45.888844Z","iopub.status.idle":"2021-07-28T11:44:46.568388Z","shell.execute_reply.started":"2021-07-28T11:44:45.888822Z","shell.execute_reply":"2021-07-28T11:44:46.567469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6. Model training","metadata":{}},{"cell_type":"code","source":"# using an early stop callback to stop the trainning if the loss function cannot be improved anymore.\n\nearly_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\nmodel.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              optimizer=tf.keras.optimizers.Adam(1e-4),\n              metrics=['accuracy'])\n\nhistory = model.fit(X_train, Y_train, epochs=10, validation_split=0.1, batch_size=32, shuffle=True, callbacks=[early_stop])","metadata":{"execution":{"iopub.status.busy":"2021-07-28T11:44:46.569729Z","iopub.execute_input":"2021-07-28T11:44:46.57004Z","iopub.status.idle":"2021-07-28T11:59:12.818863Z","shell.execute_reply.started":"2021-07-28T11:44:46.570007Z","shell.execute_reply":"2021-07-28T11:59:12.818075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Save the model","metadata":{}},{"cell_type":"code","source":"model.save(\"/kaggle/output/model1.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-07-28T12:01:34.216533Z","iopub.execute_input":"2021-07-28T12:01:34.217006Z","iopub.status.idle":"2021-07-28T12:01:34.36823Z","shell.execute_reply.started":"2021-07-28T12:01:34.21696Z","shell.execute_reply":"2021-07-28T12:01:34.367562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting the architecture of the model.\n\nplot_model(model, to_file='/kaggle/output/model_schema.png', show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T11:59:12.938773Z","iopub.execute_input":"2021-07-28T11:59:12.939028Z","iopub.status.idle":"2021-07-28T11:59:13.374513Z","shell.execute_reply.started":"2021-07-28T11:59:12.939004Z","shell.execute_reply":"2021-07-28T11:59:13.373846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 7. Model Evaluation","metadata":{}},{"cell_type":"code","source":"# evaluating the model with the evaluate method.\nmodel.evaluate(X_test, Y_test)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-07-28T11:59:13.375736Z","iopub.execute_input":"2021-07-28T11:59:13.376104Z","iopub.status.idle":"2021-07-28T11:59:24.346853Z","shell.execute_reply.started":"2021-07-28T11:59:13.376076Z","shell.execute_reply":"2021-07-28T11:59:24.346143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict the labels of test set.\nY_pred = (model.predict(X_test) >= 0.5).astype(\"int\")","metadata":{"execution":{"iopub.status.busy":"2021-07-28T11:59:24.348855Z","iopub.execute_input":"2021-07-28T11:59:24.349212Z","iopub.status.idle":"2021-07-28T11:59:34.591869Z","shell.execute_reply.started":"2021-07-28T11:59:24.349175Z","shell.execute_reply":"2021-07-28T11:59:34.591053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluating the model using sklearn metrics.\n\naccuracy = accuracy_score(list(Y_test['label']), Y_pred)\nprecision = precision_score(Y_test, Y_pred)\nrecall = recall_score(Y_test, Y_pred)\n\nprint(\"Model Accuracy : \", accuracy)\nprint('Precision on testing set:', precision)\nprint('Recall on testing set:', recall)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T11:59:34.594877Z","iopub.execute_input":"2021-07-28T11:59:34.59512Z","iopub.status.idle":"2021-07-28T11:59:34.618548Z","shell.execute_reply.started":"2021-07-28T11:59:34.595096Z","shell.execute_reply":"2021-07-28T11:59:34.617954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ploting the confusion matrix using the seaborn library\n\ngraph = confusion_matrix(Y_test, Y_pred)\nplt.figure(figsize=(12, 10))\nax= plt.subplot()\nsns.heatmap(graph, annot=True, ax = ax)\nax.xaxis.set_ticklabels(['Fake','True'], size=15)\nax.yaxis.set_ticklabels(['Fake','True'], size=15)\nplt.savefig(\"../Confusion_matrix.png\", bbox_inches='tight')","metadata":{"execution":{"iopub.status.busy":"2021-07-28T11:59:34.619461Z","iopub.execute_input":"2021-07-28T11:59:34.619833Z","iopub.status.idle":"2021-07-28T11:59:34.945095Z","shell.execute_reply.started":"2021-07-28T11:59:34.619799Z","shell.execute_reply":"2021-07-28T11:59:34.944535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}