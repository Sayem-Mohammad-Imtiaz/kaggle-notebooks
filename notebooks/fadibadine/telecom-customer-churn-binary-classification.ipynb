{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Configuration","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Include","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\n\nimport tensorflow as tf\nprint(\"TensorFlow version: {}\".format(tf.__version__))\n\nfrom tensorflow.keras import Input, Model\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import AUC, FalseNegatives, FalsePositives, TrueNegatives, TruePositives, Recall, Precision\nfrom tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Initialisation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"init = {\n    \"datadir\": \"/kaggle/input/telco-customer-churn/\",\n    \"datafile\": \"WA_Fn-UseC_-Telco-Customer-Churn.csv\",\n    \"test_split\": 0.1,\n    \"test_random_state\": 42,\n    \"val_split\": 0.1,\n    \"val_random_state\": 43,\n    \"clear_logs\": True,\n    \"classweights\": True\n}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Useful Functions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_telco_churn_data(dataset_path, dataset_file):\n    assert(dataset_path is not None and dataset_file is not None)\n    \n    csv_path = os.path.join(dataset_path, dataset_file)\n    \n    return pd.read_csv(csv_path)\n\ndef plot_feature(df,\n                  x,\n                  y = \"Percent\",\n                  title = None,\n                  x_label = None,\n                  y_label = None,\n                  x_axis_split = None,\n                  figsize=(16,5),\n                  annotate = False,\n                  sort_per_feature = True,\n                  exclude_values = None):\n    fig = plt.figure(figsize=figsize)\n\n    if exclude_values is not None and isinstance(exclude_values, str):\n        feature_counts = (df.loc[df[x] != exclude_values].groupby(['Churn'])[x]\n                        .value_counts(normalize=True)\n                        .rename(y)\n                        .mul(100)\n                        .reset_index())\n    else:\n        feature_counts = (df.groupby(['Churn'])[x]\n                        .value_counts(normalize=True)\n                        .rename(y)\n                        .mul(100)\n                        .reset_index())\n        \n    if sort_per_feature is True:\n        feature_counts = feature_counts.sort_values(x, ascending=False)\n    \n    p = sns.barplot(x=x, y=y, hue=\"Churn\", data=feature_counts)\n    if title is not None:\n        p.set_title(title, fontsize=20)\n    if x_label is not None:\n        p.set_xlabel(x_label)\n    if y_label is not None:\n        p.set_ylabel(y_label)\n\n    if x_axis_split is not None:\n        _, _ = plt.xticks(np.arange(df[x].min(),\n                             df[x].max(),\n                             x_axis_split),\n                          np.arange(df[x].min(),\n                             df[x].max(),\n                             x_axis_split))\n    if annotate is True:\n        sizes = []\n        for patch in p.patches:\n            h, w = patch.get_height(), patch.get_width()\n            sizes.append(h)\n\n            p.annotate(format(h, '.2f'),\n                       (patch.get_x() + w / 2., h),\n                       ha = 'center',\n                       va = 'center',\n                       xytext = (0, 10),\n                       textcoords = 'offset points')\n            \n        p.set_ylim(0, max(sizes) * 1.15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Loading Data","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Reading the dataset and printing its header\ndf_data = load_telco_churn_data(dirname, filename)\nprint(\"Data dimension: {}\".format(df_data.shape))\n\n# Create a train / test split\ndf_train, df_test = train_test_split(df_data,\n                                       test_size=init[\"test_split\"],\n                                       random_state=init[\"test_random_state\"])\n\nprint(\"Train Data dimension: {}\".format(df_train.shape))\nprint(\"Test Data dimension: {}\".format(df_test.shape))\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Analysis\n\nIn this section, we shall explore the data and focus on the following:\n* General data analysis: \n    * How many samples do we have for training and testing\n    * What are the different columns and their types\n    * Any missing data\n* Data visualisation: \n    Display the Churn as a function of other properties","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Basic Analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's first see how the training sample is split across churn vs non-churn just to see if we have an unbalanced dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"no_yes_percentage = df_train[\"Churn\"].value_counts() / df_train.shape[0] * 100\n\nprint(\"In the training set, {0:.2f}% will churn and {1:.2f}% will not\".format(no_yes_percentage[1], no_yes_percentage[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is an **unbalanced** dataset so we need to take this into consideration when we train the model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We notice that non of the fields have a null-object. Let's double check this","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"However this does not mean that some values are not the way we want them to be.   \nExample: we notice that unlike MonthlyCharges which is of type float32, TotalCharges is of type Object. Let's see if it contains values that are not float","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train[\"TotalCharges\"].to_frame().head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"There are {} white space occurrences in TotalCharges\".format(df_train[\"TotalCharges\"].str.count(\" \").sum()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have 11 occurrences of space.   \nLet's drop those for visualisation reasons","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"o_shape = df_train.shape\n\ndf_train.drop(df_train.loc[df_train[\"TotalCharges\"] == \" \"].index, inplace=True)\n\nprint(\"Shape has been reduced from {} to {}\".format(o_shape, df_train.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Churn as a function of\nIn this section, we will plot and analyse the Churn as a function of the different profiles' characteristics in order to better understand what drives Churn","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Gender","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(df_train,\n              x = \"gender\",\n              title = \"Churn Percentage / Gender\",\n              x_label = \"Gender\",\n              y_label = \"Percentage\",\n              x_axis_split = None,\n              annotate = True,\n              exclude_values = 'test')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observation:** Both Male and Female subscribers churn almost equally. 49.85% of churners are male and 50.15% female.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Senior Citizen","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(df_train,\n              x = \"SeniorCitizen\",\n              title = \"Churn Percentage / Senior Citizen\",\n              x_label = \"Senior Citizen\",\n              y_label = \"Percentage\",\n              x_axis_split = None,\n              annotate = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observation:** The majority of those who churn are younger people (74.93%)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Partners & Dependents","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(df_train,\n              x = \"Partner\",\n              title = \"Churn Percentage / Partner\",\n              x_label = \"Partner\",\n              y_label = \"Percentage\",\n              x_axis_split = None,\n              annotate = True)\n\nplot_feature(df_train,\n              x = \"Dependents\",\n              title = \"Churn Percentage / Dependents\",\n              x_label = \"Dependents\",\n              y_label = \"Percentage\",\n              x_axis_split = None,\n              annotate = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observation:** The majority of those who churn do not have a partner (63.64%) and with no dependents (82.39%)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Phone Services","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(df_train,\n              x = \"PhoneService\",\n              title = \"Churn Percentage / Phone Service\",\n              x_label = \"Phone Service\",\n              y_label = \"Percentage\",\n              x_axis_split = None,\n              annotate = True)\n\nplot_feature(df_train,\n              x = \"MultipleLines\",\n              title = \"Churn Percentage / Multiple Lines\",\n              x_label = \"Multiple Lines\",\n              y_label = \"Percentage\",\n              x_axis_split = None,\n              annotate = True,\n              exclude_values = \"No phone service\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observation:** The vast majority of those who churn have phone service (90.69%) out of which almost half have multiple lines (50.23% as opposed to 49.7% who don't)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Internet Services","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(df_train,\n              x = \"InternetService\",\n              title = \"Churn Percentage / Internet Service\",\n              x_label = \"Internet Service\",\n              y_label = \"Percentage\",\n              x_axis_split = None,\n              annotate = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(df_train,\n              x = \"OnlineSecurity\",\n              title = \"Churn Percentage / Online Security\",\n              x_label = \"Online Security\",\n              y_label = \"Percentage\",\n              x_axis_split = None,\n              annotate = True,\n             exclude_values=\"No internet service\")\n\nplot_feature(df_train,\n              x = \"OnlineBackup\",\n              title = \"Churn Percentage / Online Backup\",\n              x_label = \"Online Backup\",\n              y_label = \"Percentage\",\n              x_axis_split = None,\n              annotate = True,\n             exclude_values=\"No internet service\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(df_train,\n              x = \"DeviceProtection\",\n              title = \"Churn Percentage / Device Protection\",\n              x_label = \"Device Protection\",\n              y_label = \"Percentage\",\n              x_axis_split = None,\n              annotate = True,\n             exclude_values=\"No internet service\")\n\nplot_feature(df_train,\n              x = \"TechSupport\",\n              title = \"Churn Percentage / Tech Support\",\n              x_label = \"Tech Support\",\n              y_label = \"Percentage\",\n              x_axis_split = None,\n              annotate = True,\n             exclude_values=\"No internet service\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(df_train,\n              x = \"StreamingTV\",\n              title = \"Churn Percentage / Streaming TV\",\n              x_label = \"Streaming TV\",\n              y_label = \"Percentage\",\n              x_axis_split = None,\n              annotate = True,\n             exclude_values=\"No internet service\")\n\nplot_feature(df_train,\n              x = \"StreamingMovies\",\n              title = \"Churn Percentage / Streaming Movies\",\n              x_label = \"Streaming Movies\",\n              y_label = \"Percentage\",\n              x_axis_split = None,\n              annotate = True,\n             exclude_values=\"No internet service\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observation:** It seems that the vast majority of churners have internet service (~ 93%). A big chunk of those have fiber optic (~ 69%)\nThe different internet services that are affecting churn are:\n* Big impact: Online Security (~ 83%) and Tech Support (~ 82%)\n* Medium impact: Online Backup (~ 70%) and Device Protection (~ 69%)\n* Low impact: Streaming TV and Streaming Movies (~ 53% each)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Contract","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(df_train,\n              x = \"Contract\",\n              title = \"Churn Percentage / Contract\",\n              x_label = \"Contract\",\n              y_label = \"Percentage\",\n              x_axis_split = None,\n              annotate = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observation:** Those who churn have shorter contracts. The vast majority (~ 88%) are on month-to-month plans while only ~ 2.5% of churners have a two-year-*contract*","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Tenure","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(df_train,\n              x = \"tenure\",\n              title = \"Churn Percentage / Tenure\",\n              x_label = \"Tenure (months)\",\n              y_label = \"Percentage\",\n              x_axis_split = 5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observation:** The majority of customers who churn have not been with the operator for a long period with almost 20% not exceeding one month","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Billing Method","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature(df_train,\n              x = \"PaperlessBilling\",\n              title = \"Churn Percentage / Paperless Billing\",\n              x_label = \"Paperless Billing\",\n              y_label = \"Percentage\",\n              x_axis_split = None,\n              annotate = True)\n\nplot_feature(df_train,\n              x = \"PaymentMethod\",\n              title = \"Churn Percentage / Payment Method\",\n              x_label = \"Payment Method\",\n              y_label = \"Percentage\",\n              x_axis_split = None,\n              annotate = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observation:** Almost 75% of churners use paperless billing. ~ 57% use electronic check","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Monthly Charges","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"col     = \"MonthlyCharges\"\nsep     = \" \"\nsuf     = \"Ranges\"\nnew_col = col + sep + suf\n\nbins    = 30\nx_min   = df_train[col].min()\nx_max   = df_train[col].max()\nx_step  = (x_max - x_min) / bins\n\ndf_train[new_col] = pd.cut(df_train[col], bins, right=True, labels=False)\ndf_train.loc[:, [new_col]] = ((df_train[new_col] + 1) * x_step + x_min).astype(np.int32)\n\nplot_feature(df_train,\n              x = new_col,\n              title = \"Churn Percentage / Monthly Charges\",\n              x_label = \"Monthly Charges Ranges (less than)\",\n              y_label = \"Percentage\",\n              x_axis_split = None,\n              sort_per_feature=False)\n\ndf_train = df_train.drop(columns=[new_col])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observation:** The Churn slightly changes as a function of the monthly charges with ~ 5% of churners having a monthly bill of less that 21`$`, ~ 8% have their bill less than 81`$` It then decreases to reach 0.4% for monthly bills in the 118`$` range.  ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Total Charges","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"col     = \"TotalCharges\"\nsep     = \" \"\nsuf     = \"Ranges\"\nnew_col = col + sep + suf\n\ndf_train[col] = df_train[col].map(lambda x: np.nan if x in [' '] else np.float64(x))\n\nbins    = 30\nx_min   = df_train[col].min()\nx_max   = df_train[col].max()\nx_step  = (x_max - x_min) / bins\n\ndf_train[new_col] = pd.cut(df_train[col], bins, right=True, labels=False)\ndf_train.loc[:, [new_col]] = ((df_train[new_col] + 1) * x_step + x_min).astype(np.int32)\n\nplot_feature(df_train,\n              x = new_col,\n              title = \"Churn Percentage / Total Charges\",\n              x_label = \"Total Charges Ranges (less than)\",\n              y_label = \"Percentage\",\n              x_axis_split = None,\n              sort_per_feature=False)\n\ndf_train = df_train.drop(columns=[new_col])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observation:** Total Charges on the other hand takes a different shape where the majority of churners (~ 36%) have their total bill less than 307. This percentage decreases until it reaches 0.07%","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Data Preprocessing\n\nIn this section, we will create pipelines and a column transformer that will prepare the data for training","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Reloading Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# If df_train and df_test were already read, delete them in order\n# to load them again and let the automatic data preprocessing take\n# care of the wrong data in TotalAmounts column automatically\ntry:\n    del df_train\n    del df_test\nexcept NameError:\n    pass\n\ndf_data = load_telco_churn_data(init[\"datadir\"], init[\"datafile\"])\n\n# Create a (train, val) / test split\ndf_train, df_test = train_test_split(df_data,\n                                       test_size=init[\"test_split\"],\n                                       random_state=init[\"test_random_state\"])\n\n\n# Copy in order not to have a warning when trying to alter the data\ndf_train_features = df_train.copy()\ndf_train_labels   = df_train[\"Churn\"].map(dict(Yes=1, No=0)).copy()\ndf_train_features = df_train.drop(\"Churn\", axis=1)\n\ndf_test_features  = df_test.copy()\ndf_test_labels    = df_test[\"Churn\"].map(dict(Yes=1, No=0)).copy()\ndf_test_features  = df_test.drop(\"Churn\", axis=1)\n\n# Remove df_data\ndel df_data, df_train, df_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Encoders","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Object to Float Encoder\nThis encoder is used to transform the TotalCharges attribute which in the dataset is of type Object and its elements are of type string. 10 of which, as we have seen contains space.\nWe are replacing any value that cannot be converted to np.float64 by a `replace_value` with default value is np.nan\nWhen this goes into a Pipeline, a SimpleImputer should follow that will replace np.nan by the appropriate value.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class ObjectToFloatEncoder(BaseEstimator, TransformerMixin):\n    def __init__(self, replace_value = np.nan):\n        self.replace_value = replace_value\n    \n    def fit(self, X, y = None):\n        return self\n    \n    def transform(self, X, y = None):\n        if isinstance(X, pd.DataFrame):\n            for s_name in list(X):\n                X[s_name] = X[s_name].map(lambda x: self.replace_value if not self._is_float(x) else np.float64(x))\n        elif isinstance(X, pd.Series):\n            X = X.map(lambda x: self.replace_value if not self._is_float(x) else np.float64(x))\n        else:\n            X = np.apply_along_axis(self._to_float64, 0, X)\n        \n        return X\n\n    def _is_float(self, s):\n        try:\n            np.float64(s)\n            return True\n        except ValueError:\n            return False\n\n    def _to_float64(self, s):\n        try:\n            f = np.float64(s)\n        except ValueError:\n            f = [np.float64(x) if is_float(x) else self.replace_value for x in s]\n        \n        return f\n ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Pipelines","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Features that do not need any changes => Passthrough\npass_attrs = [\"SeniorCitizen\"]\n\npass_pipeline = Pipeline([\n    ('pass', \"passthrough\")\n])\n\n\n## Features that are encoded as ordinal values\nordinal_attrs = [\"gender\", \"Partner\", \"Dependents\", \"PhoneService\", \"PaperlessBilling\"]\n\nordinal_pipeline = Pipeline([\n    ('ordinal', OrdinalEncoder()),\n    ('std_scaler', StandardScaler())\n])\n\n\n## OneHot Encoded features\nonehot_attrs = [\"MultipleLines\", \"InternetService\", \"OnlineSecurity\", \"OnlineBackup\",\n                \"DeviceProtection\", \"TechSupport\", \"StreamingTV\", \"StreamingMovies\",\n                \"Contract\", \"PaymentMethod\"]\n\nonehot_pipeline = Pipeline([\n    ('onehot', OneHotEncoder())\n])\n\n## TotalCharges is encoded as object while we need it as a float\n## hence we apply the already defined ObjectToFloatEncoder\ntotal_attrs = [\"TotalCharges\"]\n\ntotal_pipeline = Pipeline([\n    ('obj_to_float', ObjectToFloatEncoder()),\n    ('imputer', SimpleImputer(strategy=\"mean\")),\n    ('std_scaler', StandardScaler())\n])\n\n## Float features\nnum_attrs = [\"tenure\", \"MonthlyCharges\"]\n\nnum_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy=\"median\")),\n    ('std_scaler', StandardScaler())\n])\n\n## The full Pipeline\nfull_pipeline = ColumnTransformer([\n    (\"pass\", pass_pipeline, pass_attrs),\n    (\"ordinal\", ordinal_pipeline, ordinal_attrs),\n    (\"onehot\", onehot_pipeline, onehot_attrs),\n    (\"total\", total_pipeline, total_attrs),\n    (\"num\", num_pipeline, num_attrs)\n], remainder='drop')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Generating Preprocessed Sets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_processed = full_pipeline.fit_transform(df_train_features)\ndf_test_processed  = full_pipeline.fit_transform(df_test_features)\n\nprint(\"Dataset dimension transformed from {} to {}\".format(df_train_features.shape[1], df_train_processed.shape[1]))\n\nprint(\"Training set dimension: {}\".format(df_train_processed.shape))\nprint(\"Test set dimension: {}\".format(df_test_processed.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Getting Class Weights\n\nSince our dataset is unbalanced, we need to generate class weight in order to pass to our model when training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"counts = np.bincount(df_train_labels)\nprint(\n    \"Number of positive samples in training data: {} ({:.2f}% of total)\".format(\n        counts[1], 100 * float(counts[1]) / df_train_labels.shape[0]\n    )\n)\n\nclass_weights = {0: 1.0 / counts[0], 1: 1.0 / counts[1]}\nprint(class_weights)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Initialisation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.keras.backend.clear_session()\n\nnp.random.seed(42)\ntf.random.set_seed(42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## TPU Configuration","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# TPU detection  \ntry:\n  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\nexcept ValueError:\n  tpu = None\n\n# TPUStrategy for distributed training\nif tpu:\n  tf.config.experimental_connect_to_cluster(tpu)\n  tf.tpu.experimental.initialize_tpu_system(tpu)\n  strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse: # default strategy that works on CPU and single GPU\n  strategy = tf.distribute.get_strategy()\n\nprint(strategy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Definition","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(input_shape, strategy, metrics):\n    with strategy.scope():\n        inputs = Input(shape=input_shape, name=\"input\")\n\n        x = inputs\n\n        x = Dense(20, activation='relu', name=\"dense1\")(x)\n        x = Dropout(0.2, name=\"dropout1\")(x)\n        x = Dense(15, activation='relu', name=\"dense2\")(x)\n        x = Dropout(0.4, name=\"dropout2\")(x)\n        x = Dense(20, activation='relu', name=\"dense3\")(x)\n        x = Dropout(0.2, name=\"dropout3\")(x)\n        x = Dense(25, activation='relu', name=\"dense4\")(x)\n        x = Dropout(0.3, name=\"dropout4\")(x)\n\n        outputs = Dense(1, activation='sigmoid', name=\"output\")(x)\n\n        model = Model(inputs, outputs)\n\n        model.compile(optimizer=Adam(lr=0.0035157669392935006), # 0.0035157669392935006\n                                    loss='binary_crossentropy',\n                                    metrics=metrics)\n\n    return model\n\nmetrics = [\n    FalseNegatives(name=\"fn\"),\n    FalsePositives(name=\"fp\"),\n    TrueNegatives(name=\"tn\"),\n    TruePositives(name=\"tp\"),\n    Precision(name=\"precision\"),\n    Recall(name=\"recall\"),\n    AUC(name=\"auc\")\n]\n\nmodel = build_model(df_train_processed.shape[1:], strategy=strategy, metrics=metrics)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Callbacks","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"earlystopping_cb = EarlyStopping(patience=10, restore_best_weights=True)\nmdlcheckpoint_cb = ModelCheckpoint(\"model.h5\", monitor=\"val_fn\", save_best_only=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(df_train_processed, df_train_labels, epochs=100,\n                validation_split=init[\"val_split\"],\n                class_weight=class_weights if init[\"classweights\"] is True else None,\n                callbacks=[earlystopping_cb, mdlcheckpoint_cb])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Results","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Due to an issue in EarlyStopping ([Check GitHub issue here](https://github.com/tensorflow/tensorflow/issues/35634)), we are loading the best model that was saved by ModelCheckPoint","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"best_model = tf.keras.models.load_model(\"model.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(best_model.evaluate(df_test_processed, df_test_labels))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We notice the following:\n* Out of the overall 335 predicted cases that are probably going to churn, only 175 (True Positives) are actually going to churn. A 52% rate. \n* Out of 191 subscribers that will churn, the system only missed 19 (False Negatives) (a 90% detecting accuracy) \n\nIt means that our model:\n* Is able to detect the majority of the cases that will churn\n* However, when it claims a subscriber is going to churn, it is just 52%\n\n**Conclusion:** What is most important for us is to minimise those False Negatives i.e. those who will churn but we failed to predict even if along the way we incorrectly predicted that some customer is going to churn while he won't. ","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}