{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Load EDA packages\nimport pandas as pd\nimport spacy\nfrom spacy.lang.en.stop_words import STOP_WORDS\nnlp = spacy.load('en')\n\n# Build a list of stopwords to use to filter\nstopwords = list(STOP_WORDS)\n\n# Use the punctuations of string module\nimport string\npunctuations = string.punctuation\n\n# Creating a Spacy Parser\nfrom spacy.lang.en import English\nparser = English()\n\ndef spacy_tokenizer(sentence):\n    mytokens = parser(sentence)\n    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n    mytokens = [ word for word in mytokens if word not in stopwords and word not in punctuations ]\n    return mytokens\n\n# ML Packages\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.base import TransformerMixin\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import LinearSVC\n\n#Custom transformer using spaCy\nclass predictors(TransformerMixin):\n    def transform(self, X, **transform_params):\n        return [clean_text(text) for text in X]\n    def fit(self, X, y=None, **fit_params):\n        return self\n    def get_params(self, deep=True):\n        return {}\n\n# Basic function to clean the text\ndef clean_text(text):\n    return str(text).strip().lower()\n\n# Vectorization\nvectorizer = CountVectorizer(tokenizer = spacy_tokenizer, ngram_range=(1,1))\nclassifier = LinearSVC()\n\n# Using Tfidf\ntfvectorizer = TfidfVectorizer(tokenizer = spacy_tokenizer)\n\n# Splitting Data Set\nfrom sklearn.model_selection import train_test_split\n\n# Features and Labels\ndf = pd.read_csv('/kaggle/input/dataset/preprocesado_GrammarandProductReviews.csv')\nX = df['reviews.text']\nylabels = df['reviews.rating']\nX_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.2, random_state=42)\n\n# Create the  pipeline to clean, tokenize, vectorize, and classify\npipe = Pipeline([(\"cleaner\", predictors()),\n                 ('vectorizer', vectorizer),\n                 ('classifier', classifier)])\n\n# Fit our data\npipe.fit(X_train,y_train)\n\n# Predicting with a test dataset\nsample_prediction = pipe.predict(X_test)\n\n# Prediction Results\n# 1 = Positive review\n# 0 = Negative review\nfor (sample,pred) in zip(X_test,sample_prediction):\n    print(sample,\"Prediction=>\",pred)\n\n# Accuracy\nprint(\"Accuracy: \",pipe.score(X_test,y_test))\nprint(\"Accuracy: \",pipe.score(X_test,sample_prediction))\n\n# Accuracy\nprint(\"Accuracy: \",pipe.score(X_train,y_train))\n\n# Another random review\npipe.predict([\"This was a great movie\"])\n\n\n#### Using Tfid\n# Create the  pipeline to clean, tokenize, vectorize, and classify\npipe_tfid = Pipeline([(\"cleaner\", predictors()),\n                 ('vectorizer', tfvectorizer),\n                 ('classifier', classifier)])\npipe_tfid.fit(X_train,y_train)\nsample_prediction1 = pipe_tfid.predict(X_test)\nfor (sample,pred) in zip(X_test,sample_prediction1):\n    print(sample,\"Prediction=>\", pred)\n\nprint(\"Accuracy: \", pipe_tfid.score(X_test, y_test))\nprint(\"Accuracy: \", pipe_tfid.score(X_test, sample_prediction1))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}