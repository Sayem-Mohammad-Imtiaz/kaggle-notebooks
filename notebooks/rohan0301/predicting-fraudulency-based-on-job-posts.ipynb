{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Predicting Fraudulency based on Job Posts.\n1. Visualizing **Missing Values**\n2. **WORDCLOUD** on Job Titles\n3. **Splitting** Locations into Country, State & City\n4. Converting salary ranges into **Min & Max**\n5. **Label Encoding** Categorical Features\n6. Cleaning Text Features by removing **STOPWORDS** and **Lemmatizing** Words using **NLP**\n7. **OVERSAMPLING** Target Variable\n8. Scaling Data using **MINMAXSCALER**\n9. Plotting **AUC** and **Accuracies** of following Models:\n    * **Logistic Regression**\n    * **Support Vector Classifier**\n    * **MultiLayer Perceptron Classifier**\n    * **KNN Classifier**\n    * **Decision Tree Classifier**\n    * **XGBoost Classifier**\n    * **Random Forest Classifier**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# IMPORTING LIBRARIES","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random,matplotlib\nimport missingno as msno\nimport warnings\nwarnings.filterwarnings('ignore')\nimport nltk as nlp\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import roc_curve, roc_auc_score, accuracy_score\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/real-or-fake-fake-jobposting-prediction/fake_job_postings.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualizing Missing Values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"msno.matrix(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plotting Barchart for Missing Values in our dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"msno.bar(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# WORDCLOUD","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"text = \" \".join(title for title in df.title)\nprint (\"There are {} words in the combination of all available job titles.\".format(len(text)))\nstopwords=set(STOPWORDS)\nwordcloud = WordCloud(background_color=\"black\",max_font_size=100, max_words=10000,width=1600, height=800,stopwords=stopwords,colormap=matplotlib.cm.cool).generate(text)\nplt.figure(figsize=(20,10))\nplt.imshow(wordcloud,interpolation=\"bilinear\")\nplt.axis(\"off\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dropping 'job_id' as it is irrelevant to fraudulent\ndf.drop('job_id', axis=1, inplace=True)\ntext_features = ['title', 'company_profile', 'description', 'requirements', 'benefits']\ncomplex_features = ['location', 'salary_range']\nbin_features = ['telecommuting', 'has_company_logo', 'has_questions']\ncat_features = ['department', 'employment_type', 'required_experience', \n                'required_education', 'industry', 'function']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Filling Null values from Text Features with 'Unspecified'","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature_name in text_features[1:]:\n    df[feature_name].fillna('Unspecified', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Filling Null values from location with 'Unspecified' <br>\nSplitting location into 3 seperate columns: country, state, city<br>\nDropping location column<br>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Splitting Locations","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"location = df['location'].copy()\n#splitting location\nlocation_splitted = list(location.str.split(', ').values)\nfor loc_ind, loc in enumerate(location_splitted):\n    if loc is np.nan:\n        location_splitted[loc_ind] = ['Unpecified'] * 3\n    else:\n        for el_ind, el in enumerate(loc):\n            if el == '':\n                loc[el_ind] = 'Unpecified'\n                \nlocation_splitted = list(map(lambda loc: list(loc), location_splitted))\nfor loc_ind, loc in enumerate(location_splitted):\n    if len(loc) > 3:\n        location_splitted[loc_ind] = loc[:2] + [', '.join(loc[2:])]\n    if len(loc) < 3:\n        location_splitted[loc_ind] += ['Unpecified'] * 2\n        \ndata_location = pd.DataFrame(location_splitted, columns=['country', 'state', 'city'])\ncat_features += ['country', 'state', 'city']\ndf= pd.concat([df, data_location], axis=1)\ndf.drop('location', axis=1, inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Converting Salary Ranges","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Filling Null values from salary_range with '0-0'\nSplitting salary_range into 2 seperate columns: min_salary and max_salary\nDropping salary_range","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"salary_range = df.salary_range.copy()\nsalary_range.fillna('0-0', inplace=True)\nsalary_range_sep = list(salary_range.str.split('-').values)\nsalary_range_sep[5538] = ['40000', '40000']\nerror_range_inds = []\nfor range_ind, s_range in enumerate(salary_range_sep):\n    min_value, max_value = s_range\n    if not min_value.isdigit() or not max_value.isdigit():\n        error_range_inds += [range_ind]\nfor range_ind in error_range_inds:\n    salary_range_sep[range_ind] = ['0', '0']\ndata_salary_range = pd.DataFrame(np.array(salary_range_sep, dtype='int64'), \n                                 columns=['min_salary', 'max_salary'])\n\nnum_features = ['min_salary', 'max_salary']\ndf = pd.concat([df, data_salary_range], axis=1)\ndf.drop('salary_range', axis=1, inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Filling Null values from remaining features with 'Unspecified'","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.fillna('Unspecified', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All the null values are cleaned.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cleaning text using NLP","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"*clean_text* function to receive column as argument, apply regex functions, tokenizing and lemmatizing and returning the modified dataframe","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_text(data):\n    description_list = []\n    for description in data:\n        description = re.sub(\"[^a-zA-Z]\",\" \",description)\n        description = description.lower()\n        description = nlp.word_tokenize(description)\n        description = [word for word in description if not word in stopwords]\n        lemma = nlp.WordNetLemmatizer()\n        description = [lemma.lemmatize(word) for word in description ]\n        description =\" \".join(description)\n        description_list.append(description)\n    return description_list","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Applying this function on text variables","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['description_cleaned']= clean_text(df.description)\ndf['company_profile_cleaned']=clean_text(df.company_profile)\ndf['requirements_cleaned']= clean_text(df.requirements)\ndf['benefits_cleaned']=clean_text(df.benefits)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Calculating length of each text feature's entries and saving them into feature_length","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['title_length']=df['title'].astype(str).str.split(' ').apply(len)\ndf['company_profile_length']=df['company_profile_cleaned'].astype(str).str.split(' ').apply(len)\ndf['benefits_length']=df['benefits_cleaned'].astype(str).str.split(' ').apply(len)\ndf['description_length']=df['description_cleaned'].astype(str).str.split(' ').apply(len)\ndf['requirements_length']=df['requirements_cleaned'].astype(str).str.split(' ').apply(len)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Label Encoding","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"label=LabelEncoder()\ndf['employment_type']=label.fit_transform(df['employment_type'])\ndf['required_experience']=label.fit_transform(df['required_experience'])\ndf['required_education']=label.fit_transform(df['required_education'])\ndf['industry']=label.fit_transform(df['industry'])\ndf['function']=label.fit_transform(df['function'])\ndf['country']=label.fit_transform(df['country'])\ndf['state']=label.fit_transform(df['state'])\ndf['city']=label.fit_transform(df['city'])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plotting Target Variable","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 5))\nax = sns.countplot(df.fraudulent)\nplt.title('The distribution of the target feature (fraudulent)')\nfor p in ax.patches:\n    ax.annotate(p.get_height(), (p.get_x()+0.33, p.get_height()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Oversampling Target Variable","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_1f = df[df.fraudulent == 1]\noriginal_data = df.copy()\ndf = pd.concat([df] + [data_1f] * 7, axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 5))\nax = sns.countplot(df.fraudulent)\nplt.title('The distribution of the target feature (fraudulent)')\nfor p in ax.patches:\n    ax.annotate(p.get_height(), (p.get_x()+0.33, p.get_height()))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Preparing X and y variables by removing unwanted features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X=check=df.drop(['title','department','company_profile','description','requirements','benefits','description_cleaned','company_profile_cleaned','requirements_cleaned','benefits_cleaned','fraudulent'],axis=1)\ny=df.fraudulent","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SCALING DATA with MINMAXSCALER","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler=MinMaxScaler()\nX=scaler.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"X","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# MODELING\n**1. LOGISTIC REGRESSION** <br>\n**2. XGBOOST**<br>\n**3. Logistic Regression**<br>\n**4. Support Vector Classifier**<br>\n**5. MultiLayer Perceptron Classifier**<br>\n**6. KNN Classifier**<br>\n**7. Decision Tree Classifier**<br>\n**8. XGBoost Classifier**<br>\n**9. Random Forest Classifier**<br>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test , y_train , y_test = train_test_split(X,y,test_size=0.2,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating a function 'roc_plotter' for passing model object, model name and plotting its roc auc curve with accuracy","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def roc_plotter(model_object,model_name):     \n        model_object.fit(X_train, y_train)\n        y_pred=model_object.predict(X_test)\n        ns_probs = [0 for _ in range(len(y_test))]\n\n        # predict probabilities\n        model_probs = model_object.predict_proba(X_test)[:, 1]\n\n        # calculate scores\n        ns_auc = roc_auc_score(y_test, ns_probs)\n        model_auc = roc_auc_score(y_test, model_probs)\n    \n        fig = plt.figure(figsize=(12,5))\n\n        # calculate roc curves\n        ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n        lr_fpr, lr_tpr, _ = roc_curve(y_test, model_probs)\n        # plot the roc curve for the model\n        plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n        plt.plot(lr_fpr, lr_tpr, marker='.', label=model_name)\n\n        # axis labels\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        # show the legend\n        plt.legend()\n        # show the plot\n        score= accuracy_score(y_test, y_pred)\n        txt1='ROC AUC = {}'.format(round(model_auc,2))\n        txt2='Accuracy = {}%'.format(round(score*100,2))\n        \n        plt.text(0.3,0.2,model_name,fontsize=25, fontweight='bold',color='red')\n        plt.text(0.3,0.1,txt1,bbox={'facecolor': 'orange','pad': 10},fontsize=15)\n        plt.text(0.5,0.1,txt2,bbox={'facecolor': 'red', 'pad': 10},fontsize=15,color='white')\n        plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lrmodel=LogisticRegression()\nroc_plotter(lrmodel,'Logistic Regression')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Support Vector Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"svmmodel=SVC(probability=True)\nroc_plotter(svmmodel,'Support Vector Classifier')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MultiLayer Perceptron Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"nnmodel=MLPClassifier()\nroc_plotter(nnmodel,'MultiLayer Perceptron Classifier')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# KNN Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"knnmodel=KNeighborsClassifier()\nroc_plotter(knnmodel,'KNN Classifier')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decision Tree Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dtmodel=DecisionTreeClassifier()\nroc_plotter(dtmodel,'Decision Tree Classifier')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# XGBoost Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb = XGBClassifier()\nroc_plotter(xgb,'XGBoost Classifier')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rfmodel=RandomForestClassifier()\nroc_plotter(rfmodel,'Random Forest Classifier')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models=['Logistic Regression','Support Vector Classifier','MultiLayer Perceptron Classifier','KNN Classifier','Decision Tree Classifier','XGBoost Classifier','Random Forest Classifier']\naccuracies=[80.79,87.76,93.3,96.1,98.43,99.25,99.83]\nplt.figure(figsize=(18,10))\nplt.scatter(x=models, y=accuracies,s=200)\nplt.plot(models,accuracies)\nfor x,y in zip(models,accuracies):\n    label = \"{:.2f}%\".format(y)\n    plt.annotate(label, (x,y), textcoords=\"offset points\", xytext=(0,10), ha='center',fontsize=20)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}