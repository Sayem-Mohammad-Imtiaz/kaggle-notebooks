{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport missingno as msno\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import tree\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost as xgb\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import classification_report\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('../input/heart-disease-prediction-using-logistic-regression/framingham.csv'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Fazendo o carregamento do Dataset doenças cardíacas\ndados = pd.read_csv('../input/heart-disease-prediction-using-logistic-regression/framingham.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Verificando quantidade de instâncias e variáveis\ndados.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Mostrando os primeiros 05 registros\ndados.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Mostrando graficamente a ocorrência de dados missing \nmsno.matrix(dados)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Quantificando a ocorrência de dados missing\ndados.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Avaliando a distribuição de ocorrências de casos cardíacos no Dataset\ndados['TenYearCHD'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotando a ocorência de doenças cardíacas verificando uma maior prevalência de ocorrência negativa\nplt.hist(dados['TenYearCHD'], bins=2)\nplt.title(\"Contagem de casos de cardiologia\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotando a correlação entre as variáveis\ncorrelation = dados.corr(method='pearson')\ncorrelation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotando a matriz da correlação\nplt.matshow(dados.corr())\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Usando um novo estilo para apresentar a matriz de correlação, nesta representação os valores em laranja representam as variáveis com \n#maior correlação positiva entre as variáveis indenpendentes\n\n#Pode-se verificar também que as variáveis age,prevalentHyp,sysBP,diaBP,glucose são as que apresentar mais correlação com a variável target TenYearCHD\n\n#Sendo possivelmente estas variáveis as que estão relacionadas aos casos de problemas cardíacos, tomando como base os dados históricos do dataset\ncorr = dados.corr()\ncorr.style.background_gradient(cmap='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Montando um dataset com os dados com maior correlação\nanalise = dados[[\"age\",\"currentSmoker\",\"prevalentHyp\",\"sysBP\",\"diaBP\",\"glucose\", \"TenYearCHD\"]]\nanalise","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Verificando a ocorrência de dados missing\nanalise.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calculando índice glicêmico médio do dataset e substituindo os dados missing pela média\nIGM = dados[\"glucose\"].mean()\nIGM\nanalise.update(analise['glucose'].fillna(IGM))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Depois de tratato o dados de glucose considerando a média nos valores faltantes, nosso dataset está pronto\nanalise.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Analisando a estatística dos dados\nanalise.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dividindo o dataset em dados de entrada (variáveis preditoras) e dados de saída (variável target)\n\nentradas = analise[['age','currentSmoker','prevalentHyp','sysBP','diaBP','glucose']]\nsaidas = analise[[\"TenYearCHD\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Verificando as estatísticas dos dados de entrada\nentradas.describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Normalizando os dados de entrada já que este processo é importante para os classificadores\nentradas = preprocessing.scale(entradas)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Apresetando as variáveis preditoras normalizadas\nentradas","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Realizando o reshape dos dados e separando em 80% para treinamento e 20% para teste\n#analise, target = np.arange(10).reshape((5, 2)), range(5)\n\ndata_train, data_test, target_train, target_test = train_test_split(entradas,saidas, test_size=0.20, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Instanciando e treinando o modelo de arvore \nclf = tree.DecisionTreeClassifier() # instância do classificador\nclf.fit(data_train, target_train) # fit encontra padrões nos dados para o argoritmo de árvore de decisão \ncRF = RandomForestClassifier() # instância do classificador\ncRF.fit(data_train, target_train)  #fit encontra padrões nos dados para o argoritmo Randon Forest\ncXGB = xgb.XGBClassifier() # instância do classificador\ncXGB.fit(data_train, target_train) #fit encontra padrões nos dados para o argoritmo xgBoost","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Realizando a predição dos dados de teste como o modelo já treinado \nprevisao = clf.predict(data_test)\nprevisao\nprevisaoRF = cRF.predict(data_test)\nprevisaoRF\nprevisaoXGB = cXGB.predict(data_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Mostrando a árvore de decisão\ntree.plot_tree(clf) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Avaliando a acurácia modelo de árvore de decisão\nfrom sklearn.metrics import accuracy_score\naccuracy_score(target_test, previsao)* 100\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Avaliando o modelo de RandonForest\naccuracy_score(target_test, previsaoRF)* 100\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Avaliando a acurácia do Algoritmo XGBOOST\naccuracy_score(target_test, previsaoXGB)* 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# O modelo apresenta desbalanceamento nos dados de saída, desta forma a acurácia não é a melhor métrica de avaliação\n# A matriz de confusão pode ser uma saída.\ndados['TenYearCHD'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Imprimindo métricas do algoritmo de árvore de decisão\nfrom sklearn.metrics import confusion_matrix\nprint ('Accuracy:', accuracy_score(target_test, previsao))\nprint ('F1 score:', f1_score(target_test, previsao,average='weighted'))\nprint ('Recall:', recall_score(target_test, previsao,\n                              average='weighted'))\nprint ('Precision:', precision_score(target_test, previsao,\n                                    average='weighted'))\nprint ('\\n clasification report:\\n', classification_report(target_test, previsao))\nprint ('\\n confussion matrix:\\n',confusion_matrix(target_test, previsao))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Imprimindo métricas do algoritmo Randon Forest\nfrom sklearn.metrics import confusion_matrix\nprint ('Accuracy:', accuracy_score(target_test, previsaoRF))\nprint ('F1 score:', f1_score(target_test, previsaoRF,average='weighted'))\nprint ('Recall:', recall_score(target_test, previsaoRF,\n                              average='weighted'))\nprint ('Precision:', precision_score(target_test, previsaoRF,\n                                    average='weighted'))\nprint ('\\n clasification report:\\n', classification_report(target_test, previsaoRF))\nprint ('\\n confussion matrix:\\n',confusion_matrix(target_test, previsaoRF))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Imprimindo métricas do algoritmo do algoritmo XGBOOST\nfrom sklearn.metrics import confusion_matrix\nprint ('Accuracy:', accuracy_score(target_test, previsaoXGB))\nprint ('F1 score:', f1_score(target_test, previsaoXGB,average='weighted'))\nprint ('Recall:', recall_score(target_test, previsaoXGB,\n                              average='weighted'))\nprint ('Precision:', precision_score(target_test, previsaoXGB,\n                                    average='weighted'))\nprint ('\\n clasification report:\\n', classification_report(target_test, previsaoXGB))\nprint ('\\n confussion matrix:\\n',confusion_matrix(target_test, previsaoXGB))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Neste caso o melhor resultado foi alcançado como algoritmo XGBOOST, lembrando que para este experimento foram utitlizados todos os algoritmos \n#com hiperparâmetros default.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Percebe-se que o resultado sofre impacto deste desbalanceamento o que caracterizamos como víes nos dados. Podemos solucinar \n#utilizando os métodos class weight, undersampling, oversamoling e SMOTE, no entanto a técnica de balanceamento será realizada em outro artigo.","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}