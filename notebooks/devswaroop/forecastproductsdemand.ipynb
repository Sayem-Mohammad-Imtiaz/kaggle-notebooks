{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Import \n** ","metadata":{}},{"cell_type":"code","source":"import os\nfor dirname,_,filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print (os.path.join(dirname,filename))","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:43:21.580613Z","iopub.execute_input":"2021-05-30T12:43:21.580928Z","iopub.status.idle":"2021-05-30T12:43:21.590844Z","shell.execute_reply.started":"2021-05-30T12:43:21.580901Z","shell.execute_reply":"2021-05-30T12:43:21.589822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd # Data handling and managing\nimport numpy as np  # Handiling linear Algera\nimport seaborn as sn\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\ndf = pd.read_csv('../input/productdemandforecasting/Historical Product Demand.csv', parse_dates=['Date'])\ndf.head(100) # Getting the first 100 rows to view the records\n#df.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:43:21.592805Z","iopub.execute_input":"2021-05-30T12:43:21.593337Z","iopub.status.idle":"2021-05-30T12:43:22.417082Z","shell.execute_reply.started":"2021-05-30T12:43:21.593296Z","shell.execute_reply":"2021-05-30T12:43:22.415866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"df.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:43:22.418536Z","iopub.execute_input":"2021-05-30T12:43:22.418905Z","iopub.status.idle":"2021-05-30T12:43:22.430295Z","shell.execute_reply.started":"2021-05-30T12:43:22.418866Z","shell.execute_reply":"2021-05-30T12:43:22.429427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for the columns which got has the NaN values\nprint(df.isnull().any().sum(), ' / ', len(df.columns))\n# Check any number of data points with NaN\nprint(df.isnull().any(axis=1).sum(),'/', len(df))\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:43:22.431634Z","iopub.execute_input":"2021-05-30T12:43:22.432215Z","iopub.status.idle":"2021-05-30T12:43:22.73235Z","shell.execute_reply.started":"2021-05-30T12:43:22.432174Z","shell.execute_reply":"2021-05-30T12:43:22.731192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dropna(axis=0, inplace=True) #Remove all the rows with null values\ndf.reset_index(drop=True)\ndf.sort_values('Date')[1:50]","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:43:22.734506Z","iopub.execute_input":"2021-05-30T12:43:22.734775Z","iopub.status.idle":"2021-05-30T12:43:23.154821Z","shell.execute_reply.started":"2021-05-30T12:43:22.734747Z","shell.execute_reply":"2021-05-30T12:43:23.153819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df.dropna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:43:23.156635Z","iopub.execute_input":"2021-05-30T12:43:23.15701Z","iopub.status.idle":"2021-05-30T12:43:23.160854Z","shell.execute_reply.started":"2021-05-30T12:43:23.15697Z","shell.execute_reply":"2021-05-30T12:43:23.159953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Order_Demand']=df['Order_Demand'].str.replace('(',\"\")\ndf['Order_Demand']=df['Order_Demand'].str.replace(')',\"\")\ndf.head(100)\n#Since the \"()\" has been removed , Now i Will change the data type.\n\ndf['Order_Demand'] = df['Order_Demand'].astype('int64')","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:43:23.162499Z","iopub.execute_input":"2021-05-30T12:43:23.162927Z","iopub.status.idle":"2021-05-30T12:43:23.925975Z","shell.execute_reply.started":"2021-05-30T12:43:23.16289Z","shell.execute_reply":"2021-05-30T12:43:23.925031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.sort_values('Date')[10:20]","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:43:23.927482Z","iopub.execute_input":"2021-05-30T12:43:23.927922Z","iopub.status.idle":"2021-05-30T12:43:24.140944Z","shell.execute_reply.started":"2021-05-30T12:43:23.927883Z","shell.execute_reply":"2021-05-30T12:43:24.140058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Get the Hieghest and lowest dates in the dataset.\ndf['Date'].min() , df['Date'].max()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:43:24.142362Z","iopub.execute_input":"2021-05-30T12:43:24.142724Z","iopub.status.idle":"2021-05-30T12:43:24.15642Z","shell.execute_reply.started":"2021-05-30T12:43:24.142694Z","shell.execute_reply":"2021-05-30T12:43:24.155097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.stats import norm, skew #Import Norm and skew for some statistics\nfrom scipy import stats #Import stats\nimport statsmodels.api as sm #for decomposing the trends, seasonality etc.\n\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX #for the Seasonal Forecast\n\n\n#Lets check the ditribution of the target variable (Order_Demand)\nfrom matplotlib import rcParams\n# figure size in inches\nrcParams['figure.figsize'] = 10,5\n\nsn.distplot(df['Order_Demand'],fit=norm)\n\n#Get the QQ-plot\nfig = plt.figure()\nres = stats.probplot(df['Order_Demand'], plot=plt)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:43:24.157865Z","iopub.execute_input":"2021-05-30T12:43:24.158175Z","iopub.status.idle":"2021-05-30T12:43:30.344851Z","shell.execute_reply.started":"2021-05-30T12:43:24.158139Z","shell.execute_reply":"2021-05-30T12:43:30.344068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Warehouse'].value_counts().sort_values(ascending=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:43:30.345878Z","iopub.execute_input":"2021-05-30T12:43:30.346117Z","iopub.status.idle":"2021-05-30T12:43:30.438742Z","shell.execute_reply.started":"2021-05-30T12:43:30.346092Z","shell.execute_reply":"2021-05-30T12:43:30.437818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Now I will get the amount of orders shipped by each warehouse.\ndf.groupby('Warehouse').sum().sort_values('Order_Demand', ascending = False)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:43:30.439843Z","iopub.execute_input":"2021-05-30T12:43:30.440134Z","iopub.status.idle":"2021-05-30T12:43:30.534786Z","shell.execute_reply.started":"2021-05-30T12:43:30.440106Z","shell.execute_reply":"2021-05-30T12:43:30.53381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Date'] = pd.to_datetime(df['Date'])\ndf['Year'] = df['Date'].dt.year","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:43:30.536043Z","iopub.execute_input":"2021-05-30T12:43:30.536286Z","iopub.status.idle":"2021-05-30T12:43:30.6709Z","shell.execute_reply.started":"2021-05-30T12:43:30.536262Z","shell.execute_reply":"2021-05-30T12:43:30.669803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2 = df[['Year', 'Warehouse', 'Order_Demand']].groupby(['Year', 'Warehouse'], as_index=False).count()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:43:30.672097Z","iopub.execute_input":"2021-05-30T12:43:30.672363Z","iopub.status.idle":"2021-05-30T12:43:30.783549Z","shell.execute_reply.started":"2021-05-30T12:43:30.672337Z","shell.execute_reply":"2021-05-30T12:43:30.782751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2  = df2.pivot(index='Year', columns='Warehouse', values='Order_Demand')","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:43:30.784683Z","iopub.execute_input":"2021-05-30T12:43:30.784932Z","iopub.status.idle":"2021-05-30T12:43:30.792498Z","shell.execute_reply.started":"2021-05-30T12:43:30.784908Z","shell.execute_reply":"2021-05-30T12:43:30.79149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.index = df2.index.map(int) # let's change the index values of df2 to type integer for plotting\ndf2.plot(kind='area', stacked=False, figsize=(20, 10))\n\nplt.title('Order_Demand Trend')\nplt.ylabel('Number of Order_Demand')\nplt.xlabel('Years')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:43:30.793556Z","iopub.execute_input":"2021-05-30T12:43:30.793818Z","iopub.status.idle":"2021-05-30T12:43:31.044125Z","shell.execute_reply.started":"2021-05-30T12:43:30.793794Z","shell.execute_reply":"2021-05-30T12:43:31.043148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2['Total'] = df2.sum(axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:44:25.713635Z","iopub.execute_input":"2021-05-30T12:44:25.713946Z","iopub.status.idle":"2021-05-30T12:44:25.719344Z","shell.execute_reply.started":"2021-05-30T12:44:25.71392Z","shell.execute_reply":"2021-05-30T12:44:25.718579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"colors_list = ['gold', 'yellowgreen', 'lightcoral', 'lightskyblue', 'lightgreen', 'pink', 'red']\nexplode_list = [0.2, 0, 0, 0, 0, 0, 0.2] # ratio for each year with which to offset each wedge.\n\ndf2['Total'].plot(kind='pie',\n                            figsize=(15, 6),\n                            autopct='%1.1f%%', \n                            startangle=90,    \n                            shadow=True,       \n                            labels=None,         # turn off labels on pie chart\n                            pctdistance=1.12,    # the ratio between the center of each pie slice and the start of the text generated by autopct \n                            colors=colors_list,  # add custom colors\n                            explode=explode_list \n                            )\n\n# scale the title up by 12% to match pctdistance\nplt.title('Order_Demand Trend [2011 - 2017]', y=1.12) \n\nplt.axis('equal') \n\n# add legend\nplt.legend(labels=df2.index, loc='upper left') \n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:44:29.272377Z","iopub.execute_input":"2021-05-30T12:44:29.272744Z","iopub.status.idle":"2021-05-30T12:44:29.456263Z","shell.execute_reply.started":"2021-05-30T12:44:29.272709Z","shell.execute_reply":"2021-05-30T12:44:29.455577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rcParams['figure.figsize']=20,5 #Figure Size in Inches for Plotting\nf, axes = plt.subplots(1,2)\nnormalDW=sn.boxplot(df['Warehouse'],df['Order_Demand'],ax=axes[0]) #Create a variable for Regular Data for WH and OD \n\nlogWH=sn.boxplot(df['Warehouse'],np.log1p(df['Order_Demand']),ax=axes[1]) #Craete a Variable with Log Transformation\n","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:43:31.961448Z","iopub.execute_input":"2021-05-30T12:43:31.961798Z","iopub.status.idle":"2021-05-30T12:43:33.351385Z","shell.execute_reply.started":"2021-05-30T12:43:31.961762Z","shell.execute_reply":"2021-05-30T12:43:33.35052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=df.groupby('Date')['Order_Demand'].sum().reset_index()\n#Step-02: Indexing the Date Column as for further procssing.\ndf = df.set_index('Date')\ndf.index #Lets check the index\n#Step-03:#Averages daily sales value for the month, and we are using the start of each month as the timestamp.\nmonthly_avg_sales = df['Order_Demand'].resample('MS').mean()\n#In case there are Null values, they can be imputed using bfill.\nmonthly_avg_sales = monthly_avg_sales.fillna(monthly_avg_sales.bfill())\n#Visualizing time series.\n\nmonthly_avg_sales.plot(figsize=(20,10))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:43:33.352716Z","iopub.execute_input":"2021-05-30T12:43:33.352971Z","iopub.status.idle":"2021-05-30T12:43:33.603398Z","shell.execute_reply.started":"2021-05-30T12:43:33.352946Z","shell.execute_reply":"2021-05-30T12:43:33.602416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Displaying the trends with their seasons**","metadata":{}},{"cell_type":"code","source":"#Using Time Series for Decomposition. \nfrom pylab import rcParams\nimport statsmodels.api as sm\nrcParams['figure.figsize'] = 20, 10\ndecomposition = sm.tsa.seasonal_decompose(monthly_avg_sales, model='additive')\nfig = decomposition.plot()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:43:33.604571Z","iopub.execute_input":"2021-05-30T12:43:33.604814Z","iopub.status.idle":"2021-05-30T12:43:34.17982Z","shell.execute_reply.started":"2021-05-30T12:43:33.604791Z","shell.execute_reply":"2021-05-30T12:43:34.179136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:43:34.181228Z","iopub.execute_input":"2021-05-30T12:43:34.181615Z","iopub.status.idle":"2021-05-30T12:43:34.189735Z","shell.execute_reply.started":"2021-05-30T12:43:34.181586Z","shell.execute_reply":"2021-05-30T12:43:34.188846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:43:34.191041Z","iopub.execute_input":"2021-05-30T12:43:34.191299Z","iopub.status.idle":"2021-05-30T12:43:34.206723Z","shell.execute_reply.started":"2021-05-30T12:43:34.191275Z","shell.execute_reply":"2021-05-30T12:43:34.205795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Creating the ARIMA Model","metadata":{}},{"cell_type":"code","source":"import itertools\np = d = q = range(0, 2)\npdq = list(itertools.product(p, d, q))\nseasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]\n#print('Examples of parameter combinations for Seasonal ARIMA...')\nprint('SARIMAX1: {} x {}'.format(pdq[1], seasonal_pdq[1]))\nprint('SARIMAX2: {} x {}'.format(pdq[1], seasonal_pdq[2]))\nprint('SARIMAX3: {} x {}'.format(pdq[2], seasonal_pdq[3]))\nprint('SARIMAX4: {} x {}'.format(pdq[2], seasonal_pdq[4]))\n\n#STEP-02:\n#Get the best params for the data. Choose the lowest AIC.\n\n# The Akaike information criterion (AIC) is an estimator of the relative quality of statistical models for a \n# given set of data. \n# AIC measures how well a model fits the data while taking into account the overall complexity of the model.\n# Large AIC: Model fits very well using a lot of features.\n# Small AIC: Model fits similar fit but using lesser features. \n# Hence LOWER THE AIC, the better it is.\n\n#The code tests the given params using sarimax and outputs the AIC scores.\n\nfor param in pdq:\n    for param_seasonal in seasonal_pdq:\n        try:\n            mod = sm.tsa.statespace.SARIMAX(monthly_avg_sales,\n                                            order=param,\n                                            seasonal_order=param_seasonal,enforce_stationarity=False,\n                                            enforce_invertibility=False)\n            results = mod.fit()\n            print('SARIMA{}x{}12 - AIC:{}'.format(param, param_seasonal, results.aic))\n        except:\n            continue","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:43:34.208186Z","iopub.execute_input":"2021-05-30T12:43:34.208488Z","iopub.status.idle":"2021-05-30T12:43:38.667698Z","shell.execute_reply.started":"2021-05-30T12:43:34.208448Z","shell.execute_reply":"2021-05-30T12:43:38.666686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statsmodels.tsa.statespace.sarimax import SARIMAX\nmod = sm.tsa.statespace.SARIMAX(monthly_avg_sales,\n                                order=(1, 1, 1),\n                                seasonal_order=(0, 1, 1, 12),\n                                enforce_stationarity=False,\n                                enforce_invertibility=False)\nresults = mod.fit()\nprint(results.summary().tables[1])","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:43:38.670605Z","iopub.execute_input":"2021-05-30T12:43:38.670874Z","iopub.status.idle":"2021-05-30T12:43:38.964321Z","shell.execute_reply.started":"2021-05-30T12:43:38.670849Z","shell.execute_reply":"2021-05-30T12:43:38.963587Z"},"trusted":true},"execution_count":null,"outputs":[]}]}