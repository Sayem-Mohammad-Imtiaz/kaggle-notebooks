{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"9472b6bd-980b-ab0c-8302-1f0a9349d37f"},"source":"## Let's look at the differences between the words used in listings for Airbnb locations in different Boston neighborhoods"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ec58b503-7d47-4382-56f5-3d7bf396662f"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.pipeline import Pipeline\nfrom nltk import wordpunct_tokenize          \nfrom nltk.stem import WordNetLemmatizer"},{"cell_type":"markdown","metadata":{"_cell_guid":"c4f2e60b-c15a-e909-b8d4-40b863cd05b0"},"source":"### Function and class definitions"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b780b956-b8be-b307-53dc-e2a1ae890967"},"outputs":[],"source":"class LemmaTokenizer(object):\n    \"\"\"Custom tokenizer class that stems tokens\"\"\"\n    def __init__(self):\n        self.wnl = WordNetLemmatizer()\n    def __call__(self, doc):\n        return [self.wnl.lemmatize(t) for t in wordpunct_tokenize(doc) if len(t.strip()) > 1]\n    \ndef show_topn(classifier, vectorizer, categories, n):\n    \"\"\"Returns the top n features that characterize each category\"\"\"\n    feature_names = np.asarray(vectorizer.get_feature_names())\n    for i, category in enumerate(categories):\n        topn = np.argsort(classifier.coef_[i])[-n:] #argsort sorts in asc order\n        print('{}: {}'.format(category, \", \".join(feature_names[topn])))"},{"cell_type":"markdown","metadata":{"_cell_guid":"1fe0fb70-7495-8274-5193-39f2fa938ec8"},"source":"### Let's get on with exploring"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e4381162-6f24-7167-5603-27222a8d4218"},"outputs":[],"source":"# read in a few columns from the data and show the top of the resulting dataframe\ndf = pd.read_csv('../input/listings.csv', usecols = ['id', 'name', 'space', 'description', 'neighborhood_overview', 'neighbourhood_cleansed'])\n\ndf.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7135bdb1-8795-e589-615e-0f9fcc8d2443"},"outputs":[],"source":"# let's combine the name, space, description, and neighborhood_overview into a new column\ndf['combined_description'] = df.apply(lambda x: '{} {} {} {}'.format(x['name'], x['space'], x['description'], x['neighborhood_overview']), axis=1)"},{"cell_type":"markdown","metadata":{"_cell_guid":"8c6fbf85-8685-93cb-06f2-0c8b4203d409"},"source":"**How many listings are there for each neighborhood?**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a738d6c3-cb40-0d80-951f-75ce0baee4e6"},"outputs":[],"source":"df.groupby(by='neighbourhood_cleansed').count()[['id']].sort_values(by='id', ascending=False)"},{"cell_type":"markdown","metadata":{"_cell_guid":"1a5786e0-ad0e-0a18-5ef0-b465136f137e"},"source":"**That's not a lot, but let's still see what happens if we build a model**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"46c9fbd8-f6a7-72b3-a9d7-5d89be8a0dab"},"outputs":[],"source":"pipeline = Pipeline([('tfidf', TfidfVectorizer(ngram_range=(1,2), stop_words='english', tokenizer=LemmaTokenizer())),\n                     ('clf', SGDClassifier(loss='hinge', penalty='l2',\n                                           alpha=1e-3, n_iter=5, random_state=42)),\n])\n\n\nle = LabelEncoder()\nnew_target = le.fit_transform(df['neighbourhood_cleansed'])\nmodel = pipeline.fit(df['combined_description'], new_target)"},{"cell_type":"markdown","metadata":{"_cell_guid":"9a67fa70-f02c-0122-06cf-df653fd2ad42"},"source":"**... And show the top 5 phrases that characterize each neighborhood**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e48ad4e3-bc9d-1323-f672-1f730e2634f6"},"outputs":[],"source":"show_topn(model.named_steps['clf'], model.named_steps['tfidf'], le.inverse_transform(model.named_steps['clf'].classes_), 5)"},{"cell_type":"markdown","metadata":{"_cell_guid":"9f158ffc-15e9-91b8-b255-d977b995219a"},"source":"### How cool is that!?"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"24e3f51f-a2c8-12a7-3435-8cfb2d08d185"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}