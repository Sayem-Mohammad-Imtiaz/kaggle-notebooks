{"cells":[{"metadata":{},"cell_type":"markdown","source":"# import"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport ast\nimport re\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\n%matplotlib inline\n\n# Загружаем специальный удобный инструмент для разделения датасета:\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\nRANDOM_SEED = 42","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# зафиксируем версию пакетов, чтобы эксперименты были воспроизводимы:\n!pip freeze > requirements.txt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DATA"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"DATA_DIR = '/kaggle/input/sf-dst-restaurant-rating/'\ndf_train = pd.read_csv(DATA_DIR+'/main_task.csv')\ndf_test = pd.read_csv(DATA_DIR+'kaggle_task.csv')\nsample_submission = pd.read_csv(DATA_DIR+'/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Загружаем данные о городском населении стран"},{"metadata":{"trusted":true},"cell_type":"code","source":"population_data = pd.read_csv('/kaggle/input/population-by-country-2020/population_by_country_2020.csv')\npopulation_data['urban_pct'] = population_data['Urban Pop %'].str.strip('%').str.replace('N.A.','100').fillna(100).apply(lambda p: float(p) / 100)\npopulation_data['urban_population'] = round(population_data['Population (2020)'] * population_data['urban_pct'])\npopulation_data = population_data[['Country (or dependency)', 'urban_population']]\npopulation_data.columns = ['Country', 'urban_population']\npopulation_data.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ВАЖНО! дря корректной обработки признаков объединяем трейн и тест в один датасет\ndf_train['sample'] = 1 # помечаем где у нас трейн\ndf_test['sample'] = 0 # помечаем где у нас тест\ndf_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n\ndata = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Подробнее по признакам:\n* City: Город \n* Cuisine Style: Кухня\n* Ranking: Ранг ресторана относительно других ресторанов в этом городе\n* Price Range: Цены в ресторане в 3 категориях\n* Number of Reviews: Количество отзывов\n* Reviews: 2 последних отзыва и даты этих отзывов\n* URL_TA: страница ресторана на 'www.tripadvisor.com' \n* ID_TA: ID ресторана в TripAdvisor\n* Rating: Рейтинг ресторана"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Заполнение NA значений в колонках"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.fillna({'Reviews': '[]','Cuisine Style': \"[]\", 'Number of Reviews': 0, 'Price Range': 'unknown'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Посмотрим какие признаки у нас могут быть категориальными."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.nunique(dropna=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"К категориальным признакам отнесем City и Cuisine Style."},{"metadata":{},"cell_type":"markdown","source":"Смотрим в каких городах были отзывы:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['City'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Исправляем Oporto на Porto"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['City'] = data.City.str.replace('Oporto', 'Porto')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Добавляем методы трансформации и порождения признаков:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime\nfrom ast import literal_eval\nliteral_string_pattern = re.compile(\"^([A-Za-z &])*$\")\ncurrent_time = datetime.now()\ndef parse_reviews(c):\n    return literal_eval(c.replace('nan',\"''\"))\ndef parse_cusine(c):\n    try:        \n        return literal_eval(c.replace(\"NaN\", \"[]\"))\n    except Exception:\n        if literal_string_pattern.match(c):\n            return \"['{}']\".format(c)\n        else:\n            raise Exception('Failed to parse cusine: ' + c)\n            \ndef review_dates(reviews):        \n    if len(reviews) > 1:\n        return list(map(lambda d: datetime.strptime(d,'%m/%d/%Y'), reviews[1]))\n    else:\n        return []\n\ndef diff_in_days(d):\n    if len(d) > 1:\n        return abs((d[1] - d[0]).days)\n    else:\n        return -1\n    \ndef review_freshness(rd):\n    if len(rd) > 1:\n        return min(list(map(lambda d: abs((current_time - d).days), rd)))\n    else:\n        return -1\n    \ndef price_level(p):\n    if p == '$':\n        return 1\n    elif p == '$$ - $$$':\n        return 2\n    elif p == '$$$$':\n        return 3\n    else:\n        return -1\ndef extract_name(row):\n    url = row['URL_TA']\n    reviews = 'Reviews'\n    start = url.find(reviews) + len(reviews) + 1\n    return url[start:].split('-')[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Преобразуем строчные признаки Cuisine Style и Review Dates в списки, применим lable encoding, добавим новые признаки:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Reviews'] = data.Reviews.apply(parse_reviews)\ndata['Cuisine Style'] = data['Cuisine Style'].apply(parse_cusine)\ndata['cusine_count'] = data['Cuisine Style'].apply(lambda c: len(c))\ndata['price_level'] = data['Price Range'].apply(price_level)\ndata['Review Dates'] = data.Reviews.apply(review_dates)\ndata['days_between_reviews'] = data['Review Dates'].apply(diff_in_days)\ndata['review_freshness'] = data['Review Dates'].apply(review_freshness)\nrestraunts_per_city = data.groupby('City').ID_TA.count().reset_index()\nrestraunts_per_city.columns = ['City', 'restraunts_per_city']\ndata = data.merge(restraunts_per_city, on='City')\ndata['restaurant_name'] = data.apply(extract_name, axis=1)\nrestaurants_in_chain = data[['restaurant_name','ID_TA']].drop_duplicates()['restaurant_name'].value_counts().reset_index()\nrestaurants_in_chain.columns = ['restaurant_name', 'restaurants_in_chain']\ndata = data.merge(restaurants_in_chain, on=['restaurant_name'])\ndata['is_chain_restaurant'] = data['restaurants_in_chain'].apply(lambda r: 1 if r > 1 else 0)\ndata.drop(columns=['restaurants_in_chain'], inplace=True)\nrestaurants_in_chain_per_city = data[['restaurant_name','ID_TA', 'City']].drop_duplicates().groupby(['City', 'restaurant_name']).ID_TA.count().reset_index()\nrestaurants_in_chain_per_city.columns = ['City', 'restaurant_name', 'restaurants_in_chain']\ndata = data.merge(restaurants_in_chain_per_city, on=['City', 'restaurant_name'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"cusine_count - кол-во кухонь, представленных в ресторане \n\ndays_between_reviews - кол-во дней между опубликованными отзывами\n\nreview_freshness - колво дней от самого свежего отзыва до сегодня\n\nrestraunts_per_city - общее кол-во ресторанов в городе\n\nrestaurants_in_chain - кол-во точек ресторанной сети в городе\n\nis_chain_restaurant - является ли ресторан сетевым"},{"metadata":{},"cell_type":"markdown","source":"Посмотрим на распределение признака Number of Reviews:"},{"metadata":{"trusted":true},"cell_type":"code","source":"_, ax = plt.subplots(figsize=(20,3))\nax.set_yscale('log')\ndata[data['sample'] == 1]['Number of Reviews'].hist(bins=500, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Посмотрим на распределение признака price_level"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data['sample'] == 1]['price_level'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Видно, что значительная часть ресторанов не отнесена к тому или иному ценовому сегменту.\nПосмотрим, как пересекаются группы без отзывов и ценовой классификации:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.fillna(-1).loc[(data['sample'] == 1) & (data['Number of Reviews'] <= 0) & (data['price_level'] < 1)].ID_TA.count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"К \"неизведанным\" относится небольшая доля ресторанов - эффективный признак по этим данным собрать не получиться"},{"metadata":{},"cell_type":"markdown","source":"Исправим признак Number of Reviews с помощью информации об опубликованных отзывах:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def actual_number_of_reviews(reviews):\n    return len(list(filter(lambda r: len(r) > 0, reviews)))\n\ndef fix_number_of_reviews(row):\n    actual = actual_number_of_reviews(row['Reviews'])\n    given = row['Number of Reviews']\n    return actual if given < actual else given\n\ndata['Number of Reviews'] = data[['Number of Reviews','Reviews']].fillna(0).apply(fix_number_of_reviews, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Заполним пропуски price_level медианными значениями по городам:"},{"metadata":{"trusted":true},"cell_type":"code","source":"median_price_by_city = data.query('(sample == 1) and (price_level > 0)').groupby('City').price_level.median().reset_index()\nmedian_price_by_city.columns = ['City', 'price_level_median']\nmedian_price_ranges = { m['City']:m['price_level_median'] for m in median_price_by_city.to_dict('rows') }\ndef fix_price_level(row):\n    review_num = row['Number of Reviews']\n    given = row['price_level']\n    if (review_num == 0) and (given < 0):\n        return 0\n    elif given < 0: \n        return median_price_ranges[row['City']]\n    else:\n        return given\ndata['price_level'] = data.apply(fix_price_level, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Посмотрим на распределение признака Ranking (выглядит смещенным)"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (10,5)\ndata[data['sample'] == 1]['Ranking'].hist(bins=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Посмотрим на распределение признака Ranking по каждому из возможных значений Rating:"},{"metadata":{"trusted":true},"cell_type":"code","source":"ratings = sorted(data[data['sample'] == 1]['Rating'].unique())\nrows = round(len(ratings) / 2) + 1\nncols = 2\nfig = plt.figure(figsize=(20, 20))\n\nfor i, r in enumerate(ratings):\n    ax = fig.add_subplot(rows, ncols, i + 1)\n    series = data.query(\"(sample == 1) and (Rating == {})\".format(r))['Ranking']\n    series.hist(bins=100)\n    ax.set_xlabel(\"Rating == {}\".format(r))\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Видна зависимость Ranking ресторана и его рейтинга, однако, для средне-негативных оценок (2-2.5) она не столь очевидна, как для высоких или обсолютно-низких.\nПопробуем нормализовать признак Ranking, добавим balanced_ranking - Ranking, взвешенный на кол-во ретсоранов в городе:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['balanced_ranking'] = data.Ranking / data.restraunts_per_city","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Сравним распределение признаков Ranking и balanced_ranking"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (20,5)\ndata[data['sample'] == 1][['Ranking','balanced_ranking']].hist(bins=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Посмотрим на распределение времени между отзывами:"},{"metadata":{"trusted":true},"cell_type":"code","source":"actual_review_delays = data.query('(sample == 1) and (days_between_reviews >= 0)')['days_between_reviews']\n_, ax = plt.subplots(figsize=(20,3))\nax.set_yscale('log')\nplt.xticks(np.arange(actual_review_delays.min(), actual_review_delays.max() + 1, 100.0))\nactual_review_delays.hist(bins=500, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"есть подозрение, что значения более ~1800 получены в результате ошибок ввода / парсинга, попробуем их отсеять, отсутствующие данные заполним медианой\n\nпризнак review_freshness так же починим с помощью медианы"},{"metadata":{"trusted":true},"cell_type":"code","source":"days_between_reviews_median = data.query('(sample == 1) and (days_between_reviews >= 0)').days_between_reviews.median()\ndata['days_between_reviews'] = data['days_between_reviews'].apply(lambda d: d if (d < 1800) & (d >= 0) else days_between_reviews_median)\nreview_freshness_median = data.query('(sample == 1) and (review_freshness >= 0)').review_freshness.median()\ndata['review_freshness'] = data.review_freshness.apply(lambda d: d if d >=0 else review_freshness_median)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Добавляем признак \"Страна\":"},{"metadata":{"trusted":true},"cell_type":"code","source":"city_to_country = {'Paris': 'France',\n 'Stockholm': 'Sweden',\n 'London': 'United Kingdom',\n 'Berlin': 'Germany',\n 'Munich': 'Germany',\n 'Milan': 'Italy',\n 'Bratislava': 'Slovakia',\n 'Vienna': 'Austria',\n 'Rome': 'Italy',\n 'Barcelona': 'Spain',\n 'Madrid': 'Spain',\n 'Dublin': 'Ireland',\n 'Brussels': 'Belgium',\n 'Zurich': 'Switzerland',\n 'Warsaw': 'Poland',\n 'Budapest': 'Hungary',\n 'Copenhagen': 'Denmark',\n 'Amsterdam': 'Netherlands',\n 'Lyon': 'France',\n 'Hamburg': 'Germany',\n 'Lisbon': 'Portugal',\n 'Porto': 'Portugal',\n 'Prague': 'Czech Republic (Czechia)',\n 'Oslo': 'Norway',\n 'Helsinki': 'Finland',\n 'Edinburgh': 'United Kingdom',\n 'Geneva': 'Switzerland',\n 'Ljubljana': 'Slovenia',\n 'Athens': 'Greece',\n 'Luxembourg': 'Luxembourg',\n 'Krakow': 'Poland'}\ndata['Country'] = data.City.apply(lambda c: city_to_country[c])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Добавляем размер городского населения по странам к data-frame'у:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.merge(population_data, on='Country', how='left')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Добавим категориальные факторы кухонь по найциональным признакам (американская, восточно-европейская, кавказская и т.д.), а так же по типам заведения:"},{"metadata":{"trusted":true},"cell_type":"code","source":"cuisine_origin_groups = {\n    'european': ['Italian','French','Spanish','Swiss','Belgian','Dutch','Austrian','Czech','Greek','German','Portuguese','Central European','Spanish','Mediterranean', 'European', 'Pizza'],\n    'uk': ['British','Scottish','Welsh','Irish'],\n    'scandinavian': ['Scandinavian','Norwegian','Balti','Swedish','Danish'],\n    'east_europe':['Russian','Latvian','Romanian','Croatian','Slovenian','Albanian','Ukrainian','Hungarian','Polish','Eastern European'],\n    'asian': ['Fujian','Central Asian','Taiwanese','Tibetan','Korean','Vietnamese','Thai','Asian','Singaporean', 'Indonesian', 'Mongolian', 'Uzbek', 'Yunnan','Xinjiang','Minority Chinese','Chinese'],\n    'india':['Vegetarian Friendly', 'Indian', 'Sri Lankan', 'Nepali'],\n    'japanese':['Sushi', 'Japanese'],\n    'international': ['International', 'Fusion'],\n    'colonial': ['Native American', 'American', 'Central American', 'Cajun & Creole', 'Canadian', 'Hawaiian','Australian','Jamaican', 'New Zealand', 'Polynesian'],\n    'mideast_and_africa': ['Middle Eastern', 'Kosher', 'Israeli', 'Lebanese', 'Moroccan', 'Halal', 'African', 'Turkish', 'Tunisian', 'Egyptian', 'Arabic', 'Ethiopian', 'Afghani'],\n    'caucasus': ['Armenian', 'Caucasian', 'Georgian', 'Azerbaijani'],\n    'latam': ['Ecuadorean','Chilean','Colombian','Venezuelan','Peruvian','Brazilian','Argentinean','Latin', 'South American', 'Mexican', 'Salvadoran']\n}\ncuisine_specialization = {\n    'drinks': ['Brew Pub','Wine Bar','Pub','Bar'],\n    'general': ['Fast Food', 'Street Food', 'Cafe', 'Grill','Barbecue', 'Pizza', 'Diner', 'Soups', 'Fusion'],\n    'specialty':['Gastropub','Delicatessen','Seafood', 'Sushi', 'Steakhouse'],\n    'lifestyle': ['Vegetarian Friendly','Vegan Options','Gluten Free Options','Healthy', 'Halal', 'Contemporary']\n}\nregional_cusines = {'european', 'asian', 'american', 'colonial', 'mideast_and_africa', 'latam', 'caucasus'}\nlocal_cuisines = {'France': ['French'],\n 'Sweden': ['Swedish','Scandinavian'],\n 'United Kingdom': ['British', 'Scottish', 'Welsh'],\n 'Germany': ['German', 'Dutch'],\n 'Portugal': ['Portuguese'],\n 'Italy': ['Italian', 'Pizza'],\n 'Slovakia': [],\n 'Austria': ['Dutch','Austrian'],\n 'Italy': ['Italian', 'Pizza'],\n 'Spain': ['Spanish'],\n 'Ireland': ['Irish'],\n 'Belgium': ['Belgian'],\n 'Switzerland':['Swiss'],\n 'Poland': ['Polish','Eastern European'],\n 'Hungary': ['Hungarian','Eastern European'],\n 'Denmark': ['Danish','Scandinavian'],\n 'Netherlands': [],\n 'Czech Republic (Czechia)': ['Czech'],\n 'Norway': ['Scandinavian','Norwegian'],\n 'Finland': ['Scandinavian'],\n 'Slovenia': ['Slovenian'],\n 'Greece': ['Greek'],\n 'Luxembourg': []\n}\ndef cuisine_origin(cs):\n    found_types = {}\n    if 'international' in cs:\n        return 'international'\n    for cg, cuisines in cuisine_origin_groups.items():\n        for c in cs:\n            if c in cuisines:\n                found_types[cg] = found_types.get(cg, 0) + 1\n    if len(found_types) == 0:\n        return 'no_origin'                \n    if len(found_types.keys() & regional_cusines) > 1:\n        return 'international'\n    else:\n        return sorted(found_types.items(), key=lambda item: item[1])[-1][0]\ndef cuisine_spec(cs):\n    found_types = {}\n    for cg, cuisines in cuisine_specialization.items():\n        for c in cs:\n            if c in cuisines:\n                found_types[cg] = found_types.get(cg, 0) + 1\n    if len(found_types) == 0:\n        return 'no_spec'\n    return sorted(found_types.items(), key=lambda item: item[1])[-1][0]\ndef is_local_cuisine(row):\n    locs = local_cuisines[row['Country']]\n    return 1 if set(locs) & set(row['Cuisine Style']) else 0\ndata['cuisine_origin'] = data[\"Cuisine Style\"].apply(cuisine_origin)\ndata['cuisine_spec'] = data[\"Cuisine Style\"].apply(cuisine_spec)\ndata['is_local_cuisine'] = data.apply(is_local_cuisine,axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"cuisine_origin - национальный признак кухни\n\ncuisine_spec - специализация кухни (drinks, general, specialty..)\n\nis_local_cuisine - является ли кухня \"местной\" (например: францускую кухню в Париже считаем местной, китайскую кухню в Риме местной не считаем)"},{"metadata":{},"cell_type":"markdown","source":"Проверим, различаются ли Rating в группах полученных категориальных факторов:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import kruskal\nfactors_to_check = {\n    'cuisine_origin': data[data['sample'] == 1].cuisine_origin.unique(),\n    'cuisine_spec': data[data['sample'] == 1].cuisine_spec.unique(),\n    'is_local_cuisine': data[data['sample'] == 1].is_local_cuisine.unique(),\n    'is_chain_restaurant': data[data['sample'] == 1].is_chain_restaurant.unique()\n}\n\nfor c, values in factors_to_check.items():\n    _, p = kruskal(*[data[data[c] == v]['Rating'] for v in values])\n    if p < 0.05:\n        print(\"{} seems significant! p-value: {}\".format(c, p))\n    else:\n        print(\"{} seems irrelevant\".format(c, p))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Судя по всему, мой самый любимый фактор локальности кухни (is_local_cuisine) не подходит для оценки рейтинга :(, мы не будем его исопльзовать."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(columns=['is_local_cuisine'],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Применим one-hot-encoding к категориальным факторам cuisine_origin, cuisine_spec, City:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.get_dummies(data, columns=['cuisine_origin','cuisine_spec'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['City_is'] = data['City']\ndata = pd.get_dummies(data, columns=['City_is'], dummy_na=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from itertools import combinations\n\ndef get_corr(dataframe, name):\n    digit_columns = dataframe.select_dtypes(include=['int64', 'float64']).columns\n    combinations_all = list(combinations(digit_columns, 2))\n    corr = {}\n    \n    for c in combinations_all:\n        col1 = dataframe[c[0]]\n        col2 = dataframe[c[1]]\n        corr[c] = col1.corr(other=col2)\n\n    idx = pd.MultiIndex.from_tuples(corr.keys(), names=['A', 'B'])\n    #corr = pd.Series(corr, index = idx).sort_values()\n    corr = pd.DataFrame(list(corr.values()), index=idx,\n                        columns=[name]).sort_values(by=name)\n    return corr\n\ncorr = get_corr(data.drop(['sample'], axis=1), 'general')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_rows', 300)\npd.set_option('display.max_columns', 300)\npd.set_option('display.width', 300)\npd.set_option('display.max_colwidth', 300)\n\nperc25 = (abs(corr.max()) + abs(corr.min())) * \\\n    0.125  # ((abs(a) + abs(b)) / 2) * 0.25\ndisplay(corr[(corr < -perc25) | (corr > perc25)].dropna())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing\nТеперь, для удобства и воспроизводимости кода, завернем всю обработку в одну большую функцию."},{"metadata":{"trusted":true},"cell_type":"code","source":"def preproc_data(df_input):\n    '''includes several functions to pre-process the predictor data.'''\n    \n    df_output = df_input.copy()\n    \n    df_output.drop(['Restaurant_id','ID_TA', 'Ranking'], axis = 1, inplace=True)    \n\n    object_columns = [s for s in df_output.columns if df_output[s].dtypes == 'object']\n    df_output.drop(object_columns, axis = 1, inplace=True)\n    \n    return df_output","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Запускаем и проверяем что получилось"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_preproc = preproc_data(data)\ndf_preproc.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_preproc.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Теперь выделим тестовую часть\ntrain_data = df_preproc.query('sample == 1').drop(['sample'], axis=1)\n\ny = train_data.Rating.values            # наш таргет\nX = train_data.drop(['Rating'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Перед тем как отправлять наши данные на обучение, разделим данные на еще один тест и трейн, для валидации. \nЭто поможет нам проверить, как хорошо наша модель работает, до отправки submissiona на kaggle.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Воспользуемся специальной функцие train_test_split для разбивки тестовых данных\n# выделим 20% данных на валидацию (параметр test_size)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# проверяем\ntrain_data.shape, X.shape, X_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model \nСам ML"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Импортируем необходимые библиотеки:\nfrom sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\nfrom sklearn import metrics # инструменты для оценки точности модели","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Создаём модель (НАСТРОЙКИ НЕ ТРОГАЕМ)\nmodel = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Обучаем модель на тестовом наборе данных\nmodel.fit(X_train, y_train)\n\n# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n# Предсказанные значения записываем в переменную y_pred\ny_pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Поскольку рейтинг кратен 0.5, округляем"},{"metadata":{"trusted":true},"cell_type":"code","source":"def round_rating_pred(rating_pred):\n    if rating_pred <= 0.5:\n        return 0.0\n    if rating_pred <= 1.5:\n        return 1.0\n    if rating_pred <= 1.75:\n        return 1.5\n    if rating_pred <= 2.25:\n        return 2.0\n    if rating_pred <= 2.75:\n        return 2.5\n    if rating_pred <= 3.25:\n        return 3.0\n    if rating_pred <= 3.75:\n        return 3.5\n    if rating_pred <= 4.25:\n        return 4.0\n    if rating_pred <= 4.75:\n        return 4.5\n    return 5.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(y_pred)):\n    y_pred[i] = round_rating_pred(y_pred[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Сравниваем предсказанные значения (y_pred) с реальными (y_test), и смотрим насколько они в среднем отличаются\n# Метрика называется Mean Absolute Error (MAE) и показывает среднее отклонение предсказанных значений от фактических. \nprint('MAE:', metrics.mean_absolute_error(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# в RandomForestRegressor есть возможность вывести самые важные признаки для модели\nplt.rcParams['figure.figsize'] = (10,10)\nfeat_importances = pd.Series(model.feature_importances_, index=X.columns)\nfeat_importances.nlargest(15).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission\nЕсли все устраевает - готовим Submission на кагл"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df_sorted = data.query('sample == 0').sort_values(by='Restaurant_id')\nactual_y = test_df_sorted.Rating.values  \ntest_data = preproc_data(test_df_sorted.drop(['sample','Rating'], axis=1))\ntest_data.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_submission = model.predict(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(predict_submission)):\n    predict_submission[i] = round_rating_pred(predict_submission[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = pd.DataFrame(data = {'Restaurant_id':test_df_sorted['Restaurant_id'].values, 'Rating': predict_submission})\nsubmission = sample_submission.drop(columns=['Rating'])\nsubmission = submission.merge(result, on='Restaurant_id')\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}