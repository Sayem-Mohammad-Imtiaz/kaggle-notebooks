{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"**Objective:**\n\nTo perform data preprocessing techniques.\n\n**Secondary Objectives:**\n\n* To study Feature Scaling with Normalization and Standardization.\n* To study conversion of catgorical data into numeric using various methods.\n* To handle missing or irrelevant data."},{"metadata":{},"cell_type":"markdown","source":"Data preprocessing in Machine Learning is a crucial step that enhances the quality of data to promote the extraction of meaningful insights from the data. Data preprocessing in Machine Learning refers to the technique of preparing (cleaning and organizing) the raw data to make it suitable for a building and training Machine Learning models."},{"metadata":{},"cell_type":"markdown","source":"**Why do we need data preprocessing in machine learning?**\n\nGenerally, real-world data is incomplete, inconsistent, inaccurate and often lacks specific attribute/values. This is where data preprocessing is used – it helps to clean, format, and organize the raw data, thereby making it ready for building Machine Learning models. Preprocessing removes outliers and scales the features to an equivalent range. "},{"metadata":{},"cell_type":"markdown","source":"**Steps or techniques to perform data processing:**\n\n* Import Libraries to be used.\n* Import the dataset.\n* Remove the missing or irrelevant data.\n* Encode categorical data to numeric type.\n* Perform feature scaling techniques (Normalization and Standardization).\n* Then you can build your model with preprocessed data.\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"The first step is to load the libraries and the dataset. Here, I am going to use indian_food dataset. Let's see the details..."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import  StandardScaler\ndf= pd.read_csv('../input/indian-food-101/indian_food.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, we can see it has 255 columns and 9 rows. Most of the data is of categorical type. In the next step, we will count the number of unique ingredients used. "},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"ingre = set()\nfor i in df['ingredients']:\n    ingre.update(str(i).lower().split(\",\"))\n    \nprint(\"Total unique ingredients in dataset\",len(ingre),sep=\": \")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see there are 425 unique ingredients used. Now, we will count the number of ingredient used for a particular dish. "},{"metadata":{"trusted":true},"cell_type":"code","source":"def count_ingredient(column):\n    return float(len(column.split(\",\")))\ndf['ingredient_count'] = df['ingredients'].apply(count_ingredient)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we have 10 columns. But, we will drop the ingrident column as we already have the count of ingredients."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop('ingredients', axis=1, inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe(include='object')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, as we can see the min prep_time and cook_time is -1 which is not a realistic value. So, we will replace all the -1 in numeric as well as in categorical to NaN value. Then check for the unique values."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.replace(-1, np.NaN, inplace = True)\ndf.replace(\"-1\", np.NaN, inplace = True)\ndf.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, we are going to drop the NaN data and the new dataset is named as 'data'"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = df.dropna()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The shape which was (255,9) is now reduced to (180,9). "},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, I will be seperating the numeric data and categorical data.So that we could easily perform different operations."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, I am storing numerical data into \"num_data\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"num = (data.dtypes == 'float64')\nnumerical = list(num[num].index)\nprint(\"Numerical variables are:\")\nprint(numerical)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_data = data[numerical]\nnum_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, we will perform feature scaling on this numeric data.\n\n**What is Feature scaling?**\n\nFeature Scaling is a technique to represent in the data in a fixed range. In our example prep_time and cook time variables have different range. That is prep_time should be less than cook_time. "},{"metadata":{},"cell_type":"markdown","source":"![![image.png](attachment:image.png)](https://techondiary.files.wordpress.com/2019/02/capture.png?w=660)","attachments":{}},{"metadata":{},"cell_type":"markdown","source":"* **Normalization using MinMaxScaler() from sklearn:**\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler()\nnum_data_values = num_data.values\nnum_data_scaled = scaler.fit_transform(num_data_values)\nnormalized_df = pd.DataFrame(num_data_scaled)\nnormalized_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"normalized_df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Data Standardisation using StandardScaler()**"},{"metadata":{"trusted":true},"cell_type":"code","source":"std_scaler = StandardScaler()\nnum_data_values = num_data.values\nnum_data_std= std_scaler.fit_transform(num_data_values)\nstandardized_df = pd.DataFrame(num_data_std)\nstandardized_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"standardized_df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we will encode the categorical data into numeric data using various methods"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe(include='object')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, I have seperated categorical data from the base dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"cat = (data.dtypes == 'object')\nobjects = list(cat[cat].index)\nprint(\"Categorical variables are:\")\nprint(objects)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_data = data[objects]\ncat_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Label Encoder** \n \nNow, I will encode two features that is 'course' and 'state' using label_encoder from scikitlearn."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabel_encoder = LabelEncoder()\ncat_data['course'] = label_encoder.fit_transform(cat_data['course'])\ncat_data['state'] = label_encoder.fit_transform(cat_data['state'])\ncat_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Replace() method**\n\nNow,using replace() method replacing the flavor_profile and diet with numerical values."},{"metadata":{"trusted":true},"cell_type":"code","source":"f_pro = {'sweet':1,'spicy':2, 'bitter':3, 'sour':4}\ncat_data = cat_data.replace({'flavor_profile':f_pro})\ncat_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ndiet={'vegetarian':0,'non-vegitarian':1}\ncat_data= cat_data.replace({'diet':ndiet})\ncat_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **get_dummies()**\n\nIn this, we will use get_dummies() method. Here,cat_data is the dataframe and we use 'region' to specify which columns we want to be in dummy code. categorical variables in region are recoded into a set of separate binary variables (dummy variables). The next question is “what is a dummy variable?”. Typically, a dummy variable (or column) is one which has a value of one (1) when a categorical event occurs and zero (0) when it doesn’t occur Furthermore, this re-coding is called “dummy coding” and involves the creation of a table called contrast matrix."},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_data = pd.get_dummies(cat_data,columns=['region'],prefix = ['cat'])\ncat_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion:**\n\nThus, we preprocessed the data using normalization and standardization methods and convert the categorical data to numeric data for ease of building models."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}