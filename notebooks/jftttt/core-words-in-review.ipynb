{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport re\nimport jieba\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"c75253b5a330b35ccbc9b989cda1d0d11436b78f","_cell_guid":"4c85a3de-33b6-41bf-b148-0134c6fd9bcc"},"cell_type":"markdown","source":"## data overview"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"path = \"../input/Womens Clothing E-Commerce Reviews.csv\"\ndf = pd.read_csv(path)\ndf.describe()","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"491baa3e7a2c2a4c5fee1f3db4d64670ba78befa","_cell_guid":"0f0a6d41-0619-458a-8ecc-0a9647de3726"},"cell_type":"markdown","source":"## ignore null value of text field\nwhen parsing \"review text\" field, it occurs errors in python due to the null value of text field"},{"metadata":{"_uuid":"c310510683843c61a49519ad76efab7c0acd1cda","_cell_guid":"1b1e641f-119c-46a0-b876-a28e65c9ca7a","trusted":true},"cell_type":"code","source":"clear_df = df.dropna(subset=[\"Review Text\"])\nclear_df.describe()","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"afca5a4ec5be77aac8c8b1518d8086a8c57e4c57","_cell_guid":"419688b2-1e1a-40aa-ad14-c95893dc4e12"},"cell_type":"markdown","source":"## Tokenize\nsimple process, reserve only digits and letters , and words length larger than 1"},{"metadata":{"_uuid":"87778ee5f43ec8bef4c719a0d694aab4d85cf096","_cell_guid":"10c0788f-162e-46f3-b5ca-7ee6981fcf87","trusted":true},"cell_type":"code","source":"clear_df['tokens'] = clear_df['Review Text'].apply(\n    lambda x: \" \".join(\n        [t for t in filter(lambda xx: xx and len(xx)>1, re.sub(\"[^0-9a-z]\", \" \", x.lower()).split(' '))]\n    )\n)","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"2e6cbce84d54388a5c84fd4aac222e0e2beddfd4","_cell_guid":"a7f9167f-117c-42ec-bd49-e8f534c23715","trusted":true},"cell_type":"code","source":"clear_df['tokens'] ## check data","execution_count":8,"outputs":[]},{"metadata":{"_uuid":"9647b32a94ec71d5f717805f672f898da43735ac","_cell_guid":"d774fab2-13fc-4ec8-bc31-76a4e1f1d1e6","collapsed":true,"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\ncorpus = clear_df['tokens']\nvectorizer = CountVectorizer()  \nX = vectorizer.fit_transform(corpus)  \nword = vectorizer.get_feature_names() ## the whole words in corpus ","execution_count":9,"outputs":[]},{"metadata":{"_uuid":"ee57899f04fc422ed52319cebde538810c602330","_cell_guid":"04537bba-8602-423e-b291-7fcbfeb7c96d"},"cell_type":"markdown","source":"## calculate tfidf as weight matrix"},{"metadata":{"_uuid":"9006db8f5f15df5f810aa2945cf99b774556b35f","_cell_guid":"66f7446d-1d16-4546-bd00-8dcb9ded8547","collapsed":true,"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfTransformer  \ntransformer = TfidfTransformer()  \ntfidf = transformer.fit_transform(X)  \nweight = tfidf.toarray()","execution_count":10,"outputs":[]},{"metadata":{"_uuid":"6153b9c789449798b8c9d24433b127864599f953","_cell_guid":"5cb32fda-30b3-4ae2-b09a-52a6fb148041"},"cell_type":"markdown","source":"## extract core words\n+ use min_weight(tfidf score)\n+ speed up via vectorization (np.applay_along_axis)"},{"metadata":{"_uuid":"37b35a51537b458457b3fe4799942dca8025b8e6","_cell_guid":"d897136c-29a3-4249-aa6f-dbd7dfeb09a5","collapsed":true,"trusted":true},"cell_type":"code","source":"weight.shape\nmin_weight = 0.1\ncore_words = np.apply_along_axis(lambda vec: \" \".join([t[0] for t in filter(lambda x: x[1]>min_weight, [(word[j], ele) for j,ele in enumerate(vec)])]), 1, weight)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aab35003646d4e4f66f1da4aa8e8ee629e9d7e5f","_cell_guid":"d168b74e-61b1-4844-a455-d3ee13ac0431"},"cell_type":"markdown","source":"## concat origin clean df"},{"metadata":{"_uuid":"b97533d6d0ef72537b42f99dc682c3bc62ebe33d","_cell_guid":"d424d51c-ef5a-45d6-9212-3fcaed72e741","trusted":false,"collapsed":true},"cell_type":"code","source":"core_word_df = pd.DataFrame(core_words, columns=[\"CoreWords\"])\ncore_word_df.shape\nfinal = clear_df.join(core_word_df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6d5db3f4812571778b3902ca7415e5dfcb4c4788","_cell_guid":"7d0d68b1-fed3-4181-8384-3c2d84c7407a","trusted":false,"collapsed":true},"cell_type":"code","source":"final[['Title', 'Review Text','tokens','CoreWords']]","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}