{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfilename = \"../input/heart-failure-clinical-data/heart_failure_clinical_records_dataset.csv\"\ndf = pd.read_csv(filename)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#seperating the data and labels\nX = df.iloc[:, :12]\nY = df.iloc[:, [12]]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import the required packages\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow import keras","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#converting the data into numpy arrays and splitting the data into train and validation set\nX = np.array(X)\nY = np.array(Y)\nX_train, X_valid, Y_train, Y_valid = train_test_split(X, Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#defining the model architecture\nmodel = keras.models.Sequential([keras.layers.BatchNormalization(),\n                               keras.layers.Dense(70, activation = \"selu\", kernel_initializer=\"lecun_normal\", input_shape=X_train.shape[1:]),\n                               keras.layers.Dense(70, activation = \"selu\", kernel_initializer = \"lecun_normal\", kernel_regularizer = keras.regularizers.l2(0.03)),\n                               keras.layers.Dense(20, activation = \"selu\", kernel_initializer = \"lecun_normal\", kernel_regularizer = keras.regularizers.l2(0.03)),\n                               keras.layers.Dense(1, activation = \"sigmoid\")])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#setting the learning algorithm and compiling the model\noptimizer = keras.optimizers.Adam(lr = 0.005)\nmodel.compile(optimizer = optimizer, loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\nmodel_checkpoint = keras.callbacks.ModelCheckpoint(\"heart_failure_model.h5\")\nearly_stopping = keras.callbacks.EarlyStopping(patience=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#training the model\nhistory = model.fit(X_train, Y_train, epochs=100, validation_data = (X_valid, Y_valid), callbacks=[model_checkpoint, early_stopping])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotting the results\nimport matplotlib.pyplot as plt\n\npd.DataFrame(history.history).plot(figsize=(8, 5))\nplt.grid(True)\nplt.gca().set_ylim(0,1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above model uses 3 hidden layers with 70, 70, and 20 neuron with selu as the activation function and lecunn initialisation. it was trained for 100 epochs with early stopping and the training stopped at 33 epochs. the model uses adam optimizer along with binay cross entropy loss function. the model was able to achieve a accuracy of 85.33 percent on the validation set","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}