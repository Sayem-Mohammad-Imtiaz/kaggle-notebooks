{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"In this kernel, We will make sentiment analysis using the reviews text."},{"metadata":{},"cell_type":"markdown","source":"We will begin importing some libraries and then, show some dataset information."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importing dataset\ndf = pd.read_csv(\"../input/womens-ecommerce-clothing-reviews/Womens Clothing E-Commerce Reviews.csv\", index_col=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame.info(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The dataset has 10 columns and 23486 rows. Some features has null values."},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Now we will extract the features that we will explore."},{"metadata":{"trusted":true},"cell_type":"code","source":"reviewsDf = df[[\"Rating\",\"Review Text\"]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The updated dataset:"},{"metadata":{"trusted":true},"cell_type":"code","source":"reviewsDf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame.info(reviewsDf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Deleting rows with null values."},{"metadata":{"trusted":true},"cell_type":"code","source":"reviewsDf = reviewsDf.dropna(subset=['Review Text'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Resetting index."},{"metadata":{"trusted":true},"cell_type":"code","source":"reviewsDf.index = pd.Series(list(range(reviewsDf.shape[0])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reviewsDf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plotting the wordclouds."},{"metadata":{"trusted":true},"cell_type":"code","source":"rev = reviewsDf['Review Text']\n\nplt.subplots(figsize=(15,4))\nwordcloud = WordCloud(background_color='white', width=900, height=300).generate(\" \".join(rev))\nplt.imshow(wordcloud)\nplt.title('Words from Reviews\\n',size=20)\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that \"top\", \"love\", \"dress\" and \"shirt\" is very used on the reviews."},{"metadata":{},"cell_type":"markdown","source":"**Preprocessing our data.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Removing stop words.\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import RegexpTokenizer\nimport nltk\nfrom nltk.corpus import wordnet\nfrom nltk.stem import WordNetLemmatizer\n!pip install nltk --upgrade\nnltk.download('wordnet')\n\nsw = set(stopwords.words('english'))\n\ndef preproc(data):\n    #converting all to lowercase\n    data = data.lower() \n    #Tokenize\n    words = RegexpTokenizer(r'[a-z]+').tokenize(data)\n    #Deleting stopwords\n    words = [w for w in words if not w in sw]\n    \n    #Lemmatizing\n    for pos in [wordnet.NOUN, wordnet.VERB, wordnet.ADJ, wordnet.ADV]:\n        words = [WordNetLemmatizer().lemmatize(x, pos) for x in words]\n    return \" \".join(words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reviewsDf['New Text'] = reviewsDf['Review Text'].apply(preproc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reviewsDf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Creating the sentiment classifier.\n**\n\nWe will create a new column that will consider the ratings as follows:\n\nRating 4 or higher: Positive\nrating 3: Neutral\nRating 2 or less: Negative\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def polarity (row):\n  if row['Rating'] >= 4:\n    return 'Positive'\n  if row['Rating'] == 3:\n    return 'Neutral'\n  if row['Rating'] <= 2:\n    return 'Negative'\n\nreviewsDf['Class'] = reviewsDf.apply(lambda row: polarity(row), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reviewsDf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating train and test base."},{"metadata":{"trusted":true},"cell_type":"code","source":"text, classe = reviewsDf[\"New Text\"], reviewsDf[\"Class\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_text = text[:16980]\ntest_text = text[16981:22640]\ntrain_classe = classe[:16980]\ntest_classe = classe[16981:22640]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Processing TD-IDF Matrix**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Feature extraction\n\nfrom sklearn.feature_extraction.text import CountVectorizer\ncount_vect = CountVectorizer(encoding='latin-1')\nX_train_counts = count_vect.fit_transform(train_text)\nX_train_counts.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_vect.vocabulary_.get('dress')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfTransformer\ntfidf_transformer = TfidfTransformer(use_idf=True)\nX_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\nX_train_tfidf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Naive Bayes."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nclf = MultinomialNB().fit(X_train_tfidf, train_classe)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nX_test_counts = count_vect.transform(test_text)\nX_test_tfidf = tfidf_transformer.transform(X_test_counts)\npredito = clf.predict(X_test_tfidf)\ngaussian_acc = accuracy_score(test_classe, predito)\nprint(gaussian_acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random Forest."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nran = RandomForestClassifier(n_estimators=50)\nran.fit(X_train_tfidf, train_classe)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Accuracy score\nX_test_counts = count_vect.transform(test_text)\nX_test_tfidf = tfidf_transformer.transform(X_test_counts)\npredito = ran.predict(X_test_tfidf)\nran_acc = accuracy_score(test_classe, predito)\nprint(ran_acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Support Vector Machine"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\nsvm = SVC()\nsvm.fit(X_train_tfidf, train_classe)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Accuracy score\n\nX_test_counts = count_vect.transform(test_text)\nX_test_tfidf = tfidf_transformer.transform(X_test_counts)\npredito = svm.predict(X_test_tfidf)\nsvm_acc = accuracy_score(test_classe, predito)\nprint(svm_acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Neural network."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\n\nnn = MLPClassifier()\nnn.fit(X_train_tfidf, train_classe)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Accuracy score\n\nX_test_counts = count_vect.transform(test_text)\nX_test_tfidf = tfidf_transformer.transform(X_test_counts)\npredito = nn.predict(X_test_tfidf)\nnn_acc = accuracy_score(test_classe, predito)\nprint(nn_acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Logistic Regression."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression()\nlr.fit(X_train_tfidf, train_classe)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Accuracy score\n\nX_test_counts = count_vect.transform(test_text)\nX_test_tfidf = tfidf_transformer.transform(X_test_counts)\npredito = lr.predict(X_test_tfidf)\nlr_acc = accuracy_score(test_classe, predito)\nprint(lr_acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The ranking bellow show us that Logistic Regression was the most accurate model and Support Vector Machines was the worse."},{"metadata":{"trusted":true},"cell_type":"code","source":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'Neural Network'],\n    'Score': [svm_acc, lr_acc, \n              ran_acc, gaussian_acc, nn_acc]})\nmodels.sort_values(by='Score', ascending=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}