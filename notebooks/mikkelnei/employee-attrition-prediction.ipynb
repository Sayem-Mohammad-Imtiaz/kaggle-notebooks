{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/ibm-hr-analytics-attrition-dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Education.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nEducation = {1: \"Below College\", 2: \"College\", 3:\"Bachelor\", 4:\"Master\", 5:\"Doctor\"}\nEnvironmentSatisfaction = {1: \"Low\", 2: \"Medium\", 3:\"High\", 4:\"Very High\"}\nJobInvolvement = {1: \"Low\", 2: \"Medium\", 3:\"High\", 4:\"Very High\"}\nJobSatisfaction = {1: \"Low\", 2: \"Medium\", 3:\"High\", 4:\"Very High\"}\nPerformanceRating = {1: \"Low\", 2: \"Good\", 3:\"Excellent\", 4:\"Outstanding\"}\nRelationshipSatisfaction = {1: \"Low\", 2: \"Medium\", 3:\"High\", 4:\"Very High\"}\nWorkLifeBalance = {1: \"Bad\", 2: \"Good\", 3:\"Better\", 4:\"Best\"}\n\ndf.replace({\"Education\": Education, \"JobInvolvement\":JobInvolvement, \"JobSatisfaction\": JobSatisfaction, \n              \"PerformanceRating\":PerformanceRating, \"RelationshipSatisfaction\":RelationshipSatisfaction,\n             \"WorkLifeBalance\":WorkLifeBalance, \"EnvironmentSatisfaction\":EnvironmentSatisfaction}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualization","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df.Attrition,hue=df.Department,palette='muted')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df.Attrition,hue=df.Education,palette='muted')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df.Attrition,hue=df.EducationField,palette='muted')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df.Gender,hue=df.JobSatisfaction,palette='muted')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df.Gender,hue=df.OverTime,palette='muted')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lineplot(df.Age,df.HourlyRate,color='#C70039')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lineplot(df.YearsAtCompany,df.YearsInCurrentRole,color='#FF5733')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_cols = [x for x in df.columns if df[x].dtype == 'object']\ncat_data = df[cat_cols]\nnum_cols = df.columns.difference(cat_cols)\nnum_data = df[num_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = num_data.corr()\nheatmap = sns.heatmap(corr, vmin=0, vmax=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Categorical Data\ncat_data = pd.concat([cat_data.reset_index(drop=True)],axis=1)\ncat_data.columns\n\nfig, axarr = plt.subplots(3, 2, figsize=(18, 15))\nsns.countplot(x=\"BusinessTravel\", hue = \"Attrition\",dodge= True ,data=cat_data, ax=axarr[0][0],palette=\"muted\") \n# Higher attrition in travel Frequently\nsns.countplot(x=\"OverTime\", hue = \"Attrition\",dodge= True ,data=cat_data, ax=axarr[0][1],palette=\"muted\")\n# Higher attrition in Overtime\nsns.countplot(x=\"Education\", hue = \"Attrition\",dodge= True ,data=cat_data, ax=axarr[1][0],palette=\"muted\")\nsns.countplot(x=\"EducationField\", hue = \"Attrition\",dodge= True ,data=cat_data, ax=axarr[1][1],palette=\"muted\")\n# Higher percentage attrition in merketing and tech degree\nsns.countplot(x=\"JobInvolvement\", hue = \"Attrition\",dodge= True ,data=cat_data, ax=axarr[2][0],palette=\"muted\")\nsns.countplot(x=\"JobSatisfaction\", hue = \"Attrition\",dodge= True ,data=cat_data, ax=axarr[2][1],palette=\"muted\")\n# Extremely low attrition in Very High Job satisfaction\n# higher attrition in \"High\" vs [\"Very High and \"Medium\"]\n\nfig, axarr = plt.subplots(2, 2, figsize=(15, 10))\nsns.countplot(x=\"Gender\", hue = \"Attrition\",dodge= True ,data=cat_data, ax=axarr[0][0],palette=\"muted\")\nsns.countplot(x=\"MaritalStatus\", hue = \"Attrition\",dodge= True ,data=cat_data, ax=axarr[0][1],palette=\"muted\")\n# More attrition among single people\nsns.countplot(x=\"RelationshipSatisfaction\", hue = \"Attrition\",dodge= True ,data=cat_data, ax=axarr[1][0],palette=\"muted\")\n# More attrition among people with low relationship satisfaction\nsns.countplot(x=\"WorkLifeBalance\", hue = \"Attrition\",dodge= True ,data=cat_data, ax=axarr[1][1],palette=\"muted\")\n# High attrition among people with bad Work Life Balance, even though very few people have reported bad worklife balance\n\nfig, axarr = plt.subplots(2, figsize=(19, 10))\n# Higher percentage attrition in Sales\nsns.countplot(x=\"Department\", hue = \"Attrition\",dodge= True ,data=cat_data, ax=axarr[0],palette=\"muted\")\n# Higher attrition in Sales roles and Lab technician role\nsns.countplot(x=\"JobRole\", hue = \"Attrition\",dodge= True ,data=cat_data, ax=axarr[1],palette=\"muted\")\n\n# Overtime vs Department\nsns.factorplot(x=\"OverTime\", col=\"Department\", col_wrap=4,hue=\"Attrition\",\n                   data=cat_data, kind =\"count\",palette=\"muted\")\n\n# JobInvolvement vs JobSatisfaction\nsns.factorplot(x=\"JobInvolvement\", col=\"JobSatisfaction\", col_wrap=4,hue=\"Attrition\",\n                   data=cat_data, kind =\"count\",palette=\"muted\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = num_data\ndf['Attrition'] = df['Attrition'].replace(['Yes','No'],['1','0']).astype('int64')\n\ny = df.Attrition","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Logistic Regression with R-square\nimport statsmodels.api as sm\nlogit_model=sm.Logit(y,X)\nresult=logit_model.fit()\nprint(result.summary2())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Class Imbalance SMOTE\nfrom imblearn.over_sampling import SMOTE\nsmote = SMOTE(sampling_strategy='auto', random_state=100, k_neighbors=5)\n\nsmote_X,smote_y = smote.fit_sample(X,y)\ncolumns=X.columns\nsmote_X = pd.DataFrame(data=smote_X,columns=columns)\nsmote_y= pd.DataFrame(data=smote_y,columns=['y'])\n\nprint(\"length of oversampled data is \",len(smote_X))\nprint(\"Number of no subscription in oversampled data\",len(smote_y[smote_y['y']==0]))\nprint(\"Number of subscription\",len(smote_y[smote_y['y']==1]))\nprint(\"Proportion of no subscription data in oversampled data is \",len(smote_y[smote_y['y']==0])/len(smote_X))\nprint(\"Proportion of subscription data in oversampled data is \",len(smote_y[smote_y['y']==1])/len(smote_X))\nprint(len(smote_X))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,random_state=45,test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import precision_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression().fit(X_train,y_train)\n\npred = model.predict(X_test)\nprint('Accuracy score : ',accuracy_score(y_test,pred)*100,'%')\nprint('Confusion Matrix : ')\nprint(confusion_matrix(y_test,pred))\n\nalgo_dict = {}\nalgo_dict['LogisticRegression'] = accuracy_score(y_test,pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nforest_model = RandomForestClassifier().fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = forest_model.predict(X_test)\nprint('Accuracy score : ',accuracy_score(y_test,pred)*100,'%')\nprint('f1_score : ',f1_score(y_test,pred))\nprint('recall_score : ',recall_score(y_test,pred))\nprint('precision_score : ',precision_score(y_test,pred))\nprint('Confusion Matrix : ')\nprint(confusion_matrix(y_test,pred))\nalgo_dict['RandomForestClassifier'] = accuracy_score(y_test,pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nmodel = GradientBoostingClassifier().fit(X_train,y_train)\n\npred = model.predict(X_test)\nprint('Accuracy score : ',accuracy_score(y_test,pred)*100,'%')\nprint('f1_score : ',f1_score(y_test,pred))\nprint('recall_score : ',recall_score(y_test,pred))\nprint('precision_score : ',precision_score(y_test,pred))\nprint('Confusion Matrix : ')\nprint(confusion_matrix(y_test,pred))\nalgo_dict['GradientBoostingClassifier'] = accuracy_score(y_test,pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nmodel = DecisionTreeClassifier().fit(X_train,y_train)\n\npred = model.predict(X_test)\nprint('Accuracy score : ',accuracy_score(y_test,pred)*100,'%')\nprint('f1_score : ',f1_score(y_test,pred))\nprint('recall_score : ',recall_score(y_test,pred))\nprint('precision_score : ',precision_score(y_test,pred))\nprint('Confusion Matrix : ')\nprint(confusion_matrix(y_test,pred))\nalgo_dict['DecisionTreeClassifier'] = accuracy_score(y_test,pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import BernoulliNB\nmodel = BernoulliNB().fit(X_train,y_train)\n\npred = model.predict(X_test)\nprint('Accuracy score : ',accuracy_score(y_test,pred)*100,'%')\nprint('f1_score : ',f1_score(y_test,pred))\nprint('recall_score : ',recall_score(y_test,pred))\nprint('precision_score : ',precision_score(y_test,pred))\nprint('Confusion Matrix : ')\nprint(confusion_matrix(y_test,pred))\nalgo_dict['BernoulliNB'] = accuracy_score(y_test,pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvc = SVC().fit(X_train,y_train)\n\npred = svc.predict(X_test)\nprint('Accuracy score : ',accuracy_score(y_test,pred)*100,'%')\nprint('Confusion Matrix : ')\nprint(confusion_matrix(y_test,pred))\nalgo_dict['SVC'] = accuracy_score(y_test,pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nacc=[]\nfor i in range(3,25):\n    model = KNeighborsClassifier(n_neighbors=i).fit(X_train,y_train)\n    pred = model.predict(X_test)\n    acc.append(accuracy_score(pred,y_test))\nprint('Max accuracy is :',max(acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(list(range(3,25)),acc,palette='muted')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(list(range(3,25)),acc,palette='muted')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(acc)):\n    if acc[i]==max(acc):\n        k=i+3\n        break\nprint('Best k-value is : ',k)\nmodel = KNeighborsClassifier(n_neighbors=k).fit(X_train,y_train)\npred = model.predict(X_test)\nprint('\\nKNearestClassifier model created successfully!')\nprint()\nprint('Accuracy score  : ',accuracy_score(pred,y_test))\nprint('Confusion Matrix : ')\nprint(confusion_matrix(y_test,pred))\nalgo_dict['KNeighborsClassifier'] = accuracy_score(y_test,pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import PassiveAggressiveClassifier\nmodel = PassiveAggressiveClassifier().fit(X_train,y_train)\n\npred = model.predict(X_test)\nprint('Accuracy score : ',accuracy_score(y_test,pred)*100,'%')\nprint('Confusion Matrix : ')\nprint(confusion_matrix(y_test,pred))\nalgo_dict['PassiveAggressiveClassifier'] = accuracy_score(y_test,pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"algo_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lst_1 = list(algo_dict.keys())\nlst_2 = list(algo_dict.values())\nfig,ax = plt.subplots(figsize=(16,5))\nsns.barplot(lst_1,lst_2,ax=ax,palette='muted')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Variable Importance for model with highest accuracy\n\nimp_dict = { X.columns[i]:imp for i,imp in enumerate(forest_model.feature_importances_)}\nsorted_imp_dict = sorted(imp_dict.items(), key=lambda x: x[1], reverse=True)\nsorted_imp_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Variable Importance Bar graph\n\nlst_1 = list(imp_dict.keys())\nlst_2 = list(imp_dict.values())\nfig,ax = plt.subplots(figsize=(16,5))\nwith sns.color_palette('muted'):\n    sns.barplot(y=lst_1,x=lst_2,ax=ax,palette='muted',orient=\"h\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}