{"cells":[{"metadata":{},"cell_type":"markdown","source":"# ****SOLUCIÓN:****\n\nSe importan las librerias y se leen los datos escogidos: [Heart Disease UCI](https://www.kaggle.com/ronitf/heart-disease-uci)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neural_network import MLPRegressor as mlp_r\nfrom sklearn.neural_network import MLPClassifier as mlp_c\nfrom sklearn.metrics import confusion_matrix\nimport warnings\nwarnings.filterwarnings('ignore')\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn import datasets","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"Heart_data = pd.read_csv(\"../input/heart.csv\")\nHeart_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# REGRESIÓN\n\nSe crea una matriz X que contiene todas las filas de los datos y un vector Y que contiene la información del tipo de dolor de pecho (cp)"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = (Heart_data.iloc[:,:-1]).as_matrix()\ny = (Heart_data.iloc[:,2]).as_matrix()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Se normalizan todos los datos en X segun el maximo y se hace lo mismo para Y (se divide entre 3 porque es el maximo de esos datos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = (X - X.min(axis=0))/(X.max(axis=0) - X.min(axis=0))\ny = y.reshape((-1,1))/3","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Se dividen los datos para probar el modelo posteriormente"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.33, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Entrenamos"},{"metadata":{"trusted":true},"cell_type":"code","source":"regressor = mlp_r(\n    hidden_layer_sizes=(100,100),  activation='tanh', solver='adam', alpha=0.001, batch_size='auto',\n    learning_rate='constant', learning_rate_init=0.01, power_t=0.5, max_iter=1000, shuffle=True,\n    random_state=0, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True,\n    early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"regressor.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_hats = regressor.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(y_test, y_hats, c='k')\n\nplt.plot([0.1, 0.9], [0.1, 0.9], 'r')\nplt.xlabel('Real')\nplt.ylabel('Estimada')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creamos 2 vectores con posibles numeros de neuronas en cada capa (2 capas) y probamos todas las combinaciones para posteriormente medir el error cuadratico medio de cada uno"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\ncapa_1 = [5, 7, 9, 11, 13, 17,  19, 23, 29, 31]\ncapa_2 = [1, 5, 7, 9, 11, 13, 17,  19, 23, 29]\n\nmse_m = np.zeros((len(capa_1),len(capa_1)))\nmse_std = np.zeros((len(capa_1),len(capa_1)))\n\nfor j, n_1 in enumerate(capa_1):\n    for k, n_2 in enumerate(capa_2):\n        mse_temp = []\n    \n        for i in range(10):\n            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n            regressor = mlp_r(hidden_layer_sizes=(n_1,n_2),  activation='tanh', solver='adam', alpha=0.001, batch_size='auto',\n            learning_rate='constant', learning_rate_init=0.01, power_t=0.5, max_iter=1000, shuffle=True,\n            random_state=0, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True,\n            early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n            regressor.fit(X_train, y_train)\n            y_hats = regressor.predict(X_test)\n            mse_temp.append(mean_squared_error(y_test, y_hats))\n            \n        mse_m[j, k] = np.mean(mse_temp)\n        mse_std[j, k] = np.std(mse_temp)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A continuación se grafican 2 mapas en donde se muestra el error cuadratico medio y la desviación estandar de cada red neuronal calculada anteriormente"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(mse_m)\nplt.colorbar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para la grafica anterior, se puede ver que para el numero de neuronas en la capa 2 igual a 1 los datos contienen mucho error cuadratico medio, y que para 5 o mas neuronas en cada capa el error cuadratico medio es bajo y lo mismo ocurre para la desviación estandar. En general se puede decir que el modelo corre bien para 5 o mas neuronas en la capa 1 siempre y cuando tenga 5 o mas neuronas en la capa 2\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(mse_std)\nplt.colorbar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Variando el momentum con uno de los mejores resultados"},{"metadata":{"trusted":true},"cell_type":"code","source":"mmntm=[0,0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,1]\nmse_m = np.zeros(len(mmntm))\nfor m,n_3 in enumerate(mmntm):\n    for i in range(21):\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n        regressor = mlp_r(hidden_layer_sizes=(29,31),  activation='tanh', solver='adam', alpha=0.001, batch_size='auto',\n        learning_rate='constant', learning_rate_init=0.01, power_t=0.5, max_iter=1000, shuffle=True,\n        random_state=0, tol=0.0001, verbose=False, warm_start=False, momentum=n_3, nesterovs_momentum=True,\n        early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n        regressor.fit(X_train, y_train)\n        y_hats = regressor.predict(X_test)\n        mse_temp.append(mean_squared_error(y_test, y_hats))\n    mse_m[m] = np.mean(mse_temp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(mmntm, mse_m, '.')\nplt.xlabel('Momentum')\nplt.ylabel('Error cuadratico medio')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Se puede ver que a medida que sube el momentum, el error cuadratico medio disminuye"},{"metadata":{},"cell_type":"markdown","source":"# CLASIFICACIÓN\nSe usan los mismos datos de [Heart Disease UCI](https://www.kaggle.com/ronitf/heart-disease-uci) y se dividen los datos para el entrenamiento justo como la regresión"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = (Heart_data.iloc[:,:-1]).as_matrix()\ny = (Heart_data.iloc[:,2]).as_matrix()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.33, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Entrenamos"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = mlp_c(solver='lbfgs', alpha=1e-5,\n                    hidden_layer_sizes=(1000, 500), random_state=1)\n\nclf.fit(X_train, y_train)\ny_hat = clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Se calcula la matriz de confusion sin normalizar"},{"metadata":{"trusted":true},"cell_type":"code","source":"cm1 = confusion_matrix(y_test, y_hat)\ncm2 = confusion_matrix(y_test, y_hat)\ncm2 = cm2.astype('float') / cm2.sum(axis=1)[:, np.newaxis]\ncm1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para analizar la matriz, debemos fijarnos en la diagonal principal, para tener unos datos claros porcentualmente hablando, normalizamos."},{"metadata":{"trusted":true},"cell_type":"code","source":"cm2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A continuación, se crean varios modelos con diferentes numeros de neuronas en cada capa, y por medio de la herramienta de densidad de imagen, se establece el mejor."},{"metadata":{"trusted":true},"cell_type":"code","source":"capa_1=[100, 400, 800, 900, 1000]\ncapa_2=[20, 100, 500, 700, 800]\ncero=np.zeros((len(capa_1),len(capa_2)))\nuno=np.zeros((len(capa_1),len(capa_2)))\ndos=np.zeros((len(capa_1),len(capa_2)))\ntres=np.zeros((len(capa_1),len(capa_2)))\nsuma=np.zeros((len(capa_1),len(capa_2)))\nfor j, n_1 in enumerate(capa_1):\n    for k, n_2 in enumerate(capa_2):\n        X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.33, random_state=42)\n\n        clf = mlp_c(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(n_1, n_2), random_state=1)\n\n        clf.fit(X_train, y_train)\n        y_hat = clf.predict(X_test)\n        cm2 = confusion_matrix(y_test, y_hat)\n        cm2 = cm2.astype('float') / cm2.sum(axis=1)[:, np.newaxis]\n        suma[j,k]=cm2[0,0]+cm2[1,1]+cm2[2,2]+cm2[3,3]\n        cero[j,k]=cm2[0,0]\n        uno[j,k]=cm2[1,1]\n        dos[j,k]=cm2[2,2]\n        tres[j,k]=cm2[3,3]\n            \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"En cada imagen, se muestra la entrada diagonal de cada matriz de confusión normalizada, entre mas se aproxime a 1 mejor. Al final se tiene una grafica que cada entrada corresponde a un promedio de la diagonal."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(cero)\nplt.colorbar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(uno)\nplt.colorbar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(dos)\nplt.colorbar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(tres)\nplt.colorbar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(suma/4)\nplt.colorbar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A medida que se aumenta el numero de neuronas de la capa 2, se obtienen mejores resultados, aunque el dato del cp categoria 3 nunca se puede predecir correctamente para este caso (en el unico caso que funciona, los demás fallan)."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}