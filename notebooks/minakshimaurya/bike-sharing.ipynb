{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Step 1: Reading and Understanding the Data"},{"metadata":{"trusted":false},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df= pd.read_csv(\"day.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- ##### As there are no null values no need to handle that"},{"metadata":{"trusted":false},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Dropping Date ,casual,registered and instant columns as instant is indexing and date is not significant as we have month and years\n# and cnt variable is addition of causal and registered\ndf.drop(['dteday','instant','casual','registered'], axis = 1, inplace = True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 2: Visualising the Data"},{"metadata":{},"cell_type":"markdown","source":"#### Visualising Numeric Variables\n\nLet's make a pairplot of all the numeric variables"},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.pairplot(df, x_vars=['temp','atemp','hum','windspeed'], y_vars='cnt')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- ##### From numeric variable visualisation its clear that temp and atemp are in linear relation ship with Count"},{"metadata":{},"cell_type":"markdown","source":"#### Visualising Categorical Variables\n\nAs there are a few categorical variables as well. Let's make a boxplot for some of these variables."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Converting Season,month and Weathersit Categorical Variables into string\ndf['season']= df['season'].map({1 : 'spring', 2 :'summer', 3 :'fall', 4: 'winter'})\ndf['weathersit']= df['weathersit'].map({1 : 'Clear', 2 :'Mist', 3 :'Light Snow', 4:'Heavy Rain'})\n# df['mnth'] = df['mnth'].map({1:'January', 2:'February', 3:'March',4:'April',5:'May', 6:'June',7:'July',8:'August',9:'September',10:'October',\n#                               11:'November', 12:'December'})\n# df['weekday'] = df['weekday'].map({0:'Sunday', 1:'Monday', 2:'Tuesday',3:'Wednesday',4:'Thursday', 5:'Friday',6:'Saturday'})\n# df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(20, 12))\nplt.subplot(2,2,1)\nsns.boxplot(x = 'season', y = 'cnt', data = df)\n\nplt.subplot(2,2,2)\nsns.boxplot(x = 'weekday', y = 'cnt', data = df)\nplt.subplot(2,2,3)\nsns.boxplot(x = 'mnth', y = 'cnt', data = df)\nplt.xticks(rotation=90)\nplt.subplot(2,2,4)\nplt.xticks(rotation=90)\nsns.boxplot(x = 'weathersit', y = 'cnt', data = df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(20, 12))\nplt.subplot(2,2,1)\nplt.title('weather situation')\nsns.boxplot(x = 'yr', y = 'cnt',hue = 'weathersit', data = df)\n\nplt.subplot(2,2,2)\nplt.title('season')\nsns.boxplot(x = 'yr', y = 'cnt', hue = 'season',data = df)\n\nplt.subplot(2,2,3)\nplt.title('month')\nsns.boxplot(x = 'yr', y = 'cnt',hue = 'mnth', data = df)\n\nplt.subplot(2,2,4)\nplt.title('weekday')\nsns.boxplot(x = 'yr', y = 'cnt',hue = 'weekday', data = df)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- ####\tBased on season bike sharing is in order of Fall>summer>winter>spring\n    In fall season bike sharing is more than other seasons.    \n- ####\tBased on weather situation bike sharing is in order of clear>mist>light snow\n    In clear weather situation bike sharing is more    \n- ####\tMedian for Thursday, Wednesday and Saturday is same\n- ####\tIn September Bike sharing is more\n- ####\tIn 2019 bike sharing is more than 2018\n- ####\tin 2019 Bikes sharing is more for clear weather, in fall season and in September month\n- #### In 2019 Saturdays are having more Bike sharing"},{"metadata":{"trusted":false},"cell_type":"code","source":"df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Removing atemp variable as atemp and temp are having high corelation\ndf.drop(['atemp'], axis = 1, inplace = True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 3: Data Preparation"},{"metadata":{},"cell_type":"markdown","source":"### Dummy Variables"},{"metadata":{"trusted":false},"cell_type":"code","source":" # Creating Dummy Variables from categorical variable\nnew_mnth=pd.get_dummies(df['mnth'],drop_first=True)\nnew_mnth=new_mnth.rename(columns={1:'jan', 2:'feb', 3:'mar', 4:'apr',\n                                  5:'may', 6:'jun', 7:'jul', 8:'aug',\n                                  9:'sep', 10:'oct', 11:'nov', 12:'dec'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"new_mnth","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"new_season = pd.get_dummies(df['season'],drop_first= True)\nnew_season","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"new_week = pd.get_dummies(df['weekday'],drop_first= True)\nnew_week=new_week.rename(columns={0:'sunday', 1:'monday', 2:'tuesday', 3:'wednesday',\n                                  4:'thursday', 5:'friday', 6:'saturday'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"new_week","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"new_weather = pd.get_dummies(df['weathersit'],drop_first= True)\nnew_weather","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df = pd.concat([df, new_mnth, new_season, new_week, new_weather], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.drop(['mnth','season','weekday','weathersit'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Splitting the Data into Training and Testing Sets"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# We specify this so that the train and test data set always have the same rows, respectively\nnp.random.seed(0)\ndf_train, df_test = train_test_split(df, train_size = 0.7, test_size = 0.3, random_state = 100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Rescaling the Features "},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"num_vars =['temp','hum','windspeed']\ndf_train[num_vars] = scaler.fit_transform(df_train[num_vars])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_train.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dividing into X and Y sets for the model building"},{"metadata":{"trusted":false},"cell_type":"code","source":"y_train = df_train.pop('cnt')\nX_train = df_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 4: Building a linear model"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Using RFE \nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"lm = LinearRegression()\nlm.fit(X_train,y_train)\nrfe = RFE(lm,15)\nrfe = rfe.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"list(zip(X_train.columns,rfe.support_,rfe.ranking_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"col= X_train.columns[rfe.support_]\ncol","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train = X_train[col]\nX_train_rfe = X_train[col]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import statsmodels.api as sm\nX_train_rfe= sm.add_constant(X_train_rfe)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train_lm = sm.add_constant(X_train_rfe)\nlm = sm.OLS(y_train,X_train_lm).fit()\nprint(lm.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Checking VIF"},{"metadata":{"trusted":false},"cell_type":"code","source":"from statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dropping the variable and updating the model"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Dropping highly correlated variables and insignificant variables\n# As hum is having infinite VIF dropping it\nX_train_New =X_train.drop(['hum'],1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train_lm = sm.add_constant(X_train_New)\nlm = sm.OLS(y_train,X_train_lm).fit()\nprint(lm.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"\nvif = pd.DataFrame()\nvif['Features'] = X_train_New.columns\nvif['VIF'] = [variance_inflation_factor(X_train_New.values, i) for i in range(X_train_New.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dropping the variable and updating the model"},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train_New1 =X_train_New.drop(['aug'],1)\nX_train_lm1 = sm.add_constant(X_train_New1)\nlm1 = sm.OLS(y_train,X_train_lm1).fit()\nprint(lm1.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"vif = pd.DataFrame()\nvif['Features'] = X_train_New1.columns\nvif['VIF'] = [variance_inflation_factor(X_train_New1.values, i) for i in range(X_train_New1.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dropping the variable and updating the model"},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train_New2 =X_train_New1.drop(['jun'],1)\nX_train_lm2 = sm.add_constant(X_train_New2)\nlm2 = sm.OLS(y_train,X_train_lm2).fit()\nprint(lm2.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"vif = pd.DataFrame()\nvif['Features'] = X_train_New2.columns\nvif['VIF'] = [variance_inflation_factor(X_train_New2.values, i) for i in range(X_train_New2.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dropping the variable and updating the model"},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train_New3 =X_train_New2.drop(['apr'],1)\nX_train_lm3 = sm.add_constant(X_train_New3)\nlm3 = sm.OLS(y_train,X_train_lm3).fit()\nprint(lm3.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"vif = pd.DataFrame()\nvif['Features'] = X_train_New3.columns\nvif['VIF'] = [variance_inflation_factor(X_train_New3.values, i) for i in range(X_train_New3.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dropping the variable and updating the model"},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train_New4 =X_train_New3.drop(['may'],1)\nX_train_lm4 = sm.add_constant(X_train_New4)\nlm4 = sm.OLS(y_train,X_train_lm4).fit()\nprint(lm4.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"vif = pd.DataFrame()\nvif['Features'] = X_train_New4.columns\nvif['VIF'] = [variance_inflation_factor(X_train_New4.values, i) for i in range(X_train_New4.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dropping the variable and Building Final Model"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Final Model\nX_train_New5 =X_train_New4.drop(['mar'],1)\nX_train_lm5 = sm.add_constant(X_train_New5)\nlm_model = sm.OLS(y_train,X_train_lm5).fit()\nprint(lm_model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"vif = pd.DataFrame()\nvif['Features'] = X_train_New5.columns\nvif['VIF'] = [variance_inflation_factor(X_train_New5.values, i) for i in range(X_train_New5.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 5: Assumption Validation"},{"metadata":{"trusted":false},"cell_type":"code","source":"y_train_pred = lm_model.predict(X_train_lm5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### 1. Residual Analysis"},{"metadata":{"trusted":false},"cell_type":"code","source":"res = y_train - y_train_pred\nsns.distplot(res)\nplt.title('Residula plot')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- #### Distribution of error is almost cantered around 0"},{"metadata":{},"cell_type":"markdown","source":"##### 2. Validating Multicollinearity"},{"metadata":{"trusted":false},"cell_type":"code","source":"vif = pd.DataFrame()\nvif['Features'] = X_train_New5.columns\nvif['VIF'] = [variance_inflation_factor(X_train_New5.values, i) for i in range(X_train_New5.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15,8))\nsns.heatmap(X_train_New5.corr(), cmap=\"YlGnBu\", annot = True, ax= ax)\n\nplt.show()\n\n#X_train_New5.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- ##### For all independent variable VIF is less than 5\n- ##### In Heatplot the magnitude of the correlation coefficients should be less than .80\n\n#### Hence Multicollinearity is not there"},{"metadata":{},"cell_type":"markdown","source":"##### 3. Validating Homoscedaticity"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Validating Homoscedasticity\nsns.scatterplot(y_train,res)\nplt.title('Residual vs predicted Value', fontsize= 18)\nplt.xlabel('y_train', fontsize = 16)                        \nplt.ylabel('res', fontsize = 16) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- ##### No clear pattern in the distribution, hence Homoscedasticity is not there"},{"metadata":{},"cell_type":"markdown","source":"## Step 5: Prediction and Evaluation on Test set"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Scaling on Test data\nnum_vars =['temp','hum','windspeed']\ndf_test[num_vars] = scaler.transform(df_test[num_vars])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_test.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_test = df_test.pop('cnt')\nX_test = df_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# add constant to Test data\nX_test_lm = sm.add_constant(X_test)\nX_test_lm.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Drop Variables all the variables not available in our model\nX_test_lm = X_test_lm[['const','yr','holiday','temp','windspeed','sep','spring','winter','Light Snow','Mist']]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_test_lm.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Checking Adjusted R2 and r2 for Test data"},{"metadata":{"trusted":false},"cell_type":"code","source":"# ADjusted R2 for test data\ntest_lm_model = sm.OLS(y_test,X_test_lm).fit()\nprint(test_lm_model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# predict\ny_test_pred = lm_model.predict(X_test_lm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Evaluation r2 score for Test data\nfrom sklearn.metrics import r2_score,mean_squared_error\nmse = mean_squared_error(y_test, y_test_pred)\nr_squared=r2_score(y_true= y_test,y_pred=y_test_pred)\nprint('Mean_Squared_Error :' ,mse)\nprint('r_square_value :',r_squared)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Evaluation r2 score for Train data\nmse = mean_squared_error(y_train, y_train_pred)\nr_squared=r2_score(y_true= y_train,y_pred=y_train_pred)\nprint('Mean_Squared_Error :' ,mse)\nprint('r_square_value :',r_squared)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- ##### variance between r2_score of test and train data is within 5%"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Plotting y_test and y_pred to understand the spread\n\nfig = plt.figure()\nplt.scatter(y_test, y_test_pred)\nfig.suptitle('y_test vs y_test_pred', fontsize = 20)               \nplt.xlabel('y_test', fontsize = 18)                           \nplt.ylabel('y_test_pred', fontsize = 16)  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n#### Linear equation for Best fit line:\n\n$ price = 2045.7061  \\times  yr - 843.2761  \\times  holiday + 3544.8227 \\times temp - 1178.3391 \\times windspeed + 608.3051 \\times sep - 1009.8409 \\times spring + 416.8524 \\times winter - 2507.3109 \\times light snow - 683.1661 \\times Mist $"},{"metadata":{},"cell_type":"markdown","source":"### Recommendation: \n#### Bike sharing is decreasing in below conditions:\n- ###### If it holiday\n- ###### In spring season\n- ###### In light snow and mist season\n- ###### In windspeed\n#### Bike sharing is Increasing in below conditions:\n- ###### In Year 2019\n- ###### In Winter and September month\n- ###### Increasing based on temp"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}