{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Library\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport librosa\nimport librosa.display\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport tensorflow.keras.models as models\nimport tensorflow.keras.layers as layers\nimport IPython\nimport sklearn\nimport seaborn as sns\nfrom sklearn.utils import shuffle\n\n%load_ext tensorboard","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-26T16:15:42.803707Z","iopub.execute_input":"2021-05-26T16:15:42.804067Z","iopub.status.idle":"2021-05-26T16:15:49.784843Z","shell.execute_reply.started":"2021-05-26T16:15:42.803988Z","shell.execute_reply":"2021-05-26T16:15:49.784049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#This notebook use ESC-50 datasets on Kaggle Kernel, follow the step on README for further instructions.\nCSV_ESC = \"../input/environmental-sound-classification-50/esc50.csv\"  # path of csv file\nDATA_ESC = \"../input/environmental-sound-classification-50/audio/audio/16000/\" # path to folder containing audio files\n\nCSV_URBAN = \"../input/urbansound8k/UrbanSound8K.csv\"\nDATA_URBAN = \"../input/urbansound8k/fold\"\n# Reading the CSV File\ndf1 = pd.read_csv(CSV_ESC)\ndf2 = pd.read_csv(CSV_URBAN)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T16:15:49.786686Z","iopub.execute_input":"2021-05-26T16:15:49.787011Z","iopub.status.idle":"2021-05-26T16:15:49.835887Z","shell.execute_reply.started":"2021-05-26T16:15:49.786982Z","shell.execute_reply":"2021-05-26T16:15:49.835246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Coba liat kode diatas, pertama ganti kolom kolomnya biar mirip\ndf_esc = df1.drop(columns=['esc10','src_file','take'])\n\ndf_urban = df2.drop(columns=['fsID', 'start', 'end', 'salience'])\ndf_urban = df_urban.rename(columns={'slice_file_name':'filename', 'class':'category', 'classID':'target'})\n\n# Disini dua duanya df udah sama persis\n\n# Keep in mind ada beberapa category tuh yang sama, kyk dog dan dog_bark, ini perlu dibersihin juga tapi ntaran\n# Next kita tambahin sumber pada tiap dataframe\ndf_esc['source'] = \"esc\"\ndf_urban['source'] = \"urban\"\n\n# for fold_iterate in range(6,11):\n#     df_urban.loc[df_urban.fold == fold_iterate, 'fold'] = fold_iterate-5\n\n# print(df_esc.head())\n# print(df_urban.head())\n\n# Btw dog_bark gw samain dengan dog dlu ya\ndf_urban.loc[df_urban.category == 'dog_bark', \"category\"] = \"dog\"\n\n# Sekarang gabungin 2 dataframenya yuhu\ndf_combine = pd.concat([df_esc, df_urban])\n\n# Next, tiap hasil category harus kita kasi id buat penanda dan jadi output di model\n# Ini list category yang ada\nclasses = df_combine['category'].unique()\n# Ini bikin ID untuk tiap category\nclass_dict = {i:x for x,i in enumerate(classes)}\n#print(class_dict)\n#print(len(classes))\n\n# Terus kalo udah pnya dictionarynya, kita taruh nilai ID targetnya ke column 'target'\ndf_combine['target'] = df_combine['category'].map(class_dict)\n\ndf_combine\n# Udah kelar nih, tinggal kita preprocessing jadi melspectogram cuy","metadata":{"execution":{"iopub.status.busy":"2021-05-26T16:15:49.836952Z","iopub.execute_input":"2021-05-26T16:15:49.837299Z","iopub.status.idle":"2021-05-26T16:15:49.878002Z","shell.execute_reply.started":"2021-05-26T16:15:49.837262Z","shell.execute_reply":"2021-05-26T16:15:49.877196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Yang ini ga ada perubahan","metadata":{}},{"cell_type":"code","source":"# Class Conf will save the settings we are going to use in this notebook\nclass conf:\n    sr = 16000\n    duration = 3\n    hop_length = 340*duration\n    fmin = 20\n    fmax = sr // 2\n    n_mels = 128\n    n_fft = n_mels * 20\n    samples = sr * duration\n    epochs = 30\n\ndef read_audio(conf, pathname, trim_long_data):\n    y, sr = librosa.load(pathname, sr=conf.sr)\n    # trim silence\n    if 0 < len(y): # workaround: 0 length causes error\n        y, _ = librosa.effects.trim(y) # trim, top_db=default(60)\n    # make it unified length to conf.samples\n    if len(y) > conf.samples: # long enough\n        if trim_long_data:\n            y = y[0:0+conf.samples]\n    else: # pad blank\n        padding = conf.samples - len(y)    # add padding at both ends\n        offset = padding // 2\n        y = np.pad(y, (offset, conf.samples - len(y) - offset), 'constant')\n    return y\n\ndef audio_to_melspectrogram(conf, audio):\n    spectrogram = librosa.feature.melspectrogram(audio, \n                                                 sr=conf.sr,\n                                                 n_mels=conf.n_mels,\n                                                 hop_length=conf.hop_length,\n                                                 n_fft=conf.n_fft,\n                                                 fmin=conf.fmin,\n                                                 fmax=conf.fmax)\n    spectrogram = librosa.power_to_db(spectrogram)\n    return spectrogram\n\ndef show_melspectrogram(conf, mels, title='Log-frequency power spectrogram'):\n    librosa.display.specshow(mels, x_axis='time', y_axis='mel', \n                             sr=conf.sr, hop_length=conf.hop_length,\n                            fmin=conf.fmin, fmax=conf.fmax)\n    plt.colorbar(format='%+2.0f dB')\n    plt.title(title)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T16:15:49.879604Z","iopub.execute_input":"2021-05-26T16:15:49.879941Z","iopub.status.idle":"2021-05-26T16:15:49.890566Z","shell.execute_reply.started":"2021-05-26T16:15:49.879907Z","shell.execute_reply":"2021-05-26T16:15:49.889497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# lanjut ke preprocess\n","metadata":{}},{"cell_type":"code","source":"INPUTSHAPE = (128, 32, 1)\ndef create_model():\n    created_model =  models.Sequential([\n        layers.Conv2D(64 , (3,3),activation = 'relu',padding='same', input_shape = INPUTSHAPE),\n        layers.BatchNormalization(),\n        layers.Conv2D(64, (3,3), activation='relu',padding='same'),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D((2,2), strides=(2,2)),\n        layers.Dropout(0.2),\n\n        layers.Conv2D(128, (3,3), activation='relu',padding='same'),                      \n        layers.BatchNormalization(),\n        layers.Conv2D(128, (3,3), activation='relu',padding='same'),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D((2,2), strides=(2,2)),\n        layers.Dropout(0.2),\n\n        layers.Conv2D(256, (3,3), activation='relu',padding='same'),\n        layers.BatchNormalization(),\n        layers.Conv2D(256, (3,3), activation='relu',padding='same'),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D((2,2), strides=(2,2)),    \n        layers.Dropout(0.2),\n\n        layers.GlobalAveragePooling2D(),\n\n        layers.Dense(256 , activation = 'relu'),\n        layers.Dense(256 , activation = 'relu'),\n        layers.Dense(len(classes) , activation = 'softmax')\n    ])\n\n    created_model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics=['acc'])\n    return created_model","metadata":{"execution":{"iopub.status.busy":"2021-05-26T16:15:57.095658Z","iopub.execute_input":"2021-05-26T16:15:57.095976Z","iopub.status.idle":"2021-05-26T16:15:57.105583Z","shell.execute_reply.started":"2021-05-26T16:15:57.095945Z","shell.execute_reply":"2021-05-26T16:15:57.1047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Our model summary\nmodel = create_model()\nprint(model.summary())\n%mkdir \"cpkt\"\n%mkdir \"logs\"\nLOGDIR = \"logs\"\nCPKT = \"cpkt/\"\n\n#this callback is used to prevent overfitting.\ncallback_1 = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto',\n    baseline=None, restore_best_weights=False\n)\n\n#this checkpoint saves the best weights of model at every epoch\ncallback_2 = tf.keras.callbacks.ModelCheckpoint(\n    CPKT, monitor='val_loss', verbose=0, save_best_only=True,\n    save_weights_only=True, mode='auto', save_freq='epoch', options=None\n)\n\n#this is for tensorboard\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=LOGDIR)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T16:15:58.014881Z","iopub.execute_input":"2021-05-26T16:15:58.015244Z","iopub.status.idle":"2021-05-26T16:16:02.237885Z","shell.execute_reply.started":"2021-05-26T16:15:58.015207Z","shell.execute_reply":"2021-05-26T16:16:02.236693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train , y_train = [] , []\nx_val , y_val = [] , []\n\nfor data in df_combine[1998:2002].itertuples():\n    print(data)\n    if(data[5]=='esc'):\n        sig , sr = librosa.load(DATA_ESC+data[1], sr=16000)\n    else:\n        sig , sr = librosa.load(DATA_URBAN + str(data[2]) + '/' + data[1], sr=16000)\n    #Creating three random 2 second clip from each audio file, to create more samples\n    for i in range(4):\n        print(len(sig)/16000)\n        sig_ = sig[i : int((i+2)+sr)]\n        mel_spec = audio_to_melspectrogram(conf, sig_)\n        print(mel_spec.shape)\n        x_train.append(mel_spec)\n        y_train.append(data[3])\n","metadata":{"execution":{"iopub.status.busy":"2021-05-26T16:43:11.569096Z","iopub.execute_input":"2021-05-26T16:43:11.569449Z","iopub.status.idle":"2021-05-26T16:43:12.071487Z","shell.execute_reply.started":"2021-05-26T16:43:11.569419Z","shell.execute_reply":"2021-05-26T16:43:12.070154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Bagian sini diubah\nAku kasi If Else disini\nSisanya sama kyk yg sebelumnya","metadata":{}},{"cell_type":"code","source":"def preprocess(fold):\n    x_train , y_train = [] , []\n    x_val , y_val = [] , []\n    \n    train_df = df_combine[df_combine.fold == fold]\n    val_df = df_combine[df_combine.fold == fold]\n    \n    for data in df_combine[1990:2020].itertuples():\n        print(data[0])\n        if(data[5]=='esc'):\n            sig , sr = librosa.load(DATA_ESC+data[1], sr=16000)\n        else:\n            sig , sr = librosa.load(DATA_URBAN + str(data[2]) + '/' + data[1], sr=16000)\n        #Creating three random 2 second clip from each audio file, to create more samples\n        for i in range(4):\n            sig_ = sig[i : int((i+2)+sr)]\n            mel_spec = audio_to_melspectrogram(conf, sig_)\n            x_train.append(mel_spec)\n            y_train.append(data[3])\n\n    for data in df_combine[1990:2020].itertuples():\n        print(data[0])\n        if(data[5]=='esc'):\n            sig , sr = librosa.load(DATA_ESC+data[1], sr=16000)\n        else:\n            sig , sr = librosa.load(DATA_URBAN + str(data[2]) + '/' + data[1], sr=16000)\n        #Creating three random 2 second clip from each audio file, to create more samples\n        for i in range(4):\n            sig_ = sig[i : int((i+2)+sr)]\n            mel_spec = audio_to_melspectrogram(conf, sig_)\n            x_val.append(mel_spec)\n            y_val.append(data[3])\n            \n    # convert list to numpy array\n    x_train = np.array(x_train)\n    y_train = np.array(y_train)\n    \n    x_val = np.array(x_val)\n    y_val = np.array(y_val)\n\n    #one-hot encoding the target\n    y_train = tf.keras.utils.to_categorical(y_train , num_classes=len(classes))\n    y_val = tf.keras.utils.to_categorical(y_val , num_classes=len(classes))\n\n    # our tensorflow model takes input as (no_of_sample , height , width , channel).\n    # here X has dimension (no_of_sample , height , width).\n    # So, the below code will reshape it to (no_of_sample , height , width , 1).\n    x_train, y_train = shuffle(x_train, y_train)\n    x_val, y_val = shuffle(x_val, y_val)\n    \n    x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n    x_val = x_val.reshape(x_val.shape[0], x_val.shape[1], x_val.shape[2], 1)\n    \n    return (x_train, y_train, x_val, y_val)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T16:37:43.843499Z","iopub.execute_input":"2021-05-26T16:37:43.843825Z","iopub.status.idle":"2021-05-26T16:37:43.861849Z","shell.execute_reply.started":"2021-05-26T16:37:43.843796Z","shell.execute_reply":"2021-05-26T16:37:43.86079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#save the model history in a list after fitting so that we can plot later\nmodel_history = []\nmetrics = []\n\n\n# The training section will use k-fold cross validation, just as suggested by the dataset creator.\n# Cross Validation training will make a more robust model and prevent bias on training.\nfor fold in range(1, 6):\n    print('\\n\\nTraining fold', fold)\n    print('*' * 20)\n    \n    x_train, y_train, x_val, y_val = preprocess(fold)\n    model = create_model()\n    history = model.fit(x_train,y_train ,\n            validation_data=(x_val,y_val),\n            epochs=conf.epochs,\n            callbacks = [callback_1], verbose=2)\n    eval_score = model.evaluate(x_val, y_val)\n    print(\"Val Score: \",eval_score )\n    model_history.append(history)\n    metrics.append(eval_score)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T16:37:48.082006Z","iopub.execute_input":"2021-05-26T16:37:48.082374Z","iopub.status.idle":"2021-05-26T16:37:56.582858Z","shell.execute_reply.started":"2021-05-26T16:37:48.082343Z","shell.execute_reply":"2021-05-26T16:37:56.581306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}