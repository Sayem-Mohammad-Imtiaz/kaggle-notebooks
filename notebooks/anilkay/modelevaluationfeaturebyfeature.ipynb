{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data=pd.read_csv(\"/kaggle/input/bank-marketing-dataset/bank.csv\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Okay, I think balance and deposit have strong negative correlation. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\ndata[\"deposit_numeric\"]=le.fit_transform(data[\"deposit\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[[\"balance\",\"deposit_numeric\"]].corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Interesting correlation is weak. Maybe outlier values effect it's too much."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new=data[(data[\"balance\"]>122) & (data[\"balance\"]>2000)]\ndata_new[[\"balance\",\"deposit_numeric\"]].corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Even Smaller. Maybe if balance is negative all say yes to deposit."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new=data[(data[\"balance\"]<-100)]\ndata_new[\"deposit\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Okay we see more clear observation. Ä°f balance is negative it's more likely to say no to deposit. "},{"metadata":{},"cell_type":"markdown","source":"## Okay what about balance with age?"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.figure(figsize=(15,12))\nsns.relplot(data=data,x=\"age\",y=\"balance\",hue=\"deposit\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Okay can't clearly separable also with age and balance variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.figure(figsize=(15,12))\nsns.relplot(data=data,x=\"balance\",y=\"campaign\",hue=\"deposit\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Okay also can't clearly separable. "},{"metadata":{},"cell_type":"markdown","source":"Okay now we see all correlations."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,16))\nsns.heatmap(data.corr(),annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Deposit numeric has strong correlation with duration it's interesting. "},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.figure(figsize=(15,12))\nsns.relplot(data=data,x=\"balance\",y=\"duration\",hue=\"deposit\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Okay this 2 is more separable than others. Hovewer it isn't perfect."},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.figure(figsize=(15,12))\nsns.relplot(data=data,x=\"age\",y=\"duration\",hue=\"deposit\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Okay with these 3 feature (Age, Balance and Duration) we will have good results. "},{"metadata":{"trusted":true},"cell_type":"code","source":"x=data[[\"age\",\"duration\",\"balance\"]]\ny=data[\"deposit_numeric\"]\n\nfrom sklearn.naive_bayes import GaussianNB\nnaive_bayes=GaussianNB()\nfrom sklearn.model_selection import cross_val_score\nscores_naive = cross_val_score(naive_bayes, x, y, cv=10)\nprint(\"Naive Bayes\")\nscores_naive","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Okay naive bayes's result is not stable. Naive Bayes can't work fine with bigger datasets."},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import CatBoostClassifier\n\n\ncatb = CatBoostClassifier(iterations=1000,verbose=0)\n\nscores_catb = cross_val_score(catb, x, y, cv=10)\nprint(\"Catboost\")\nprint(scores_catb)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Worst better than naive bayes but also not that great. Okay we see classical train test split result."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=142)\ncatb = CatBoostClassifier(iterations=1000,verbose=0)\n\ncatb.fit(x_train,y_train)\nypred=catb.predict(x_test)\n\nimport sklearn.metrics as metrik\nprint(metrik.confusion_matrix(y_true=y_test,y_pred=ypred))\nprint(metrik.accuracy_score(y_true=y_test,y_pred=ypred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Okay only 3 feature and result is fine. Accuracy is %75."},{"metadata":{},"cell_type":"markdown","source":"## With all the features:"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nx_full=data.iloc[:,0:16]\nxfull_train, xfull_test, y_train, y_test = train_test_split(x_full, y, test_size=0.25, random_state=142)\n\ncategorical_features_indices = np.where(x_full.dtypes != np.float)[0]\n\ncatb = CatBoostClassifier(iterations=1000,verbose=0,cat_features=categorical_features_indices)\n\ncatb.fit(xfull_train,y_train)\nypred=catb.predict(xfull_test)\n\nimport sklearn.metrics as metrik\nprint(metrik.confusion_matrix(y_true=y_test,y_pred=ypred))\nprint(metrik.accuracy_score(y_true=y_test,y_pred=ypred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With all features. Accuracy is %85 and confusion matrix also looks just fine. "},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ncatb = CatBoostClassifier(verbose=0,cat_features=categorical_features_indices)\n\ncatb.fit(xfull_train,y_train)\nypred=catb.predict(xfull_test)\n\nimport sklearn.metrics as metrik\nprint(metrik.confusion_matrix(y_true=y_test,y_pred=ypred))\nprint(metrik.accuracy_score(y_true=y_test,y_pred=ypred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Okay, Categorical variables have important informations. Add some Categorical features too our 3 feature model."},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Add marital status and loan effected most I think."},{"metadata":{"trusted":true},"cell_type":"code","source":"x=data[[\"age\",\"duration\",\"balance\",\"marital\",\"loan\"]]\ny=data[\"deposit_numeric\"]\n\n\ncatb = CatBoostClassifier(verbose=0,cat_features=[3,4])\n\nscores_catb = cross_val_score(catb, x, y, cv=10)\nprint(\"Catboost\")\nprint(scores_catb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=142)\ncatb = CatBoostClassifier(verbose=0,cat_features=[3,4])\n\ncatb.fit(x_train,y_train)\nypred=catb.predict(x_test)\n\nimport sklearn.metrics as metrik\nprint(metrik.confusion_matrix(y_true=y_test,y_pred=ypred))\nprint(metrik.accuracy_score(y_true=y_test,y_pred=ypred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Slightly better maybe job is the most important categorical features."},{"metadata":{"trusted":true},"cell_type":"code","source":"x=data[[\"age\",\"duration\",\"balance\",\"marital\",\"loan\",\"job\"]]\ny=data[\"deposit_numeric\"]\n\n\ncatb = CatBoostClassifier(verbose=0,cat_features=[3,4,5])\n\nscores_catb = cross_val_score(catb, x, y, cv=10)\nprint(\"Catboost\")\nprint(scores_catb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=142)\ncatb = CatBoostClassifier(verbose=0,cat_features=[3,4,5])\n\ncatb.fit(x_train,y_train)\nypred=catb.predict(x_test)\n\nimport sklearn.metrics as metrik\nprint(metrik.confusion_matrix(y_true=y_test,y_pred=ypred))\nprint(metrik.accuracy_score(y_true=y_test,y_pred=ypred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Now Delete Marital and loan features and only use job categorical variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"x=data[[\"age\",\"duration\",\"balance\",\"job\"]]\ny=data[\"deposit_numeric\"]\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=142)\ncatb = CatBoostClassifier(verbose=0,cat_features=[3])\n\ncatb.fit(x_train,y_train)\nypred=catb.predict(x_test)\n\nimport sklearn.metrics as metrik\nprint(metrik.confusion_matrix(y_true=y_test,y_pred=ypred))\nprint(metrik.accuracy_score(y_true=y_test,y_pred=ypred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we add education."},{"metadata":{"trusted":true},"cell_type":"code","source":"x=data[[\"age\",\"duration\",\"balance\",\"job\",\"education\"]]\ny=data[\"deposit_numeric\"]\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=142)\ncatb = CatBoostClassifier(verbose=0,cat_features=[3,4])\n\ncatb.fit(x_train,y_train)\nypred=catb.predict(x_test)\n\nimport sklearn.metrics as metrik\nprint(metrik.confusion_matrix(y_true=y_test,y_pred=ypred))\nprint(metrik.accuracy_score(y_true=y_test,y_pred=ypred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=data[[\"age\",\"duration\",\"balance\",\"job\",\"education\",\"housing\"]]\ny=data[\"deposit_numeric\"]\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=142)\ncatb = CatBoostClassifier(verbose=0,cat_features=[3,4,5])\n\ncatb.fit(x_train,y_train)\nypred=catb.predict(x_test)\n\nimport sklearn.metrics as metrik\nprint(metrik.confusion_matrix(y_true=y_test,y_pred=ypred))\nprint(metrik.accuracy_score(y_true=y_test,y_pred=ypred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=data[[\"age\",\"duration\",\"balance\",\"job\",\"education\",\"housing\",\"marital\"]]\ny=data[\"deposit_numeric\"]\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=142)\ncatb = CatBoostClassifier(verbose=0,cat_features=[3,4,5,6])\n\ncatb.fit(x_train,y_train)\nypred=catb.predict(x_test)\n\nimport sklearn.metrics as metrik\nprint(metrik.confusion_matrix(y_true=y_test,y_pred=ypred))\nprint(metrik.accuracy_score(y_true=y_test,y_pred=ypred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=data[[\"age\",\"duration\",\"balance\",\"campaign\",\"job\",\"education\",\"housing\",\"marital\"]]\ny=data[\"deposit_numeric\"]\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=142)\ncatb = CatBoostClassifier(verbose=0,cat_features=[4,5,6,7])\n\ncatb.fit(x_train,y_train)\nypred=catb.predict(x_test)\n\nimport sklearn.metrics as metrik\nprint(metrik.confusion_matrix(y_true=y_test,y_pred=ypred))\nprint(metrik.accuracy_score(y_true=y_test,y_pred=ypred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importances=catb.get_feature_importance()\nfeatures=[\"age\",\"duration\",\"balance\",\"campaign\",\"job\",\"education\",\"housing\",\"marital\"]\nfor i in range(0,len(importances)):\n    print(features[i],\": \",importances[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Duration is the most important featues. First five feature leads all features. Job is more important than education and marital."},{"metadata":{},"cell_type":"markdown","source":"Campaign also not that important."},{"metadata":{"trusted":true},"cell_type":"code","source":"x=data[[\"age\",\"duration\",\"balance\",\"pdays\",\"job\",\"education\",\"housing\"]]\ny=data[\"deposit_numeric\"]\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=142)\ncatb = CatBoostClassifier(verbose=0,cat_features=[4,5,6])\n\ncatb.fit(x_train,y_train)\nypred=catb.predict(x_test)\n\nimport sklearn.metrics as metrik\nprint(metrik.confusion_matrix(y_true=y_test,y_pred=ypred))\nprint(metrik.accuracy_score(y_true=y_test,y_pred=ypred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importances=catb.get_feature_importance()\nfeatures=x.columns\nfor i in range(0,len(importances)):\n    print(features[i],\": \",importances[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pdays also an important column. Duration and Pdays is the most important features. Also with these 7 features we %81.5 accuracy. Ä°t is better than I expected. This model is usable enough."},{"metadata":{"trusted":true},"cell_type":"code","source":"catb.save_model(\"model7features\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Thanks for Reading :)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}