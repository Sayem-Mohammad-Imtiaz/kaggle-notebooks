{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Abstract\nAnalyze data from Mushroom Classification dataset to classify the mushrooms and find which are edible and which are poisonous."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Importing and printing dataset"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/mushroom-classification/mushrooms.csv')\nprint(data.shape)\ndata.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***\n### Preparing the Mushroom Classification dataset\n<p>I have to transform non-numerical labels (as long as they are hashable and comparable) to numerical labels.<br/>\nI use sklearn.preprocessing.LabelEncoder to do that and fit label encoder and return encoded labels.</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\n\nle = preprocessing.LabelEncoder()\nfor i in range(0,23):\n    data.iloc[:,i] = le.fit_transform(data.iloc[:,i])\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the column \"class\" the values are: 1=edible, 0=poisonous.\n***\n### Drop non-relevant column\nFrom the table above it can be seen that the column \"veil-type\" is 0 and not contributing to the data so I remove it."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature selection: remove variables no longer containing relevant information\ndata=data.drop([\"veil-type\"],axis=1)\ndata.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Check attributes correlation\nNow explore the relationship between variables by plotting the Pearson Correlation between all the attributes in dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Imports needed for the script\nimport seaborn as sns # making statistical graphics in Python\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ncolormap = plt.cm.viridis\n\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(data.astype(float).corr(),linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this case the attribute \"gill-color\" show the lower correlation value (in absolute terms) with the \"class\" attribute: -0.53. That means highest importance for the classification."},{"metadata":{"trusted":true},"cell_type":"code","source":"data[['class', 'gill-color']].groupby(['gill-color'], as_index=False).mean().sort_values(by='class', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data shows each type of gill-color with the percentage of the mushrooms (of that type) that are edible. The rest are poisonous. For example: gill-color=\"4\"(black) has 15% of mushrooms that are edible and 85% that are poisonous."},{"metadata":{},"cell_type":"markdown","source":"#### Creating training set and test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import train_test_split\nfrom sklearn.model_selection import train_test_split\n\n#Split data into 70% training and 30% test\nX=data.drop(['class'], axis=1)\ny=data['class']\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 2)\n\n\n#train_pct_index = int(0.7 * len(X))\n#X_train, X_test = X[:train_pct_index], X[train_pct_index:]\n#y_train, y_test = y[:train_pct_index], y[train_pct_index:]\n\nprint(\"Total number of data examples \" + str(len(data.index)))\nprint(\"Number of training data examples \"+str(len(X_train.index)))\nprint(\"Number of test data examples \"+str(len(X_test.index)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Decision Tree Classifier\nThe goal of the Decision Trees learning algorithms is always to find the best split for each node of the tree.\nFor measuring the \"godness\" we are trying two criteria:\n* entropy\n* gini index"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import DecisionTreeClassifier\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz\n# Import accuracy_score\nfrom sklearn.metrics import accuracy_score\n\n# Instantiate dt\ndt = DecisionTreeClassifier(criterion=\"entropy\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Measure the impurity of a node using entropy:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit dt to the training set\ndt.fit(X_train,y_train)\n# Predict test set labels\ny_pred = dt.predict(X_test)\n# Evaluate test-set accuracy\nprint(\"Accuracy score on the test set: \"+str(accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Print decision tree\nimport graphviz\ndot_data = export_graphviz(dt, feature_names=X.columns, filled=True, rounded=True, special_characters=True)\ngraph = graphviz.Source(dot_data) \ngraph","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tree accuracy is 100% and this value means clearly overfitting.\nI tried to modify the depth of the tree, saving accuracy to each step and plot it to verify at which tree depth the model begins to overfit. For this purpose I use Cross Validation method."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\n\ndef computeCVAccuracy(X,y):\n    accuracy=[]\n    foldAcc=[]\n    for i in range(1,21): \n        kf = KFold(10,False) # K-Folds cross-validator: 10 split\n        for train_index, test_index in kf.split(X):\n            X_train, X_test,y_train,y_test = train_test_split(X,y, test_size = 0.1)\n            clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth = i).fit(X_train, y_train)\n            score=clf.score(X_test, y_test)\n            accuracy.append(score)     \n        foldAcc.append(np.mean(accuracy))  \n    return(foldAcc)\n    \ncvAccuracy=computeCVAccuracy(X,y)\n\ndf1=pd.DataFrame(cvAccuracy)\ndf1.columns=['10-fold cv Accuracy']\ndf=df1.reindex(range(1,20))\ndf.plot()\nplt.title(\"Decision Tree - 10-fold Cross Validation Accuracy vs Depth of tree\")\nplt.xlabel(\"Depth of tree\")\nplt.ylabel(\"Accuracy\")\nplt.ylim([0.8,1])\nplt.xlim([0,20])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Measure the impurity of a node using Gini index:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Instantiate dt2, set 'criterion' to 'gini'\ndt2 = DecisionTreeClassifier(criterion='gini', random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit dt to the training set\ndt2.fit(X_train,y_train)\n# Predict test set labels\ny_pred2 = dt2.predict(X_test)\n# Evaluate test-set accuracy\nprint(\"Accuracy score on the test set: \"+str(accuracy_score(y_test, y_pred2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dot_data = export_graphviz(dt2, out_file=None, \n                         feature_names=X.columns,  \n                         filled=True, rounded=True,  \n                         special_characters=True)  \ngraph = graphviz.Source(dot_data)  \ngraph ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The first line of each node (except those of the final row) shows the splitting condition in the form \"feature <= value\".\nNext, we find the Gini Impurity of the node. \"Samples\" is simply the number of observations contained in the node.\n\"Value\" shows the class distribution of the samples ([edible,poisonous])."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\n\ndef computeCVAccuracy(X,y):\n    accuracy=[]\n    foldAcc=[]\n    for i in range(1,21): \n        kf = KFold(10,False) # K-Folds cross-validator: 10 split\n        for train_index, test_index in kf.split(X):\n            X_train, X_test,y_train,y_test = train_test_split(X,y, test_size = 0.1)\n            clf = DecisionTreeClassifier(criterion=\"gini\",max_depth = i).fit(X_train, y_train)\n            score=clf.score(X_test, y_test)\n            accuracy.append(score)     \n        foldAcc.append(np.mean(accuracy))  \n    return(foldAcc)\n    \ncvAccuracy=computeCVAccuracy(X,y)\n\ndf1=pd.DataFrame(cvAccuracy)\ndf1.columns=['10-fold cv Accuracy']\ndf=df1.reindex(range(1,20))\ndf.plot()\nplt.title(\"Decision Tree - 10-fold Cross Validation Accuracy vs Depth of tree\")\nplt.xlabel(\"Depth of tree\")\nplt.ylabel(\"Accuracy\")\nplt.ylim([0.8,1])\nplt.xlim([0,20])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}