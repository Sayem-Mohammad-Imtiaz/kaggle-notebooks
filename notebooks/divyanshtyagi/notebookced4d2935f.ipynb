{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\ndevice_name = tf.test.gpu_device_name()\nif device_name != '/device:GPU:0':\n  raise SystemError('GPU device not found')\nprint('Found GPU at: {}'.format(device_name))","metadata":{"id":"DRMPm5AZxatf","outputId":"bbaf1cc7-1ce4-4e84-ac14-a3e91476752f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport pandas as pd\nfrom tqdm.notebook import tqdm\npd.options.mode.chained_assignment = None","metadata":{"id":"rlJITbmMxjAx","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/cleanedhatespeechdataset/cleaned-tweets.csv\")\n\n# Make the dataframe rows accessible by loc or iloc with their respective id in the id column \n# df.set_index('id', inplace=True)","metadata":{"id":"SFkZIQpcxtrJ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"id":"sLvL8cmEyXtC","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.label.value_counts()","metadata":{"id":"NuzqaDCjy_YN","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"id":"3WzpmXnVzZFA"}},{"cell_type":"code","source":"\nfrom sklearn.model_selection import train_test_split","metadata":{"id":"kcLtJRX0zMpg","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nX_train, X_val, y_train, y_val = train_test_split(\n    df.index.values, \n    df.label.values, \n    test_size = 0.15,\n    random_state = 17,\n    stratify = df.label.values\n)","metadata":{"id":"Ok_4OBu4zUXy","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['data_type'] = ['not_set']* df.shape[0]\ndf.loc[X_train, 'data_type'] = 'train'\ndf.loc[X_val, 'data_type'] = 'val'","metadata":{"id":"MRPVrqVMzZlU","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.groupby([ 'label', 'data_type']).count()","metadata":{"id":"J11KqjmU0Bxw","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom transformers import BertTokenizer\nfrom torch.utils.data import TensorDataset","metadata":{"id":"S-8PZDAI0FvR","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)","metadata":{"id":"FCh_ARS80JLy","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_data_train = tokenizer.batch_encode_plus(\n    df[df.data_type == 'train'].tweet.values,\n    add_special_tokens = True,\n    return_attention_mask = True,\n    pad_to_max_length = True,\n    max_length = 256,\n    return_tensors = 'pt'\n)\n\nencoded_data_val = tokenizer.batch_encode_plus(\n    df[df.data_type == 'val'].tweet.values,\n    add_special_tokens = True,\n    return_attention_mask = True,\n    pad_to_max_length = True,\n    max_length = 256,\n    return_tensors = 'pt'\n)\n\ninput_ids_train = encoded_data_train['input_ids']\nattention_masks_train = encoded_data_train['attention_mask']\nlabels_train = torch.tensor(df[df.data_type == 'train'].label.values)\n\ninput_ids_val = encoded_data_val['input_ids']\nattention_masks_val = encoded_data_val['attention_mask']\nlabels_val = torch.tensor(df[df.data_type == 'val'].label.values)","metadata":{"id":"TUvtJfxX0K3y","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\ndataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)","metadata":{"id":"gqg2kmIy0Q0_","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import BertForSequenceClassification","metadata":{"id":"mlCRNOnP0nN2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodel = BertForSequenceClassification.from_pretrained(\n    'bert-base-uncased',\n    num_labels = 2,\n    output_attentions = False,\n    output_hidden_states = False\n)\nfrom transformers import BertForSequenceClassification, BertConfig\n\n","metadata":{"id":"LEbS_t_90pc4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, RandomSampler, SequentialSampler","metadata":{"id":"3ItSIsnO0syi","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 4 #32\ndataloader_train = DataLoader(\n    dataset_train,\n    sampler = RandomSampler(dataset_train),\n    batch_size = batch_size\n)\n\ndataloader_val = DataLoader(\n    dataset_val,\n    sampler = SequentialSampler(dataset_val),\n    batch_size = 32\n)","metadata":{"id":"I3ZOOd3W1Gdn","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AdamW, get_linear_schedule_with_warmup","metadata":{"id":"F2D7fdfc1NLP","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\noptimizer = AdamW(\n    model.parameters(),\n    lr = 1e-5, #2e-5 to 5e-5\n    eps = 1e-8\n)","metadata":{"id":"kA6FPPBi1Pvz","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 15\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps = 0,\n    num_training_steps = len(dataloader_train)*epochs\n)","metadata":{"id":"XviYZlxS1Rnd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np","metadata":{"id":"2t7EVWet1TmN","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom sklearn.metrics import f1_score\n\ndef f1_score_func(preds, labels):\n    preds_flat = np.argmax(preds, axis = 1).flatten()\n    labels_flat = labels.flatten()\n    return f1_score(labels_flat, preds_flat, average=\"weighted\")","metadata":{"id":"li_vMDg21V8p","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def accuracy_per_class(preds, labels):\n    labels_dict_inverse = {v: k for k,v in label_dict.items()}\n    preds_flat = np.argmax(preds, axis = 1).flatten()\n    labels_flat = labels.flatten()\n    \n    for label in np.unique(labels_flat):\n        y_preds = preds_flat[labels_flat == label]\n        y_true = labels_flat[labels_flat == label]\n        print('Class: {}'.format(labels_dict_inverse[label]))\n        print('Accuracy: {}\\n'.format( len(y_preds[y_preds == label]) / len(y_true)) )","metadata":{"id":"I4f7E-wl1evT","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\n\nseed_val = 17\nrandom.seed(seed_val)\nnp.random.seed(seed_val)\ntorch.manual_seed(seed_val)\ntorch.cuda.manual_seed_all(seed_val)","metadata":{"id":"dj6k4Qum1hej","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\n\nprint(device)","metadata":{"id":"68vO42DR1jtZ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef evaluate(dataloader_val):\n\n    model.eval()\n    \n    loss_val_total = 0\n    predictions, true_vals = [], []\n    \n    for batch in tqdm(dataloader_val):\n        \n        batch = tuple(b.to(device) for b in batch)\n        \n        inputs = {'input_ids':      batch[0],\n                  'attention_mask': batch[1],\n                  'labels':         batch[2],\n                 }\n\n        with torch.no_grad():        \n            outputs = model(**inputs)\n            \n        loss = outputs[0]\n        logits = outputs[1]\n        loss_val_total += loss.item()\n\n        logits = logits.detach().cpu().numpy()\n        label_ids = inputs['labels'].cpu().numpy()\n        predictions.append(logits)\n        true_vals.append(label_ids)\n    \n    loss_val_avg = loss_val_total/len(dataloader_val) \n    \n    predictions = np.concatenate(predictions, axis=0)\n    true_vals = np.concatenate(true_vals, axis=0)\n    print(predictions)\n    return loss_val_avg, predictions, true_vals","metadata":{"id":"ZMID29WF1lS-","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfor epoch in tqdm(range(1, epochs+1)):\n    model.train()\n    \n    loss_train_total = 0\n    progress_bar = tqdm(dataloader_train,\n                        desc=\"Epoch {:1d}\".format(epoch),\n                        leave=False,\n                        disable=False)\n    \n    for batch in progress_bar:\n        model.zero_grad()\n        batch = tuple(b.to(device) for b in batch)\n        inputs = {\n            'input_ids'       : batch[0],\n            'attention_mask'  : batch[1],\n            'labels'          : batch[2]\n        }\n    \n        outputs = model(**inputs)\n        loss = outputs[0]\n        loss_train_total += loss.item()\n        loss.backward()\n\n        torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n\n        optimizer.step()\n        scheduler.step()\n\n        progress_bar.set_postfix( {'training_loss': '{:3f}'.format(loss.item() / len(batch))} )\n\n    #torch.save(model.state_dict(), 'Models/BERT_ft_epoch{}.model'.format(epoch))\n    tqdm.write('\\nEpoch {epoch}')\n    \n    loss_train_avg = loss_train_total / len(dataloader_train)\n    tqdm.write('Training loss: {}'.format(loss_train_avg))\n    \n    val_loss, predictions, true_vals = evaluate(dataloader_val)\n    val_f1 = f1_score_func(predictions, true_vals)\n    \n    tqdm.write('Validation loss: {}'.format(val_loss))\n    tqdm.write('f1 score (weighted): {}'.format(val_f1))\n    \n    \n    ","metadata":{"id":"wUvj10aM1qP5","outputId":"13c198ef-0de0-40df-eff7-b58878f5c304","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nval_true = labels_val.detach().cpu().numpy().reshape((-1,1))\nval_preds =  np.argmax(predictions,axis = 1).reshape((-1,1))\nprint(classification_report(val_true, val_preds))    ","metadata":{"id":"v_jYR4P01s-S","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_pretrained('results/tokenizer/')","metadata":{"id":"4RIhkJUR2qp6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}