{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to loazz\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA\n","metadata":{}},{"cell_type":"code","source":"#importing the dataset\ndf = pd.read_csv('/kaggle/input/mushroom-classification/mushrooms.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#what does the data look like ?\ndf.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in df.columns:\n    print( df[col].value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### stalk-root has 2480 missing values","metadata":{}},{"cell_type":"code","source":"# resolving the missing values defect\nmissing_stalk_root = (df['stalk-root'].value_counts()['?']/df.shape[0])\nsns.displot( x = 'stalk-root',data = df)\nplt.show()\nprint(\"Over {} of the data for stalk root is missing\".format(missing_stalk_root*100))\nprint(\"It seems reasonable to drop the stalk root columns\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(['stalk-root'],axis = 1,inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let us find the unique values in each columns\nfor col in df:\n    print(col, df[col].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* each record seems contains only categorical data","metadata":{}},{"cell_type":"markdown","source":"### what all will we analyse ??\n1. Count of poisonous and non poisonous mushrooms\n2. correlation of count of poi and non poi with each categorical feature ( hopefully get some insight out of that )","metadata":{}},{"cell_type":"code","source":"#count of poisonous and edible musrooms\nax = sns.countplot(x = \"class\",data = df)\nplt.show()\nprint(df['class'].value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* The dataset is well balanced","metadata":{}},{"cell_type":"code","source":"#c orrelation of count of poi and non poi with each categorical feature \nfor col in df.columns[1:]:\n    plt.figure(figsize=(15,8))\n    ax = sns.countplot(x=\"class\", hue=col, data=df)\n    ax.set_title(col)\n    ax.legend(bbox_to_anchor= (0.9,1))\n    plt.show()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The set of redundant features are\n1. Veil-type \n","metadata":{}},{"cell_type":"code","source":"#removing redundant features\ndf.drop('veil-type',axis = 1,inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Before proceeding further, let us shuffle the dataset","metadata":{}},{"cell_type":"code","source":"df = df.sample(frac=1).reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#performing one hot encoding\ndf_x = df.iloc[:,1:]\ndf_y = df.iloc[:,0]\n\n\n\ndf_x_orig = df_x\ndf_y_orig = df_y\n\ndef convert_categorical_to_binary(df,columns):\n    print(columns)\n    df_temp = pd.DataFrame()\n    n = df.shape[0];\n    for col in columns:\n        print(col)\n        vec = df[col].unique();\n        m = len(df[col].unique())-1;\n        if(m == 0):\n            continue;\n        cat2bin = np.zeros((n,m));\n        print(cat2bin.shape)\n        for i in range(n):\n            curr_category = df[col].loc[i]\n#             print(curr_category)\n            for j in range(m):\n                if(curr_category == vec[j]):\n                    cat2bin[i][j] = 1;\n                    break\n        df_temp = pd.concat((df_temp,pd.DataFrame(cat2bin)),axis = 1)\n    return df_temp\n\ndf_x = convert_categorical_to_binary(df,df.columns[1:])\n\ndf_y = convert_categorical_to_binary(df,[df.columns[0]])\n\ndf_x.columns = np.array([i for i in range(df_x.shape[1])])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There seems to be just too many features, let us try to perform some dimensionality reduction technique","metadata":{}},{"cell_type":"markdown","source":"# Chi Square method for dimensionality reduction","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest, chi2\nf_p_values = chi2(df_x,df_y)\nf_p_values = pd.DataFrame(f_p_values[0])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# f_p_values.sort_index(ascending = False,inplace = True,axis = 0)\nf_p_values.columns = ['F Score']\nf_p_values.sort_values(ascending = False,by=['F Score'], inplace=True)\nf_p_values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f_p_values[f_p_values['F Score'] >= 100].shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For now let us take all parameters with f score greater than 100","metadata":{}},{"cell_type":"code","source":"filtered_index = f_p_values[f_p_values['F Score'] >= 100].index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_x = df_x[filtered_index]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_size,test_size,cv_size = int(.7*df.shape[0]), int(.2*df.shape[0]),int(.1*df.shape[0])\nprint(train_size,test_size,cv_size)\n\nx_train,x_test,x_cv = df_x[:train_size],df_x[train_size:train_size+test_size],df_x[train_size+test_size:]\ny_train,y_test,y_cv = df_y[:train_size],df_y[train_size:train_size+test_size],df_y[train_size+test_size:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model training","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# KNN","metadata":{}},{"cell_type":"code","source":"#Applying k - nn\nfrom sklearn.neighbors import KNeighborsClassifier\nneighCount = []\nscores_test = []\nscores_train = []\nprecision_test =[]\nprecision_train = []\nrecall_test = []\nrecall_train = []\nf1_test = []\nf1_train = []\nfor nc in range(1,100):\n    neigh = KNeighborsClassifier(n_neighbors=nc)\n    neighCount.append(nc)\n    \n    neigh.fit(x_train, y_train.values.ravel())\n    \n    y_train_pred = neigh.predict(x_train)\n    y_test_pred = neigh.predict(x_test)\n    \n    precision_test.append(precision_score(y_test.values.ravel(),y_test_pred))\n    recall_test.append(recall_score(y_test.values.ravel(),y_test_pred))\n    f1_test.append(f1_score(y_test.values.ravel(),y_test_pred))\n    \n    precision_train.append(precision_score(y_train.values.ravel(),y_train_pred))\n    recall_train.append(recall_score(y_train.values.ravel(),y_train_pred))\n    f1_train.append(f1_score(y_train.values.ravel(),y_train_pred))\n    \n    scores_test.append(neigh.score(x_test, y_test.values.ravel()))\n    scores_train.append(neigh.score(x_train,y_train.values.ravel()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8, 6), dpi=80)\nplt.plot(neighCount, scores_train, c = 'r',label = \"Train data\")\nplt.plot(neighCount,scores_test, c = 'b', label = \"Test data\")\nplt.title(\"Accuracy versus number of neighbours \")\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.argmax(scores_test)\nprint(\"Max accuracy for test set\" , scores_test[np.argmax(scores_test)])\nprint(\"max number of nearest neighbours for best score \" , neighCount[len(scores_test) - np.argmax(scores_test[::-1]) -1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8, 6), dpi=80)\nplt.plot(neighCount, f1_train, c = 'r',label = \"Train data\")\nplt.plot(neighCount,f1_test, c = 'b', label = \"Test data\")\nplt.title(\"f1-score versus number of neighbours \")\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.argmax(f1_test)\nprint(\"Max f1-score for test set\" , f1_test[np.argmax(f1_test)])\nprint(\"max number of nearest neighbours for best score \" , neighCount[len(f1_test) - np.argmax(f1_test[::-1]) -1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8, 6), dpi=80)\nplt.plot(neighCount, precision_train, c = 'r',label = \"Train data\")\nplt.plot(neighCount , precision_test, c = 'b', label = \"Test data\")\nplt.title(\"precision versus number of neighbours \")\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.argmax(precision_test)\nprint(\"Max f1-score for test set\" , precision_test[np.argmax(precision_test)])\nprint(\"max number of nearest neighbours for best score \"  , neighCount[len(precision_test) - np.argmax(precision_test[::-1]) -1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8, 6), dpi=80)\nplt.plot(neighCount, recall_train, c = 'r',label = \"Train data\")\nplt.plot(neighCount , recall_test, c = 'b', label = \"Test data\")\nplt.title(\"recall versus number of neighbours \")\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.argmax(recall_test)\nprint(\"Max recall-score for test set\" , recall_test[np.argmax(recall_test)])\nprint(\"max number of nearest neighbours for best score\" , neighCount[len(recall_test) - np.argmax(recall_test[::-1]) -1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Taking the number of nearest neightbours as 8 seems most apt in this case, since it gives the best f1-score on train and test size.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nneigh = KNeighborsClassifier(n_neighbors=8)\nneigh.fit(x_train, y_train.values.ravel())\ny_test_pred = neigh.predict(x_test)\ncm = confusion_matrix(y_test,y_test_pred)\nprint(classification_report(y_test, y_test_pred))\nprint(cm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Evaluation on the cross validation set\nneigh = KNeighborsClassifier(n_neighbors=8)\nneigh.fit(x_train, y_train.values.ravel())\ny_cv_pred = neigh.predict(x_cv)\ncm = confusion_matrix(y_cv,y_cv_pred)\nprint(classification_report(y_cv, y_cv_pred))\nprint(cm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Conclusion - We have succesfully created a KNN based model for mushroom classification\n","metadata":{}}]}