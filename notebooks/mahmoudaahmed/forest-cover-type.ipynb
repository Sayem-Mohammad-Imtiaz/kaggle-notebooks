{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#The external libraries the that will be used to help in the project\nimport numpy as np # A linear algebra library for python which has many data structures for example;numpy arrays which are much more faster than normal python lists\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt # A library that makes crearing graphs/plots.. much easier\nimport seaborn as sns #statistical data visualization\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dataset = pd.read_csv('../input/forest-cover-type-dataset/covtype.csv') #load The dataset\nprint(dataset.shape) #show the shape of the data set,returns a tuple dataset[0]=number of data entries and dataset[1] is the number of features\n                     # can be 3d for other datasets, forexample;(X,Y,Z) where X is the number of data entries ,Y could be a timestamp ,Z number of features in the timestamp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head(10) #A preview of the first 10 instances in the dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.info() #More information about the datatypes of the dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in dataset: #for each column/feature in the dataset see the unique values and the number of there occurences \n    print(dataset[str(column)].value_counts())\n    \n#from the following we can deduce that the featue 'Soil_Type14' is ussles as its almost constant","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.median() # The median value for each feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.describe(include='all') #show statistics for each feature in tha data set \n\n#count: the total number of values for each feature (not N/A) it can be seen that currenly no feature is missing since they all have same count\n#mean: the mean of all the values of each feature\n#std: the standard deviation of each feature (it is the average of how far/close are all the values to each other \n#     a low std will indicate that most of the values are near the mean value)\n#min: the smallest value each feature in the dataset\n#25%,50%,75% :It describes the distribution of teh data set values for each feature. 50 should be The median value. 25, 75 are the border of the upper/lower quarter of the data.\n#max: the largest value each feature in the dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in dataset:  #Get a more visual idea about the distribution of the values of each feature\n    dataset[str(column)].hist() #get the values of the current feature\n    print(\"Feature :\",column) #print The name of the feature\n    plt.show()# show the histogram of the value distribution of the current feature\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.corr() # The relation between each feature and another based on  the dataset A correlation of 1 means that the features are highly \n#related ,when one value increase the other one also increases in the same direction,A corrlation of 0 means that the features are not related at all\n#A corelation of  -1 (inversly correlated) means that when the value of a feature increases the other increases also but in the opposite direction(decreases)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f = plt.figure(figsize=(50, 40)) #create a new figure of size 50x40\nplt.matshow(dataset.corr(), fignum=f.number,vmin=-1, vmax=1) # plot the correlation matrix using the pandas correlation matrix with minimum value=-1 and max =1\nplt.xticks(range(dataset.shape[1]), dataset.columns, fontsize=10, rotation=45)# plot the X axis using the column names\nplt.yticks(range(dataset.shape[1]), dataset.columns, fontsize=10)# plot the X axis using the column names\ncb = plt.colorbar() #show the color bar which represents the values for each color\ncb.ax.tick_params(labelsize=10) #show the number values for each color\nplt.title('Correlation Matrix', fontsize=25)# Add a tittle to the figure","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#get the names of columns with high correlation between them\nhigh_correlation=[] #an empty python list to store the features with high correlation between them\ncorrelation_matrix=dataset.corr()# the correlation matrix from pandas\nfor column_1 in correlation_matrix: #iterate through the corrleation matrix\n    for column_2 in correlation_matrix:\n        if(column_1!=column_2):# not including the correlation between a feature and itself\n            if(abs(correlation_matrix[column_1][column_2])>0.6 and (column_2,column_1,correlation_matrix[column_1][column_2])not in high_correlation):#checking if the features have high correlation and also discluding duplicates\n                high_correlation.append((column_1,column_2,correlation_matrix[column_1][column_2]))#adding the features with high corelation between tham with the values of the correlation as a tuple to the list\n                \nfor i in high_correlation:#prining the high correlation beweenfeatures with the correlation value\n    print(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom keras.layers import Dense, Activation\nfrom keras.models import Sequential, Model\nfrom keras.optimizers import Adam\nfrom keras.utils import to_categorical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features=dataset.iloc[:,:54].to_numpy().astype('float32')\nprint(features.shape)\n\nlabels=dataset.iloc[:,54].to_numpy().astype('float32')\nprint(labels.shape)\n\ny_binary = to_categorical(labels)\nprint(y_binary.shape)\nprint(y_binary[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=Sequential()\nmodel.add(Dense(128,input_dim=features[0].shape[0]))\nmodel.add(Dense(64))\nmodel.add(Dense(32,activation='relu'))\nmodel.add(Dense(units=8, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer=Adam(0.0002, 0.5),metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x=features, y=y_binary, batch_size=64, epochs=10, verbose=1)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}