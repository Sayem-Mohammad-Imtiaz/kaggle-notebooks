{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Stroke Prediction Model (Binary Classification)\n\n### Remark: The data is strongly imbalanced in this case: We have 4861 patients with target=0 (no stroke), but only 249 (<5%) cases with target=1 (stroke). By using a trivial predictor which always returns 0 we can achieve an accuracy of 4861/5110 = 95.13%. This sounds at first like a good performance, however, this trivial predictor is completely useless as it has absolutely no discriminative power. We can see that accuracy is not a really useful metric in the context of strongly imbalanced data. In the following we will - for the sake of completeness - evaluate also accuracy but our focus will be on AUC as performance metric instead (our trivial predictor would have an AUC of 0.5)!\n\n\n## Table of Contents\n* [Import and first glance](#1)\n* [Data Cleansing](#2)\n* [Numerical Features](#3)\n* [Categorical Features](#4)\n* [Target](#5)\n* [Build Model](#6)\n* [Evaluate on Training Data](#7)\n* [Evaluate on Test Set](#8)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# packages\n\n# standard\nimport numpy as np\nimport pandas as pd\nimport time\n\n# plot\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# statistics tools\nfrom statsmodels.graphics.mosaicplot import mosaic\n\n# ML\nimport h2o\nfrom h2o.estimators import H2ORandomForestEstimator\nfrom h2o.estimators import H2OGradientBoostingEstimator","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='1'></a>\n# Import and first glance"},{"metadata":{"trusted":true},"cell_type":"code","source":"# load data\ndf = pd.read_csv('../input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dimensions of data\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# column names\nprint(df.columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='2'></a>\n# Data cleansing"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have missing values for BMI!"},{"metadata":{"trusted":true},"cell_type":"code","source":"# impute with -99\ndf.bmi = df.bmi.fillna(-99)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# rename columns\ndf.rename(columns = {'Residence_type':'residence_type'}, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define target variable\ndf['target'] = df.stroke\ndf = df.drop(['stroke'], axis=1) # remove stroke column","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='3'></a>\n# Numerical Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# select numerical features\nfeatures_num = ['age', 'avg_glucose_level','bmi']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# basic stats\ndf[features_num].describe(percentiles=[0.1,0.25,0.5,0.75,0.9])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot distribution of numerical features\nfor f in features_num:\n    df[f].plot(kind='hist', bins=50)\n    plt.title(f)\n    plt.grid()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pairwise scatter plot\nsns.pairplot(df[features_num], \n             kind='reg', \n             plot_kws={'line_kws':{'color':'magenta'}, 'scatter_kws': {'alpha': 0.1}})\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Spearman (Rank) correlation\ncorr_spearman = df[features_num].corr(method='spearman')\n\nfig = plt.figure(figsize = (6,5))\nsns.heatmap(corr_spearman, annot=True, cmap=\"RdYlGn\", vmin=-1, vmax=+1)\nplt.title('Spearman Correlation')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='4'></a>\n# Categorical Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"features_cat = ['gender','hypertension','heart_disease','ever_married',\n                'work_type','residence_type','smoking_status']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for f in features_cat:\n    df[f].value_counts().plot(kind='bar')\n    plt.title(f)\n    plt.grid()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='5'></a>\n# Target"},{"metadata":{"trusted":true},"cell_type":"code","source":"# calc frequencies\ntarget_count = df.target.value_counts()\nprint(target_count)\nprint()\nprint('Percentage of strokes [1]:', np.round(100*target_count[1] / target_count.sum(),2), '%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot target distribution\ntarget_count.plot(kind='bar')\nplt.title('Target = Stroke')\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Target vs Numerical Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# add binned version of numerical features\n\n# quantile based:\ndf['age_bin'] = pd.qcut(df['age'], q=10, precision=1)\ndf['avg_glucose_level_bin'] = pd.qcut(df['avg_glucose_level'], q=10, precision=1)\n\n# explicitly defined bins:\ndf['bmi_bin'] = pd.cut(df['bmi'], [-100,10,20,25,30,35,40,50,100])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot target vs features using mosaic plot\nplt_para_save = plt.rcParams['figure.figsize'] # remember plot settings\n\nfor f in features_num:\n    f_bin = f+'_bin'\n    plt.rcParams[\"figure.figsize\"] = (16,7) # increase plot size for mosaics\n    mosaic(df, [f_bin, 'target'], title='Target vs ' + f + ' [binned]')\n    plt.show()\n    \n# reset plot size again\nplt.rcParams['figure.figsize'] = plt_para_save","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### \"Naive\" Interpretations based on those univariate plots:\n* Risk increases with age and glucose level (diabetes).\n* High BMI levels are also indicating higher risk.\n* A missing value for BMI (the leftmost column) seems to indicate a massively increased risk!?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# BMI - check cross table\nctab = pd.crosstab(df.bmi_bin, df.target)\nctab","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# normalize each row to get row-wise target percentages\n(ctab.transpose() / ctab.sum(axis=1)).transpose()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Almost 20% of the missing BMIs had a stroke! This is way higher than for the other bins."},{"metadata":{},"cell_type":"markdown","source":"### Target vs Categorical Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot target vs features using mosaic plot\nplt_para_save = plt.rcParams['figure.figsize'] # remember plot settings\n\nfor f in features_cat:\n    plt.rcParams[\"figure.figsize\"] = (8,7) # increase plot size for mosaics\n    mosaic(df, [f, 'target'], title='Target vs ' + f)\n    plt.show()\n    \n# reset plot size again\nplt.rcParams['figure.figsize'] = plt_para_save","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### \"Naive\" Interpretations based on those univariate plots:\n* Influence of gender seems surprisingly low\n* Hypertension and heart disease massively increase risk of stroke\n* \"Ever married\" too!?\n* Work type: Higher risk for self-employed (more stress?)\n* Residence type: Slightly higher risk for urban vs rural\n* Smoking: Highest risk for *former* smokers. Not much difference between \"smokes\" and \"never smoked\"?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# \"ever married\" - check cross table\nctab = pd.crosstab(df.ever_married, df.target)\nctab","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# normalize each row\n(ctab.transpose() / ctab.sum(axis=1)).transpose()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='6'></a>\n# Build Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# select predictors\npredictors = features_num + features_cat\nprint('Number of predictors: ', len(predictors))\nprint(predictors)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# start H2O\nh2o.init(max_mem_size='12G', nthreads=4) # Use maximum of 12 GB RAM and 4 cores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# upload data frame in H2O environment\ndf_hex = h2o.H2OFrame(df)\n\ndf_hex['target'] = df_hex['target'].asfactor()\n\n# train / test split (70/30)\ntrain_hex, test_hex = df_hex.split_frame(ratios=[0.7], seed=999)\n\n# pandas versions of train/test\ndf_train = train_hex.as_data_frame()\ndf_test = test_hex.as_data_frame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# export for potential external processing\ndf_train.to_csv('df_train.csv')\ndf_test.to_csv('df_test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define Gradient Boosting model\nfit_1 = H2OGradientBoostingEstimator(ntrees = 100,\n                                     max_depth=4,\n                                     min_rows=10,\n                                     learn_rate=0.01, # default: 0.1\n                                     sample_rate=1,\n                                     col_sample_rate=0.7,\n                                     nfolds=5,\n                                     score_each_iteration=True,\n                                     stopping_metric='auto',\n                                     stopping_rounds=10,\n                                     seed=999)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train model\nt1 = time.time()\nfit_1.train(x=predictors,\n            y='target',\n            training_frame=train_hex)\nt2 = time.time()\nprint('Elapsed time [s]: ', np.round(t2-t1,2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# show training scoring history\nplt.rcParams['figure.figsize']=(7,4)\nfit_1.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# show cross validation metrics\nfit_1.cross_validation_metrics_summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# show scoring history - training vs cross validations\nfor i in range(5):\n    cv_model_temp = fit_1.cross_validation_models()[i]\n    df_cv_score_history = cv_model_temp.score_history()\n    my_title = 'CV ' + str(1+i) + ' - Scoring History [AUC]'\n    plt.scatter(df_cv_score_history.number_of_trees,\n                y=df_cv_score_history.training_auc, \n                c='blue', label='training')\n    plt.scatter(df_cv_score_history.number_of_trees,\n                y=df_cv_score_history.validation_auc, \n                c='darkorange', label='validation')\n    plt.title(my_title)\n    plt.xlabel('Number of Trees')\n    plt.ylabel('AUC')\n    plt.ylim(0.8,1)\n    plt.legend()\n    plt.grid()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='7'></a>\n# Evaluate on Training Data"},{"metadata":{},"cell_type":"markdown","source":"### ROC Curve - Training Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# training performance\nperf_train = fit_1.model_performance(train=True)\nperf_train.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ROC Curve - Cross Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# cross validation performance\nperf_cv = fit_1.model_performance(xval=True)\nperf_cv.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Confusion Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"# on training data - automatic threshold (optimal F1 score)\nconf_train = fit_1.confusion_matrix(train=True)\nconf_train.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# corresponding accuracy for this threshold:\nconf_list_temp = conf_train.to_list()\nn_matrix = sum(conf_list_temp[0]) + sum(conf_list_temp[1])\nacc_t0 = (conf_list_temp[0][0]+conf_list_temp[1][1]) / n_matrix\nprint('Accuracy:', np.round(acc_t0,6))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Selecting threshold by optimal F1 is not really helpful here, we have a big difference between actual positives (184) and predicted positives (302). Let's try to improve by selecting the threshold manually:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# alternatively specify threshold manually - here we try to achieve a symmetric outcome\ntt = 0.148\nconf_train_man = fit_1.confusion_matrix(train=True, thresholds=tt)\nconf_train_man.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# corresponding accuracy for manual threshold:\nconf_list_temp = conf_train_man.to_list()\nn_matrix = sum(conf_list_temp[0]) + sum(conf_list_temp[1]) \nacc_t1 = (conf_list_temp[0][0]+conf_list_temp[1][1]) / n_matrix\nprint('Accuracy:', np.round(acc_t1,6))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Much better: 184 actual positives vs. 185 predicted positives!"},{"metadata":{"trusted":true},"cell_type":"code","source":"# check on cross validation\nconf_cv_man = fit_1.confusion_matrix(xval=True, thresholds=tt)\nconf_cv_man.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# corresponding accuracy for our manual threshold:\nconf_list_temp = conf_cv_man.to_list()\nn_matrix = sum(conf_list_temp[0]) + sum(conf_list_temp[1])\nacc_t1_CV = (conf_list_temp[0][0]+conf_list_temp[1][1]) / n_matrix\nprint('Accuracy:', np.round(acc_t1_CV,6))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Variable Importance"},{"metadata":{"trusted":true},"cell_type":"code","source":"# basic version\nfit_1.varimp_plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# variable importance using shap values => see direction as well as severity of feature impact\nt1 = time.time()\nfit_1.shap_summary_plot(train_hex);\nt2 = time.time()\nprint('Elapsed time [s]: ', np.round(t2-t1,2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### The blue dots for BMI are probably a little bit confusing. They are based on the strongly predictive missing values which we have encoded with -99!"},{"metadata":{},"cell_type":"markdown","source":"### Predictions on training data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict on train set (extract probabilities only)\npred_train = fit_1.predict(train_hex)['p1']\npred_train = pred_train.as_data_frame().p1\n\n# and plot\nplt.hist(pred_train, bins=50)\nplt.title('Predictions on Train Set')\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check calibration\nfrequency_pred = sum(pred_train)\nfrequency_act = df_train.target.sum()\nprint('Predicted Frequency:', frequency_pred)\nprint('Actual Frequency   :', frequency_act)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='8'></a>\n# Evaluate on Test Set"},{"metadata":{"trusted":true},"cell_type":"code","source":"# calc performance on test test\nperf_test = fit_1.model_performance(test_hex)\n\n# ROC Curve - Test Set\nperf_test.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# confusion matrix using our manual threshold\nconf_test_man = perf_test.confusion_matrix(thresholds=tt)\nconf_test_man.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Quite good:  65 actual positives vs 69 predicted positives."},{"metadata":{"trusted":true},"cell_type":"code","source":"# calc accuracy for manual threshold:\nconf_list_temp = conf_test_man.to_list()\nn_matrix = sum(conf_list_temp[0]) + sum(conf_list_temp[1]) \nacc_t1_test = (conf_list_temp[0][0]+conf_list_temp[1][1]) / n_matrix\nprint('Accuracy:', np.round(acc_t1_test,6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict on test set (extract probabilities only)\npred_test = fit_1.predict(test_hex)['p1']\npred_test = pred_test.as_data_frame().p1\n\n# and plot\nplt.hist(pred_test, bins=50)\nplt.title('Predictions on Test Set')\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# connect prediction with data frame\ndf_test['prediction'] = pred_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Show examples"},{"metadata":{"trusted":true},"cell_type":"code","source":"# show most endangered patients (according to our model) in test set\ndf_high_20 = df_test.nlargest(20, columns='prediction')\ndf_high_20","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Check calibration at high end:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Actual cases in highest 20    :', df_high_20.target.sum())\nprint('Predicted cases in highest 20 :', np.round(df_high_20.prediction.sum(),2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# show least endangered patients (according to our model) in test set\ndf_low_20 = df_test.nsmallest(20, columns='prediction')\ndf_low_20","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Check calibration at low end:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Actual cases in lowest 20    :', df_low_20.target.sum())\nprint('Predicted cases in lowest 20 :', np.round(df_low_20.prediction.sum(),2))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}