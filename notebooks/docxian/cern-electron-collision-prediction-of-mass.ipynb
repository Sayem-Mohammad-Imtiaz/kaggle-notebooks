{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Predict invariant mass of two electrons in particle collision events using Gradient Boosting and the power of Feature Engineering\n\n## Table of Contents\n* [Admin Columns](#1)\n* [Target Distribution](#2)\n* [Feature Distributions](#3)\n* [Feature Correlations](#4)\n* [Target vs Features](#5)\n* [Feature Engineering](#6)\n* [Gradient Boosting Model w/o Feature Engineering](#7)\n* [Gradient Boosting Model using Feature Engineering](#8)\n* [Local Explanations](#9)\n\n### The features are not self-explanatory, so here is a copy of the data description:\n\nRun: The run number of the event.\n\nEvent: The event number.\n\nE1, E2: The total energy of the electron (GeV) for electrons 1 and 2.\n\npx1, py1, pz1, px2, py2, pz2: The components of the momemtum of the electron 1 and 2 (GeV).\n\npt1, pt2: The transverse momentum of the electron 1 and 2 (GeV).\n\neta1, eta2: The pseudorapidity of the electron 1 and 2.\n\nphi1, phi2: The phi angle of the electron 1 and 2 (rad).\n\nQ1, Q2: The charge of the electron 1 and 2.\n\nM: The invariant mass of two electrons (GeV) <= OUR TARGET","metadata":{}},{"cell_type":"code","source":"# packages\n\n# standard\nimport numpy as np\nimport pandas as pd\nimport time\n\n# plots\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Statistics\nimport scipy.stats as stats\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\n\n# ML tools\nimport h2o\nfrom h2o.estimators import H2ORandomForestEstimator\nfrom h2o.estimators import H2OGradientBoostingEstimator","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load data\ndf = pd.read_csv('../input/cern-electron-collision-data/dielectron.csv')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dimension of table\ndf.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# structure of data frame\ndf.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# clean column names\ndf.rename(columns = {'px1 ':'px1'}, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='1'></a>\n# Admin Columns","metadata":{}},{"cell_type":"markdown","source":"### Runs","metadata":{}},{"cell_type":"code","source":"# frequencies of run\ndf.Run.value_counts().plot(kind='bar')\nplt.grid()\nplt.title('Run')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### We have 13 runs of varying size.","metadata":{}},{"cell_type":"markdown","source":"### Events","metadata":{}},{"cell_type":"code","source":"# events: a few of them occur more than once!\nmultis = df.Event.value_counts() # get counts\nmultis = multis[multis.values>1] # filter by frequency > 1\nmultis","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# extract ids\nmultis_ids = multis.index.to_list()\nprint(multis_ids)\n# and show corresponding rows\ndf[df.Event.isin(multis_ids)].sort_values('Event')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Multiple event occurrences are duplicates, only exception being Event=418006834:","metadata":{}},{"cell_type":"code","source":"df[df.Event==418006834]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Interestingly the two rows are even from different runs... maybe a bug?","metadata":{}},{"cell_type":"code","source":"# we fix the situation by changing the Event for the second row\ndf.loc[79612,'Event'] = 418006835 # use a number that is not yet in use!\n# and adjust our duplicate list\nmultis_ids.remove(418006834)\n# check:\ndf[df.Event==418006834]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Finally, remove remaining duplicates:","metadata":{}},{"cell_type":"code","source":"# remove duplicates\ndf = df.drop_duplicates(subset='Event')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='2'></a>\n# Target Distribution","metadata":{}},{"cell_type":"code","source":"# check for missing values in the target\ndf.M.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### We have 85 rows without a target value.","metadata":{}},{"cell_type":"code","source":"# remove the rows having missing targets for the following as it's only a very small fraction\ndf = df[~df.M.isna()]\ndf.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot target\nplt.figure(figsize=(10,6))\ndf.M.plot(kind='hist', bins=100)\nplt.title('Distribution of M - The invariant mass of two electrons (GeV).')\nplt.grid()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Interesting shape, we have a concentration on the minimum value of 2 and two further peaks.","metadata":{}},{"cell_type":"code","source":"# stats for target; adding a few more percentiles compared to standard output\ndf.M.describe(percentiles=[0.01,0.1,0.25,0.5,0.75,0.9,0.99])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='3'></a>\n# Feature Distributions","metadata":{}},{"cell_type":"markdown","source":"### Charges of electron 1 and 2","metadata":{}},{"cell_type":"code","source":"df.Q1.value_counts().plot(kind='bar')\nplt.title('Q1 - Charge of electron 1')\nplt.grid()\nplt.show()\n\ndf.Q2.value_counts().plot(kind='bar')\nplt.title('Q2 - Charge of electron 2')\nplt.grid()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Nicely balanced!","metadata":{}},{"cell_type":"code","source":"# define numeric features\nfeatures_num = ['E1', 'px1', 'py1', 'pz1', 'pt1', 'eta1', 'phi1', \n                'E2', 'px2', 'py2', 'pz2', 'pt2', 'eta2', 'phi2']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# summary stats, adding a few more percentiles compared to standard output\ndf[features_num].describe(percentiles=[0.01,0.1,0.25,0.5,0.75,0.9,0.99])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature distributions","metadata":{}},{"cell_type":"code","source":"# combo plot hist / boxplot\nfor f in features_num:\n    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10,8))\n    ax1.hist(df[f], bins=100)\n    ax1.grid()\n    ax1.set_title(f)\n    ax2.boxplot(df[f], vert=False)\n    ax2.grid()   \n    ax2.set_title(f + '- boxplot')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='4'></a>\n# Feature Correlations","metadata":{}},{"cell_type":"markdown","source":"### Numerical Features","metadata":{}},{"cell_type":"code","source":"# Pearson correlation\ncorr_pearson = df[features_num].corr(method='pearson')\n\nfig = plt.figure(figsize = (14,8))\nsns.heatmap(corr_pearson, annot=True, cmap='RdYlGn',\n            vmin=-1, vmax=1)\nplt.title('Pearson Correlation')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Spearman (Rank) correlation\ncorr_spearman = df[features_num].corr(method='spearman')\n\nfig = plt.figure(figsize = (14,8))\nsns.heatmap(corr_spearman, annot=True, cmap='RdYlGn',\n            vmin=-1, vmax=1)\nplt.title('Spearman Correlation')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### A few interesting scatter plots (we pick the ones having the highest correlation):","metadata":{}},{"cell_type":"code","source":"plt.scatter(df.E1, df.pt1, alpha=0.1)\nplt.xlabel('E1')\nplt.ylabel('pt1')\nplt.grid()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(df.E2, df.pt2, alpha=0.1)\nplt.xlabel('E2')\nplt.ylabel('pt2')\nplt.grid()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(df.py1, df.phi1, alpha=0.1)\nplt.xlabel('py1')\nplt.ylabel('phi1')\nplt.grid()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(df.py2, df.phi2, alpha=0.1)\nplt.xlabel('py2')\nplt.ylabel('phi2')\nplt.grid()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(df.pz1, df.eta1, alpha=0.1)\nplt.xlabel('pz1')\nplt.ylabel('eta1')\nplt.grid()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(df.pz2, df.eta2, alpha=0.1)\nplt.xlabel('pz2')\nplt.ylabel('eta2')\nplt.grid()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Electron Charges","metadata":{}},{"cell_type":"code","source":"# cross table for electron charges\npd.crosstab(df.Q1, df.Q2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Again, almost symmetric. However, combinations with different signs are more frequent than those having same signs. Let's try to add the product of the two charges (+1 if both have same sign, -1 if they have different signs) to our features:","metadata":{}},{"cell_type":"code","source":"df['Q12'] = df.Q1 * df.Q2\ndf['Q12'].value_counts().plot(kind='bar')\nplt.title('Q1 = Q1*Q2')\nplt.grid()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='5'></a>\n# Target vs Features","metadata":{}},{"cell_type":"markdown","source":"### Numerical Features","metadata":{}},{"cell_type":"code","source":"# scatter plot including correlation figure\nfor f in features_num:\n    c = np.round(df[f].corr(df.M, method='spearman'),4) # correlation\n    plt.scatter(df[f], df.M, alpha=0.1)\n    plt.title('Target vs '+f+' - corr_sp='+str(c))\n    plt.grid()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Electron charges","metadata":{}},{"cell_type":"code","source":"for f in ['Q1','Q2','Q12']:\n    sns.violinplot(data=df, x=f, y='M')\n    plt.title('Target vs '+f)\n    plt.grid()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We cannot really see a significant impact of each Q1 and Q2 on the target.\n### But the product Q12 = Q1*Q2 seems to make a difference!","metadata":{}},{"cell_type":"markdown","source":"<a id='6'></a>\n# Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"### Let's check if this \"product trick\" works also with other features:","metadata":{}},{"cell_type":"code","source":"corr_method='spearman'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['px12'] = df.px1 * df.px2\n# calc correlation with target and visualize\nfor f in ['px1','px2','px12']:\n    c = np.round(df[f].corr(df.M, method='spearman'),4) # correlation\n    plt.scatter(df[f], df.M, alpha=0.1)\n    plt.title('Target vs '+f+' - corr_sp='+str(c))\n    plt.grid()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['py12'] = df.py1 * df.py2\n# calc correlation with target and visualize\nfor f in ['py1','py2','py12']:\n    c = np.round(df[f].corr(df.M, method='spearman'),4) # correlation\n    plt.scatter(df[f], df.M, alpha=0.1)\n    plt.title('Target vs '+f+' - corr_sp='+str(c))\n    plt.grid()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['pz12'] = df.pz1 * df.pz2\n# calc correlation with target and visualize\nfor f in ['pz1','pz2','pz12']:\n    c = np.round(df[f].corr(df.M, method='spearman'),4) # correlation\n    plt.scatter(df[f], df.M, alpha=0.1)\n    plt.title('Target vs '+f+' - corr_sp='+str(c))\n    plt.grid()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['phi12'] = df.phi1 * df.phi2\n# calc correlation with target and visualize\nfor f in ['phi1','phi2','phi12']:\n    c = np.round(df[f].corr(df.M, method='spearman'),4) # correlation\n    plt.scatter(df[f], df.M, alpha=0.1)\n    plt.title('Target vs '+f+' - corr_sp='+str(c))\n    plt.grid()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['eta12'] = df.eta1 * df.eta2\n# calc correlation with target and visualize\nfor f in ['eta1','eta2','eta12']:\n    c = np.round(df[f].corr(df.M, method='spearman'),4) # correlation\n    plt.scatter(df[f], df.M, alpha=0.1)\n    plt.title('Target vs '+f+' - corr_sp='+str(c))\n    plt.grid()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Ok, this is somewhat surprising. None of the features px1/2, py1/2, pz1/2, phi1/2 and eta1/2 shows a significant correlation with the target, but all the products do!!!","metadata":{}},{"cell_type":"code","source":"df['pt12'] = df.pt1 * df.pt2\n# calc correlation with target and visualize\nfor f in ['pt1','pt2','pt12']:\n    c = np.round(df[f].corr(df.M, method='spearman'),4) # correlation\n    plt.scatter(df[f], df.M, alpha=0.1)\n    plt.title('Target vs '+f+' - corr_sp='+str(c))\n    plt.grid()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['E12'] = df.E1 * df.E2\n# calc correlation with target and visualize\nfor f in ['E1','E2','E12']:\n    c = np.round(df[f].corr(df.M, method='spearman'),4) # correlation\n    plt.scatter(df[f], df.M, alpha=0.1)\n    plt.title('Target vs '+f+' - corr_sp='+str(c))\n    plt.grid()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Also the more predictive features show the effect that the product seems more predictive than each of the factors!","metadata":{}},{"cell_type":"markdown","source":"<a id='7'></a>\n# Gradient Boosting Model w/o Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"## Let's first build a model using just the original features:","metadata":{}},{"cell_type":"code","source":"# select predictors\npredictors = features_num + ['Q1','Q2']\nprint('Number of predictors: ', len(predictors))\nprint(predictors)\n\n# define target\ntarget='M'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# start H2O\nh2o.init(max_mem_size='12G', nthreads=4) # Use maximum of 12 GB RAM and 4 cores","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# upload data frame in H2O environment\ndf_hex = h2o.H2OFrame(df)\n\n# train / test split (80/20)\ntrain_perc = 0.8\ntrain_hex, test_hex = df_hex.split_frame(ratios=[train_perc], seed=999)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# export train/test for external processing\ndf_train = train_hex.as_data_frame()\ndf_test = test_hex.as_data_frame()\n\ndf_train.to_csv('df_train.csv')\ndf_test.to_csv('df_test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # define (distributed) Random Forest model\n# fit_1 = H2ORandomForestEstimator(ntrees=100,\n#                                    max_depth=15,\n#                                    min_rows=1,\n#                                    nfolds=5,\n#                                    seed=999)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define Gradient Boosting model\nfit_1 = H2OGradientBoostingEstimator(ntrees = 801,\n                                     max_depth=4,\n                                     min_rows=15,\n                                     sample_rate=0.9,\n                                     col_sample_rate=0.7,\n                                     nfolds=5,\n                                     seed=999)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train model - this takes a few minutes...\nt1 = time.time()\nfit_1.train(x=predictors,\n            y=target,\n            training_frame=train_hex)\nt2 = time.time()\nprint('Elapsed time [s]: ', np.round(t2-t1,2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show training scoring history\nplt.rcParams['figure.figsize']=(7,4)\nfit_1.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show cross validation metrics\nfit_1.cross_validation_metrics_summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show scoring history - training vs cross validations\nfor i in range(5):\n    cv_model_temp = fit_1.cross_validation_models()[i]\n    df_cv_score_history = cv_model_temp.score_history()\n    my_title = 'CV ' + str(1+i) + ' - Scoring History [RMSE]'\n    plt.scatter(df_cv_score_history.number_of_trees,\n                y=df_cv_score_history.training_rmse, \n                c='blue', label='training')\n    plt.scatter(df_cv_score_history.number_of_trees,\n                y=df_cv_score_history.validation_rmse, \n                c='darkorange', label='validation')\n    plt.title(my_title)\n    plt.xlabel('Number of Trees')\n    plt.legend()\n    plt.grid()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# variable importance using shap values => see direction as well as severity of feature impact\nt1 = time.time()\nfit_1.shap_summary_plot(train_hex);\nt2 = time.time()\nprint('Elapsed time [s]: ', np.round(t2-t1,2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The plot confirms that neither Q1 nor Q2 have relevant predictive power.","metadata":{}},{"cell_type":"markdown","source":"### Predict and evaluate performance on training data","metadata":{}},{"cell_type":"code","source":"# predict on training data\npred_train = fit_1.predict(train_hex)\ny_train_act = train_hex.as_data_frame()[target].values # actuals\ny_train_pred = pred_train.as_data_frame().predict.values # predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot predictions vs actual\np=sns.jointplot(y_train_act, y_train_pred,\n              joint_kws={'alpha' : 0.1})\np.fig.suptitle('Prediction vs Actual - Training Data')\nplt.xlabel('Actual')\nplt.ylabel('Prediction')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Correlations - Training Data')\nprint('Correlation Pearson:', stats.pearsonr(y_train_act, y_train_pred))\nprint('Correlation Spearman:', stats.spearmanr(y_train_act, y_train_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# metrics on training data\nprint('MAE (train): ', np.round(mean_absolute_error(y_train_act, y_train_pred),2))\nprint('RMSE(train): ', np.round(np.sqrt(mean_squared_error(y_train_act, y_train_pred)),2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predict and evaluate performance on test set:","metadata":{}},{"cell_type":"code","source":"# predict on test data\npred_test = fit_1.predict(test_hex)\ny_test_act = test_hex.as_data_frame()[target].values # actual values\ny_test_pred = pred_test.as_data_frame().predict.values # predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot predictions vs actuals\np=sns.jointplot(y_test_act, y_test_pred,\n              joint_kws={'alpha' : 0.1})\np.fig.suptitle('Prediction vs Actual - Test Data')\nplt.xlabel('Actual')\nplt.ylabel('Prediction')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Correlations - Test Set')\nprint('Correlation Pearson:', stats.pearsonr(y_test_act, y_test_pred))\nprint('Correlation Spearman:', stats.spearmanr(y_test_act, y_test_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# metrics on test data\nprint('MAE (test): ', np.round(mean_absolute_error(y_test_act, y_test_pred),2))\nprint('RMSE(test): ', np.round(np.sqrt(mean_squared_error(y_test_act, y_test_pred)),2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Not bad, but let's see what we can achieve with our feature engineering...","metadata":{}},{"cell_type":"markdown","source":"<a id='8'></a>\n# Gradient Boosting Model using Feature Engineering\n","metadata":{}},{"cell_type":"markdown","source":"## Let's check if our feature engineering (products feature_1 * feature_2) can improve our model:","metadata":{}},{"cell_type":"code","source":"# update predictors\npredictors = features_num + ['Q1','Q2'] + ['Q12', 'px12', 'py12', 'pz12', 'pt12', 'phi12', 'eta12', 'E12']\nprint('Number of predictors: ', len(predictors))\nprint(predictors)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We keep the same hyper-parameters for the sake of simplicity:","metadata":{}},{"cell_type":"code","source":"# define Gradient Boosting model\nfit_2 = H2OGradientBoostingEstimator(ntrees = 801,\n                                     max_depth=4,\n                                     min_rows=15,\n                                     sample_rate=0.9,\n                                     col_sample_rate=0.7,\n                                     nfolds=5,\n                                     seed=999)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train model - this takes a few minutes...\nt1 = time.time()\nfit_2.train(x=predictors,\n            y=target,\n            training_frame=train_hex)\nt2 = time.time()\nprint('Elapsed time [s]: ', np.round(t2-t1,2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show training scoring history\nplt.rcParams['figure.figsize']=(7,4)\nfit_2.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show cross validation metrics\nfit_2.cross_validation_metrics_summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Wow, this is an unreal improvement! Our RMSE (on CV) is now less then half compared to the first model!!!","metadata":{}},{"cell_type":"code","source":"# show scoring history - training vs cross validations\nfor i in range(5):\n    cv_model_temp = fit_2.cross_validation_models()[i]\n    df_cv_score_history = cv_model_temp.score_history()\n    my_title = 'CV ' + str(1+i) + ' - Scoring History [RMSE]'\n    plt.scatter(df_cv_score_history.number_of_trees,\n                y=df_cv_score_history.training_rmse, \n                c='blue', label='training')\n    plt.scatter(df_cv_score_history.number_of_trees,\n                y=df_cv_score_history.validation_rmse, \n                c='darkorange', label='validation')\n    plt.title(my_title)\n    plt.xlabel('Number of Trees')\n    plt.legend()\n    plt.grid()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# variable importance using shap values => see direction as well as severity of feature impact\nt1 = time.time()\nfit_2.shap_summary_plot(train_hex);\nt2 = time.time()\nprint('Elapsed time [s]: ', np.round(t2-t1,2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predict and evaluate performance on training data:","metadata":{}},{"cell_type":"code","source":"# predict on training data\npred_train = fit_2.predict(train_hex)\ny_train_act = train_hex.as_data_frame()[target].values # actuals\ny_train_pred = pred_train.as_data_frame().predict.values # predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot predictions vs actuals\np=sns.jointplot(y_train_act, y_train_pred,\n              joint_kws={'alpha' : 0.1})\np.fig.suptitle('Prediction vs Actual - Training Data')\nplt.xlabel('Actual')\nplt.ylabel('Prediction')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Correlations - Training Data')\nprint('Correlation Pearson:', stats.pearsonr(y_train_act, y_train_pred))\nprint('Correlation Spearman:', stats.spearmanr(y_train_act, y_train_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# metrics on training data\nprint('MAE (train): ', np.round(mean_absolute_error(y_train_act, y_train_pred),2))\nprint('RMSE(train): ', np.round(np.sqrt(mean_squared_error(y_train_act, y_train_pred)),2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predict and evaluate performance on test set:","metadata":{}},{"cell_type":"code","source":"# predict on test data\npred_test = fit_2.predict(test_hex)\ny_test_act = test_hex.as_data_frame()[target].values # actual values\ny_test_pred = pred_test.as_data_frame().predict.values # predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot predictions vs actuals\np=sns.jointplot(y_test_act, y_test_pred,\n              joint_kws={'alpha' : 0.1})\np.fig.suptitle('Prediction vs Actual - Test Data')\nplt.xlabel('Actual')\nplt.ylabel('Prediction')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The improved performance is also clearly visible in our scatter plot.","metadata":{}},{"cell_type":"code","source":"print('Correlations - Test Set')\nprint('Correlation Pearson:', stats.pearsonr(y_test_act, y_test_pred))\nprint('Correlation Spearman:', stats.spearmanr(y_test_act, y_test_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# metrics on test data\nprint('MAE (test): ', np.round(mean_absolute_error(y_test_act, y_test_pred),2))\nprint('RMSE(test): ', np.round(np.sqrt(mean_squared_error(y_test_act, y_test_pred)),2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Also the performance on the test set is more than twice as good!","metadata":{}},{"cell_type":"markdown","source":"<a id='9'></a>\n# Local Explanations","metadata":{}},{"cell_type":"code","source":"# select individual row from training data\nmy_row = 1\ntrain_hex[my_row,:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show detailed explanations for this prediction\nfit_2.explain_row(frame=train_hex, row_index=my_row);","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}