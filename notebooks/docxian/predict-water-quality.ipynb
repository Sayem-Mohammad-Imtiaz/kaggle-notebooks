{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Table of Contents\n* [Target](#1)\n* [Features](#2)\n* [Target vs Features](#3)\n* [PCA Visualization](#4)\n* [Model](#5)","metadata":{}},{"cell_type":"code","source":"# packages\n\n# standard\nimport numpy as np\nimport pandas as pd\nimport time\n\n# plots\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport seaborn as sns\nfrom statsmodels.graphics.mosaicplot import mosaic\n\n# missing values visualization\nimport missingno as msno\n\n# PCA / Clustering\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\n# machine learning tools\nimport h2o\nfrom h2o.estimators import H2OGeneralizedLinearEstimator, H2ORandomForestEstimator, H2OGradientBoostingEstimator","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load data\ndf = pd.read_csv('../input/water-potability/water_potability.csv')\ndf.head()\nn = df.shape[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# structure of data\ndf.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### We observe missings for some of the columns.","metadata":{}},{"cell_type":"code","source":"# show structure of missings\nmsno.matrix(df)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# percentage of missing values\nprint('Missings ph             :', np.round(100*df.ph.isna().sum() / n, 2), '%')\nprint('Missings Sulfate        :', np.round(100*df.Sulfate.isna().sum() / n, 2), '%')\nprint('Missings Trihalomethanes:', np.round(100*df.Trihalomethanes.isna().sum()/n, 2), '%')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='1'></a>\n# Target","metadata":{}},{"cell_type":"code","source":"# basic stats\nprint(df.Potability.value_counts())\ndf.Potability.value_counts().plot(kind='bar')\nplt.grid()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Target = 1 means potable water!","metadata":{}},{"cell_type":"markdown","source":"<a id='2'></a>\n# Features","metadata":{}},{"cell_type":"code","source":"# features\nfeatures_num = ['ph', 'Hardness', 'Solids', 'Chloramines', 'Sulfate', \n                'Conductivity', 'Organic_carbon', 'Trihalomethanes',\n                'Turbidity']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot distribution of numerical features\nfor f in features_num:\n    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10,6), sharex=True)\n    ax1.hist(df[f], bins=30)\n    ax1.grid()\n    ax1.set_title(f)\n    # for boxplot we need to remove the NaNs first\n    feature_wo_nan = df[~np.isnan(df[f])][f]\n    ax2.boxplot(feature_wo_nan, vert=False)\n    ax2.grid()\n    ax2.set_title(f + ' - boxplot')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Correlations","metadata":{}},{"cell_type":"code","source":"corr_pearson = df[features_num].corr(method='pearson')\ncorr_spearman = df[features_num].corr(method='spearman')\n\nplt.figure(figsize=(16,6))\nax1 = plt.subplot(1,2,1)\nsns.heatmap(corr_pearson, annot=True, cmap='RdYlGn', vmin=-1, vmax=+1)\nplt.title('Pearson Correlation')\n\nax2 = plt.subplot(1,2,2, sharex=ax1)\nsns.heatmap(corr_spearman, annot=True, cmap='RdYlGn', vmin=-1, vmax=+1)\nplt.title('Spearman Correlation')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pairwise scatter plot of numerical features\nt1 = time.time()\nsns.pairplot(df[features_num],\n             diag_kws = {'alpha': 1.0},\n             plot_kws = {'alpha': 0.1})\nplt.show()\nt2 = time.time()\nprint('Elapsed time:', np.round(t2-t1,2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='3'></a>\n# Target vs Features","metadata":{}},{"cell_type":"code","source":"# plot target vs BINNED numerical features using mosaic plot\nplt_para_save = plt.rcParams['figure.figsize'] # remember plot settings\n\nfor f in features_num:\n    # add binned version of each numerical feature first\n    new_var = f + '_bin'\n    df[new_var] = pd.qcut(df[f], 10)\n    # then create mosaic plot\n    plt.rcParams['figure.figsize'] = (16,6) # increase plot size for mosaics\n    mosaic(df, [new_var, 'Potability'], title='Target vs ' + f + ' [binned]')\n    plt.show()\n    \n# reset plot size again\nplt.rcParams['figure.figsize'] = plt_para_save","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Alternative Visualization:","metadata":{}},{"cell_type":"code","source":"for f in features_num:\n    plt.figure(figsize=(6,4))\n    sns.violinplot(y=f, x='Potability', data=df)\n    my_title = f + ' - split by target'\n    plt.title(my_title)\n    plt.grid()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='4'></a>\n# PCA Visualization","metadata":{}},{"cell_type":"code","source":"# use PCA to reduce dimension of data\ndf4pca = df.copy().dropna(axis=0) # remove rows having missings first\n# standardize features\ndf4pca_std = StandardScaler().fit_transform(df4pca[features_num])\n# define 3D PCA model\npc_model = PCA(n_components=3)\n# and apply model\npc = pc_model.fit_transform(df4pca_std)\n# add components to data frame\ndf4pca['pc_1'] = pc[:,0]\ndf4pca['pc_2'] = pc[:,1]\ndf4pca['pc_3'] = pc[:,2]\n# show extended data frame\ndf4pca.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# interactive plot\ndf4pca['size'] = 1\ndf4pca.Potability = df4pca.Potability.astype('category')\nfig = px.scatter_3d(df4pca, x='pc_1', y='pc_2', z='pc_3',\n                    color='Potability',\n                    size='size',\n                    size_max=10,\n                    opacity=0.5)\nfig.update_layout(title='PCA 3D Interactive')\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The plot looks like we will have some trouble finding a good model discriminating potable/non-potable.","metadata":{}},{"cell_type":"markdown","source":"<a id='5'></a>\n# Model","metadata":{}},{"cell_type":"code","source":"# start H2O\nh2o.init(max_mem_size='12G', nthreads=4) # Use maximum of 12 GB RAM and 4 cores","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# upload data frame in H2O environment\nt1 = time.time()\ndf_hex = h2o.H2OFrame(df)\nt2 = time.time()\nprint('Elapsed time [s]: ', np.round(t2-t1,2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# select features\npredictors = features_num\nprint('Number of predictors: ', len(predictors))\nprint(predictors)\n\n# define target\ntarget = 'Potability'\n# explicitly convert target to categorical => classification problem\ndf_hex[target] = df_hex[target].asfactor()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train / test split\ntrain_perc = 0.5\ntrain_hex, test_hex = df_hex.split_frame(ratios=[train_perc], seed=999)\n\n# Pandas versions of train/test set\ndf_train = train_hex.as_data_frame()\ndf_test = test_hex.as_data_frame()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define (distributed) random forest model\nfit_DRF = H2ORandomForestEstimator(ntrees=30,\n                                   max_depth=20,\n                                   min_rows=5,\n                                   nfolds=5,\n                                   seed=999)\n\n# train model\nt1 = time.time()\nfit_DRF.train(x=predictors,\n              y=target,\n              training_frame=train_hex)\nt2 = time.time()\nprint('Elapsed time [s]: ', np.round(t2-t1,2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show training scoring history\nfit_DRF.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# variable importance\nfit_DRF.varimp_plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cross validation metrics\nfit_DRF.cross_validation_metrics_summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Performance on Training Data / CV","metadata":{}},{"cell_type":"code","source":"# training performance\nperf_train = fit_DRF.model_performance(train=True)\nperf_train.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CV performance\nperf_cv = fit_DRF.model_performance(xval=True)\nperf_cv.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict on training data\npred_train = fit_DRF.predict(train_hex)\n# add actual target\npred_train['target'] = train_hex[target]\npred_train = pred_train.as_data_frame()\npred_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot probabilities\nplt.figure(figsize=(8,4))\nplt.hist(pred_train.p1, bins=30)\nplt.title('Predictions on Train Set')\nplt.grid()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check calibration\nn_actual = sum(df_train.Potability)\nn_pred = sum(pred_train.p1)\n\nprint('Actual Frequency    :', n_actual)\nprint('Predicted Frequency :', n_pred)\nprint('Calibration Ratio   :', n_pred / n_actual)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# adjust threshold for 0/1 translation\nbinary_threshold = 0.4212 # chose such that actual frequency is (approximately) met\npred_train_binary = np.where(pred_train.p1 > binary_threshold, 1, 0)\nprint('Actual Frequency      :', n_actual)\nprint('Calibrated Prediction :', sum(pred_train_binary))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# confusion matrix; rows ~ actual observations, cols ~ predictions\nconf_train = pd.crosstab(pred_train['target'], pred_train_binary)\n# visualize\nsns.heatmap(conf_train, cmap='Blues', annot=True, \n            cbar=False, fmt='d',\n            linecolor='black',\n            linewidths=0.1)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Performance on Test Set","metadata":{}},{"cell_type":"code","source":"# predict on test set\npred_test = fit_DRF.predict(test_hex)\n# add actual target\npred_test['target'] = test_hex[target]\npred_test = pred_test.as_data_frame()\npred_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8,4))\nplt.hist(pred_test.p1, bins=30)\nplt.title('Predictions on Test Set')\nplt.grid()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert to 0/1\npred_test_binary = np.where(pred_test.p1 > binary_threshold, 1, 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# confusion matrix; rows ~ actual observations, cols ~ predictions\nconf_test = pd.crosstab(pred_test['target'], pred_test_binary)\n# visualize\nsns.heatmap(conf_test, cmap='Blues', annot=True, \n            cbar=False, fmt='d',\n            linecolor='black',\n            linewidths=0.1)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Accuracy - Test Set:', np.round((conf_test.loc[0,0]+conf_test.loc[1,1])/conf_test.sum().sum(),4))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}