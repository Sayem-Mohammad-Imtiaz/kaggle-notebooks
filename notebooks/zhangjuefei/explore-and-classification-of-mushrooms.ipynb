{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"0e8a4cce-8950-0718-dcc6-c4412b0adb81"},"source":"Explore the data and do  some classification"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0b043dbe-d6d8-5650-b4e8-c562dd022f2b"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"00b5b34b-ff72-a193-32e1-442d2eb1386b"},"outputs":[],"source":"data = pd.read_csv(\"../input/mushrooms.csv\")\ndata.describe()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b221254a-244b-aea5-ff50-d2f417bfc60a"},"outputs":[],"source":"feature_columns = data.columns[1:]\nfor i, f in zip(np.arange(1, len(feature_columns) + 1), feature_columns):\n    print('feature {:d}:\\t{}'.format(i, f))"},{"cell_type":"markdown","metadata":{"_cell_guid":"5fcc3157-ad39-f23f-9c4f-d6561900efd6"},"source":"Draw 2-class hist-gram for every feature"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"83ca4ec9-51be-f7b0-f076-7f47dd06e19b"},"outputs":[],"source":"import matplotlib.pyplot as plt\nplt.style.use('ggplot')\n\nfig, axes = plt.subplots(nrows=11, ncols=2, figsize=(8, 60))\ndata['id'] = np.arange(1, data.shape[0] + 1)\n\nfor f, ax in zip(feature_columns, axes.ravel()):\n    data.groupby(['class', f])['id'].count().unstack(f).plot(kind='bar', ax=ax, legend=False, grid=True, title=f)"},{"cell_type":"markdown","metadata":{"_cell_guid":"2377034f-fa96-ed32-268a-3f63a7ba65ad"},"source":"Check chi2 significance of 22 features."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"584f4122-9e31-a7dd-a351-d4de84b10a22"},"outputs":[],"source":"from sklearn.feature_selection import chi2, SelectKBest\nfrom sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\nnumeric_data = pd.DataFrame()\nfor f in feature_columns:\n    numeric_data[f] = le.fit_transform(data[f])\n    \nchi_statics, p_values = chi2(numeric_data, data['class'])\n\nchi2_result = pd.DataFrame({'features': feature_columns, 'chi2_statics': chi_statics, 'p_values': p_values})\nchi2_result.dropna(axis=0, how='any', inplace=True)\n\nprint(chi2_result.sort_values(by='chi2_statics', ascending=False)[['features', 'chi2_statics', 'p_values']].reset_index().drop('index', axis=1))\n\n_ = chi2_result.sort_values(by='chi2_statics', ascending=True).set_index('features')['chi2_statics'].plot(kind='barh', logx=True, rot=-2)"},{"cell_type":"markdown","metadata":{"_cell_guid":"be7653f1-acdf-de9c-d53e-053f2697152e"},"source":"Now we know which features are significantly distinct by two classess. \nWe will use only top 5 most distinct feature (chi2 static are more than 1000) next for classification and clustering."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4fb1ae48-5e83-cd5c-a3be-cb0930279696"},"outputs":[],"source":"use_features = chi2_result.sort_values(by='chi2_statics', ascending=False)['features'].head(5).values\n\nprint('top 5 most useful features are:')\nfor f in use_features:\n    print(f)"},{"cell_type":"markdown","metadata":{"_cell_guid":"966f67a6-279b-cf3c-8677-d4ee8cb033b7"},"source":"One-hot encoding these features."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"624a29b2-8b49-1cf6-7998-80bdde894f00"},"outputs":[],"source":"data_reduced = pd.DataFrame()\nfor f in use_features:\n    dummies = data[f].str.get_dummies()\n    dummies.columns = ['{}_{}'.format(f, v) for v in dummies.columns]\n    data_reduced = pd.concat([data_reduced, dummies], axis=1)\n\ndata_reduced['class'] = data['class']"},{"cell_type":"markdown","metadata":{"_cell_guid":"6cac03a8-e13a-aa4f-3d1b-3c4ad9d79a01"},"source":"Try classification by back-propagation neural network"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"15140630-20ba-6699-5b98-85d820f1fd36"},"outputs":[],"source":"from sklearn.neural_network import MLPClassifier\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\n\n# A two-hidden layer network.\nnw = MLPClassifier(hidden_layer_sizes = (30, 30), activation='logistic', alpha=0.001, solver='lbfgs', learning_rate='constant')\n\n# Prepare the training set & testing set.\ntrain_features, test_features, train_labels, test_labels = train_test_split(data_reduced[data_reduced.columns[: -1]], data_reduced['class'], train_size=0.8)\n\nnw.fit(train_features, train_labels)\n\n# Check metrics on training set.\ntrain_predict_labels = nw.predict(train_features)\nprint('\\nTraining Classification Report:')\nprint(classification_report(train_labels, train_predict_labels))\n\n# Check metrics on testing set.\ntest_predict_labels = nw.predict(test_features)\nprint('\\nTesting Classification Report:')\nprint(classification_report(test_labels, test_predict_labels))\n\n# Confision Matrix.\ncm = confusion_matrix(test_labels, test_predict_labels)\n\n# print('\\nConfusion Matrix:')\n_ = sns.heatmap(cm, square = True, xticklabels = ['e', 'p'], annot = True, annot_kws = {'fontsize': 12}, yticklabels = ['e', 'p'], cbar = True, cbar_kws = {\"orientation\": \"horizontal\"}, cmap = \"Blues\").set(xlabel = \"predicted\", ylabel = \"true\", title = 'Confusion Matrix')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"faf8bbcc-c66a-65cb-33ef-d99262d2f4b7"},"outputs":[],"source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, auc, precision_recall_curve\n\ntest_labels = (test_labels == 'p').astype(np.int)\ntest_predict_labels = (test_predict_labels == 'p').astype(np.int)\n\n# merics.\ntest_predict_proba = nw.predict_proba(test_features)\nfpr, rc, th = roc_curve(test_labels, test_predict_proba[:, 1])\nprecision, recall, threshold = precision_recall_curve(test_labels, test_predict_proba[:, 1])\nroc_auc = auc(fpr, rc)\n\nprint('\\nMetrics: Accuracy: {:.3f}, Precision: {:.3f}, Recall: {:.3f}, AUC: {:.3f}'.format(accuracy_score(test_labels, test_predict_labels), precision_score(test_labels, test_predict_labels), recall_score(test_labels, test_predict_labels), roc_auc))\n\n# draw some charts.\nfig = plt.figure(figsize=(16, 4))\nax = fig.add_subplot(131)\nax.set_xlabel('False Positive Rate')\nax.set_ylabel('Recall')\nax.set_title('ROC Curve')\nax.plot(fpr, rc, 'b')\nax.plot([0.0, 1.0], [0.0, 1.0], 'r--')\nax.text(0.80, 0.05, 'auc: {:.2f}'.format(roc_auc))\n\nax = fig.add_subplot(132)\nax.set_xlabel('Threshold')\nax.set_ylabel('Precision & Recall')\nax.set_title('Precsion & Recall')\nax.set_xlim([threshold.min(), threshold.max()])\nax.set_ylim([0.0, 1.0])\nax.plot(threshold, precision[:-1], 'b', label='Precision')\nax.plot(threshold, recall[:-1], 'r', label='Recall')\n_ = ax.legend(loc='best')\n\nts = np.arange(0, 1.02, 0.02)\naccuracy = []\nfor t in ts:\n    predict_label = (test_predict_proba[:, 1] >= t).astype(np.int)\n    accuracy.append(accuracy_score(test_labels, test_predict_labels))\n\nax = fig.add_subplot(133)\nax.set_xlabel(\"Threshold\")\nax.set_ylabel(\"Accuracy\")\nax.set_ylim([0.0, 1.0])\nax.set_title('Accuracy')\nax.plot([0.0, 1.0], [0.5, 0.5], 'r--')\nax.plot(ts, accuracy, 'b')\n\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"0a05dd13-007e-887e-42f1-22a2e051de92"},"source":"Not bad\n-------\n\n (to be continued ...)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}