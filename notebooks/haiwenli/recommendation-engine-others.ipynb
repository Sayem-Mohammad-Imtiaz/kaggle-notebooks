{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### 1. Data lmport","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/netflix-shows/netflix_titles.csv')\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. Some Exploration","metadata":{}},{"cell_type":"markdown","source":"#### 2.1 What content is available in different countries?","metadata":{}},{"cell_type":"code","source":"data[\"country\"] = data[\"country\"].fillna(\"\")\ncountry_list = [string.split(\",\") for string in list(data[\"country\"])]\ncountry_list = [[country.lstrip() for country in sublist] for sublist in country_list]\ndata[\"country_list\"] = country_list","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import itertools\nall_countries = list(itertools.chain(*country_list))\nall_unique_countries = list(set(all_countries))\nall_unique_countries = sorted(all_unique_countries[1:])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import collections\ncountry_count = pd.DataFrame(collections.Counter(all_countries).most_common(117),\n                            columns=[\"country\",\"count\"])\ncountry_count = country_count.drop([3])\nimport matplotlib.pyplot as plt\nplt.bar(country_count[\"country\"][:20],country_count[\"count\"][:20])\nplt.xticks(rotation=90)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The bar graph above presents the number of available netflix movies and tv shows in top 20 countries.","metadata":{}},{"cell_type":"code","source":"data[\"listed_in\"] = data[\"listed_in\"].fillna(\"\")\ngenre = [string.split(\",\") for string in list(data[\"listed_in\"])]\ngenre = [[string.lstrip() for string in sublist] for sublist in genre]\ndata[\"genre\"] = genre","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_genre = list(itertools.chain(*genre))\nall_unique_genre = sorted(list(set(all_genre)))\ngenre_count = pd.DataFrame(collections.Counter(all_genre).most_common(42),\n                            columns=[\"genre\",\"count\"])\n\nplt.bar(genre_count[\"genre\"][:15],genre_count[\"count\"][:15])\nplt.xticks(rotation=90)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The bar graph above present the number of top 15 genres.","metadata":{}},{"cell_type":"code","source":"genre_in_country = {}\nfor row in range(7787):\n    for country in country_list[row]:\n        if country not in genre_in_country:\n            genre_in_country[country] = []\n        genre_in_country[country].extend(genre[row])\n        genre_in_country[country] = list(set(genre_in_country[country]))  ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# what contents are available in Egypt?\ngenre_in_country[\"Egypt\"]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 2.2 Network analysis of actors and directors","metadata":{}},{"cell_type":"code","source":"cast = list(data[\"cast\"].fillna(\"\"))\ncast = [string for string in cast if string!=\"\"]\ncast = [string.split(\",\") for string in cast]\ncast = [[person.lstrip() for person in people] for people in cast]\nall_cast = list(itertools.chain(*cast))\nall_unique_cast = list(set(all_cast))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"castdf = pd.DataFrame(collections.Counter(all_cast).most_common(),\n                            columns=[\"actor/actress\",\"count\"])\ncastdf_3 = castdf.drop(castdf[castdf[\"count\"]<3].index)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"castdf_3.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Top 5 actors and the number of their works。","metadata":{}},{"cell_type":"code","source":"from nltk import bigrams\ncast_bigram = [list(bigrams(group)) for group in cast]\ncast_bigram = list(itertools.chain(*cast_bigram))\nbicast_count = collections.Counter(cast_bigram)\nbicast = pd.DataFrame(bicast_count.most_common(30),columns=[\"groups\",\"count\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# network visualization \nd = bicast.set_index('groups').T.to_dict('records')\n\nimport networkx as nx\nG = nx.Graph()\nfor k, v in d[0].items():\n    G.add_edge(k[0], k[1], weight=(v * 10))\n               \n\nspring_3D = nx.spring_layout(G,dim=3, seed=18)\nlabel = list(spring_3D.keys())\nx_nodes = [spring_3D[i][0] for i in label]# x-coordinates of nodes\ny_nodes = [spring_3D[i][1] for i in label]# y-coordinates\nz_nodes = [spring_3D[i][2] for i in label]# z-coordinates\nedge_list = G.edges()\nx_edges=[]\ny_edges=[]\nz_edges=[]\n\n#need to fill these with all of the coordiates\nfor edge in edge_list:\n    #format: [beginning,ending,None]\n    x_coords = [spring_3D[edge[0]][0],spring_3D[edge[1]][0],None]\n    x_edges += x_coords\n\n    y_coords = [spring_3D[edge[0]][1],spring_3D[edge[1]][1],None]\n    y_edges += y_coords\n\n    z_coords = [spring_3D[edge[0]][2],spring_3D[edge[1]][2],None]\n    z_edges += z_coords\n\nimport networkx as nx \nimport plotly.graph_objects as go\nimport pandas as pd\n\n%matplotlib inline\n\ntrace_edges = go.Scatter3d(x=x_edges,\n                        y=y_edges,\n                        z=z_edges,\n                        mode='lines',\n                        line=dict(color='black', width=2),\n                        hoverinfo='none')\n\ntrace_nodes = go.Scatter3d(x=x_nodes,\n                         y=y_nodes,\n                        z=z_nodes,\n                        mode='markers+text',\n                        marker=dict(symbol='circle',\n                                    size=10,\n                                    line=dict(color='black', width=0.5)),\n                        text=label,\n                        hoverinfo='text')\n\naxis = dict(showbackground=False,\n            showline=False,\n            zeroline=False,\n            showgrid=False,\n            showticklabels=False,\n            title='')\n\nlayout = go.Layout(title=\"cast network\",\n                width=650,\n                height=625,\n                showlegend=False,\n                scene=dict(xaxis=dict(axis),\n                        yaxis=dict(axis),\n                        zaxis=dict(axis),\n                        ),\n                margin=dict(t=100),\n                hovermode='closest')\n\nvizdata = [trace_edges, trace_nodes]\nfig = go.Figure(data=vizdata, layout=layout)\n\nfig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Clustering exists.","metadata":{}},{"cell_type":"code","source":"dir_cast = data[[\"director\",\"cast\"]]\ndir_cast = dir_cast.dropna()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dir_cast[\"director\"] = [string.split(\",\") for string in list(dir_cast[\"director\"])]\ndir_cast[\"director\"] = [[person.lstrip() for person in people] for people in list(dir_cast[\"director\"])]\ndir_cast[\"cast\"] = [string.split(\",\") for string in list(dir_cast[\"cast\"])]\ndir_cast[\"cast\"] = [[person.lstrip() for person in people] for people in list(dir_cast[\"cast\"])]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dircast_pair = []\ndirect = list(dir_cast[\"director\"])\nca = list(dir_cast[\"cast\"])\nfor i in range(4979):\n    for director in direct[i]:\n        for act in ca[i]:\n            pair = [director,act]\n            dircast_pair.append(pair)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_director = list(itertools.chain(*direct))\nunique_director = list(set(all_director))\ndirector_count = pd.DataFrame(collections.Counter(all_director).most_common(10),\n                             columns= [\"director\",\"count\"])\ndirector_count","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Top 10 directors and the number of their works.","metadata":{}},{"cell_type":"code","source":"top3 = [pair for pair in dircast_pair if pair[0] in [\"Jan Suter\",\"Raúl Campos\",\"Marcus Raboy\"]]\ntop3_bigram = [list(bigrams(pair)) for pair in top3]\ntop3_bigram = list(itertools.chain(*top3_bigram))\ntop3df = pd.DataFrame(collections.Counter(top3_bigram).most_common(),\n                      columns=[\"pair\",\"count\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 2D network visualization\nd = top3df.set_index('pair').T.to_dict('records')\nG = nx.Graph()\n\nfor k, v in d[0].items():\n    G.add_edge(k[0], k[1], weight=(v * 10))\nfig, ax = plt.subplots(figsize=(10, 8))\npos = nx.spring_layout(G, k=2,seed=1)\nnx.draw_networkx(G, pos,\n                 font_size=16,\n                 width=3,\n                 edge_color='grey',\n                 node_color='purple',\n                 with_labels = False,\n                 ax=ax)\n\nfor key, value in pos.items():\n    x, y = value[0]+.135, value[1]+.045\n    ax.text(x, y,\n            s=key,\n            bbox=dict(facecolor='red', alpha=0.25),\n            horizontalalignment='center', fontsize=13) \nplt.figure(figsize = (500,500)) \nplt.figure()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Not pretty clear, use 3D.","metadata":{}},{"cell_type":"code","source":"# 3d\nd = top3df.set_index('pair').T.to_dict('records')\nG = nx.Graph()\n\nfor k, v in d[0].items():\n    G.add_edge(k[0], k[1], weight=(v * 10))              \n\nspring_3D = nx.spring_layout(G,dim=3, seed=18)\nlabel = list(spring_3D.keys())\nx_nodes = [spring_3D[i][0] for i in label]# x-coordinates of nodes\ny_nodes = [spring_3D[i][1] for i in label]# y-coordinates\nz_nodes = [spring_3D[i][2] for i in label]# z-coordinates\nedge_list = G.edges()\nx_edges=[]\ny_edges=[]\nz_edges=[]\n\nfor edge in edge_list:\n    #format: [beginning,ending,None]\n    x_coords = [spring_3D[edge[0]][0],spring_3D[edge[1]][0],None]\n    x_edges += x_coords\n\n    y_coords = [spring_3D[edge[0]][1],spring_3D[edge[1]][1],None]\n    y_edges += y_coords\n\n    z_coords = [spring_3D[edge[0]][2],spring_3D[edge[1]][2],None]\n    z_edges += z_coords\n\n%matplotlib inline\n\ntrace_edges = go.Scatter3d(x=x_edges,\n                        y=y_edges,\n                        z=z_edges,\n                        mode='lines',\n                        line=dict(color='black', width=2),\n                        hoverinfo='none')\n\ntrace_nodes = go.Scatter3d(x=x_nodes,\n                         y=y_nodes,\n                        z=z_nodes,\n                        mode='markers+text',\n                        marker=dict(symbol='circle',\n                                    size=10,\n                                    line=dict(color='black', width=0.5)),\n                        text=label,\n                        hoverinfo='text')\n\naxis = dict(showbackground=False,\n            showline=False,\n            zeroline=False,\n            showgrid=False,\n            showticklabels=False,\n            title='')\n\nlayout = go.Layout(title=\"top3 director-actor network\",\n                width=650,\n                height=625,\n                showlegend=False,\n                scene=dict(xaxis=dict(axis),\n                        yaxis=dict(axis),\n                        zaxis=dict(axis),\n                        ),\n                margin=dict(t=100),\n                hovermode='closest')\n\nvizdata = [trace_edges, trace_nodes]\nfig = go.Figure(data=vizdata, layout=layout)\n\nfig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Jan Suter and Raúl Campos are probably partners.","metadata":{}},{"cell_type":"markdown","source":"### 3. A simple recomendation engine","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfidf = TfidfVectorizer(stop_words=\"english\")\ndata[\"description\"] = data[\"description\"].fillna('')\ntfidf_matrix = tfidf.fit_transform(data[\"description\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using cosine similarity for similarity between two descriptions\nfrom sklearn.metrics.pairwise import linear_kernel\ncosine_sim = linear_kernel(tfidf_matrix,tfidf_matrix)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"indices = pd.Series(data.index,index=data[\"title\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"director\"] = data[\"director\"].fillna(\"\")\ndata[\"director list\"] = [string.split(\",\") for string in list(data[\"director\"])]\ndata[\"director list\"] = [[person.lstrip() for person in people] for people in list(data[\"director list\"])]\n\ndata[\"cast\"] = data[\"cast\"].fillna(\"\")\ndata[\"top3 cast\"] = [string.split(\",\") for string in list(data[\"cast\"])]\ndata[\"top3 cast\"] = [[person.lstrip() for person in people] for people in list(data[\"top3 cast\"])]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_top3(x):\n    \"\"\" return the first 3 element of a list\"\"\"\n    if len(x)>3:\n        x = x[:3]\n    return x\ndata[\"top3 cast\"] = [get_top3(l) for l in list(data[\"top3 cast\"])]\ndata[\"top3 dir\"] = [get_top3(l) for l in list(data[\"director list\"])]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def lower_no_space(x):\n    if x == [\"\"]:\n        return x\n    else:\n        return [s.replace(\" \",\"\").lower() for s in x]\n\nfeatures = [\"top3 dir\",\"top3 cast\",\"genre\"]\nfor f in features:\n    data[f] = [lower_no_space(l) for l in list(data[f])]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def join_feature(df):\n    return \" \".join(df[\"genre\"])+\" \"+\" \".join(df[\"top3 dir\"])+\" \"+\" \".join(df[\"top3 cast\"])\ndata['rec_feature'] = data.apply(join_feature,axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\ncount = CountVectorizer(stop_words = \"english\")\ncount_matrix = count.fit_transform(data[\"rec_feature\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity\ncosine_sim2 = cosine_similarity(count_matrix, count_matrix)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def recommender(title,sim1 = cosine_sim,sim2=cosine_sim2,n=5):\n    \"\"\"\n    a recommender than takes a netflix show's title as input \n    and return (default) 5 other most similar netflix shows\n    \n    the recommendation is based on description, 3 top actors, director, and related genres\n    \"\"\"\n    \n    index = indices[title]\n    sim_scores1 = list(enumerate(cosine_sim[index]))\n    sim_scores2 = list(enumerate(cosine_sim2[index]))\n    length = len(sim_scores1)\n    total_scores = [(i,sim_scores1[i][1]+sim_scores2[i][1]) for i in range(length)]\n    total_scores = sorted(total_scores,key = lambda x:x[1],reverse=True)\n    \n    top_n = total_scores[1:1+n]\n    top_n_index = [tup[0] for tup in top_n]\n    \n    return data[\"title\"].iloc[top_n_index]\n    \n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"recommender(\"13 Reasons Why\")","metadata":{},"execution_count":null,"outputs":[]}]}