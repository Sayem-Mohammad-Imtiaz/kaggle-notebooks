{"cells":[{"metadata":{},"cell_type":"markdown","source":"**MASTER AT BIG DATE AND BUSINESS ANALYTICS - UNED 2019 2020 - MALNUTRITION AND HEALTH SYSTEMS ACROSS THE WORLD**\n\nNIDIA I. PAIVA VEGA\n\nThis is a digest of the information described at https://www.kaggle.com/danevans/world-bank-wdi-212-health-systems, https://www.kaggle.com/ruchi798/malnutrition-across-the-globe\n\nContext\n\nMalnutrition continues to be the reason for making children much more vulnerable to diseases and death.\nThere are 4 broad types of malnutrition: wasting, stunting, underweight and overweight.\n\nInspiration\n- Was there a decline or rise in the number of severe wasting cases country-wise?\n- Which countries bear the greatest  of severe wasting forms of malnutrition?\n- % of  wasted children under 5, by country income classification and various health spending per capita by Country, as well as doctors, nurses and midwives, and specialist surgical staff per capita.\n\n\nCONTENT\nNotes, explanations, etc.\n* There are countries/regions in the World Bank data not in the Covid-19 data, and countries/regions in the Covid-19 data with no World Bank data. This is unavoidable.\n* There were political decisions made in both datasets that may cause problems. I chose to go forward with the data as presented, and did not attempt to modify the decisions made by the dataset creators.\n\nColumns are as follows:\n\nCountry_Region: the region as used in Kaggle Covid-19 spread data challenges.\n\nWorldBankName: the name of the country used by the World Bank\n\nHealthexppctGDP2016: Level of current health expenditure expressed as a percentage of GDP. Estimates of current health expenditures include healthcare goods and services consumed during each year. This indicator does not include capital health expenditures such as buildings, machinery, IT and stocks of vaccines for emergency or outbreaks.\n\nHealthexppublicpct2016: Share of current health expenditures funded from domestic public sources for health. Domestic public sources include domestic revenue as internal transfers and grants, transfers, subsidies to voluntary health insurance beneficiaries, non-profit institutions serving households (NPISH) or enterprise financing schemes as well as compulsory prepayment and social health insurance contributions. They do not include external resources spent by governments on health.\n\nHealthexpoutofpocketpct2016: Share of out-of-pocket payments of total current health expenditures. Out-of-pocket payments are spending on health directly out-of-pocket by households.\n\nHealthexppercapitaUSD_2016: Current expenditures on health per capita in current US dollars. Estimates of current health expenditures include healthcare goods and services consumed during each year.\n\npercapitaexpPPP2016: Current expenditures on health per capita expressed in international dollars at purchasing power parity (PPP).\n\nExternalhealthexppct2016: Share of current health expenditures funded from external sources. External sources compose of direct foreign transfers and foreign transfers distributed by government encompassing all financial inflows into the national health system from outside the country. External sources either flow through the government scheme or are channeled through non-governmental organizations or other schemes.\n\nPhysiciansper1000_2009-18: Physicians include generalist and specialist medical practitioners.\n\nNursemidwifeper10002009-18: Nurses and midwives include professional nurses, professional midwives, auxiliary nurses, auxiliary midwives, enrolled nurses, enrolled midwives and other associated personnel, such as dental nurses and primary care nurses.\n\nSpecialistsurgicalper10002008-18: Specialist surgical workforce is the number of specialist surgical, anaesthetic, and obstetric (SAO) providers who are working in each country per 100,000 population.\n\nCompletenessofbirthreg2009-18: Completeness of birth registration is the percentage of children under age 5 whose births were registered at the time of the survey. The numerator of completeness of birth registration includes children whose birth certificate was seen by the interviewer or whose mother or caretaker says the birth has been registered.\n\nCompletenessofdeathreg2008-16: Completeness of death registration is the estimated percentage of deaths that are registered with their cause of death information in the vital registration system of a country.\n\nSevere Wasting - % of children aged 0–59 months who are below minus three standard deviations from median weight-for-height\nWasting – Moderate and severe: % of children aged 0–59 months who are below minus two standard deviations from median weight-for-height\nOverweight – Moderate and severe: % aged 0-59 months who are above two standard deviations from median weight-for-height\nStunting – Moderate and severe: % of children aged 0–59 months who are below minus two standard deviations from median height-for-age\nUnderweight – Moderate and severe: % of children aged 0–59 months who are below minus two standard deviations from median weight-for-age\nContinent_id: the name of the continent used by the present research. \n\n"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load libraries.\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\n\n\npd.set_option('display.max_columns', None)\n\npd.set_option('display.max_columns', None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing the data and displaying some rows\ndf = pd.read_csv(\"../input/malnutrition-across-the-globe/country-wise-average.csv\")\ncountry_average = df\ndisplay(country_average.head(10))\n\ndf = pd.read_csv(\"../input/world-bank-wdi-212-health-systems/2.12_Health_systems.csv\")\nhealth_system = df\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_average.count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Showing the NaNs\ncountry_average.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# View the second dataset\nhealth_system.count()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Counting the NaNs\nhealth_system.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removed one column containing redundant values\nhealth_system_1=health_system.drop(['Province_State'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Descripción del dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Showing all variables-- distribution\nhealth_system_1.describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Drow Income Classification\nimport numpy as np\nimport matplotlib.pyplot as plt\n\npk_colors = ['#A8B820',  # Bug,\n             '#705848',  # Dark,\n             '#7038F8',  # Dragon\n             '#F8D030',  # Electric\n        \n             ]\n\nhelthSys_cnt = country_average[\"Income Classification\"].value_counts(sort=False).sort_index()\nhelthSys_cnt = pd.concat([helthSys_cnt, pd.DataFrame(pk_colors,\n                                           index=helthSys_cnt.index,\n                                           columns=[\"Colors\"])], axis=1)\nhelthSys_cnt.sort_values(\"Income Classification\", inplace=True)\nhelthSys_cnt_bar = helthSys_cnt.plot(kind='barh', y=\"Income Classification\", color=helthSys_cnt.Colors,\n                                           legend=False, figsize=(8, 8))\nhelthSys_cnt_bar.set_title(\"Number of Country\\nIncome Classification\",\n                                           fontsize=16, weight=\"bold\")\n\nhelthSys_cnt_bar.set_xlabel(\"Number of Country\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We created the *fill_NaN* function to fill up the Country Region column with the information from the World Bank Name column.\n# The Country Region column contains NaN\ndef rellenar_NaN(row):\n    if pd.isnull(row['Country_Region']):\n        val = row['World_Bank_Name']\n    else:\n        val = row['Country_Region']\n    return val\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We apply the fill_NaN function and assign it to the Country Region column.\nhealth_system_1['Country_Region']=health_system_1.apply(rellenar_NaN, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We check it out\nhealth_system_1['Country_Region'].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We filter the countries that do not have information in the next column.\nhealth_system_1 = health_system_1[health_system_1['Health_exp_per_capita_USD_2016'].notnull()]","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"health_system_1_numericas=health_system_1.select_dtypes(include=['number'])\nhealth_system_1_categoricas=health_system_1.select_dtypes(include=['object'])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# View categorical variables\nhealth_system_1_categoricas","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creamos un encoding de la columna de los nombres de los paises"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Encoding of the column of *country names*\nhealth_system_1_categoricas['Country_Region_num']=health_system_1_categoricas.Country_Region.astype('category').cat.codes\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# View of numerical variables\nhealth_system_1_numericas.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let´s look at how many columns without *health system* information are there...\nfiltered_df= pd.merge(health_system_1_categoricas, health_system_1_numericas, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"filtered_df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have lines with very important value absent on the health system as: \"total of birth...\", \"total of death\", \"out-of-pocket spending on health\", \"surgeons per thousand ...\" and \"doctors per thousand ...\". "},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Correlations. Show a mini plot of Current\nmy_plot = filtered_df.plot(\"per_capita_exp_PPP_2016\", \"Health_exp_pct_GDP_2016\", kind=\"scatter\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlations. Show a mini plot\nmy_plot = filtered_df.plot(\"Nurse_midwife_per_1000_2009-18\", \"Health_exp_pct_GDP_2016\", kind=\"scatter\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filtered_df_2=filtered_df[['Country_Region','Health_exp_pct_GDP_2016']]\nfiltered_df_2=filtered_df_2.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation mini Bar Plot\nsplot=filtered_df_2.plot(kind='bar',stacked=True,title=\"Region and current health as a GDP\")\nsplot.set_xlabel(\"Country_Region\")","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# the countries in the *country average* file to capital letters in order to cross the datasets\nfiltered_df['Country_Region'] = filtered_df['Country_Region'].str.upper()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_completeness=filtered_df.merge(country_average, left_on='Country_Region', right_on='Country')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"dataset_completeness.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Removing Country column\ndataset_completeness.drop(['Country'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pint ---- Correlation Matrix\nimport seaborn as sns\n\nVar_Corr = dataset_completeness.corr()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Var_Corr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsns.heatmap(Var_Corr, xticklabels=Var_Corr.columns, yticklabels=Var_Corr.columns)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"CONTINENT STUDY\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_completeness['Country_Region'] = dataset_completeness['Country_Region'].str.upper() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**STUDY OF HEALTH AND NUTRITION SYSTEMS BY CONTINENT REGIONS**"},{"metadata":{},"cell_type":"markdown","source":"**Regretion Logitics model. Target (Dummy) Severe Wasting**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Change the column name for *Population*\ndataset_completeness_1 = dataset_completeness.rename(columns={'''U5 Population ('000s)''': 'Population'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_completeness_1['pctje_Muerte_por_malnutricion'] =dataset_completeness_1['Severe Wasting']*0.3\n\ndataset_completeness_1['Num_Muerte_por_malnutricion'] =(dataset_completeness_1['pctje_Muerte_por_malnutricion']/100)*dataset_completeness_1['Population']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We defined the criterion of our target variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"# We assume  4% cap to define like country_severewasted in this target variable.\ndef label_race (row):\n   if row['Severe Wasting'] >= 3.0 :\n      return 1\n   else:\n      return 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we apply the function label_race to datset\ndataset_completeness_1['Pais_malnutrido']=dataset_completeness_1.apply (lambda row: label_race(row), axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Evololution of the research: Label Encoders --> Create a label each country."},{"metadata":{"trusted":true},"cell_type":"code","source":"country_name=dataset_completeness_1['Country_Region']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_completeness_reg_lineal=dataset_completeness_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove the columns wich containt categoric variables  \ndataset_completeness_1=dataset_completeness_1.drop(['Severe Wasting','Country_Region','World_Bank_Name','Country'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_completeness_1.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#Fill up with 0 all NaN\ndataset_completeness_1 = dataset_completeness_1.fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import libraries for Logistic Regression\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import datasets\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.calibration import calibration_curve","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_completeness_1.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply dTypes to look up variables type\ndataset_completeness_1.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Choose target and predictor variables\nfrom sklearn.model_selection import train_test_split\n\ny=dataset_completeness_1['Pais_malnutrido']\n\nx=dataset_completeness_1.drop(['Pais_malnutrido'], axis=1)\n\nX_train,X_test, y_train, y_test=train_test_split( x, y, test_size=0.33, random_state=42)\n\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Showing y_test of target variable\ny_test","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"lr = LogisticRegression()\nlr.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show the prediction of logistic Regretion\npredictions = lr.predict(X_test)\nprint(predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\n\nprint(accuracy_score(y_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show the Confusion Matrix\nprint(confusion_matrix(y_test, predictions))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Feature Importance --> "},{"metadata":{"trusted":true},"cell_type":"code","source":"lista_col=X_train.columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Export table with coefficients and column names to excel."},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot\n# get importance\nimportance = lr.coef_[0]\n# summarize feature importance\n\nfor i,v in enumerate(importance):\n    \n    print(lista_col[i]+', Score: '+str( \"%.2f\" % (v,)))\n\npyplot.bar([x for x in range(len(importance))], importance)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Report of the first model:\n- Predictions level too hight\n- Variables of Malnutrition would can be one correlationed other and make  target conditioned of them.\n- Variables that came of  health sistems got into model.  Is good to explanations in this study\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#dataset_completeness=dataset_completeness.drop(['Overweight','pctje_Muerte_por_malnutricion', 'Num_Muerte_por_malnutricion'], axis=1)\n# We choose only Helth-Systems variables this time\nfrom sklearn.model_selection import train_test_split\n\ny=dataset_completeness_1['Pais_malnutrido']\n\nx=dataset_completeness_1.drop(['Pais_malnutrido','pctje_Muerte_por_malnutricion','Num_Muerte_por_malnutricion'\n                           ,'Overweight','Stunting','Underweight','Wasting','Income Classification','Country_Region_num'], axis=1)\n\nX_train,X_test, y_train, y_test=train_test_split( x, y, test_size=0.33, random_state=42)\n\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)\n\n\nlr = LogisticRegression()\nlr.fit(X_train,y_train)\n\npredictions = lr.predict(X_test)\nprint(predictions)\n\nlr.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\n\nprint(accuracy_score(y_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show the Confusion Matrix\nprint(confusion_matrix(y_test, predictions))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We convert the xtrain column array into a list to use the function for\nlista_col=X_train.columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot\n# get importance\nimportance = lr.coef_[0]\n# summarize feature importance\n\nfor i,v in enumerate(importance):\n    \n    print(lista_col[i]+', Score: '+str( \"%.2f\" % (v,)))\n    \npyplot.bar([x for x in range(len(importance))], importance)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Join up ytest, la xtest, the target and the prediction. Transform the prediction array to dataframe; do the some with ytest.\n# merge function brings together the predictive variables and the objective variable ytest.\n# Then the index is reset out to cross with the prediction\ndf = pd.DataFrame(data=predictions,  columns=[\"pred\"])\n\ny_test=y_test.to_frame()\n\nprediction=pd.merge(X_test, y_test, left_index=True, right_index=True)\n\nprediction.reset_index(inplace=True)\n\nprediction_completeness=pd.merge(prediction, df, left_index=True, right_index=True)\n\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"prediction_completeness","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_completeness.to_excel('prediction_completeness.xlsx')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Conclusions of the second model\n\n- The prediction level appears with a slightly lower level. This is an acceptable level of prediction for the attachment of dataset.\n- Level of prediction appears a bit more low\n- The fields of health-systems are opposite of  fields  Malnutrition"},{"metadata":{},"cell_type":"markdown","source":"RANDOM FORREST.\nIn this case we use categorical variables as targets"},{"metadata":{"trusted":true},"cell_type":"code","source":"def label_race (row):\n   if row['Pais_malnutrido'] == 1 :\n      return 'Malnutrido'\n   else:\n      return 'Nutrido'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_completeness_1['Pais_malnutrido']=dataset_completeness_1.apply (lambda row: label_race(row), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=dataset_completeness_1['Pais_malnutrido']\n\nx=dataset_completeness_1.drop(['Pais_malnutrido','pctje_Muerte_por_malnutricion','Num_Muerte_por_malnutricion'], axis=1)\n\nX_train,X_test, y_train, y_test=train_test_split( x, y, test_size=0.33, random_state=42)\n\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load the Library\nfrom sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc = RandomForestClassifier()\nrfc.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Take predict on the xtest and see the score it had obtained\ny_pred=rfc.predict(X_test)\ndf_pred = pd.DataFrame(y_pred)\nrfc.score(X_test,y_test)\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Take the function Matrix imporatamos to see prediction\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\nprint(confusion_matrix(y_test,y_pred))\nprint(classification_report(y_test,y_pred))\nprint(accuracy_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We choose the important variables\nimportances = rfc.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in rfc.estimators_],\n             axis=0)\nindices = np.argsort(importances)[::-1]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We create a list with an array of predictions.\nnom_columnas=X_test.columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Let`s see the ranking of Feature\nprint(\"Feature ranking:\")\n\nfor f in range(X_test.shape[1]):\n    print(nom_columnas[f]+\" (%f)\" % (  importances[indices[f]]))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's repeat the model by removing that Health_exp_pct_GDP_2016 (0.166318). It look overffiting."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# Creamos un dataset paralelo para hacer el random forrest \ndataset_completo_rf=dataset_completeness_1.drop(['Country_Region_num'], axis=1)\ndataset_completeness_1=dataset_completeness_1.drop(['Country_Region_num'], axis=1)\n\n# 114 Paises\n# 102 Nutridos\n# 12 Malnutridos\n# Evaluamos el numero de paises malnutridos y nutridos que tenemos\nprint(dataset_completo_rf['Pais_malnutrido'].value_counts())\n\n# Balanceamos el modelo para quedarnos con el mismo número de malnutridos que nutridos\ndataset_completo_rf_1 = dataset_completo_rf.groupby('Pais_malnutrido')\ndataset_completo_rf_1 = pd.DataFrame(dataset_completo_rf_1.apply(lambda x: x.sample(dataset_completo_rf_1.size().min()).reset_index(drop=True)))\n\n# Evaluamos los cambios realizados\nprint(dataset_completo_rf_1['Pais_malnutrido'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Utilizamos el nuevo dataset para lanzar el random forrest\ny=dataset_completo_rf_1['Pais_malnutrido']\n\nx=dataset_completo_rf_1.drop(['Pais_malnutrido','pctje_Muerte_por_malnutricion','Num_Muerte_por_malnutricion'], axis=1)\n\nX_train,X_test, y_train, y_test=train_test_split( x, y, test_size=0.35, random_state=42)\n\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc = RandomForestClassifier()\npredictor=rfc.fit(X_train, y_train)\n\ny_pred=rfc.predict(X_test)\ndf_pred = pd.DataFrame(y_pred)\n\nimportances = rfc.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_test,y_pred))\nprint(classification_report(y_test,y_pred))\nprint(accuracy_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importances = rfc.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in rfc.estimators_],\n             axis=0)\nindices = np.argsort(importances)[::-1]\nnom_columnas=X_test.columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print the feature ranking\nprint(\"Feature ranking:\")\n\nfor f in range(X_test.shape[1]):\n    print(nom_columnas[f]+\" (%f)\" % (  importances[indices[f]]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Draw the desission tree to understand the Random Forest clasification\nnom_features=X_test.columns.tolist()\nnom_features_y=y_test.tolist()\nestimator = rfc.estimators_[5]","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"from sklearn.tree import export_graphviz\nimport graphviz\n# Export as dot file\ngraph = export_graphviz(estimator, \n                feature_names = nom_features,\n                class_names = nom_features_y,\n                rounded = True, proportion = False, \n                precision = 2, filled = True)\ngraphviz.Source(graph)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"LINEAR REGRESSION OF with Severe Wasting target.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_completeness_reg_lineal.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_completeness_reg_lineal","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Take exclude the categorical variables\ndataset_completeness_reg_lineal=dataset_completeness_reg_lineal.drop(['Country_Region','World_Bank_Name','Country','Country_Region_num','pctje_Muerte_por_malnutricion',\n       'Num_Muerte_por_malnutricion', 'Pais_malnutrido'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load necessary libraries for Linear Regresion\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib import cm\nplt.rcParams['figure.figsize'] = (16, 9)\nplt.style.use('ggplot')\nfrom sklearn import linear_model\nfrom sklearn.metrics import mean_squared_error, r2_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot all variables-- distribution \ndataset_completeness_reg_lineal.hist()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Take start Linear Regression Model\nregr = linear_model.LinearRegression()\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"dataset_completeness_reg_lineal=dataset_completeness_reg_lineal.fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_completeness_reg_lineal","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Take the target\ny=dataset_completeness_reg_lineal['Severe Wasting']\n\n# Taking out the target of dataset X \n\nx=dataset_completeness_reg_lineal.drop(['Severe Wasting'], axis=1)\n\n#split of datset xtrain e ytrain\nX_train,X_test, y_train, y_test=train_test_split( x, y, test_size=0.4, random_state=42)\n\n\n# Training the model\nregr.fit(X_train, y_train)\n \n# We make the predictions that ultimately one line (in this case, being 2D)\ny_pred = regr.predict(X_test)\n \n# Let's see the coefficients obtained. In our case, they will be the Tangent\nprint('Coefficients: \\n', regr.coef_)\n# This is the value where the Y axis cuts (in X=0)\nprint('Independent term: \\n', regr.intercept_)\n# Mean Square Error\nprint(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n# Variance Score. The best score is 1.0\nprint('Variance score: %.2f' % r2_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Take convert the prediction into a dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's repeat the same operation transforming the prediction into a data frame\ndf_pred = pd.DataFrame(data=y_pred,  columns=[\"pred\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# How many elements do we have in the test (evaluation) set?\ny_test.count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test=y_test.to_frame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# join up together\nprediction=pd.merge(X_test, y_test, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We create the indox to prediction\nprediction.reset_index(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets predict on dataset \nprediction_completeness=pd.merge(prediction, df_pred, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Show prediction completeness\nprediction_completeness","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_completeness.to_excel('dataset_reg_lineal_pred.xlsx')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Show the hyperparameters of the model\nregr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#\nregr.coef_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Y_pred = term indep + -2,71e-01*10,2+ -2.64339594e-02*5,1...... m1 X1 + m2 X2 + … + m(n) X(n)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_columns = pd.DataFrame(X_test.columns.tolist(),  columns =['columns'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_coef = pd.DataFrame(data=regr.coef_, columns=[\"coeficientes\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_coeficientes = pd.merge(df_columns, df_coef, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Save the dataframe of coeficientes to excel file"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_coeficientes.to_excel('coeficientes_reg_lineal.xlsx')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Decision Tree Regression**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decision Tree of LinealRegression\nfrom sklearn.tree import DecisionTreeRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# hiperparameter\nregr_1 = DecisionTreeRegressor(max_depth=5)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separate ytest and xpred from dataset\ny=dataset_completeness_reg_lineal['Severe Wasting']\n\nx=dataset_completeness_reg_lineal.drop(['Severe Wasting'], axis=1)\n\nX_train,X_test, y_train, y_test=train_test_split( x, y, test_size=0.4, random_state=42)\n\n\n# Training the model\nregr_1.fit(X_train, y_train)\n \n# Making the prediction that ultimately one line \ny_pred = regr_1.predict(X_test)\n \nprint(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n# Variance Score. The best score is 1.0\nprint('Variance score: %.2f' % r2_score(y_test, y_pred))\n\nprint('Score: %.2f' % regr_1.score(X_test, y_test))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"regr_1.get_params()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot linear regression\ndataset_completeness_reg_lineal.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pinting the Linear regression of *Level of current health expenditure expressed as a percentage of GDP *.\nx_draw=dataset_completeness_reg_lineal['Health_exp_pct_GDP_2016']\n\nX_test_draw=X_test['Health_exp_pct_GDP_2016']\nplt.figure()\n#plt.scatter(x_draw, y, s=20, edgecolor=\"black\",\n #           c=\"darkorange\", label=\"data\")\nplt.plot(X_test, y_test, color=\"cornflowerblue\",\n         label=\"max_depth=2\", linewidth=2)\nplt.xlabel(\"data\")\nplt.ylabel(\"target\")\nplt.title(\"Decision Tree Regression\")\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" Data containt outlier value\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}