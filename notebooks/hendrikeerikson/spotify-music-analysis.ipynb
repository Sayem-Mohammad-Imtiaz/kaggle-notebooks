{"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"},"language_info":{"codemirror_mode":{"version":3,"name":"ipython"},"mimetype":"text/x-python","file_extension":".py","version":"3.6.3","nbconvert_exporter":"python","pygments_lexer":"ipython3","name":"python"}},"nbformat":4,"cells":[{"source":"# Spotify music analysis\n\nThis notebook does basic analysis of song metadata taken from spotify. The data contains numeric metrics generetade by spotify on the songs danceability, mood, liveness, etc. The data also contains the songs title and artist.","cell_type":"markdown","metadata":{}},{"execution_count":null,"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\nfrom sklearn import datasets, linear_model\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.manifold import TSNE\n\n%matplotlib inline\n\ndata_frame = pd.read_csv(\"../input/data.csv\")\ndata_frame.head()","cell_type":"code","metadata":{"_cell_guid":"923dda0d-d248-4d0e-be78-5a00e49f6722","scrolled":true,"_uuid":"888a736f6744f709d667bf674817abb178628f2f"},"outputs":[]},{"execution_count":null,"source":"x = data_frame[\"danceability\"].values\ny = data_frame[\"valence\"].values\n\nx = x.reshape(x.shape[0], 1)\ny = y.reshape(y.shape[0], 1)\n\nregr = linear_model.LinearRegression()\nregr.fit(x, y)\n\nfig = plt.figure(figsize=(6, 6))\nfig.suptitle(\"Correlation between danceability and song mood\")\n\nax = plt.subplot(1, 1, 1)\nax.scatter(x, y, alpha=0.5)\nax.plot(x, regr.predict(x), color=\"red\", linewidth=3)\nplt.xticks(())\nplt.yticks(())\n\nax.xaxis.set_major_locator(ticker.MultipleLocator(0.1))\nax.xaxis.set_minor_locator(ticker.MultipleLocator(0.02))\n\nax.yaxis.set_major_locator(ticker.MultipleLocator(0.1))\nax.yaxis.set_minor_locator(ticker.MultipleLocator(0.02))\n\nplt.xlabel(\"danceability\")\nplt.ylabel(\"valence\")\n\nplt.show()","cell_type":"code","metadata":{"_cell_guid":"cd1e2deb-bb4c-491f-8801-58c798ca9827","_uuid":"1550de598be0a27e003e97c3bdb345116a8c7832"},"outputs":[]},{"execution_count":null,"source":"x = \"danceability\"\ny = \"valence\"\n\nfig, (ax1, ax2) = plt.subplots(1, 2, sharey=False, sharex=False, figsize=(10, 5))\nfig.suptitle(\"Histograms\")\nax1.hist2d(data_frame[x], data_frame[y], bins=20)\nax2.hist(data_frame[\"energy\"])\n\nax1.set_xlabel(x)\nax1.set_ylabel(y)\n\nax2.set_xlabel(\"energy\")\n\nplt.show()","cell_type":"code","metadata":{"_cell_guid":"2683892f-7144-4e3c-9982-9fd929133e81","_uuid":"b7f5c7abb99c9e2389a3f9b00d51e7bf03b73b70"},"outputs":[]},{"execution_count":null,"source":"chosen = [\"energy\", \"liveness\", \"tempo\", \"valence\", \"loudness\", \"speechiness\", \"acousticness\", \"danceability\", \"instrumentalness\"]\ntext1 = data_frame[\"artist\"] + \" - \" + data_frame[\"song_title\"]\ntext2 = text1.values\n\n# X = data_frame.drop(droppable, axis=1).values\nX = data_frame[chosen].values\ny = data_frame[\"danceability\"].values\n\nmin_max_scaler = MinMaxScaler()\nX = min_max_scaler.fit_transform(X)\n\npca = PCA(n_components=3)\npca.fit(X)\n\nX = pca.transform(X)\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\ntrace = go.Scatter3d(\n    x=X[:,0],\n    y=X[:,1],\n    z=X[:,2],\n    text=text2,\n    mode=\"markers\",\n    marker=dict(\n        size=8,\n        color=y\n    )\n)\n\nfig = go.Figure(data=[trace])\npy.iplot(fig, filename=\"test-graph\")","cell_type":"code","metadata":{"_cell_guid":"37348dc7-fa82-4eb3-ab2b-f6bb51abe4b3","_uuid":"c6f471a64e0acdab363752170ca9b6adcc15ef98"},"outputs":[]},{"execution_count":null,"source":"chosen = [\"energy\", \"liveness\", \"tempo\", \"valence\"]\ntext1 = data_frame[\"artist\"] + \" - \" + data_frame[\"song_title\"]\ntext2 = text1.values\n\n# X = data_frame.drop(droppable, axis=1).values\nX = data_frame[chosen].values\ny = data_frame[\"loudness\"].values\n\nmin_max_scaler = MinMaxScaler()\nX = min_max_scaler.fit_transform(X)\n\npca = PCA(n_components=2)\npca.fit(X)\n\nX = pca.transform(X)\n\nfig = {\n    \"data\": [\n        {\n            \"x\": X[:, 0],\n            \"y\": X[:, 1],\n            \"text\": text2,\n            \"mode\": \"markers\",\n            \"marker\": {\"size\": \"8\", \"color\": y}\n        }\n    ],\n    \"layout\": {\n        \"xaxis\": {\"title\": \"How hard is this to dance to?\"},\n        \"yaxis\": {\"title\": \"How metal is this?\"}\n    }\n}\n\npy.iplot(fig, filename=\"test-graph2\")","cell_type":"code","metadata":{"_cell_guid":"423ce2d3-aea8-497e-9c63-7d658d662aa1","_uuid":"08da859705a55c15d6d12474aceeb25ff362f0c1"},"outputs":[]},{"execution_count":null,"source":"import time\n\nchosen = [\"energy\", \"liveness\", \"tempo\", \"valence\", \"loudness\",\n          \"speechiness\", \"acousticness\", \"danceability\", \"instrumentalness\"]\n\nX = data_frame[chosen].values\ny = data_frame[\"loudness\"].values\n\nmin_max_scaler = MinMaxScaler()\nX = min_max_scaler.fit_transform(X)\n\ntime_start = time.time()\ntsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\ntsne_results = tsne.fit_transform(X)\n\nprint('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))\n\nfig = {\n    \"data\": [\n        {\n            \"x\": tsne_results[:, 0],\n            \"y\": tsne_results[:, 1],\n            \"text\": text2,\n            \"mode\": \"markers\",\n            \"marker\": {\"size\": \"8\", \"color\": y}\n        }\n    ],\n    \"layout\": {\n        \"xaxis\": {\"title\": \"x-tsne\"},\n        \"yaxis\": {\"title\": \"y-tsne\"}\n    }\n}\n\npy.iplot(fig, filename=\"test-graph2\")","cell_type":"code","metadata":{"_cell_guid":"560e211c-72b0-439c-9629-ec6dc929f9cb","_uuid":"384c270e4d8fb002b7dfef49f2efeeb04a680f06"},"outputs":[]}],"nbformat_minor":1}