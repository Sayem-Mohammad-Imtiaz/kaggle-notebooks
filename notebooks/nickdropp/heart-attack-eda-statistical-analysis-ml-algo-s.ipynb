{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\nimport tensorflow as tf\nfrom tensorflow import keras\n# Layers for our neural networks\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n# A pretrained model for transfer learning\nfrom keras.models import Model\nfrom keras.applications import vgg19\n\n# Our normal python data science stack you've come to know and love\n\n\nimport sys\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n\n# Helper fuctions to evaluate our model.\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score\n\nfrom sklearn import tree\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom sklearn.model_selection import GridSearchCV\n\nimport statsmodels.api as sm\n\nimport xgboost as xgb\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-02T17:15:08.941265Z","iopub.execute_input":"2021-06-02T17:15:08.941635Z","iopub.status.idle":"2021-06-02T17:15:08.961131Z","shell.execute_reply.started":"2021-06-02T17:15:08.941605Z","shell.execute_reply":"2021-06-02T17:15:08.960281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_o2sat = pd.read_csv('../input/heart-attack-analysis-prediction-dataset/o2Saturation.csv')\ndf_heart = pd.read_csv('../input/heart-attack-analysis-prediction-dataset/heart.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:15:08.962583Z","iopub.execute_input":"2021-06-02T17:15:08.96312Z","iopub.status.idle":"2021-06-02T17:15:08.985295Z","shell.execute_reply.started":"2021-06-02T17:15:08.963077Z","shell.execute_reply":"2021-06-02T17:15:08.984349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Shape of o2 Saturation dataset ' + str(df_o2sat.shape))\nprint('Shape of heart attack dataset ' + str(df_heart.shape))\ndf_heart","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:15:08.987256Z","iopub.execute_input":"2021-06-02T17:15:08.987855Z","iopub.status.idle":"2021-06-02T17:15:09.015513Z","shell.execute_reply.started":"2021-06-02T17:15:08.98781Z","shell.execute_reply":"2021-06-02T17:15:09.01424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_heart","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:15:09.017782Z","iopub.execute_input":"2021-06-02T17:15:09.018126Z","iopub.status.idle":"2021-06-02T17:15:09.04604Z","shell.execute_reply.started":"2021-06-02T17:15:09.018093Z","shell.execute_reply":"2021-06-02T17:15:09.044883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_heart.output.value_counts().plot(kind ='bar')\nplt.title('Heart attack frequency')","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:15:09.047624Z","iopub.execute_input":"2021-06-02T17:15:09.047966Z","iopub.status.idle":"2021-06-02T17:15:09.200073Z","shell.execute_reply.started":"2021-06-02T17:15:09.047935Z","shell.execute_reply":"2021-06-02T17:15:09.19907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Assuming 1 is a heart attack and 0 is no heart attack, 165 heart attacks in the dataset****","metadata":{}},{"cell_type":"code","source":"df_heart.isna().sum()\n#no missing values","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:15:09.20143Z","iopub.execute_input":"2021-06-02T17:15:09.201767Z","iopub.status.idle":"2021-06-02T17:15:09.210924Z","shell.execute_reply.started":"2021-06-02T17:15:09.201736Z","shell.execute_reply":"2021-06-02T17:15:09.2098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20,20))     \nsns.heatmap(df_heart.corr(),annot=True,cmap='coolwarm')\nplt.title('Correlation Plot ')","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:15:09.212296Z","iopub.execute_input":"2021-06-02T17:15:09.212751Z","iopub.status.idle":"2021-06-02T17:15:10.71485Z","shell.execute_reply.started":"2021-06-02T17:15:09.212642Z","shell.execute_reply":"2021-06-02T17:15:10.713593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorical_cols = ['sex', 'cp', 'fbs', 'restecg', 'exng','slp', 'caa','thall'] # 8\ncontinous_cols = ['age', 'trtbps', 'chol','thalachh', 'oldpeak'] # 5\nlabel_col = ['output']\n#X = df['']","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:15:10.716289Z","iopub.execute_input":"2021-06-02T17:15:10.716632Z","iopub.status.idle":"2021-06-02T17:15:10.721899Z","shell.execute_reply.started":"2021-06-02T17:15:10.716597Z","shell.execute_reply":"2021-06-02T17:15:10.720834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnt = 0\nmax_in_row = 3\nfor x in continous_cols:\n    data = df_heart[x]\n    plt.figure(cnt//max_in_row, figsize=(40,4))\n    plt.subplot(1, max_in_row, (cnt)%max_in_row + 1)\n    plt.title(x)\n    sns.histplot(data, bins = 50, kde=50);\n    cnt += 1","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:15:10.724751Z","iopub.execute_input":"2021-06-02T17:15:10.725102Z","iopub.status.idle":"2021-06-02T17:15:12.003208Z","shell.execute_reply.started":"2021-06-02T17:15:10.725067Z","shell.execute_reply":"2021-06-02T17:15:12.001652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_in_row = 3\nfor x in continous_cols:\n    plt.figure(cnt//max_in_row, figsize=(25,4))\n    plt.subplot(1, max_in_row, (cnt)%max_in_row + 1)\n    plt.title(x)\n    sns.kdeplot(data=df_heart, x=x, hue=\"output\", fill=True, common_norm=1, alpha=.5, linewidth=0);\n    cnt += 1","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:15:12.005667Z","iopub.execute_input":"2021-06-02T17:15:12.006018Z","iopub.status.idle":"2021-06-02T17:15:12.903358Z","shell.execute_reply.started":"2021-06-02T17:15:12.005987Z","shell.execute_reply":"2021-06-02T17:15:12.902195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_in_row = 3\nfor x in categorical_cols:\n    plt.figure(cnt//max_in_row, figsize=(25,4))\n    plt.subplot(1, max_in_row, (cnt)%max_in_row + 1)\n    plt.title(x)\n    sns.kdeplot(data=df_heart, x=x, hue=\"output\", fill=True, common_norm=False, alpha=.5, linewidth=0,);\n    cnt += 1","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:15:12.904564Z","iopub.execute_input":"2021-06-02T17:15:12.90487Z","iopub.status.idle":"2021-06-02T17:15:14.297533Z","shell.execute_reply.started":"2021-06-02T17:15:12.904814Z","shell.execute_reply":"2021-06-02T17:15:14.296227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Some statistical analysis","metadata":{}},{"cell_type":"code","source":"#some statistical libraries\nimport statsmodels.api as sm\nfrom scipy.stats import shapiro\nimport scipy.stats as stats\nfrom scipy.stats import anderson\nfrom scipy.stats import norm, skew","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:15:14.298955Z","iopub.execute_input":"2021-06-02T17:15:14.299282Z","iopub.status.idle":"2021-06-02T17:15:14.304847Z","shell.execute_reply.started":"2021-06-02T17:15:14.299249Z","shell.execute_reply":"2021-06-02T17:15:14.303463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Are any of the continous variables in the dataset normal?\nLets use graphs and normality tests to verify normality","metadata":{"execution":{"iopub.status.busy":"2021-05-25T20:45:42.070394Z","iopub.execute_input":"2021-05-25T20:45:42.070832Z","iopub.status.idle":"2021-05-25T20:45:42.075738Z","shell.execute_reply.started":"2021-05-25T20:45:42.070796Z","shell.execute_reply":"2021-05-25T20:45:42.074435Z"}}},{"cell_type":"code","source":"max_in_row = 3\ncnt=0\nfor x in continous_cols:\n    plt.figure(cnt//max_in_row, figsize=(25,4))\n    plt.subplot(1, max_in_row, (cnt)%max_in_row + 1)\n    plt.title(x)\n    sns.boxplot(df_heart[x],orient='v')\n    cnt += 1","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:15:14.306329Z","iopub.execute_input":"2021-06-02T17:15:14.306704Z","iopub.status.idle":"2021-06-02T17:15:14.835632Z","shell.execute_reply.started":"2021-06-02T17:15:14.306671Z","shell.execute_reply":"2021-06-02T17:15:14.834541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Let's remove the outliers from thalachh, oldpeak, chol, trtbps & test for normality","metadata":{}},{"cell_type":"code","source":"Q1 = df_heart.thalachh.quantile(.25)\nQ3= df_heart.thalachh.quantile(.75)\nIQR = Q3 - Q1 # the 50% between .25 & .75\nfilter = (df_heart.thalachh >= Q1 - 1.5 * IQR) & (df_heart.thalachh <= Q3 + 1.5 *IQR)\nsns.boxplot(df_heart.loc[filter].thalachh,orient='v')\nplt.title('Thalachh boxplot after removing outliers ')\nshapiro(df_heart.loc[filter].thalachh)\nfig = plt.figure()\nres = stats.probplot(df_heart.loc[filter].thalachh, plot=plt)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:15:14.83855Z","iopub.execute_input":"2021-06-02T17:15:14.839012Z","iopub.status.idle":"2021-06-02T17:15:15.114542Z","shell.execute_reply.started":"2021-06-02T17:15:14.838967Z","shell.execute_reply":"2021-06-02T17:15:15.11368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Thalachh does not have a pvalue > .05. so we reject the null hypothesis & it does not fit the QQ plot","metadata":{}},{"cell_type":"code","source":"Q1 = df_heart.oldpeak.quantile(.25)\nQ3= df_heart.oldpeak.quantile(.75)\nIQR = Q3 - Q1 # the 50% between .25 & .75\nfilter = (df_heart.oldpeak >= Q1 - 1.5 * IQR) & (df_heart.oldpeak <= Q3 + 1.5 *IQR)\nsns.boxplot(df_heart.loc[filter].oldpeak,orient='v')\nplt.title('Oldpeak boxplot after removing outliers ')\nshapiro(df_heart.loc[filter].oldpeak)\nfig = plt.figure()\nres = stats.probplot(df_heart.loc[filter].oldpeak, plot=plt)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:15:15.115824Z","iopub.execute_input":"2021-06-02T17:15:15.116135Z","iopub.status.idle":"2021-06-02T17:15:15.398533Z","shell.execute_reply.started":"2021-06-02T17:15:15.116104Z","shell.execute_reply":"2021-06-02T17:15:15.397673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Oldpeak does not have a pvalue > .05. so we reject the null hypothesis & it does not fit the QQ plot","metadata":{}},{"cell_type":"code","source":"Q1 = df_heart.chol.quantile(.25)\nQ3= df_heart.chol.quantile(.75)\nIQR = Q3 - Q1 # the 50% between .25 & .75\nfilter = (df_heart.chol >= Q1 - 1.5 * IQR) & (df_heart.chol <= Q3 + 1.5 *IQR)\nsns.boxplot(df_heart.loc[filter].chol,orient='v')\nplt.title('Chol boxplot after removing outliers ')\nprint(shapiro(df_heart.loc[filter].chol))\n\nfig = plt.figure()\nres = stats.probplot(df_heart.loc[filter].chol, plot=plt)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:15:15.399913Z","iopub.execute_input":"2021-06-02T17:15:15.400487Z","iopub.status.idle":"2021-06-02T17:15:15.670111Z","shell.execute_reply.started":"2021-06-02T17:15:15.400442Z","shell.execute_reply":"2021-06-02T17:15:15.669264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Cholesterol is normal, pvalue > .05 so we accept the null hypothesis","metadata":{}},{"cell_type":"code","source":"Q1 = df_heart.trtbps.quantile(.25)\nQ3= df_heart.trtbps.quantile(.75)\nIQR = Q3 - Q1 # the 50% between .25 & .75\nfilter = (df_heart.trtbps >= Q1 - 1.5 * IQR) & (df_heart.trtbps <= Q3 + 1.5 *IQR)\nsns.boxplot(df_heart.loc[filter].trtbps,orient='v')\nplt.title('Trtbps boxplot after removing outliers ')\nprint(shapiro(df_heart.loc[filter].trtbps))\n\nfig = plt.figure()\nres = stats.probplot(df_heart.loc[filter].trtbps, plot=plt)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:15:15.671325Z","iopub.execute_input":"2021-06-02T17:15:15.671895Z","iopub.status.idle":"2021-06-02T17:15:15.94452Z","shell.execute_reply.started":"2021-06-02T17:15:15.671852Z","shell.execute_reply":"2021-06-02T17:15:15.943754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Trtbps  does not have a pvalue > .05. so we reject the null hypothesis & it does not fit the QQ plot","metadata":{}},{"cell_type":"markdown","source":"## Cholesterol is normal so let's analyze it a bit more","metadata":{}},{"cell_type":"markdown","source":"### What is the average cholesterol for people that are more likely to have heart attack?","metadata":{}},{"cell_type":"code","source":"Q1 = df_heart.chol.quantile(.25)\nQ3= df_heart.chol.quantile(.75)\nIQR = Q3 - Q1 # the 50% between .25 & .75\nfilter0 = (df_heart.chol >= Q1 - 1.5 * IQR) & (df_heart.chol <= Q3 + 1.5 *IQR) & (df_heart.output == 1)\nsm.stats.DescrStatsW(df_heart[filter]['chol']).zconfint_mean()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:15:15.945804Z","iopub.execute_input":"2021-06-02T17:15:15.946271Z","iopub.status.idle":"2021-06-02T17:15:15.959243Z","shell.execute_reply.started":"2021-06-02T17:15:15.946224Z","shell.execute_reply":"2021-06-02T17:15:15.958395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### What does this mean? This means that the cholesterol population average of people that are more likely to have heart attacks have a mean cholesterole between 231 - 245.","metadata":{}},{"cell_type":"markdown","source":"## What about the population average of cholesterol for people that are less likely to have a heart attack?","metadata":{}},{"cell_type":"code","source":"Q1 = df_heart.chol.quantile(.25)\nQ3= df_heart.chol.quantile(.75)\nIQR = Q3 - Q1 # the 50% between .25 & .75\nfilter1 = (df_heart.chol >= Q1 - 1.5 * IQR) & (df_heart.chol <= Q3 + 1.5 *IQR) & (df_heart.output == 0)\nsm.stats.DescrStatsW(df_heart[filter]['chol']).zconfint_mean()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:15:15.960418Z","iopub.execute_input":"2021-06-02T17:15:15.960901Z","iopub.status.idle":"2021-06-02T17:15:15.982668Z","shell.execute_reply.started":"2021-06-02T17:15:15.960855Z","shell.execute_reply":"2021-06-02T17:15:15.98135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### What does this mean? This means that the cholesterol population average of people that are more likely to have heart attacks have a mean cholesterole between 241 - 256.","metadata":{}},{"cell_type":"markdown","source":"## These population averages are rather similiar, is there a statistically significant difference between the the population that is more likely to have a heart attack and the population that is less likely to have a heart attack?\n* Null Hypothesis- There is no statistically significant difference between the two populations.\n* Alternate Hypothesis - There does exist a statiscally significant difference betweent he two populations\n## We will use t-test's to see if there is a difference.\n### Do the 2 populations share the same variance? Levenne test will tell us.","metadata":{}},{"cell_type":"markdown","source":"*  Null hypothesis - the two populations have the same variance\n*  Alternate hypothesis- the two populations have different variances","metadata":{}},{"cell_type":"code","source":"leveneTest = stats.levene(df_heart[filter0].chol, df_heart[filter1].chol)\nleveneTest","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:15:15.983934Z","iopub.execute_input":"2021-06-02T17:15:15.984255Z","iopub.status.idle":"2021-06-02T17:15:16.006586Z","shell.execute_reply.started":"2021-06-02T17:15:15.984226Z","shell.execute_reply":"2021-06-02T17:15:16.005149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The p-value is greater than .05, so we don't accept the alternate hypothesis, and can proceed with a t-test","metadata":{}},{"cell_type":"code","source":"ttest = stats.ttest_ind(df_heart[filter0]['chol'], df_heart[filter1]['chol'], equal_var=1)\nttest\n","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:15:16.008155Z","iopub.execute_input":"2021-06-02T17:15:16.008582Z","iopub.status.idle":"2021-06-02T17:15:16.02574Z","shell.execute_reply.started":"2021-06-02T17:15:16.008544Z","shell.execute_reply":"2021-06-02T17:15:16.024635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Since the p-value is less than .05, we can safely infer that the population of people that have heart attacks come from a different distribution than the population that does not have heart attacks.","metadata":{}},{"cell_type":"markdown","source":"# Start of machine learning models","metadata":{}},{"cell_type":"code","source":"df_heart = pd.get_dummies(df_heart, columns = categorical_cols, drop_first = True)\n\nX = df_heart.drop(['output'],axis=1) \n\ny = df_heart['output']\nscalerX = MinMaxScaler(feature_range=(0, 1))\nX[X.columns] = scalerX.fit_transform(X[X.columns])\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:15:16.072039Z","iopub.status.idle":"2021-06-02T17:15:16.072471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Logistic Regression Model","metadata":{}},{"cell_type":"code","source":"model = LogisticRegression(max_iter=550)\n# Train our model using our training data.\n\nmodel.fit(X_train, y_train)\n#model.predict(X_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:15:16.073768Z","iopub.status.idle":"2021-06-02T17:15:16.074414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:15:16.075606Z","iopub.status.idle":"2021-06-02T17:15:16.076253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# Calculate our accuracy\naccuracy  = accuracy_score(y_test, y_pred)\n\n# Calculate our precision score\nprecision = precision_score(y_test, y_pred)\n\n# Calculate our recall score\nrecall = recall_score(y_test, y_pred)\n\nf1 = f1_score(y_test, y_pred)\n\n# Print each of our scores to inspect performance.\nprint(\"Accuracy Score: %f\" % accuracy)\nprint(\"Precision Score: %f\" % precision)\nprint(\"Recall Score: %f\" % recall)\nprint('F1 Score %f' % f1)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:15:16.077477Z","iopub.status.idle":"2021-06-02T17:15:16.077969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Logistic Regression model gives accuracy of 90%","metadata":{}},{"cell_type":"markdown","source":"# Neural Network Model","metadata":{}},{"cell_type":"code","source":"model = tf.keras.models.Sequential([                \n  tf.keras.layers.Dense(256, activation='relu'),\ntf.keras.layers.Dense(1, activation='sigmoid')\n])\nmodel.compile(optimizer=tf.keras.optimizers.Adam(), loss='binary_crossentropy', metrics=['acc'])\nepochs = 100\nmodel.fit(X_train, y_train, epochs=epochs, validation_split=0.1,verbose=0)\nmodel.evaluate(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:15:16.079202Z","iopub.status.idle":"2021-06-02T17:15:16.079634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Neural Network accuracy: 87%","metadata":{}},{"cell_type":"code","source":"#model = DecisionTreeClassifier(max_depth=)\nparams = {\n    'criterion' : ['gini', 'entropy'],\n    'max_depth': [2, 4, 8, 16,32,64,128], \n    'min_samples_split': [2, 4, 8, 16,32,64,128],\n    'min_samples_leaf': [2, 4, 8, 16,32,64,128],\n         }\ngrid_search_cv =  GridSearchCV( \n    estimator = DecisionTreeClassifier(), \n    param_grid = params, \n    scoring = 'accuracy')\ngrid_search_cv.fit(X_train, y_train)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:15:16.08063Z","iopub.status.idle":"2021-06-02T17:15:16.081039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = DecisionTreeClassifier(grid_search_cv.best_estimator_)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:15:16.082Z","iopub.status.idle":"2021-06-02T17:15:16.082432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = grid_search_cv.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:15:16.0836Z","iopub.status.idle":"2021-06-02T17:15:16.084018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_pred = model.predict(X_test)\n\naccuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\nprint(\"Accuracy Score: %f\" % accuracy)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:15:16.084977Z","iopub.status.idle":"2021-06-02T17:15:16.085414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Decision Tree Classifier not so good","metadata":{}},{"cell_type":"markdown","source":"# Random Forrest 82% accuracy","metadata":{}},{"cell_type":"code","source":"\nmodel = RandomForestClassifier()\nmodel.fit(X_train, y_train)\n\npred = model.predict(X_test)\nprint(accuracy_score(pred,y_test))","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:15:16.086243Z","iopub.status.idle":"2021-06-02T17:15:16.086764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# K Neighbors classifier 89% accuracy","metadata":{}},{"cell_type":"code","source":"model =  KNeighborsClassifier(n_neighbors=9)\nmodel.fit(X_train,y_train)\ny_pred = model.predict(X_test)\nprint(accuracy_score(y_pred,y_test))","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:15:16.087644Z","iopub.status.idle":"2021-06-02T17:15:16.088048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Support Vector Machine Classifier 85%","metadata":{}},{"cell_type":"code","source":"params = {\n            'max_iter' : [5,7,9,10,12,-1],\n            'degree' : [2,3,4,5,6],\n            'kernel' : [ 'poly','sigmoid','rbf','linear'],\n            'gamma' : ['scale','auto'],\n        \n         }\ngrid_search_cv =  GridSearchCV( \n    estimator = SVC(), \n    param_grid = params, \n    scoring = 'accuracy')\ngrid_search_cv.fit(X_train, y_train)\ny_pred = grid_search_cv.predict(X_test)\nprint(grid_search_cv.best_estimator_)\naccuracy_score(y_pred=y_pred,y_true=y_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:15:16.088886Z","iopub.status.idle":"2021-06-02T17:15:16.08931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = SVC(max_iter=10,degree=3,kernel='poly')\nmodel.fit(X_train,y_train)\ny_pred = model.predict(X_test)\nprint(accuracy_score(y_pred,y_test))","metadata":{"execution":{"iopub.status.busy":"2021-06-02T17:15:16.090192Z","iopub.status.idle":"2021-06-02T17:15:16.090672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}