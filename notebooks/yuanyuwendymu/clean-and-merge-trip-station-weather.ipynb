{"cells":[{"metadata":{},"cell_type":"markdown","source":"The data cleaning & merging process is based on the documentation 'Codebook from Data Source' in the 'Discuss' session, which can be found here: https://www.kaggle.com/benhamner/sf-bay-area-bike-share/discussion/23165"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom datetime import datetime","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trip = pd.read_csv('../input/trip.csv')\nstation = pd.read_csv('../input/station.csv')\nweather = pd.read_csv('../input/weather.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploration"},{"metadata":{},"cell_type":"markdown","source":"Show the first 5 rows of 3 datasets."},{"metadata":{"trusted":true},"cell_type":"code","source":"trip.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"station.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"weather.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Find the unique identifier in **trip** dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"result = trip.groupby('id')['start_date'].count().sort_values(ascending = False)\nresult.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All results equal to 1, meaning that *id* is the unique identifier of *trip* dataset."},{"metadata":{},"cell_type":"markdown","source":"Get an idea of missing values."},{"metadata":{"trusted":true},"cell_type":"code","source":"trip.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weather.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"station.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Merge Data"},{"metadata":{},"cell_type":"markdown","source":"### Transform trip data\nFirst, get rid of *zip_code* column. As 'Codebook from Data Source' in the Discussion session describes, *zip_code* represents \"Home zip code of subscriber (customers can choose to manually enter zip at kiosk however data is unreliable)\". The column itself may not be very reliable, and the analysis will not need the home zip of customers. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = trip.drop(columns = ['zip_code'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Second, change *start_date* and *end_date* to datetime object. Extract the date in %Y-%m-%d format to join on **weather** dataset later on."},{"metadata":{"trusted":true},"cell_type":"code","source":"##Transform start and end date to datetime objects\ndf1['start_date'] = df1['start_date'].apply(lambda x: datetime.strptime(x, '%m/%d/%Y %H:%M'))\ndf1['end_date'] = df1['end_date'].apply(lambda x: datetime.strptime(x, '%m/%d/%Y %H:%M'))\n##Extracc only year, month and date to join on weather data later on\ndf1['date_for_join'] = df1['start_date'].apply(lambda x: x.strftime('%Y-%m-%d'))\ndf1['date_for_join'] = df1['date_for_join'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Join trip with station"},{"metadata":{},"cell_type":"markdown","source":"First, add a *zip_for_join* column to **station** data before join. This is for linking **station**.*city* column with **weather**.*zip_code* column. As 'Codebook from Data Source' in the Discussion session describes, \"94107=San Francisco, 94063=Redwood City, 94301=Palo Alto, 94041=Mountain View, 95113= San Jose\". "},{"metadata":{"trusted":true},"cell_type":"code","source":"city_zip = pd.DataFrame({'city': ['San Jose', 'Redwood City', 'Mountain View', 'Palo Alto','San Francisco'], \\\n                         'zip_for_join': [95113,94063,94041,94301,94107]})\nmerge1 = station.merge(city_zip, how = 'left', left_on = 'city', right_on = 'city')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Second, create **merge2** as a copy of **merge1** to join on transformed **trip** data to find the station info of *start_station*, create **merge3** as another copy of **merge1** to find the station info of *end_station*."},{"metadata":{"trusted":true},"cell_type":"code","source":"merge2 = merge1.copy()\nmerge2.columns = ['start_station_id','start_name','start_lat','start_long','start_dock_count','start_city','start_installation_date','start_zip']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merge3 = merge1.copy()\nmerge3.columns =  ['end_station_id','end_name','end_lat','end_long','end_dock_count','end_city','end_installation_date','end_zip']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merge4 = df1.merge(merge2, how = 'left', left_on = 'start_station_id',right_on = 'start_station_id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merge5 = merge4.merge(merge3,how = 'left', left_on = 'end_station_id',right_on = 'end_station_id' )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merge6 = merge5.drop(columns = ['start_name','end_name'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Transform and join weather data"},{"metadata":{},"cell_type":"markdown","source":"First, change the *date* column into datetime object."},{"metadata":{"trusted":true},"cell_type":"code","source":"weather['date'] = weather['date'].apply(lambda x: datetime.strptime(x,'%m/%d/%Y'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Second, create **start_weather** as a copy of **weather** to join on **merge6** to find the weather info of start_station, create **end_weather** as another copy of **weather** to find the weather info of end_station."},{"metadata":{"trusted":true},"cell_type":"code","source":"start_weather = weather.copy()\ncolumns = list(start_weather.columns)\nnew_columns = []\nfor i in columns:\n    i = 'start_' + i\n    new_columns.append(i)\nstart_weather.columns = new_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"end_weather = weather.copy()\ncolumns = list(end_weather.columns)\nnew_columns = []\nfor i in columns:\n    i = 'end_' + i\n    new_columns.append(i)\nend_weather.columns = new_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merge7 = merge6.merge(start_weather, how = 'left', left_on = ['date_for_join','start_zip'], \\\n                      right_on = ['start_date','start_zip_code'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merge8 = merge7.merge(end_weather,how = 'left', left_on = ['date_for_join','end_zip'], \\\n                      right_on = ['end_date','end_zip_code'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merge8.head(5).transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merge9 = merge8.drop(columns = ['end_zip_code','end_date_y','start_date_y',\\\n                                'start_zip_code','date_for_join'])\nmerge9.rename(columns={'start_date_x':'start_date','end_date_x':'end_date'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Clean Merged Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"merge9.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Find all columns with NAs, sort by #of NAs."},{"metadata":{"trusted":true},"cell_type":"code","source":"na_list = pd.DataFrame(merge9.isnull().sum())\nna_list['column_name'] = na_list.index\nna_list.columns = ['count_na','column_name']\nna_column = na_list[na_list['count_na']>0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"na_column.sort_values(by = 'count_na')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*start_events* and *end_event* denote the unusal weather events (fog, rain, ect.) on a particular day. NA means that there was no unusal event on that day. Therefore I filled NAs with \"No Special Events\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"merge9['start_events'] = merge9['start_events'].fillna('No Special Events')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merge9['end_events'] = merge9['end_events'].fillna('No Special Events')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merge9 = merge9.drop(columns = ['start_max_gust_speed_mph','end_max_gust_speed_mph'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, remove about 0.07% of records that has NA values (mostly in weather data)."},{"metadata":{"trusted":true},"cell_type":"code","source":"merge10 = merge9.dropna()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check the final data shape and export the merged and cleaned dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"merge10.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merge10.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"merge10.to_csv('SF_Bay_Area_Bike_Share_Data_Cleaned.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"256px"},"toc_section_display":true,"toc_window_display":true}},"nbformat":4,"nbformat_minor":1}