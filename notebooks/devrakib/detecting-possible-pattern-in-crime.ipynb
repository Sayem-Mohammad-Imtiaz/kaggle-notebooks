{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use('dark_background')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/homicide-reports/database.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.describe())\ndf.describe().plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df)\nplt.title('Crime Happened Between 1980-2014')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"crime_describe = df.describe()\ntype(crime_describe)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"crime_describe = crime_describe.drop(columns = ['Record ID'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"crime_describe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Incident'].sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### So we have 14.663963 Million Crime Happpened In Just 34 Years In US..","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"states = df['State'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(states)\n\n#so in all states","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cities = df['City'].unique()\nlen(cities)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"more_focused = df[['Victim Sex', 'Victim Age', 'Perpetrator Sex','Perpetrator Age', 'Relationship', \n                  'Weapon', 'Victim Count', 'Perpetrator Count', 'Crime Type', 'City', 'State','Year', \n                  'Month', 'Incident']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"more_focused.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"more_focused['Crime Type'].unique()\n\n# so we have just murdered..","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"more_focused['Victim Count'].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"more_focused['Perpetrator Count'].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(more_focused['Victim Count'], more_focused['Perpetrator Count'])\nplt.grid()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Strange! We see When Perpetrator Decreases Victim Count Increases","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,8))\nsns.barplot(more_focused['Year'],more_focused['Incident'])\nplt.xticks(rotation= 'vertical')\nplt.title('Yearly Incident(Murdered) In US\\n1980-2014')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We Can See After 2008 Financial Crisis The Rate Had Rised Heavily.. But After Few Years the Count Has become Quite steady..","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### From 1991 to 1999,crime number decreases.. We have to find the relevant possibilities that has been done on those years by the authority.. It may be applying strict rules or financial stability or good govern or may be decreasing in particular cities that has high number of cases.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,8))\nsns.barplot(more_focused['State'], more_focused['Incident'])\nplt.xticks(rotation= 'vertical')\nplt.title('State Wise Incident(Murdered) In US\\n1980-2014')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### we can find Florida and New York to be exceptionally high in crime rate.. This may be caused by over population that other cities, having less strict and applied rules or curroption.. Or in those area number of Gang may cause extermely high number..or the overall population mentality is not stable like other cities.. This may be cause by over drug availablity or family distance..","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,8))\nsns.barplot(more_focused['Month'], more_focused['Incident'])\nplt.xticks(rotation= 'vertical')\nplt.title('Monthly Incident(Murdered) In US\\n1980-2014')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### This plot dosnt help.. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cities =  more_focused.groupby('City')['Incident'].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cities_describe = cities.describe()\ncities_describe","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Our 75% of cities Crime Count Lies 194.7500\n- in New York It is highest\n- So we Will Visualize our data in 75% or Our Q3\n- There are few cities which crime count is above our Q3 value of 195","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"below_100 =  cities.loc[cities < 100].values\nbelow_1000 =  cities.loc[cities < 1000].values\nbelow_10000 =  cities.loc[cities < 10000].values\nbelow_100000 =  cities.loc[cities < 100000].values\nbelow_1000000 =  cities.loc[cities < 1000000].values\n\nabove_1M_incident_city = cities.loc[cities < 1000000]\nabove_1lakh_to_1M_incident_city = cities.loc[(cities > 100000) & (cities <1000000)]\nabove_10th_to_1lakh_incident_city = cities.loc[(cities > 10000) & (cities <100000)]\nabove_1th_to_10th_incident_city = cities.loc[(cities > 1000) & (cities <10000)]\nabove_100_to_1th_incident_city = cities.loc[(cities > 100) & (cities <1000)]\nabove_10_to_100_incident_city = cities.loc[(cities > 10) & (cities <100)]\nabove_0_to_10_incident_city = cities.loc[(cities > 0) & (cities <10)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Amount Of Cities Having Number Of Incident\\n')\nprint(f'> 1M :              {len(above_1M_incident_city)}')\nprint(f'1lakh> <1M :        {len(above_1lakh_to_1M_incident_city)}')\nprint(f'10th> <1lakh :      {len(above_10th_to_1lakh_incident_city)}')\nprint(f'1th> <10th :        {len(above_1th_to_10th_incident_city)}')\nprint(f'100> <1th :         {len(above_100_to_1th_incident_city)}')\nprint(f'10> <100 :          {len(above_10_to_100_incident_city)}')\nprint(f'0> <10 :            {len(above_0_to_10_incident_city)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"range_list = [below_100, below_1000, below_10000, below_100000, below_1000000]\nj = 0\n\nwhile j < 5:\n    for i in range_list:\n        \n        plt.figure(figsize=(10,8))\n        sns.kdeplot(i, shade = True)\n        plt.show()\n        \n        \n        plt.figure(figsize=(10,8))\n        sns.distplot(i,bins= 50,rug=True, rug_kws={'color':'purple'}, hist_kws= {'color': 'red'}, kde_kws= {'color': 'blue'})\n        plt.show()\n        \n        j +=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"std = []\nmean_cities = cities.mean()\nstd_cities = cities.std()\n\nfor i in cities:\n    standardizise =( i - mean_cities )/ std_cities  \n    std.append(standardizise)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(cities_describe, palette='winter')\nplt.xlim([0,30000])\nplt.title('Cities Incident')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.kdeplot(std)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Standardized Kde plot","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cities_describe = cities.describe()\ncities_describe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i = 0\nrange_j = range(1,18)\nwhile i < 1700:\n    for j in range_j:\n    \n        plt.figure(figsize=(20,8))\n        sns.barplot(cities.index[i:j*100], cities[i:j*100])\n        plt.xticks(rotation= 'vertical')\n        plt.ylim([0,1000])\n        plt.title(f'Cities Incident(Murdered) In US\\n1980-2014\\n\\nSummary: \\n\\n{cities_describe}')\n        plt.show()\n\n        i += 100\n        j += 1\n    \n    \nplt.figure(figsize=(20,8))\nsns.barplot(cities.index[1700:], cities[1700:])\nplt.xticks(rotation= 'vertical')\nplt.ylim([0,1000])\nplt.title(f'Cities Incident(Murdered) In US\\n1980-2014\\n\\nSummary: \\n\\n{cities_describe}')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_matrix = df[['Victim Sex', 'Perpetrator Sex','Victim Age','Perpetrator Age', \n                  'Victim Count', 'Perpetrator Count', 'City', 'State','Year', \n                  'Month', 'Incident', 'Relationship', 'Weapon','Crime Type','Crime Solved']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_matrix.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.barplot(data_matrix['Crime Type'], data_matrix['Incident'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"crime_type_gb = data_matrix.groupby('Crime Type')['Incident'].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,8))\nsns.barplot(crime_type_gb.index, crime_type_gb, palette= 'spring')\nplt.title(f'{crime_type_gb}')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_incident = crime_type_gb[0] + crime_type_gb[1]\nnegligence_percentage = (crime_type_gb[0] / total_incident) * 100\nnot_negligence_percentge = (crime_type_gb[1] / total_incident) *100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,8))\nsns.barplot(crime_type_gb.index, crime_type_gb, palette= 'spring')\nplt.title(f'{crime_type_gb}\\n\\nBy Willingly: {not_negligence_percentge}%\\nBy Negligence: {negligence_percentage}%')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_matrix.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def perpetartor_count_wise(i, name):\n    perpetrator = data_matrix.loc[data_matrix['Perpetrator Count'] == i]\n    perpetrator_percentage = (len(perpetrator) / len(data_matrix)) * 100\n    perpetrator_percentage\n    print(f'{name} Perpetrator: \\t{perpetrator_percentage}%')\n\n    \nperpetartor_count_wise(0, '0')    \nperpetartor_count_wise(1, 'Individual')\nperpetartor_count_wise(2, 'Two')\nperpetartor_count_wise(3, 'Three')\nperpetartor_count_wise(4, 'Four')\nperpetartor_count_wise(5, 'Five')\nperpetartor_count_wise(6, 'Six')\nperpetartor_count_wise(7, 'Seven')\nperpetartor_count_wise(8, 'Eight')\nperpetartor_count_wise(9, 'Nine')\nperpetartor_count_wise(10, 'Ten')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def perpetartor_count_df(i):\n    perpetrator = data_matrix.loc[data_matrix['Perpetrator Count'] == i]\n    return perpetrator\n\n\nperpetrator0 = perpetartor_count_df(0)\nperpetrator1 = perpetartor_count_df(1)\nperpetrator2 = perpetartor_count_df(2)\nperpetrator3 = perpetartor_count_df(3)\nperpetrator4 = perpetartor_count_df(4)\nperpetrator5 = perpetartor_count_df(5)\nperpetrator6 = perpetartor_count_df(6)\nperpetrator7 = perpetartor_count_df(7)\nperpetrator8 = perpetartor_count_df(8)\nperpetrator9 = perpetartor_count_df(9)\nperpetrator10 = perpetartor_count_df(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def perpetartor_gb(df):\n    perpetrator_gb = df.groupby('Relationship')['Incident'].sum()\n    return perpetrator_gb\n\nperpetrator0_gb = perpetartor_gb(perpetrator0)\nperpetrator1_gb = perpetartor_gb(perpetrator1)\nperpetrator2_gb = perpetartor_gb(perpetrator2)\nperpetrator3_gb = perpetartor_gb(perpetrator3)\nperpetrator4_gb = perpetartor_gb(perpetrator4)\nperpetrator5_gb = perpetartor_gb(perpetrator5)\nperpetrator6_gb = perpetartor_gb(perpetrator6)\nperpetrator7_gb = perpetartor_gb(perpetrator7)\nperpetrator8_gb = perpetartor_gb(perpetrator8)\nperpetrator9_gb = perpetartor_gb(perpetrator9)\nperpetrator10_gb = perpetartor_gb(perpetrator10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"perpetrator_all = data_matrix.groupby('Relationship')['Incident'].sum()\nperpetrator_all","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def perpetartor_count_wise_(i, name):\n    perpetrator = data_matrix.loc[data_matrix['Perpetrator Count'] == i]\n    perpetrator_percentage = (len(perpetrator) / len(data_matrix)) * 100\n    perpetrator_percentage\n    formated = f'{i} Perpetrator: {perpetrator_percentage}%'\n    return formated\n\ntitle = perpetartor_count_wise_(0, 'individual')\ntitle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"overall_perpetrator = data_matrix.groupby('Relationship')['Incident'].sum()\n\n\ndef relationship_plot(var, name, i):\n    plt.figure(figsize = (20,8))\n\n    sns.barplot(var.index, var)\n    percentages = perpetartor_count_wise_(i, name)\n    title = f'{name} Perpetrator Relationship With Victim\\n\\n{percentages}'\n    plt.xticks(rotation = 45)\n    plt.title(title)\n    plt.show()\n\n    \n    \nrelationship_plot(perpetrator0_gb, 'Undefined',0)\nrelationship_plot(perpetrator1_gb, 1, 1)\nrelationship_plot(perpetrator2_gb, 2,2)\nrelationship_plot(perpetrator3_gb, 3,3)\nrelationship_plot(perpetrator4_gb, 4,4)\nrelationship_plot(perpetrator5_gb, 5,5)\nrelationship_plot(perpetrator6_gb, 6,6)\nrelationship_plot(perpetrator7_gb, 7,7)\nrelationship_plot(perpetrator8_gb, 8,8)\nrelationship_plot(perpetrator9_gb, 9,9)\nrelationship_plot(perpetrator10_gb, 10,10)\n\n\n\nplt.figure(figsize = (20,8))\n\nsns.barplot(overall_perpetrator.index, overall_perpetrator)\nplt.xticks(rotation = 'vertical')\ntitle = 'Overall Perpetrator Relationship With Victim'\nplt.title(title)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def return_arguments_var(data, series1, value1, series2 = None, value2= None):\n    if series2:\n        args = data.loc[(data[series1] == value1) & (data[series2] == value2)]\n        \n    else:\n        args = data.loc[(data[series1] == value1)]\n    return args\n\n\nunsolved_cases = return_arguments_var(data_matrix,'Crime Solved', 'No')\nall_cases_done_by_unknown = return_arguments_var(data_matrix, 'Relationship', 'Unknown')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Number of Cases Didnt Solved: {len(unsolved_cases)}')\nprint(f'Percentage Crime Didnt Solved: {(len(unsolved_cases)/len(data_matrix))*100}%')\nprint(f'Percentage Crime Done by Unknown: {(len(all_cases_done_by_unknown)/len(data_matrix))*100}%')\n\nunknown_and_not_solved = data_matrix.loc[(data_matrix['Relationship'] == 'Unknown') & (data_matrix['Crime Solved'] == 'No')]\nprint(f'Number of Crime has done by Unknown and Hasnt Solved: {len(unknown_and_not_solved)}')\nprint(f'Percentage Crime Done By Unknown and Hasnt Solved: {(len(unknown_and_not_solved)/len(data_matrix))*100}%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Among All Cases, 29.8% is Unsolved. In 29.8% Unsolved Cases About 27% has been done by Unknown..","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(perpetrator0))\nprint(len(all_cases_done_by_unknown))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"perpetrator0_unknown = return_arguments_var(data_matrix, 'Relationship','Unknown', 'Perpetrator Count', 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"perpetrator0_unknown.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Percentage of Crime Unknown Vs 0 Perpetarator:\\n {(len(all_cases_done_by_unknown) / len(perpetrator0))*100}%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### About 48.853% of Perpetrator Count 0 is Unknown","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"year1980 = return_arguments_var(data_matrix, 'Year', 1980)\nyear1981 = return_arguments_var(data_matrix, 'Year', 1981)\nyear1982 = return_arguments_var(data_matrix, 'Year', 1982)\nyear1983 = return_arguments_var(data_matrix, 'Year', 1983)\nyear1984 = return_arguments_var(data_matrix, 'Year', 1984)\nyear1985 = return_arguments_var(data_matrix, 'Year', 1985)\nyear1986 = return_arguments_var(data_matrix, 'Year', 1986)\nyear1987 = return_arguments_var(data_matrix, 'Year', 1987)\nyear1988 = return_arguments_var(data_matrix, 'Year', 1988)\nyear1989 = return_arguments_var(data_matrix, 'Year', 1989)\nyear1990 = return_arguments_var(data_matrix, 'Year', 1990)\nyear1991 = return_arguments_var(data_matrix, 'Year', 1991)\nyear1992 = return_arguments_var(data_matrix, 'Year', 1992)\nyear1993 = return_arguments_var(data_matrix, 'Year', 1993)\nyear1994 = return_arguments_var(data_matrix, 'Year', 1994)\nyear1995 = return_arguments_var(data_matrix, 'Year', 1995)\nyear1996 = return_arguments_var(data_matrix, 'Year', 1996)\nyear1997 = return_arguments_var(data_matrix, 'Year', 1997)\nyear1998 = return_arguments_var(data_matrix, 'Year', 1998)\nyear1999 = return_arguments_var(data_matrix, 'Year', 1999)\nyear2000 = return_arguments_var(data_matrix, 'Year', 2000)\nyear2001 = return_arguments_var(data_matrix, 'Year', 2001)\nyear2002 = return_arguments_var(data_matrix, 'Year', 2002)\nyear2003 = return_arguments_var(data_matrix, 'Year', 2003)\nyear2004 = return_arguments_var(data_matrix, 'Year', 2004)\nyear2005 = return_arguments_var(data_matrix, 'Year', 2005)\nyear2006 = return_arguments_var(data_matrix, 'Year', 2006)\nyear2007 = return_arguments_var(data_matrix, 'Year', 2007)\nyear2008 = return_arguments_var(data_matrix, 'Year', 2008)\nyear2009 = return_arguments_var(data_matrix, 'Year', 2009)\nyear2010 = return_arguments_var(data_matrix, 'Year', 2010)\nyear2011 = return_arguments_var(data_matrix, 'Year', 2011)\nyear2012 = return_arguments_var(data_matrix, 'Year', 2012)\nyear2013 = return_arguments_var(data_matrix, 'Year', 2013)\nyear2014 = return_arguments_var(data_matrix, 'Year', 2014)\n\n\n\n\n\ndef groupby(data, series1, on_groupby):\n    year = data.groupby(series1)[on_groupby].sum()\n    return year\n\n\nyear_wise_incident = groupby(data_matrix, 'Year', 'Incident')\nyear_wise_victim = groupby(data_matrix, 'Year', 'Victim Count')\nyear_wise_perpetrator = groupby(data_matrix, 'Year', 'Perpetrator Count')\nyear_wise_crime_solved = groupby(data_matrix, 'Year', 'Crime Solved')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,8))\nyear_wise_incident.plot(c='r')\nplt.title('Incident Each Year')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,8))\nyear_wise_victim.plot(label = 'Victim Count Each Year')\nyear_wise_perpetrator.plot(label = 'Perpetrator Count Each Year')\nplt.legend(loc = 'best')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def year_month_df(data):\n    year_month = data.groupby('Month')['Incident'].sum()\n    year_month = pd.DataFrame(year_month)\n    return year_month\ndef year_month_decode(data, decode_list):\n    year_month['MonthCode'] = decode_list\n    return year_month","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"year1980.to_csv('../Data/CrimeYear1980.csv')\nyear1981.to_csv('../Data/CrimeYear1981.csv')\nyear1982.to_csv('../Data/CrimeYear1982.csv')\nyear1983.to_csv('../Data/CrimeYear1983.csv')\nyear1984.to_csv('../Data/CrimeYear1984.csv')\nyear1985.to_csv('../Data/CrimeYear1985.csv')\nyear1986.to_csv('../Data/CrimeYear1986.csv')\nyear1987.to_csv('../Data/CrimeYear1987.csv')\nyear1988.to_csv('../Data/CrimeYear1988.csv')\nyear1989.to_csv('../Data/CrimeYear1989.csv')\nyear1990.to_csv('../Data/CrimeYear1990.csv')\nyear1991.to_csv('../Data/CrimeYear1991.csv')\nyear1992.to_csv('../Data/CrimeYear1992.csv')\nyear1993.to_csv('../Data/CrimeYear1993.csv')\nyear1994.to_csv('../Data/CrimeYear1994.csv')\nyear1995.to_csv('../Data/CrimeYear1995.csv')\nyear1996.to_csv('../Data/CrimeYear1996.csv')\nyear1997.to_csv('../Data/CrimeYear1997.csv')\nyear1998.to_csv('../Data/CrimeYear1998.csv')\nyear1999.to_csv('../Data/CrimeYear1999.csv')\nyear2000.to_csv('../Data/CrimeYear2000.csv')\nyear2001.to_csv('../Data/CrimeYear2001.csv')\nyear2002.to_csv('../Data/CrimeYear2002.csv')\nyear2003.to_csv('../Data/CrimeYear2003.csv')\nyear2004.to_csv('../Data/CrimeYear2004.csv')\nyear2005.to_csv('../Data/CrimeYear2005.csv')\nyear2006.to_csv('../Data/CrimeYear2006.csv')\nyear2007.to_csv('../Data/CrimeYear2007.csv')\nyear2008.to_csv('../Data/CrimeYear2008.csv')\nyear2009.to_csv('../Data/CrimeYear2009.csv')\nyear2010.to_csv('../Data/CrimeYear2010.csv')\nyear2011.to_csv('../Data/CrimeYear2011.csv')\nyear2012.to_csv('../Data/CrimeYear2012.csv')\nyear2013.to_csv('../Data/CrimeYear2013.csv')\nyear2014.to_csv('../Data/CrimeYear2014.csv')","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_matrix['Month']=data_matrix['Month'].replace(['January','February', 'March', 'April', 'May', 'June', 'July',\n                              'August','September', 'October', 'November','December', ],\n                            [1,2,3,4,5,6,7,8,9,10,11,12])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_matrix['new']= data_matrix['Year'].map(str) + ' ' + data_matrix['Month'].map(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_matrix['new'] = pd.to_datetime(data_matrix['new'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_matrix.groupby('new')['Incident'].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_matrix['new1'] = data_matrix['new'].dt.to_period('M')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_matrix.columns = ['Victim Sex', 'Perpetrator Sex', 'Victim Age', 'Perpetrator Age',\n       'Victim Count', 'Perpetrator Count', 'City', 'State', 'Year', 'Month',\n       'Incident', 'Relationship', 'Weapon', 'Crime Type', 'Crime Solved',\n       'new', 'YMonth']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_matrix.drop(columns = ['Year', 'Month', 'new'], inplace= True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_matrix.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"data_matrix.to_csv('../Data/YearMonthformated.csv')","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"monthly_incident = data_matrix.groupby('YMonth')['Incident'].sum()\nmonthly_perpetrator = data_matrix.groupby('YMonth')['Perpetrator Count'].sum()\nmonthly_victim = data_matrix.groupby('YMonth')['Victim Count'].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,8))\nmonthly_incident.plot(c='r')\nplt.title('Incident Per Month In Each Year')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,8))\nmonthly_victim.plot(label = 'Victim', c= 'r')\nmonthly_perpetrator.plot(label= 'Perpetrator', c = 'w')\nplt.legend(loc='best')\nplt.title('Analysis Per Month In each year')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### there are huge spike in 1995 and quite high spike in 1990.. lets see what happened in that two month..","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"monthly_victim[120:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### So, It is in March 1990 and count is 918 in one single month.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"monthly_victim[180:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### And it is Aprill 1995, incident count 1686 ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Lets Gather some Information on net and newspapers to find the reason..","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"monthly_victim.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,8))\nmonthly_perpetrator.plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"monthly_perpetrator = pd.DataFrame(monthly_perpetrator)\nmonthly_perpetrator.reset_index(inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"monthly_perpetrator.reset_index(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"monthly_perpetrator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"time = monthly_perpetrator['index'].values\ntime[:10]\nseries = monthly_perpetrator['Perpetrator Count'].values\nseries[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"split_time = 380\ntrain_time = time[:split_time]\ntrain_x = series[:split_time]\n\nvalid_time = time[split_time:]\nvalid_x = series[split_time:]\n\nwindow_size = 12\nbatch_size = 10\nshuffle_buffer_size = 420","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf \n\ndef windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n    dataset = tf.data.Dataset.from_tensor_slices(series)\n    dataset = dataset.window(window_size+1, shift=1, drop_remainder = True)\n    dataset = dataset.flat_map(lambda window: window.batch((window_size + 1 )))\n    dataset = dataset.shuffle(shuffle_buffer).map(lambda window: (window[:-1], window[-1]))\n    dataset = dataset.batch(batch_size).prefetch(1)\n    return dataset\n\nperpetrator_dataset = windowed_dataset(train_x, window_size, batch_size, shuffle_buffer_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_sl = tf.keras.Sequential([\n            tf.keras.layers.Dense(1, input_shape = [window_size])\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_sl.compile(loss= 'mse', optimizer = tf.keras.optimizers.RMSprop(1e-6,momentum= 0.9))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model_sl.fit(perpetrator_dataset, epochs= 500, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_series(time, series, format = '', start= 0, end= None, label = None):\n  plt.plot(time[start:end], series[start:end], format, label= label, )\n  plt.xlabel('Time')\n  plt.ylabel('Value')\n  if label:\n    plt.legend(fontsize = 10)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,8))\nloss = history.history['loss']\nepochs = range(len(loss))\nplt.plot(epochs, loss, 'w', label = 'Training Loss')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Our Single layer net is doing very good enough in just 150 epochs..","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_loss = loss[200:]\nplt.plot(epochs[200:], plot_loss, 'b', label = 'Training Loss')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast = []\nfor time in range(len(series) - window_size):\n  forecast.append(model_sl.predict(series[time: time + window_size][np.newaxis]))\n\nforecast = forecast[split_time - window_size:]\nresults = np.array(forecast)[:, 0,0]\n\nplt.figure(figsize =(20,8) )\n\nplot_series(valid_time, valid_x)\nplot_series(valid_time, results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.keras.metrics.mean_absolute_error(valid_x, results).numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_sl.save('model_sl.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Its too high.. lets see by another model..","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow import keras as tk\nfrom tensorflow.keras import layers as tkl\nfrom tensorflow.keras.layers import Dense as tkld","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# as our dataset is 2 dim but rnn need 3 dim we can expand dim using Lambda layer\nimport tensorflow as tf\n\nmodel_rnn = tk.models.Sequential([\n                              tkl.Lambda(lambda x: tf.expand_dims(x, axis = -1), input_shape = [None]),\n                              tkl.SimpleRNN(20, return_sequences= True, input_shape = [None, 1]),\n                              tkl.SimpleRNN(20),\n                              tkld(1),\n                              tkl.Lambda(lambda x: x*100.0)\n])\n\n# as default activation function of rnn is tanh, our output range from -1,1.. so we are scaling to normal sequence like 30,40 as time series are like that","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_schedule = tk.callbacks.LearningRateScheduler(lambda epoch: 1e-8* 10**(epoch /20))\n\noptimizer = tk.optimizers.RMSprop(lr = 1e-6, momentum= 0.9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_rnn.compile(loss = 'mse', optimizer= optimizer, metrics= ['mae'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model_rnn.fit(perpetrator_dataset, epochs= 500,verbose= 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,8))\nloss = history.history['loss']\nepochs = range(len(loss))\nplt.plot(epochs, loss, 'w', label = 'Training Loss')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,8))\nloss = history.history['loss']\nepochs = range(120,len( loss))\nplot_loss = loss[120:]\n\nplt.plot(epochs, plot_loss, 'w', label = 'Training Loss')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast = []\nfor time in range(len(series) - window_size):\n  forecast.append(model_rnn.predict(series[time: time + window_size][np.newaxis]))\n\nforecast = forecast[split_time - window_size:]\nresults = np.array(forecast)[:, 0,0]\n\nplt.figure(figsize =(20,8) )\n\nplot_series(valid_time, valid_x)\nplot_series(valid_time, results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tk.metrics.mean_absolute_error(valid_x, results).numpy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Accuracy is quite good but it seems it just followed average line.. Not so helpful ..","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}