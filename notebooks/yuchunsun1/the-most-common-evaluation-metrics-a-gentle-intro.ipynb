{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### Hi all.  üôã‚Ä¢‚ôÇÔ∏è \n\n#### We continue our **Beginner-Intermediate Friendly Machine Learning series**, which would help anyone who wants to learn or refresh the basics of ML.\n\n#### What we have covered: \n\n#### [Beginner Friendly Detailed Explained EDAs ‚Äì For anyone at the beginnings of DS/ML journey](https://www.kaggle.com/general/253911#1393015) ‚úîÔ∏è\n\n#### [BIAS & VARIANCE TRADEOFF](https://www.kaggle.com/kaanboke/ml-basics-bias-variance-tradeoff) ‚úîÔ∏è\n\n#### [LINEAR ALGORITHMS](https://www.kaggle.com/kaanboke/ml-basics-linear-algorithms)  ‚úîÔ∏è\n\n#### [NONLINEAR ALGORITHMS](https://www.kaggle.com/kaanboke/nonlinear-algorithms)  ‚úîÔ∏è\n\n#### [The Most Used Methods to Deal with MISSING VALUES](https://www.kaggle.com/kaanboke/the-most-used-methods-to-deal-with-missing-values)  ‚úîÔ∏è\n\n#### [Beginner Friendly End to End ML Project- Classification with Imbalanced Data](https://www.kaggle.com/kaanboke/beginner-friendly-end-to-end-ml-project-enjoy)  ‚úîÔ∏è\n\n#### [How to Prevent the Data Leakage ?](https://www.kaggle.com/kaanboke/how-to-prevent-the-data-leakage) ‚úîÔ∏è\n\n#### In this notebook we will  cover one of the important concepts of the **Machine Learning Evaluation Metrics**\n#### Enjoy ü§ò","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"#### **By the way, when you like the topic, you can show it by supporting** üëç\n\n####  **Feel free to leave a comment in the notebook**. \n\n#### All the best ü§ò","metadata":{}},{"cell_type":"markdown","source":"![](https://miro.medium.com/max/1400/1*FUZS9K4JPqzfXDcC83BQTw.png)","metadata":{}},{"cell_type":"markdown","source":"Image Credit: https://miro.medium.com/","metadata":{}},{"cell_type":"markdown","source":"<a id=\"toc\"></a>\n\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" role=\"tab\" aria-controls=\"home\">Table of Contents</h3>\n    \n* [What is Evaluation Metrics?](#0)\n* [Classification Evalution Metrics](#1)\n    * [Confusion Matrix](#2)\n    * [Accuracy](#3)\n    * [Precision & Recall](#4)\n    * [F Score (F Measure)](#5)\n    * [ROC Curve (AUC)](#6)\n    * [Log Loss](#7)\n  \n  \n* [Regression Evaluation Metrics](#8)    \n    * [Mean Absolute Error(MAE)](#9)\n    * [Mean Squared Error (MSE)](#10)    \n    * [Root Mean Squared Error (RMSE)](#11)\n    * [R Squared (R2)](#12)\n\n\n* [Conclusion](#13)\n* [References & Further Reading](#14)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"0\"></a>\n<font color=\"lightseagreen\" size=+2.5><b>What is Evaluation Metrics? & Why We Need Them?</b></font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents</a>\n","metadata":{}},{"cell_type":"markdown","source":"![](https://www.magazine.etnfocus.com/wp-content/uploads/2017/08/metrics.jpg)","metadata":{}},{"cell_type":"markdown","source":"image credit: https://www.magazine.etnfocus.com","metadata":{}},{"cell_type":"markdown","source":"- In machine learning, evaluation metrics are used to measure the performance of machine learning models/algorithms.\n- Evaluation metrics are crucial. Based on the model performance we are giving decisions.\n- We should remember that we are not just only looking for a better model, also looking for our end goal.\n- Let's imagine our end goal is to make an application to detect fraud.\n- We develop our model based on the data in hand, which contains 99.5% non-fraud cases and %.5 fraud cases.\n- Without using the correct evaluation metric on this imbalanced data we will deploy the model with poor performance and prediction on the real data.","metadata":{}},{"cell_type":"markdown","source":"- In this study we will divide our evaluation metrics into two categories.\n    - Classification Evaluation Metrics\n    - Regression Evaluation Metrics\n \n - Ok let's start.","metadata":{}},{"cell_type":"markdown","source":"![](https://www.negotiations.com/wp-content/uploads/2017/05/negotiation-success.jpg)","metadata":{}},{"cell_type":"markdown","source":"image credit: https://www.negotiations.com","metadata":{}},{"cell_type":"markdown","source":"<a id=\"1\"></a>\n<font color=\"lightseagreen\" size=+2.5><b>Classification Evaluation Metrics</b></font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents</a>","metadata":{}},{"cell_type":"markdown","source":"- Classification problems are the most common problems in the Machine Learning.\n- It would be a good idea to refresh our knowledge on the classification evaluation metrics.\n- In the classification part of the study, we will use Credit Card Fraud dataset.","metadata":{}},{"cell_type":"code","source":"import pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \n\nfrom sklearn.preprocessing import StandardScaler,MinMaxScaler,PowerTransformer\nfrom sklearn.model_selection import train_test_split, RepeatedStratifiedKFold,cross_val_score,GridSearchCV\nfrom sklearn.linear_model import LinearRegression,LogisticRegression\nfrom sklearn.pipeline import Pipeline,make_pipeline\nfrom sklearn.metrics import mean_squared_error,classification_report,make_scorer,accuracy_score,plot_roc_curve,auc,roc_curve\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.model_selection import KFold\n\nimport cufflinks as cf\nimport plotly.offline\ncf.go_offline()\ncf.set_config_file(offline=False, world_readable=True)\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2021-08-18T08:57:23.624189Z","iopub.execute_input":"2021-08-18T08:57:23.624721Z","iopub.status.idle":"2021-08-18T08:57:23.64602Z","shell.execute_reply.started":"2021-08-18T08:57:23.624673Z","shell.execute_reply":"2021-08-18T08:57:23.644592Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"2\"></a>\n<font color=\"lightseagreen\" size=+1.5><b>Confusion Matrix</b></font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents</a>","metadata":{}},{"cell_type":"markdown","source":"- Before starting the evaluation metrics, we should be on the same page.\n- Let's refresh the basics.","metadata":{}},{"cell_type":"markdown","source":"![](https://www.superheuristics.com/wp-content/uploads/2021/03/Blog_image_confusion-matrix.png)","metadata":{}},{"cell_type":"markdown","source":"image credit: https://www.superheuristics.com","metadata":{}},{"cell_type":"markdown","source":"- **True Positive**: Predicted vale is positive and we predicted correctly. \n- Real Transaction --> Fraud  and our model correctly predict as fraud.","metadata":{}},{"cell_type":"markdown","source":"- **False Negative**: Predicted value is negative, but actual value is positive. Our prediction is false.\n   - We predict non-fraud, benign, but actual value is fraud or malign.\n   - Which is also called **Type 2 error**.","metadata":{}},{"cell_type":"markdown","source":"- **False Positive**: Our prediction is positive but actual value is negative. Our prediction is false.\n   - We predict as fraud or malign but actual value is non-fraud or benign.\n   - Which is also called as **Type 1 error**.","metadata":{}},{"cell_type":"markdown","source":"- **True Negative** : We predict as negative and our prediction is correct. Actual value is negative ( non-fraud, benign, etc.)","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://www.publichealthnotes.com/wp-content/uploads/2020/04/slide_9.jpg\" width=\"600\">\n","metadata":{}},{"cell_type":"markdown","source":"image credit: https://www.publichealthnotes.com","metadata":{}},{"cell_type":"markdown","source":"<a id=\"3\"></a>\n<font color=\"lightseagreen\" size=+1.5><b>Accuracy</b></font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents</a>","metadata":{"execution":{"iopub.status.busy":"2021-08-17T09:45:04.260568Z","iopub.execute_input":"2021-08-17T09:45:04.261094Z","iopub.status.idle":"2021-08-17T09:45:04.275751Z","shell.execute_reply.started":"2021-08-17T09:45:04.260978Z","shell.execute_reply":"2021-08-17T09:45:04.274188Z"}}},{"cell_type":"markdown","source":"- One of the most common evaluation metrics, we can see in the real world and also in the Kaggle.\n- Accuracy is better to use with balanced classification problem and when all predictions and prediction errors are equally important (for example using iris dataset. Every class has equal instances).\n\n- Balanced Data: Target has equal or almost equal number of instances.\n- Prediction Errors are  equally important: Predicting  Class A, Class B or Probability of detecting fraud or detecting non fraud\n- Is it really possible in the real life?\n- I can't say, it is impossible, but fair to say it is rare.\n- Most of the classification problem, we handle in ML, has imbalanced data and consequences of the prediction errors are rarely same.\n- When we have the imbalanced data, accuracy is not a good evaluation metric to use.\n","metadata":{}},{"cell_type":"markdown","source":"- Formula for the accuracy is easy one: Total number of correct predictions divided by the total number of predictions.","metadata":{}},{"cell_type":"markdown","source":"![](https://www.mydatamodels.com/wp-content/uploads/2020/10/2.-Accuracy-formula-machine-learning-algorithms.png)","metadata":{}},{"cell_type":"markdown","source":"image credit: https://www.mydatamodels.com","metadata":{}},{"cell_type":"markdown","source":"- It is clearly seen in the formula, why accuracy is not a good measure for the imbalanced data.\n- Imagine we have  a data...\n- Just kidding, you don't need to imagine we have real data to see.\n- We will use credit card fraud data to estimate fraud cases.\n- This is imbalanced data. Be careful !!!","metadata":{}},{"cell_type":"code","source":"df_credit = pd.read_csv('../input/creditcardfraud/creditcard.csv')\ndf_credit.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-18T08:42:16.472033Z","iopub.execute_input":"2021-08-18T08:42:16.472447Z","iopub.status.idle":"2021-08-18T08:42:21.862241Z","shell.execute_reply.started":"2021-08-18T08:42:16.472401Z","shell.execute_reply":"2021-08-18T08:42:21.86087Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_credit['Class'].value_counts(normalize=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-18T08:42:25.813108Z","iopub.execute_input":"2021-08-18T08:42:25.813685Z","iopub.status.idle":"2021-08-18T08:42:25.829302Z","shell.execute_reply.started":"2021-08-18T08:42:25.81363Z","shell.execute_reply":"2021-08-18T08:42:25.828109Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- When we look at the formula above, if we put 100 cases as non-fraud, based on the equation we can get 99.8% accuracy\n-  99.8% accuracy !!!!\n- It is great isn't it ?\n- Let's see all of this by using Dummy Classifier.","metadata":{}},{"cell_type":"code","source":"\ndf_credit = pd.read_csv('../input/creditcardfraud/creditcard.csv')\n\nX = df_credit.drop('Class', axis=1)\ny = df_credit['Class']\n\nmodel =DummyClassifier(strategy='most_frequent')\n\n#pipeline = Pipeline(steps=[('imp', SimpleImputer(strategy='median')),('s',MinMaxScaler()),('m', model)]) \n\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n\nresult = cross_val_score(model, X, y,  scoring='accuracy',cv=cv, n_jobs=-1)\n\nprint(f'{round(np.mean(result),6)}')","metadata":{"execution":{"iopub.status.busy":"2021-08-18T08:42:30.683993Z","iopub.execute_input":"2021-08-18T08:42:30.684354Z","iopub.status.idle":"2021-08-18T08:42:37.942435Z","shell.execute_reply.started":"2021-08-18T08:42:30.684317Z","shell.execute_reply":"2021-08-18T08:42:37.940852Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Ok we have 99.8% accuracy on the credit card fraud, without learning anything, why we are bothering ourselves to build a model?\n\n- We can easily select every case as a non-fraud and 99.8 out of 100 times, we are right.\n\n- Why aren't we celebrating it?","metadata":{}},{"cell_type":"markdown","source":" #### **What is the problem with the accuracy metric for the imbalanced data?**\n\n- Accuracy metric with imbalanced data gives us the accuracy on the majority class (non-fraud)\n- We can reach to 99.8% accuracy without building a machine leraning model, by always predicting the non-fraud.\n- The problem here is that accuracy is an inadequate measure for quantifying predictive performance in this imbalanced setting.\n- Accuracy does not report the correct score for the imbalanced data.\n- As we have seen overwhelming number of non-fraud instances (99.8%) surprass the fraud instances.\n- Even Dummy Classifier can get the 99.8% accuracy score.","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<b>Rule of Thumb:</b> Do not use accuracy score metric with the imbalanced data.\n</div>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"4\"></a>\n<font color=\"lightseagreen\" size=+1.5><b>Precision & Recall</b></font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents</a>","metadata":{}},{"cell_type":"markdown","source":"#### **Precision**\n- Precision gives us accuracy of the positive classs (fraud case, cancer case, malign case, etc).\n- Main aim of the precision is the minimize the false positive (Type 1 error)","metadata":{}},{"cell_type":"markdown","source":"![](https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/600px-Precisionrecall.svg.png)","metadata":{}},{"cell_type":"markdown","source":"image credit: https://en.wikipedia.org","metadata":{}},{"cell_type":"markdown","source":"#### **Recall**\n- Recall gives us the score of the number of correct positive predictions made out of all correct positive predictions.\n- Main aim ofthe recall is the minimize the false negative (Type 2 error).","metadata":{}},{"cell_type":"markdown","source":"![](https://i.pinimg.com/originals/aa/91/7a/aa917a42422eaedb18224224519e48f0.jpg)","metadata":{}},{"cell_type":"markdown","source":"image credit: https://www.pinterest.com","metadata":{"execution":{"iopub.status.busy":"2021-08-17T14:22:31.063553Z","iopub.execute_input":"2021-08-17T14:22:31.064055Z","iopub.status.idle":"2021-08-17T14:22:31.077849Z","shell.execute_reply.started":"2021-08-17T14:22:31.063941Z","shell.execute_reply":"2021-08-17T14:22:31.076499Z"}}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<b>Precision & Recall --> Which one to use and When ?</b> \n     <ul style=\"list-style-type:none\">\n         <li><b>Precision:</b>  When our aim is to minimize false positive (Only fraud case, not include non-fraud transaction as a fraud transaction)</li>\n         <li><b>Recall : </b> When our aim is to minimize false negative (Every cancer patient should be classified as  a cancer patient, not classified as a healthy one)</li>\n      </ul>\n    \n   \n</div>\n","metadata":{}},{"cell_type":"markdown","source":"<a id=\"5\"></a>\n<font color=\"lightseagreen\" size=+1.5><b>F Score (F Measure)</b></font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents</a>","metadata":{"execution":{"iopub.status.busy":"2021-08-17T16:59:49.250076Z","iopub.execute_input":"2021-08-17T16:59:49.251646Z","iopub.status.idle":"2021-08-17T16:59:49.287175Z","shell.execute_reply.started":"2021-08-17T16:59:49.251397Z","shell.execute_reply":"2021-08-17T16:59:49.285438Z"}}},{"cell_type":"markdown","source":"- In real life we want to get perfect prediction on the positive class\n- Which means that we are looking high recall and high precision.\n- We have to balance them to get what we want.\n- F score provides us a score which combines precision and recall into a single measure without losing  their properties.","metadata":{}},{"cell_type":"markdown","source":"![](https://i.ytimg.com/vi/fcO9820wCXE/hqdefault.jpg)","metadata":{}},{"cell_type":"markdown","source":"image credit: https://www.youtube.com/channel/UCeoF_5Kw0YyWOqhAbQGrxJQ","metadata":{"execution":{"iopub.status.busy":"2021-08-17T17:07:30.852171Z","iopub.execute_input":"2021-08-17T17:07:30.852531Z","iopub.status.idle":"2021-08-17T17:07:30.859821Z","shell.execute_reply.started":"2021-08-17T17:07:30.852501Z","shell.execute_reply":"2021-08-17T17:07:30.858393Z"}}},{"cell_type":"code","source":"\ndef classification_report_with_validation(y_true, y_pred):\n    real_values.extend(y_true)\n    predicted_values.extend(y_pred)\n    return accuracy_score(y_true, y_pred)\n\n\ndf_credit = pd.read_csv('../input/creditcardfraud/creditcard.csv')\n\nX = df_credit.drop('Class', axis=1)\ny = df_credit['Class']\n\nreal_values = []\npredicted_values = []\n\nmodel =LogisticRegression(solver='liblinear')\n\npipeline = Pipeline(steps=[('s',MinMaxScaler()),('m', model)]) \n\ncv = KFold(n_splits=10, random_state=42)\n\nresult = cross_val_score(pipeline, X, y,  scoring=make_scorer(classification_report_with_validation),cv=cv)\n\nprint(classification_report(real_values, predicted_values)) ","metadata":{"execution":{"iopub.status.busy":"2021-08-18T08:52:08.065388Z","iopub.execute_input":"2021-08-18T08:52:08.065785Z","iopub.status.idle":"2021-08-18T08:52:34.229888Z","shell.execute_reply.started":"2021-08-18T08:52:08.065753Z","shell.execute_reply":"2021-08-18T08:52:34.228764Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- We didn't make any extensive exploratory analysis with the data. \n- We have just used it for showing the usage of the classification metrics on the imbalanced data.\n- For having said that precision: .93 , recall : 77 and f1 score: .83\n- And accuracy is 1.00 !!!","metadata":{}},{"cell_type":"markdown","source":"- As we have mentioned before, deciding which metric to use very crucial step on the Machine Learning projects.\n- Stakeholders / customers concerns should be taken into consideration before deciding which metric to use.\n\n- In fraud detection case, if our customer aims to reduce false negative:\n    - Which means every fraud case should be defined as a fraud case\n    - Missing the prediction of the fraud case should be minimum\n    - We have to focus on how to reduce wrongly classified non-fraud cases.\n    - In that case we are looking for minimizin type 2 error and increasing the positive rate.\n    - We are looking for higher score recall for fraud case.\n    \n    \n- In fraud detection case, if our customer aims to reduce false positive:\n    - Which means we want to be sure that positive case should be positive case, not the others\n    - We do not want to classify our loyal customer's transaction as a fraud transaction and block his/her account.\n    - We have to focus on wrongly classified positive case.\n    - In that case we are looking for minimizin type 1 error and decreasing the false positive rate.\n    - We are looking for higher score precision for fraud case.\n \n \n- If we want to reduce the risk of the fraud without losing our customer:\n    - We want to make a balance between precision and recall\n    - It would be good idea to focus on F score\n","metadata":{}},{"cell_type":"markdown","source":"<a id=\"6\"></a>\n<font color=\"lightseagreen\" size=+1.5><b>ROC Curve (AUC)</b></font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents</a>","metadata":{}},{"cell_type":"markdown","source":"- ROC Curve (receiver operating characteristic curve- AUC) measures model's ability to make distinction between two classes (positive & negative).\n- ROC Curve score close to 1, represents better model.\n- ROC Curve shows false positive rate against the true positive rate (recall)\n- What we are looking for : **High recall and low false positive rate**\n- ROC Curve should be as close as possible to the top left corner.\n- No matter how imbalanced  data we have,predicting randomly always produces an AUC of 0.5.","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://els-jbs-prod-cdn.jbs.elsevierhealth.com/cms/attachment/36cdb4ec-0c7d-48cb-9a4d-7cb463f8b7c3/gr1.jpg\" width=\"600\">","metadata":{}},{"cell_type":"markdown","source":"image credit: https://www.jtcvs.org/article/S0022-5223(18)32875-7","metadata":{}},{"cell_type":"code","source":"df_credit = pd.read_csv('../input/creditcardfraud/creditcard.csv')\n\nX = df_credit.drop('Class', axis=1)\ny = df_credit['Class']\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1, stratify=y)\n\npipeline = make_pipeline(MinMaxScaler(), LogisticRegression(solver='liblinear'))\n\npipeline.fit(X_train,y_train)\nprobs = pipeline.predict_proba(X_test)\nfpr1, tpr1, thresholds = roc_curve(y_test, probs[:, 1], pos_label=1)\nroc_auc1 = auc(fpr1, tpr1)\n\n\nfig, ax = plt.subplots(figsize=(7.5, 7.5))\n \nplt.plot(fpr1, tpr1, label='ROC Curve 1 (AUC = %0.2f)' % (roc_auc1))\nplt.plot([0, 1], [0, 1], linestyle='--', color='red', label='Random Classifier')   \nplt.plot([0, 0, 1], [0, 1, 1], linestyle=':', color='green', label='Perfect Classifier')\nplt.xlim([-0.05, 1.05])\nplt.ylim([-0.05, 1.05])\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.legend(loc=\"lower right\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-18T08:57:34.087236Z","iopub.execute_input":"2021-08-18T08:57:34.088089Z","iopub.status.idle":"2021-08-18T08:57:40.042562Z","shell.execute_reply.started":"2021-08-18T08:57:34.088016Z","shell.execute_reply":"2021-08-18T08:57:40.040997Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Higher value of True Positive Rate (TPR) means that false negative is very low. Model correctly predicted positive class.\n\n- Lower value of False Positive Rate means that false positive is very low. Model correctly predicted negative class.","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<b>Note:</b>  ROC Curve (AUC) is often more meaningful than using accuracy metric for classification problems with imbalanced data.\n</div>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"7\"></a>\n<font color=\"lightseagreen\" size=+1.5><b>Log Loss</b></font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents</a>","metadata":{}},{"cell_type":"markdown","source":"- Logarithmic loss or log loss metric is based on probabilities.\n- The log loss function calculates the negative log likelihood for probability predictions made by the binary classification model.\n\n","metadata":{}},{"cell_type":"markdown","source":"![](https://i.stack.imgur.com/UN1Pk.png)","metadata":{}},{"cell_type":"markdown","source":"image credit: https://stackoverflow.com","metadata":{}},{"cell_type":"markdown","source":"- What we are looking for  is the lowest level loss. The best possible log loss is 0.0\n- Any model with lower log-loss value brings us better predictions.","metadata":{}},{"cell_type":"markdown","source":"- Below code-snippet is generated by using code recipe in the [Imbalanced Classification with Python](https://machinelearningmastery.com/imbalanced-classification-with-python/). I have made changes and modified it to adjust to the problem at hand.","metadata":{}},{"cell_type":"code","source":"# log loss for naive probability predictions.\nfrom sklearn.metrics import log_loss\n# generate 2 class dataset\ndf_credit = pd.read_csv('../input/creditcardfraud/creditcard.csv')\n\nX = df_credit.drop('Class', axis=1)\ny = df_credit['Class']\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n\n\n# no skill prediction 0\nprobabilities = [[1, 0] for _ in range(len(y_test))]\navg_logloss = log_loss(y_test, probabilities)\nprint('P(class0=1): Log Loss=%.3f' % (avg_logloss))\n# no skill prediction 1\nprobabilities = [[0, 1] for _ in range(len(y_test))]\navg_logloss = log_loss(y_test, probabilities)\nprint('P(class1=1): Log Loss=%.3f' % (avg_logloss))\n# baseline probabilities\nprobabilities = [[0.99, 0.01] for _ in range(len(y_test))]\navg_logloss = log_loss(y_test, probabilities)\nprint('Baseline: Log Loss=%.3f' % (avg_logloss))\n# perfect probabilities\navg_logloss = log_loss(y_test, y_test)\nprint('Perfect: Log Loss=%.3f' % (avg_logloss))","metadata":{"execution":{"iopub.status.busy":"2021-08-18T09:01:26.961689Z","iopub.execute_input":"2021-08-18T09:01:26.962125Z","iopub.status.idle":"2021-08-18T09:01:31.920599Z","shell.execute_reply.started":"2021-08-18T09:01:26.962094Z","shell.execute_reply":"2021-08-18T09:01:31.918724Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- We have used log loss() function of the scikit-learn.\n- It took the predicted probability for each class as input and returned the average log loss.\n- Predicting certainty for fraud and non fraud label is punished with large log loss scores.\n- Since dataset has .5% minority class instances,  being certain for the minority class in all cases results in a much larger log loss score.\n- Baseline did better job by using target distribution.\n- Any model brings us lower than baseline log loss score would make prediction with skill.\n- Perfect log loss score: 0.0 means that there is no difference between prediction and the real values.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"8\"></a>\n<font color=\"lightseagreen\" size=+2.5><b>Regression Evaluation Metrics</b></font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents</a>","metadata":{}},{"cell_type":"markdown","source":"- It would be good idea to refresh our knowledge on the regression evaluation metrics.\n- We will look at \n    - Mean Absolute Error, \n    - Mean Squared Error\n    - Root Mean Squared Error\n    - R2\n- First we will see their definitions and formulas and then see them in the action.\n- In this study, we will use Boston House  prices dataset.","metadata":{}},{"cell_type":"code","source":"column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\ndf_boston= pd.read_csv('../input/boston-house-prices/housing.csv',header=None, delimiter=r\"\\s+\", names=column_names)\ndf_boston = df_boston.drop('CHAS', axis=1)\ndf_boston.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-18T09:02:10.643706Z","iopub.execute_input":"2021-08-18T09:02:10.644102Z","iopub.status.idle":"2021-08-18T09:02:10.691655Z","shell.execute_reply.started":"2021-08-18T09:02:10.644069Z","shell.execute_reply":"2021-08-18T09:02:10.69074Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_boston['MEDV'].describe()","metadata":{"execution":{"iopub.status.busy":"2021-08-18T09:02:14.075797Z","iopub.execute_input":"2021-08-18T09:02:14.076345Z","iopub.status.idle":"2021-08-18T09:02:14.095864Z","shell.execute_reply.started":"2021-08-18T09:02:14.076309Z","shell.execute_reply":"2021-08-18T09:02:14.093965Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" <a id=\"9\"></a>\n<font color=\"lightseagreen\" size=+1.5><b>Mean Absolute Error (MAE)</b></font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents</a>","metadata":{}},{"cell_type":"markdown","source":"- As shown below, MAE is average absolute differences between  our predicitions and the real value.\n- MAE is easily interpretable\n- Lower the MAE, better the prediction.","metadata":{}},{"cell_type":"markdown","source":"![](https://i.imgur.com/19LNbyQ.jpg)","metadata":{}},{"cell_type":"markdown","source":"image credit : https://stackoverflow.com/questions/56401346/mean-absolute-error-in-tensorflow-without-built-in-functions/56401550","metadata":{}},{"cell_type":"code","source":"X = df_boston.drop('MEDV',axis=1)\ny = df_boston['MEDV']\npipeline = make_pipeline(PowerTransformer(method='yeo-johnson'), LinearRegression())\ncv = KFold(n_splits=10, random_state=42)\nresults = cross_val_score(pipeline, X, y, cv=cv, scoring='neg_mean_absolute_error')\nprint(f'MAE: {round(results.mean()*-1,3)}, ({round(results.std(),3)})')","metadata":{"execution":{"iopub.status.busy":"2021-08-18T09:02:28.007652Z","iopub.execute_input":"2021-08-18T09:02:28.008043Z","iopub.status.idle":"2021-08-18T09:02:28.559229Z","shell.execute_reply.started":"2021-08-18T09:02:28.008011Z","shell.execute_reply":"2021-08-18T09:02:28.557989Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"10\"></a>\n<font color=\"lightseagreen\" size=+1.5><b>Mean Squared Error (MSE)</b></font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents</a>","metadata":{}},{"cell_type":"markdown","source":"- MSE is the squarred average squared differences between predicted value and the real value.\n- Lower the MSE, better the prediction.","metadata":{}},{"cell_type":"markdown","source":"![](https://cdn-images-1.medium.com/max/959/1*WDKhO-z7rti70ZTv59yJ9A.jpeg)","metadata":{}},{"cell_type":"markdown","source":"image credit: https://cdn-images-1.medium.com","metadata":{}},{"cell_type":"code","source":"X = df_boston.drop('MEDV',axis=1)\ny = df_boston['MEDV']\npipeline = make_pipeline(PowerTransformer(method='yeo-johnson'), LinearRegression())\ncv = KFold(n_splits=10, random_state=42)\nresults = cross_val_score(pipeline, X, y, cv=cv, scoring='neg_mean_squared_error')\nprint(f'MSE: {round(results.mean()*-1,3)}, ({round(results.std(),3)})')","metadata":{"execution":{"iopub.status.busy":"2021-08-18T09:02:37.524965Z","iopub.execute_input":"2021-08-18T09:02:37.525406Z","iopub.status.idle":"2021-08-18T09:02:38.042826Z","shell.execute_reply.started":"2021-08-18T09:02:37.525374Z","shell.execute_reply":"2021-08-18T09:02:38.04165Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"11\"></a>\n<font color=\"lightseagreen\" size=+1.5><b>Root Mean Squared Error (RMSE)</b></font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents</a>","metadata":{}},{"cell_type":"markdown","source":"- RMSE is basically square root of the MSE\n- By taking the square root of the MSE, units are converted  back to the original units of the target variable.","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://programmerah.com/wp-content/uploads/2020/11/20190714113817886.png\" width=\"600\">","metadata":{}},{"cell_type":"markdown","source":"image credit: https://programmerah.com","metadata":{}},{"cell_type":"code","source":"X = df_boston.drop('MEDV',axis=1)\ny = df_boston['MEDV']\npipeline = make_pipeline(PowerTransformer(method='yeo-johnson'), LinearRegression())\ncv = KFold(n_splits=10, random_state=42)\nresults = cross_val_score(pipeline, X, y, cv=cv, scoring='neg_mean_squared_error')\nprint(f'RMSE: {round(np.sqrt(results.mean()*-1),3)}, ({round(results.std(),3)})')","metadata":{"execution":{"iopub.status.busy":"2021-08-18T09:02:44.942382Z","iopub.execute_input":"2021-08-18T09:02:44.94281Z","iopub.status.idle":"2021-08-18T09:02:45.479512Z","shell.execute_reply.started":"2021-08-18T09:02:44.942777Z","shell.execute_reply":"2021-08-18T09:02:45.478373Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"12\"></a>\n<font color=\"lightseagreen\" size=+1.5><b>R Squared (R2)</b></font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents</a>","metadata":{}},{"cell_type":"markdown","source":"- Most of the applications in default uses R squared as a metric for the regression problems.\n- R squared gives us the proportion of the target variable is explained by the feature(s).\n- R squared provides an indication of the goodness of fit of a set of predictions to the actual values.","metadata":{}},{"cell_type":"markdown","source":"![](https://slidetodoc.com/presentation_image/7d85c6a301ba5b97b7d3b73273b073d0/image-13.jpg)","metadata":{}},{"cell_type":"markdown","source":"image credit: https://slidetodoc.com/class-5-thurs-sep-23-example-of-using","metadata":{}},{"cell_type":"code","source":"X = df_boston.drop('MEDV',axis=1)\ny = df_boston['MEDV']\npipeline = make_pipeline(PowerTransformer(method='yeo-johnson'), LinearRegression())\ncv = KFold(n_splits=10, random_state=42)\nresults = cross_val_score(pipeline, X, y, cv=cv, scoring='r2')\nprint(f'R Squared: {round(results.mean(),3)}, ({round(results.std(),3)})')","metadata":{"execution":{"iopub.status.busy":"2021-08-18T09:02:50.712227Z","iopub.execute_input":"2021-08-18T09:02:50.712763Z","iopub.status.idle":"2021-08-18T09:02:51.244012Z","shell.execute_reply.started":"2021-08-18T09:02:50.712726Z","shell.execute_reply":"2021-08-18T09:02:51.242898Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"13\"></a>\n<font color=\"darkblue\" size=+1.5><b>Conclusion</b></font>\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents</a>","metadata":{}},{"cell_type":"markdown","source":"- We have covered one of the most important concepts of the Machine Learning.\n- We have looked at both classification metrics and regression metrics.\n- We have talked about the misusages of the metrics and the correct ones.\n\n- Evaluation metrics are crucial. Based on the model performance we are giving decisions.\n- We should remember that we are not just only looking for a better model, also looking for our end goal.\n- Before deciding evaluation metrics, it would be a good idea to talk your customer, stakeholders and relevant people to clarify their goals and what they realy want.\n- And please remember that most of the classification problems in the real life have imbalanced data.\n","metadata":{}},{"cell_type":"markdown","source":"#### **By the way, when you like the topic, you can show it by supporting** üëç\n\n####  **Feel free to leave a comment in the notebook**. \n\n#### All the best ü§ò","metadata":{}},{"cell_type":"markdown","source":"- **Enjoy** ü§ò","metadata":{}},{"cell_type":"markdown","source":"![](https://media.giphy.com/media/l2JJsJQY6yj9HLaZW/giphy.gif)","metadata":{}},{"cell_type":"markdown","source":"image credit: https://giphy.com","metadata":{}},{"cell_type":"markdown","source":"<a id=\"14\"></a>\n<font color=\"darkblue\" size=+1.5><b>References & Further Reading</b></font>\n\n\n<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Table of Contents</a>\n\n\n[Machine Learning - Beginner &Intermediate-Friendly BOOKS](https://www.kaggle.com/general/255972)","metadata":{"execution":{"iopub.status.busy":"2021-08-18T08:11:57.924116Z","iopub.execute_input":"2021-08-18T08:11:57.924503Z","iopub.status.idle":"2021-08-18T08:11:57.932496Z","shell.execute_reply.started":"2021-08-18T08:11:57.924474Z","shell.execute_reply":"2021-08-18T08:11:57.9311Z"}}}]}