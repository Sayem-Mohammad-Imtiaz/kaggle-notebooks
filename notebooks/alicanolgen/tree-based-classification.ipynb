{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from __future__ import print_function\nimport os\nimport warnings\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas_profiling\nimport matplotlib.image as image\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use(\"ggplot\")\nwarnings.simplefilter(\"ignore\")\nplt.rcParams['figure.figsize'] = (12,8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/ibm-hr-analytics-attrition-dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_original = data\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.profile_report(title = \"Data\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(data.BusinessTravel,data.Attrition).plot(kind = \"bar\")\nplt.title('Turnover Frequency on Business Travel Bracket')\nplt.xlabel('Travel')\nplt.ylabel('Frequency of Turnover')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(data.Department,data.Attrition).plot(kind = \"bar\")\nplt.title('Turnover Frequency on Department Bracket')\nplt.xlabel('Department')\nplt.ylabel('Frequency of Turnover')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(data.EducationField,data.Attrition).plot(kind = \"bar\")\nplt.title('Turnover Frequency on Edication Field Bracket')\nplt.xlabel('Education Field')\nplt.ylabel('Frequency of Turnover')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(data.Gender,data.Attrition).plot(kind = \"bar\")\nplt.title('Turnover Frequency on Gender')\nplt.xlabel('Gender')\nplt.ylabel('Frequency of Turnover')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_vars = ['EducationField','Department','BusinessTravel','Gender','JobRole','MaritalStatus','Over18','OverTime']\nfor i in cat_vars:\n    cat_list = 'var'+'_'+i\n    cat_list = pd.get_dummies(data[i],prefix = i)\n    hr = data.join(cat_list)\n    data = hr\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(columns=['EducationField','Department','BusinessTravel','Gender','JobRole','MaritalStatus','Over18','OverTime'],axis=1,inplace= True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Attrition = data.Attrition.replace(to_replace=['No','Yes'], value=[0,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.loc[:,data.columns != 'Attrition']\ny = data.Attrition","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42, stratify = y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import tree\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import export_graphviz # display the tree within a Jupyter notebook\nfrom IPython.display import SVG\nfrom graphviz import Source\nfrom IPython.display import display\nfrom ipywidgets import interactive, IntSlider, FloatSlider, interact\nimport ipywidgets\nfrom IPython.display import Image\nfrom subprocess import call\nimport matplotlib.image as mpimg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@interact\n\ndef plot_DecisionTree(crit=[\"gini\",\"entropy\"],\n             split = [\"best\",\"random\"],\n             depth = IntSlider(min = 1,max=30,value=2,continuous_update = False),\n             min_split = IntSlider(min = 2, max=5, value=2,continuous_update = False),\n             min_leaf = IntSlider(min=1, max=5,value=1,continuous_update = False)):\n    \n    estimator = DecisionTreeClassifier(random_state=0,\n                                     criterion=crit,\n                                     splitter = split,\n                                     max_depth = depth,\n                                     min_samples_split=min_split,\n                                     min_samples_leaf=min_leaf)\n    \n    estimator.fit(X_train,y_train)\n    print('Decision Tree Training Accuracy: {:.3f}'.format(accuracy_score(y_train, estimator.predict(X_train))))\n    print('Decision Tree Test Accuracy: {:.3f}'.format(accuracy_score(y_test, estimator.predict(X_test))))\n    \n    graph = Source(tree.export_graphviz(estimator,\n                                        out_file=None,\n                                        feature_names=X_train.columns,\n                                        class_names=['0', '1'],\n                                        filled = True))\n    \n    display(Image(data=graph.pipe(format='png')))\n    \n    return estimator\n\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@interact \n\ndef polt_RandomForestTree(crit=[\"gini\", \"entropy\"],\n                         bootstrap=[\"True\", \"False\"],\n                         depth=IntSlider(min=1,max=30,value=3, continuous_update=False),\n                         forests=IntSlider(min=1,max=200,value=100,continuous_update=False),\n                         min_split=IntSlider(min=2,max=5,value=2, continuous_update=False),\n                         min_leaf=IntSlider(min=1,max=5,value=1, continuous_update=False)):\n    \n    estimator = RandomForestClassifier(random_state=1,\n                                       criterion=crit,\n                                       bootstrap=bootstrap,\n                                       n_estimators=forests,\n                                       max_depth=depth,\n                                       min_samples_split=min_split,\n                                       min_samples_leaf=min_leaf,\n                                       n_jobs=-1,\n                                      verbose=False).fit(X_train, y_train)\n    \n    print('Random Forest Training Accuracy: {:.3f}'.format(accuracy_score(y_train, estimator.predict(X_train))))\n    print('Random Forest Test Accuracy: {:.3f}'.format(accuracy_score(y_test, estimator.predict(X_test))))\n    num_tree = estimator.estimators_[0]\n    print('\\nVisualizing Decision Tree:', 0)\n    \n    graph = Source(tree.export_graphviz(num_tree,\n                                        out_file=None,\n                                        feature_names=X_train.columns,\n                                        class_names=['0', '1'],\n                                        filled = True))\n    \n    display(Image(data=graph.pipe(format='png')))\n    \n    return estimator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from yellowbrick.model_selection import FeatureImportances\nplt.rcParams['figure.figsize'] = (12,8)\nplt.style.use(\"ggplot\")\n\nrf = RandomForestClassifier(bootstrap='True', class_weight=None, criterion='gini',\n            max_depth=3, max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n            oob_score=False, random_state=1, verbose=False,\n            warm_start=False)\n\nviz = FeatureImportances(rf)\nviz.fit(X_train, y_train)\nviz.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from yellowbrick.classifier import ROCAUC\n\nvisualizer = ROCAUC(rf, classes=[\"Yes\", \"No\"])\n\nvisualizer.fit(X_train, y_train)        # Fit the training data to the visualizer\nvisualizer.score(X_test, y_test)        # Evaluate the model on the test data\nvisualizer.poof();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n            max_features=None, max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n            splitter='best')\n\nvisualizer = ROCAUC(dt, classes=[\"No\", \"Yes\"])\n\nvisualizer.fit(X_train, y_train)        # Fit the training data to the visualizer\nvisualizer.score(X_test, y_test)        # Evaluate the model on the test data\nvisualizer.poof();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegressionCV\n\nlogit = LogisticRegressionCV(random_state=1, n_jobs=-1,max_iter=500,\n                             cv=10)\n\nlr = logit.fit(X_train, y_train)\n\nprint('Logistic Regression Accuracy: {:.3f}'.format(accuracy_score(y_test, lr.predict(X_test))))\n\nvisualizer = ROCAUC(lr, classes=[\"Yes\", \"No\"])\n\nvisualizer.fit(X_train, y_train)        # Fit the training data to the visualizer\nvisualizer.score(X_test, y_test)        # Evaluate the model on the test data\nvisualizer.poof();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}