{"cells":[{"metadata":{},"cell_type":"markdown","source":"CelebA is a dataset of facial images that includes a set of binary attributes per each image. Some of which relate to the color of hair. This will be combined into a single multi-class label, which will be learnt using an InceptionV3 model.\n\nNotes:\n- The notebook uses the `celeba_utils` utility script for convinience.\n- For simplisity of the notebook, all classes are tightly bound to the `Config` and `Paths` data classes. It is generally advised to make the use of these connfigurations more explicit (and passing the relevant configuration as arguments).","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport random\nimport tensorflow.compat.v1 as tf\nimport keras.backend as K\n\n# set a seed for reproducible results\nos.environ['PYTHONHASHSEED'] = '0'\nnp.random.seed(1234)\nrandom.seed(1234)\ntf.set_random_seed(1234)\n\nfrom typing import List, Tuple, Callable\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.layers import Dropout, Dense, GlobalAveragePooling2D\nfrom keras.models import Model\nfrom keras.optimizers import SGD\nfrom keras.utils import Sequence\n\nfrom celeba_utils import Config  # struct with configurations \nfrom celeba_utils import AttrColumns, Paths\nfrom celeba_utils import PartitionType, DataPartition, load_partition_table_with_attributes\nfrom celeba_utils import load_image_set\n\n\n# Configure current run\n\nConfig.TRAINING_SAMPLES = 1984\nConfig.VALIDATION_SAMPLES = 1984\nConfig.BATCH_SIZE = 32\nConfig.NUM_EPOCHS = 15\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will begin with sampling the large dataset using existing official celeba data partitioning (training/validation/test)\n\n`_create_partition` is a generic method that organizes the image ids into a `DataPartition` class (defined in *celeba_utils.py*), based on a pandas DataFrame (celeba's partitioning table) and a method that will implement the sampling strategy: `(df: pd.DataFrame, partition: PartitionType, num_samples: int) -> pd.DataFrame:`.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def _create_partition(df: pd.DataFrame, sample_strategy: Callable) -> DataPartition:\n    _training = sample_strategy(\n        df, PartitionType.TRAINING, Config.TRAINING_SAMPLES)\n\n    _validation = sample_strategy(\n        df, PartitionType.VALIDATION, Config.VALIDATION_SAMPLES)\n\n    _test = sample_strategy(\n        df, PartitionType.TEST, Config.TEST_SAMPLES)\n\n    return DataPartition(\n        training=_training[AttrColumns.ID.value].values,\n        validation=_validation[AttrColumns.ID.value].values,\n        test=_test[AttrColumns.ID.value].values\n    )\n\n\ndef _sample_random_partition(df: pd.DataFrame, partition: PartitionType, num_samples: int) -> pd.DataFrame:\n    filtered = df[df['partition'] == partition.value]\n    sampled = filtered.sample(num_samples)\n    return sampled\n\n\ndef create_random_partition() -> DataPartition:\n    df = pd.read_csv(Paths.DATA_PARTITION)\n    return _create_partition(df, _sample_random_partition)\n\n\ndef trace_partition(partition: DataPartition):\n    print(f\"Training includes {len(partition.training)} images: {partition.training[:10]}...\")\n    print(f\"Validation includes {len(partition.validation)} images: {partition.validation[:10]}...\")\n    print(f\"Test includes {len(partition.test)} images: {partition.test[:10]}...\")\n    \n    \nrandom_partition = create_random_partition()\ntrace_partition(random_partition)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"CelebA offers a set of binary attributes, some of which relate to hair color: 'Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Gray_Hair' and 'Bald' (colum names are defined with the `AttrColumns` enum). We want to combine them into a single multi-class hair color labels.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"print(f\"Readding attributes table from {Paths.ATTRIBUTES}\")\ndf_attr = pd.read_csv(Paths.ATTRIBUTES)\ndf_attr.set_index(AttrColumns.ID.value, inplace=True)\n\n# sampling relevant columns\ncolumns = [\n    AttrColumns.BALD,\n    AttrColumns.BLACK_HAIR,\n    AttrColumns.BLOND_HAIR,\n    AttrColumns.BROWN_HAIR,\n    AttrColumns.GRAY_HAIR,\n]        \ndf_attr = df_attr[[c.value for c in columns]]\ndf_attr[df_attr <= 0] =  0\n\nprint(\"First 5 labels (one hot encoding)\")\nprint(df_attr.head(5))\n\nprint(\"Distribution of attributes\")\nprint(df_attr.sum())\n\n\ndef trace_attributes_per_sample_count(df, title: str):\n    attributes_per_sample = np.bincount(df.sum(axis=1))\n    print(title + '=>')\n    print(f\"\\t{attributes_per_sample[0]} samples don't have any hair-color attributes\")\n    print(f\"\\t{attributes_per_sample[1]} samples have exactly one hair-color attribute\")\n    print(f\"\\t{sum(attributes_per_sample[2:])} samples have more than one hair-color attribute\")\n\n    \ntrace_attributes_per_sample_count(df_attr, \"Total attribute count per sample\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"That's interesting, right? Shouldn't each person have only a single hair color? Well, real world data is s messy buisiness. This is a critical issue to consider because rows don't form a valid target for 1-hot encoding (labels should be a normalized distribution over the categories). \n1. In the case of \"no-color\", encoding can be changed from `[0,0,0,0,0]` to `[.2,.2,.2,.2,.2]`. This is not recomended though, as in reality the lack of any color attributes doesn't imply a uniform probability for all colors (note also that about 1/3 of data doesn't have hair color attributes, so that's a lot of low quality data).\n1. In the case of multiple color attributes, treating them as a distribution makes more sense, so:\n   1. We will explore both sampling method (with or without these samples).\n   1. During label preparation we will normalize the rows as a distribution (sum should be 1).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def _sample_non_zero_partition(df: pd.DataFrame, partition: PartitionType, num_samples: int) -> pd.DataFrame:\n    \"\"\"\n    At least one column (attribute) must be positive\n    \"\"\"\n    filtered = df[df['partition'] == partition.value]\n    values = filtered.values[:, 2:]  # ignore first 2 columns: image_id and partition\n    values[values <= 0] = 0  # attribute values in CelebA are in {-1, 1}\n    filtered = filtered[values.sum(axis=1) > 0]\n    sampled = filtered.sample(num_samples)\n    return sampled\n\n\ndef _sample_mutualy_exclusive_partition(df: pd.DataFrame, partition: PartitionType, num_samples: int) -> pd.DataFrame:\n    \"\"\"\n    Columns (attributes) are mutually exclusive (only one is allowed to be possitive)\n    \"\"\"\n    filtered = df[df['partition'] == partition.value]\n    values = filtered.values[:, 2:]\n    values[values <= 0] = 0\n    filtered = filtered[values.sum(axis=1) == 1]\n    sampled = filtered.sample(num_samples)\n    return sampled\n\n\ndef create_hair_color_partition(sample_strategy: Callable) -> DataPartition:\n    attrs = [\n        AttrColumns.BALD,\n        AttrColumns.BLACK_HAIR,\n        AttrColumns.BLOND_HAIR,\n        AttrColumns.BROWN_HAIR,\n        AttrColumns.GRAY_HAIR,\n    ]\n    df = load_partition_table_with_attributes([c.value for c in attrs])\n    return _create_partition(df, sample_strategy)\n\n\nnon_zero_partition = create_hair_color_partition(_sample_non_zero_partition)\ntrace_attributes_per_sample_count(df_attr.loc[non_zero_partition.training], \"non-zero attribute count (training)\")\ntrace_attributes_per_sample_count(df_attr.loc[non_zero_partition.validation], \"non-zero attribute count (validation)\")\n\nmutually_exclusive_partition = create_hair_color_partition(_sample_mutualy_exclusive_partition)\ntrace_attributes_per_sample_count(df_attr.loc[mutually_exclusive_partition.training], \"mutually-exclusive attribute count (training)\")\ntrace_attributes_per_sample_count(df_attr.loc[mutually_exclusive_partition.validation], \"mutually-exclusive attribute count (validation)\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are now ready to create our data generators (based on Keras `Sequence` class)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def _generate_multi_class_labels(columns: List[AttrColumns], df_attr: pd.DataFrame) -> np.ndarray:\n    attr = df_attr[[c.value for c in columns]]\n    labels = np.array(attr.values)\n    labels[labels <= 0] = 0\n    # we want to keep this method independant of our sampling method\n    # therefore, regardless of sampling stretagy, we want our label generation method to work with \n    # images that have no attributes or more than a single attribute\n    num_of_attributes = labels.sum(axis=1)\n    labels = np.where(\n        (num_of_attributes != 0).reshape(-1, 1),\n        labels / num_of_attributes.reshape(-1, 1),\n        1 / len(columns))\n    return labels\n        \n\nclass MultiClassSequence(Sequence):\n    def __init__(self, columns: List[AttrColumns], image_ids: List[str]):\n        df_attr = pd.read_csv(Paths.ATTRIBUTES)\n        df_attr.set_index(AttrColumns.ID.value, inplace=True)\n               \n        self.labels = _generate_multi_class_labels(\n            columns,\n            df_attr.loc[image_ids]\n        )\n        self.image_ids = image_ids\n        self.batch_size = Config.BATCH_SIZE\n\n    def __len__(self):\n        return len(self.image_ids) // self.batch_size\n\n    def __getitem__(self, idx) -> Tuple[np.ndarray, np.ndarray]:\n        image_ids = self.image_ids[idx * self.batch_size:(idx + 1) * self.batch_size]\n        images = load_image_set(image_ids)\n        labels = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n\n        return images, labels\n\n    \nclass HairColorSequence(MultiClassSequence):\n    def __init__(self, image_ids: List[str]):\n        hair_color_columns = [\n            AttrColumns.BALD,\n            AttrColumns.BLACK_HAIR,\n            AttrColumns.BLOND_HAIR,\n            AttrColumns.BROWN_HAIR,\n            AttrColumns.GRAY_HAIR,\n        ]\n        super().__init__(hair_color_columns, image_ids)       \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We use a pretrained InceptionV3 model and replace its top layers with a new one-hot encoding classification.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(num_classes) -> Model:\n    inc_model = InceptionV3(\n        weights=str(Paths.MODEL_WEIGHTS),\n        include_top=False,\n        input_shape=(Config.IMG_HEIGHT, Config.IMG_WIDTH, 3))\n    \n    x = GlobalAveragePooling2D()(inc_model.output)\n    x = Dense(1024, activation=\"relu\")(x)\n    x = Dropout(0.5)(x)\n    x = Dense(512, activation=\"relu\")(x)\n    x = Dense(num_classes, activation=\"softmax\")(x)    \n\n    model = Model(inputs=inc_model.input, outputs=x)\n\n    for layer in model.layers[:52]:\n        layer.trainable = False\n\n    model.compile(\n        optimizer=SGD(lr=0.0001, momentum=0.9), \n        loss='categorical_crossentropy', \n        metrics=['accuracy'])\n\n    return model\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will train the model twice, using both partition methods (\"non zero\" and \"mutually exclusive\"). However, please note that validation will always be performed using the `mutually_exclusive_partition`.\n1. For a more fair comparison, we should test (validate) all experiments using the same data. In a sense, we need to assume a single source of truth, upon which to measure our results.\n1. I usually favour testing with the more challanging test cases. We need to consider though that the multi-attribute cases are less reliable, so if we use them to test ourselves, we may panalize our system at times where it might be correct (and the labels wrong) - and vice versa.\n1. Generally speaking, each experiment can use it's own validation set (given it is there to assess and control the training process). What is important is that when you **compare**, do so consistently.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Rןun non-zero configuration: \n#   data sampling includes all rows where there is atleast one positive attribute\n#   (include rows with multiple positive color attributes)\n\ncheckpoint = ModelCheckpoint(\n    filepath='weights.best.non-zero.hdf5',\n    verbose=1,\n    save_best_only=True)\n\nhist_non_zero = build_model(num_classes=5).fit_generator(\n    HairColorSequence(non_zero_partition.training),\n    validation_data=HairColorSequence(mutually_exclusive_partition.validation),\n    epochs=Config.NUM_EPOCHS,\n    callbacks=[checkpoint],\n    verbose=1\n)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Rןun mutually-exclusive configuration: \n#   data sampling includes all rows where there is ONLY one positive attribute\n#   (ignore rows with multiple positive color attributes)\n\ncheckpoint = ModelCheckpoint(\n    filepath='weights.best.mutually_exclusive.hdf5',\n    verbose=1,\n    save_best_only=True)\n\nhist_mutually_exclusive =  build_model(num_classes=5).fit_generator(\n    HairColorSequence(mutually_exclusive_partition.training),\n    validation_data=HairColorSequence(mutually_exclusive_partition.validation),\n    epochs=Config.NUM_EPOCHS,\n    callbacks=[checkpoint],\n    verbose=2\n)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(range(Config.NUM_EPOCHS), hist_non_zero.history['val_accuracy'])\nplt.plot(range(Config.NUM_EPOCHS), hist_mutually_exclusive.history['val_accuracy'])\nplt.xlabel('Epochs')\nplt.ylabel('Val Accuracy')\nplt.legend(['non_zero', 'mutually_exclusive'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In our humble experiment we can see similar results for both the more strict \"mutually-exclusive\" and the \"non-zero\" configurations. Please take into account the following:\n1. We have used only a portion of all the available data (although we did use a rather large validation set). \n1. To reach any real conclusions, an experiment should be repeated ([cross validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)). Prefereably exploring several hyperparameters.\n1. In the \"non-zero\" sampling strategy, the (supposedly) \"lower quality\" samples (where a face has multiple color attributes) come at the expense of the \"better\" samples. The current experiment is relevant for the case where we are sampling a subset of the data and the question under investigation is - wherether to allow to substitute the \"high quality\" samples with the \"low quality\" samples.\n1. Alternetively, if we plan to use the entire dataset, a different question needs to be investigated - whether to have **additional** \"low quality\" samples.\n\nHow about we try out the above hypothesis? The new sampling strategy will sample `num_samples` rows with exactly one positive attribute, and additional `num_samples/extention_factor` rows with more than one positibe attributes. This way we can verify whether or not adding such samples is benificial.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def _sample_mutually_exclusive_partition_with_extra_multi_attributes(df: pd.DataFrame, partition: PartitionType, num_samples: int, extention_factor = 5) -> pd.DataFrame:    \n    filtered = df[df['partition'] == partition.value]\n    values = filtered.values[:, 2:]\n    values[values <= 0] = 0\n    \n    mutually_exlusize = filtered[values.sum(axis=1) == 1]\n    mutually_exlusize = mutually_exlusize.sample(num_samples)\n    \n    multiple_attributes = filtered[values.sum(axis=1) > 1]\n    multiple_attributes = multiple_attributes.sample(num_samples // extention_factor)\n    \n    sampled = pd.concat([mutually_exlusize, multiple_attributes]) \n    sampled = sampled.sample(frac=1.)  # reshuffle\n    \n    return  sampled\n\n\npartition_with_extra = create_hair_color_partition(_sample_mutually_exclusive_partition_with_extra_multi_attributes)\ntrace_attributes_per_sample_count(df_attr.loc[partition_with_extra.training], \"extended partition attribute count (training)\")\ntrace_attributes_per_sample_count(df_attr.loc[partition_with_extra.validation], \"extended partition attribute count (validation)\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = ModelCheckpoint(\n    filepath='weights.best.extended.hdf5',\n    verbose=1,\n    save_best_only=True)\n\nhist_extended =  build_model(num_classes=5).fit_generator(\n    HairColorSequence(partition_with_extra.training),\n    validation_data=HairColorSequence(mutually_exclusive_partition.validation),\n    epochs=Config.NUM_EPOCHS,\n    callbacks=[checkpoint],\n    verbose=2\n)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(range(Config.NUM_EPOCHS), hist_non_zero.history['val_accuracy'])\nplt.plot(range(Config.NUM_EPOCHS), hist_mutually_exclusive.history['val_accuracy'])\nplt.plot(range(Config.NUM_EPOCHS), hist_extended.history['val_accuracy'])\nplt.xlabel('Epochs')\nplt.ylabel('Val Accuracy')\nplt.legend(['non_zero', 'mutually_exclusive', 'extended'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To sum up:\n- An example of how to perform multi-class classfication with the CelebA dataset was presented.\n- We also explored a few methods to sample our data and saw how to compare between them. \n- As already mentioned, real conclusion requires a more robust experimentation.\n- Either way, **make sure you give a thorough consideration to what data you include in the training set**. \n   1. Always check what is the common practice.\n   1. Make sure the common practice is actually relevant for your situation. \n   \nI can share my personal experience with working on the [LIDC lung nodule dataset][1]: \n- A common practice was estiblished for nodule malignancy classification - not including nodules with unknown malignancy.\n- This practice was largely adopted by content based image retrieval studies.\n- As part of my [study][2], we saw that the addition of unknown malignancy nodules was acutally benificial to retrieval tasks and has consistently improved results.\n\nReferences:\n1. [LIDC][1]\n1. [Loyman, Mark, and Hayit Greenspan. \"Lung nodule retrieval using semantic similarity estimates.\" Medical Imaging 2019: Computer-Aided Diagnosis. SPIE,2019.][2]\n\n[1]: https://wiki.cancerimagingarchive.net/display/Public/LIDC-IDRI\n[2]: https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10950/109503P/Lung-nodule-retrieval-using-semantic-similarity-estimates/10.1117/12.2512115.short\n","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}