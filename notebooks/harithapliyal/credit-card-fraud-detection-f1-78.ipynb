{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Author : Hari Thapliyal\n#Project: Credit Card Fraud Detection\n#Client: Kaggle Competition\n#Dataset: https://www.kaggle.com/mlg-ulb/creditcardfraud\n#github repo: https://github.com/dasarpai/CapProject-CreditFraud-Detection\n\nT#The Best Results of many experimentation\n#KNN: AUC 0.92, Recall 0.82, Precision 0.74, F1 0.78\n#RFC: AUC 0.98, Recall 0.89, Precision 0.04, F1 0.07\n#LGBM: AUC 0.93, Recall 0.83, Precision 0.09, F1 0.16","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Learnings","metadata":{"id":"nGtVlXq6_jOl"}},{"cell_type":"raw","source":"A- How to handle unbalanced dataset. 99.83% transactions are normal. 0.17% transactions are fraud transaction in our dataset.\n \nB- Using Smote, Adasync, RandomOversampler. Out dataset is unbalanced so we are planning to oversample the small set. There are many techniques of oversampling and we donot know which can work best for our dataset. So we are using all these 3 techniques to oversample along with normal dataset (without balancing dataset)\n\nC- Classfication with PCA varabiles. Due to security reasons data provided by the bank is PCA so we donot know field name and their values .\n\nD- Apply Cross validation for Hyperparamter tuning. We do not know which model with what set of hyper parameters will give us the best results so we are planning to created many models with many combination of hyperparameters and many algorithms.\n\nE- RFE for feature selection. We want to understand how effective is RFE in feature selection for our kind of dataset.\n\nF- Using StandardScalar. Although out dataset is PCA but we will still scale our dataset. PCA helps in encrypition and imformation compression but it does not guraratee that all feature will have same range.\n\nG- Code Modularization.: Many models need to be created with differnet hyper parameters, different algorithms, different types of data balancing. So we cannot write same code again and again with small change.\n\nH- Tradeoff of metrics: F1, AUC, Recall, Precision, Accuracy. In unbalanced databset accuracy does not make sense (with oversampling it is fine). But how to tradeoff between F1, Recall and Precision.\n\nI- Building different models and comparing their performance.\n\nJ- Determining which field is important in the creditcard trataction fraud prediction.\n\nK- Using following algorithms our classification problem.\n 1. Logistic Regression, 2. stats.glm, 3. KN Classifier, 4. SVC, 5. NaiveBayes, 6. Stochastic Grandient Descent\n 7. Decision Tree 8. Random forest classifier 9. XGBoost, 10. LightLBGM, 11. AdaBoost, 12. CatBoostClassifier.\n 13. Perceptron, 14. DNN 15. CNN","metadata":{}},{"cell_type":"markdown","source":"# Workflow in this Notebook","metadata":{}},{"cell_type":"raw","source":"Section 1: Exploratory data analysis\n    Getting data from kaggle to colab dataset. \n    Analysis of Fraud against the Transaction Value\n    Let us see distribution of various columns\n    Here we will observe the distribution of our classes\n    Let us Check Coorelation Between Different Variables\n    Is there an relationship between variables and Class?\n    Let us see Distribution of data for the given 2 Classes\n    To observe the relation between amount and other variable for both the classes.\n    Standard Scale All the Fields Including Time and Amount\n    Plotting the distribution of a variable- After Scaling\n    Some fields are still skewed. So using PowerTransformer to fix that issue.\n    Plotting the distribution of a variable- After Correcting Skweness Issue\n    Check the outliers after fixing skewness & scale issue\n\nSection 2: Splitting the data into Train & Test\nSection 3: Visuzalise Results of Various Oversampling Methods\nSection 4: Select the Dataset Imbalancing Method\nSection 5: Helper Functions for Model Building \n    \nSection 6: Model Building \n    Model 1: Logistic Regression\n    Model 2: GLM\n    Model 3: KNeighborsClassifier\n    Model 4: RandomForestClassifier\n    Model 5: DecisionTreeClassifier\n    Model 6: LGBM\n    Model 7: Perceptron\n    Model 8: SVC\n    Model 9: XGBoost\n    Model 10: Adaboost\n    Model 11: CatboostClassifier\n    Model 12: Naive Bayes\n    Model 13: Stochastic Gradient Descent Classifier\n    Model 14: Dense Neural Network\n    Model 15: Convolution Neural Network","metadata":{}},{"cell_type":"code","source":"#!pip install -U pip\n#!pip install -U imblearn\n#!pip install importlib_metadata\n#!pip install -U scikit-learn\n#!pip install Catboost\n#from importlib_metadata import version\n#version('scikit-learn')","metadata":{"id":"CwwMNDNQ8KQl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport numpy as np\nimport pandas as pd\n\n# Matplotlib library to plot the charts\nimport matplotlib.pyplot as plt\nimport matplotlib.mlab as mlab\nimport seaborn as sns\n\n# Import Various Classical ML Algorithm Libraries\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nimport statsmodels.api as sm\n\n#Import Tree Based Libraries\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom xgboost import XGBRFClassifier as xgbc\nfrom catboost import CatBoostClassifier\nimport lightgbm as lgbmc\n\n#Import Deep Learning Libraries\nimport tensorflow as tf\nfrom keras import backend as K\nfrom keras import layers\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Dropout, Flatten, BatchNormalization, Activation\nfrom keras.layers import MaxPool1D, AvgPool1D, GlobalAvgPool1D\nfrom keras.layers.convolutional import Conv1D, MaxPooling1D\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom keras import optimizers\nfrom keras.optimizers import Adam, SGD\nfrom keras.regularizers import l2, L1L2\nfrom sklearn.linear_model import Perceptron\n\n\n#Import Libraries for Model Evaluation\nfrom sklearn import metrics\nfrom sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\nfrom sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n\n#Import Helping Libraries\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold,KFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import power_transform\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_selection import RFE\nfrom imblearn import over_sampling\nfrom collections import Counter\nimport itertools\nfrom timeit import default_timer as timer","metadata":{"id":"IJcTiAr8_jOo","execution":{"iopub.status.busy":"2021-06-02T12:57:08.15619Z","iopub.execute_input":"2021-06-02T12:57:08.156773Z","iopub.status.idle":"2021-06-02T12:57:17.398184Z","shell.execute_reply.started":"2021-06-02T12:57:08.156685Z","shell.execute_reply":"2021-06-02T12:57:17.397324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#So that matplot produces all the graphs in the cell below from where the graph is called. \n#Otherwise it will open in the different window.\n%matplotlib inline \n\n#So that we don't see .... between columns. I want to see the name of all columns and their values.\npd.options.display.max_columns = 31 \n\nsns.set_style(\"white\")\n\n#5 folds will be created from the given data and it will be ensured that \n#each fold has equal number of normal and fraud transactions.\nfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=100)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T11:34:23.529833Z","iopub.execute_input":"2021-06-02T11:34:23.530251Z","iopub.status.idle":"2021-06-02T11:34:23.538341Z","shell.execute_reply.started":"2021-06-02T11:34:23.530217Z","shell.execute_reply":"2021-06-02T11:34:23.53742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font color=red>Want to run Expensive/Time/ Resource consuming Process- CrossValidation?</font>","metadata":{}},{"cell_type":"code","source":"#Everytime running cross validation is taking time. \n#So if you do not want to run the code with CV and \n#want to run only with optimized Hyper Parameters then set this False\n\nrun_cv=False","metadata":{"execution":{"iopub.status.busy":"2021-06-02T13:08:34.962616Z","iopub.execute_input":"2021-06-02T13:08:34.96308Z","iopub.status.idle":"2021-06-02T13:08:34.967423Z","shell.execute_reply.started":"2021-06-02T13:08:34.963044Z","shell.execute_reply":"2021-06-02T13:08:34.966348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font color=blue> Section 1: Exploratory data analysis </font>","metadata":{"id":"1aSkY1p2_jOv"}},{"cell_type":"markdown","source":"#### Getting data from kaggle to colab dataset.","metadata":{"id":"Koo1EYN88KQz"}},{"cell_type":"code","source":"#!wget \"https://www.kaggle.com/mlg-ulb/creditcardfraud\"\nfilename = r'../input/creditcardfraud/creditcard.csv'\n#filename=r'D:\\01-Works\\00-Doc-to-Sync\\0-Download\\Creditcard\\creditcard.csv'\n\ndf = pd.read_csv(filename)\nprint (df.shape)","metadata":{"id":"e-MiO1J2_jOw","outputId":"84718933-124d-4aff-cd45-54d33b461444","execution":{"iopub.status.busy":"2021-06-02T13:08:39.26499Z","iopub.execute_input":"2021-06-02T13:08:39.265631Z","iopub.status.idle":"2021-06-02T13:08:43.944655Z","shell.execute_reply.started":"2021-06-02T13:08:39.265581Z","shell.execute_reply":"2021-06-02T13:08:43.943488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#observe the different feature type present in the data\ndf.head(3)","metadata":{"id":"-efqS6tijNcs","outputId":"f081dc1e-b99f-45ec-e93e-f3709c9548c7","execution":{"iopub.status.busy":"2021-06-02T11:36:40.654554Z","iopub.execute_input":"2021-06-02T11:36:40.65517Z","iopub.status.idle":"2021-06-02T11:36:40.699434Z","shell.execute_reply.started":"2021-06-02T11:36:40.655131Z","shell.execute_reply":"2021-06-02T11:36:40.698508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Class'].value_counts()/len(df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()\n#No Null Value. All the float fields","metadata":{"id":"5Cq8_K2l_jO3","outputId":"f1b9ee0d-2fe0-469f-8609-75db904b314b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe().T\n#Range of all the fields not same. If we take data as given for modeling some variables will \n#have more influence on the model than other so scaling need to done","metadata":{"id":"P3fXUxN5m3Lt","outputId":"b0ee8fef-af0f-4090-f906-4b6fd40205f7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Can we take time as primary key field?\n\ntemp=df.groupby('Time')['Class'].count()\ntemp.reset_index()\nprint(temp[temp>1].sort_values(ascending=False))\ndel temp\n\n#Time Field cannot be treated as unique identifier because it has many duplicate entries.\n#it be useful in prediction fraud.","metadata":{"id":"BEpuECfVpRLY","outputId":"bc09d8be-08a0-4d4c-a39d-b930f8f34bfc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Amount'].describe(percentiles=[.25,.50,.75,.90,.95,.99])\n#99% Transaction are less than $1018","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"amt99 = 1018\ndf99 = df.iloc[ list(df['Amount']<=amt99) ]\ndf01 = df.iloc[ list(df['Amount']>amt99) ]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Distribution of class along the time\nfig,(ax1,ax2) = plt.subplots(ncols=2, figsize=(20,4))\nstart=timer()\n\nplt.figure(figsize=(10,5))\n#plt.title (\"Distribution of class along the time\")\n\nclass_0 = df99.loc[df['Class'] == 0][\"Time\"]\nclass_1 = df99.loc[df['Class'] == 1][\"Time\"]\nsns.distplot(class_0,hist=False,rug=False,label='Not Fraud', color=\"red\", ax=ax1, kde_kws=dict(linewidth=5)).set(xlim=0)\nsns.distplot(class_1,hist=False,rug=False,label='Fraud', ax=ax1, color=\"blue\")\nsns.distplot(df99.Time,hist=False,rug=False,label='All-Transactions', ax=ax1, color=\"yellow\")\nax1.set_title   (\"Distribution of class along the time - 99 Percentile of Transactions\")\n#ax1.legend(bbox_to_anchor=(.25, 1))\nax1.legend(loc='upper left')\n\nclass_0 = df01.loc[df['Class'] == 0][\"Time\"]\nclass_1 = df01.loc[df['Class'] == 1][\"Time\"]\nsns.distplot(class_0,hist=False,rug=False,label='Not Fraud', color=\"red\", kde_kws=dict(linewidth=5), ax=ax2).set(xlim=0)\nsns.distplot(class_1,hist=False,rug=False,label='Fraud', color=\"blue\", ax=ax2)\nsns.distplot(df01.Time,hist=False,rug=False,label='All-Transactions', color=\"yellow\", ax=ax2)\nax2.set_title (\"Distribution of class along the time - 1 Percentile of Transactions\")\n# ax2.legend(bbox_to_anchor=(-.25, 1))\nax2.legend(loc='upper left')\n\nplt.show()\n\nend = timer()\nprint(\"Duration \",end - start)\n\n#Distribution of data for fraud and non-faud transactions are different. \n#Normal transaction and sum total of all transaction following same distribution. Because fraud trans are very few.\n#We have two days data with us so it shows two peack in normal transaction.\n#I am not able to identify any signfificant pattern in fraud transaction from two days data.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Distribution of class along the time\nfig,(ax1,ax2) = plt.subplots(ncols=2, figsize=(20,4))\nstart=timer()\n\nplt.figure(figsize=(10,5))\n#plt.title (\"Distribution of class along the time\")\n\nclass_0 = df99.loc[df['Class'] == 0][\"Amount\"]\nclass_1 = df99.loc[df['Class'] == 1][\"Amount\"]\nsns.distplot(class_0,hist=False,rug=False,label='Not Fraud', color=\"red\", ax=ax1, kde_kws=dict(linewidth=5)).set(xlim=0)\nsns.distplot(class_1,hist=False,rug=False,label='Fraud', ax=ax1, color=\"blue\")\nsns.distplot(df99.Amount,hist=False,rug=False,label='All-Transactions', ax=ax1, color=\"yellow\")\nax1.set_title   (\"Distribution of class with Amount - 99 Percentile of Transactions\")\n#ax1.legend(bbox_to_anchor=(.25, 1))\nax1.legend(loc='upper right')\n\nclass_0 = df01.loc[df['Class'] == 0][\"Amount\"]\nclass_1 = df01.loc[df['Class'] == 1][\"Amount\"]\nsns.distplot(class_0,hist=False,rug=False,label='Not Fraud', color=\"red\", kde_kws=dict(linewidth=5), ax=ax2).set(xlim=0)\nsns.distplot(class_1,hist=False,rug=False,label='Fraud', color=\"blue\", ax=ax2)\nsns.distplot(df01.Amount,hist=False,rug=False,label='All-Transactions', color=\"yellow\", ax=ax2)\nax2.set_title (\"Distribution of class with Amount - 1 Percentile of Transactions\")\n# ax2.legend(bbox_to_anchor=(-.25, 1))\nax2.legend(loc='upper right')\n\nplt.show()\n\nend = timer()\nprint(\"Duration \",end - start)\n\n#Distribution of data for fraud and non-fraud transactions are different. \n#Normal transaction and sum total of all transaction following same distribution. Because fraud trans are very few.\n#In 99 percentile we see most of the transactions are less than $200\n#in 1 percentile we see a right tailed bell curve with a mean around $3000. \n#for this 1 percentile data interesting around this mean we see spike of fraud transaction","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Analysis of Fraud against the Transaction Value","metadata":{}},{"cell_type":"code","source":"max_amount=int(round(max(df.Amount) *1.04,-3))\nbins=list(range(0,1601,100))\nbins.append(max_amount)\ndf['Amt']=pd.cut(df.Amount,bins)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_trans = df.pivot_table(index=\"Amt\",columns=\"Class\",values=\"V1\",aggfunc=len) \nall_trans['All'] = all_trans[0] +all_trans[1]\nall_trans = all_trans.drop( 0, axis=1)\nall_trans.columns=['Fraud','All']\nall_trans['Fraud %'] = all_trans['Fraud']  / len( df[df.Class==1])*100\nall_trans['All %'] = all_trans['All']  / len( df.Class)*100\nall_trans\n#79.5% of the transactions are less than $100 but fraud in that category is 68%.\n#There are 9.57% transactions between $200 and 1600 but fraud is 16.86%","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_trans[['All %','Fraud %']].plot(figsize=(20, 4))\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Let us see distribution of various columns","metadata":{}},{"cell_type":"code","source":"start = timer()\n#Distribution of the data\nplt.figure(figsize=(20,8))\ni=1\nfor col in df.columns[0:30]:\n    plt.subplot(3,11,i)\n    sns.distplot(df[col])\n    i+=1\nplt.tight_layout()\n\nend = timer()\nprint(\"Duration \",end - start)\n\n#Except time and amount all fields looks having single peak bell curve. Although some of the fields are skwed right\n#side and some looks skewed left side. So we can use power-transformer -yeo-johnson to handle this issue.","metadata":{"id":"bPNj7SsG_jO6","outputId":"69008353-5cf5-40cb-93c7-02454fd0ec4a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"dmwqW7CgIu1a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Here we will observe the distribution of our classes","metadata":{"id":"TxOLpWOn_jPh"}},{"cell_type":"code","source":"# classes=df['Class'].value_counts()\n# normal_share=classes[0]/df['Class'].count()*100\n# fraud_share=classes[1]/df['Class'].count()*100\n\n# amt=100*df.groupby(\"Class\").sum()[\"Amount\"] / sum(df.Amount)\n\n# print (\"Normal Transaction {:.2f}  Fraud Transaction {:.2f}  \".format (classes[0],classes[1]))\n# print (\"Normal Transaction {:.2f}%  Fraud Transaction {:.2f}%  \".format (normal_share,fraud_share))\n# print (\"Value of Normal Transaction {:.2f}%  Fraud Transaction {:.2f}%  \".format (amt[0],amt[1]))\n\n# fraud_amt=df.loc[df['Class'] == 1][\"Amount\"]\n# print (\"\\nAverage Value {:.2f} Min Value {:.2f}  Max Value {:.2f} Fraud Transactions\".format( np.average(fraud_amt), np.min(fraud_amt), np.max(fraud_amt)))\n\n# fraud_0amt_trans=len ( df.loc[  (df['Class'] == 1) & (df['Amount']==0)  ] )\n# print (\"\\n# Fraud Transactions of 0 Value = \",fraud_0amt_trans)","metadata":{"id":"WkipUfuR_jPj","outputId":"9cf1a3b9-321f-46b3-957e-79f44ed8bf3c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Let us Check Coorelation Between Different Variables","metadata":{}},{"cell_type":"code","source":"df_corr = df.corr()\nplt.figure(figsize=(16,8))\nsns.heatmap(df_corr, cmap=\"YlGnBu\") # Displaying the Heatmap\n#sns.set(font_scale=.5,style='white')\n\nplt.title('Heatmap correlation')\nplt.show()\n\n#Since this is is PCA data it looks there is no relationship between the given variables. Except time and amount has\n#some sort of relationship with other fields.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Is there an relationship between variables and Class?","metadata":{}},{"cell_type":"code","source":"\nrank = pd.DataFrame(df_corr['Class']) #.sort_values(ascending=False)\nrank['Relationship'] = rank.Class.apply(lambda x: \"+\" if x>0 else \"-\")\nrank.Class=abs(rank.Class)\nrank.rename(columns={\"Class\":\"Degree of Relation with Class\"}, inplace=True)\nrank.sort_values(\"Degree of Relation with Class\", ascending=False)\n\n#Some variables show positive relationship with fraud and some negative. For example V17 & Fraud share share -ve\n#relation. More the value of V17 lesser are the chances of this being fraud.\n#V11 has +ve relationship. More the value of V11 more are the chances that transation is fraud.\n#Value of transaction (amount) has very weak relation with class (fraud / non-fraud transaction) only .005 or .5 %\n#Time of transaction has also has a very weak relation with class (fraud / non-fraud transaction) only .012 or 1.2 %","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=red>Note 1: Because I don't have enough computing resources available (I tried nimblebox, google colab, kaggle but that also too slow), therfore I am NOT using full given dataset for the model building.</font> </br>\n\n#### <font color=red>Note 2: We need to have modular code to run same models with different parameters and differnt data imbalance treatment otherwise it will be extremely difficult to maintain the code. Therefore I have taken different approach. Which you can observer while scanning and running the code.\n</font>","metadata":{}},{"cell_type":"code","source":"df.drop(columns=\"Amt\", inplace=True) #This field was created for binning purpose so not required for modeling","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Training model on huge dataset taking too much time so taking 5% of data initially. \n#Fraud class dataset is very small so adding it fully to the new dataset.\n#When code start working fine and start doing reasonable prediction disable below line\n#If you have enough resources you can disable this cell\n\ndf = pd.concat([ df.sample(frac=.05, random_state=1),df.loc[df.Class==1] ])\nprint (df.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Let us see Distribution of data for the given 2 Classes","metadata":{}},{"cell_type":"code","source":"\nstart=timer()\n\ncolor = sns.color_palette(\"Set1\", 6)\nplt.figure(figsize=(20,20))\ni=1\n\nfor col in df.columns:\n    plt.subplot(8,4,i)\n    ax=sns.boxplot(x=df['Class'],y=df[col],  palette=color)\n    \n    for p in ax.patches:\n        ax.annotate(format(p.get_height(), '.2f'), \n                (p.get_x() + p.get_width() / 2.,\n                 p.get_height()), ha = 'center', va = 'center', \n                fontsize=8,\n                xytext = (0, 10), textcoords = 'offset points')\n    i+=1\nplt.tight_layout()\n\nend = timer()\nprint(\"Duration \",end - start)\n\n#Almost all fields has outlier values.\n#Median of data for both the classes is almost same for all variables.\n#IQR range is significantly different for some of the variables like v1, v4, v5, v12, v14,v16, v17, v18","metadata":{"id":"aEnPIx--1PTk","outputId":"8024b30d-f130-496e-db57-e2c6e310999e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Creating a scatter plot \n#### To observe the relation between amount and other variable for both the classes.","metadata":{}},{"cell_type":"code","source":"\nstart=timer()\n\nplt.figure(figsize=(20,80))\ni=1\nfor col in df.columns:\n    plt.subplot(16,2,i)\n    \n    sns.regplot(y=df[df.Class==0].Amount,x=df[df.Class==0][col], color=\"g\")\n    ax= sns.regplot(y=df[df.Class==1].Amount,x=df[df.Class==1][col], color=\"r\")\n    ax.tick_params(labelsize=15)\n    ax.set_xlabel(col,fontsize=15)\n\n    i+=1\nplt.tight_layout()\n\nend = timer()\nprint(\"Duration \",end - start)\n\n#For most of the variables slope of amount field for non-fraud transaction has some slope. \n#But there is almost no slope for fraud transaction.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Standard Scale All the Fields Including Time and Amount","metadata":{}},{"cell_type":"code","source":"cols2Scale = list(df.columns)\ncols2Scale.remove(\"Class\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sc=StandardScaler()\nt=sc.fit_transform(df[ cols2Scale ])\ndf[cols2Scale] = t\ndf.head(5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe().T","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plotting the distribution of a variable- After Scaling","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot the histogram of a variable from the dataset to see the skewness\n#Distribution of the data\nstart=timer()\n\nplt.figure(figsize=(20,8))\ni=1\nfor col in df.columns[1:30]:\n    plt.subplot(3,11,i)\n    sns.distplot(df[col])\n    i+=1\nplt.tight_layout()\n\nend = timer()\nprint(\"Duration \",end - start)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Some fields are still skewed. So using PowerTransformer to fix that issue.\n- <b>Power Transformer</b> package present in the <b>preprocessing library provided by sklearn</b> to make distribution more gaussian","metadata":{"id":"C_dB1b0Z_jQM"}},{"cell_type":"code","source":"# - Apply : preprocessing.PowerTransformer(copy=False) to fit & transform the train & test data\n#'yeo-johnson’ [1], works with positive and negative values\n#‘box-cox’ [2], only works with strictly positive values\n\ndf[cols2Scale] = power_transform(df[cols2Scale], method='yeo-johnson')","metadata":{"id":"KnDZlao5_jQN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plotting the distribution of a variable- After Correcting Skweness Issue","metadata":{}},{"cell_type":"code","source":"# Re-plot the histogram of a variable from the dataset to see the skewness\n#Distribution of the data\nstart=timer()\n\nplt.figure(figsize=(20,8))\ni=1\nfor col in df.columns[1:30]:\n    plt.subplot(3,11,i)\n    sns.distplot(df[col])\n    i+=1\nplt.tight_layout()\n\nend = timer()\nprint(\"Duration \",end - start) ","metadata":{"id":"bbrNhQbm8KSs","outputId":"017b35a8-9f25-4f15-a772-a1354a177a2d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Re-Check Coorelation Between Different Variables\ndf_corr = df.corr()\nplt.figure(figsize=(16,8))\nsns.heatmap(round(df_corr,1), annot=True, cbar=False, cmap=\"YlGnBu\", ) # Displaying the Heatmap\n#sns.set(font_scale=.5,style='white')\n\nplt.title('Heatmap correlation')\nplt.show()\n\n#After scaling and normalising variable looks there is some kind of relationship between different fields.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check the outliers after fixing skewness & scale issue","metadata":{}},{"cell_type":"code","source":"#Distribution of data acrros 2 Classes\nstart=timer()\n\ncolor = sns.color_palette(\"Set1\", 6)\nplt.figure(figsize=(20,20))\ni=1\n\nfor col in df.columns:\n    plt.subplot(8,4,i)\n    ax=sns.boxplot(x=df['Class'],y=df[col],  palette=color)\n    \n    for p in ax.patches:\n        ax.annotate(format(p.get_height(), '.2f'), \n                (p.get_x() + p.get_width() / 2.,\n                 p.get_height()), ha = 'center', va = 'center', \n                fontsize=8,\n                xytext = (0, 10), textcoords = 'offset points')\n    i+=1\nplt.tight_layout()\n\nend = timer()\nprint(\"Duration \",end - start)\n\n#Now dataset looks quite balance for fraud and non-fraud transaction. \n#Almost same ratio of IQR width, and almost same median value for fraud/non-fraud for each varaible.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <font color=blue> Section 2: Splitting the data into Train & Test","metadata":{"id":"v_qVOkcV8KSv"}},{"cell_type":"code","source":"def split_data_normal(df):\n    X= df.drop(columns=[\"Class\"], axis=0)\n    y= df.Class #class variable\n\n    X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y,stratify=y, test_size=0.25, random_state=100)\n    return (X_train1, X_test1, y_train1, y_test1)\n\ndef split_data_ros(X_train1, X_test1, y_train1, y_test1):\n    #Oversample the fraud transaction data using RandomOverSampler Method\n    ros = over_sampling.RandomOverSampler(random_state=100)\n    X_train_ros, y_train_ros       = ros.fit_resample(X_train1, y_train1)\n    X_test_ros,  y_test_ros        = (X_test1, y_test1)\n    return (X_train_ros, X_test_ros, y_train_ros, y_test_ros)\n\ndef split_data_smote(X_train1, X_test1, y_train1, y_test1):\n    #OverSample the fraud transaction data using Smoth method\n    smt = over_sampling.SMOTE(random_state=100)\n    X_train_smote, y_train_smote   = smt.fit_resample(X_train1, y_train1)\n    X_test_smote,  y_test_smote    = (X_test1, y_test1)\n    return (X_train_smote, X_test_smote, y_train_smote, y_test_smote)\n\ndef split_data_adasyn(X_train1, X_test1, y_train1, y_test1):\n    #OverSample the fraud transaction data using AdaSyn\n    ada = over_sampling.ADASYN(random_state=100)\n    X_train_adasyn, y_train_adasyn = ada.fit_resample(X_train1, y_train1)\n    X_test_adasyn,  y_test_adasyn  = (X_test1, y_test1)\n    return (X_train_adasyn, X_test_adasyn, y_train_adasyn, y_test_adasyn)","metadata":{"id":"VrcH1oyo8KSy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train1, X_test1, y_train1, y_test1  = split_data_normal(df)\nX_train_ros, X_test_ros, y_train_ros, y_test_ros              = split_data_ros(X_train1, X_test1, y_train1, y_test1)\nX_train_smote, X_test_smote, y_train_smote, y_test_smote      = split_data_smote(X_train1, X_test1, y_train1, y_test1)\nX_train_adasyn, X_test_adasyn, y_train_adasyn, y_test_adasyn  = split_data_adasyn(X_train1, X_test1, y_train1, y_test1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train1.value_counts(), y_test1.value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <font color=blue>Section 3: Visuzalise Results of Various Oversampling Methods</font>","metadata":{}},{"cell_type":"markdown","source":"### Random Oversampling","metadata":{"id":"T6NTb7jG_jQ3"}},{"cell_type":"code","source":"X_train_ros_1 = X_train_ros[X_train1.shape[0]:]\n\nX_train_1 = X_train1.to_numpy()[np.where(y_train1==1.0)]\nX_train_0 = X_train1.to_numpy()[np.where(y_train1==0.0)]\n\nplt.rcParams['figure.figsize'] = [20, 10]\nfig = plt.figure()\n\nplt.subplot(1, 3, 1)\nplt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\nplt.legend()\n\nplt.subplot(1, 3, 2)\nplt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\nplt.scatter(X_train_ros_1.iloc[:X_train_1.shape[0], 0], \n            X_train_ros_1.iloc[:X_train_1.shape[0], 1],\n            label='Artificial ROS Class-1 Examples')\nplt.legend()\n\nplt.subplot(1, 3, 3)\nplt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\nplt.scatter(X_train_0[:X_train_1.shape[0], 0], \n            X_train_0[:X_train_1.shape[0], 1], label='Actual Class-0 Examples')\nplt.legend()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### SMOTE : Synthetic Minority Over-sampling Technique","metadata":{"id":"DE8-AKFN_jQ8"}},{"cell_type":"code","source":"X_train_smote_1 = X_train_smote[X_train1.shape[0]:]\n\nX_train_1 = X_train1.to_numpy()[np.where(y_train1==1.0)]\nX_train_0 = X_train1.to_numpy()[np.where(y_train1==0.0)]\n\n\nplt.rcParams['figure.figsize'] = [20, 10]\nfig = plt.figure()\n\nplt.subplot(1, 3, 1)\nplt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\nplt.legend()\n\nplt.subplot(1, 3, 2)\nplt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\nplt.scatter(X_train_smote_1.iloc[:X_train_1.shape[0], 0], \n            X_train_smote_1.iloc[:X_train_1.shape[0], 1],\n            label='Artificial SMOTE Class-1 Examples')\nplt.legend()\n\nplt.subplot(1, 3, 3)\nplt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\nplt.scatter(X_train_0[:X_train_1.shape[0], 0], X_train_0[:X_train_1.shape[0], 1], label='Actual Class-0 Examples')\nplt.legend()","metadata":{"id":"0yyBqspJ_jQ-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ADASYN : Adaptive Synthetic Sampling Method","metadata":{"id":"R3bgREWt_jRH"}},{"cell_type":"code","source":"X_train_adasyn_1 = X_train_adasyn[X_train1.shape[0]:]\n\nX_train_1 = X_train1.to_numpy()[np.where(y_train1==1.0)]\nX_train_0 = X_train1.to_numpy()[np.where(y_train1==0.0)]\n\nplt.rcParams['figure.figsize'] = [20, 10]\nfig = plt.figure()\n\nplt.subplot(1, 3, 1)\nplt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\nplt.legend()\n\nplt.subplot(1, 3, 2)\nplt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\nplt.scatter(X_train_adasyn_1.iloc[:X_train_1.shape[0], 0], \n            X_train_adasyn_1.iloc[:X_train_1.shape[0], 1],\n            label='Artificial ADASYN Class-1 Examples')\nplt.legend()\n\nplt.subplot(1, 3, 3)\nplt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\nplt.scatter(X_train_0[:X_train_1.shape[0], 0], X_train_0[:X_train_1.shape[0], 1], label='Actual Class-0 Examples')\nplt.legend()","metadata":{"id":"ZOPb5MQU_jRI","scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <font color=blue> Section 4: Select the Dataset Imbalancing Method</font>","metadata":{}},{"cell_type":"code","source":"model_with_data_list=['Normal','RandomOverSampler','Smote','AdaSyn']\ndef select_dataset(option=-1):\n    if option==0:\n        X_train, X_test, y_train, y_test = X_train1, X_test1, y_train1, y_test1\n    elif option==1:\n        X_train, X_test, y_train, y_test = X_train_ros, X_test_ros, y_train_ros , y_test_ros\n    elif option==2:\n        X_train, X_test, y_train, y_test = X_train_smote, X_test_smote, y_train_smote , y_test_smote\n    elif option==3:\n        X_train, X_test, y_train, y_test = X_train_adasyn, X_test_adasyn, y_train_adasyn , y_test_adasyn\n\n\n    print (\"\\n\\nRunning Model with **\",model_with_data_list[option],\"Data\")\n    \n    print('Transaction Records in Train',len(y_train))\n    print('Transaction Records in Test',len(y_test))\n    print('Total Fraud Transaction Records',np.sum(y_train) + np.sum(y_test))\n    print('Fraud Transaction Records in Train',np.sum(y_train))\n    print('Fraud Transaction Records in Test',np.sum(y_test))\n    \n    return (X_train, X_test, y_train, y_test)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <font color=blue> Section 5: Helper Functions for Model Building </font>","metadata":{"id":"raw1_hNl_jQV"}},{"cell_type":"code","source":"# Plotting cv results\ndef draw_cv_results(cv_df, param_name, metric_name, title_name, log_true):\n    plt.figure(figsize=(10,4))\n    \n    if log_true:\n        x_axis= np.log10( list(cv_df[param_name]))\n        x_axis_title = \"Log Value \"+param_name\n    else:\n        x_axis = list(cv_df[param_name])\n        x_axis_title = param_name\n        \n    plt.plot( x_axis, cv_df['mean_train_score'] )\n    plt.plot( x_axis, cv_df['mean_test_score'] )\n    plt.xlabel(x_axis_title)\n    plt.ylabel(metric_name)\n    plt.title(title_name)\n    plt.legend(['Train ' + metric_name +' score', 'Test ' +metric_name+' score'], loc='upper left')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to plot the confusion Matrix\ndef draw_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.tab10):\n    \n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title, fontsize=20)\n   \n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=0, fontsize=20)\n    plt.yticks(tick_marks, classes, fontsize=20)\n\n    fmt = 'd' \n    thresh = cm.max() / 2.\n    \n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.fill(j,i,facecolor=\"red\" if cm[i, j] < thresh else \"blue\", edgecolor='b', linewidth=2)\n        #plt.Rectangle((0, 0), 1, 0, linewidth=1, edgecolor='b', facecolor='none')\n        \n        plt.text(j, i, format(cm[i, j], fmt), fontsize=20, weight=\"bold\", \n                 verticalalignment='center',\n                 horizontalalignment=\"center\",\n                 color=\"white\", \n                 \n                bbox=dict(facecolor='red', alpha=0.8))\n\n    plt.tight_layout()\n    plt.ylabel('True label',fontsize=18)\n    plt.xlabel('Predicted label', fontsize=18)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names=[0,1]\ndef draw_roc( actual, probs, prob_values=True, Threshold_limit=0.5 ):\n  \n    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n                                          drop_intermediate = False )\n    \n    threshold = thresholds[np.argmax(tpr-fpr)]\n\n    if prob_values:\n        pred= probs.map(lambda x: 1 if x > threshold else 0)\n    else:\n        pred= probs\n        \n    auc_score = round( metrics.roc_auc_score( actual, probs) ,2)\n    \n    recall    = round( metrics.recall_score(actual,pred),2)\n    precision = round(metrics.precision_score(actual, pred),2)\n    f1= round(metrics.f1_score(actual,pred),2)\n    print (\"This Model Result is for \", model_with_data_list[option], \" Data\")\n    print (\"ROC AUC Score on Test:\",auc_score,\" Threshold:{:.5f}\".format(threshold))\n\n    plt.figure(figsize=(20, 5))\n    plt.subplot(1,2,1)\n    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate or [1 - True Negative Rate]',fontsize=16)\n    plt.ylabel('True Positive Rate', fontsize=16)\n    plt.title('Receiver operating characteristic example',fontsize=20)\n    plt.legend(loc=\"lower right\")\n    \n    plt.subplot(1,2,2)\n    cm = confusion_matrix(actual, pred)\n    draw_confusion_matrix(cm,class_names)\n    plt.show()\n\n    return auc_score,recall,precision,f1","metadata":{"id":"bXj539qw8KTA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <font color=blue> Section 6: Model Building </font>","metadata":{}},{"cell_type":"markdown","source":"### Model 1: Logistic Regression","metadata":{"id":"Z65LCb3t8KTC"}},{"cell_type":"code","source":"# Cross validation using different values of C. Let's check which value of C gives best result\ndef logistic_cv():\n    start=timer()\n    if run_cv:\n        hyper_params = [{'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }]\n\n        lr = LogisticRegression(max_iter=1000, random_state=100)\n        lr.fit(X_train, y_train)      \n\n        model_cv_logistic = GridSearchCV(estimator=lr, param_grid=hyper_params, \\\n                                cv=folds, scoring=\"roc_auc\", return_train_score=True, verbose=True)\n        model_cv_logistic.fit(X_train,  y_train)\n\n        cv_results_lr = pd.DataFrame(model_cv_logistic.cv_results_)\n        print(cv_results_lr)\n\n    end = timer()\n    print(\"Duration \",end - start)\n    \n    if run_cv:\n        draw_cv_results(cv_results_lr, 'param_C', 'ROC AUC', 'Optimal C', True)\n        \n    if run_cv:\n        model_cv_logistic.best_estimator_","metadata":{"id":"CXyos4d68KTH","outputId":"df8c6bd1-3327-4579-facf-61d9c1cb77ca"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#There are 29 variables in X_train. Let's see can we manage good result with lessor variables.\ndef logistic_with_rfe():\n    if option==0 or option==1:\n        lr = LogisticRegression(C=.1,max_iter=1000, random_state=100) \n        #Value of C & max_iter from earlier steps #for normal\n    elif option==2:\n        lr = LogisticRegression(C=10,max_iter=1000, random_state=100) \n        #Value of C & max_iter from earlier steps #for smote\n    else:\n        lr = LogisticRegression(C=100,max_iter=1000, random_state=100) \n        #Value of C & max_iter from earlier steps #for adasyn\n    rfe = RFE(lr,15) #Identify top 15 important variables\n    rfe.fit(X_train,y_train)\n    useful_cols = X_train.columns[rfe.support_]\n    #print (\"Useful Columns: \" ,useful_cols)\n    \n    #check the ranking of these variables\n    print('Important Variables Identified in RFE')\n    print(list(zip(X_train.columns, rfe.support_, rfe.ranking_)))\n    return useful_cols","metadata":{"id":"CFELWhCX8KTS","outputId":"4becdbfe-9ea7-4658-f9cd-83d5667cc9d3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def logistic():\n    #Hyperparameter Turning of LogisticRegression\n    #Train the model with only 15 variables (identified in earlier step)\n\n    useful_cols = logistic_with_rfe()\n    X_train_= X_train[useful_cols]\n    X_test_ = X_test[useful_cols]\n    lr = LogisticRegression(C=.1,max_iter=1000, random_state=100)\n    lr.fit(X_train_,y_train)\n\n    y_test_pred_logistic = lr.predict_proba(X_test_)\n    y_test_pred_logistic = pd.DataFrame({'Class':y_test.values, 'Class_Prob':y_test_pred_logistic[:,1:2].reshape(-1) })\n\n    #check ROC_AUC Score on Test\n    logistic_auc_test, logistic_recall_test, logistic_precision_test, logistic_f1_test = \\\n                            draw_roc(y_test_pred_logistic.Class, y_test_pred_logistic.Class_Prob, True)\n    return (logistic_auc_test, logistic_recall_test, logistic_precision_test, logistic_f1_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model 2: GLM","metadata":{"id":"XyXaN2AQ8KUD"}},{"cell_type":"code","source":"def glm():\n    useful_cols = logistic_with_rfe()\n    X_train_sm = sm.add_constant(X_train[useful_cols])\n    X_test_ = X_test[useful_cols]\n    \n    glm = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n    glm = glm.fit()\n\n    X_test_sm = sm.add_constant(X_test_)\n    y_test_pred_glm = glm.predict( X_test_sm  )\n    y_test_pred_glm = pd.DataFrame({'Class':y_test.values, 'Class_Prob':y_test_pred_glm })\n\n    #check ROC_AUC Score on Test\n    glm_auc_test, glm_recall_test, glm_precision_test, glm_f1_test = \\\n                        draw_roc(y_test_pred_glm.Class, y_test_pred_glm.Class_Prob)\n    \n    print (glm.summary())\n    return (glm_auc_test, glm_recall_test, glm_precision_test, glm_f1_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model 3: KNeighborsClassifier","metadata":{"id":"VvH2hq148KUE"}},{"cell_type":"code","source":"# Cross validation using different values of n_neighbors.\ndef knn_cv():\n    start=timer()\n\n    if run_cv:\n        hyper_params = [{'n_neighbors': range(2,15,2) }]\n        knn = KNeighborsClassifier()\n        model_cv_knn = GridSearchCV(estimator=knn, param_grid=hyper_params, \\\n                                cv=folds, scoring=\"roc_auc\", return_train_score=True, verbose=True)\n        model_cv_knn.fit(X_train,  y_train)\n\n        cv_results_knn = pd.DataFrame(model_cv_knn.cv_results_)\n        print(cv_results_knn.sort_values('rank_test_score'))\n\n    end = timer()\n    print(\"Duration \",end - start)\n    \n    if run_cv:\n        draw_cv_results(cv_results_knn, 'param_n_neighbors', 'ROC AUC', 'Optimal n_neighbours', False)\n    \n    if run_cv:\n        print(model_cv_knn.best_estimator_)","metadata":{"id":"o697Ba1e8KUF","outputId":"a8b42d1d-af4e-49c5-9cee-7bbe69a5d9fd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Hyperparameter Turning of KNeighborsClassifier\ndef knn():\n    knn = KNeighborsClassifier(n_neighbors = 4, leaf_size=30, p=2)\n    knn.fit(X_train, y_train)\n    y_test_pred_knn = knn.predict_proba(X_test)\n\n    y_test_pred_knn = pd.DataFrame({'Class':y_test.values, 'Class_Prob':y_test_pred_knn[:,1:2].reshape(-1) })\n\n\n    knn_auc_test, knn_recall_test, knn_precision_test,knn_f1_test = \\\n                            draw_roc(y_test_pred_knn.Class, y_test_pred_knn.Class_Prob)\n    \n    return (knn_auc_test, knn_recall_test, knn_precision_test,knn_f1_test)\n","metadata":{"id":"2uNeOVtZ8KUG","outputId":"963c328a-43eb-4687-ab2f-9d97a7035f5c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model 4: RandomForestClassifier","metadata":{"id":"Oz4jr6ay8KUI"}},{"cell_type":"code","source":"# Cross validation using different values of C. Let's check which value of C gives best result\ndef rfc_cv():\n    start=timer()\n    if run_cv:\n        hyper_params=[{'n_estimators':range(4,20,2),'max_depth':range(8,25,2)}]\n\n        rfc = RandomForestClassifier()\n        model_cv_rfc = GridSearchCV(estimator=rfc, param_grid=hyper_params, \\\n                                cv=folds, scoring=\"roc_auc\", return_train_score=True, verbose=True)\n        model_cv_rfc.fit(X_train,  y_train)\n\n        cv_results_rfc = pd.DataFrame(model_cv_rfc.cv_results_)\n        print(cv_results_rfc.sort_values('rank_test_score'))\n\n    end = timer()\n    print(\"Duration \",end - start)\n    \n    if run_cv:\n        cv_results_rfc.param_max_depth = cv_results_rfc.param_max_depth.astype(\"float\")\n        plt.figure(figsize=(20,4))\n        plt.subplot(1,2,1)\n        ax1=sns.lineplot(x='param_n_estimators',  y='mean_test_score', hue='param_max_depth', data=cv_results_rfc)\n        ax1.set_title(\"Test AUC Score\")\n        plt.subplot(1,2,2)\n        ax2= sns.lineplot(x='param_n_estimators', y='mean_train_score', hue='param_max_depth',data=cv_results_rfc, ci=0)\n        ax2.set_title(\"Train AUC Score\")\n        plt.show()\n        \n    if run_cv:\n        print(model_cv_rfc.best_estimator_)","metadata":{"id":"3NQKj2oQ8KUJ","outputId":"ee63863a-3e0d-4d79-fb0c-af17f78f8d77"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Optimised Hyper Parameters\ndef rfc():\n    rfc= RandomForestClassifier(n_estimators=16, criterion=\"gini\", max_depth=6, random_state=100)\n    rfc.fit(X_train,y_train)\n    y_test_pred_rfc = rfc.predict_proba(X_test)[:,1:2]\n\n    y_test_pred_rfc = pd.DataFrame({'Class':y_test.values, 'Class_Prob':y_test_pred_rfc.reshape(-1) })\n\n    rfc_auc_test, rfc_recall_test, rfc_precision_test, rfc_f1_test = \\\n                            draw_roc(y_test_pred_rfc.Class, y_test_pred_rfc.Class_Prob)\n    return (rfc_auc_test, rfc_recall_test, rfc_precision_test, rfc_f1_test)","metadata":{"id":"lkoQVZZh8KUP","outputId":"333b24dc-107e-4609-c150-730c355485e3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model 5: DecisionTreeClassifier","metadata":{"id":"QFPr4pxz8KUR"}},{"cell_type":"code","source":"","metadata":{"id":"GPzNto-tKhVU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cross validation using different values of C. Let's check which value of C gives best result\ndef dtc_cv():\n    start=timer()\n\n    if run_cv:\n        hyper_params=[{'max_depth': range(10,20,2),\n                   'min_samples_leaf': range(1, 5, 1),\n                   'min_samples_split': range(1, 5, 1) }]\n\n        dtc = DecisionTreeClassifier(random_state=100)\n        model_cv_dtc = GridSearchCV(estimator=dtc, param_grid=hyper_params,\n                                cv=folds, scoring=\"roc_auc\", return_train_score=True, verbose=True)\n        model_cv_dtc.fit(X_train,  y_train)\n\n        cv_results_dtc = pd.DataFrame(model_cv_dtc.cv_results_)\n        print(cv_results_dtc.sort_values('rank_test_score'))\n\n    end = timer()\n    print(\"Duration \",end - start)\n    \n    if run_cv:\n        cv_results_dtc.param_max_depth = cv_results_dtc.param_max_depth.astype(\"float\")\n\n        plt.figure(figsize=(20,4))\n        plt.subplot(1,4,1)\n        ax1=sns.lineplot(x='param_min_samples_leaf', y='mean_test_score', hue='param_max_depth',data=cv_results_dtc, ci=0)\n        ax1.set_title(\"Test AUC Score\")\n        plt.subplot(1,4,2)\n        ax2= sns.lineplot(x='param_min_samples_leaf', y='mean_train_score', hue='param_max_depth',data=cv_results_dtc, ci=0)\n        ax2.set_title(\"Train AUC Score\")\n\n        plt.subplot(1,4,3)\n        ax1=sns.lineplot(x='param_min_samples_split', y='mean_test_score', hue='param_max_depth',data=cv_results_dtc, ci=0)\n        ax1.set_title(\"Test AUC Score\")\n        plt.subplot(1,4,4)\n        ax2= sns.lineplot(x='param_min_samples_split', y='mean_train_score', hue='param_max_depth',data=cv_results_dtc, ci=0)\n        ax2.set_title(\"Train AUC Score\")\n        plt.show()\n    \n    if run_cv:\n        print(model_cv_dtc.best_estimator_)","metadata":{"id":"qTrgYstT8KUS","outputId":"3a29145e-cf94-4674-89a2-114acf88c87e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Optimised Hyper Parameters\ndef dtc():\n    dtc= DecisionTreeClassifier(max_depth=16, min_samples_leaf=1, min_samples_split=2, random_state=100)\n\n    dtc.fit(X_train,y_train)\n    y_test_pred_dtc = dtc.predict_proba(X_test)[:,1:2]\n\n    y_test_pred_dtc = pd.DataFrame({'Class':y_test.values, 'Class_Prob':y_test_pred_dtc.reshape(-1) })\n\n    dtc_auc_test, dtc_recall_test, dtc_precision_test, dtc_f1_test = \\\n                        draw_roc(y_test_pred_dtc.Class, y_test_pred_dtc.Class_Prob, True)\n    return (dtc_auc_test, dtc_recall_test, dtc_precision_test, dtc_f1_test)\n","metadata":{"id":"1E5H8DywZD5M","outputId":"bdd609cf-ce3b-40c0-bddd-20893cb1f7ac"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model 6: LGBM","metadata":{}},{"cell_type":"code","source":"# Cross validation using different values of n_estimators.\ndef lgbm_cv():\n    start=timer()\n    if run_cv:\n        hyper_params=[{  'n_estimators': range(10,110,10)  }]\n\n        lgbm_clf = lgbmc.LGBMClassifier(random_state=100)\n        model_cv_lgbm = GridSearchCV(estimator=lgbm_clf, param_grid=hyper_params,\n                                cv=folds, scoring=\"roc_auc\", return_train_score=True, verbose=True)\n        model_cv_lgbm.fit(X_train,  y_train)\n\n        cv_results_lbgm = pd.DataFrame(model_cv_lgbm.cv_results_)\n        cv_results_lbgm.sort_values('rank_test_score')\n\n    end = timer()\n    print(\"Duration \",end - start)\n    \n    if run_cv:\n        draw_cv_results(cv_results_lbgm, 'param_n_estimators', 'ROC AUC', 'Optimal n_estimator', False)\n    if run_cv:\n        print(model_cv_lgbm.best_estimator_)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Optimized Hyper Paramters.\ndef lgbm():\n    lgbm_clf = lgbmc.LGBMClassifier(n_estimators=100, random_state = 42)\n\n    lgbm_clf.fit(X_train,y_train)\n    y_test_pred_lgbm = lgbm_clf.predict_proba(X_test)[:,1:2]\n\n    y_test_pred_lgbm = pd.DataFrame({'Class':y_test.values, 'Class_Prob':y_test_pred_lgbm.reshape(-1) })\n\n    lgbm_auc_test, lgbm_recall_test, lgbm_precision_test, lgbm_f1_test = \\\n                        draw_roc(y_test_pred_lgbm.Class, y_test_pred_lgbm.Class_Prob,True,.5)\n    return (lgbm_auc_test, lgbm_recall_test, lgbm_precision_test, lgbm_f1_test)","metadata":{"id":"y-XvtIIohIVq","outputId":"77f422d0-0daf-4943-ec56-f03da37a0b07"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model 7: Perceptron","metadata":{}},{"cell_type":"code","source":"# Cross validation using different values of n_iter_no_change\ndef perceptron_cv():\n    start=timer()\n    if run_cv:\n        hyper_params=[{'n_iter_no_change': [ 5,6,7,8,9] }]\n\n        percept = Perceptron(random_state = 42)\n        model_cv_percept = GridSearchCV(estimator=percept, param_grid=hyper_params,\n                                cv=folds, scoring=\"roc_auc\", return_train_score=True, verbose=True)\n        model_cv_percept.fit(X_train,  y_train)\n\n        cv_results_percept = pd.DataFrame(model_cv_percept.cv_results_)\n        cv_results_percept.sort_values('rank_test_score')\n\n    end = timer()\n    print(\"Duration \",end - start)\n    \n    if run_cv:\n        draw_cv_results(cv_results_percept, 'param_n_iter_no_change', 'ROC AUC', 'Optimal n_estimator', False)\n    if run_cv:\n        print(model_cv_percept.best_estimator_)","metadata":{"id":"rlpJ8WY0kQ6F","outputId":"45935881-d9ff-4105-a6ba-ad80fa4780e6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Optmized Hyper Parameter\ndef perceptron():\n    percept = Perceptron(alpha=.00001,n_iter_no_change=7,random_state = 42, penalty=\"l2\")\n\n    percept.fit(X_train,y_train)\n    y_test_pred_percept = percept.predict(X_test)#[:,1:2]\n\n    y_test_pred_percept = pd.DataFrame({'Class':y_test.values, 'Class_Prob':y_test_pred_percept.reshape(-1) })\n\n    percept_auc_test, percept_recall_test, percept_precision_test, percept_f1_test = \\\n                            draw_roc(y_test_pred_percept.Class, y_test_pred_percept.Class_Prob, False)\n    \n    return (percept_auc_test, percept_recall_test, percept_precision_test, percept_f1_test)","metadata":{"id":"CYmEPMzC8KUV","outputId":"01c0d1cc-8292-492b-fe11-1cecec0ee669"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model 8: SVC","metadata":{"id":"rI_UWtSn_jQa"}},{"cell_type":"code","source":"#hyper_params=[{'C': range(1,30,1) }]\ndef svc_cv():\n    start=timer()\n    if run_cv:\n        hyper_params=[{'C': range(10,30,2) }]\n\n        svmc = SVC(random_state = 100)\n        model_cv_svm = GridSearchCV(estimator=svmc, param_grid=hyper_params,\n                                cv=folds, scoring=\"roc_auc\", return_train_score=True, verbose=True)\n        model_cv_svm.fit(X_train,  y_train)\n\n        cv_results_svm = pd.DataFrame(model_cv_svm.cv_results_)\n        cv_results_svm.sort_values('rank_test_score')\n\n    end = timer()\n    print(\"Duration \",end - start)\n    \n    if run_cv:\n        draw_cv_results(cv_results_svm, 'param_C', 'ROC AUC', 'Optimal n_estimator', False)\n        \n    if run_cv:\n        print(model_cv_svm.best_estimator_)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Optimized Hyper Parameters\ndef svc():\n    svmc = SVC(C=20.0,random_state=100, probability=True).fit(X_train,y_train)\n    y_test_pred_svm = svmc.predict(X_test)\n    y_test_pred_svm = svmc.predict_proba(X_test)[:,1:2]\n    y_test_pred_svm = pd.DataFrame({'Class':y_test.values, 'Class_Prob':y_test_pred_svm.reshape(-1) })\n\n    svm_auc_test, svm_recall_test, svm_precision_test, svm_f1_test = \\\n                        draw_roc(y_test_pred_svm.Class, y_test_pred_svm.Class_Prob, True)\n    \n    return (svm_auc_test, svm_recall_test, svm_precision_test, svm_f1_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model 9: XGBoost","metadata":{"id":"4IeBeD3h_jQb"}},{"cell_type":"code","source":"#Cross Validation\ndef xgb_cv():\n    start=timer()\n    if run_cv:\n        hyper_params=[{'max_depth': range(10,15,1), 'n_estimators': range(95,120,2) }]\n\n        xgb_clf = xgb(random_state = 100)\n        model_cv_xgb = GridSearchCV(estimator=xgb_clf, param_grid=hyper_params,\n                                cv=folds, scoring=\"roc_auc\", return_train_score=True, verbose=True)\n        model_cv_xgb.fit(X_train,  y_train)\n\n        cv_results_xgb = pd.DataFrame(model_cv_xgb.cv_results_)\n        cv_results_xgb.sort_values('rank_test_score')\n\n    end = timer()\n    print(\"Duration \",end - start)\n    \n    if run_cv:\n        cv_results_xgb.param_max_depth = cv_results_xgb.param_max_depth.astype(\"float\")\n        cv_results_xgb.param_n_estimators = cv_results_xgb.param_n_estimators.astype(\"float\")\n        plt.figure(figsize=(20,4))\n        plt.subplot(1,2,1)\n        ax1=sns.lineplot(x='param_n_estimators',  y='mean_test_score', hue='param_max_depth', data=cv_results_xgb)\n        ax1.set_title(\"Test AUC Score\")\n        plt.subplot(1,2,2)\n        ax2= sns.lineplot(x='param_n_estimators',  y='mean_train_score', hue='param_max_depth',data=cv_results_xgb)\n        ax2.set_title(\"Train AUC Score\")\n        plt.show()\n\n    if run_cv:\n        print(model_cv_xgb.best_estimator_)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Optimized Hyper Parameters\ndef xgb():\n    xgb_clf = xgbc(max_depth=10, n_estimators=95, learning_rate=.01,random_state=100).fit(X_train,y_train)\n    y_test_pred_xgb = xgb_clf.predict_proba(X_test)[:,1:2]\n    y_test_pred_xgb = pd.DataFrame({'Class':y_test.values, 'Class_Prob':y_test_pred_xgb.reshape(-1) })\n\n    xgb_auc_test, xgb_recall_test, xgb_precision_test, xgb_f1_test = \\\n                        draw_roc(y_test_pred_xgb.Class, y_test_pred_xgb.Class_Prob, True)\n    \n    return (xgb_auc_test, xgb_recall_test, xgb_precision_test, xgb_f1_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model 10: Adaboost","metadata":{}},{"cell_type":"code","source":"#Cross Validation\ndef adaboost_cv():\n    sart=timer()\n    if run_cv:\n        hyper_params=[{'learning_rate': range(1,5,1), 'n_estimators': range(40,71,10) }]\n\n        adbc = AdaBoostClassifier(random_state = 100)\n        model_cv_adbc = GridSearchCV(estimator=adbc, param_grid=hyper_params,\n                                cv=folds, scoring=\"roc_auc\", return_train_score=True, verbose=True)\n        model_cv_adbc.fit(X_train,  y_train)\n\n        cv_results_adbc = pd.DataFrame(model_cv_adbc.cv_results_)\n        print(cv_results_adbc.sort_values('rank_test_score'))\n\n    end = timer()\n    print(\"Duration \",end - start)\n    \n    if run_cv:\n        plt.figure(figsize=(20,4))\n        plt.subplot(1,2,1)\n        cv_results_adbc.param_n_estimators = cv_results_adbc.param_n_estimators.astype(\"float\")\n        cv_results_adbc.param_learning_rate = cv_results_adbc.param_learning_rate.astype(\"float\")\n\n        ax1=sns.lineplot(x='param_n_estimators',  y='mean_test_score', hue='param_learning_rate', data=cv_results_adbc)\n        ax1.set_title(\"Test AUC Score\")\n        plt.subplot(1,2,2)\n        ax2= sns.lineplot(x='param_n_estimators',  y='mean_train_score', hue='param_learning_rate',data=cv_results_adbc)\n        ax2.set_title(\"Train AUC Score\")\n        plt.show()\n\n    if run_cv:\n        print(model_cv_adbc.best_estimator_)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def adaboost():\n    # Optimized Hyper Parameters\n    adbc = AdaBoostClassifier(learning_rate=1,random_state=100)\n    adbc.fit(X_train,y_train)\n\n    y_test_pred_adbc = adbc.predict_proba(X_test)[:,1:2]\n    y_test_pred_adbc = pd.DataFrame({'Class':y_test.values, 'Class_Prob':y_test_pred_adbc.reshape(-1) })\n\n    adbc_auc_test, adbc_recall_test, adbc_precision_test, adbc_f1_test = \\\n                        draw_roc(y_test_pred_adbc.Class, y_test_pred_adbc.Class_Prob,True,.5)\n    \n    return (adbc_auc_test, adbc_recall_test, adbc_precision_test, adbc_f1_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model 11: CatboostClassifier","metadata":{}},{"cell_type":"code","source":"# Optimized Hyper Parameters\ndef catboost():\n    catb_clf = CatBoostClassifier(learning_rate=1,random_state=100)\n    catb_clf.fit(X_train,y_train, verbose=False)\n\n    y_test_pred_catbc = catb_clf.predict_proba(X_test)[:,1:2]\n    y_test_pred_catbc = pd.DataFrame({'Class':y_test.values, 'Class_Prob':y_test_pred_catbc.reshape(-1) })\n\n    catbc_auc_test, catbc_recall_test, catbc_precision_test, catbc_f1_test = \\\n                        draw_roc(y_test_pred_catbc.Class, y_test_pred_catbc.Class_Prob,True,.5)\n    \n    return (catbc_auc_test, catbc_recall_test, catbc_precision_test, catbc_f1_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model 12: Naive Bayes","metadata":{}},{"cell_type":"code","source":"### Naive Bayes\ndef naiveb():\n    gnb = GaussianNB() \n    gnb.fit(X_train, y_train) \n\n    y_test_pred_gnb = gnb.predict_proba(X_test)[:,1:2]\n    y_test_pred_gnb = pd.DataFrame({'Class':y_test.values, 'Class_Prob':y_test_pred_gnb.reshape(-1) })\n\n    gnb_auc_test, gnb_recall_test, gnb_precision_test, gnb_f1_test = \\\n                        draw_roc(y_test_pred_gnb.Class, y_test_pred_gnb.Class_Prob,True)\n    \n    return ( gnb_auc_test, gnb_recall_test, gnb_precision_test, gnb_f1_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model 13: Stochastic Gradient Descent Classifier","metadata":{}},{"cell_type":"code","source":"#Cross Validation\ndef sgdc_cv():\n    start=timer()\n    if run_cv:\n        hyper_params = [{ 'alpha': [10 ** x for x in range(-3, 1)],\n                        'l1_ratio': [0, 0.05, 0.1, 0.2, 0.5, 0.9, 0.95, 1] }]\n        sgd = SGDClassifier(random_state=100, class_weight='balanced',\\\n                            loss='hinge', penalty='elasticnet')\n\n        model_cv_sgd = GridSearchCV(estimator=sgd, param_grid=hyper_params,\n                                cv=folds, scoring=\"roc_auc\", return_train_score=True, verbose=True)\n        model_cv_sgd.fit(X_train,  y_train)\n\n        cv_results_sgd = pd.DataFrame(model_cv_sgd.cv_results_)\n        cv_results_sgd.sort_values('rank_test_score')\n\n    end = timer()\n    print(\"Duration \",end - start)\n\n    if run_cv:\n        print(model_cv_sgd.best_estimator_)\n\n    #draw_cv_results(cv_results_sgd, 'param_alpha', 'Recall', 'Optimal Alpha', False)\n    if run_cv:\n        cv_results_sgd.param_l1_ratio = cv_results_sgd.param_l1_ratio.astype(\"float\")\n        cv_results_sgd.param_alpha = cv_results_sgd.param_alpha.astype(\"float\")\n\n        plt.figure(figsize=(20,4))\n        plt.subplot(1,2,1)\n        ax1=sns.lineplot(x= np.log(cv_results_sgd['param_alpha']), y='mean_test_score', hue='param_l1_ratio',data=cv_results_sgd)\n        ax1.set_xlabel=\"Log Param_Alpha\"\n        ax1.set_title(\"Test AUC Score\")\n        plt.subplot(1,2,2)\n        ax2= sns.lineplot(x=np.log(cv_results_sgd['param_alpha']), y='mean_train_score', hue='param_l1_ratio',data=cv_results_sgd)\n        ax2.set_xlabel=\"Log Param_Alpha\"\n        ax2.set_title(\"Train AUC Score\")\n        plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Hyperparamter Tuning\ndef sgdc():\n    sgd = SGDClassifier(max_iter=1000, alpha=0.0001, l1_ratio=0.2, random_state=100, penalty=\"elasticnet\", \\\n                        class_weight='balanced',loss='hinge', )\n\n    sgd.fit(X_train, y_train) \n\n    y_test_pred_sgd = sgd.predict(X_test) #[:,1:2]\n    y_test_pred_sgd = pd.DataFrame({'Class':y_test.values, 'Class_Prob':y_test_pred_sgd  }) #.reshape(-1)\n\n    sgd_auc_test, sgd_recall_test, sgd_precision_test, sgd_f1_test = \\\n                        draw_roc(y_test_pred_sgd.Class, y_test_pred_sgd.Class_Prob,False)\n    \n    return (sgd_auc_test, sgd_recall_test, sgd_precision_test, sgd_f1_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model 14:  Dense Neural Network","metadata":{}},{"cell_type":"code","source":"def create_dnn(indput_dim, dropout=0.2):\n    model = Sequential([\n    Dense(units=16, input_dim=indput_dim, activation='relu'),\n    Dropout(dropout),\n    Dense(units=16, activation='relu'),\n    Dropout(dropout),\n    Dense(1, activation='sigmoid')])\n    return model\n\ndef dnn():\n    dnn = create_dnn(indput_dim=X_train.shape[1], dropout=0.2)\n    dnn.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n    dnn.fit(X_train, y_train,batch_size=100, epochs=50)\n\n    y_test_pred_dnn = dnn.predict(X_test).ravel()\n    y_test_pred_dnn = pd.DataFrame({'Class':y_test.values, 'Class_Prob':y_test_pred_dnn  }) #.reshape(-1)\n\n    dnn_auc_test, dnn_recall_test, dnn_precision_test, dnn_f1_test = \\\n                        draw_roc(y_test_pred_dnn.Class, y_test_pred_dnn.Class_Prob,True)\n    \n    return (dnn_auc_test, dnn_recall_test, dnn_precision_test, dnn_f1_test)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model 15:  Convolution Neural Network","metadata":{}},{"cell_type":"code","source":"def create_cnn(indput_dim, dropout=0.2):\n    cnn = Sequential()\n    cnn.add(Conv1D(128, kernel_size = ( 5), activation='relu', padding=\"same\",input_shape=(30, 1) ))\n    cnn.add(layers.GlobalMaxPool1D())\n    cnn.add(BatchNormalization())\n    \n    cnn.add(Dense(30,  activation='relu'))\n    cnn.add(Dense(1, activation='sigmoid'))\n    return cnn\n\ndef cnn():\n    xtrain = X_train.values.reshape(X_train.shape[0],X_train.shape[1],-1)\n    xtest  = X_test.values.reshape(X_test.shape[0],X_test.shape[1],-1)\n\n    cnn = create_cnn(indput_dim=xtrain.shape[1], dropout=0.2)\n    cnn.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n    cnn.fit(xtrain, y_train,batch_size=5000, epochs=50)\n\n    y_test_pred_cnn = cnn.predict(xtest).ravel()\n    y_test_pred_cnn = pd.DataFrame({'Class':y_test.values, 'Class_Prob':y_test_pred_cnn  }) #.reshape(-1)\n\n    cnn_auc_test, cnn_recall_test, cnn_precision_test, cnn_f1_test = \\\n                        draw_roc(y_test_pred_cnn.Class, y_test_pred_cnn.Class_Prob,True)\n    \n    return (cnn_auc_test, cnn_recall_test, cnn_precision_test, cnn_f1_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <font color=blue> Section 7: Run All Models and Save Results </font>","metadata":{}},{"cell_type":"code","source":"models_cv =['logistic','knn','rfc','dtc','lgbm','perceptron','svc','xgb','adaboost','sgdc']\nmodels =['logistic','glm','knn','rfc','dtc','lgbm','perceptron','svc','xgb','adaboost',\n         'catboost', 'naiveb', 'sgdc', 'dnn','cnn']\n\nmodels_name = ['Logistic Regression','GLM', 'KNN', 'Random Forest',  \n                      'Decision Tree', 'LGBM', 'Perceptron','SVC',\n                      'XGBoost','AdaBoost', 'CatBoost','Naive Bayes', 'SGD', \"DNN\",\"CNN\"]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Run Models\ndef run_all_models(option):\n    for model_no in range(len(models)):\n        model = models[model_no]\n        print (f\"Running Model {model}\")\n        auc_test, recall_test, precision_test, f1_test = globals()[model]()\n        results.append([options[option],models_name[model_no],auc_test, recall_test, precision_test, f1_test])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"global option, X_train, X_test, y_train, y_test\nresults=[]\noptions = ['Normal', 'RandomOverSampler', 'Smote', 'AdaSyn']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#options = ['0-Normal', '1-RandomOverSampler', '2-Smote', '3-AdaSyn']\noption=0\nX_train, X_test, y_train, y_test = select_dataset(option)\nrun_all_models(option)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#options = ['0-Normal', '1-RandomOverSampler', '2-Smote', '3-AdaSyn']\noption=1\nX_train, X_test, y_train, y_test = select_dataset(option)\nrun_all_models(option)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#options = ['0-Normal', '1-RandomOverSampler', '2-Smote', '3-AdaSyn']\noption=2\nX_train, X_test, y_train, y_test = select_dataset(option)\nrun_all_models(option)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#options = ['0-Normal', '1-RandomOverSampler', '2-Smote', '3-AdaSyn']\noption=3\nX_train, X_test, y_train, y_test = select_dataset(option)\nrun_all_models(option)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_results=pd.DataFrame(results, columns=['Data','Models','AUC','Recall','Precision','F1'])\nfinal_results","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <font color=blue> Section 8: Comparing All the Models and all Data Imbalancing Methods</font>","metadata":{}},{"cell_type":"markdown","source":"#### Mearge All Model, All Metrics Results Together","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#AUC Score\nfinal_results.sort_values('AUC',ascending=False).head(6)\n#The Best AUC score on Test data with Any model is .99 \n#AUC: The Best models are based on RF, LogR, CatBoost,SVC,GLM","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Recall Score\nfinal_results.sort_values('Recall',ascending=False).head(6) \n\n#The Best Recall score on Test data with Any model is .94.\n#Recall: The Best Models are based on RF,SGD, Perceptron","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Precision Score\nfinal_results.sort_values('Precision',ascending=False).head(6)\n#The Best Precision score on Test data with Any model is .96. \n#Precision: The Best Models is based on KNN","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#F1 Score\nfinal_results.sort_values('F1',ascending=False).head(6)\n#The Best F1 score on Test data with Any model is .93.\n#F1: The Best Models are based on KNN, SGD","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <font color=blue> Secion 9: Final Conclusion </font>","metadata":{}},{"cell_type":"code","source":"#AUC: The Best models are based on RF, LogR, CatBoost,SVC,GLM\n#Recall: The Best Models are based on RF,SGD, Perceptron\n#Precision: The Best Models is based on KNN\n#F1: The Best Models are based on KNN, SGD\n#AdpativeSyn is good oversampling technique\noption=3\nmodels_final =['logistic','knn','rfc']\nmodels_final_name = ['Logistic Regression', 'KNN', 'Random Forest']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Section 9.1 Now train the model with LGBM algo with full dataset.","metadata":{}},{"cell_type":"code","source":"#Load full dataset\ndf1 = pd.read_csv(filename)\n\ncols2Scale = list(df1.columns)\ncols2Scale.remove(\"Class\")\n\n#scale fields\nsc=StandardScaler()\nt=sc.fit_transform(df1[ cols2Scale ])\ndf1[cols2Scale] = t\ndf1.head(5)\n\n#Trasform fields\ndf1[cols2Scale] = power_transform(df1[cols2Scale], method='yeo-johnson')\n\nX= df1.drop(columns=[\"Class\"], axis=0)\ny= df1.Class #class variable\n\n#Split the data.\n#options = ['0-Normal', '1-RandomOverSampler', '2-Smote', '3-AdaSyn']\nX_train1, X_test1, y_train1, y_test1  = split_data_normal(df1)\n#X_train_ros, X_test_ros, y_train_ros, y_test_ros              = split_data_ros(X_train1, X_test1, y_train1, y_test1)\n#X_train_smote, X_test_smote, y_train_smote, y_test_smote      = split_data_smote(X_train1, X_test1, y_train1, y_test1)\nX_train_adasyn, X_test_adasyn, y_train_adasyn, y_test_adasyn  = split_data_adasyn(X_train1, X_test1, y_train1, y_test1)\n\nX_train, X_test, y_train, y_test = select_dataset(option)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Section 9.2 Develop Models using Selected Algorithm and Oversampler","metadata":{}},{"cell_type":"code","source":"auc_test, recall_test, precision_test, f1_test =logistic()\nprint (f\"AUC {auc_test}, Recall {recall_test}, Precision {precision_test}, F1 {f1_test}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"auc_test, recall_test, precision_test, f1_test =knn()\nprint (f\"AUC {auc_test}, Recall {recall_test}, Precision {precision_test}, F1 {f1_test}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"auc_test, recall_test, precision_test, f1_test =rfc()\nprint (f\"AUC {auc_test}, Recall {recall_test}, Precision {precision_test}, F1 {f1_test}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"auc_test, recall_test, precision_test, f1_test =lgbm()\nprint (f\"AUC {auc_test}, Recall {recall_test}, Precision {precision_test}, F1 {f1_test}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Print the important features of the best model to understand the dataset\n- This will not give much explanation on the already transformed dataset\n- But it will help us in understanding if the dataset is not PCA transformed","metadata":{}},{"cell_type":"code","source":"clf = KNeighborsClassifier(n_neighbors = 4, leaf_size=30, p=2)\nclf.fit(X_train, y_train)\ny_test_pred_knn = clf.predict_proba(X_test)\n\ny_test_pred_knn = pd.DataFrame({'Class':y_test.values, 'Class_Prob':y_test_pred_knn[:,1:2].reshape(-1) })\n\n\nknn_auc_test, knn_recall_test, knn_precision_test,knn_f1_test = \\\n                        draw_roc(y_test_pred_knn.Class, y_test_pred_knn.Class_Prob)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# var_imp = []\n# for i in clf.feature_importances_:\n#     var_imp.append(i)\n\n# top_var_index = var_imp.index(np.sort(clf.feature_importances_)[-1])\n# second_top_var_index = var_imp.index(np.sort(clf.feature_importances_)[-2])\n# third_top_var_index = var_imp.index(np.sort(clf.feature_importances_)[-3])\n\n# print('Top var =', var_imp.index(np.sort(clf.feature_importances_)[-1])+1, X_train.columns[top_var_index])\n# print('2nd Top var =', var_imp.index(np.sort(clf.feature_importances_)[-2])+1, X_train.columns[second_top_var_index])\n# print('3rd Top var =', var_imp.index(np.sort(clf.feature_importances_)[-3])+1, X_train.columns[third_top_var_index])\n\n# X_train_1 = X_train.to_numpy()[np.where(y_train==1.0)]\n# X_train_0 = X_train.to_numpy()[np.where(y_train==0.0)]\n\n# np.random.shuffle(X_train_0)\n\n# import matplotlib.pyplot as plt\n# %matplotlib inline\n# plt.rcParams['figure.figsize'] = [10, 5]\n\n# plt.scatter(X_train_0[:X_train_1.shape[0], top_var_index], X_train_0[:X_train_1.shape[0], second_top_var_index], \n#             label='Actual Class-0 Examples', alpha=.5)\n# plt.scatter( X_train_1[:, top_var_index], X_train_1[:, second_top_var_index], label='Actual Class-1 Examples', alpha=.1)\n# plt.xlabel(X_train.columns[top_var_index], fontsize=14)\n# plt.ylabel(X_train.columns[second_top_var_index], fontsize=14)\n# plt.title(\"Top 2 Variables Relationship\", fontsize=20)\n# plt.legend()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"fBE_EUU3_jRf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <font color=blue> Secion 10: Financial Benefits of the Model </font>","metadata":{}},{"cell_type":"code","source":"#Test Data: 71079 (normal) + 123 (fraud)\n#KNN:      AUC 0.92, Recall 0.82, Precision 0.74, F1 0.78\n#Logistic: AUC 0.97, Recall 0.89, Precision 0.03, F1 0.07\n#RFC:      AUC 0.98, Recall 0.89, Precision 0.04, F1 0.07\n#LGBM:     AUC 0.93, Recall 0.83, Precision 0.09, F1 0.16\n    \n#Total Fraud transactions in 2 days are 384. In one day 192 fraud transaction (average)\n#Total normal transaction in 2 days are 284807. In one day 142,403 normal transations (average)\n#Average fraud transaction is $122. In a 6 months FRAUD Tranactions of $122*6*30*192 = 42,16,320 i.e $ 4.2 million \n#can happen in the bank. \n\n#Next Six Month Approx Fraud Transactions: 34,560\n#Next Six Month Approx Normal Transactions:51,265,260\n\n#Recall score is 92% means 8% is False Negative.\n#it means everyday 16 (8% of 192) fraud will be marked as normal transactions. \n#It also means 176 (92% of 192) fraud transactions can be caught using our model.\n\n#i.e. out of 34560 fraud transactions our model can detect 31680 correctly in 6month. \n#And 2880 transaction will be False Negative. These are fraud transaction which our system fail to detect.\n\n#Precision score is 97% means 3% is False Positive it means for every 100 fraud transactions identied by the system \n#3 are normal transaction. This can lead to customer dissatisfaction, because 3% customer feel that \n#their normal transaction was kept on hold.\n\n#If bank call to the customer for all the transaction which are detected as fraud then only 3% cases will be \n#irritating call for the customer. Because he/she feel it is my genuine transaction.\n#(176/.97)=> 181 calls every day=> 181 * 180 (days) =>  32580 calls (6 months)\n#if Cost of each call is Rs 10 (assuming call centre in India) then cost of making \n#Then cost of making these call is Rs. 3,25,800. It can solve 92% fraud related problems\n#For other normal transactions bank can call to the customer as per their policy based on random samplng and calling.\n#In this they will be able to identify some of those 16 transactions which model couldn't detect.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}