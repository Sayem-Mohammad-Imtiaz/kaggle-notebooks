{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport os\nimport string\nfrom unidecode import unidecode\nimport dill\nfrom IPython.display import Image as IPythonImage, display\nfrom PIL import Image\nimport pytesseract\nfrom Levenshtein import jaro_winkler\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_df = pd.read_csv(\"../input/handwriting-recognition/written_name_validation_v2.csv\")\nvalidation_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH = '../input/handwriting-recognition/validation_v2/validation'\nNUMBER_OF_IMAGES = 4\nrandom_index = np.random.choice(validation_df.shape[0], NUMBER_OF_IMAGES, False)\nfor row in validation_df.loc[random_index, :].itertuples(index=False):\n    filename = os.path.join(PATH, row.FILENAME)\n    print(row.IDENTITY)\n    display(IPythonImage(filename=filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = {}\nfor row in validation_df.itertuples():\n    file_path = os.path.join(PATH, row.FILENAME)\n    image = Image.open(file_path)\n    text = pytesseract.image_to_string(image)\n    output[row.FILENAME] = text\n    if ((row.Index + 1) % 5000) == 0:\n        print(f\"Processed {row.Index + 1} rows\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_df = pd.DataFrame()\nfor i, (k, v) in enumerate(output.items()):\n    if (i + 1) % 5000 == 0:\n        print(f\"Converted output from {i + 1} images\")\n    \n    text = [t for t in v.split('\\n') if t not in ['', ' ', '\\n', '\\x0c']]\n    \n    temp_df = pd.DataFrame({\n        'FILENAME': [k] * len(text), \n        'TEXT': text\n    })\n    result_df = pd.concat([result_df, temp_df], ignore_index=True)\n\n# Look at the top 10 text tokens (these will probably be generic terms like \"nom\")\nresult_df['TEXT'].value_counts().nlargest(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_df\\\n    .loc[result_df['TEXT'].str.upper().str.contains('NOM|PRENOM|DATE DE NAISSANCE CLASSE') , \"TEXT\"]\\\n    .head(30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def filter_tokens(token_list, tokens_to_filter, remove_punctuation = True):\n    # Punctuation and empty text\n    punctuation_list = list(string.punctuation) + ['']\n    result = []\n    for t in token_list:\n        # Remove stand-alone punctuation/empty string\n        # Unicode has some fancy punctuation marks (slanting quotes, for example)\n        # remove them using unidecode\n        if remove_punctuation and unidecode(t) in punctuation_list:\n            continue\n        \n        # Remove if any token in tokens_to_filter list is a substring of current token\n        found = 0\n        for t_filter in tokens_to_filter:\n            if t_filter.upper() in t.upper():\n                # token is matched in tokens_to_filter list\n                found = 1\n                break\n        \n        if found == 1:\n            continue\n        else:\n            result.append(t)\n    \n    return result\n\n\n# Define text to remove\nSINGLE_TOKENS_REMOVE = ['NOM', 'PRENOM']\nMULTI_TOKENS_REMOVE = ['DATE DE NAISSANCE CLASSE']\n\n# Remove tokens\nresult_df['CLEAN_TEXT'] = result_df['TEXT']\\\n    .str\\\n    .split(' ')\\\n    .apply(lambda c: ' '.join(filter_tokens(c, SINGLE_TOKENS_REMOVE)))\n\nfor multi_token in MULTI_TOKENS_REMOVE:\n    result_df['CLEAN_TEXT'] = np.where(result_df['CLEAN_TEXT'].str.contains(multi_token), \n                                       '', \n                                       result_df['CLEAN_TEXT'])\n\nresult_df.head(40)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clean_result = result_df\\\n    .groupby('FILENAME')['CLEAN_TEXT']\\\n    .apply(''.join)\\\n    .reset_index()\n\nclean_result.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ocr_vs_actual = validation_df.merge(clean_result, how='left', on='FILENAME')\n\n# Remove labels which do not exist\nocr_vs_actual = ocr_vs_actual.loc[ocr_vs_actual['IDENTITY'].notnull(), :]\n\n# Remove spaces in OCR output\nocr_vs_actual['CLEAN_TEXT'] = ocr_vs_actual['CLEAN_TEXT'].str.replace('\\\\s', '', regex=True)\nocr_vs_actual.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorized_jaro_winkler = np.vectorize(jaro_winkler)\n\nocr_vs_actual['SIMILARITY_SCORE'] = vectorized_jaro_winkler(ocr_vs_actual['IDENTITY'].str.upper(), \n                                                            np.where(ocr_vs_actual['CLEAN_TEXT'].isnull(), \n                                                                     '', \n                                                                     ocr_vs_actual['CLEAN_TEXT'].str.upper()))\nocr_vs_actual.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('seaborn-white')\nplt.figure(figsize=(8,3), dpi=120)\nplt.hist(ocr_vs_actual['SIMILARITY_SCORE'], bins=50, alpha=0.5, color='steelblue', edgecolor='none')\nplt.title('Histogram of Jaro-Winkler similarity score between label and OCR-results')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"second_lowest_score = ocr_vs_actual.loc[(ocr_vs_actual['SIMILARITY_SCORE'] != 0), 'SIMILARITY_SCORE'].min()\n\nocr_vs_actual['BINS'] = pd.cut(ocr_vs_actual['SIMILARITY_SCORE'], \n                               bins=[0] + np.linspace(second_lowest_score, 0.95, 9).tolist() + [0.96, 0.97, 0.98, 0.99, 1.01], \n                               labels = ['no-match', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', 'best-match'],\n                               right=False)\nocr_vs_actual['BINS'].value_counts().sort_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NUMBER_OF_IMAGES = 5\nrandom_filename = np.random.choice(ocr_vs_actual.loc[ocr_vs_actual['BINS'] == 'best-match', 'FILENAME'].tolist(), NUMBER_OF_IMAGES, False)\nfor row in ocr_vs_actual.loc[ocr_vs_actual['FILENAME'].isin(random_filename), :].itertuples(index=False):\n    filename = os.path.join(PATH, row.FILENAME)\n    print(f\"\"\"Filename: {row.FILENAME}\\nActual: {row.IDENTITY}\\nOCR: {row.CLEAN_TEXT}\"\"\")\n    display(IPythonImage(filename=filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NUMBER_OF_IMAGES = 5\nrandom_filename = np.random.choice(ocr_vs_actual.loc[ocr_vs_actual['BINS'] == '8', 'FILENAME'].tolist(), NUMBER_OF_IMAGES, False)\nfor row in ocr_vs_actual.loc[ocr_vs_actual['FILENAME'].isin(random_filename), :].itertuples(index=False):\n    filename = os.path.join(PATH, row.FILENAME)\n    print(f\"\"\"Filename: {row.FILENAME}\\nActual: {row.IDENTITY}\\nOCR: {row.CLEAN_TEXT}\"\"\")\n    display(IPythonImage(filename=filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NUMBER_OF_IMAGES = 5\nrandom_filename = np.random.choice(ocr_vs_actual.loc[ocr_vs_actual['BINS'] == 'no-match', 'FILENAME'].tolist(), NUMBER_OF_IMAGES, False)\nfor row in ocr_vs_actual.loc[ocr_vs_actual['FILENAME'].isin(random_filename), :].itertuples(index=False):\n    filename = os.path.join(PATH, row.FILENAME)\n    print(f\"\"\"Filename: {row.FILENAME}\\nActual: {row.IDENTITY}\\nOCR: {row.CLEAN_TEXT}\"\"\")\n    display(IPythonImage(filename=filename))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}