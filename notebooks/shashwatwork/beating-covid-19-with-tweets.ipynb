{"cells":[{"metadata":{},"cell_type":"markdown","source":"<img src = \"https://ieee-dataport.org/sites/default/files/coronavirus-dataset-1.png\">\n<img src = \"https://media.giphy.com/media/6h8jgwC3dU6vS/giphy.gif\">","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"#For uploading and accessing the data\nimport pandas as pd\nimport numpy as np\n\n#For visualizations\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n!pip install dexplot -q\n!pip install pycaret -q\n!pip install stylecloud -q\n# for visualizations\nplt.style.use('ggplot')\n\n# for interactive visualizations\nimport plotly.offline as py\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\nfrom plotly import tools\ninit_notebook_mode(connected = True)\nimport plotly.figure_factory as ff\nfrom sklearn.preprocessing import StandardScaler\n\nfrom pandas_profiling import ProfileReport\n\nimport dexplot as dxp\n\n\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n\n# Nltk for tokenize and stopwords\nfrom nltk.corpus import stopwords \nfrom nltk.tokenize import word_tokenize \nimport requests\nfrom PIL import Image\nfrom io import BytesIO\nfrom wordcloud import WordCloud, STOPWORDS\nimport stylecloud\nfrom wordcloud import ImageColorGenerator\nRANDOM_SEED = 42\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a id='1'> Detailed Analysis for Tweets in COVID Pandemic</a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/covid19-tweets/covid19_tweets.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def missing_value_of_data(data):\n    total=data.isnull().sum().sort_values(ascending=False)\n    percentage=round(total/data.shape[0]*100,2)\n    return pd.concat([total,percentage],axis=1,keys=['Total','Percentage'])\n\ndef duplicated_values_data(data):\n    dup=[]\n    columns=data.columns\n    for i in data.columns:\n        dup.append(sum(data[i].duplicated()))\n    return pd.concat([pd.Series(columns),pd.Series(dup)],axis=1,keys=['Columns','Duplicate count'])\n\ndef unique_values_in_column(data,feature):\n    unique_val=pd.Series(data.loc[:,feature].unique())\n    return pd.concat([unique_val],axis=1,keys=['Unique Values'])\n\ndef count_values_in_column(data,feature):\n    total=data.loc[:,feature].value_counts(dropna=False)\n    percentage=round(data.loc[:,feature].value_counts(dropna=False,normalize=True)*100,2)\n    return pd.concat([total,percentage],axis=1,keys=['Total','Percentage'])\n\ndef ngrams_top(corpus,ngram_range,n=None):\n    \"\"\"\n    List the top n words in a vocabulary according to occurrence in a text corpus.\n    \"\"\"\n    vec = CountVectorizer(stop_words = 'english',ngram_range=ngram_range).fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    total_list=words_freq[:n]\n    df=pd.DataFrame(total_list,columns=['text','count'])\n    return df\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_value_of_data(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"duplicated_values_data(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_values_in_column(df,'user_location')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_values_in_column(df,'hashtags')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dd_11 = ngrams_top(df['text'],(1,1),n=10)\ndxp.bar(x='text', y='count', data=dd_11,figsize=(10,5),cmap='dark12_r',title='Count Plot for Most Frequent words in Tweets')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dd_22 = ngrams_top(df['text'],(2,2),n=10)\ndxp.bar(x='text', y='count', data=dd_22,figsize=(10,5),cmap='dark12_r',title='Count Plot for Most Frequent words in Tweets')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dd_33 = ngrams_top(df['text'],(3,3),n=10)\ndxp.bar(x='text', y='count', data=dd_33,figsize=(10,5),cmap='dark12_r',title='Count Plot for Most Frequent words in Tweets')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"Top10_source = pd.DataFrame(df['source'].value_counts().sort_values(ascending=False)[:10]).reset_index()\nTop10_source.columns = ['Source','Count']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dxp.bar(x='Source', y='Count', data=Top10_source,figsize=(10,5),cmap='viridis',title='Source for Tweets in COVID-19')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Inference-\n* Twitter Web app has most tweets followed by Twitter for Android and Iphone","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"best_10_regions = pd.DataFrame(df['user_location'].value_counts().sort_values(ascending=False)[:15]).reset_index()\nbest_10_regions.columns = ['user_location','Count']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dxp.bar(x='user_location', y='Count', data=best_10_regions,figsize=(15,5),cmap='viridis',title='Geographical Location for Tweets')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Inference-\n* India dominates in Tweets for COVID -19 followed by US.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"Top10_user = pd.DataFrame(df['user_name'].value_counts().sort_values(ascending=False)[:10]).reset_index()\nTop10_user.columns = ['user_name','count']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dxp.bar(x='user_name', y='count', data=Top10_user,figsize=(15,5),cmap='viridis',title='Users Dominating in Tweets in COVID-19')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dxp.bar(x='user_verified', y='user_followers', data=df.head(100),figsize=(10,10),split='source',aggfunc='mean',title='Relationship betwwen fake and real users')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hashtags = df['hashtags'].dropna().tolist()\nunique_hashtags=(\" \").join(hashtags)\nstylecloud.gen_stylecloud(text = unique_hashtags,\n                          icon_name='fas fa-first-aid',\n                          palette='colorbrewer.diverging.Spectral_11',\n                          background_color='black',\n                          gradient='horizontal')\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from IPython.display import Image \n\nImage(\"./stylecloud.png\",width = 600, height = 600)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hashtags = df['text'].dropna().tolist()\nunique_hashtags=(\" \").join(hashtags)\nstylecloud.gen_stylecloud(text = unique_hashtags,\n                          icon_name='far fa-comment',\n                          background_color='white',\n                          gradient='horizontal')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from IPython.display import Image \n\nImage(\"./stylecloud.png\",width = 600, height = 600)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_plot = df[['user_created','user_followers','user_favourites','user_friends']]\ndf_plot['user_created'] = pd.to_datetime(df_plot.user_created)\ndf_plot['user_created'] = df_plot['user_created'].dt.strftime('%m/%d/%Y')\ndf_plot = df_plot.sort_values('user_created')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dxp.line(x='user_created',y = 'user_followers',aggfunc='mean',data=df_plot.head(100),figsize=(10,5),cmap='viridis',title='Followers Timeline')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dxp.line(x='user_created',y = 'user_favourites',aggfunc='mean',data=df_plot.head(100),figsize=(10,5),cmap='viridis_r',title='User Favourite Timeline')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dxp.line(x='user_created',y = 'user_friends',aggfunc='mean',data=df_plot.head(100),figsize=(10,5),cmap='plotly3',title='User Friends Timeline')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a id='1'> Topic Modeling with PyCaret</a><br>\n<img src = 'https://pycaret.org/wp-content/uploads/2020/03/Divi93_43.png'> <br>\n\n###### PyCaret is an open source low-code machine learning library in Python that aims to reduce the hypothesis to insights cycle time in a ML experiment. It enables data scientists to perform end-to-end experiments quickly and efficiently. In comparison with the other open source machine learning libraries, PyCaret is an alternative low-code library that can be used to perform complex machine learning tasks with only few lines of code. PyCaret is essentially a Python wrapper around several machine learning libraries and frameworks such as scikit-learn, XGBoost, Microsoft LightGBM, spaCy and many more.\n\n###### PyCaret is a great library which not only simplifies the machine learning tasks for citizen data scientists but also helps new startups to reduce the cost of investing in a team of data scientists. Therefore, this library has not only helped the citizen data scientists but has also helped individuals who want to start exploring the field of data science, having no prior knowledge in this field.\n\n###### PyCaret is simple, easy to use and deployment ready. All the steps performed in a ML experiment can be reproduced using a pipeline that is automatically developed and orchestrated in PyCaret as you progress through the experiment. A pipeline can be saved in a binary file format that is transferable across environments.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from pycaret.nlp import *","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b> This function initializes the environment in pycaret. setup() must called before executing any other function in pycaret. It takes one mandatory parameter: dataframe {array-like, sparse matrix} or object of type list. If a dataframe is passed, target column containing text must be specified. When data passed is of type list, no target parameter is required.<b>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"nlp1 = setup(df, target = 'text', session_id=RANDOM_SEED, experiment_name='covid')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b> This function creates a model on the dataset passed as a data param during the setup stage. setup() function must be called before using create_model(). This function returns a trained model object.  </b>\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Latent Dirichlet Allocation\nlda = create_model('lda',multi_core=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Non-Negative Matrix Factorization\nnmf = create_model('nmf', num_topics = 6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Latent Semantic Indexing\nlsi = create_model('lsi', num_topics = 6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Hierarchical Dirichlet Process\nhdp = create_model('hdp', num_topics = 6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Random Projections\nrp = create_model('rp',num_topics = 6)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b> This function assigns each of the data point in the dataset passed during setup stage to one of the topic using trained model object passed as model param. create_model() function must be called before using assign_model(). This function returns data frame with topic weights, dominant topic and % of the dominant topic (where applicable). <b>\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lda_results = assign_model(lda)\nlda_results.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nmf_results = assign_model(nmf)\nnmf_results.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hdp_results = assign_model(hdp)\nhdp_results.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b> This function takes a trained model object (optional) and returns a plot based on the inferred dataset by internally calling assign_model before generating a plot </b>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"##### Plotting LDA Results(Word Frequency Distribution)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(lda)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Plotting Word Distribution","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(lda, plot = 'distribution')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Plotting Bigrams","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(lda, plot = 'bigram')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Plotting Trigrams","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(lda, plot = 'trigram')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Plotting tsne 3D Dimension Plot","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(lda, plot = 'tsne')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Plotting Topic Distribution","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(lda, plot = 'topic_distribution')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Plotting WordCloud","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(lda, plot = 'wordcloud')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Plotting UMAP Dimensionality Plot","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(lda, plot = 'umap')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b> This function displays the user interface for all the available plots for a given model. It internally uses the plot_model() function.<b/>\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluate_model(lda)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a id='1'> References</a>\n* [Pycaret](https://github.com/pycaret/pycaret)\n* [Helper Functions Notebook](https://www.kaggle.com/raenish/cheatsheet-text-helper-functions)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Made with ❤️ for Learning ","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}