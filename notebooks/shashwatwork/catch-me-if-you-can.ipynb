{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<img src = \"https://www.indiewire.com/wp-content/uploads/2018/12/r4offmlfqwjhmvhysomm.jpg\">\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n  <h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\"  role=\"tab\" aria-controls=\"home\">Notebook Content:</h3>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#one_\" role=\"tab\" aria-controls=\"profile\">1.Exploratory Data Analysis<span class=\"badge badge-primary badge-pill\"></span></a>\n    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#one_\" role=\"tab\" aria-controls=\"profile\">2.Data Preprocessing<span class=\"badge badge-primary badge-pill\"></span></a>\n    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#one_\" role=\"tab\" aria-controls=\"profile\">3.Predictive Models<span class=\"badge badge-primary badge-pill\"></span></a>","metadata":{}},{"cell_type":"code","source":"# Pandas and numpy for data manipulation\nimport pandas as pd\nimport numpy as np\nfrom collections import Counter\n\n\n# Display up to 60 columns of a dataframe\npd.set_option('display.max_columns', 60)\n\n# Matplotlib visualization\nimport matplotlib.pyplot as plt\nplt.style.use('grayscale')\n%matplotlib inline\n\n# Seaborn for visualization\nimport seaborn as sns\nimport plotly.express as px\nsns.set(font_scale = 2)\n\n# Splitting data into training and testing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.linear_model import LogisticRegression # to apply the Logistic regression\nfrom sklearn.feature_selection import RFE\nfrom sklearn.model_selection import KFold # for cross validation\nfrom sklearn.model_selection import GridSearchCV # for tuning parameter\nfrom sklearn.model_selection import RandomizedSearchCV  # Randomized search on hyper parameters.\nfrom sklearn.preprocessing import StandardScaler # for normalization\nfrom sklearn.pipeline import Pipeline \nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import classification_report,balanced_accuracy_score,f1_score,recall_score,accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.neighbors import KNeighborsClassifier #KNN\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn import metrics # for the check the error and accuracy of the model\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/creditcarddefaultdata/data.csv')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Phase I - Exploratory Data Analysis\n### Univariate \n### Bivariate \n### Multivariate","metadata":{}},{"cell_type":"code","source":"print(\" Shape of  dataframe: \", data.shape)\n# Drop duplicates\ndata.drop_duplicates()\nprint(data.shape)\n","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"null= data.isnull().sum().sort_values(ascending=False)\ntotal =data.shape[0]\npercent_missing= (data.isnull().sum()/total).sort_values(ascending=False)\n\nmissing_data= pd.concat([null, percent_missing], axis=1, keys=['Total missing', 'Percent missing'])\n\nmissing_data.reset_index(inplace=True)\nmissing_data= missing_data.rename(columns= { \"index\": \" column name\"})\npd.DataFrame(missing_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Univariate Analysis","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(18,8))\nplt.subplot(1,2,1)\ndata.Y.value_counts().plot.pie(explode=[0,0.1])\nplt.subplot(1,2,2)\nsns.countplot(data.Y)\nplt.suptitle(\"Target Distribution\", size=20)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_df = pd.DataFrame(data['Y'].value_counts())\ncount_df.style.background_gradient(cmap='vlag')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Count_Nodefault_transacation = len(data[data['Y']==0])\nCount_default_transacation = len(data[data['Y']==1]) \nPercentage_nodefault = Count_Nodefault_transacation/(Count_default_transacation+Count_Nodefault_transacation)\nprint('% of no defaults       :', Percentage_nodefault*100)\nprint('Number of no defaults     :', Count_Nodefault_transacation)\nPercentage_of_default= Count_default_transacation/(Count_default_transacation+Count_Nodefault_transacation)\nprint('% of defaults         :',Percentage_of_default*100)\nprint('Number of defaults    :', Count_default_transacation)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> A number of 6,636 out of 30,000 (or 22%) of defaulters . The data has unbalance with respect of the target value\n\n","metadata":{}},{"cell_type":"code","source":"def plot_distribution(feature,color):\n    plt.figure(figsize=(10,6))\n    plt.title(\"Distribution of %s\" % feature)\n    sns.distplot(data[feature].dropna(),color=color, kde=True,bins=30)\n    plt.show()\n\ndef plot_box(feature, color):\n    plt.figure(figsize=(10,6))\n    plt.title(\"Box Plot of %s\" % feature)\n    sns.boxplot(data[feature].dropna(),color=color)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_distribution('X1','g')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_distribution('X12','r')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_distribution('X16','y')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_box('X12',color='b')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_box('X1','b')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,8))\nsns.boxenplot(x = 'X5', y = 'X1',data = data, color='g')\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('values', fontsize=12)\nplt.title('Boxplot for X5')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnt_srs = data['X5'].value_counts()\n\nplt.figure(figsize=(20,8))\nsns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8, color='g')\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('values', fontsize=12)\nplt.title('Count for X5')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnt_srs = data['X3'].value_counts()\n\nplt.figure(figsize=(20,8))\nsns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8, color='r')\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('values', fontsize=12)\nplt.title('Count for X3')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnt_srs = data['X2'].value_counts()\n\nplt.figure(figsize=(20,8))\nsns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8, color='y')\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('values', fontsize=12)\nplt.title('Count for X2')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Bivariate Analysis","metadata":{}},{"cell_type":"code","source":"fig = px.scatter(data, x=\"X1\", y=\"X20\", trendline=\"ols\",color = 'X2',color_continuous_scale='ylgn',template = 'simple_white')\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.scatter(data, x=\"X1\", y=\"X12\", marginal_y=\"violin\",color = 'X3',marginal_x=\"box\", trendline=\"ols\", template=\"simple_white\")\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Multivariate Analysis","metadata":{}},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_corr = data[['X12', 'X13', 'X14', 'X15', 'X16', 'X17', 'X18', 'X19', 'X20', 'X21','X22', 'X23', 'Y']]","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(df_corr,hue = 'Y')","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr = df_corr.corr(method='spearman')\nplt.figure(figsize=(10,10))\nsns.heatmap(corr, annot=True, vmax=.8, square=True,cmap = 'rainbow_r');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Zoomed out correlation map\nk = 10\ncols = corr.nlargest(k, 'Y')['Y'].index\ncm = np.corrcoef(data[cols].values.T)\nsns.set(font_scale=1.25)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True,cmap = 'rainbow_r', fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Phase II - Data Preprocessing\n#### Feature Engineering\n#### Over Sampling - Imbalanced Dataset with SMOTETomek","metadata":{}},{"cell_type":"code","source":"# Binned Age Feature\nbins = [20, 29, 39, 49, 59, 69, 81]\nbins_names = [1, 2, 3, 4, 5, 6]\ndata['age_binned'] = pd.cut(data['X5'], bins, labels=bins_names)\ndata['age_binned'] = pd.to_numeric(data['age_binned'])\nprint(data.sample())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replacing all Negative values with 0\ndata['X6'] = data['X6'].apply(lambda x : x if x > 0 else 0)\ndata['X7'] = data['X6'].apply(lambda x : x if x > 0 else 0)\ndata['X8'] = data['X6'].apply(lambda x : x if x > 0 else 0)\ndata['X9'] = data['X6'].apply(lambda x : x if x > 0 else 0)\ndata['X10'] = data['X6'].apply(lambda x : x if x > 0 else 0)\ndata['X11'] = data['X6'].apply(lambda x : x if x > 0 else 0)\nprint(data.head(10))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[data.X1 > 300000][['X12', 'X13', 'X14', 'X15', 'X16', 'X17', 'X18', 'X19', 'X20', 'X21','X22', 'X23', 'Y']]","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Percetage_amount_1'] = (data.X1 - data.X12) / data.X1\ndata['Percetage_amount_2'] = (data.X1 - data.X13) / data.X1\ndata['Percetage_amount_3'] = (data.X1 - data.X14) / data.X1\ndata['Percetage_amount_4'] = (data.X1 - data.X15) / data.X1\ndata['Percetage_amount_5'] = (data.X1 - data.X16) / data.X1\ndata['Percetage_amount_6'] = (data.X1 - data.X17) / data.X1\nprint(data.sample())","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols_to_drop = ['X5']\ndata_preprocess = data.drop(cols_to_drop,1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_preprocess.to_csv('preprocess_data.csv',index=False)\nprint(f\"Train Rows and columns {data_preprocess.shape[0]}, {data_preprocess.shape[1]}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = data_preprocess.drop('Y', axis=1)\ny =  data_preprocess['Y']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Shape of X_train :\", X_train.shape)\nprint(\"Shape of X_test :\", X_test.shape)\nprint(\"Shape of y_train :\", y_train.shape)\nprint(\"Shape of y_test :\", y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from imblearn.combine import SMOTETomek\noversample = SMOTETomek(random_state=42)\nX_train_resam, y_train_resam = oversample.fit_resample(X_train, y_train)\ncounter = Counter(y_train)\ncounter_ = Counter(y_train_resam)\n\nprint('before oversampling',counter)\nprint('after oversampling' ,counter_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Scaling the Data with Robust Scaler due to oultiers observed in EDA\nscaler = RobustScaler()\nX_train_resam = scaler.fit_transform(X_train_resam)\nX_test = scaler.transform(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Phase III Predictive Models\n### Model Selection\n### Hyperparameter Tuning\n### Persist Final Model","metadata":{}},{"cell_type":"code","source":"clfs = []\n\nclfs.append((\"LogRegression\", \n             Pipeline([(\"Scaler\", RobustScaler()),\n                       (\"LogReg\", LogisticRegression())])))\n\nclfs.append((\"XGB\",\n             Pipeline([(\"Scaler\", RobustScaler()),\n                       (\"XGB\", XGBClassifier())]))) \nclfs.append((\"KNN\", \n             Pipeline([(\"Scaler\", RobustScaler()),\n                       (\"KNN\", KNeighborsClassifier())]))) \n\nclfs.append((\"DTC\", \n             Pipeline([(\"Scaler\", RobustScaler()),\n                       (\"DecisionTrees\", DecisionTreeClassifier())]))) \n\nclfs.append((\"RFClassifier\", \n             Pipeline([(\"Scaler\", RobustScaler()),\n                       (\"RandomForest\", RandomForestClassifier())]))) \n\nclfs.append((\"GBClassifier\", \n             Pipeline([(\"Scaler\", RobustScaler()),\n                       (\"GradientBoosting\", GradientBoostingClassifier())]))) \n\n\nscoring = 'f1_weighted'\nn_folds = 10\nmsgs = []\nresults, names  = [], [] \n\nfor name, model  in clfs:\n    kfold = KFold(n_splits=n_folds, random_state=None)\n    cv_results = cross_val_score(model, X, y, \n                                 cv=kfold, scoring=scoring, n_jobs=-1)    \n    names.append(name)\n    results.append(cv_results)    \n    msg = \"%s: %f (+/- %f)\" % (name, cv_results.mean(),  \n                               cv_results.std())\n    msgs.append(msg)\n    print(msg)","metadata":{"scrolled":true,"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(10,5))\nsns.set_context('notebook', font_scale=1.1)\nfig.suptitle('Algorithm Comparison - F1 (cv=10)')\nax = fig.add_subplot(111)\nplt.boxplot(results, showmeans=True)\nax.set_xticklabels(names)\nax.set_ylabel('F1')\nax.set_ylim([0.75,1])\nplt.box(False)","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr = LogisticRegression()\nlr.fit(X_train_resam, y_train_resam)\ny_pred_lr = lr.predict(X_test)\n\nprint(\"Accuracy of model \",accuracy_score(y_test, y_pred_lr))\nprint(\"F1 Score \",f1_score(y_test, y_pred_lr))\nprint(\"Recall Score \",recall_score(y_test, y_pred_lr))\nprint(\"Balanced Accuracy Score \",balanced_accuracy_score(y_test, y_pred_lr))\n\nprint()\nprint(classification_report(y_test, y_pred_lr))\nplt.figure(figsize=(4,3))\nConfMatrix = confusion_matrix(y_test,lr.predict(X_test))\nsns.heatmap(ConfMatrix,annot=True, cmap=\"Blues\", fmt=\"d\", \n            xticklabels = ['Non-default', 'Default'], \n            yticklabels = ['Non-default', 'Default'])\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.title(\"Confusion Matrix\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn = KNeighborsClassifier()\nknn.fit(X_train_resam, y_train_resam)\ny_pred_knn = knn.predict(X_test)\n\nprint(\"Accuracy of model \",accuracy_score(y_test, y_pred_knn))\nprint(\"F1 Score \",f1_score(y_test, y_pred_knn))\nprint(\"Recall Score \",recall_score(y_test, y_pred_knn))\nprint(\"Balanced Accuracy Score \",balanced_accuracy_score(y_test, y_pred_knn))\n\nprint()\nprint(classification_report(y_test, y_pred_knn))\nplt.figure(figsize=(4,3))\nConfMatrix = confusion_matrix(y_test,knn.predict(X_test))\nsns.heatmap(ConfMatrix,annot=True, cmap=\"Blues\", fmt=\"d\", \n            xticklabels = ['Non-default', 'Default'], \n            yticklabels = ['Non-default', 'Default'])\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.title(\"Confusion Matrix\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dt = DecisionTreeClassifier()\ndt.fit(X_train_resam, y_train_resam)\ny_pred_dt = dt.predict(X_test)\n\nprint(\"Accuracy of model \",accuracy_score(y_test, y_pred_dt))\nprint(\"F1 Score \",f1_score(y_test, y_pred_dt))\nprint(\"Recall Score \",recall_score(y_test, y_pred_dt))\nprint(\"Balanced Accuracy Score \",balanced_accuracy_score(y_test, y_pred_dt))\n\nprint()\nprint(classification_report(y_test, y_pred_dt))\nplt.figure(figsize=(4,3))\nConfMatrix = confusion_matrix(y_test,dt.predict(X_test))\nsns.heatmap(ConfMatrix,annot=True, cmap=\"Blues\", fmt=\"d\", \n            xticklabels = ['Non-default', 'Default'], \n            yticklabels = ['Non-default', 'Default'])\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.title(\"Confusion Matrix\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators=100,random_state=42)\nrf.fit(X_train_resam, y_train_resam)\ny_pred_rf = rf.predict(X_test)\n\nprint(\"Accuracy of model \",accuracy_score(y_test, y_pred_rf))\nprint(\"F1 Score \",f1_score(y_test, y_pred_rf))\nprint(\"Recall Score \",recall_score(y_test, y_pred_rf))\nprint(\"Balanced Accuracy Score \",balanced_accuracy_score(y_test, y_pred_rf))\n\nprint()\nprint(classification_report(y_test, y_pred_rf))\nplt.figure(figsize=(4,3))\nConfMatrix = confusion_matrix(y_test,rf.predict(X_test))\nsns.heatmap(ConfMatrix,annot=True, cmap=\"Blues\", fmt=\"d\", \n            xticklabels = ['Non-default', 'Default'], \n            yticklabels = ['Non-default', 'Default'])\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.title(\"Confusion Matrix\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gb = GradientBoostingClassifier(n_estimators=100,random_state=42)\ngb.fit(X_train_resam, y_train_resam)\ny_pred_gb = gb.predict(X_test)\n\nprint(\"Accuracy of model \",accuracy_score(y_test, y_pred_gb))\nprint(\"F1 Score \",f1_score(y_test, y_pred_gb))\nprint(\"Recall Score \",recall_score(y_test, y_pred_gb))\nprint(\"Balanced Accuracy Score \",balanced_accuracy_score(y_test, y_pred_gb))\n\nprint()\nprint(classification_report(y_test, y_pred_gb))\nplt.figure(figsize=(4,3))\nConfMatrix = confusion_matrix(y_test,gb.predict(X_test))\nsns.heatmap(ConfMatrix,annot=True, cmap=\"Blues\", fmt=\"d\", \n            xticklabels = ['Non-default', 'Default'], \n            yticklabels = ['Non-default', 'Default'])\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.title(\"Confusion Matrix\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb = XGBClassifier(n_estimators=100,random_state=42)\nxgb.fit(X_train_resam, y_train_resam)\ny_pred_xgb = xgb.predict(X_test)\n\nprint(\"Accuracy of model \",accuracy_score(y_test, y_pred_xgb))\nprint(\"F1 Score \",f1_score(y_test, y_pred_xgb))\nprint(\"Recall Score \",recall_score(y_test, y_pred_xgb))\nprint(\"Balanced Accuracy Score \",balanced_accuracy_score(y_test, y_pred_xgb))\n\nprint()\nprint(classification_report(y_test, y_pred_xgb))\nplt.figure(figsize=(4,3))\nConfMatrix = confusion_matrix(y_test,xgb.predict(X_test))\nsns.heatmap(ConfMatrix,annot=True, cmap=\"Blues\", fmt=\"d\", \n            xticklabels = ['Non-default', 'Default'], \n            yticklabels = ['Non-default', 'Default'])\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.title(\"Confusion Matrix\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import lightgbm as ltb\nlgbm = ltb.LGBMClassifier()\nlgbm.fit(X_train_resam, y_train_resam)\ny_pred_lgb = lgbm.predict(X_test)\n\nprint(\"Accuracy of model \",accuracy_score(y_test, y_pred_lgb))\nprint(\"F1 Score \",f1_score(y_test, y_pred_lgb))\nprint(\"Recall Score \",recall_score(y_test, y_pred_lgb))\nprint(\"Balanced Accuracy Score \",balanced_accuracy_score(y_test, y_pred_lgb))\n\nprint()\nprint(classification_report(y_test, y_pred_lgb))\nplt.figure(figsize=(4,3))\nConfMatrix = confusion_matrix(y_test,lgbm.predict(X_test))\nsns.heatmap(ConfMatrix,annot=True, cmap=\"Blues\", fmt=\"d\", \n            xticklabels = ['Non-default', 'Default'], \n            yticklabels = ['Non-default', 'Default'])\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.title(\"Confusion Matrix\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Conclusion\n\n* Offical Scoring Metrics  - Balanced Accuracy, F1 Score and Recall Score.\n* After Model Selection Final Model Picked up <b> Gradient Boosting Classifier </b>.\n* Please Refer Doc for more info.\n\n#### Hyperparameter Tuning Using Optuna.\n* [Reference](https://optuna.org/)","metadata":{}},{"cell_type":"code","source":"!pip install optuna -q","metadata":{"_kg_hide-input":true,"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import optuna","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def objective(trial):\n    \n    param = {\n        'loss': 'deviance', \n        'random_state': 101,\n        'n_estimators' : trial.suggest_int('n_estimators', 100, 500),\n        'learning_rate': trial.suggest_categorical('learning_rate', [0.001,0.008,0.01,0.02,0.03,0.04,0.05]),\n        'max_depth': trial.suggest_categorical('max_depth', [1,2,3,4,5]),\n        'min_samples_leaf' : trial.suggest_int('min_samples_leaf', 1, 10)}\n    model = GradientBoostingClassifier(**param)  \n    \n    model.fit(X_train_resam,y_train_resam)\n    \n    preds = model.predict(X_test)\n    score = f1_score(y_test,preds)\n    \n    return score","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=10)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optuna.visualization.plot_param_importances(study)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuned_params=study.best_params   \ntuned_params","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuned_params['random_state'] = 101","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuned_gb = GradientBoostingClassifier(**tuned_params)\ntuned_gb.fit(X_train_resam, y_train_resam)\ny_pred_tuned_gb = tuned_gb.predict(X_test)\n\nprint(\"Accuracy of model \",accuracy_score(y_test, y_pred_tuned_gb))\nprint(\"F1 Score \",f1_score(y_test, y_pred_tuned_gb))\nprint(\"Recall Score \",recall_score(y_test, y_pred_tuned_gb))\nprint(\"Balanced Accuracy Score \",balanced_accuracy_score(y_test, y_pred_tuned_gb))\n\nprint()\nprint(classification_report(y_test, y_pred_tuned_gb))\nplt.figure(figsize=(4,3))\nConfMatrix = confusion_matrix(y_test,tuned_gb.predict(X_test))\nsns.heatmap(ConfMatrix,annot=True, cmap=\"Blues\", fmt=\"d\", \n            xticklabels = ['Non-default', 'Default'], \n            yticklabels = ['Non-default', 'Default'])\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.title(\"Confusion Matrix\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Feature Importance Plot \nfeat_imp = pd.Series(tuned_gb.feature_importances_, index=data_preprocess.drop(['Y'], axis=1).columns)\nfeat_imp.nlargest(20).plot(kind='bar', figsize=(8,10))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Persisting Final Model\nimport pickle\nfilename = '_gb.pkl'\npickle.dump(tuned_gb, open(filename, 'wb'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<img src = \"https://drinkwhen.ca/wp-content/uploads/2020/04/Catch-Me-If-You-Can-Drinking-Game.gif\">","metadata":{}}]}