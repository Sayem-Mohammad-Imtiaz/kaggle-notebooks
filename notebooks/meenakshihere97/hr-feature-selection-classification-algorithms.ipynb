{"cells":[{"metadata":{},"cell_type":"markdown","source":"# HR ANALYTICS\n\nThe aim of this notebook is to predict the Employee attrition rate based on the given features in the dataset. **Logistic Regression, Decision tree, Random Forest algorithm, Support Vector Machine and Gradient Boosting classification algorithms**  are used for prediction and the ML models are implemented using **Pipelines**. Each feature is analysed and the features that influence the attrition rate is chosen for prediction. "},{"metadata":{},"cell_type":"markdown","source":"## Table of contents\n1. Data Gathering\n2. Feature Selection\n    <br>2.1 Categorical features analysis\n    <br>2.2 Quantitative features analysis\n3. Data Transformation\n4. Maching Learning Models Implementation\n5. Conclusion"},{"metadata":{},"cell_type":"markdown","source":"# 1. DATA GATHERING"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#loading the dataset\nretent_df = pd.read_csv('/kaggle/input/hr-analytics/HR_comma_sep.csv')\nretent_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check for null values\nretent_df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. FEATURE SELECTION"},{"metadata":{},"cell_type":"markdown","source":"Categorical columns - Work_accident, Department, salary\n<br>Quantitative columns - satisfaction_level, last_evaluation, number_project, average_monthly_hours, time_spend_company, promotion_last_5years"},{"metadata":{"trusted":true},"cell_type":"code","source":"#analysing the correlation between features\nretent_df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(retent_df.corr())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(retent_df.corr())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"retent_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking null values\nretent_df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.1 CATEGORICAL FEATURES ANALYSIS "},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(retent_df.Department, retent_df.left).style.background_gradient(cmap='summer_r')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the graph, it is understood that employees from Sales Department has left the organisation in greater numbers."},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(retent_df.salary, retent_df.left).plot(kind='bar')\nplt.title('Salary vs Employee Attrition')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems like Low income employees has left the most from the organisation."},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(retent_df.Work_accident, retent_df.left).plot(kind='bar',cmap='copper')\nplt.title('Work accident vs Employee retention')\nplt.xticks([0,1],['No','Yes'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Work accident does not influence Employee retention rate."},{"metadata":{},"cell_type":"markdown","source":"## 2.2 QUANTITATIVE FEATURES ANALYSIS "},{"metadata":{"trusted":true},"cell_type":"code","source":"retent_df.groupby('left').mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above table, it can be seen that satisfaction level and promotion rate is low in employees who has left the organisation. Average working hours and time spent in the company is higher for the resigned employees. These 4 features can be chosen for prediction."},{"metadata":{"trusted":true},"cell_type":"code","source":"#satisfaction level vs employee attrition\nsns.violinplot(x='left', y='satisfaction_level',data=retent_df)\nplt.title('Satisfaction level vs Employee attrition')\nplt.tight_layout()\nplt.xticks([0,1],['No','Yes'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems like the employees with lower satisfaction rate has left the most."},{"metadata":{"trusted":true},"cell_type":"code","source":"#promotion vs Employee attrition\npd.crosstab(retent_df.promotion_last_5years, retent_df.left).style.background_gradient(cmap='summer_r')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Employees who received no promotions has left the organisation in greater numbers."},{"metadata":{"trusted":true},"cell_type":"code","source":"retent_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='left', y='average_montly_hours', data=retent_df)\nplt.title('Average monthly hours vs Employee attrition')\nplt.xticks([0,1],['No','Yes'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Employees who spent more time in working has left in greater numbers."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Time spent in the company vs Employee attrition\nsns.boxplot(x='left', y='time_spend_company', data=retent_df)\nplt.title('Time spent in the company vs Employee attrition')\nplt.xticks([0,1],['No','Yes'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thus, it is safe to conclude that Department, Salary, satisfaction level, promotion, average working hours in a month and time spent in the company influences the Employee attrition rate. Hence these features are chosen for prediction."},{"metadata":{},"cell_type":"markdown","source":"# 3. DATA TRANSFORMATION"},{"metadata":{"trusted":true},"cell_type":"code","source":"#save the 6 features selected from feature analysis in a separate dataframe\ndf = retent_df[['Department','salary','satisfaction_level','promotion_last_5years','average_montly_hours','time_spend_company']]\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#transform the data to numerical so that it can be passed to the model\nsalary_df = pd.get_dummies(df.salary, prefix='salary')\nsalary_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#transform department\ndept_df = pd.get_dummies(df.Department, prefix='dept')\ndept_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#concatenate salary with the main dataframe\ntransform_df = pd.concat([df,salary_df], axis='columns')\ntransform_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#concatenate Department with the main dataframe\ntransform_df = pd.concat([transform_df,dept_df], axis='columns')\ntransform_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop columns Department and salary\ntransform_df.drop(['Department','salary'], axis=1, inplace=True)\ntransform_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. MACHINE LEARNING MODELS IMPLEMENTATION"},{"metadata":{"trusted":true},"cell_type":"code","source":"#split the dataset into training and test data\nx_train, x_test, y_train, y_test = train_test_split(transform_df, retent_df.left, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create a pipeline for Logistic Regression\npipeline_log_reg = Pipeline([('Logistic Regression',LogisticRegression(solver='lbfgs', max_iter=1000))])\n\n#create a pipeline for decision tree\npipeline_dec_tree = Pipeline([('Decision tree', DecisionTreeClassifier())])\n\n#create a pipeline for Random Forest Classifier\npipeline_random_forest = Pipeline([('Random Forest', RandomForestClassifier())])\n\n#create a pipeline for Support Vector Machine\npipeline_svm = Pipeline([('Support Vector Machine', SVC(C=2.0))])\n\n#create a pipeline for Gradient Boosting Classifier\npipeline_gradient_boost = Pipeline([('Gradient Boosting Classifier', GradientBoostingClassifier(learning_rate=0.1))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create a list and dictionary for pipelines\npipelines = [pipeline_log_reg, pipeline_dec_tree, pipeline_random_forest, pipeline_svm, pipeline_gradient_boost]\npipelines_dict = {0:'Logistic Regression',\n                 1:'Decision Tree',\n                 2:'Random Forest',\n                 3:'Support Vector Machine',\n                 4:'Gradient Boosting Classifier'}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predict and display the accuracy of models\nfor i,pipe in enumerate(pipelines):\n    pipe.fit(x_train,y_train)\n    y_pred = pipe.predict(x_test)\n    print(\"Accuracy of {} is {}\".format(pipelines_dict[i], pipe.score(x_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. CONCLUSION\n\nFrom the analysis and prediction, the accuracy of the models are listed as follows:\n<br>Logistic Regression - 77%\n<br>Decision Tree algorithm - 97% \n<br>Random Forest algorithm - 98% \n<br>Support Vector machine - 78%\n<br>Gradient Boosting Classifier - 96%"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}