{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\n# print(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\npath = '../input/winequality-red.csv'\ndata = pd.read_csv(path)\nY = data.quality\nX = data.iloc[:, :11]\n\n# Preprocessing data\npoints = (2, 6.5, 8)\ngroup_names = ['bad wine', 'good wine']\ndata['quality'] = pd.cut(data['quality'], bins=points, labels=group_names)\n\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nlabel = LabelEncoder()\ndata['quality'] = label.fit_transform(data['quality'])\n    \nfrom sklearn.model_selection import train_test_split\ntrain_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.1, random_state=42)\n\nscale = StandardScaler()\ntrain_X = scale.fit_transform(train_X)\ntest_X = scale.fit_transform(test_X)\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import classification_report\n\n\ndef test_models(amount_leafes):\n    model_2 = RandomForestClassifier(max_depth=amount_leafes, n_estimators=50)\n    model_2.fit(train_X, train_Y)\n    return model_2, cross_val_score(model_2, train_X, train_Y)\n\nbest_score = 0\nscore = 0\nopt_amount_leafes = 0\nfor i in [27, 28, 30, 31, 32, 33]:\n    model, score = test_models(i)\n    if max(score) > best_score:\n        best_score = max(score)\n        final_model = model\n    print(score)\npred_val = final_model.predict(test_X)\n\nprint('Algorithm is RandomForest')\nprint(classification_report(test_Y, pred_val))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"08bd60eddc272fa14524dae47c627933ebc9b70c"},"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.model_selection import cross_val_score\n\n\ndef test_models_xg_boost(amount_leafes):\n    model_1 = XGBClassifier(amount_leafes)\n    model_1.fit(train_X, train_Y)\n    return model_1, cross_val_score(model, train_X, train_Y)\n\nbest_score = 0\nscore = 0\nfor i in [27, 28, 30, 31, 32, 33]:\n    model, score = test_models_xg_boost(i)\n    if max(score) > best_score:\n        best_score = max(score)\n        final_model = model\n\npredicted_value = final_model.predict(test_X)\nprint('Algorithm is XGBClassifier')\nprint(classification_report(test_Y, predicted_value))\n\nmy_submission = pd.DataFrame({'Quality': predicted_value})\nmy_submission.to_csv('my_submission', index=False)","execution_count":6,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}