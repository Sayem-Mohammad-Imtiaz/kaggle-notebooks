{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport random\nimport time\nfrom skimage import io, transform\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def load_images(path):\n    \"\"\"\n    \n    Arguments:\n    path (str) -- path to images\n    \n    Returns:\n    images (list) -- list with images;\n    labels (list) -- list with labels;\n    \n    \"\"\"\n    classes = [i for i in range(43)]\n    images = []\n    labels = []\n    for new_class in classes:\n        new_path = path + str(new_class) + \"/\"\n        file_names = [os.path.join(new_path, f)\n                     for f in os.listdir(new_path)]\n        \n        for file in file_names:\n            images.append(io.imread(file))\n            labels.append(new_class)\n    \n    return images, labels\n\n\ntrain_images, train_labels = load_images(\"../input/train/\")       ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.read_csv(\"../input/Test.csv\")\ntest_labels = test_data['ClassId'].values\npaths = test_data['Path'].values\n\n\ndef load_test_images(paths):\n    \"\"\"\n    \n    Arguments:\n    paths (str) -- paths to images;\n    \n    Returns:\n    images (list) - list with images;\n    \n    \"\"\"\n    images = []\n    for f in paths:\n        image = io.imread('../input/test/' + f.replace('Test/', ''))\n        images.append(image)\n    return images\n\ntest_images = load_test_images(paths)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NUM_CLASSES = 43\ntrain_images = np.array(train_images)\ntrain_labels = np.array(train_labels)\ntest_images = np.array(test_images)\ntest_labels = np.array(test_labels)\n\nprint(\"Shape of train images is \" + str(train_images.shape))\nprint(\"Shape of train labels is \" + str(train_labels.shape))\nprint(\"Shape of test images is \" + str(test_images.shape))\nprint(\"Shape of test labels is \" + str(test_labels.shape))\nprint(\"Amount of classes is \" + str(NUM_CLASSES))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_images(images, labels, amount):\n    \"\"\"\n    \n    Arguments:\n    images (np.array) -- list with images;\n    labels (np.array) -- list with labels\n    amount (int) -- amount of images to show.\n    \n    \"\"\"\n    \n    for i in range(amount):\n        index = int(random.random() * len(images))\n        plt.axis('off')\n        plt.imshow(images[index])\n        plt.show()\n        \n        print(\"Size of this image is \" + str(images[index].shape))\n        print(\"Class of the image is \" + str(labels[index]))\n\n        \nprint(\"Train images\")\nshow_images(train_images, train_labels, 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Test images\")\nshow_images(test_images, test_labels, 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def change_images_size(images, size):\n    \"\"\"\n    \n    Arguments:\n    images (np.array) -- list with images;\n    size (tuple) -- new shape of images.\n    \n    Returns:\n    new_images (np.array) -- np.array with new shape of images. \n    \n    \"\"\"\n    \n    print(\"Change shape...\")\n    new_images = np.array([transform.resize(image, size) for image in images])\n    \n    print(\"Done!\")\n    return new_images\n\ntrain_images = change_images_size(train_images, (51, 51))\ntest_images = change_images_size(test_images, (51, 51))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images /= 255.\ntest_images /= 255.\n\ntrain_images = train_images.reshape(train_images.shape[0], -1).T\ntest_images = test_images.reshape(test_images.shape[0], -1).T\ntrain_labels = np.eye(NUM_CLASSES)[train_labels.reshape(-1)].T\ntest_labels = np.eye(NUM_CLASSES)[test_labels.reshape(-1)].T\n\nprint(\"Train images shape is \" + str(train_images.shape))\nprint(\"Train labels shape is \" + str(train_labels.shape))\nprint(\"Test images shape is \" + str(test_images.shape))\nprint(\"Test labels shape is \" + str(test_labels.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_placeholder(n_x, n_y):\n    \"\"\"\n    \n    Arguments:\n    n_x (int) -- amount of input neurons;\n    n_y (int) -- amount of classes;\n    \n    Returns:\n    X (tf.placeholder) -- placeholder for data imput;\n    Y (tf.placeholder) -- placeholder for imput labels.\n    \n    \"\"\"\n    \n    X = tf.placeholder(tf.float32, (n_x, None))\n    Y = tf.placeholder(tf.float32, (n_y, None))\n    \n    return X, Y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def initialize_parameters():\n    \"\"\"\n    \n    Initialize parameters for neural network.\n    \n    \"\"\"\n    \n    W1 = tf.get_variable('W1', [625, 7803], initializer=tf.contrib.layers.xavier_initializer())\n    b1 = tf.get_variable('b1', [625, 1], initializer=tf.zeros_initializer())\n    W2 = tf.get_variable('W2', [125, 625], initializer=tf.contrib.layers.xavier_initializer())\n    b2 = tf.get_variable('b2', [125, 1], initializer=tf.zeros_initializer())\n    W3 = tf.get_variable('W3', [75, 125], initializer=tf.contrib.layers.xavier_initializer())\n    b3 = tf.get_variable('b3', [75, 1], initializer=tf.zeros_initializer())\n    W4 = tf.get_variable('W4', [43, 75], initializer=tf.contrib.layers.xavier_initializer())\n    b4 = tf.get_variable('b4', [43, 1], initializer=tf.zeros_initializer())\n    \n    parameters = dict()\n    \n    parameters['W1'] = W1\n    parameters['b1'] = b1\n    parameters['W2'] = W2\n    parameters['b2'] = b2\n    parameters['W3'] = W3\n    parameters['b3'] = b3\n    parameters['W4'] = W4\n    parameters['b4'] = b4\n    \n    return parameters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def forward_propogation(X, parameters, training):\n    \"\"\"\n    \n    Arguments:\n    X (tf.placeholder) -- input images;\n    parameters (dict) -- model parameters;\n    \n    Returns:\n    \n    Z3 -- output of NN.\n    \n    \"\"\"\n    \n    W1 = parameters['W1']\n    b1 = parameters['b1']\n    W2 = parameters['W2']\n    b2 = parameters['b2']\n    W3 = parameters['W3']\n    b3 = parameters['b3']\n    W4 = parameters['W4']\n    b4 = parameters['b4']\n    \n    Z1 = tf.add(tf.matmul(W1, X), b1)                                              \n    A1 = tf.nn.leaky_relu(Z1)\n    A1_dropout = tf.layers.dropout(A1, training=training)\n    Z2 = tf.add(tf.matmul(W2, A1_dropout), b2)                                            \n    A2 = tf.nn.leaky_relu(Z2)\n    A2_dropout = tf.layers.dropout(A2, training=training)\n    Z3 = tf.add(tf.matmul(W3, A2_dropout), b3)\n    A3 = tf.nn.leaky_relu(Z3)\n    A3_dropout = tf.layers.dropout(A3, training=training)\n    Z4 = tf.add(tf.matmul(W4, A3_dropout), b4)\n    \n    return Z4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_cost(Z3, Y):\n    \"\"\"\n    \n    Arguments:\n    Z3 - output of NN;\n    Y - input labels.\n    \n    Returns:\n    cost (tf.tensor) -- tensor of cost function.\n    \n    \"\"\"\n    logits = tf.transpose(Z3)\n    labels = tf.transpose(Y)\n    \n    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n    \n    return cost","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model(X_train, Y_train, X_test, Y_test, num_epochs, learning_rate=0.001):\n    \n    \"\"\"\n    \n    Arguments:\n    X_train (np.array) -- train images for NN;\n    Y_train (np.array) -- train labels for NN;\n    X_test (np.array) -- test_images for NN;\n    Y_test (np,array) -- test_labels for NN;\n    num_epochs (int) -- amount of epochs.\n    \n    \"\"\"\n    tf.reset_default_graph()\n    tf.set_random_seed(1)\n    \n    n_x, m = X_train.shape[0], X_train.shape[1]\n    n_y = Y_train.shape[0]\n    \n    X, Y = create_placeholder(n_x, n_y)\n    \n    parameters = initialize_parameters()\n    \n    Z3 = forward_propogation(X, parameters, True)\n    \n    Z3_test = forward_propogation(X, parameters, False)\n    \n    cost = compute_cost(Z3, Y)\n    \n    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n    \n    costs = []\n    \n    init = tf.global_variables_initializer()\n    \n    max_accuracy = 0\n    \n    with tf.Session() as sess:\n        \n        sess.run(init)\n        \n        print(\"I am learning\")\n        \n        start_time = time.time()\n        \n        for i in range(num_epochs):\n            \n            _, t_cost  = sess.run([optimizer, cost], feed_dict={X: X_train, Y: Y_train})\n            \n            if i % 10 == 0 or i == num_epochs - 1:\n                print(\"Cost after \" + str(i) + \" epoch is \" + str(t_cost) + \" |\", end=\" \")\n                costs.append(t_cost)\n                \n                correct_pred = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n                accuracy = tf.reduce_mean(tf.cast(correct_pred, 'float'))\n                \n                test_pred = tf.equal(tf.argmax(Z3_test), tf.argmax(Y))\n                accuracy_2 = tf.reduce_mean(tf.cast(test_pred, 'float'))\n        \n                train_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n                test_accuracy = accuracy_2.eval({X: X_test, Y: Y_test})\n                \n                if test_accuracy > max_accuracy:\n                    max_accuracy = test_accuracy\n                    epoch = i\n                \n                print(\"Train accuracy is \" + str(train_accuracy) + \" |\", end=\" \")\n                print(\"Test accuracy is \" + str(test_accuracy))\n        \n        print(\"Done!\")\n        print()\n        \n        end_time = time.time()\n                \n        parameters = sess.run(parameters)\n        \n        print(\"The best test accuracy is \" + str(max_accuracy))\n        print(\"Amount of epochs is \" + str(epoch))\n        print(\"The speed of the algorithm is \" + str(end_time - start_time) + \" seconds\")\n        \n    plt.plot(np.squeeze(costs))\n    plt.xlabel('iterations')\n    plt.ylabel('cost')\n    plt.title(\"Learning rate is \" + str(learning_rate))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model(train_images, train_labels, test_images, test_labels, 1000)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}