{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1.1.Importing Libraries","metadata":{}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set(style='whitegrid')\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.2.Importing Data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/breast-cancer-wisconsin-data/data.csv')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image.\nn the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\n\n\nAttribute Information:\n1. ID number\n1. Diagnosis (M = malignant, B = benign)\n\nTen real-valued features are computed for each cell nucleus:\n\n1. radius (mean of distances from center to points on the perimeter)\n1. texture (standard deviation of gray-scale values)\n1. perimeter\n1. area\n1. smoothness (local variation in radius lengths)\n1. compactness (perimeter^2 / area - 1.0)\n1. concavity (severity of concave portions of the contour)\n1. concave points (number of concave portions of the contour)\n1. symmetry\n1. fractal dimension (\"coastline approximation\" - 1)\n\nThe mean, standard error and \"worst\" or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features. All feature values are recoded with four significant digits.","metadata":{}},{"cell_type":"markdown","source":"## 1.3.Data Analysis","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Count the number of empty values in each column:\n","metadata":{}},{"cell_type":"code","source":"df.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We delete the column 'Unnamed: 32' because it does not affect the data set.","metadata":{}},{"cell_type":"code","source":"df.drop(['Unnamed: 32'], axis = 1 , inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labelencoder_Y = LabelEncoder()\ndf.iloc[:,1] = labelencoder_Y.fit_transform(df.iloc[:,1].values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.iloc[:,1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We converted the diagnosis values to numerical values. B=0 and M=1","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2.Data Visualization","metadata":{}},{"cell_type":"markdown","source":"## 2.1.Diagnosis Values","metadata":{}},{"cell_type":"code","source":"df['diagnosis'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(df['diagnosis'], label = 'Count')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.2.Correlation Map","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,15))\nsns.heatmap(df.corr(), annot=True, cmap='viridis')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.heatmap(df[[df.columns[1],df.columns[2], df.columns[3],df.columns[4],df.columns[5],\n                     df.columns[6], df.columns[7], df.columns[8],df.columns[9],df.columns[10],df.columns[11]]].corr(),linewidths=.1,cmap=\"YlGnBu\", annot=True)\nplt.yticks(rotation=0);\nplt.suptitle('Correlation Map')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.3.Distribution Charts","metadata":{}},{"cell_type":"code","source":"sns.pairplot(df[['diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n       'area_mean', 'smoothness_mean', 'compactness_mean']], hue = 'diagnosis')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3.Model Building","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.cluster import KMeans\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, BaggingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import svm\nfrom keras.models import Sequential \nfrom keras.layers import Dense\nfrom sklearn.metrics import confusion_matrix","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First, We delete the \"id\" column as it will not contribute to model training.","metadata":{}},{"cell_type":"code","source":"df.drop(columns=\"id\", inplace=True, errors=\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We define the \"diagnosis\" column to y and the other columns to X.","metadata":{}},{"cell_type":"code","source":"X = df.iloc[:,1:31].values\ny = df.iloc[:,0].values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will divide our data into 4 variables; The x_train and y_train variables for training, x_test and y_test variables to test the model at the end of the training.\n\nThe test_size parameter specifies what percentage of the data set should be reserved for testing","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.1. Logistic Regression","metadata":{}},{"cell_type":"code","source":"lr_model = LogisticRegression()\nlr_model.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_prediction = lr_model.predict(X_test)\nlr_prediction","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_acc = accuracy_score(y_test,lr_prediction)\nlr_re = recall_score(y_test,lr_prediction)\nlr_pr = precision_score(y_test,lr_prediction)\nlr_f1 = f1_score(y_test,lr_prediction)\nprint(\"Accuracy score:\",lr_acc)\nprint(\"Recall score:\",lr_re)\nprint(\"Precision score:\",lr_pr)\nprint(\"f1 score:\",lr_f1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(lr_model,X_test, y_test,cmap= plt.cm.Blues)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.2.KNeighborsClassifier","metadata":{}},{"cell_type":"code","source":"KNN = KNeighborsClassifier(n_neighbors=7, metric='minkowski', p = 2)\nKNN.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"KNN_predictions = KNN.predict(X_test)\nKNN_predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"KNN_acc = accuracy_score(y_test,KNN_predictions)\nKNN_re = recall_score(y_test,KNN_predictions)\nKNN_pr = precision_score(y_test,KNN_predictions)\nKNN_f1 = f1_score(y_test,KNN_predictions)\nprint(\"Accuracy score:\",KNN_acc)\nprint(\"Recall score:\",KNN_re)\nprint(\"Precision score:\",KNN_pr)\nprint(\"f1 score:\",KNN_f1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(KNN,X_test, y_test,cmap= plt.cm.Blues)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.3.Decision Tree","metadata":{}},{"cell_type":"code","source":"dt_classifier = DecisionTreeClassifier(random_state=42)\ndt_classifier.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dt_predictions = dt_classifier.predict(X_test)\ndt_predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dt_acc = accuracy_score(y_test,dt_predictions)\ndt_re = recall_score(y_test,dt_predictions)\ndt_pr = precision_score(y_test,dt_predictions)\ndt_f1 = f1_score(y_test,dt_predictions)\nprint(\"Accuracy score:\",dt_acc)\nprint(\"Recall score:\",dt_re)\nprint(\"Precision score:\",dt_pr)\nprint(\"f1 score:\",dt_f1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(dt_classifier,X_test, y_test,cmap= plt.cm.Blues)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.4.Random Forest Classifier","metadata":{}},{"cell_type":"code","source":"rf_classifier = RandomForestClassifier(random_state=42)\nrf_classifier.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_predictions = rf_classifier.predict(X_test)\nrf_predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_acc = accuracy_score(y_test,rf_predictions)\nrf_re = recall_score(y_test,rf_predictions)\nrf_pr = precision_score(y_test,rf_predictions)\nrf_f1 = f1_score(y_test,rf_predictions)\nprint(\"Accuracy score:\",rf_acc)\nprint(\"Recall score:\",rf_re)\nprint(\"Precision score:\",rf_pr)\nprint(\"f1 score:\",rf_f1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(rf_classifier,X_test, y_test,cmap= plt.cm.Blues)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.5.Gaussian Naive Bayes ","metadata":{}},{"cell_type":"code","source":"Gnb = GaussianNB() \nGnb.fit(X_train, y_train) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Gnb_predictions = Gnb.predict(X_test)\nGnb_predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Gnb_acc = accuracy_score(y_test,Gnb_predictions)\nGnb_re = recall_score(y_test,Gnb_predictions)\nGnb_pr = precision_score(y_test,Gnb_predictions)\nGnb_f1 = f1_score(y_test,Gnb_predictions)\nprint(\"Accuracy score:\",Gnb_acc)\nprint(\"Recall score:\",Gnb_re)\nprint(\"Precision score:\",Gnb_pr)\nprint(\"f1 score:\",Gnb_f1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(Gnb,X_test, y_test,cmap= plt.cm.Blues)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.6. Support Vector Machine","metadata":{}},{"cell_type":"code","source":"svm_model = svm.SVC(random_state=42)\nsvm_model.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svm_prediction = svm_model.predict(X_test)\nsvm_prediction","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svm_acc = accuracy_score(y_test,svm_prediction)\nsvm_re = recall_score(y_test,svm_prediction)\nsvm_pr = precision_score(y_test,svm_prediction)\nsvm_f1 = f1_score(y_test,svm_prediction)\nprint(\"Accuracy score:\",svm_acc)\nprint(\"Recall score:\",svm_re)\nprint(\"Precision score:\",svm_pr)\nprint(\"f1 score:\",svm_f1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(svm_model,X_test, y_test,cmap= plt.cm.Blues)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.7.Artificial Neural Network (ANN)","metadata":{}},{"cell_type":"code","source":"ANN_model = Sequential() \nANN_model.add(Dense(activation = \"relu\", input_dim = 30,  \n                     units = 8, kernel_initializer = \"uniform\")) \nANN_model.add(Dense(activation = \"relu\", units = 14,  \n                     kernel_initializer = \"uniform\")) \nANN_model.add(Dense(activation = \"sigmoid\", units = 1,  \n                     kernel_initializer = \"uniform\")) \nANN_model.compile(optimizer = 'adam' , loss = 'binary_crossentropy',  \n                   metrics = ['accuracy'] ) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ANN_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ANN_model.fit(X_train , y_train , batch_size = 8 ,epochs = 400 )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ANN_prediction = ANN_model.predict(X_test) \nANN_prediction = (ANN_prediction > 0.5) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ANN_acc = accuracy_score(y_test,ANN_prediction)\nANN_re = recall_score(y_test,ANN_prediction)\nANN_pr = precision_score(y_test,ANN_prediction)\nANN_f1 = f1_score(y_test,ANN_prediction)\nprint(\"Accuracy score:\",ANN_acc)\nprint(\"Recall score:\",ANN_re )\nprint(\"Precision score:\",ANN_pr)\nprint(\"f1 score:\",ANN_f1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cmann = confusion_matrix(y_test,ANN_prediction) \nprint(cmann)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4.Comparison of Models","metadata":{}},{"cell_type":"code","source":"models = [('Logistic Regression',lr_acc,lr_pr,lr_re,lr_f1),\n          ('K-Nearest Neighbors (KNN)',KNN_acc,KNN_pr,KNN_re,KNN_f1),\n          ('Decision Tree Classifier',dt_acc,dt_pr,dt_re,dt_f1),\n          ('Random Forest Classifier',rf_acc,rf_pr,rf_re,rf_f1),\n          ('Gaussian Naive Bayes',Gnb_acc,Gnb_pr,Gnb_re,Gnb_f1),\n          ('Support Vector Machine (SVM)',svm_acc,svm_pr,svm_re,svm_f1),\n          ('Artificial Neural Network (ANN)',ANN_acc,ANN_pr,ANN_re,ANN_f1)]\n\nComp_models = pd.DataFrame(data = models, columns=['Model','Accuracy Score','Precision Score','Recall Score','F1 Score'])\nComp_models","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.catplot(x='Model',y='Accuracy Score',data=Comp_models,kind='point',height=4,aspect=4.5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5.PCA: Principal Component Analysis","metadata":{}},{"cell_type":"code","source":"standard_scaler = StandardScaler()\nstandard_scaler.fit(df)\n\nscaled_features = standard_scaler.transform(df)\n\nscaled_features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.decomposition import PCA\npca_model = PCA(n_components=3)\npca_model.fit(scaled_features)\n\nX_pca = pca_model.transform(scaled_features)\n\nprint('Shape of the dataset after PCA transformation is {}'.format(X_pca.shape))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca_df = pd.DataFrame(X_pca, columns=['pca0', 'pca1', 'pca2'])          \npca_df['diagnosis'] = df['diagnosis']\nprint('Shape of PCA dataset is {}'.format(pca_df.shape))\npca_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_target  = df['diagnosis']\nX = pca_df.drop(['diagnosis'], axis=1)\ny = df_target \n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nb_model_pca = GaussianNB()\nnb_model_pca.fit(X_train, y_train)\nnb_predict_pca = nb_model_pca.predict(X_test)\nnb_accuracy_pca = accuracy_score(y_test, nb_predict_pca)\n\nprint('The accuracy score after PCA using Naive bayes : ',nb_accuracy_pca)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_pca = RandomForestClassifier(random_state=42)\nrf_pca.fit(X_train, y_train)\nrf_pca_predict = rf_pca.predict(X_test)\nrf_acc_pca = accuracy_score(y_test,rf_pca_predict) \n\nprint('The accuracy score after PCA using Random Forest : ',rf_acc_pca)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"KNN_pca = KNeighborsClassifier(n_neighbors=7, metric='minkowski', p = 2)\nKNN_pca.fit(X_train, y_train)\nKNN_pca_predict = KNN_pca.predict(X_test)\nKNN_acc_pca = accuracy_score(y_test,KNN_pca_predict)\n\nprint('The accuracy score after PCA using KNN : ',KNN_acc_pca)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dt_pca = DecisionTreeClassifier(random_state=42)\ndt_pca.fit(X_train, y_train)\ndt_pca_predict = dt_pca.predict(X_test)\ndt_acc_pca = accuracy_score(y_test,dt_pca_predict) \n\nprint('The accuracy score after PCA using Decision Tree : ',dt_acc_pca)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svm_model_pca = svm.SVC(random_state=42)\nsvm_model_pca.fit(X_train, y_train)\nsvm_predict_pca = svm_model_pca.predict(X_test)\nsvm_accuracy_pca = accuracy_score(y_test, svm_predict_pca)\n\nprint('The accuracy score after PCA using Suppoer Vector Machine : ',svm_accuracy_pca)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_model_pca = LogisticRegression()\nlr_model_pca.fit(X_train, y_train)\nlr_predict_pca = lr_model_pca.predict(X_test)\nlr_accuracy_pca = accuracy_score(y_test, lr_predict_pca)\n\nprint('The accuracy score after PCA using Logistic Regression : ',lr_accuracy_pca)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = [('K-Nearest Neighbors (KNN)',KNN_acc,KNN_acc_pca),\n         ('Random Forest Classifier',rf_acc,rf_acc_pca),\n         ('Gaussian Naive Bayes',Gnb_acc,nb_accuracy_pca),\n          ('Decision Tree Classifier',dt_acc,dt_acc_pca),\n         ('Suppoer Vector Machine',svm_acc,svm_accuracy_pca),\n         ('Logistic Regression',lr_acc,lr_accuracy_pca)]\n\nComp_models = pd.DataFrame(data = models, columns=['Model','Accuracy without PCA','Accuracy with PCA'])\nComp_models","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6.Comparison of Test&Train Percentage","metadata":{}},{"cell_type":"markdown","source":"While training the previous models, we allocated 20% of the model for testing. Now, let's compare the accuracy results of models with different ratios.","metadata":{}},{"cell_type":"markdown","source":"## 25% rate for testing","metadata":{}},{"cell_type":"code","source":"X25_train, X25_test, y25_train, y25_test = train_test_split(X, y, test_size=0.25, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Logistic Regression\nlr_model_25=LogisticRegression()\nlr_model_25.fit(X25_train, y25_train)\nlr_prediction_25 = lr_model_25.predict(X25_test)\nlr_acc_25 = accuracy_score(y25_test,lr_prediction_25)\n\n#KNeighborsClassifier\nKNN_25 = KNeighborsClassifier(n_neighbors=7, metric='minkowski', p = 2)\nKNN_25.fit(X25_train, y25_train)\nKNN_predictions_25 = KNN_25.predict(X25_test)\nKNN_acc_25 = accuracy_score(y25_test,KNN_predictions_25)\n\n#Decision Tree\ndt_classifier_25 = DecisionTreeClassifier(random_state=42)\ndt_classifier_25.fit(X25_train, y25_train)\ndt_predictions_25 = dt_classifier_25.predict(X25_test)\ndt_acc_25 = accuracy_score(y25_test,dt_predictions_25)\n\n#Random Forest Classifier\nrf_classifier_25 = RandomForestClassifier(random_state=42)\nrf_classifier_25.fit(X25_train, y25_train)\nrf_predictions_25 = rf_classifier_25.predict(X25_test)\nrf_acc_25 = accuracy_score(y25_test,rf_predictions_25)\n\n#Gaussian Naive Bayes\nGnb_25 = GaussianNB() \nGnb_25.fit(X25_train, y25_train) \nGnb_predictions_25 = Gnb_25.predict(X25_test)\nGnb_acc_25 = accuracy_score(y25_test,Gnb_predictions_25)\n\n#Support Vector Machine\nsvm_model_25 = svm.SVC(random_state=42)\nsvm_model_25.fit(X25_train, y25_train)\nsvm_prediction_25 = svm_model_25.predict(X25_test)\nsvm_acc_25 = accuracy_score(y25_test,svm_prediction_25)\n\n#Artificial Neural Network (ANN)\n#ANN_model_25 = Sequential() \n#ANN_model_25.add(Dense(activation = \"relu\", input_dim = 30,  \n#                     units = 8, kernel_initializer = \"uniform\")) \n#ANN_model_25.add(Dense(activation = \"relu\", units = 14,  \n#                     kernel_initializer = \"uniform\")) \n#ANN_model_25.add(Dense(activation = \"sigmoid\", units = 1,  \n#                     kernel_initializer = \"uniform\")) \n#ANN_model_25.compile(optimizer = 'adam' , loss = 'binary_crossentropy',  \n#                   metrics = ['accuracy'] ) \n#ANN_model_25.fit(X25_train , y25_train , batch_size = 8 ,epochs = 400 )\n#ANN_prediction_25 = ANN_model_25.predict(X25_test) \n#ANN_prediction_25 = (ANN_prediction_25 > 0.5) \n#ANN_acc_25 = accuracy_score(y25_test,ANN_prediction_25)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 30% rate for testing","metadata":{}},{"cell_type":"code","source":"X30_train, X30_test, y30_train, y30_test = train_test_split(X, y, test_size=0.30, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Logistic Regression\nlr_model_30=LogisticRegression()\nlr_model_30.fit(X30_train, y30_train)\nlr_prediction_30 = lr_model_30.predict(X30_test)\nlr_acc_30 = accuracy_score(y30_test,lr_prediction_30)\n\n#KNeighborsClassifier\nKNN_30 = KNeighborsClassifier(n_neighbors=7, metric='minkowski', p = 2)\nKNN_30.fit(X30_train, y30_train)\nKNN_predictions_30 = KNN_30.predict(X30_test)\nKNN_acc_30 = accuracy_score(y30_test,KNN_predictions_30)\n\n#Decision Tree\ndt_classifier_30 = DecisionTreeClassifier(random_state=42)\ndt_classifier_30.fit(X30_train, y30_train)\ndt_predictions_30 = dt_classifier_30.predict(X30_test)\ndt_acc_30 = accuracy_score(y30_test,dt_predictions_30)\n\n#Random Forest Classifier\nrf_classifier_30 = RandomForestClassifier(random_state=42)\nrf_classifier_30.fit(X30_train, y30_train)\nrf_predictions_30 = rf_classifier_30.predict(X30_test)\nrf_acc_30 = accuracy_score(y30_test,rf_predictions_30)\n\n#Gaussian Naive Bayes\nGnb_30 = GaussianNB() \nGnb_30.fit(X30_train, y30_train) \nGnb_predictions_30 = Gnb_30.predict(X30_test)\nGnb_acc_30 = accuracy_score(y30_test,Gnb_predictions_30)\n\n#Support Vector Machine\nsvm_model_30 = svm.SVC(random_state=42)\nsvm_model_30.fit(X30_train, y30_train)\nsvm_prediction_30 = svm_model_30.predict(X30_test)\nsvm_acc_30 = accuracy_score(y30_test,svm_prediction_30)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 35% rate for testing","metadata":{}},{"cell_type":"code","source":"X35_train, X35_test, y35_train, y35_test = train_test_split(X, y, test_size=0.35, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Logistic Regression\nlr_model_35= LogisticRegression()\nlr_model_35.fit(X35_train, y35_train)\nlr_prediction_35 = lr_model_35.predict(X35_test)\nlr_acc_35 = accuracy_score(y35_test,lr_prediction_35)\n\n#KNeighborsClassifier\nKNN_35 = KNeighborsClassifier(n_neighbors=7, metric='minkowski', p = 2)\nKNN_35.fit(X35_train, y35_train)\nKNN_predictions_35 = KNN_35.predict(X35_test)\nKNN_acc_35 = accuracy_score(y35_test,KNN_predictions_35)\n\n#Decision Tree\ndt_classifier_35 = DecisionTreeClassifier(random_state=42)\ndt_classifier_35.fit(X35_train, y35_train)\ndt_predictions_35 = dt_classifier_35.predict(X35_test)\ndt_acc_35 = accuracy_score(y35_test,dt_predictions_35)\n\n#Random Forest Classifier\nrf_classifier_35 = RandomForestClassifier(random_state=42)\nrf_classifier_35.fit(X35_train, y35_train)\nrf_predictions_35 = rf_classifier_35.predict(X35_test)\nrf_acc_35 = accuracy_score(y35_test,rf_predictions_35)\n\n#Gaussian Naive Bayes\nGnb_35 = GaussianNB() \nGnb_35.fit(X35_train, y35_train) \nGnb_predictions_35 = Gnb_35.predict(X35_test)\nGnb_acc_35 = accuracy_score(y35_test,Gnb_predictions_35)\n\n#Support Vector Machine\nsvm_model_35 = svm.SVC(random_state=42)\nsvm_model_35.fit(X35_train, y35_train)\nsvm_prediction_35 = svm_model_35.predict(X35_test)\nsvm_acc_35 = accuracy_score(y35_test,svm_prediction_35)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Comparison of Accuracy Scores","metadata":{}},{"cell_type":"code","source":"models_total = [('Logistic Regression',lr_acc,lr_acc_25,lr_acc_30,lr_acc_35 ),\n          ('K-Nearest Neighbors (KNN)',KNN_acc,KNN_acc_25,KNN_acc_30,KNN_acc_35 ),\n          ('Decision Tree Classifier',dt_acc,dt_acc_25,dt_acc_30,dt_acc_35 ),\n          ('Random Forest Classifier',rf_acc,rf_acc_25,rf_acc_30,rf_acc_35 ),\n          ('Gaussian Naive Bayes',Gnb_acc,Gnb_acc_25,Gnb_acc_30,Gnb_acc_35 ),\n          ('Support Vector Machine (SVM)',svm_acc,svm_acc_25,svm_acc_30,svm_acc_35 )]\n\nComp_models_total = pd.DataFrame(data = models_total, columns=['Model','Accuracy Score-20%','Accuracy Score-25%','Accuracy Score-30%','Accuracy Score-35%'])\nComp_models_total","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7.Grid Search Application on Models","metadata":{}},{"cell_type":"markdown","source":"## 7.1.Logistic Regression ","metadata":{}},{"cell_type":"code","source":"lr_gs = LogisticRegression()\nlr_params = {\n    'penalty' : ['l2','elasticnet','none'],\n    'class_weight' : ['dict','balanced','None'],\n    'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n    'multi_class' : ['auto', 'ovr', 'multinomial']\n}\ngs_lr = GridSearchCV(estimator = lr_gs, param_grid = lr_params, scoring = 'accuracy', \n                        cv = 5, verbose = 1, n_jobs = -1)\ngs_lr.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gs_lr.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Grid_lr = LogisticRegression(class_weight='dict',multi_class='auto',penalty='l2',solver='newton-cg')\nGrid_lr.fit(X_train, y_train)\nGrid_lr_predictions = Grid_lr.predict(X_test)\nGrid_lr_acc = accuracy_score(y_test,Grid_lr_predictions)\nprint(\"Accuracy score with Grid Search:\",Grid_lr_acc)\nprint(\"Accuracy score without Grid Search:\",lr_acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(Grid_lr,X_test, y_test,cmap= plt.cm.Blues)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7.2.KNeighborsClassifier ","metadata":{}},{"cell_type":"code","source":"KNN_gs = KNeighborsClassifier()\nKNN_params = {\n    'n_neighbors' : [5,7,9,11,13,15,19,23],\n    'algorithm': ['auto','ball_tree', 'kd_tree', 'brute'],\n    'p' : [1,2]\n}\ngs_knn = GridSearchCV(estimator = KNN_gs, param_grid = KNN_params, scoring = 'accuracy', \n                        cv = 5, verbose = 1, n_jobs = -1)\ngs_knn.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gs_knn.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Grid_KNN = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p = 2 ,algorithm='auto')\nGrid_KNN.fit(X_train, y_train)\nGrid_KNN_predictions = Grid_KNN.predict(X_test)\nGrid_KNN_acc = accuracy_score(y_test,Grid_KNN_predictions)\nprint(\"Accuracy score with Grid Search:\",Grid_KNN_acc)\nprint(\"Accuracy score without Grid Search:\",KNN_acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(Grid_KNN,X_test, y_test,cmap= plt.cm.Blues)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7.3.Decision Tree","metadata":{}},{"cell_type":"code","source":"dt_classifier_gs = DecisionTreeClassifier()\ndt_classifier_params = {\n    'criterion': ['gini', 'entropy'],\n    'splitter' : ['best', 'random'],\n    'max_features' : ['auto','sqrt','log2',None],\n    'class_weight' : ['dict', 'balanced', None]\n\n}\ngs_dt_classifier = GridSearchCV(estimator = dt_classifier_gs, param_grid = dt_classifier_params, scoring = 'accuracy', \n                        cv = 5, verbose = 1, n_jobs = -1)\ngs_dt_classifier.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gs_dt_classifier.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Grid_dt = DecisionTreeClassifier(class_weight=None, criterion='entropy', max_features=None, splitter='random',random_state=42)\nGrid_dt.fit(X_train, y_train)\nGrid_dt_predictions = Grid_dt.predict(X_test)\nGrid_dt_acc = accuracy_score(y_test,Grid_dt_predictions)\nprint(\"Accuracy score with Grid Search:\",Grid_dt_acc)\nprint(\"Accuracy score without Grid Search:\",dt_acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(Grid_dt,X_test, y_test,cmap= plt.cm.Blues)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7.4.Random Forest Classifier","metadata":{}},{"cell_type":"code","source":"rf_classifier_gs = RandomForestClassifier()\nrf_classifier_params = {\n    'criterion': ['gini', 'entropy'],\n    'max_features' : ['auto','sqrt','log2',None]\n\n}\ngs_rf_classifier = GridSearchCV(estimator = rf_classifier_gs, param_grid = rf_classifier_params, scoring = 'accuracy', \n                        cv = 5, verbose = 1, n_jobs = -1)\ngs_rf_classifier.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gs_rf_classifier.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Grid_rf = RandomForestClassifier(criterion='entropy', max_features=None,random_state=42)\nGrid_rf.fit(X_train, y_train)\nGrid_rf_predictions = Grid_rf.predict(X_test)\nGrid_rf_acc = accuracy_score(y_test,Grid_rf_predictions)\nprint(\"Accuracy score with Grid Search:\",Grid_rf_acc)\nprint(\"Accuracy score without Grid Search:\",rf_acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(Grid_rf,X_test, y_test,cmap= plt.cm.Blues)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7.5.Gaussian Naive Bayes","metadata":{}},{"cell_type":"code","source":"Gnb_gs = GaussianNB() \nGnb_params = {\n    'var_smoothing': np.logspace(0,-9, num=100)\n}\ngs_Gnb = GridSearchCV(estimator = Gnb_gs, param_grid = Gnb_params, scoring = 'accuracy', \n                        cv = 5, verbose = 1, n_jobs = -1)\ngs_Gnb.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gs_Gnb.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Grid_Gnb = GaussianNB(var_smoothing= 0.15199110829529336 )\nGrid_Gnb.fit(X_train, y_train)\nGrid_Gnb_predictions = Grid_Gnb.predict(X_test)\nGrid_Gnb_acc = accuracy_score(y_test,Grid_Gnb_predictions)\nprint(\"Accuracy score with Grid Search:\",Grid_Gnb_acc)\nprint(\"Accuracy score without Grid Search:\",Gnb_acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(Grid_Gnb,X_test, y_test,cmap= plt.cm.Blues)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7.6.Support Vector Machine","metadata":{}},{"cell_type":"code","source":"svm_model_gs = svm.SVC()\nsvm_model_params = {\n    'degree' : [2,3,4,5,6],\n    'gamma' : ['scale','auto'],\n    'shrinking' : [True,False],\n    'probability' : [True, False],\n    'class_weight' : ['dict', 'balanced', None],\n    'verbose' : [True, False],\n    'decision_function_shape' : ['ovo', 'ovr']\n}\ngs_svm_model = GridSearchCV(estimator = svm_model_gs, param_grid = svm_model_params, scoring = 'accuracy', \n                        cv = 5, verbose = 1, n_jobs = -1)\ngs_svm_model.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gs_svm_model.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Grid_svm = svm.SVC(class_weight = None, decision_function_shape='ovo',degree=2,gamma='scale',probability=True,\n                   shrinking=True, verbose= True ,random_state=42)\nGrid_svm.fit(X_train, y_train)\nGrid_svm_predictions = Grid_svm.predict(X_test)\nGrid_svm_acc = accuracy_score(y_test,Grid_svm_predictions)\nprint(\"Accuracy score with Grid Search:\",Grid_svm_acc)\nprint(\"Accuracy score without Grid Search:\",svm_acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(Grid_svm,X_test, y_test,cmap= plt.cm.Blues)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Comparison of Accuracy Scores","metadata":{}},{"cell_type":"code","source":"models_total = [('Logistic Regression',lr_acc,Grid_lr_acc ),\n          ('K-Nearest Neighbors (KNN)',KNN_acc,Grid_KNN_acc ),\n          ('Decision Tree Classifier',dt_acc,Grid_dt_acc ),\n          ('Random Forest Classifier',rf_acc,Grid_rf_acc ),\n          ('Gaussian Naive Bayes',Gnb_acc,Grid_Gnb_acc),\n          ('Support Vector Machine (SVM)',svm_acc,Grid_svm_acc )]\n\nComp_models_total = pd.DataFrame(data = models_total, columns=['Model','Accuracy Score  without Grid Search','Accuracy Score with Grid Search'])\nComp_models_total","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}