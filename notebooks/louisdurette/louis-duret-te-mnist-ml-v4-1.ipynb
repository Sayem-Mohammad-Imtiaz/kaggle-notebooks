{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Reconnaissance de chiffres manuscrits : MNIST"},{"metadata":{},"cell_type":"markdown","source":"## Librairies et fonctions utiles"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Directive pour afficher les graphiques dans Jupyter\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pandas : librairie de manipulation de données\n# NumPy : librairie de calcul scientifique\n# MatPlotLib : librairie de visualisation et graphiques\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import metrics\nfrom sklearn import preprocessing\nfrom sklearn import model_selection\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score,auc, accuracy_score\n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nfrom sklearn.model_selection import train_test_split\n\nfrom IPython.core.display import HTML # permet d'afficher du code html dans jupyter","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fonction pour tracer les courbes d'apprentissage sur l'ensemble d'apprentissage et l'ensemble de validation :"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import learning_curve\ndef plot_learning_curve(est, X_train, y_train) :\n    train_sizes, train_scores, test_scores = learning_curve(estimator=est, X=X_train, y=y_train, train_sizes=np.linspace(0.1, 1.0, 10),\n                                                        cv=5,\n                                                        n_jobs=-1)\n    train_mean = np.mean(train_scores, axis=1)\n    train_std = np.std(train_scores, axis=1)\n    test_mean = np.mean(test_scores, axis=1)\n    test_std = np.std(test_scores, axis=1)\n    plt.figure(figsize=(8,10))\n    plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='training accuracy')\n    plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\n    plt.plot(train_sizes, test_mean,color='green', linestyle='--',marker='s', markersize=5,label='validation accuracy')\n    plt.fill_between(train_sizes,test_mean + test_std,test_mean - test_std,alpha=0.15, color='green')\n    plt.grid(b='on')\n    plt.xlabel('Number of training samples')\n    plt.ylabel('Accuracy')\n    plt.legend(loc='lower right')\n    plt.ylim([0.6, 1.0])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fonction pour tracer la courbe ROC :"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_roc_curve(est,X_test,y_test) :\n    probas = est.predict_proba(X_test)\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,probas[:, 1])\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    plt.figure(figsize=(8,8))\n    plt.title('Receiver Operating Characteristic')\n    plt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.2f'% roc_auc)\n    plt.legend(loc='lower right')\n    plt.plot([0,1],[0,1],'r--')        # plus mauvaise courbe\n    plt.plot([0,0,1],[0,1,1],'g:')     # meilleure courbe\n    plt.xlim([-0.05,1.2])\n    plt.ylim([-0.05,1.2])\n    plt.ylabel('Taux de vrais positifs')\n    plt.xlabel('Taux de faux positifs')\n    plt.show","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Le dataset de chiffres manuscrits MNIST"},{"metadata":{},"cell_type":"markdown","source":"On charge le dataset MNIST :"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/mnist-in-csv/mnist_test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On a 785 colonnes :\n* une colonne 'label' identifiant le chiffre  \n* et 784 colonnes de pixels (image de 28x28 pixels \"aplatie\")"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On crée la cible y (colonne 'label') :"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df['label']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"et les caractéristiques X :"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop(['label'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On sépare les ensembles d'apprentissage et de test :"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On peut maintenant appliquer les méthodes de machine learning, mais auparavant on va visualiser les images"},{"metadata":{},"cell_type":"markdown","source":"## Visualisation des images MNIST"},{"metadata":{},"cell_type":"markdown","source":"Pour visualiser les images, on va convertir une ligne de 784 pixels en une matrice 28x28  \nIl faut en premier transformer le dataframe X en un tableau :"},{"metadata":{"trusted":true},"cell_type":"code","source":"X1 = np.array(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On affiche la première ligne :"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X1[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On applique la méthode **reshape** pour convertir cette ligne de 784 éléments en une matrice 28x28 :"},{"metadata":{"trusted":true},"cell_type":"code","source":"image = X1[0].reshape(28,28)\nprint(image)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On peut maintenant afficher cette matrice :"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(image)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"en niveaux de gris, sans graduation des axes, et avec le label comme titre :"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(image, cmap=\"gray_r\")\nplt.axis('off')\nplt.title(y[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On redimensionne toutes les lignes :"},{"metadata":{"trusted":true},"cell_type":"code","source":"n_samples = len(df.index)\nimages = X1.reshape(n_samples,28,28)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On affiche les 50 premiers :"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,20))\nfor i in range(0,49) :\n    plt.subplot(10,5,i+1)\n    plt.axis('off')\n    plt.imshow(images[i], cmap=\"gray_r\")\n    plt.title(y[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Machine learning"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import ensemble\nrf = ensemble.RandomForestClassifier()\nrf.fit(X_train, y_train)\ny_rf = rf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_learning_curve(rf, X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_rf))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test, y_rf)\nprint(cm)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exercice : tester Xgboost"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sous Jupyter, si xgboost n'est pas déjà installé\n!pip install xgboost","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importation de la méthode\nimport xgboost as XGB\n#Entrainement\nxgb  = XGB.XGBClassifier()\nxgb.fit(X_train, y_train)\n#Prédiction\ny_xgb = xgb.predict(X_test)\n#Calcul du score\nrf_score = accuracy_score(y_test, y_xgb)\nprint(rf_score)\n#Matrice de confusion \ncm = confusion_matrix(y_test, y_xgb)\nprint(cm)\n#Classification report\nprint(classification_report(y_test, y_xgb))\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}