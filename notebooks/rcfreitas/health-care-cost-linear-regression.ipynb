{"cells":[{"metadata":{"_uuid":"fc36e9750941f6c6d1835c026b99106ec7c02d5d"},"cell_type":"markdown","source":"# **Health Care Cost - Linear Regression**\n\nRodolfo Camargo de Freitas"},{"metadata":{"_uuid":"54009b8f7acbf27b2e6ff52f5a59ae1f71e68985"},"cell_type":"markdown","source":"## 1 - The data\n\nThis data can be found in [kaggle](https://www.kaggle.com/mirichoi0218/insurance/version/1) and is an attempt to gather the datasets of the book **Machine Learning With R**, by Brett Lantz, as can be seen in  [Machine-Learning-with-R-datasets](https://github.com/stedy/Machine-Learning-with-R-datasets).\n\nThere are 1338 points with 7 features in the dataset. They are:\n\n-  age: age of the primary beneficiary - numeric;\n-  sex: male or female - string;\n-  bmi: [Body mass index](https://en.wikipedia.org/wiki/Body_mass_index) ($kg/mÂ²$) - numeric;\n\n-  children: Number of children covered by health insurance - numeric;\n\n-  smoker: do the beneficiary smoke (yes, no)? \n\n-  region: beneficiary's residential area in the US (northeast, southeast, southwest, northwest) - string;\n\n-  charges: Individual medical costs billed by health insurance - numeric;"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9ffdccff076a4476d72cd8d709b86521f9d4f06b"},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt","execution_count":3,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fbd90fa6342f68d8fef405b857794990a24b1def"},"cell_type":"code","source":"#loading the dataset\ndata = pd.read_csv(\"../input/insurance.csv\")\n\n#basic infos\ndata.info()\n\n#changing data types\nfor column in ['sex', 'smoker', 'region']:\n    data[column] = data[column].astype('category')\n\n#note the memory usage reduction from 73.2 kB to 46.2 kB\ndata.info()","execution_count":4,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b40214317522fa98d5e17fa5e3dbb9a74a53871"},"cell_type":"code","source":"#the numerical features\ndata.describe()","execution_count":5,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ac87ff16ac00d654b778204b825eff53b729144"},"cell_type":"code","source":"#the categorical features\ndata.describe(include='category', exclude='float')","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"ec0cacdc22cfaa7f509830d15467cafe6092b2f7"},"cell_type":"markdown","source":"## 2 - Visualizing the data\n\nPlotting the data can help more to give insights than the statistical summary above."},{"metadata":{"trusted":true,"_uuid":"135e56d5f3db246a39817f973b2a7f6fa42df406"},"cell_type":"code","source":"from pandas.plotting import scatter_matrix\n\nscatter_matrix(data[['charges','age','bmi', 'children']], alpha=0.3, diagonal='kde')","execution_count":7,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"91a353a2d5ddd841f47e7e64d5f4e0771fe2e116"},"cell_type":"code","source":"plt.figure(1)\nplt.subplot(2,2,1)\ndata.groupby(['sex'])['charges'].sum().plot.bar()\nplt.subplot(2,2,2)\ndata.groupby(['smoker'])['charges'].sum().plot.bar()\nplt.subplot(2,2,3)\ndata.groupby(['region'])['charges'].sum().plot.bar()\n\nplt.figure(2)\nplt.subplot(2,2,1)\ndata.groupby(['sex'])['bmi'].sum().plot.bar()\nplt.subplot(2,2,2)\ndata.groupby(['smoker'])['bmi'].sum().plot.bar()\nplt.subplot(2,2,3)\ndata.groupby(['region'])['bmi'].sum().plot.bar()","execution_count":8,"outputs":[]},{"metadata":{"_uuid":"29b9d71215dc4fc760a2cc5e6d0453dd8e30f57d"},"cell_type":"markdown","source":"# 3 - Regression\n\nCan we predict the charges knowing the value of the other 6 features? Which feature is more important?\nFirst, we will consider only the numerical features. Later, we will analyze the result with the categorical features."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c0359bc4d25ca2734ccc331080d323eaf03b4bda"},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nnumerical = ['age','bmi', 'children']\ncategorical = ['sex', 'smoker', 'region']\nX_train, X_test, y_train, y_test = train_test_split(data[numerical], \n                                                    data['charges'], \n                                                    test_size=0.2,\n                                                   random_state=42)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4aca82b9850210db323ecc1f84d293363874577a"},"cell_type":"code","source":"regressor = LinearRegression()\nregressor.fit(X_train, y_train)\n\ny_pred = regressor.predict(X_test)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8503f2a1ccd69ad86325c53f6dd9187bab3d394f"},"cell_type":"code","source":"print(\"The mean squared error is {:.2f}\".format(mean_squared_error(y_test,y_pred)))\nprint(\"R2-score: {:.2f}\".format(r2_score(y_test,y_pred)))","execution_count":11,"outputs":[]},{"metadata":{"_uuid":"5f70c147515443478ee2bc731da68eac366ca6ac"},"cell_type":"markdown","source":"Let's test each numerical feature individually."},{"metadata":{"trusted":true,"_uuid":"58042a633e4c0ce491340dbbd62eadcab2f1e4b5"},"cell_type":"code","source":"for feature in numerical:\n    X_train, X_test, y_train, y_test = train_test_split(data[feature].values.reshape(-1,1),\n                                                       data['charges'],\n                                                       test_size=0.2,\n                                                       random_state=42)\n    regressor = LinearRegression()\n    regressor.fit(X_train,y_train)\n    y_pred = regressor.predict(X_test)\n    print(\"Feature: {}\".format(feature))\n    print(\"Mean squared error: {:.2f}\".format(mean_squared_error(y_test,y_pred)))\n    print(\"R2-score: {:.2f}\".format(r2_score(y_test,y_pred)))\n    plt.scatter(X_train,y_train, color='black')\n    plt.plot(X_test,y_pred, color='blue')\n    plt.ylabel('Charges')\n    plt.xlabel(feature)\n    plt.show()","execution_count":12,"outputs":[]},{"metadata":{"_uuid":"b788a160e332a5c983186d1957043594db57dc9d"},"cell_type":"markdown","source":"What happens when we add the numerical features one by one into the model?"},{"metadata":{"trusted":true,"_uuid":"b41390658a46368ce6169ea20d7c603fe9b72003"},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(data[numerical[0]].values.reshape(-1,1),\n                                                       data['charges'],\n                                                       test_size=0.2,\n                                                       random_state=42)\nregressor = LinearRegression()\nregressor.fit(X_train,y_train)\ny_pred = regressor.predict(X_test)\nprint(\"Features: {}\".format(numerical[0]))\nprint(\"Mean squared error: {:.2f}\".format(mean_squared_error(y_test,y_pred)))\nprint(\"R2-score: {:.2f}\".format(r2_score(y_test,y_pred)))\nfor i in range(2,4):\n    X_train, X_test, y_train, y_test = train_test_split(data[numerical[0:i]],\n                                                       data['charges'],\n                                                       test_size=0.2,\n                                                       random_state=42)\n    regressor = LinearRegression()\n    regressor.fit(X_train,y_train)\n    y_pred = regressor.predict(X_test)\n    print(\"Features: {}\".format(numerical[0:i]))\n    print(\"Mean squared error: {:.2f}\".format(mean_squared_error(y_test,y_pred)))\n    print(\"R2-score: {:.2f}\".format(r2_score(y_test,y_pred)))","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"ccd7cbeb7f0035e9d5a1c44ccb723ce3b1a5cc76"},"cell_type":"markdown","source":"Although the small reduction in the mean squared error, the R2 score indicates that adding the number of children to the model won't improve it.\nIn order to add the categorical features we need first to transform it into numerical features. We will do it as follows."},{"metadata":{"trusted":true,"_uuid":"57ea5496cb365f1beb569c00729fc947c87c6132"},"cell_type":"code","source":"data = pd.get_dummies(data)\ndata.head()","execution_count":14,"outputs":[]},{"metadata":{"_uuid":"d50b97086a62b6a965f597c24fb362bd126d10fb"},"cell_type":"markdown","source":"As a result, each categorical feature was transformed into a new column for each one of the categories. \nLet's see how the model evolves for each of the features."},{"metadata":{"trusted":true,"_uuid":"f65f35a2df4c980cb8e98f47bc72b432ed56fd1f"},"cell_type":"code","source":"features = list(data.columns)\nfeatures.remove('charges')\n\nr2_scores = []\n\nX_train, X_test, y_train, y_test = train_test_split(data[features[0]].values.reshape(-1,1),\n                                                       data['charges'],\n                                                       test_size=0.2,\n                                                       random_state=42)\nregressor = LinearRegression()\nregressor.fit(X_train,y_train)\ny_pred = regressor.predict(X_test)\nprint(\"Feature added: {}. Total features: {}\".format(features[0],len(features[0:1])))\nprint(\"Mean squared error: {:.2f}\".format(mean_squared_error(y_test,y_pred)))\nprint(\"R2-score: {:.2f}\".format(r2_score(y_test,y_pred)))\nr2_scores.append(r2_score(y_test,y_pred))\nfor i in range(2,11):\n    X_train, X_test, y_train, y_test = train_test_split(data[features[0:i]],\n                                                       data['charges'],\n                                                       test_size=0.2,\n                                                       random_state=42)\n    regressor = LinearRegression()\n    regressor.fit(X_train,y_train)\n    y_pred = regressor.predict(X_test)\n    print(\"Feature addes: {}. Total features: {}\".format(features[i],len(features[0:i])))\n    print(\"Mean squared error: {:.2f}\".format(mean_squared_error(y_test,y_pred)))\n    print(\"R2-score: {:.2f}\".format(r2_score(y_test,y_pred)))\n    r2_scores.append(r2_score(y_test,y_pred))","execution_count":15,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"36cb2f6373194d72bd55b54085c60dee17b36c99"},"cell_type":"code","source":"plt.plot(list(range(0,10)),r2_scores)\nplt.ylabel('R2 score')\nplt.xlabel('features')\nplt.show()","execution_count":16,"outputs":[]},{"metadata":{"_uuid":"0f569b0e5772b2594799a704303e43b47848ecea"},"cell_type":"markdown","source":"It seems that a optimal model is the one with the features 'age', 'bmi', 'sex' and 'smoker'."},{"metadata":{"trusted":true,"_uuid":"cfa0332d59c1513d8e7fc0dddd553a7388dde48d"},"cell_type":"code","source":"best = ['age','bmi','sex_male','sex_female','smoker_yes', 'smoker_no']\nX_train, X_test, y_train, y_test = train_test_split(data[best],\n                                                   data['charges'],\n                                                   test_size=0.2,\n                                                   random_state=42)\nregressor = LinearRegression()\nregressor.fit(X_train,y_train)\ny_pred = regressor.predict(X_test)\n\nprint(\"Mean squared error: {:.2f}\".format(mean_squared_error(y_test,y_pred)))\nprint(\"R2-score: {:.2f}\".format(r2_score(y_test,y_pred)))","execution_count":17,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}