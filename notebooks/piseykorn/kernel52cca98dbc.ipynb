{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, GRU, Bidirectional\nfrom keras.optimizers import SGD\nimport math\nfrom sklearn.metrics import mean_squared_error\nprint(os.listdir(\"../input\"))\nimport keras","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read data from csv file, consider column 'date' as index and parse it into date object\ndataset = pd.read_csv('../input/historical_stock_prices.csv', index_col='date', parse_dates=['date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display some sort of sample of dataset\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Selecting training_set from begin of 2015 till end of 2017, we can do this because our index in date object\ntraining_data = dataset['2015':'2017'].adj_close","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verify training_data corresponding to our selection or not\ntraining_data.head(-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# transform method required reshape our training_set\ntraining_set = training_data.values.reshape(-1, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# It is kind of data preprocessing in order to obtain more accurancy of our model\n# Once I trained our model without transform training set I got higher loss\nsc = MinMaxScaler(feature_range=(0,1))\ntraining_set_scaled = sc.fit_transform(training_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_set_scaled.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we create a data structure with 60 timesteps and 1 output\n# We consider 60 previous elements to produce 1 output\n# You can set beside from 60 timesteps but my case I prefer 60 timesteps\nX_train = []\ny_train = []\ntimesteps = 60\nfor i in range(timesteps,len(training_set_scaled)):\n    X_train.append(training_set_scaled[i-timesteps:i,0])\n    y_train.append(training_set_scaled[i,0])\n# y_train[0] is an output of X_train[0], X_train[0] contains 60 previous elements of y_train[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Frame our X_train and y_train into numpy array\nX_train, y_train = np.array(X_train), np.array(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reshaping X_train to match with our GRU network input\nX_train = np.reshape(X_train, (X_train.shape[0],X_train.shape[1],1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Callback function `earlystopping` to trigger while training it monitor 'loss'\n# start from first epoch it record min value of loss and if model can not find \n# lower loss value in next 3 epochs model will stop training.\nes = keras.callbacks.EarlyStopping(monitor='loss',patience=3, mode='min')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The GRU architecture\n# We are using Sequential model of Keras\n# Our hidden layer using activation = 'tanh' and having 50 neurons each layer\n# The output layer of fully connected layer is having only 1 neurons because we want only one output value\n\nregressorGRU = Sequential()\n# First GRU layer with Dropout regularisation\nregressorGRU.add(GRU(units=50, return_sequences=True, input_shape=(X_train.shape[1],1), activation='tanh'))\nregressorGRU.add(Dropout(0.2))\n# Second GRU layer\nregressorGRU.add(GRU(units=50, return_sequences=True, input_shape=(X_train.shape[1],1), activation='tanh'))\nregressorGRU.add(Dropout(0.2))\n# Third GRU layer\nregressorGRU.add(GRU(units=50, return_sequences=True, input_shape=(X_train.shape[1],1), activation='tanh'))\nregressorGRU.add(Dropout(0.2))\n# Fourth GRU layer\nregressorGRU.add(GRU(units=50, activation='tanh'))\nregressorGRU.add(Dropout(0.2))\n# The output layer\nregressorGRU.add(Dense(units=1))\n# Compiling the RNN\nregressorGRU.compile(optimizer=SGD(lr=0.01, decay=1e-7, momentum=0.9, nesterov=False),loss='mean_squared_error')\n# Fitting to the training set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training model with earlystopping callbacks function\n# It's processing 6000 sample a step\nregressorGRU.fit(X_train,y_train,epochs=20,batch_size=6000, callbacks=[es])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Calculate MSE #"},{"metadata":{"trusted":true},"cell_type":"code","source":"def return_mse(test,predicted):\n    mse = mean_squared_error(test, predicted)\n    print(\"The mean squared error is {}.\".format(mse))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Calculate RMSE on test set ##"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Selecting test set\n# Consider index start from 2018 date object and select only adj_close column\ntest_set = dataset['2018':].adj_close.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_set.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_dateset = dataset.adj_close\ninputs = total_dateset[len(total_dateset.values)-len(test_set)-60:].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reshape inputs and scale it because our training set also scaled\ninputs = inputs.reshape(-1,1)\ninputs  = sc.transform(inputs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Frame X_test and y_test structure same as trining\nX_test = []\ny_test = []\nfor i in range(timesteps,len(inputs)):\n    X_test.append(inputs[i-timesteps:i,0])\n    y_test.append(inputs[i,0])\nX_test = np.array(X_test)\nY_test = np.array(y_test)\nX_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Selecting some from test set\ntest = X_test[:10000]\ny = Y_test[:10000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting\npredicted_stock_price = regressorGRU.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_stock_price","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluating our model\nreturn_mse(y,predicted_stock_price)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}