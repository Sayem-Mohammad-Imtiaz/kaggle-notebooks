{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"cell_type":"markdown","source":"# Práctica 1: Análisis exploratorio de datos, preprocesamiento y validación de modelos de clasificación\\*\n\n### Minería de Datos: Curso académico 2020-2021\n\n### Profesorado:\n\n* Juan Carlos Alfaro Jiménez\n* José Antonio Gámez Martín\n\n\\* Adaptado de las prácticas de Jacinto Arias Martínez y Enrique González Rodrigo\n\n\n### Grupo H:\n\n* Alejandro Fernández Arjona\n* Pablo Torrijos Arenas"},{"metadata":{"_uuid":"8a7623324f8efa406ac9e5a9d0753c872bfdc032"},"cell_type":"markdown","source":"En esta práctica hemos trabajado algunos de los aspectos más importantes del proceso *KDD* (*Knowledge Discovery from Data*):\n\n* Almacenamiento y carga de datos\n* Análisis exploratorio de datos\n* Preprocesamiento de datos\n* Validación de modelos de clasificación\n\nPara la visualización de los datos, además de las librerías `pandas` y `plotly`, hemos usado algunas librerías auxiliares, como `seaborn` y `graphviz`. Para los algoritmos de clasificación hemos usado `scikit-learn`.\n\nHemos realizado los estudios sobre las base de datos `pima_diabetes` y `wisconsin`:\n\n- `pima_diabetes`: https://www.kaggle.com/uciml/pima-indians-diabetes-database\n- `wisconsin`: https://www.kaggle.com/uciml/breast-cancer-wisconsin-data\n\n---\n\nVamos a empezar realizando nuestro análisis para la base de datos `pima_diabetes`."},{"metadata":{},"cell_type":"markdown","source":"# Pima Indians Diabetes Database"},{"metadata":{"_uuid":"35d7e4008f39bffb579a13479097fe83e6a8eb00"},"cell_type":"markdown","source":"## 1. Preliminares"},{"metadata":{},"cell_type":"markdown","source":"Cargamos las librerías que vamos a usar posteriormente:"},{"metadata":{"_uuid":"e46dd0285013848672368ecbbe380e83103949c1","trusted":true},"cell_type":"code","source":"# Third party\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import KBinsDiscretizer\nfrom sklearn.tree import DecisionTreeClassifier\n\n#Otras liberrías auxiliares\nfrom sklearn.compose import ColumnTransformer, make_column_transformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn import tree\n\nfrom imblearn import FunctionSampler\nfrom imblearn.pipeline import make_pipeline\n\nimport numpy as np\nimport pandas as pd\n\nimport seaborn as sb\nimport plotly as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport graphviz \nimport matplotlib\nimport matplotlib.pyplot as pypl\nfrom matplotlib.pyplot import figure\n\n# Local application\nimport miner_a_de_datos_an_lisis_exploratorio_utilidad as utils","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Además, fijamos una semilla para que los experimentos sean reproducibles (hemos usado la misma que se usó en la libreta del estudio de `iris`:"},{"metadata":{"trusted":true},"cell_type":"code","source":"seed = 27912","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c225b530d06a70b6bbf26ec0d593aa42715fa9d8"},"cell_type":"markdown","source":"## 2. Acceso y almacenamiento de datos"},{"metadata":{},"cell_type":"markdown","source":"El primer conjunto de datos que usaremos es `diabetes`. Es original del Instituto Nacional de Diabetes y Enfermedades Digestivas y del riñón. El objetivo es intentar predecir si un paciente tiene o no diabetes, basándonos en ciertas variables predictores. Se trata de 768 instancias, mujeres de entre 20 y 81 años, un extracto muy pequeño de la colección de datos original.\n\nLa variable objetivo es `Outcome`, y estos son los posibles Outcomes:\n\n* `0`: Predicción de que el paciente no tiene diabetes.\n* `1`: Predicción de que el paciente tiene diabetes.\n\nLas distintas variables predictoras son las siguientes:\n\n* `Pregnancies`: Número de embarazos.\n* `Glucose`: Concentración de glucosa en plasma (tras 2 horas de un test de tolerancia a glucosa oral).\n* `BloodPressure`: Presión arterial diastólica (en milímetros de mercurio).\n* `SkinThickness`: Espesor del pliegue cutáneo del tríceps (en milímetros).\n* `Insulin`: Insulina en suero 2-horas.\n* `BMI`: Índice de masa corporal (kg / m^2).\n* `DiabetesPedigree`: Función de pedigrí de diabetes.\n* `Age`: Edad (en años).\n\nEl objetivo sería clasificar una nueva instancia (cuyo `Outcome` es desconocido) en función de sus propiedades."},{"metadata":{},"cell_type":"markdown","source":"Comenzamos cargando el conjunto de datos `diabetes`:"},{"metadata":{"_uuid":"6476f218bc9071bd38b06ee77eae9f0e651228a7","trusted":true},"cell_type":"code","source":"filepath = \"../input/pima-indians-diabetes-database/diabetes.csv\"\n\nindex = None\ntarget = \"Outcome\"\n\ndata = utils.load_data(filepath, index, target)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"23f95e5c93b4393a2030093eaa21956ac96b88fc"},"cell_type":"markdown","source":"Tenemos que darnos cuenta de que el conjunto de datos `diabetes` no tiene una variable identificadora, por lo que definimos como identificador `None` y el método creará una variable Id automáticamente. Definimos como variable objetivo `Outcome`.\n\nUna vez hemos cargado el conjunto de datos es fundamental comprobar que el proceso ha funcionado sin problemas, y que las variables y los valores están dentro de lo esperado. Para ello, podemos escoger una instancia al azar o mostrar las primeras instancias del conjunto de datos.\n\nPodemos usar la función `sample` para obtener una muestra aleatoria de `n` instancias del conjunto de datos, ya que con el método `head` obtendríamos una muestra muy sesgada:"},{"metadata":{"_uuid":"9f1a39585fceb516af8ddcf5afd85945b50c418a","trusted":true},"cell_type":"code","source":"data.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a43dd350512365db94a69a5a6f6cf0828e7afb9f"},"cell_type":"markdown","source":"Es muy útil disponer del conjunto de datos separado dos subconjuntos, uno con las variables predictoras (`X`) y otro con la variable objetivo (`y`). Se puede utilizar el siguiente fragmento de código para dividirlo: "},{"metadata":{"_uuid":"77c75aa49e6cd91426d1de882b7feaa0a883fcdb","trusted":true},"cell_type":"code","source":"(X, y) = utils.divide_dataset(data, target=\"Outcome\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"De nuevo, comprobamos que se haya separado correctamente. Comenzamos con las variables predictoras:"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"X.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Y continuamos con la variable clase:"},{"metadata":{"trusted":true},"cell_type":"code","source":"y.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Si bien podríamos comenzar con el análisis exploratorio, vamos a dividir primero nuestro conjunto de datos en dos:\n\n* Una muestra de entrenamiento (vamos a usar 75%)\n* Una muestra de prueba (el 25% restante)\n\nDe este modo, podemos dejar el conjunto de prueba a modo de instancias no observadas para asegurarnos que los resultados de validación han sido estimados de manera honesta (y no optimista). De hecho, si utilizamos el mismo conjunto de datos para aprender y validar un modelo, observaremos un resultado inusual y es que, conforme más sobreajustado está el modelo, menor es el error cometido. Por el contrario, si usamos un conjunto de entrenamiento muy pequeño (50% training, 50% test, por ejemplo), no estaríamos ajustando lo suficiente (*underfitting*)y podemos obtener resultados peores de los que deberíamos.\n\nPara realizar un *holdout* podemos utilizar el método `train_test_split` de `scikit-learn`:\n\nPodríamos realizar una validación cruzada con k=5 por ejemplo (carpetas de unas 154 o 153 instancias) para reducir la aleatoriedad y usar cada registro como test una vez, pero lo dejamos para la siguiente práctica, para esta realizaremos un *holdout*."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size = 0.75\n\n(X_train, X_test, y_train, y_test) = train_test_split(X, y,\n                                                      stratify=y,\n                                                      random_state=seed,\n                                                      train_size=train_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Aleatorizamos las instancias del conjunto de datos (`shuffle=True`, valor por defecto aunque no lo especifiquemos) para evitar que eliminar todas las instancias de alguna clase en conjuntos de datos que estén ordenados por la variable clase. No es nuestro caso, ya que la variable `Outcome` toma valores 0 y 1 alternadamente a lo largo de los 768 registros, pero no está mal que aleatoricemos los datos igualmente.\n\nMediante la semilla, con `random_state`, conseguimos las mismas particiones de training y test cada vez que ejecutemos el algoritmo, para conseguir la reproducibilidad de los experimentos.\n\nAl igual que en el caso que se nos dio de `iris`, hemos aplicado un *holdout* estratificado (`stratify=y`), para conservar la proporción de ejemplos de cada clase durante la revisión. Es muy importante que lo hagamos con esta base de datos, ya que al ser un problema desbalanceado, podríamos eliminar mucha información si no lo hacemos.\n\nDe nuevo, vamos a asegurarnos de que el conjunto de datos se ha dividido correctamente en entrenamiento y prueba. Comenzamos con las variables predictoras del conjunto de datos de entrenamiento:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Y prueba:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Por último, finalizamos con la variable objetivo del conjunto de datos de entrenamiento:"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Y prueba:"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para facilitar el análisis exploratorio de datos, juntamos de nuevo las variables predictores con la variable clase."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train = utils.join_dataset(X_train, y_train)\n\ndata_test = utils.join_dataset(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vamos a obtener una muestra aleatoria de ambos conjuntos:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dfa6448396ab99305eddfd23cfd958266ad967a8"},"cell_type":"markdown","source":"## 3. Análisis exploratorio de datos"},{"metadata":{},"cell_type":"markdown","source":"Antes de comenzar el preprocesamiento, vamos a analizar las variables y sus relaciones, mediante gráficos y estadísticos. Usamos las libreías `Pandas`, `Plotly` y `Seaborn`."},{"metadata":{},"cell_type":"markdown","source":"## 3.1 Descripción del conjunto de datos"},{"metadata":{},"cell_type":"markdown","source":"Como hemos dicho antes, el conjunto de datos `Diabetes` tiene 768 instancias y 9 variables. Vamos a ver esta información sobre el conjunto de entrenamiento con el atributo shape."},{"metadata":{"_uuid":"2353b44c7a384810e27f487853d000a2edbe543a","trusted":true},"cell_type":"code","source":"data_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tal y como se puede observar, el conjunto de datos de entrenamiento está formado por 576 casos y 9 variables (8 variables predictoras y 1 variable clase, Outcome).\n\nPara conocer el tipo de las variables usamos `info`:"},{"metadata":{"_uuid":"015c899c3ec4a2177b1986797554b66dfcaac1ee","trusted":true},"cell_type":"code","source":"data_train.info(memory_usage=False)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Es decir, 6 variables predictoras del conjunto de datos (`Pregnancies`,`Glucose`,`BloodPressure`,`SkinThickness`,`Insulin`,`Age`) son numéricas (continuas) del tipo `int64`, 2 variables predictoras numéricas (continuas) del tipo `float64`, y la variable clase (`Outcome`) es categórica (`category`) o discreta, con los estados `0` y `1`, como vemos a continuación:"},{"metadata":{"trusted":true},"cell_type":"code","source":"y.cat.categories","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Es decir, nuestra variable clase es bivariada (tiene 2 posibles valores)."},{"metadata":{"_uuid":"f17f376d1ed7405027aebcd226bb6f54d61834ed"},"cell_type":"markdown","source":"## 3.2 Visualización de las variables"},{"metadata":{},"cell_type":"markdown","source":"Hemos realizado distintos tipos de gráficas y de diagramas para comprender mejor las variables de nuestro problema y las capadidades de la librería `plotly`, realizando tanto un análisis univariado, como uno multivariado."},{"metadata":{},"cell_type":"markdown","source":"Análisis univariado (involucra una sola variable):\n* Histogramas para las variables numéricas\n* Diagramas circulares para observar información de `Insulin` y `SkinThickness`\n* Diagramas de barras para la variable clase `Outcome`\n* Diagramas de cajas\n* Diagramas de violín\n"},{"metadata":{},"cell_type":"markdown","source":"Análisis multivariado (involucra varias variables):\n* Matriz de gráficos de nube de puntos\n* Mapa de calor\n* Gráficos de dispersión\n* Diagramas de  densidad de contorno"},{"metadata":{},"cell_type":"markdown","source":"### 3.2.1 Análisis univariado"},{"metadata":{},"cell_type":"markdown","source":"Para empezar, vamos a hacer un análisis univariado para identificar ruido y outliers en las variables de nuestro conjunto de datos."},{"metadata":{"_uuid":"9ab7ff50c8e596f47f8b1e2bece56de40ad52da9","trusted":true},"cell_type":"code","source":"utils.plot_histogram(data_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4083a4c4c0cf6cfceafe1febbb68be23664931a2"},"cell_type":"markdown","source":"La variable `Pregnancies` sigue una distribución normal con asimetría positiva, y la mayoría de casos se encuentran entre 0 y 10 embarazos. No parece muy lógico que haya tantos casos de mujeres con más de 4 casos, ya que en mi opinión la gran mayoría de mujeres suelen tener entre 0 y 4 embarazos, no es lo normal que de 768 mujeres 38 de ellas hayan pasado por 8 embarazos. Esos datos los tendremos en cuenta aunque no parezcan lógicos, ya que tampoco podemos considerarlos como outlayers ni como ruido. Lo que sí podemos considerar como outlayers son las mujeres que hayan tenido más de 12 embarazos, llegando incluso a 17. Estos valores los podemos eliminar.\n\nLas variables `Glucose`, `BloodPressure`, `BMI` y `DiabetesPedigreeFunction` muestran una distribución con tendencia central (teniendo la última de ellas una asimetría positiva), es decir, también siguen una distribución normal. También debemos destacar que hay algunos casos cuyo nivel de glucosa, índice de masa corporal o presión sanguínea es 0, lo cual significa que se trata de valores perdidos y debemos imputarlos.  En cuanto a `BMI` y `DiabetesPedigreeFunction` también podemos destacar que hay algunos outlayers que debemos eliminar. Por ejemplo, en cuanto al índice de masa corporal, aunque lo más común son los valores entre 20 y 40, existen casos con mayor IMC, pero no tanto como 60 o 68 como se ve en la gráfica, ya que la obesidad extrema comprende desde 40 hasta 55 de IMC. En cuanto a la función de pedigree de diabetes, también hay unos cuantos valores outlayers que eliminaremos más adelante. \n\nComo se puede observar, la variable `Insulina` parece seguir una distribución exponencial, tieniendo la mayoría de los casos valor `0`. Sin embargo, si nos paramos a analizar un poco el significado de esta gráfica, nos damos cuenta de que todos esos datos con valor de insulina igual a cero son erróneos. Una persona no puede generar cero de insulina, moriría, por lo que se trata de valores perdidos. En las variables que he comentado antes vamos a tratar de imputar los valores perdidos, sin embargo, en este caso, esos errores suponen el 49.8% de la variable, por lo que estaríamos tratando con unos datos muy sesgados. En este caso, vamos a eliminar la variable y a no tenerla en cuenta para nuestro problema.\n\nPor último, la variable `SkinThickness` (distribución normal), que mide el grosor de la piel, también tiene una gran cantidad de datos perdidos: suponen el 32.3% del total. Además, no parece normal que el grosor de la piel esté concentrado entre 15 y 40 milímetros, ya que lo normal es entre 0.5mm y 4.0mm. En cualquier caso, esa enorme cantidad de datos perdidos es motivo suficiente para eliminar la variable y no tenerla en cuenta, al igual que hemos comentado respecto a la variable `Insulina`.\n\nPor último, la variable `Age` presenta de nuevo una distribución normal, y en este caso no parece haber valores perdidos ni outlayers, ya que todas las edades se encuentran entre 20 y 80 años."},{"metadata":{},"cell_type":"markdown","source":"Aunque hemos calculado el número de valores perdidos manualmente, vamos a ver ahora esa cantidad con un gráfico circular. Empezamos con `Insuline`:"},{"metadata":{"trusted":true},"cell_type":"code","source":"circular1 = px.pie(data_train, values='Outcome', names='Insulin')\ncircular1.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Aunque los registros con valor mayor que cero no se aprecien bien, se ve claramente que casi la mitad de las instancias toman valor cero, por lo que, como ya hemos dicho, no debemos tener en cuenta esta variable predictora."},{"metadata":{},"cell_type":"markdown","source":"Repetimos para `SkinThickness`:"},{"metadata":{"trusted":true},"cell_type":"code","source":"circular1 = px.pie(data_train, values='Outcome', names='SkinThickness')\ncircular1.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"En este caso, casi un tercio de los datos son datos erróneos, por lo que también tenemos que eliminar esta variable."},{"metadata":{},"cell_type":"markdown","source":"Vamos a almacenar en una lista las dos variables a eliminar, para futuros usos."},{"metadata":{"trusted":true},"cell_type":"code","source":"eliminadas = ['Insulin','SkinThickness']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Continuamos visualizando la variables clase:"},{"metadata":{"_uuid":"268a87c979078129be8902cc50e24118d7f6254b","trusted":true},"cell_type":"code","source":"utils.plot_barplot(data_train) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9852797c305df3f69fd5b8a4436509758a57a0d0"},"cell_type":"markdown","source":"Podemos observar que la clase 0 (No diabetes) tiene el 65.1% de los casos, y la clase 1 (Sí diabetes) el resto de los casos, es decir, 34.9%. Esto quiere decir que el problema no está `balanceado`.\n"},{"metadata":{},"cell_type":"markdown","source":"Podemos realizar otro diagrama de barras con el conjunto de datos original (data) en lugar de usar el conjunto de datos de entrenamiento (data_train), para comprobar si habíamos estratificado correctamente:"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_barplot(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como se puede observar, se matiene el mismo porcentaje de ceros y unos en ambos casos, por lo que la estratificación es correcta."},{"metadata":{},"cell_type":"markdown","source":"Vamos a realizar un diagrama de cajas para observar las variables predictoras y sus cuartiles. Los diagramas de cajas sirven también para encontrar los outliers rápidamente. Usamos el conjunto X_train ya que la variable clase no nos interesa analizarla en este caso, siempre toma valores 0 o 1."},{"metadata":{"trusted":true},"cell_type":"code","source":"cajas2 = go.Figure()\n\nfor columna in X_train:\n    cajas2.add_trace(go.Box(y=X_train[columna].values, name=X_train[columna].name))\n\ncajas2.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A simple vista en este diagrama podemos ver cómo por culpa de todos los valores perdidos de la variable `Insulina`, ésta tiene su mediana en el valor 0, siendo los valores superiores a 326 los outliers, cuando no es para nada lo que ocurre en realidad. Como vamos a eliminar las variables `Insulina` y `SkinThickness`, podemos realizar otro diagrama de cajas con el resto de variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"cajas2 = go.Figure()\n\nfor columna in X_train:\n    if columna not in eliminadas:\n        cajas2.add_trace(go.Box(y=X_train[columna].values, name=X_train[columna].name))\n\ncajas2.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos destacar que `Glucose`, `BloodPressure` y `BMI` son variables simétricas, ya que la mediana se encuentra en el centro del rectángulo. Respecto a esas 3 variables, también podemos comprobar lo que dijimos antes, que tienen algunos datos perdidos que toman valor 0. `Pregnancies` y `DiabetesPedigreeFunction` también tienen registros con valor 0, pero como ya hemos dicho antes, en estas variables es completamente normal.\n\nEn cuanto a `Pregnancies`, salen valores muy altos, ya que por ejemplo según este diagrama la mediana se encuentra en 3, y existen múltiples registros con valor por encima de 10 embarazos.\n\nPor último, se pueden ver outlayers en todas las variables, excepto en la de `Glucose`"},{"metadata":{},"cell_type":"markdown","source":"Vamos a realizar ahora un diagrama de violín para `Glucose` por ejemplo. Es similar a un diagrama de cajas pero añadiendo densidad a ambos lados del diagrama:"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.violin(data_train, y=\"Glucose\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos observar, al igual que en el diagrama de cajas, que la mayoría de los registros se encuentran en el intervalo [100-150]. Además, vemos como hay esos registros con valor 0 que deberemos imputar. "},{"metadata":{},"cell_type":"markdown","source":"### 3.2.2 Análisis multivariado"},{"metadata":{},"cell_type":"markdown","source":"Hemos realizado ahora un análisis multivariado para tratar de obtener mejores conclusiones determinando la potencia discriminativa de los atributos, viendo las relaciones entre ellos respecto a la información que nos den sobre la variable objetivo `Outcome`."},{"metadata":{},"cell_type":"markdown","source":"Para empezar, vamos a crear una matriz de gráficos del tipo nube puntos, al igual que se hizo en el estudio sobre `Iris`. Cada diagrama muestra la relación entre pares de variables predictoras, coloreando cada registro según la clase a la que pertenezca (0 o 1)."},{"metadata":{"_uuid":"868d232e2b351a751d24b70ba8cb3e93236ec6bf","trusted":true},"cell_type":"code","source":"utils.plot_pairplot(data_train, target=\"Outcome\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Este gráfico resultaba muy útil en problemas como el de base de datos `iris`, ya que al tener pocas variables y pocos registros se podían extraer rápidamente algunas conclusiones. Sin embargo, en este problema es difícil sacar conclusiones viendo este pairplot debido a que hay 8 x 8 (64) gráficas y no se aprecian muy bien. Podemos ver algunos outliers en casi todos los diagramas."},{"metadata":{},"cell_type":"markdown","source":"Vamos a realizar ahora un mapa de calor (heatmap) para ver mejor la correlación que existe entre las distintas variables predictoras de nuestra base de datos:"},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\npx.imshow(data_train.corr(method=\"pearson\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como se puede apreciar, no existe prácticamente correlación entre ningun par de variables de nuestro problema. La única pareja que supera el umbral 0.5 es la correlación entre edad y número de embarazos. Tiene sentido que a mayor edad, más número de embarazos se tengan, pero realmente un valor de correlación de 0.558 no es una correlación muy fuerte."},{"metadata":{},"cell_type":"markdown","source":"Podemos crear ahora un gráfico de dispersión entre `Age` y `Pregnancies`, para comprobar la relación que hemos comentado que existía entre esas 2 variables. Separamos con colores según el `Outcome` sea 0 o 1."},{"metadata":{"trusted":true},"cell_type":"code","source":"dispersion = px.scatter(data_train, x=\"Age\",y=\"Pregnancies\",color=\"Outcome\",trendline=\"ols\")\ndispersion.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como habíamos dicho, existía una correlación pequeña, y aquí podemos apreciar que hay mucha dispersión entre las variables. Esto se debe a que las mujeres no tienen una edad fija a la que quedarse embarazadas, ni un número fijo de embarazos, sino que cada caso es muy diferente, aunque exista cierta correlación."},{"metadata":{},"cell_type":"markdown","source":"Podemos realizar un diagrama de densidad de contorno (o histograma en 2D) para comparar de otra manera estas 2 variables. Este gráfico se utiliza cuando hay muchos puntos en un diagrama de dispersión, como el que acabamos de hacer."},{"metadata":{"trusted":true},"cell_type":"code","source":"contorno = px.density_contour(data_train, x=\"Age\", y=\"Pregnancies\")\ncontorno.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos crear ahora otro gráfico de dispersión y otro de densidad de contorno entre dos variables que tengan correlación casi nula (0), para ver la diferencia respecto a estos dos diagramas. Por ejemplo, `Pregnancies` y `DiabetesPedigreeFunction`.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"dispersion2 = px.scatter(data_train, x=\"DiabetesPedigreeFunction\",y=\"Pregnancies\",color=\"Outcome\",trendline=\"ols\")\ndispersion2.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"contorno2 = px.density_contour(data_train, x=\"DiabetesPedigreeFunction\", y=\"Pregnancies\")\ncontorno2.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Efectivamente, en este caso existe una dispersión todavía mayor, debido a que es completamente indeferente el número de embarazos que una mujer haya tenido, con su función de pedigrí de diabetes."},{"metadata":{},"cell_type":"markdown","source":"## 4. Preprocesamiento de datos"},{"metadata":{},"cell_type":"markdown","source":"Ahora comenzamos con la tarea más importante de toda la práctica, el preprocesamiento de los datos. Vamos a transdormar los datos crudos en información más accesible para los algoritmos de aprendizaje. Vamos a realizar una limpieza y una discretización del conjunto de datos, todo ello dentro de un pipeline, para evitar fugas de datos."},{"metadata":{},"cell_type":"markdown","source":"## 4.1 Limpieza de datos"},{"metadata":{},"cell_type":"markdown","source":"Para la limpieza de datos en nuestro problema vamos a realizar los siguientes pasos:\n* Eliminar las variables `Insuline` y `SkinThickness` por tener más de un 20% de datos perdidos.\n* Imputar datos perdidos de las variables `Glucose`, `BloodPressure` y `BMI`.\n* Eliminar *outliers*\n\n### Eliminar variables\n\nPara comenzar con la limpieza de los datos, lo primero que vamos a hacer es eliminar las variables `Insuline` y `SkinThickness`, como hemos explicado en el análisis exploratorio. Podemos eliminar directamente las variables con la función drop de pandas:"},{"metadata":{"trusted":true},"cell_type":"code","source":"eliminadas = ['Insulin','SkinThickness']\n\ncopiadatos = X_train.copy()\ncopiadatos = copiadatos.drop(eliminadas, axis=1)\ncopiadatos.sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Sin embargo, queremos eliminar las variables dentro del pipeline, al igual que la normalización. Para ello, tenemos que crear una clase que implemente los métodos fit( ) y transform( ), y el constructor debe recibir como parámetro las columnas a eliminar."},{"metadata":{"trusted":true},"cell_type":"code","source":"class EliminarVariables():\n    \n    def __init__(self, columnas):\n        self.columnas=columnas\n    \n    def fit(self, x, y=None):\n        return self\n    \n    def transform(self, x, y=None):\n        return x.drop(self.columnas,axis=1,inplace=False)\n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Imputar datos"},{"metadata":{},"cell_type":"markdown","source":"Queremos imputar los datos de las variables `Glucose`, `BloodPressure` y `BMI`, como ya hemos dicho antes. Para ello necesitamos usar ColumnTransformer, al cual debemos indicarle qué tipo de imputador queremos usar (por ejemplo, SimpleImputer con la media), y las variables que queremos modificar."},{"metadata":{"trusted":true},"cell_type":"code","source":"variables = ['Glucose','BloodPressure','BMI']\n\nImputador = ColumnTransformer([('imp1',SimpleImputer(missing_values=0,strategy=\"mean\"), variables)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Eliminar outliers"},{"metadata":{},"cell_type":"markdown","source":"Para eliminar outliers vamos a usar la función que se nos proporcionó en prácticas. Creamos un IsolationForest para detectar los outliers, y con un FunctionSampler la incluiremos en el pipeline. Es importante que el valor `random_state` lo igualemos a nuestra semilla, para permitir que los experimentos se puedan reproducir."},{"metadata":{"trusted":true},"cell_type":"code","source":"def outlier_rejection(X, y):\n    model = IsolationForest(max_samples=100,\n                            contamination=0.4,\n                            random_state=seed)\n    model.fit(X)\n    y_pred = model.predict(X)\n    return X[y_pred == 1], y[y_pred == 1]\n\n\nEliminarOutliers = FunctionSampler(func=outlier_rejection)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.2 Discretización"},{"metadata":{},"cell_type":"markdown","source":"En el ejemplo de `iris` era evidente que dividir en 3 secciones era una buena opción viendo las gráficas, por que las 3 clases estaban muy diferenciadas, pero en el caso de `Diabetes`, no se puede extraer una información clara de las gráficas que hemos visto, por lo que usamos el mismo discretizador que usábamos en `iris`: discretización uniforme, dividiendo en 3 intervalos de igual anchura."},{"metadata":{"trusted":true},"cell_type":"code","source":"Discretizador = KBinsDiscretizer(n_bins=3, strategy=\"uniform\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Algoritmos de clasificación y evaluación de modelos"},{"metadata":{},"cell_type":"markdown","source":"## 5.1 Algoritmos de clasificación"},{"metadata":{},"cell_type":"markdown","source":"### Algoritmo *Zero-R*"},{"metadata":{},"cell_type":"markdown","source":"Vamos a usar primero el algoritmo Zero-R, aunque no tenga mucha precisión, nos puede dar una idea para la precisión que debemos conseguir con otros modelos. Para usar el algoritmo Zero-R, recurrimos al estimador `DummyClassifier` de `scikit-learn`:"},{"metadata":{"trusted":true},"cell_type":"code","source":"ZeroR = DummyClassifier(strategy=\"most_frequent\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Inducción de árboles de decisión"},{"metadata":{},"cell_type":"markdown","source":"Vamos a usar ahora un árbol de decisión, usamos el estimador `DecisionTreeClassifier` de `scikit-learn`. Usamos la misma semilla, como siempre, para que las pruebas sean reprodubibles."},{"metadata":{"trusted":true},"cell_type":"code","source":"ArbolDecision = DecisionTreeClassifier(random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### *Pipeline*"},{"metadata":{},"cell_type":"markdown","source":"Para crear un *pipeline*, vamos a usar la función `make_pipeline` de `scikit-learn`. Esta toma como parámetros la lista de transformadores a aplicar al conjunto de datos y, al final de este, el estimador a utilizar.\n\nLos transformadores de limpieza que hemos son:\n* Eliminar las variables `Insulin` y `SkinThickness`.\n* Imputar valores perdidos de `Glucose`, `BloodPressure` y `BMI`.\n* Eliminar outliers de todas las variables que los tengan.\n\nVamos a evaluar 5 modelos distintos para comprobar como afectan los distintas transformadores a los resultados:\n* Usando el algoritmo `ZeroR`.\n* Usando el algoritmo `DecisionTreeClassifier`.\n* Pipeline usando `DecisionTreeClassifier` y los transformadores de limpieza.\n* Pipeline usando `DecisionTreeClassifier` y `KBinsDiscretizer`.\n* Pipeline usando `DecisionTreeClassifier`, los transformadores de limpieza y `KBinsDiscretizer`."},{"metadata":{"trusted":true},"cell_type":"code","source":"eliminadas = ['Insulin','SkinThickness']\n\nPipeline1 = make_pipeline(EliminarVariables(eliminadas),Imputador,EliminarOutliers, ArbolDecision)\nPipeline2 = make_pipeline(Discretizador, ArbolDecision)\nPipeline3 = make_pipeline(EliminarVariables(eliminadas),Imputador,EliminarOutliers, Discretizador, ArbolDecision)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5.2 Evaluación de modelos"},{"metadata":{"_uuid":"96ade70b1295a55b55307c9bd09cfd37a783c1e4"},"cell_type":"markdown","source":"Ahora es el momento de entrenar y validar nuestros clasificadores. Para ello, vamos a usar una matriz de confusión y tasa de acierto.\n\n### Zero_R"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(ZeroR,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"56eac04a7c1e86758c1a208ba0d568d216132393"},"cell_type":"markdown","source":"Como era de esperar, el modelo *Zero-R* obtiene malos resultados, solo predice la clase mayoritaria (0). Si la clase estuviera balanceada, obtendríamos una precisión todavía peor, del 50%. Vamos a probar otros modelos para ver cuánto mejora la precisión."},{"metadata":{},"cell_type":"markdown","source":"### Árbol de decisión"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(ArbolDecision,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Árbol de decisión con los transformadores de limpieza"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(Pipeline1,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Árbol de decisión discretizando el conjunto de datos"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(Pipeline2,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Árbol de decisión discretizando el conjunto de datos y usando los transformadores de limpieza"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(Pipeline3,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como era evidente, los árboles de decisión obtienen mejores resultados que Zero_R, que tiene un 65.1% de precisión, lo cual es lógico teniendo en cuenta que ese es el porcentaje de ceros que hay en la variable clase; tanto en el conjunto de datos original, como en el conjunto de entrenamiento (gracias a que hemos estratificado correctamente). No importa que discreticemos o no, ni que usemos o no los transformadores de limpieza, todos los modelos con árbol de clasificación superan al algoritmo Zero_R.\n\nUsando simplemente árboles de decisión, obtenemos una tasa de acierto del 66.67%, lo cual supone una mejora de más de 1.5% respecto al Zero_R.\n\nSi usamos también los transformadores de limpieza, obtenemos una precisión del 67.2%, que indica una mejora del 0.5% aproximadamente respecto a no usar esos transformadores.\n\nSi usamos árboles de decisión y discretizamos el conjunto de datos (al igual que se hacía en la libreta de `iris`), se obtiene una tasa de acierto de 68.22%, mejorando en un 1.5% a su versión sin discretizar.\n\nY por último, si con árboles de decisión usamos los transformadores de limpieza y discretizamos el conjunto de datos, conseguimos la mayor precisión de todas, 71.35%.\n\nEstos resultados pueden variar mucho según la semilla que elijamos (por la aleatoriedad) y porque estas base de datos con las que estamos trabajando son muy pequeñas, y fallar o acertar la predicción en un par de registros puede variar mucho los resultados. Para obtener resultados más fiables, podríamos ejecutar estos mismos algoritmos con 100 semillas distintas (por ejemplo), y devolver como medida de precisión la media de todas esas pruebas. Otra opción sería realizar una validación cruzada, para evitar resultados demasiado buenos o demasiado malos."},{"metadata":{},"cell_type":"markdown","source":"---\n\nAhora vamos a realizar los mismos pasos, pero para la base de datos `Wisconsin`."},{"metadata":{},"cell_type":"markdown","source":"# Breast Cancer Wisconsin (Diagnostic) Data Set"},{"metadata":{},"cell_type":"markdown","source":"## 1. Preliminares"},{"metadata":{},"cell_type":"markdown","source":"Vamos a usar los mismos *imports* y la misma semilla que en el análisis exploratorio de la base de datos `pima_diabetes`, por lo que no debemos realizar nada en este apartado."},{"metadata":{},"cell_type":"markdown","source":"## 2. Acceso y almacenamiento de datos"},{"metadata":{},"cell_type":"markdown","source":"Ahora, vamos a cargar los datos de la base de datos desde el fichero .csv, y definimos el nombre de la columna de id y de la clase."},{"metadata":{"trusted":true},"cell_type":"code","source":"filepath = \"../input/breast-cancer-wisconsin-data/data.csv\"\n\nindex = \"id\"\ntarget = \"diagnosis\"\n\n\ndata = utils.load_data(filepath, index, target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Comprobamos que la carga se ha realizado correctamente, mediante un muestreo de 5 instancias:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"En el muestreo anterior podemos ver cómo hay una variable cuyo nombre es `Unnamed 32`. Lo volvemos a comprobar con data.info:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info(memory_usage=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Y podemos ver cómo se crea una última columna sin ningún dato ni nombre. Esto es debido a que en el fichero .csv la línea con el nombre de las variables acaba con una coma, por lo que Pandas detecta una variable más sin ningún nombre especificado. Para arreglarlo, simplemente borramos esa columna, aunque también podríamos haber modificado el archivo .csv."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(data.columns[[31]], axis='columns')\ndata.info(memory_usage=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como podemos ver, ahora ya contamos con las 31 columnas que tenemos que tener.\n\nAhora, vamos a dividir nuestra base de datos en los conjuntos de variables predictoras (`X`), y variables predictivas (`y`)."},{"metadata":{"trusted":true},"cell_type":"code","source":"(X, y) = utils.divide_dataset(data, target=\"diagnosis\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Al igual que antes, comprobamos que el conjunto de datos se haya separado correctamente:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Y ahora dividimos nuestros datos en los conjuntos de entrenamiento y prueba para `X` e `y`, con unos porcentajes de 70% entrenamiento y 30% prueba. Además, al hacerlo los datos se aleatorizan, evitando así problemas con bases de datos ordenadas."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size = 0.7\n\n(X_train, X_test, y_train, y_test) = train_test_split(X, y,\n                                                      stratify=y,\n                                                      random_state=seed,\n                                                      train_size=train_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Y comprobamos que los 4 conjuntos resultantes son correctos:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como parecen correctos, para facilitar el análisis exploratorio posterior, vamos a juntar tanto X_train e y_train, como X_test e y_test:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train = utils.join_dataset(X_train, y_train)\ndata_test = utils.join_dataset(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Y volvemos a comprobar que los conjuntos creados son correctos:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Y al igual que antes, también parece que se han realizado las uniones correctamente.\n\n---\n\n## 3. Análisis exploratorio de datos\n\nPrimero vamos a ver el tamaño de nuestro problema, conociendo el tamaño los conjuntos de datos que hemos creado, y los tipos de variables que éstos tienen."},{"metadata":{},"cell_type":"markdown","source":"### 3.1 Descripción del conjunto de datos\n\nPrimero vamos a ver el tamaño de nuestro problema, conociendo el tamaño los conjuntos de datos que hemos creado, y los tipos de variables que éstos tienen."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.info(memory_usage=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_barplot(data_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos ver que tenemos 398 instancias, en las cuales contamos con 30 variables predictoras numéricas, y una variable clase categórica (la variable clase). Además, esta variable clase tiene 2 estados posibles, `B` y `M`, habiendo bastantes más casos de `B` que de `M` por lo que nuestra muestra no está balanceada.\n\nEn cuanto a las variables predictoras, se dividen en 3 conjuntos atendiendo a la nomenclatura de las variables:\n* Medias: Las 10 primeras variables son medias de distintos parámetros de las células.\n* Desviación típica: Las 10 siguientes son las desviaciones típicas de dichos parámetros.\n* Peor: Y las 10 últimas son el peor de los casos para cada variable, de entre las células observadas."},{"metadata":{},"cell_type":"markdown","source":"### 3.2 Visualización de las variables\n\n---\n\n### 3.2.1 Análisis multivariado\n\nPrimero vamos a comprobar la correlación de las variables predictoras realizando un análisis multivariado, ya que como tenemos una gran cantidad de variables (30), si podemos deberíamos intentar reducir ese número antes de iniciar una análisis univariado.\n\nPodríamos usar esta función de `plotly` para hacerlo, pero se ve más claro con `Seaborn`.\n> px.imshow(data_train.corr(method=\"pearson\"))"},{"metadata":{"trusted":true},"cell_type":"code","source":"figure(figsize=(20,15))\n\nsb.heatmap(data_train.corr(), annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"De este análisis de correlación podemos obtener conclusiones valiosas (poniendo el umbral entre muy correlacionadas y no en 0,9):\n* Por un lado, las variables `radius_mean`, `perimeter_mean` y `area_mean` están muy correlacionadas, lo cual tiene mucho sentido viendo que tanto el perímetro como el área son funciones matemáticas basadas en la multiplicación del radio por un número. Lo mismo pasa entre `radius_se`, `perimeter_se` y `area_se`; y entre `radius_worst`, `perimeter_worst` y `area_worst`. Por lógica, nos vamos a quedar con los valores del radio ya que los otros están basados en él. Por tanto, nos quedamos solo con `radius_mean`, `radius_sd` y `radius_worst`.\n* Además, la media del radio `radius_mean` está muy correlacionada con su peor valor `radius_worst`, por lo que podemos eliminar este último.\n* Con `texture_mean` y `texture_worst` pasa exactamente lo mismo, por lo que también eliminaremos `texture_worst`.\n* `concavity_mean`, `concave points_mean`, `compactness_mean` están muy relacionadas, por lo que nos quedamos con `concavity_mean`, y con `concavity_worst`, `concave points_worst` y `compactness_worst` ocurre lo mismo, quedándonos con `concavity_worst`.\n* Pero además, `concavity_mean` y `concavity_worst` también están muy correlacionadas, por lo que eliminamos esta última.\n\nPor ello, vamos a eliminar las variables comentadas anteriormente de `data_train`, simplificando así la base de datos perdiendo la mínima información posible. \n\nEsto lo hacemos para continuar la visualización de las variables solo con las que nos interesan, aunque posteriormente hagamos el borrado dentro del *pipeline* ya que no usaremos `data_train` si no `X_train` e `y_train`."},{"metadata":{"trusted":true},"cell_type":"code","source":"borrado = ['perimeter_mean', 'area_mean', 'perimeter_se', 'area_se', 'perimeter_worst', 'area_worst', \n           'area_worst', 'radius_worst', 'texture_worst', 'concave points_mean', 'compactness_mean', \n           'concave points_worst', 'compactness_worst', 'concavity_worst']\n\ndata_train.drop(borrado, axis='columns', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Y comprobamos con el mapa de calor que el borrado se ha realizado correctamente, y qu eno nos dejamos ninguna variable con alta correlación."},{"metadata":{"trusted":true},"cell_type":"code","source":"figure(figsize=(16,13))\n\nsb.heatmap(data_train.corr(), annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"De esta forma nos hemos quedado solo con 17 variables, teniendo así menos datos redundantes (lo cual es bastante malo para algunos algoritmos) ya que ahora cada una de las variables aporta bastante información propia."},{"metadata":{},"cell_type":"markdown","source":"### 3.2.2 Análisis univariado\n\nAhora, vamos a realizar un análisis univariado de las variables. Primero vamos a comprobar si nuestros datos tienen *outliers*. Para ello, nos hará falta dividir nuestro nuevo `data_train` en `X_train2` e `y_train2`, del mismo modo que hicimos anteriormente, y comprobar que están bien divididos."},{"metadata":{"trusted":true},"cell_type":"code","source":"(X_train2, y_train2) = utils.divide_dataset(data_train, target=\"diagnosis\")\n\nX_train2.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train2.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Una vez divididos, y comprobado que la división se ha realizado correctamente, vamos a representar un gráfico de cajas en el que podremos ver si contamos con outliers, además de la distribución de cada variable para la clase. Para ello, primero tenemos que estandarizar los datos, creando `data_est`.\n\nUna versión usando *plotly* en lugar de *seaborn* sería:\n> px.box(data_grafica, x=\"Variables\", y=\"Estandarización\", color=\"diagnosis\")\n\nSin embargo, como en ocasiones *plotly* no funciona o relantiza mucho *Kaggle*, además de que en este caso se ven más claro los datos con *Seaborn*, nos quedaremos con esta última librería. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Estandarizamos los datos\ndata_est = (X_train2 - X_train2.mean()) / (X_train2.std()) \n\n# Convertimos los datos para que puedan ser representados en la gráfica\ndata_grafica = pd.concat([y_train2, data_est], axis = 1)\ndata_grafica = pd.melt(data_grafica, id_vars = \"diagnosis\",\n                     var_name = \"Variables\",\n                     value_name = \"Estandarización\")\n\n# Definimos el tamaño y el tipo de gráfica\npypl.figure(figsize = (25,10))\nsb.boxplot(x=\"Variables\", y=\"Estandarización\", hue=\"diagnosis\", data=data_grafica)\n\n# Rotamos el nombre de las variables para que no se solapen\npypl.xticks(rotation = 90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos ver cómo contamos con *outliers* en todas las variables, por lo que los tendremos que eliminar posteriormente en el *pipeline*.\n\nAdemás, en esta gráfica podemos ver cómo variables como `radius_mean` o `concavity_mean` pueden ser muy buenas para la clasificación ya que están muy diferenciadas entre `B` y `M`. Todo lo contrario pasa con otras variables como `texture_se` o `smoothness_se`, que será difícil que sean útiles para nuestro árbol de clasificación.\n\n---\n\nAhora vamos a representar cada uno de los puntos de nuestro conjunto de test. En *plotly* podríamos hacer algo parecido usando:\n\n> px.strip(data_grafica, x=\"Variables\", y=\"Estandarización\", color=\"diagnosis\")\n\nSin embargo, también lo vamos a realizar con *Seaborn* ya que se ve mucho mejor."},{"metadata":{"trusted":true},"cell_type":"code","source":"sb.catplot(x=\"Variables\", y=\"Estandarización\", hue=\"diagnosis\", data=data_grafica, height=10, aspect=5/2, kind=\"swarm\")\npypl.xticks(rotation = 90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos ver cómo efectivamente variables como `radius_mean`, `radius_se`, `radius_worst` o `concavity_mean` crean una división casi perfecta entre los casos Benignos y Malignos, mientras que otras como `texture_se`, `smoothness_se`, `fractal_dimension_mean` o `symmetry_se` están totalmente mezcladas.\n\nEl que haya variables que puedan crear una buena división por sí mismas nos dice que el modelo que generemos finalmente probablemente tenga un gran porcentaje de acierto, ya que simplemente usando esa clase se conseguiría un resultado decente.\n\n---\n\nAdemás, vamos a observar el histograma de las variables:"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_histogram(data_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos ver cómo todas las variables siguen más o menos una distribución normal. Sin embargo, algunas variables como `concavity_mean`, `radius_se`, `compactness_se` y `fractal_dimension_se` tienen una asimetría positiva bastante destacable. También podemos ver claramente los *outliers* en algunas variables como `concavity_se` o `radius_se`, entre otras."},{"metadata":{},"cell_type":"markdown","source":"## 4. Preprocesamiento de datos\n\n---\n\n### 4.1. Eliminar variables\n\nPara eliminar las variables vamos a crear esta función simple (`EliminarVariables`) con `fit` y `transform` para poderlo usar en el *pipeline*. Simplemente tenemos que pasar por parámetro las variables que queremos borrar."},{"metadata":{"trusted":true},"cell_type":"code","source":"class EliminarVariables():\n\n    def __init__(self, columnas):\n        self.columnas=columnas\n\n    def fit(self, x, y=None):\n        return self\n\n    def transform(self, x, y=None):\n        return x.drop(self.columnas, axis='columns', inplace=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.2. Eliminación de *outliers*\n\nPara eliminar los *outliers* vamos a usar una función (`outlier_rejection`) que cree un `IsolationForest` para detectarlos, y después pasarla por un `FunctionSampler` para poder incluirla en el *pipeline*."},{"metadata":{"trusted":true},"cell_type":"code","source":"def outlier_rejection(X, y):\n\n    model = IsolationForest(max_samples=100,\n                            contamination=0.4,\n                            random_state=seed)\n    model.fit(X)\n    y_pred = model.predict(X)\n    return X[y_pred == 1], y[y_pred == 1]\n\nelimOutliers = FunctionSampler(func=outlier_rejection)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.3. Discretización\n\n___\n\nVamos a utilizar un discretizador por `kmeans = 2`, ya que como hemos visto en el análisis de las variables, muchas de ellas como `radius_mean`, `radius_se`, `radius_worst`, `concavity_mean` o `concavity_worst` se pueden dividir casi perfectamente en dos partes, dejando a cada lado la clase mayoritaria. Además, usamos `kmeans` porque como los datos están desbalanceados, si partiésemos por ejemplo por la media seguramente esa partición sería peor. "},{"metadata":{"trusted":true},"cell_type":"code","source":"discretizer = KBinsDiscretizer(n_bins=2, strategy=\"kmeans\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Aprendizaje y evaluación de modelos\n\n---\n\n### 5.1. Algoritmo Zero-R\n\nPrimero vamos a crear un clasificador `Zero-R`, que nos servirá como *baseline* para poder comparar con los valores que obtengamos de nuestros árboles de clasificación."},{"metadata":{"trusted":true},"cell_type":"code","source":"zero_r_model = DummyClassifier(strategy=\"most_frequent\")\n\nutils.evaluate(zero_r_model,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"En el algoritmo *Zero-R* siempre se predecirá la clase mayoritaria, en este caso B (62,81% en los datos de entrenamiento). La tasa de acierto es por tanto un número muy cercano a dicho porcentaje (0,62573), ya que 0,6281 sería dicha tasa si utilizásemos el conjunto de datos de entrenamiento como test. Este rendimento es muy malo, ovbiamente, ya que tenemos que predecir si el cáncer de mama es benigno o maligno, y para todos los casos diríamos que es benigno.\n\n---\n\n### 5.2. Algoritmo *CART* (*Classification and Regression Trees*)\n\n---\n\n### 5.2.1. Algoritmo *CART* sin eliminar variables y *outliers*.\n\nAhora vamos a probar los modelos basados en árboles de clasificación sin discretizar.\n\nPrimero creamos nuestro clasificador `DecisionTreeClassifier`, que usaremos para todas las demás modelos de árboles de clasificación. Como hiperparámetros incluiremos la semilla, que garanzita que los resultados sean reproducibles; vamos a establecer como criterio la entropía en lugar de Gini, ya que es el que más hemos usado en asignaturas anteriores y en la parte de teoría de Minería de Datos; y establecemos a 4 el mínimo de hojas para no realizar un sobreajuste demasiado grande en las hojas del árbol.\n\nAhora, vamos a comprobar el rendimiento del clasificador usando la base de datos original:"},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_model = DecisionTreeClassifier(random_state=seed,\n                                    criterion='entropy',\n                                    min_samples_leaf = 5)\n\nutils.evaluate(tree_model,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos ver cómo obtenemos un *accuracy* del 93,567%, lo cual es una mejora muy grande con respecto a `Zero-R`. Tiene sentido, ya que como hemos visto en el análisis exploratorio de los datos había varias variables que podían dividir bastante bien los datos dependiendo de la clase `B`o `M` obteniendo poco error.\n\n---\n\nTambién podemos representar el árbol que se ha generado usando la librería `graphviz`, que es el siguiente:"},{"metadata":{"trusted":true},"cell_type":"code","source":"dot_data = tree.export_graphviz(tree_model, out_file=None, \n                         feature_names=list(X_train),  \n                         class_names=[\"B\", \"M\"],  \n                         filled=True, rounded=True,  \n                         special_characters=True)\n\ngraphviz.Source(dot_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos ver cómo no es excesivamente grande, y utiliza varias variables como `permieter_worst` o `concave points_worst` que nosotros hemos eliminado en el análisis exploratorio de datos, por lo que si no hemos realizado bien el proceso de selección de variables, el resultado al borrarlas podría verse muy afectado.\n\n---\n\n### 5.2.2. Algoritmo CART eliminando variables y outliers.\n\nAhora vamos a realizar un *pipeline* realizando la eliminación de las variables que tenían una gran correlación en el análisis exploratorio, y de los outliers que también encontramos en dicho análisis antes de evaluar el árbol de clasificación."},{"metadata":{"trusted":true},"cell_type":"code","source":"sinOutliers_tree_model = make_pipeline(EliminarVariables(borrado),\n                                       elimOutliers,\n                                       tree_model)\n\nutils.evaluate(sinOutliers_tree_model,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vemos como la tasa de aciertos ha disminuido del 93,567% al 90,058%. No es una diferencia muy grande teniendo en cuenta que los conjuntos de entrenamiento y test no son muy grandes, por lo que el resultado se puede ver bastante afectado dependiendo de la semilla que hayamos definido. Aún así, dicho resultado tiene sentido ya que los árboles de clasificación con variables numéricas no se ven afectados por el hecho de tener variables muy correlacionadas entre sí, ni les castiga excesivamente la presencia de algunos outliers.\n\nAsí, con poco que eliminemos alguna variable que sea un algo mejor clasificando que las que dejamos, o que por lo que sea viene mejor para los datos de test que tenemos, ya reduciremos sensiblemente la tasa de acierto.\n\n---\n\nAl igual que antes, también vamos a representar el árbol:"},{"metadata":{"trusted":true},"cell_type":"code","source":"dot_data = tree.export_graphviz(tree_model, out_file=None, \n                         feature_names=list(X_train2),  \n                         class_names=[\"B\", \"M\"],  \n                         filled=True, rounded=True,  \n                         special_characters=True)\n\ngraphviz.Source(dot_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como podemos ver, solo aparecen las variables que dejamos en el análisis exploratorio, por lo que el *pipeline* parece haber funcionado correctamente. Este árbol es prácticamente del mismo tamaño que el anterior, ya que como en nuestra base de datos tenemos pocas instancias, el pasar de 30 a 17 variables predictoras no hace que disminuya el tamaño de éste ya que se queda antes sin instancias que sin variables. Con una base de datos más grande, seguramente sí que podríamos conseguir un modelo más compacto que sobreajuste menos.\n\n___\n\n### 5.3. Algoritmo CART (Classification and Regression Trees) con discretización\n\n---\n\n### 5.3.1. Algoritmo CART discretizando, pero sin eliminar variables y outliers.\n\nAhora vamos a comprobar el rendimiento del árbol de decisión cuando le aplicamos el discretizador por `kmeans` con 2 *bins*. "},{"metadata":{"trusted":true},"cell_type":"code","source":"discretize_tree_model = make_pipeline(discretizer, \n                                      tree_model)\n\nutils.evaluate(discretize_tree_model,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos ver cómo hemos obtenido un porcentaje de acierto del 92,398%, algo menor que el 93,567% que obteníamos sin discretizar. Con esta variación tan pequeña no podemos obtener ninguna conclusión sobre cuál es mejor, aunque es un buen valor teniendo en cuenta que los árboles de clasificación trabajan especialmente bien con variables continuas.\n\n___\n\n### 5.3.2. Algoritmo *CART* discretizando y eliminando variables y *outliers*.\n\nPor último, vamos a aplicar la eliminación de variables y *outliers* junto con la discretización."},{"metadata":{"trusted":true},"cell_type":"code","source":"discretize_tree_model = make_pipeline(EliminarVariables(borrado),\n                                      elimOutliers, \n                                      discretizer, \n                                      tree_model)\n\nutils.evaluate(discretize_tree_model,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos ver que en este caso el porcentaje de acierto ha bajado de un 92,398% a un 91,913%. Este resultado es más extraño que los anteriores ya que para la discretización sí que es especialmente útil la eliminación de outliers que no alteren artificialmente los intervalos, por lo que podemos presuponer que esta pequeña reducción del *accuracy* viene dada simplemente por tener mala suerte con estos datos en concreto o con la semilla escogida en los casos que se use la aleatorización."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}