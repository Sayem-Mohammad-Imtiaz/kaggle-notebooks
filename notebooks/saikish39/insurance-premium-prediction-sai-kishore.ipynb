{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#Importing Seaborn\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reading from the CSV File\n\ndf = pd.read_csv(\"../input/insurance.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check the header to get a rough idea about the columns and rows\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Describe the dataframe to know about it's statistics \n\ndf.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that the data given to us does not contain any significant outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Obtaining the total rows and columns (Entries)\n\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We need to get to know about the data types of columns\n\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can infer that there are three categorical columns "},{"metadata":{"trusted":true},"cell_type":"code","source":"#We are checking for Null values\n\ndf.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are no null values present in the dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"#We are looking for duplicated rows \n\ndf.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* There is one duplicated row.\n* We need to remove it from the dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Removing duplicated rows\n\ndf = df.drop_duplicates()\ndf.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking the dataframe\n\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we need to preprocess the categorical data and convert it to useful numbers for our model "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking the 'Sex' column for any ambiguous/incorrect entries\n\ndf.sex.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are no incorrect/ambiguous entry in this column"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking the 'Region' column for any ambiguous/incorrect entries\n\ndf.region.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are no incorrect/ambiguous entry in this column"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking the 'Smoker' column for any ambiguous/incorrect entries\n\ndf.smoker.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are no incorrect/ambiguous entry in this column"},{"metadata":{},"cell_type":"markdown","source":"Since the smoker column has only two distinct categorical entries, we can simply replace them with 0/1"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Replacing 'no' with 0 and 'yes' with 1 in the dataframe\n\ndf.smoker.replace({\"no\":0,\"yes\":1}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that the smoker column has been changed to a numerical one"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking the Correlation between each columns\n\ndf.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our target data is expenses and we can see that it has high correlation with the smoker column."},{"metadata":{},"cell_type":"markdown","source":"We will see the whole distribution of data using different plots"},{"metadata":{"trusted":true},"cell_type":"code","source":"#We are using Pairplot to get a visual representation of complete data distribution\n\nsns.pairplot(data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We need to try to draw a linear line between our target data and the columns which have considerable impact on our target data."},{"metadata":{"trusted":true},"cell_type":"code","source":"#We use regplot to draw a linear regression line between two columns, namely, age & expenses here.\n\nsns.regplot(x=df[\"age\"],y=df[\"expenses\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This does not give a clear idea as the data is distributed evenly. So, we need to change the parameters."},{"metadata":{},"cell_type":"markdown","source":"We need to change the plot and try to include one more parameter which might help us understand the data distribution better."},{"metadata":{"trusted":true},"cell_type":"code","source":"#We use scatterplot so that we can include the smoker column, which has high correlation with expenses \n#and see whether it gives any knowledge on the dataframe \n\nsns.scatterplot(x=df[\"bmi\"],y=df[\"expenses\"],hue=df[\"smoker\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As expected, smoker column gives us a rough idea on what is influencing the target data."},{"metadata":{"trusted":true},"cell_type":"code","source":"#We can alter the parameters to get a better visual representation\n\nsns.scatterplot(x=df[\"age\"],y=df[\"expenses\"],hue=df[\"smoker\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Again, we need to refine the parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"#We will make use of the lmplot to draw two regression lines for the parameters.\n\nsns.lmplot(x=\"bmi\", y=\"expenses\", hue=\"smoker\", data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We can make use of swarmplot to better understand the relationship between expenses and smoker columns\n\nsns.swarmplot(x=df[\"smoker\"],y=df[\"expenses\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can finally infer that the target data of our dataset is strongly depending on smoker column. Apart from this, the bmi and age column has considerable significance as well."},{"metadata":{},"cell_type":"markdown","source":"Now, we need to convert the rest of the categorical columns to numbers."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Selecting the categorical columns\n\ndf_categorical_col = df.select_dtypes(exclude=np.number).columns\ndf_categorical_col","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Selecting the numerical columns\n\ndf_numeric_col = df.select_dtypes(include=np.number).columns\ndf_numeric_col","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can perform One hot encoding to convert these categorical data to numerical ones as they are nominal data."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Get the truth table of each row for the categorical columns\n\ndf_onehot = pd.get_dummies(df[df_categorical_col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Viewing the obatined truth table\n\ndf_onehot","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have obtained an encoded truth table for all the 1337 entries. Now we need to concatenate it with other numerical columns. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Concatenation of encoded data and existing numerical columns we obtained earlier.\n\ndf_after_encoding = pd.concat([df[df_numeric_col],df_onehot], axis = 1)\ndf_after_encoding","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above dataframe does not have any categorical columns and can be further used for developing a model"},{"metadata":{},"cell_type":"markdown","source":"We will be implementing the Linear Regression model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importing necessary libraries for Linear Regression\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Selecting the 'y' value (Target Data)\n\ny = df_after_encoding[\"expenses\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Selecting the 'x' value (Coefficients array)\n\nx = df_after_encoding.drop(columns = \"expenses\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We need to split the data into Train and Test datasets for training the model and then testing it to check the accuracy."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Splitting the dataframe into train & test datasets in 70:30 ratio\n\ntrain_x, test_x, train_y, test_y = train_test_split(x,y,test_size=0.3,random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Selecting the model\n\nmodel = LinearRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We need to draw a best-fit line for our model\n\nmodel.fit(train_x,train_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Print the obtained 'c' value\n\nprint(model.intercept_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Print the obtained 'x' coefficients value\n\nprint(model.coef_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have obtained the model formula using which we can predict the target data. "},{"metadata":{},"cell_type":"markdown","source":"We will check the accuracy of the model by implementing the following tests."},{"metadata":{"trusted":true},"cell_type":"code","source":"#We are Predicting the target data for our dataset\n\nprint(\"Predicting train data\")\ntrain_predict = model.predict(train_x)\nprint(\"Predicting test data\")\ntest_predict = model.predict(test_x)\n\n#Test using MAE, MSE, RMSE, R^2 Error\nprint(\" \")\nprint(\"MAE\")\nprint(\"Train data: \",mean_absolute_error(train_y,train_predict))\nprint(\"Test data: \",mean_absolute_error(test_y,test_predict))\nprint(\" \")\nprint(\"MSE\")\nprint(\"Train data: \",mean_squared_error(train_y,train_predict))\nprint(\"Test data: \",mean_squared_error(test_y,test_predict))\nprint(\" \")\nprint(\"RMSE\")\nprint(\"Train data: \",np.sqrt(mean_squared_error(train_y,train_predict)))\nprint(\"Test data: \",np.sqrt(mean_squared_error(test_y,test_predict)))\nprint(\" \")\nprint(\"R^2\")\nprint(\"Train data: \",r2_score(train_y,train_predict))\nprint(\"Test data: \",r2_score(test_y,test_predict))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that there is a slight difference in the train and test data for every test. We can say that our model is fairly accurate and can be improved upon performing further changes in the preprocessing of data."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}