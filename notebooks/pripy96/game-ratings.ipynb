{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.preprocessing import LabelEncoder\nfrom torchvision.transforms import transforms\n\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns', 500)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/video-games-rating-by-esrb/test_esrb.csv')\ndf_test = pd.read_csv('/kaggle/input/video-games-rating-by-esrb/Video_games_esrb_rating.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x=df_train['esrb_rating'].value_counts().index, y=df_train['esrb_rating'].value_counts());","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterions = df_train.select_dtypes('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion_dict = {}\nfor col in criterions:\n    criterion_df = df_train.groupby('esrb_rating', as_index=False).agg({f'{col}': 'mean'})\n    criterion_df[f'{col}'] = criterion_df[f'{col}'] * 100\n    criterion_dict[f'{col}'] = criterion_df\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"    criterion_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dict_key = list(criterion_dict.keys())\nfig, axs = plt.subplots(8, 4, figsize=(18,14))\nfig.tight_layout()\n\nfor i, axis in enumerate(axs.reshape(32)):\n    data = criterion_dict[dict_key[i]]\n    axis.bar(x=data['esrb_rating'], height=data[f'{dict_key[i]}'])\n    axis.title.set_text(dict_key[i])\n    axis.set_ylabel('precentage')\n    \nplt.xlabel = 'Ratings'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see that mature humour is not responsible for any class to be classify so we can drop this feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.drop('mature_humor', axis=1,inplace=True)\ndf_test.drop('mature_humor', axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_encoder = LabelEncoder()\ndf_train['esrb_rating'] = target_encoder.fit_transform(df_train['esrb_rating'])\ndf_test['esrb_rating'] = target_encoder.transform(df_test['esrb_rating'])\ndf_train_clean = df_train.drop('title', axis=1)\ndf_test_clean = df_test.drop('title', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class GameDataset(Dataset):\n\n    def __init__(self, df, target=None,transform=None):\n        # Data Loading\n        super(GameDataset, self).__init__()\n        self.x = df.drop(target, axis=1).values\n        self.y = df[target].values\n#         self.x = torch.from_numpy(x)\n#         self.y = torch.from_numpy(y)\n        self.n_samples = self.x.shape[0]\n        self.transform = transform\n\n    def __getitem__(self, index):\n        sample = self.x[index], self.y[index]\n        if self.transform:\n            sample = self.transform(sample)\n        return sample\n\n    def __len__(self):\n        return self.n_samples\n\n\ndataset = GameDataset(df_train_clean, target='esrb_rating')\ndataloader = DataLoader(dataset=dataset, batch_size=45, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_clean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.l1 = torch.nn.Linear(31, 128)\n        self.relu = torch.nn.ReLU()\n        self.l2 = torch.nn.Linear(128, 64)\n        self.l3 = torch.nn.Linear(64, 32)\n        self.l4 = torch.nn.Linear(32, 4)\n        \n        \n    def forward(self, x):\n        x = self.relu(self.l1(x))\n        x = self.relu(self.l2(x))\n        x = self.relu(self.l3(x))\n        x = self.l4(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 100\nlearning_rate = 0.001\nmodel = Model()\ncriterion = nn.CrossEntropyLoss()\noptim = torch.optim.Adam(model.parameters(), lr=learning_rate)\nn_total_steps = len(dataloader)\n\nfor epoch in range(num_epochs):\n    for i, (datapoint, labels) in enumerate(dataloader):\n        labels = labels.reshape(labels.shape[0],1)\n        output = model(datapoint)\n        loss = criterion(outputs, labels)\n\n        optim.zero_grad()\n        loss.backward()\n        optim.step()\n\n        if (i + 1) % 100 == 0:\n            print(f\"epochs {epoch + 1}/{num_epochs}, step {i + 1}/{n_total_steps}, loss = {loss.item():.4f}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}