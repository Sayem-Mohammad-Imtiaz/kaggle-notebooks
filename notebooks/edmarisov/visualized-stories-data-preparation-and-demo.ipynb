{"cells":[{"metadata":{},"cell_type":"markdown","source":"> ## Data preparation scripts\nIn this kernel I want to share data preparation scripts which were used for this visualization project. \nData used on the demo page are for 2006â€“2007 period, but since its format is the same as current one - code below is applicable for any period of time. \nYou can build your own dataset using those scripts and visualize it using project which is publicly available on the GitHub.\n\nCode: https://github.com/edmarisov/cavernsoftime \n\nVisualization demo: https://www.cavernsoftime.net/"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom collections import Counter","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Data export tools.\n#usage: prepare_data(category, dataframe) \n# - Saves data in chunks of 2 days under a folder named with value from \"category\" variable. \n# - Also generates index.json file with mapping (<date>: <chunk file path>)\n\nimport json\nimport os\nimport math\n\ndef del_none(d):\n    \"\"\"\n    Delete keys with the value ``None`` in a dictionary, recursively.\n\n    This alters the input so you may wish to ``copy`` the dict first.\n    \"\"\"\n    for key, value in list(d.items()):\n        #print('1:%s %s' % (key, type(value)))\n        if isinstance(value, dict):\n            del_none(value)\n        elif value is None or math.isnan(value) or not isinstance(key, str):\n            del d[key]\n\n    return d  # For convenience\n\n\ndef prepare_data(category, df):\n    directory = '../cavernsoftime/data/%s' % category\n    \n    if os.path.exists(directory):\n        shutil.rmtree(directory)\n        \n    os.makedirs(directory)\n    \n    prev_date = None\n    data = {}\n    index = {}\n    for idx in range(len(df.index.get_level_values(0))):\n        l = df.index.get_level_values(0)[idx]\n        if(prev_date is None):\n            prev_date = l\n        key = l.strftime('%m/%d/%y %H:%M:%S')\n        data[key] = df.xs(l).to_dict(orient='index')\n        if l - prev_date > pd.Timedelta(days=2) or idx == len(df.index.get_level_values(0)) - 1:\n            print(l)\n            file_name = prev_date.strftime('%m_%d_%y_%H_%M_%S.json')\n            file_path = '%s/%s' % (directory, file_name)\n            index[prev_date.strftime('%m/%d/%y %H:%M:%S')] = '/data/%s/%s' % (category, file_name)\n            with open(file_path, \"w\") as data_file:\n                json.dump(del_none(data), data_file, indent=2)\n\n            prev_date = None\n            data = {}\n\n    with open('data/index.json', \"w\") as data_file:\n        json.dump(index, data_file, indent=2)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#loading the data\ndf = pd.read_csv('../input/wowah_data.csv', \n                         sep=',', \n                         error_bad_lines=False)\n\n#column names contains leading space\ndf.columns = [col.replace(' ', '') for col in df.columns]\n\ndf['timestamp'] = pd.to_datetime(df['timestamp'], utc=False, format='%m/%d/%y %H:%M:%S')\ndf['level'] = df['level'].astype('int64')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#New column \"moved_to\" containing information about player's next zone:\nchar_grp = df.groupby('char', sort=False)\ndf['moved_to'] = char_grp['zone'].shift()\ndf.loc[df['moved_to'] == df['zone'], 'moved_to'] = None\n\n#New column lvl_diff which contains player's level difference between two consequent observations\ndf['lvl_diff'] = char_grp['level'].diff().fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#exporting data, which contains number of players per zone and how many players moved from one specific zone to another.\n\nall_data = df.groupby([pd.Grouper(key='timestamp', freq='10Min'), 'zone'], sort=False).agg({\n            'char': {\n                'char_count': 'nunique'\n            },\n            'moved_to': {\n                'moves': lambda s: Counter(s)\n            }\n    })\n\nall_data.columns = all_data.columns.droplevel()\nall_data[1000:].head()\n\n#export the data\n#prepare_data('default', all_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now I want to find player with \"average leveling path from level 1 to lvl 60\". \n#It is done by selecting all players who leveled from lvl 1 to lvl 60,\n#And then taking average time taken to level-up (time between different levels) per player followed by median across those values.\n\nstart = df.loc[df['level'] == 1]\nend = df.loc[df['level'] == 60]\n\n#take all users who did 1-60 lvl\njoined = start.merge(end, on='char', how='inner', suffixes=('l', 'r'))\n\n#cleaning the data, since they are a bit skewed, there are cases when same charId has level 60 earlier than it had lvl 1\noneToSixty = joined.loc[joined['timestampl'] < joined['timestampr']]['char'].unique()\n\nleveling = df[df.char.isin(oneToSixty)].copy()\n\n#calculating online time, I count all time diffs above 15 minutes as 0s since the data are being polled every 10 minutes. \nleveling['diff_time'] = leveling.groupby(['char'], sort=False)['timestamp'].diff().fillna(pd.Timedelta('0 second'))\n\nleveling['online_time'] = leveling['diff_time'] /pd.Timedelta('1 minutes')\nleveling.loc[leveling['online_time'] > 15, 'online_time'] = 0\n\nchar_level_grp = leveling.groupby([leveling.char, leveling.level])['online_time'].sum().reset_index().rename(columns={'online_time': 'time_per_level'})\ntime_per_level = char_level_grp.groupby('char')['time_per_level'].mean()\n\ntime_per_level.loc[time_per_level>=time_per_level.median()].head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now lets take that charId and export \"average player\" leveling path\ndef build_aggregations(s):\n    ss = pd.Series([Counter(s.moved_to), s.char.nunique(), {'radius': 15 if s.lvl_diff.max() == 0 else 55, 'tooltip': {'level': max(s.level)}}])\n    return ss\n\navg_leveling = df[df['char'] == 4629]\\\n    .groupby([pd.Grouper(key='timestamp', freq='10Min'), 'zone'], sort=False)\n\navg_leveling = avg_leveling.apply(build_aggregations)\navg_leveling = avg_leveling.rename(columns={0:'moves', 1: 'char_count', 2: 'meta'})\navg_leveling.head()\n\n#export the data\n#prepare_data('avg_leveling', avg_leveling)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}