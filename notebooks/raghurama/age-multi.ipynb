{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport os\nimport glob\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objects as go\n\ndef plot_distribution(pd_series):\n    labels = pd_series.value_counts().index.tolist()\n    counts = pd_series.value_counts().values.tolist()\n    \n    pie_plot = go.Pie(labels=labels, values=counts, hole=.3)\n    fig = go.Figure(data=[pie_plot])\n    fig.update_layout(title_text='Distribution for %s' % pd_series.name)\n    \n    fig.show()\n    \nTRAIN_TEST_SPLIT = 0.7\nIM_WIDTH = IM_HEIGHT = 48\ndataset_dict = {\n    'race_id': {\n        0: 'white', \n        1: 'black', \n        2: 'asian', \n        3: 'indian', \n        4: 'others'\n    },\n    'gender_id': {\n        0: 'male',\n        1: 'female'\n    }\n}\n\ndataset_dict['gender_alias'] = dict((g, i) for i, g in dataset_dict['gender_id'].items())\ndataset_dict['race_alias'] = dict((r, i) for i, r in dataset_dict['race_id'].items())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/age-gender-and-ethnicity-face-data-csv/age_gender.csv')\n\n## Converting pixels into numpy array\ndf['pixels']=df['pixels'].apply(lambda x:  np.array(x.split(), dtype=\"float32\"))\n\ndf.columns=[\"age\",\"race_id\",\"gender_id\",\"img_name\",\"pixels\"]\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bins = [0, 10, 20, 30, 40, 60, 80, np.inf]\nnames = ['<10', '10-20', '20-30', '30-40', '40-60', '60-80', '80+']\n\nage_binned = pd.cut(df['age'], bins, labels=names)\nplot_distribution(age_binned)\n\nplot_distribution(df['gender_id'])\nplot_distribution(df['race_id'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nimport dlib\nfrom PIL import Image\n\nface_detector = dlib.get_frontal_face_detector()\nshape_predictor = dlib.shape_predictor('/kaggle/input/dlib-data/shape_predictor_68_face_landmarks.dat')\n\n\n\nx=df['pixels'][5].reshape(48,48).astype(np.uint8)\nx = cv2.resize(x, (198, 198)) \nimg = Image.fromarray(x)\ndetected_faces = face_detector(img, 1)\nx1=[shape_predictor(image, face) for face in detected_faces]\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical\nfrom PIL import Image\n\nclass UtkFaceDataGenerator():\n    \"\"\"\n    Data generator for the UTKFace dataset. This class should be used when training our Keras multi-output model.\n    \"\"\"\n    def __init__(self, df):\n        self.df = df\n        \n    def generate_split_indexes(self):\n        p = np.random.permutation(len(self.df))\n        train_up_to = int(len(self.df) * TRAIN_TEST_SPLIT)\n        train_idx = p[:train_up_to]\n        test_idx = p[train_up_to:]\n\n        train_up_to = int(train_up_to * TRAIN_TEST_SPLIT)\n        train_idx, valid_idx = train_idx[:train_up_to], train_idx[train_up_to:]\n        \n        # converts alias to id\n        #self.df['gender_id'] = self.df['gender'].map(lambda gender: dataset_dict['gender_alias'][gender])\n        #self.df['race_id'] = self.df['race'].map(lambda race: dataset_dict['race_alias'][race])\n\n        self.max_age = self.df['age'].max()\n        \n        return train_idx, valid_idx, test_idx\n    \n    def preprocess_image(self, img_path):\n        \"\"\"\n        Used to perform some minor preprocessing on the image before inputting into the network.\n        \"\"\"\n        im = Image.open(img_path)\n        im = im.resize((IM_WIDTH, IM_HEIGHT))\n        im = np.array(im) / 255.0\n        \n        return im\n        \n    def generate_images(self, image_idx, is_training, batch_size=16):\n        \"\"\"\n        Used to generate a batch with images when training/testing/validating our Keras model.\n        \"\"\"\n        \n        # arrays to store our batched data\n        images, ages, races, genders = [], [], [], []\n        while True:\n            for idx in image_idx:\n                person = self.df.iloc[idx]\n                \n                age = person['age']\n                race = person['race_id']\n                gender = person['gender_id']\n                file = person['pixels']\n                \n                im = file.reshape(IM_WIDTH, IM_HEIGHT)#self.preprocess_image(file)\n                \n                ages.append(age / self.max_age)\n                races.append(to_categorical(race, len(dataset_dict['race_id'])))\n                genders.append(to_categorical(gender, len(dataset_dict['gender_id'])))\n                images.append(im)\n                \n                # yielding condition\n                if len(images) >= batch_size:\n                    yield np.array(images), [np.array(ages), np.array(races), np.array(genders)]\n                    images, ages, races, genders = [], [], [], []\n                    \n            if not is_training:\n                break\n                \ndata_generator = UtkFaceDataGenerator(df)\ntrain_idx, valid_idx, test_idx = data_generator.generate_split_indexes()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.core import Activation\nfrom keras.layers.core import Dropout\nfrom keras.layers.core import Lambda\nfrom keras.layers.core import Dense\nfrom keras.layers import Flatten\nfrom keras.layers import Input\nimport tensorflow as tf\n\nclass UtkMultiOutputModel():\n    \"\"\"\n    Used to generate our multi-output model. This CNN contains three branches, one for age, other for \n    sex and another for race. Each branch contains a sequence of Convolutional Layers that is defined\n    on the make_default_hidden_layers method.\n    \"\"\"\n    def make_default_hidden_layers(self, inputs):\n        \"\"\"\n        Used to generate a default set of hidden layers. The structure used in this network is defined as:\n        \n        Conv2D -> BatchNormalization -> Pooling -> Dropout\n        \"\"\"\n        x = Conv2D(16, (3, 3), padding=\"same\")(inputs)\n        x = Activation(\"relu\")(x)\n        x = BatchNormalization(axis=-1)(x)\n        x = MaxPooling2D(pool_size=(3, 3))(x)\n        x = Dropout(0.25)(x)\n\n        x = Conv2D(32, (3, 3), padding=\"same\")(x)\n        x = Activation(\"relu\")(x)\n        x = BatchNormalization(axis=-1)(x)\n        x = MaxPooling2D(pool_size=(2, 2))(x)\n        x = Dropout(0.25)(x)\n\n        x = Conv2D(32, (3, 3), padding=\"same\")(x)\n        x = Activation(\"relu\")(x)\n        x = BatchNormalization(axis=-1)(x)\n        x = MaxPooling2D(pool_size=(2, 2))(x)\n        x = Dropout(0.25)(x)\n\n        return x\n\n    def build_race_branch(self, inputs, num_races):\n        \"\"\"\n        Used to build the race branch of our face recognition network.\n        This branch is composed of three Conv -> BN -> Pool -> Dropout blocks, \n        followed by the Dense output layer.\n        \"\"\"\n        x = self.make_default_hidden_layers(inputs)\n\n        x = Flatten()(x)\n        x = Dense(128)(x)\n        x = Activation(\"relu\")(x)\n        x = BatchNormalization()(x)\n        x = Dropout(0.5)(x)\n        x = Dense(num_races)(x)\n        x = Activation(\"softmax\", name=\"race_output\")(x)\n\n        return x\n\n    def build_gender_branch(self, inputs, num_genders=2):\n        \"\"\"\n        Used to build the gender branch of our face recognition network.\n        This branch is composed of three Conv -> BN -> Pool -> Dropout blocks, \n        followed by the Dense output layer.\n        \"\"\"\n        x = Lambda(lambda c: tf.image.rgb_to_grayscale(c))(inputs)\n\n        x = self.make_default_hidden_layers(inputs)\n\n        x = Flatten()(x)\n        x = Dense(128)(x)\n        x = Activation(\"relu\")(x)\n        x = BatchNormalization()(x)\n        x = Dropout(0.5)(x)\n        x = Dense(num_genders)(x)\n        x = Activation(\"sigmoid\", name=\"gender_output\")(x)\n\n        return x\n\n    def build_age_branch(self, inputs):   \n        \"\"\"\n        Used to build the age branch of our face recognition network.\n        This branch is composed of three Conv -> BN -> Pool -> Dropout blocks, \n        followed by the Dense output layer.\n\n        \"\"\"\n        x = self.make_default_hidden_layers(inputs)\n\n        x = Flatten()(x)\n        x = Dense(128)(x)\n        x = Activation(\"relu\")(x)\n        x = BatchNormalization()(x)\n        x = Dropout(0.5)(x)\n        x = Dense(1)(x)\n        x = Activation(\"linear\", name=\"age_output\")(x)\n\n        return x\n\n    def assemble_full_model(self, width, height, num_races):\n        \"\"\"\n        Used to assemble our multi-output model CNN.\n        \"\"\"\n        input_shape = (height, width, 1)\n\n        inputs = Input(shape=input_shape)\n\n        age_branch = self.build_age_branch(inputs)\n        race_branch = self.build_race_branch(inputs, num_races)\n        gender_branch = self.build_gender_branch(inputs)\n\n        model = Model(inputs=inputs,\n                     outputs = [age_branch, race_branch, gender_branch],\n                     name=\"face_net\")\n\n        return model\n    \nmodel = UtkMultiOutputModel().assemble_full_model(IM_WIDTH, IM_HEIGHT, num_races=len(dataset_dict['race_alias']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.optimizers import Adam\n\ninit_lr = 1e-4\nepochs = 100\n\nopt = Adam(lr=init_lr, decay=init_lr / epochs)\n\nmodel.compile(optimizer=opt, \n              loss={\n                  'age_output': 'mse', \n                  'race_output': 'categorical_crossentropy', \n                  'gender_output': 'binary_crossentropy'},\n              loss_weights={\n                  'age_output': 4., \n                  'race_output': 1.5, \n                  'gender_output': 0.1},\n              metrics={\n                  'age_output': 'mae', \n                  'race_output': 'accuracy',\n                  'gender_output': 'accuracy'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint\n\nbatch_size = 32\nvalid_batch_size = 32\ntrain_gen = data_generator.generate_images(train_idx, is_training=True, batch_size=batch_size)\nvalid_gen = data_generator.generate_images(valid_idx, is_training=True, batch_size=valid_batch_size)\n\ncallbacks = [\n    ModelCheckpoint(\"./model_checkpoint\", monitor='val_loss')\n]\n\nhistory = model.fit_generator(train_gen,\n                    steps_per_epoch=len(train_idx)//batch_size,\n                    epochs=epochs,\n                    callbacks=callbacks,\n                    validation_data=valid_gen,\n                    validation_steps=len(valid_idx)//valid_batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_batch_size = 128\ntest_generator = data_generator.generate_images(test_idx, is_training=False, batch_size=test_batch_size)\nage_pred, race_pred, gender_pred = model.predict_generator(test_generator, \n                                                           steps=len(test_idx)//test_batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_generator = data_generator.generate_images(test_idx, is_training=False, batch_size=test_batch_size)\nsamples = 0\nimages, age_true, race_true, gender_true = [], [], [], []\nfor test_batch in test_generator:\n    image = test_batch[0]\n    labels = test_batch[1]\n    \n    images.extend(image)\n    age_true.extend(labels[0])\n    race_true.extend(labels[1])\n    gender_true.extend(labels[2])\n    \nage_true = np.array(age_true)\nrace_true = np.array(race_true)\ngender_true = np.array(gender_true)\n\nrace_true, gender_true = race_true.argmax(axis=-1), gender_true.argmax(axis=-1)\nrace_pred, gender_pred = race_pred.argmax(axis=-1), gender_pred.argmax(axis=-1)\n\nage_true = age_true * data_generator.max_age\nage_pred = age_pred * data_generator.max_age","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n\n\n\ncr_race = classification_report(race_true, race_pred, target_names=dataset_dict['race_alias'].keys())\nprint(cr_race)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cr_gender = classification_report(gender_true, gender_pred, target_names=dataset_dict['gender_alias'].keys())\nprint(cr_gender)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}