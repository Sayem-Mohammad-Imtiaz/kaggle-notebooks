{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pyprind\nimport pandas as pd\nfrom string import punctuation\nimport re\nimport numpy as np\ndf = pd.read_csv('../input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv', encoding='utf-8')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from collections import Counter\ncounts = Counter()\npbar = pyprind.ProgBar(len(df['review']), title='Counting words occurrences')\nfor i,review in enumerate(df['review']):\n    text=''.join([c if c not in punctuation else ' '+c+' ' for c in review]).lower()\n    df.loc[i,'review'] = text\n    pbar.update()\n    counts.update(text.split())\n\n## Create a mapping\n## Map each unique word to an integer\nword_counts = sorted(counts, key=counts.get, reverse=True)\nprint(word_counts[:5])\nword_to_int = {word: ii for ii, word in enumerate(word_counts, 1)}\n\nmapped_reviews = []\npbar = pyprind.ProgBar(len(df['review']), title='Map reviews to ints')\nfor review in df['review']:\n    mapped_reviews.append([word_to_int[word] for word in review.split()])\n    pbar.update()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Define same-length sequences\n## if sequence length < 200: left-pad with zeros\n## if sequence length > 200: use the last 200 elements\nsequence_length = 200\nsequences = np.zeros((len(mapped_reviews), sequence_length), dtype=int)\nfor i, row in enumerate(mapped_reviews):\n    review_arr = np.array(row)\n    sequences[i, -len(row):] = review_arr[-sequence_length:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = sequences[:25000,:]\ny_train = df.loc[:24999, 'sentiment'].values\ny_train[y_train=='positive'] = 1\ny_train[y_train=='negative'] = 0\nX_test = sequences[25000:,:]\ny_test = df.loc[25000:, 'sentiment'].values\ny_test[y_test=='positive'] = 1\ny_test[y_test=='negative'] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Train: {len(X_train)}; Test: {len(X_test)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense , Input , LSTM , Embedding, Dropout , Activation, GRU, Flatten, Conv2D\nfrom keras.layers import Bidirectional, GlobalMaxPool1D\nfrom keras.models import Model, Sequential\nfrom keras.layers import Convolution1D\nfrom keras import initializers, regularizers, constraints, optimizers, layers\nn_words = max(list(word_to_int.values())) + 1\nmbed_size = 200\n\ndef create_model():\n    model = Sequential()\n    model.add(Embedding(n_words, mbed_size))\n    model.add(Bidirectional(LSTM(32, return_sequences = True)))\n    model.add(GlobalMaxPool1D())\n    model.add(Dense(20, activation=\"relu\"))\n    model.add(Dropout(0.05))\n    model.add(Dense(1, activation=\"sigmoid\"))\n    \n    model.compile(\n        loss='binary_crossentropy', \n        optimizer='adam', \n        metrics=['accuracy']\n    )\n    \n    return model\n\nmodel = create_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\n\nSVG(model_to_dot(model, show_shapes=True, show_layer_names=False, \n                 rankdir='LR').create(prog='dot', format='svg'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 100\nepochs = 3\n\nmodel.fit(\n    X_train,\n    y_train, \n    batch_size=batch_size, \n    epochs=epochs, \n    validation_split=0.3\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import string\nprint(\"punctuation:\",string.punctuation)\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nprint(\"stopwords:\",set(stopwords.words(\"english\")))\nlines = df[\"review\"].values.tolist()\nstop_words = set(stopwords.words(\"english\"))\nreviews = list()\nfor line in lines:\n    tokens = word_tokenize(line)\n    tokens = [w.lower() for w in tokens]\n    table = str.maketrans(\"\",\"\",string.punctuation)\n    stripped = [w.translate(table) for w in tokens]\n    words = [w for w in stripped if w.isalpha()]\n    words = [w for w in words if w not in stop_words]\n    reviews.append(words)\nlen(reviews)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gensim\nmodel = gensim.models.Word2Vec(\n    sentences=reviews,\n    size=mbed_size,\n    window=5,\n    workers=4,\n    min_count=1\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"words=list(model.wv.vocab)\nprint(\"vocabulary size:\",len(words))\nmodel.wv.get_vector(words[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.python.keras.preprocessing.text import Tokenizer\nfrom tensorflow.python.keras.preprocessing.sequence import pad_sequences\n\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(reviews)\nseqs = tokenizer.texts_to_sequences(reviews)\nreview_pad = pad_sequences(seqs,padding=\"post\")\nword_index = tokenizer.word_index\nsentiments = df[\"sentiment\"].values\n\nnum_words = len(word_index)+1\nembedding_matrix = np.zeros((num_words,mbed_size))\nfor word,i in word_index.items():\n    vector = model.wv.get_vector(word)\n    if vector is not None:\n        embedding_matrix[i] = vector","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model():\n    model = Sequential()\n    model.add(Embedding(len(embedding_matrix), mbed_size))\n    model.add(Bidirectional(LSTM(32, return_sequences = True)))\n    model.add(GlobalMaxPool1D())\n    model.add(Dense(20, activation=\"relu\"))\n    model.add(Dropout(0.05))\n    model.add(Dense(1, activation=\"sigmoid\"))\n    \n    model.layers[0].set_weights([embedding_matrix])\n    \n    model.compile(\n        loss='binary_crossentropy', \n        optimizer='adam', \n        metrics=['accuracy']\n    )\n    \n    return model\n\nmodel = create_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 100\nepochs = 3\n\nmodel.fit(\n    review_pad,\n    sentiments,\n    batch_size=batch_size,\n    epochs=epochs,\n    validation_split=0.3\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model():\n    model = Sequential()\n    model.add(Embedding(len(embedding_matrix), mbed_size))\n    model.add(Bidirectional(LSTM(32, return_sequences = True)))\n    model.add(Dense(64, activation='relu'))\n    model.add(Dense(128, activation='relu'))\n    model.add(GlobalMaxPool1D())\n    model.add(Dense(20, activation=\"relu\"))\n    model.add(Dropout(0.05))\n    model.add(Dense(1, activation=\"sigmoid\"))\n    \n    model.layers[0].set_weights([embedding_matrix])\n    \n    model.compile(\n        loss='binary_crossentropy', \n        optimizer='adam',  \n        metrics=['accuracy']\n    )\n    \n    return model\n\nmodel = create_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 100\nepochs = 3\n\nmodel.fit(\n    review_pad,\n    sentiments,\n    batch_size=batch_size,\n    epochs=epochs,\n    validation_split=0.3\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model():\n    model = Sequential()\n    model.add(Embedding(len(embedding_matrix), mbed_size))\n    model.add(Bidirectional(LSTM(32, return_sequences = True)))\n    model.add(Bidirectional(LSTM(64, return_sequences = True)))\n    model.add(GlobalMaxPool1D())\n    model.add(Dense(20, activation=\"relu\"))\n    model.add(Dropout(0.05))\n    model.add(Dense(1, activation=\"sigmoid\"))\n    \n    model.layers[0].set_weights([embedding_matrix])\n    \n    model.compile(\n        loss='binary_crossentropy', \n        optimizer='adam',  \n        metrics=['accuracy']\n    )\n    \n    return model\n\nmodel = create_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 100\nepochs = 1\n\nmodel.fit(\n    review_pad,\n    sentiments,\n    batch_size=batch_size,\n    epochs=epochs,\n    validation_split=0.3\n)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}