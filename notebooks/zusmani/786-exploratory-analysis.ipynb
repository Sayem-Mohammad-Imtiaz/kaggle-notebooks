{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# 786\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport plotly.express as px\nimport plotly.graph_objs as go\n\nimport plotly as py\nfrom plotly import tools\nfrom plotly.offline import iplot\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Loading & Preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"dt = pd.read_csv(\"../input/pakistans-largest-ecommerce-dataset/Pakistan Largest Ecommerce Dataset.csv\", parse_dates=[\"created_at\", \"Working Date\"], low_memory=False)\nprint(\"Data Dimensions are: \", dt.shape)\nprint(\"Columns: \", dt.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(dt.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data contains 1048574 rows but maximum columns contain 584524 records. \n\nHalf of row are completely empty, so we will drop them. The tricky part is we can't drop all na rows as actual data set  also contain few NA entries. We need to keep them.\nWe will drop NA values where all entries are Null. \n\nAlso, we will drop last 5 empty columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"dt = dt.iloc[:, :-5]\ndt = dt.dropna(how = 'all') ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The column MV contains leading and trailing space that might cause problem. We will rename it first."},{"metadata":{"trusted":true},"cell_type":"code","source":"dt.rename(columns = {' MV ':'MV'}, inplace = True)\ndt.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see above, few columns are not in correct data type. We need to perform casting."},{"metadata":{"trusted":true},"cell_type":"code","source":"dt['Customer ID'] = dt['Customer ID'].astype(str)\ndt['item_id'] = dt['item_id'].astype(str)\ndt['qty_ordered'] = dt['qty_ordered'].astype(int)  \ndt['Year'] = dt['Year'].astype(int)  \ndt['Month'] = dt['Month'].astype(int)  \n# dt['MV'] = dt['MV'].astype(float, errors = 'raise')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's look into summary of data\nData Summary of non-numeric data"},{"metadata":{"trusted":true},"cell_type":"code","source":"dt.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data Summary of non-numeric data"},{"metadata":{"trusted":true},"cell_type":"code","source":"dt.describe(include=['object', 'bool'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Analysis to Understand Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"dt = dt.sort_values('created_at')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Few new features extracted"},{"metadata":{"trusted":true},"cell_type":"code","source":"dtg = dt.groupby('created_at')['grand_total'].sum().reset_index()\ndtq = dt.groupby('created_at')['qty_ordered'].sum().reset_index()\ndtd = dt.groupby('created_at')['discount_amount'].sum().reset_index()\n# comput count for non numeric values\ndts = dt.groupby('created_at')['sku'].count().reset_index() \ndtst = dt.groupby('created_at')['status'].count().reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# new data set\np = pd.DataFrame(dtg) \np['qty_ordered'] = dtq['qty_ordered']\np['discount_amount'] = dtd['discount_amount']\np['sku'] = dts['sku']\np['status'] = dtst['status']\n#Cumulative Sum\np['cum_grand_total'] = p['grand_total'].cumsum()\np['cum_qty_ordered'] = p['qty_ordered'].cumsum()\np['cum_discount_amount'] = p['discount_amount'].cumsum()\np['cum_sku_cnt'] = p['sku'].cumsum()\np['cum_status_cnt'] = p['status'].cumsum()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Date features\np['Dateofmonth'] = p['created_at'].dt.day\np['Month'] = p['created_at'].dt.month\np['Week'] = p['created_at'].dt.week\np['Dayofweek'] = p['created_at'].dt.dayofweek # 0 = monday.\np['Weekdayflg'] = (p['Dayofweek'] // 5 != 1).astype(float)\np['Month'] = p['created_at'].dt.month\np['Quarter'] = p['created_at'].dt.quarter\np['Dayofyear'] = p['created_at'].dt.dayofyear","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Daily Sales vs. Discount"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure()\n\n# Add traces\nfig.add_trace(go.Scatter(x=p['created_at'], y=p['grand_total'],\n                    mode='lines+markers',\n                    name='grand_total'))\nfig.add_trace(go.Scatter(x=p['created_at'], y=p['discount_amount'],\n                    mode='lines+markers',\n                    name='discount_amount'))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cumulative Sums of Grand_Total and discount_amount"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure()\n\n# Add traces\nfig.add_trace(go.Scatter(x=p['created_at'], y=p['cum_grand_total'],\n                    mode='lines+markers',\n                    name='xcum_grand_total'))\nfig.add_trace(go.Scatter(x=p['created_at'], y=p['cum_discount_amount'],\n                    mode='lines+markers',\n                    name='cum_discount_amount'))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**In above graphs we can observe that sales boosted when discount offer initiated.**\n\nBut this can we tempting without looking into item status."},{"metadata":{"trusted":true},"cell_type":"code","source":"n = dt.groupby(['Year' ,'status'])['grand_total'].sum().reset_index()\nfig = px.bar(n, x=\"Year\", y=\"grand_total\", color=\"status\", title=\"Long-Form Input\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**In each year order cancellation is high. We need to drop Cancelled items and recheck sales growth**\n\nNote: We will do this after looking into other data points. "},{"metadata":{"trusted":true},"cell_type":"code","source":"n = dt.groupby(['Year' ,'payment_method'])['grand_total'].sum().reset_index()\nfig = px.bar(n, x=\"Year\", y=\"grand_total\", color=\"payment_method\", title=\"Long-Form Input\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Order Status"},{"metadata":{"trusted":true},"cell_type":"code","source":"n = dt.groupby(['status'])['grand_total'].sum().reset_index()\nfig = px.bar(n, y='grand_total', x='status', text='grand_total')\nfig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n = dt.groupby(['created_at' ,'status'])['grand_total'].sum().reset_index()\npx.box(n, y=\"grand_total\", color = \"status\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Category Type"},{"metadata":{"trusted":true},"cell_type":"code","source":"n = dt.groupby(['category_name_1'])['grand_total'].sum().reset_index()\nfig = px.bar(n, y='grand_total', x='category_name_1', text='grand_total')\nfig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n = dt.groupby(['category_name_1','status'])['grand_total'].sum().reset_index()\nfig = px.bar(n, x=\"category_name_1\", y=\"grand_total\",\n             color='status', barmode='group')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Payment Methods\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"n = dt.groupby(['payment_method'])['grand_total'].sum().reset_index()\n\nfig = px.bar(n, y='grand_total', x='payment_method', text='grand_total')\nfig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Growth Analysis"},{"metadata":{},"cell_type":"markdown","source":"As we analysed above, we need to drop cancelled orders\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"ord_cncl_ind = dt[dt['status'] == 'canceled' ].index\ndt.drop(ord_cncl_ind , inplace=True)\ndt.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Recomputing daily figures"},{"metadata":{"trusted":true},"cell_type":"code","source":"dtg = dt.groupby('created_at')['grand_total'].sum().reset_index()\ndtq = dt.groupby('created_at')['qty_ordered'].sum().reset_index()\ndtd = dt.groupby('created_at')['discount_amount'].sum().reset_index()\n# comput count for non numeric values\ndts = dt.groupby('created_at')['sku'].count().reset_index() \ndtst = dt.groupby('created_at')['status'].count().reset_index()\n\n# new data set\np = pd.DataFrame(dtg) \np['qty_ordered'] = dtq['qty_ordered']\np['discount_amount'] = dtd['discount_amount']\np['sku'] = dts['sku']\np['status'] = dtst['status']\n#Cumulative Sum\np['cum_grand_total'] = p['grand_total'].cumsum()\np['cum_qty_ordered'] = p['qty_ordered'].cumsum()\np['cum_discount_amount'] = p['discount_amount'].cumsum()\np['cum_sku_cnt'] = p['sku'].cumsum()\np['cum_status_cnt'] = p['status'].cumsum()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure()\n\n# Add traces\nfig.add_trace(go.Scatter(x=p['created_at'], y=p['grand_total'],\n                    mode='lines+markers',\n                    name='grand_total'))\nfig.add_trace(go.Scatter(x=p['created_at'], y=p['discount_amount'],\n                    mode='lines+markers',\n                    name='discount_amount'))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## A quick view of Regession model (OLS)"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter(p, x= 'created_at', y = 'grand_total', trendline = \"ols\")\nfig.show()\nresults = px.get_trendline_results(fig)\nresults","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Density Graph"},{"metadata":{"trusted":true},"cell_type":"code","source":"n = dt.groupby('created_at')['grand_total'].sum().reset_index()\npx.density_contour(n,x=\"created_at\",y=\"grand_total\",marginal_x=\"histogram\",marginal_y=\"histogram\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Graph for quantity\nn = dt.groupby('created_at')['qty_ordered'].sum().reset_index()\npx.density_contour(n,x=\"created_at\",y=\"qty_ordered\",marginal_x=\"histogram\",marginal_y=\"histogram\", title=\"no of orders\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n = dt.groupby(['created_at' ,'category_name_1', 'status'])['qty_ordered'].sum().reset_index()\npx.scatter(n, x=\"created_at\", y=\"qty_ordered\", color=\"status\", size=\"qty_ordered\", hover_data=['category_name_1','status'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n = dt.groupby(['created_at' ,'status'])['qty_ordered'].sum().reset_index()\npx.line(n, x=\"created_at\", y=\"qty_ordered\", color=\"status\", )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To be Continue...\n\n**You can fork this kernel and continue your analysis.**\n\n**Way Forward**\n* Data Cleansing at SKU and Status columns\n* Segregate analysis by dropping Cancel status orders. \n* Quarterly, Monthly, Weekday and Weekend Analysis\n* Seasonality Analysis\n* What are the Trends in Top 10 Categories\n* Weekly Moving Average Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}