{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# END RESULT: https://breast-cancer-model.herokuapp.com/"},{"metadata":{},"cell_type":"markdown","source":"Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image.\nn the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\n\nThis database is also available through the UW CS ftp server:\nftp ftp.cs.wisc.edu\ncd math-prog/cpo-dataset/machine-learn/WDBC/\n\nAlso can be found on UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\n\nAttribute Information:\n\n1) ID number\n2) Diagnosis (M = malignant, B = benign)\n3-32)\n\nTen real-valued features are computed for each cell nucleus:\n\n*  radius (mean of distances from center to points on the perimeter)\n*  texture (standard deviation of gray-scale values)\n*  perimeter\n*  area\n*  smoothness (local variation in radius lengths)\n*  compactness (perimeter^2 / area - 1.0)\n*  concavity (severity of concave portions of the contour)\n*  concave points (number of concave portions of the contour)\n*  symmetry\n*  fractal dimension (\"coastline approximation\" - 1)\n\nThe mean, standard error and \"worst\" or largest (mean of the three\nlargest values) of these features were computed for each image,\nresulting in 30 features. For instance, field 3 is Mean Radius, field\n13 is Radius SE, field 23 is Worst Radius.\n\nAll feature values are recoded with four significant digits.\n\nMissing attribute values: none\n\nClass distribution: 357 benign, 212 malignant"},{"metadata":{},"cell_type":"markdown","source":"**PROJECT DETAILS:**\nBreast cancer (BC) is one of the most common cancers among women worldwide, representing the majority of new cancer cases and cancer-related deaths according to global statistics, making it a significant public health problem in todayâ€™s society. The early diagnosis of BC can improve the prognosis and chance of survival significantly, as it can promote timely clinical treatment to patients. ML techniques are being broadly used in the breast cancer classification problem. They provide high classification accuracy and effective diagnostic capabilities.\n\nTask -\n\n* Data importing, cleaning and Inspecting (check whether any null/duplicate values are present)\n* Data Preprocessing\n* EDA\n* Label Encoding (if required)\n* Perform PCA for dimensionality reduction\n* Model Building - Select the best performing classification model as final model, based upon highest accuracy score.\n* Deploy it using Flask/Streamlit."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.decomposition import PCA\nimport os\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import svm\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nimport pickle","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data importing, cleaning and Inspecting "},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/breast-cancer-wisconsin-data/data.csv\")\n#temp=pd.read_csv(\"/kaggle/input/breast-cancer-wisconsin-data/data.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape                                          #569 rows 33 columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Since all data (apart from diagnosis) is in numerical form, label encoding is not required.\n* Drop column 32.\n* No null values in other columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(columns=['Unnamed: 32'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check for duplicate entries: "},{"metadata":{"trusted":true},"cell_type":"code","source":"dup = df[df.duplicated('id')]\ndup","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No duplicate values."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(columns=['id']).describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Drop column id"},{"metadata":{"trusted":true},"cell_type":"code","source":"#df.drop(columns=['id'],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(columns=['id']).hist(bins=20,figsize=(18, 16))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(20,20))\nsns.heatmap(df.drop(columns=['id']).corr());","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = df.drop(['id','diagnosis'], axis=1)\nfig, ax = plt.subplots(figsize=(100,25))       \ncols.boxplot(ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Clearly the data has different range of values and outliers."},{"metadata":{},"cell_type":"markdown","source":"# MODEL"},{"metadata":{"trusted":true},"cell_type":"code","source":"features = df.drop(columns=['diagnosis','id'])\ny = df['diagnosis']\nfeatures.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nx_scaled = scaler.fit_transform(features)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"PCA:"},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA()\nX = pca.fit_transform(x_scaled) \nX.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Test-train split"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,y_train,y_test = train_test_split(features,y,test_size = 0.30,random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression(random_state=0)\nlr_pred = lr.fit(X_train,y_train).predict(X_test)\n\nsvmclf=svm.LinearSVC(random_state=0)\nsvm_pred=svmclf.fit(X_train,y_train).predict(X_test)\n\ngnb = GaussianNB()\ngnb_pred = gnb.fit(X_train, y_train).predict(X_test)\n\ndt = DecisionTreeClassifier(random_state=0)\ndt_pred = dt.fit(X_train, y_train).predict(X_test)\n\nrf = RandomForestClassifier(max_depth=2,random_state=0)\nrf_pred = rf.fit(X, y).predict(X_test)\n\nknn = KNeighborsClassifier()\nknn_pred = knn.fit(X, y).predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models=['LR','SVM','GNB','DT','RF','KNN']\npreds=[lr_pred,svm_pred,gnb_pred,dt_pred,rf_pred,knn_pred]\nacc=[]\nfor i in preds:\n    accscore=accuracy_score(i,y_test).round(2)\n    acc.append(accscore)\ndata=zip(models,acc)\nscoresdf=pd.DataFrame(data,columns=['MODEL','ACCURACY SCORE']) \nscoresdf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Linear Regression has the highest accuracy score."},{"metadata":{},"cell_type":"markdown","source":"Evaluate LR model"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_test,lr_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,lr_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pickle.dump(lr, open('model.pkl', 'wb'))\nmodel = pickle.load(open('model.pkl', 'rb'))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}