{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"text-align:center; color:#546545;text-shadow: 2px 2px 4px #000000;\"> A comparison of different classifiers’ accuracy & performance for high-dimensional data</h2>"},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"text-align:center; color:#546545;text-shadow: 2px 2px 4px #000000;\">Problem formulation</h2>\n\nThe **EEG Brainwave Dataset** contains electronic brainwave signals from an EEG headset and is in temporal format.\n\nThe challenge is: **Can we predict emotional sentiment from brainwave readings?**"},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"text-align:center; color:#546545;text-shadow: 2px 2px 4px #000000;\">Import Packages</h2>"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.model_selection import cross_val_score, train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neural_network import MLPClassifier\n\nimport xgboost as xgb\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nos.listdir('../input')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"brainwave_df = pd.read_csv('../input/emotions.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"text-align:center; color:#546545;text-shadow: 2px 2px 4px #000000;\">Peek of Data</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"brainwave_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"text-align:center; color:#546545;text-shadow: 2px 2px 4px #000000;\">Tail of Data</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"brainwave_df.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"text-align:center; color:#546545;text-shadow: 2px 2px 4px #000000;\">Dimensions of Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"brainwave_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"text-align:center; color:#546545;text-shadow: 2px 2px 4px #000000;\">Data Type For Each Attribute</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"brainwave_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"text-align:center; color:#546545;text-shadow: 2px 2px 4px #000000;\">Descriptive Statistics</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"brainwave_df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"text-align:center; color:#546545;text-shadow: 2px 2px 4px #000000;\">Class Distribution</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,5))\nsns.countplot(x=brainwave_df.label, color='mediumseagreen')\nplt.title('Emotional sentiment class distribution', fontsize=16)\nplt.ylabel('Class Counts', fontsize=16)\nplt.xlabel('Class Label', fontsize=16)\nplt.xticks(rotation='vertical');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"text-align:center; color:#546545;text-shadow: 2px 2px 4px #000000;\">Correlation Between Attributes</h2>\nCorrelation refers to the relationship between two variables and how they may or may not change together.\n\nThe most common method for calculating correlation is [Pearson’s Correlation Coefficient](https://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient), that assumes a normal distribution of the attributes involved. A correlation of -1 or 1 shows a full negative or positive correlation respectively. Whereas a value of 0 shows no correlation at all."},{"metadata":{"trusted":true},"cell_type":"code","source":"label_df = brainwave_df['label']\nbrainwave_df.drop('label', axis = 1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correlations = brainwave_df.corr(method='pearson')\ncorrelations","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"text-align:center; color:#546545;text-shadow: 2px 2px 4px #000000;\">Skew of Univariate Distributions</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"skew = brainwave_df.skew()\nskew","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"text-align:center; color:#546545;text-shadow: 2px 2px 4px #000000;\">RandomForest Classifier</h2>\n\n`RandomForest` is a tree & bagging approach-based ensemble classifier. It will automatically reduce the number of features by its probabilistic entropy calculation approach."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"%%time\n\npl_random_forest = Pipeline(steps=[('random_forest', RandomForestClassifier())])\nscores = cross_val_score(pl_random_forest, brainwave_df, label_df, cv=10,scoring='accuracy')\nprint('Accuracy for RandomForest : ', scores.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"text-align:center; color:#546545;text-shadow: 2px 2px 4px #000000;\">Logistic Regression Classifier</h2>\n\n`Logistic Regression` is a linear classifier and works in same way as linear regression."},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"%%time\n\npl_log_reg = Pipeline(steps=[('scaler',StandardScaler()),\n                             ('log_reg', LogisticRegression(multi_class='multinomial', solver='saga', max_iter=200))])\nscores = cross_val_score(pl_log_reg, brainwave_df, label_df, cv=10,scoring='accuracy')\nprint('Accuracy for Logistic Regression: ', scores.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"text-align:center; color:#546545;text-shadow: 2px 2px 4px #000000;\">Principal Component Analysis (PCA)</h2>\n\nPCA can transform original low level variables to a higher dimensional space and thus reduce the number of required variables. All co-linear variables get clubbed together. "},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nscaled_df = scaler.fit_transform(brainwave_df)\npca = PCA(n_components = 20)\npca_vectors = pca.fit_transform(scaled_df)\nfor index, var in enumerate(pca.explained_variance_ratio_):\n    print(\"Explained Variance ratio by Principal Component \", (index+1), \" : \", var)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25,8))\nsns.scatterplot(x=pca_vectors[:, 0], y=pca_vectors[:, 1], hue=label_df)\nplt.title('Principal Components vs Class distribution', fontsize=16)\nplt.ylabel('Principal Component 2', fontsize=16)\nplt.xlabel('Principal Component 1', fontsize=16)\nplt.xticks(rotation='vertical');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"text-align:center; color:#546545;text-shadow: 2px 2px 4px #000000;\">Logistic Regression classifier with these two PCs</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\npl_log_reg_pca = Pipeline(steps=[('scaler',StandardScaler()),\n                             ('pca', PCA(n_components = 2)),\n                             ('log_reg', LogisticRegression(multi_class='multinomial', solver='saga', max_iter=200))])\nscores = cross_val_score(pl_log_reg_pca, brainwave_df, label_df, cv=10,scoring='accuracy')\nprint('Accuracy for Logistic Regression with 2 Principal Components: ', scores.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"text-align:center; color:#546545;text-shadow: 2px 2px 4px #000000;\">Take all 10 PCs</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\npl_log_reg_pca_10 = Pipeline(steps=[('scaler',StandardScaler()),\n                             ('pca', PCA(n_components = 10)),\n                             ('log_reg', LogisticRegression(multi_class='multinomial', solver='saga', max_iter=200))])\nscores = cross_val_score(pl_log_reg_pca_10, brainwave_df, label_df, cv=10,scoring='accuracy')\nprint('Accuracy for Logistic Regression with 10 Principal Components: ', scores.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"text-align:center; color:#546545;text-shadow: 2px 2px 4px #000000;\">Artificial Neural Network Classifier (ANN)</h2>\n\nAn ANN classifier is non-linear with automatic feature engineering and dimensional reduction techniques. `MLPClassifier` in scikit-learn works as an ANN. But here also, basic scaling is required for the data.[](http://)"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\npl_mlp = Pipeline(steps=[('scaler',StandardScaler()),\n                             ('mlp_ann', MLPClassifier(hidden_layer_sizes=(1275, 637)))])\nscores = cross_val_score(pl_mlp, brainwave_df, label_df, cv=10,scoring='accuracy')\nprint('Accuracy for ANN : ', scores.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"text-align:center; color:#546545;text-shadow: 2px 2px 4px #000000;\">Linear Support Vector Machines Classifier (SVM)</h2>"},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\n\npl_svm = Pipeline(steps=[('scaler',StandardScaler()),\n                             ('pl_svm', LinearSVC())])\nscores = cross_val_score(pl_svm, brainwave_df, label_df, cv=10,scoring='accuracy')\nprint('Accuracy for Linear SVM : ', scores.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"text-align:center; color:#546545;text-shadow: 2px 2px 4px #000000;\">Extreme Gradient Boosting Classifier (XGBoost)</h2>\n\nXGBoost is a boosted tree based ensemble classifier. Like ‘RandomForest’, it will also automatically reduce the feature set. "},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\npl_xgb = Pipeline(steps=\n                  [('xgboost', xgb.XGBClassifier(objective='multi:softmax'))])\nscores = cross_val_score(pl_xgb, brainwave_df, label_df, cv=10)\nprint('Accuracy for XGBoost Classifier : ', scores.mean())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.2"}},"nbformat":4,"nbformat_minor":1}