{"cells":[{"metadata":{},"cell_type":"markdown","source":"###### In this notebook, First I have done some exploration on the data using matplotlib and seaborn. Then, I use different classifier models to predict the quality of the wine.\n\n1. Logistic regression\n\n2. Random Forest Classifier\n \n3. Support Vector Classifier(SVC)\n\n###### then i did some resampling in the given data as the data is imbalanced which gave me some different results."},{"metadata":{},"cell_type":"markdown","source":"###### importing required packages"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.svm import SVC","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.read_csv('../input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### some basic observation of the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### no null values great!!"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['quality'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data['quality'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"as we can see the data is imbalanced .\n\nthe quality 5 and 6 of the wine are in large number compared to other qualities.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### some visualisation between the various features and the quality of the wine."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_columns=data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for ele in data_columns:\n    fig = plt.figure(figsize = (10,6))\n    sns.barplot(x = 'quality', y = ele, data = data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### as per the problem statement we have to classify the wine type in two varities good or bad.\n\n###### 1 for good and 0 for bad.\n\n###### the criteria to decide whether it is good or bad is that if the quality score is less than 6.5 it is a bad wine and if it is greater than 6.5 it is considered as good."},{"metadata":{},"cell_type":"markdown","source":"###### converting the quality to 0 and 1 depending on their score."},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(1599):\n    if(data['quality'][i]<=6.5):\n        data['quality'][i]=0\n    else:\n        data['quality'][i]=1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### now we have two varities in our quality column either 0 or 1 and the count of each variety is shown in the countplot ."},{"metadata":{"trusted":true},"cell_type":"code","source":"data['quality'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data['quality'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### this data is also imbalanced but lets continue with this data and see what we can do."},{"metadata":{},"cell_type":"markdown","source":"###### using logistic regression model ."},{"metadata":{"trusted":true},"cell_type":"code","source":"model=LogisticRegression(solver='lbfgs',multi_class='auto',max_iter=1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=data['quality']\nX=data.drop(['quality'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"so thats a very good accuracy with a logistic regression model.\n\nlet's try some other methods in the data."},{"metadata":{},"cell_type":"markdown","source":"###### using random forest\n\nrandom forest documentation https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc = RandomForestClassifier(n_estimators=200)\nrfc.fit(X_train, y_train)\npred_rfc = rfc.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, pred_rfc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_test, pred_rfc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### using support vector machine\nsvc documentation https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = SVC() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.fit(X_train, y_train) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_svc=clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, pred_svc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_test, pred_svc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Accuracy from logistic regression is 85.9\n###### Accuracy from Random Forest classifier is 91\n###### Accuracy from support vector machine is 85"},{"metadata":{},"cell_type":"markdown","source":"### Resampling\nData imbalance can be treated with resampling the data. data resampling can be of two types.\nundersampling and oversampling.\n\nhere i am using oversampling.\n"},{"metadata":{},"cell_type":"markdown","source":"Over-Sampling increases the number of instances in the minority class by randomly replicating them in order to present a higher representation of the minority class in the sample."},{"metadata":{},"cell_type":"markdown","source":"###### Collecting all the rows of quality 1 and all the rows of quality 0."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_1=data[data.quality == 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_0=data[data.quality == 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_1.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_0.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_1_new = pd.concat([data_1, data_1],ignore_index=True, sort =False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### running the above cell will replicate the data_1 dataframe and thus it will create a dataframe with more rows with the same data."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_1_new.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Concatenating the two dataframes data_1_new and data_0 to create a training dataset for further use"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new = pd.concat([data_1_new,data_0],ignore_index=True, sort =False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### using all the above models one by one again on this resampled data."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_new=data_new['quality']\nX_new=data_new.drop(['quality'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size=0.20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=LogisticRegression(solver='lbfgs',multi_class='auto',max_iter=1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc = RandomForestClassifier(n_estimators=200)\nrfc.fit(X_train, y_train)\npred_rfc = rfc.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, pred_rfc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = SVC() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.fit(X_train, y_train) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_svc_new=clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, pred_svc_new))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Accuracy from logistic regression is 85.9\n###### Accuracy from Random Forest classifier is 95\n###### Accuracy from support vector machine is 89"},{"metadata":{},"cell_type":"markdown","source":"## Looks like resampling the data worked."},{"metadata":{},"cell_type":"markdown","source":"# If you like my work give it a thumps UP."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}