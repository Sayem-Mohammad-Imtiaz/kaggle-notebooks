{"cells":[{"metadata":{"_uuid":"64a4b12ecf89d06858a9202017c3ac6a72dc8a22"},"cell_type":"markdown","source":"**The code below reads the csv into a Pandas dataframe...**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input/\"))\n\n# Any results you write to the current directory are saved as output.\nimport pandas as pd\ndf=pd.read_csv('../input/Concrete_Data_Yeh.csv', sep=',',header=None)\ndf.values","execution_count":9,"outputs":[]},{"metadata":{"_uuid":"453519d433be0c0c948425997a5aba80bf503b19"},"cell_type":"markdown","source":"**After reading the code into a dataframe, some basic analysis prior to preprocessing.**"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from IPython.display import display\n\n%matplotlib inline","execution_count":11,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e328ad52eadea583e37a3aba35356834dd9348a"},"cell_type":"code","source":"try:\n    data = pd.read_csv(\"../input/Concrete_Data_Yeh.csv\")\n    #data.drop(['age'], axis = 1, inplace = True)\n    print(\"Loaded Dataset.\")\nexcept:\n    print(\"Dataset could not be loaded. Is the dataset missing?\")\n    \ndata = data.sample(n=1000)\n\n# Display a description of the dataset\ndisplay(data.describe())","execution_count":32,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c3e9f559743ff074c84dcf404504c6d2d247bd63"},"cell_type":"markdown","source":"**Picking a few samples...**\n\n"},{"metadata":{"trusted":true,"_uuid":"59bb6e81a05437be547991ff8460924fdfae40bf"},"cell_type":"code","source":"# TODO: Select three indices of your choice you wish to sample from the dataset\n# indices = [ 10,20,30]\n\n# Create a DataFrame of the chosen samples\nsamples = data.sample(n=5)\n\nprint(\"Chosen samples of wholesale customers dataset:\")\ndisplay(samples)","execution_count":33,"outputs":[]},{"metadata":{"_uuid":"bbd9131086cfc674cafa72acc8c09125a1425449"},"cell_type":"markdown","source":"**Now a heatmap of the sample set.**"},{"metadata":{"trusted":true,"_uuid":"db6589018d3b2e65d993f4aab17ef6bda54f3c72"},"cell_type":"code","source":"import seaborn as sns\n\npercentiles_data = 100*data.rank(pct=True)\npercentiles_samples = percentiles_data.iloc[indices]\nsns.heatmap(percentiles_samples, annot=True)","execution_count":34,"outputs":[]},{"metadata":{"_uuid":"c217882068dc5b27fde5282781ab4b2a3cb6a4bc"},"cell_type":"markdown","source":"****"},{"metadata":{"trusted":true,"_uuid":"57192590be60be77057f5cac3148462ce23ebd3c"},"cell_type":"code","source":"features = data.drop(['age'],1)\nwildcard = data['age']\n\n# TODO: Split the data into training and testing sets(0.25) using the given feature as the target\n# Set a random state.\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(features, wildcard, test_size=0.25, random_state=23)\n\n# TODO: Create a decision tree regressor and fit it to the training set\nfrom sklearn.tree import DecisionTreeRegressor\nregressor = DecisionTreeRegressor(max_depth=2, random_state=23)\nregressor.fit(X_train, y_train)\nresults = regressor.predict(X_test)\ndisplay(results)\n# TODO: Report the score of the prediction using the testing set\nfrom sklearn.metrics import r2_score\nscore = regressor.score(X_test, y_test)\nprint(\"score\")\ndisplay(score)","execution_count":36,"outputs":[]},{"metadata":{"_uuid":"bcb5871873b85702f49d29d1d602731f89d6dccb"},"cell_type":"markdown","source":"**Log Based Feature Scaling**"},{"metadata":{"trusted":true,"_uuid":"8617f8c5aa2dee3cd96a6f79da9101f5baa9a241"},"cell_type":"code","source":"# TODO: Scale the data using the natural logarithm\nlog_data = np.log(data)\n\n# TODO: Scale the sample data using the natural logarithm\nlog_samples = np.log(samples)\n\n# Produce a scatter matrix for each pair of newly-transformed features\npd.plotting.scatter_matrix(log_data, alpha = 0.3, figsize = (18,12), diagonal = 'kde');","execution_count":37,"outputs":[]},{"metadata":{"_uuid":"49e95f97da2c1bea3f671966e029825f132e5d9a"},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}