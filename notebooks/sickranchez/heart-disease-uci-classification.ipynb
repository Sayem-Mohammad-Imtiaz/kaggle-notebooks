{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Introduction"},{"metadata":{},"cell_type":"markdown","source":"The goal of the Heart Disease UCI dataset is to develop a model able to classify whether a person has heart disease or not based on a number of variables with the target conditions.\n\nIn this notebook, we will go through some necessary steps of cleaning and visualizing the data to get a better understanding of our problem and finally choose the best model for our dataset."},{"metadata":{},"cell_type":"markdown","source":"## Import libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Matplotlib style\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('fivethirtyeight')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Import dataset\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.read_csv(\"/kaggle/input/heart-disease-uci/heart.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Describing "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for data types\ndataset.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Statistics of the data\ndataset.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for missing data\ndataset.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for duplicates\ndataset.duplicated().sum()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop duplicates\ndataset.drop_duplicates(inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add an index column to the dataset\ndataset.reset_index(inplace=True, level=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Target distribution by features"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_target(dataframe, column, title,  fontsize=11, figsize_=(18, 10), percentage=False, rot_=0):\n    '''\n    Plot target distribution by a feature\n    \n    Parameters:\n        dataframe: Dataset that has the features\n        column: The feature we want to plot it's distribution\n        title: Title of the plot\n    '''\n    feature = dataframe[[column, 'target', 'index']].groupby(\n        [column, 'target'])['index'].count().unstack(level=1, fill_value=0)\n    \n    ax_1 = feature.plot(kind='bar',\n                figsize=figsize_,\n                stacked=True,\n                rot=rot_,\n                title=title)\n    \n    # Add percentage to the plot\n    c = 0\n    df_len = len(feature)\n    if percentage == True:\n        for bar in ax_1.patches:\n            height = bar.get_height()\n            ax_1.text(bar.get_x() + bar.get_width() / 2,\n                     bar.get_y() + height / 2,\n                     '{:.0f}%'.format((height/feature.iloc[c].sum())*100),\n                     ha='center',\n                     va='center')\n            c += 1\n            if c == df_len:\n                c = 0\n    \n    # Rename Legend\n    plt.legend(['Healthy', 'Patient'])\n    # Labels\n    plt.ylabel('Number of samples')\n    # Set xlabel fontsize\n    plt.xticks(fontsize=fontsize)\n    plt.tight_layout()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_target(dataset, 'age', 'Age Feature')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_target(dataset, 'sex', 'Gender', figsize_=(12, 10), percentage=True)\n# 0 for female, 1 for male","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We Can Clearly see that females are more likely to have heart disease than men"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_target(dataset, 'cp', 'Chest pain type', figsize_=(15, 10), percentage=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### People having chest pain number 1 are more likely to have hear disease"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_target(dataset, 'trestbps', 'Resting blood pressure', rot_=70)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Chol feature has many unique values and plotting it won't be useful"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_target(dataset, 'fbs', 'Fasting blood sugar', percentage=True)\n# 1 True, 0 False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_target(dataset, 'restecg', 'Resting electrocariographic results', percentage=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## thalach feature has alot of unique values, so we will plot maximum heart rate with the highest number of patients"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot values with alot of patients\nheart_rate = dataset[['thalach', 'target', 'index']].groupby(\n        ['thalach', 'target'])['index'].count().unstack(level=1, fill_value=0)\nheart_rate = heart_rate[heart_rate[1] >= heart_rate[1].mean()]\nplt.figure(figsize=(12, 5))\nplt.plot(heart_rate[1],\n        color='red')\nplt.xlabel('Maximum heart reate achieved')\nplt.ylabel('Num of people')\nplt.title('Has heart disease')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_target(dataset, 'exang', 'Exercise induced angina(chest pain)', percentage=True, figsize_=(8,7))\n# No: 0, Yes: 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Most of the patients didn't have exercise induced angina"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Old peak feature\nfeature = dataset[['oldpeak', 'target', 'index']].groupby(\n        ['oldpeak', 'target'])['index'].count().unstack(level=1, fill_value=0)\nplt.figure(figsize=(15, 5))\nplt.plot(feature[0])\nplt.plot(feature[1])\nplt.title('ST depression induced by exercise relative to rest')\nplt.xlabel('old peak')\nplt.ylabel('Num of people')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_target(dataset, 'slope', 'The slope of the peak exercise ST segment', figsize_=(8, 7), percentage=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_target(dataset, 'ca', 'Number of major vessels')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_target(dataset, 'thal', 'Thal(Blood disorder)', percentage=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check for outliers\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create 10 subplots\nfig = plt.figure(figsize=(18,10))\na1 = fig.add_subplot(531)\na2 = fig.add_subplot(532)\na3 = fig.add_subplot(533)\na4 = fig.add_subplot(534)\na5 = fig.add_subplot(535)\na6 = fig.add_subplot(536)\na7 = fig.add_subplot(537)\na8 = fig.add_subplot(538)\na9 = fig.add_subplot(539)\na10 = fig.add_subplot(5,3,11)\nfig.tight_layout(h_pad=2, w_pad=2)\naxes = [a1, a2, a3, a4, a5, a6, a7, a8, a9, a10]\n\n# Get columns of dataset\ncol = dataset.columns\nj = 0\nfor i in range(13):\n    if len(dataset[col[i]].value_counts()) > 2:\n        axes[j].boxplot(dataset[col[i]], vert=False)\n        axes[j].title.set_text(col[i])\n        j += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.boxplot(dataset['thal'], vert=False)\nplt.title('thal')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Statistics of the data\ndataset.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check unique values in thal feature\ndataset['thal'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replace outliers in thal feature with the median\ndataset[dataset['thal'] == 0]['thal'] = dataset['thal'].median()\nplt.boxplot(dataset['thal'], vert=False)\nplt.title('thal')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['thal'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check unique values in Ca feature\ndataset['ca'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Values must be between (0-3), replace values equal 4 with the median\ndataset[dataset['ca'] == 4]['ca'] = dataset['ca'].median()\nplt.boxplot(dataset['ca'], vert=False)\nplt.title('ca')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check unique values in oldpeak feature\ndataset['oldpeak'].value_counts().sort_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replace values greater than or equal 4 with the median value\ndataset[dataset['oldpeak'] >= 4]['oldpeak'] = dataset['oldpeak'].median()\nplt.boxplot(dataset['oldpeak'], vert=False)\nplt.title('oldpeak')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for unique values in chol feature\ndataset['chol'].value_counts().sort_index(ascending=True).head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replace values greater than 350 or less than 120 with the median\ndataset[(dataset['chol'] >= 350) | (dataset['chol'] < 120)]['chol'] = dataset['chol'].median()\nplt.boxplot(dataset['chol'], vert=False)\nplt.title('chol')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for unique values in trestbps feature\ndataset['trestbps'].value_counts().sort_index(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replace values greater than 170 or less than 90 with the median value\ndataset[(dataset['trestbps'] > 170) | (dataset['trestbps'] < 90)]['trest'] = dataset['trestbps'].median()\nplt.boxplot(dataset['trestbps'], vert=False)\nplt.title('trestbps')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check for variables correlation"},{"metadata":{"trusted":true},"cell_type":"code","source":"correlation = dataset.corr()\n\n# Plot correlation\nplt.figure(figsize=(19, 15))\nsns.heatmap(correlation, xticklabels=correlation.columns.values, \n            yticklabels=correlation.columns.values, annot=True, annot_kws={'size':10})\n\n# Axis ticks size\nplt.xticks(fontsize=10)\nplt.yticks(fontsize=10)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### There is no highly correlated variables"},{"metadata":{},"cell_type":"markdown","source":"# Model evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Shuffle rows and reset index\ndataset = dataset.sample(frac=1).reset_index()\n\n# Drop index column\ndataset.drop(columns='index', inplace=True)\n\nx = dataset.drop(columns='target')\ny = dataset['target']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Perceptron algorithm"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import Perceptron\nclf = Perceptron(shuffle=True, penalty='l2', max_iter=1000)\nscores = cross_val_score(clf, x, y, cv=10).sum() / 10\nscores","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logestic regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nclf = LogisticRegression()\nscores = cross_val_score(clf, x, y, cv=10).sum() / 10\nscores","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Naive Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nclf = GaussianNB()\nscores = cross_val_score(clf, x, y, cv=10).sum() / 10\nscores","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## K-nearest neighbours"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nclf = KNeighborsClassifier(n_neighbors=3, )\nscores = cross_val_score(clf, x, y, cv=10).sum() / 10\nscores","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Support vector machines"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import svm\nclf = svm.SVC(kernel='linear')\nscores = cross_val_score(clf, x, y, cv=10).sum() / 10\nscores","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Decision tree classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nclf = DecisionTreeClassifier(criterion='entropy')\nscores = cross_val_score(clf, x, y, cv=10).sum() / 10\nscores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nclf = xgb.XGBClassifier(learning_rate=0.1,max_depth=6,n_estimators=500,n_jobs=-1)\nscores = cross_val_score(clf, x, y, cv=10).sum() / 10\nscores","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We choose to use SVM model"},{"metadata":{},"cell_type":"markdown","source":"## Model evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import svm\nfrom sklearn.metrics import confusion_matrix\nclf = svm.SVC(kernel='linear')\nclf.fit(x_train, y_train)\ny_pred = clf.predict(x_test)\nconfusion_matrix(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Findings"},{"metadata":{},"cell_type":"markdown","source":"#### With the SVM model we were able to get nearly 99% accuracy, however, high percentage accuracy may be an indicator of overfitting so we shuffled the data then split it into a train and test data to make sure that our model doesn't overfit but the accuracy didn't change that much which may be due to dataset small size."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}