{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport glob\nimport gc\nimport os\nimport cv2\nfrom torch.utils.data import DataLoader,SubsetRandomSampler\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nfrom torchvision import transforms,models\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# common variables\noc_path=\"../input/ocular-disease-recognition-odir5k/full_df.csv\"\noc_img_path=\"../input/ocular-disease-recognition-odir5k/ODIR-5K/ODIR-5K/Training Images\"\ncat_normal=\"../input/cataractdataset/dataset/1_normal\"\ncat_cat=\"../input/cataractdataset/dataset/2_cataract\"\n\ndevice='cuda:0' if torch.cuda.is_available() else 'cpu'\nprint(device)\nIMG_SIZE=256\nBATCH=64\nEPOCHS=5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Length of cataract images in cat dataset \", len(os.listdir(cat_cat)))\nprint(\"Length of normal images in cat dataset \", len(os.listdir(cat_normal)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_df=pd.DataFrame(columns=[\"Path\",\"cataract\"])\nfor cat_imgs in glob.glob(cat_cat+\"/*\"):\n    cat_df=cat_df.append({\"Path\":cat_imgs,\"cataract\":1},ignore_index=True)\n\nfor nor_imgs in glob.glob(cat_normal+\"/*\"):\n    cat_df=cat_df.append({\"Path\":nor_imgs,\"cataract\":0},ignore_index=True)\ncat_df=cat_df.sample(frac=1).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv(oc_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cataract_or_not(txt):\n    if \"cataract\" in txt:\n        return 1\n    else:\n        return 0\n\ndef prepare_dataset(df_path,imgs_path):\n    df=pd.read_csv(df_path)\n    df['left_eye_cataract']=df[\"Left-Diagnostic Keywords\"].apply(lambda x:cataract_or_not(x))\n    df['right_eye_cataract']=df[\"Right-Diagnostic Keywords\"].apply(lambda x:cataract_or_not(x))\n    left_df=df.loc[:,['Left-Fundus','left_eye_cataract']].rename(columns={'left_eye_cataract':'cataract'})\n    left_df['Path']=imgs_path+\"/\"+left_df['Left-Fundus']\n    left_df=left_df.drop(['Left-Fundus'],1)\n\n    right_df=df.loc[:,['Right-Fundus','right_eye_cataract']].rename(columns={'right_eye_cataract':'cataract'})\n    right_df['Path']=imgs_path+\"/\"+right_df['Right-Fundus']\n    right_df=right_df.drop(['Right-Fundus'],1)\n    print('Number of left eye images')\n    print(left_df['cataract'].value_counts())\n    print('\\nNumber of right eye images')\n    print(right_df['cataract'].value_counts())\n    train_df=pd.concat([right_df,left_df])\n    return train_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['left_eye_cataract']=df[\"Left-Diagnostic Keywords\"].apply(lambda x:cataract_or_not(x))\ndf['right_eye_cataract']=df[\"Right-Diagnostic Keywords\"].apply(lambda x:cataract_or_not(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"left_df=df.loc[:,['Left-Fundus','left_eye_cataract']].rename(columns={'left_eye_cataract':'cataract'})\nleft_df['Path']=oc_img_path+\"/\"+left_df['Left-Fundus']\nleft_df=left_df.drop(['Left-Fundus'],1)\n\nright_df=df.loc[:,['Right-Fundus','right_eye_cataract']].rename(columns={'right_eye_cataract':'cataract'})\nright_df['Path']=oc_img_path+\"/\"+right_df['Right-Fundus']\nright_df=right_df.drop(['Right-Fundus'],1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"left_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"right_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of left eye images')\nprint(left_df['cataract'].value_counts())\nprint('\\nNumber of right eye images')\nprint(right_df['cataract'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def downsample(df):\n    df = pd.concat([\n        df.query('cataract==1'),\n        df.query('cataract==0').sample(sum(df['cataract']), \n                                       random_state=42)\n    ])\n    return df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"left_df = downsample(left_df)\nright_df = downsample(right_df)\n\nprint('Number of left eye images')\nprint(left_df['cataract'].value_counts())\nprint('\\nNumber of right eye images')\nprint(right_df['cataract'].value_counts())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ocu_df = pd.concat([left_df, right_df])\nocu_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.concat([cat_df, ocu_df], ignore_index=True)\nlen(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df=train_df.sample(frac=1.0)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"length of train_df \",len(train_df))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del left_df,right_df,cat_df,ocu_df\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.cataract.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# class_count_samples=list(train_df.cataract.value_counts())\n# class_count_samples","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df,test_df=train_test_split(train_df,test_size=0.12,shuffle=True,stratify=train_df.cataract)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.cataract.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.cataract.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class cat_dataset(torch.utils.data.Dataset):\n    def __init__(self,df,transforms=None):\n        self.df=df\n        self.transforms=transforms\n    def __len__(self):\n        return len(self.df)\n    def __getitem__(self,idx):\n        \n        img=cv2.imread(self.df.Path.iloc[idx])\n        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n        if self.transforms:\n            img=self.transforms(img)\n        label=self.df.cataract.iloc[idx]\n        return (img,label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain_set=cat_dataset(train_df,transforms=transforms.Compose([\n     transforms.ToPILImage(),\n    transforms.Resize((IMG_SIZE,IMG_SIZE)),\n     transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n]))\ntest_set=cat_dataset(test_df,transforms=transforms.Compose([\n     transforms.ToPILImage(),\n    transforms.Resize((IMG_SIZE,IMG_SIZE)),\n     transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n]))\n\n\n# class_weights = 1./torch.Tensor(class_count_samples)\n# train_target=list(train_df.cataract)\n# train_samples_weight = [class_weights[class_id] for class_id in train_target]\n# test_target=list(test_df.cataract)\n# test_samples_weight = [class_weights[class_id] for class_id in test_target]\n\n\n# train_sampler = torch.utils.data.sampler.WeightedRandomSampler(train_samples_weight, len(train_df))\n# test_sampler = torch.utils.data.sampler.WeightedRandomSampler(test_samples_weight, len(test_df))\n\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size=BATCH,shuffle=True)\nval_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH,shuffle=True)\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def get_freq(sampler):\n#     vc={0:0,1:0}\n#     for i in sampler:\n#         vc[train_df.iloc[i].cataract]+=1\n#     return vc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(\"freq labels in train loader is \",get_freq(train_sampler))\n# print(\"freq labels in test loader is \",get_freq(test_sampler))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_me(loader):\n    \"\"\" Batch size must be more than 25 \"\"\"\n    imgs,lab=next(iter(loader))\n    imgs=imgs[:25]\n    lab=lab[:25]\n    plt.figure(figsize=(15,10))\n    for i in range(1,26):\n        img=imgs[i-1].numpy().transpose(1,2,0)\n        img=img*[0.5,0.5,0.5]+[0.5,0.5,0.5]\n        labs=lab[i-1].numpy()\n        labs=\"normal\" if labs==0 else \"cataract\"\n        plt.subplot(5,5,i,)\n        plt.imshow(img)\n        plt.title(labs)\n        plt.axis('off')\n    #plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_me(train_loader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_me(val_loader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=models.densenet121(pretrained=True)\nmodel.classifier=nn.Sequential(nn.Linear(1024,1),nn.Sigmoid())\nmodel=model.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# img,lab=next(iter(train_loader))\n# densenet_model(img.cuda())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lab","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def binary_acc(y_pred, y_test):\n    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n\n    correct_results_sum = (y_pred_tag == y_test).sum().float()\n    acc = correct_results_sum/y_test.shape[0]\n    acc = torch.round(acc * 100)\n    \n    return acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"crit=nn.BCELoss()\noptimizer=torch.optim.Adam(model.parameters(),lr=0.01)\nfrom torch.optim.lr_scheduler import StepLR\nscheduler = StepLR(optimizer, step_size=1, gamma=0.90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(model, epochs, optimizer, train_loader, criterion,test_loader,sch=None):\n    for epoch in range(1,epochs+1):\n        # train\n        total_loss = 0\n\n        model.train()\n        epoch_acc=0\n        for batch_idx, (data, target) in enumerate(train_loader):\n\n            data, target = data.type(torch.FloatTensor).to(device), target.type(torch.FloatTensor).to(device)\n            optimizer.zero_grad()\n            output = model(data)\n            loss = criterion(output, target)\n            total_loss += loss.item()\n            acc = binary_acc(output, target.unsqueeze(1))\n            loss.backward()\n            optimizer.step()\n            if sch:\n                sch.step()\n        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tAverage loss: {:.6f}'.format(\n            epoch, batch_idx * len(data), len(train_loader),\n            100. * batch_idx / len(train_loader), total_loss /len(train_loader)))\n        #print('Train Accuracy for epoch {} is {} \\n'.format(epoch,100. *correct/len(train_loader.dataset)))\n        print(' Acc', epoch_acc/len(train_loader))\n\n        # test\n        model.eval()\n        test_loss = 0\n        with torch.no_grad():\n            for data, target in test_loader:\n                data, target = data.type(torch.FloatTensor).to(device), target.type(torch.FloatTensor).to(device)\n                output = model(data)\n                test_loss += criterion(output, target).item()\n                \n\n        test_loss /= len(test_loader)\n        print('\\nTest set: Average loss: {:.4f}\\n'.format(test_loss))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train(model, 20, optimizer, train_loader, crit,val_loader,scheduler)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.eval()\ncorrect=0\ntotal=0\nwith torch.no_grad():\n    for data, target in val_loader:\n        data, target = data.type(torch.FloatTensor).to(device), target.type(torch.FloatTensor).to(device)\n        output = model(data)\n        pred=(output>0.5).float()\n        correct+=(pred==target).float().sum()\n        total+=target.size(0)\n    print(100* correct//total)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}