{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Emotion Recognition FER2013\n\n   ![](https://www.researchgate.net/profile/Garima-Verma-3/publication/343556711/figure/fig1/AS:933334486114318@1599535690875/Sample-of-the-FER2013-dataset.png)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"\nimport pandas as pd\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n### CNN models ###\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping,ReduceLROnPlateau\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D, SeparableConv2D\nfrom keras.utils import np_utils\nfrom keras.regularizers import l2\nfrom keras.optimizers import SGD, RMSprop\nfrom keras.utils import to_categorical\nfrom keras.layers.normalization import BatchNormalization\nfrom keras import models\nfrom keras.utils.vis_utils import plot_model\nfrom keras.layers import Input, GlobalAveragePooling2D,concatenate\nfrom keras.models import Model\nfrom tensorflow.keras import layers\nfrom keras.applications.inception_v3 import InceptionV3\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_curve, roc_auc_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Parameters","metadata":{}},{"cell_type":"code","source":"\nbatch_size = 32\nnum_epochs = 50\ninput_shape = (48, 48, 1)\nvalidation_split = .2\nverbose = 1\nnum_classes = 7\nbase_path = 'models/'\nshape_x = 48\nshape_y = 48\nimage_size=(48,48)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data ","metadata":{}},{"cell_type":"code","source":"data=pd.read_csv('../input/fer2013/fer2013.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"code","source":"data['pixels']=data['pixels'].astype(\"string\")\npixels = data['pixels'].tolist()\nwidth, height = 48, 48\nfaces = []\nfor pixel_sequence in pixels:\n    face = [int(pixel) for pixel in pixel_sequence.strip().split(' ',48*48)]\n    face = np.asarray(face).reshape(width, height)\n    face = cv2.resize(face.astype('uint8'),image_size)\n    faces.append(face.astype('float32'))\nfaces = np.asarray(faces)\nfaces = np.expand_dims(faces, -1)\nfaces /= 127.5\nfaces -= 1.\nemotions = pd.get_dummies(data['emotion']).to_numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Augmentation","metadata":{}},{"cell_type":"code","source":"datagen = ImageDataGenerator(\n        zoom_range=0.2,          # randomly zoom into images\n        rotation_range=10,       # randomly rotate images in the range (degrees, 0 to 180)\n        width_shift_range=0.1,   # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,    # randomly flip images\n        vertical_flip=False)     # randomly flip images","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.3,shuffle=True)\nxval,xtest,yval,ytest=train_test_split(xtest,ytest,test_size=0.3,shuffle=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Xception :\n[PAPER](https://arxiv.org/pdf/1610.02357.pdf)\n\n![](https://www.researchgate.net/publication/342580102/figure/fig3/AS:908305815830530@1593568390179/Schematic-diagram-of-the-Xception-model.png)","metadata":{}},{"cell_type":"code","source":"def entry_flow(inputs) :\n    \n    x = Conv2D(32, 3, strides = 2, padding='same')(inputs)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    \n    x = Conv2D(64,3,padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    \n    previous_block_activation = x\n    \n    for size in [64, 128, 256] :\n    \n        x = Activation('relu')(x)\n        x = SeparableConv2D(size, 3, padding='same')(x)\n        x = BatchNormalization()(x)\n    \n        x = Activation('relu')(x)\n        x = SeparableConv2D(size, 3, padding='same')(x)\n        x = BatchNormalization()(x)\n        \n        x = MaxPooling2D(3, strides=2, padding='same')(x)\n        \n        residual = Conv2D(size, 1, strides=2, padding='same')(previous_block_activation)\n        \n        x = keras.layers.Add()([x, residual])\n        previous_block_activation = x\n    \n    return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def middle_flow(x, num_blocks=8) :\n    \n    previous_block_activation = x\n    \n    for _ in range(num_blocks) :\n    \n        x = Activation('relu')(x)\n        x = SeparableConv2D(256, 3, padding='same')(x)\n        x = BatchNormalization()(x)\n    \n        x = Activation('relu')(x)\n        x = SeparableConv2D(256, 3, padding='same')(x)\n        x = BatchNormalization()(x)\n        \n        x = Activation('relu')(x)\n        x = SeparableConv2D(256, 3, padding='same')(x)\n        x = BatchNormalization()(x)\n        \n        x = keras.layers.Add()([x, previous_block_activation])\n        previous_block_activation = x\n    \n    return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def exit_flow(x, num_classes=7) :\n    \n    previous_block_activation = x\n    \n    x = Activation('relu')(x)\n    x = SeparableConv2D(256, 3, padding='same')(x)\n    x = BatchNormalization()(x)\n    \n    x = Activation('relu')(x)\n    x = SeparableConv2D(1024, 3, padding='same')(x)\n    x = BatchNormalization()(x)\n    \n    x = MaxPooling2D(3, strides=2, padding='same')(x)\n    \n    residual = Conv2D(1024, 1, strides=2, padding='same')(previous_block_activation)\n    x = keras.layers.Add()([x, residual])\n      \n    x = Activation('relu')(x)\n    x = SeparableConv2D(728, 3, padding='same')(x)\n    x = BatchNormalization()(x)\n    \n    x = Activation('relu')(x)\n    x = SeparableConv2D(1024, 3, padding='same')(x)\n    x = BatchNormalization()(x)\n    \n    x = GlobalAveragePooling2D()(x)\n    x = Dense(num_classes, activation='softmax')(x)\n    \n    return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = Input(shape=(shape_x, shape_y, 1))\noutputs = exit_flow(middle_flow(entry_flow(inputs)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xception = Model(inputs, outputs,name=\"Xception\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(xception, to_file='xception.png', show_shapes=True, show_layer_names=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xception.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nxception.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dexpression\n[PAPER](https://arxiv.org/pdf/1509.05371.pdf)\n\n![](https://qph.fs.quoracdn.net/main-qimg-252e5047af30f8ea18def43bb35dbf41.webp)","metadata":{}},{"cell_type":"code","source":"def dexpression():\n    inputs = Input(shape=(shape_x, shape_y, 1))\n\n    x = Conv2D(64, 7, strides = 2, padding='same')(inputs)\n    x = Activation('relu')(x)\n    x = MaxPooling2D(3, strides=2, padding='same')(x)\n    x = BatchNormalization()(x)\n\n    x_1 = Conv2D(96, 1, strides = 1, padding='same')(x)\n    x_1 = Activation('relu')(x_1)\n    x_1 = MaxPooling2D(3, strides=1, padding='same')(x_1)\n    x_1 = BatchNormalization()(x_1)\n\n    x_2 = Conv2D(208, 3, strides = 1, padding='same')(x_1)\n    x_2 = Activation('relu')(x_2)\n    x_2 = MaxPooling2D(3, strides=1, padding='same')(x_2)\n\n    x_3 = Conv2D(64, 1, strides = 1, padding='same')(x_1)\n    x_3 = Activation('relu')(x_3)\n    x_3 = MaxPooling2D(3, strides=1, padding='same')(x_3)\n\n\n    x_4=concatenate([x_2,x_3],axis=3)\n\n    x_5 = Conv2D(96, 1, strides = 1, padding='same')(x_4)\n    x_5 = Activation('relu')(x_5)\n    x_5 = Conv2D(208, 3, strides = 1, padding='same')(x_5)\n    x_5 = Activation('relu')(x_5)\n\n    x_6 = MaxPooling2D(3, strides=1, padding='same')(x_4)\n    x_6 = Activation('relu')(x_6)\n    x_6 = Conv2D(64, 1, strides = 1, padding='same')(x_6)\n    x_6 = Activation('relu')(x_6)\n    x_6 = MaxPooling2D(3, strides=1, padding='same')(x_6)\n    x_7 = concatenate([x_5,x_6],axis=3)\n\n    x_8 = Flatten()(x_7)\n    x_8 = Dropout(0.25)(x_8)\n    x_8 = Dense(7, activation='softmax')(x_8)\n    return Model(inputs, x_8,name='DeXpression')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dexpression=dexpression()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(dexpression, to_file='dexpression.png', show_shapes=True, show_layer_names=True)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dexpression.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\ndexpression.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CNN inspired by Goodfellow I.J\n[PAPER](https://arxiv.org/pdf/1307.0414.pdf)\n\n![](https://raw.githubusercontent.com/NJNischal/Facial-Expression-Recognition-with-CNNs/9999cbdaa55542e86e11a9e129bafcfb96bd0e60/model.png)","metadata":{}},{"cell_type":"code","source":"def CNN():\n    model = Sequential(name='CNN')\n    model.add(Conv2D(64, (3, 3), padding='same', input_shape=(48,48,1)))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='same'))\n    model.add(Dropout(0.25))\n\n    model.add(Conv2D(128, (3, 3), padding='same'))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='same'))\n    model.add(Dropout(0.25))\n\n    model.add(Conv2D(256, (3, 3), padding='same'))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='same'))\n    model.add(Dropout(0.25))\n\n    model.add(Conv2D(512, (3, 3), padding='same'))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='same'))\n    model.add(Dropout(0.25))\n\n    model.add(Flatten())\n\n    model.add(Dense(512))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Dropout(0.25))\n\n    model.add(Dense(256))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Dropout(0.25))\n\n    model.add(Dense(7))\n    model.add(Activation('softmax'))\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN=CNN()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(CNN, to_file='CNN.png', show_shapes=True, show_layer_names=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nCNN.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training \n## Xception","metadata":{}},{"cell_type":"code","source":"\nearly_stop = EarlyStopping('val_loss', patience=100)\nreduce_lr = ReduceLROnPlateau('val_loss', factor=0.1,\n                                  patience=50, min_lr=0.00001,model='auto')\ntrained_models_path = base_path + '_Xception'\nmodel_names = trained_models_path + '.{epoch:02d}-{val_accuracy:.2f}.hdf5'\nmodel_checkpoint = ModelCheckpoint(model_names, 'val_loss', verbose=1,\n                                                    save_best_only=True)\ncallbacks = [model_checkpoint, early_stop, reduce_lr]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xception_history =xception.fit(datagen.flow(xtrain, ytrain, batch_size),\n          steps_per_epoch=len(xtrain) / batch_size, \n          epochs=num_epochs, \n          verbose=1, \n          callbacks=callbacks,\n          validation_data=(xval,yval))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dexpression","metadata":{}},{"cell_type":"code","source":"early_stop = EarlyStopping('val_loss', patience=100)\nreduce_lr = ReduceLROnPlateau('val_loss', factor=0.1,\n                                  patience=25, min_lr=0.00001,model='auto')\ntrained_models_path = base_path + '_DeXpression'\nmodel_names = trained_models_path + '.{epoch:02d}-{val_accuracy:.2f}.hdf5'\nmodel_checkpoint = ModelCheckpoint(model_names, 'val_loss', verbose=1,\n                                                    save_best_only=True)\ncallbacks = [model_checkpoint, early_stop, reduce_lr]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dexpression_history =dexpression.fit(datagen.flow(xtrain, ytrain, batch_size),\n          steps_per_epoch=len(xtrain) / batch_size, \n          epochs=num_epochs, \n          verbose=1, \n          callbacks=callbacks,\n          validation_data=(xval,yval))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CNN\n","metadata":{}},{"cell_type":"code","source":"early_stop = EarlyStopping('val_loss', patience=100)\nreduce_lr = ReduceLROnPlateau('val_loss', factor=0.1,\n                                  patience=25, min_lr=0.00001,model='auto')\ntrained_models_path = base_path + 'CNN'\nmodel_names = trained_models_path + '.{epoch:02d}-{val_accuracy:.2f}.hdf5'\nmodel_checkpoint = ModelCheckpoint(model_names, 'val_loss', verbose=1,\n                                                    save_best_only=True)\ncallbacks = [model_checkpoint, early_stop, reduce_lr]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN_history =CNN.fit(datagen.flow(xtrain, ytrain, batch_size),\n          steps_per_epoch=len(xtrain) / batch_size, \n          epochs=num_epochs, \n          verbose=1, \n          callbacks=callbacks,\n          validation_data=(xval,yval))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing","metadata":{}},{"cell_type":"markdown","source":"### Plotting accuracy and loss curves ","metadata":{}},{"cell_type":"code","source":"\nfig,axes=plt.subplots(3,2,figsize=(20, 20))\nfor (m,history), ax in zip({'CNN':CNN_history,'Xception':xception_history,'Dexpression':dexpression_history}.items(),axes):\n    # Loss Curves\n    \n    ax[0].plot(history.history['loss'],'r',linewidth=2.0)\n    ax[0].plot(history.history['val_loss'],'b',linewidth=2.0)\n    ax[0].legend(['Training loss', 'Validation Loss'],fontsize=18)\n    ax[0].set_xlabel('Epochs ',fontsize=16)\n    ax[0].set_ylabel('Loss',fontsize=16)\n    ax[0].set_title('Loss Curves '+m,fontsize=16)\n \n    # Accuracy Curves\n    ax[1].plot(history.history['accuracy'],'r',linewidth=2.0)\n    ax[1].plot(history.history['val_accuracy'],'b',linewidth=2.0)\n    ax[1].legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n    ax[1].set_xlabel('Epochs ',fontsize=16)\n    ax[1].set_ylabel('Accuracy',fontsize=16)\n    ax[1].set_title('Accuracy Curves '+m,fontsize=16)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.savefig('plots.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Classification reports","metadata":{}},{"cell_type":"code","source":"\nfor model in [CNN,xception,dexpression]:\n    ypred=model.predict(xtest)\n    ypred_=np.argmax(ypred, axis=1)\n    ytest_=np.argmax(ytest, axis=1)\n    print(classification_report(ytest_, ypred_,digits=3))\n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Confusion Matrix","metadata":{}},{"cell_type":"code","source":"import itertools\nfrom sklearn.metrics import confusion_matrix\nfrom matplotlib.pyplot import figure\n\n\nfor model,i in zip([CNN,xception,dexpression],[1,2,3]):\n    fig = figure(figsize=(10, 10))\n    \n    ypred=model.predict(xtest)\n    rounded_predections=np.argmax(ypred, axis=1)\n    rounded_labels=np.argmax(ytest, axis=1)\n    cm = confusion_matrix(rounded_labels, rounded_predections)\n    labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n    title='Confusion matrix '+model.name\n    \n\n    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(labels))\n    plt.xticks(tick_marks, labels, rotation=45)\n    plt.yticks(tick_marks, labels)\n    fmt = 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                horizontalalignment=\"center\",\n                color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()\n    plt.savefig('confusion_matrix_'+model.name+'.png')\n    plt.show()\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}