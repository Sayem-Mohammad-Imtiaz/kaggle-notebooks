{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport torch\nfrom torch import nn\nfrom PIL import Image\nfrom torchvision import transforms","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Make_dataset:\n    def __init__(self,path):\n        self.path=path\n        self.img=os.listdir(path)\n        self.transforms=transforms.Compose([\n            transforms.Resize((64,64)),\n            transforms.ToTensor()])\n    def __len__(self):\n        return len(self.img)\n#         return 1000\n    def __getitem__(self,idx):\n        X=Image.open(f'{self.path}/{self.img[idx]}')\n#         X=transforms.Resize((64,64))(X)\n#         X=transforms.ToTensor()(X)\n        return self.transforms(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset=Make_dataset(\"../input/celeba-dataset/img_align_celeba/img_align_celeba\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset[100001]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_loader=torch.utils.data.DataLoader(dataset, batch_size=500)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for x in data_loader:\n    print (x.shape)\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"next(iter(data_loader))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Dicriminator(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.layer_0=nn.Sequential(\n            nn.Conv2d(3,32,kernel_size=(3,3),padding=(1,1)),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(2,2)\n        )\n        self.layer_1=torch.nn.Sequential(\n            nn.Conv2d(32,64,kernel_size=(3,3),padding=(1,1)),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(2,2)\n        )\n        self.layer_2=torch.nn.Sequential(\n            nn.Conv2d(64,128,kernel_size=(3,3),padding=(1,1)),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(2,2)\n        )\n        self.layer_3=torch.nn.Sequential(\n            nn.Conv2d(128,256,kernel_size=(3,3),padding=(1,1)),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(2,2)\n        )\n        self.layer_4=torch.nn.Sequential(\n            nn.Conv2d(256,512,kernel_size=(3,3),padding=(1,1)),\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(2,2)\n        )\n        self.layer_5=torch.nn.Sequential(\n            nn.Conv2d(512,1024,kernel_size=(3,3),padding=(1,1)),\n            nn.BatchNorm2d(1024),\n            nn.ReLU(),\n            nn.MaxPool2d(2,2)\n        )\n        self.layer_6=torch.nn.Sequential(\n            nn.Linear(1024,512),\n            nn.Linear(512, 2)\n        )\n    def forward(self, x):\n        x = self.layer_0(x)\n        x = self.layer_1(x)\n        x = self.layer_2(x)\n        x = self.layer_3(x)\n        x = self.layer_4(x)\n        x = self.layer_5(x)\n#         print(x.shape)\n        x = x.view(-1, 1024)\n        x = self.layer_6(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# disc=dicriminator()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# disc(torch.ones((2,3,64,64)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.layer_0=torch.nn.Sequential(\n            nn.ConvTranspose2d(100, 64*8, 4, 1, 0, bias=False),\n            nn.BatchNorm2d(64*8),\n            nn.ReLU()\n        )\n        self.layer_1=torch.nn.Sequential(\n            nn.ConvTranspose2d(64*8, 64*4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(64*4),\n            nn.ReLU()\n        )\n        self.layer_2=torch.nn.Sequential(\n            nn.ConvTranspose2d(64*4, 64*2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(64*2),\n            nn.ReLU()\n        )\n        self.layer_3=torch.nn.Sequential(\n            nn.ConvTranspose2d(64*2, 64, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU()\n        )\n        \n        self.layer_4=torch.nn.Sequential(\n            torch.nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False),\n            torch.nn.Tanh()\n        )\n    \n    def forward(self, x):\n        x = self.layer_0(x)\n        x = self.layer_1(x)\n        x = self.layer_2(x)\n        x = self.layer_3(x)\n        x = self.layer_4(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# gen=Generator()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# gen(torch.ones((2,100,1,1)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# criterion=nn.CrossEntropyLoss()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# optimizer_D=torch.optim.Adam(disc.parameters(), lr = 0.0001)\n# optimizer_G=torch.optim.Adam(gen.parameters(), lr = 0.0001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = 'cuda'\ngen = Generator().to(device)\ndisc = Dicriminator().to(device)\n# state_dict = torch.load(\"model.pth\", map_location = device)\n# gen.load_state_dict(state_dict[\"generator\"])\n# disc.load_state_dict(state_dict[\"discriminator\"])\ncriterion = nn.CrossEntropyLoss()\noptimizer_G = torch.optim.Adam(gen.parameters(), lr = 0.0001)\noptimizer_D = torch.optim.Adam(disc.parameters(), lr = 0.0001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gen(torch.ones((2, 100, 1, 1), device=device)).shape, disc(torch.ones((2, 3, 64, 64), device=device)).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Train(epoch):\n    total_loss_G=0\n    total_loss_D=0\n    for x in data_loader:\n        x=x.to(device)\n        true_d=disc(x)\n        y_1=torch.ones((len(x)),dtype=torch.long, device = device)\n        true_loss_d=criterion(true_d, y_1)\n        optimizer_D.zero_grad()\n        true_loss_d.backward()\n        \n        \n        noise=torch.randn((len(x),100,1,1),device = device)\n        fake_image=gen(noise)\n        false_d=disc(fake_image.detach())\n        y_0=torch.zeros((len(x)),dtype=torch.long,device = device)\n        false_loss_d=criterion(false_d, y_0)\n        false_loss_d.backward()\n        optimizer_D.step()\n        \n        output=disc(fake_image)\n        loss_g=criterion(output, y_1)\n        optimizer_D.zero_grad()\n        loss_g.backward()\n        optimizer_G.step()\n        \n#         print(f\"Discriminator Loss: {true_loss_d + false_loss_d}, Generator Loss: {loss_g}\")\n        \n        total_loss_D += true_loss_d.item() + false_loss_d.item()\n        total_loss_G += loss_g.item()\n        \n#         print(f\"Discriminator Loss: {true_loss_d + false_loss_d}, Generator Loss: {loss_g}\")\n        \n    print(f\"Epoch: {epoch}, Loss D: {total_loss_D/len(data_loader)}, Loss G: {total_loss_G/len(data_loader)}\")\n    return epoch, total_loss_D/len(data_loader), total_loss_G/len(data_loader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for epoch in range(1, 31): Train(epoch)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"noise = torch.randn((1, 100, 1, 1), device = device)\nfake_image = gen(noise)\ntransforms.ToPILImage()(fake_image.squeeze()).resize((256, 256))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save({\"generator\": gen.state_dict(), \"discriminator\": disc.state_dict()}, \"model.pth\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# x=os.listdir('../input/celeba-dataset/img_align_celeba/img_align_celeba')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# from PIL import Image\n# from torchvision import transforms","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# img=Image.open(f'../input/celeba-dataset/img_align_celeba/img_align_celeba/{x[0]}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# np.array(img).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# transforms.Resize((64,64))(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# transforms.ToTensor()(img).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# transforms.Compose([transforms.Resize((64,64)),transforms.ToTensor()])(img).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def x():\n#     for i in range (10):\n        yield i","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for j in x():\n#     print (j)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y=x()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# next(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def x():\n#     yield 1\n#     yield 2\n#     yield 3\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y=x()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# next(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}