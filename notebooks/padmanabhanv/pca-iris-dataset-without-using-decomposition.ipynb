{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# In this Notebook, We understand PCA using Iris DataSet.\n"},{"metadata":{},"cell_type":"markdown","source":"Importing required libraries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler \nfrom scipy.linalg import eigh\nimport seaborn as sn","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reading IRIS DataSet"},{"metadata":{"trusted":true},"cell_type":"code","source":"url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n\n# load dataset into Pandas DataFrame\niris_df = pd.read_csv(\"../input/iris-flower-dataset/IRIS.csv\")\n\nprint(iris_df.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Column Standardize the features."},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n\ndata = iris_df.loc[:, features].values\ntarget = iris_df.loc[:, ['species']].values\n\nstandardized_data = StandardScaler().fit_transform(data)\n\nprint(\"Shape of the data after standardized : \", standardized_data.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To get euigen vectors and values,  we need covariance matrix of the standardized_data. Then using the covariance Matrix, we get vectors and values using eigh from sicpy library."},{"metadata":{"trusted":true},"cell_type":"code","source":"cov_matrix = np.matmul(standardized_data.T, standardized_data)\nprint(\"Shape of cov matrix : \", cov_matrix.shape)\n\neuigen_values, euigen_vectors = eigh(cov_matrix, eigvals=(2,3))\nprint(\"Shape of vectors : \", euigen_vectors.shape)\n\neuigen_vectors_T = euigen_vectors.T\nprint(\"Shape of vectors transpose: \", euigen_vectors_T.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we are projecting our Standardized data to the euigen vectors where maximum variance is present."},{"metadata":{"trusted":true},"cell_type":"code","source":"result_data = np.matmul(euigen_vectors_T, standardized_data.T)\nprint(\"Shape of new Coordinates: \", result_data.shape)\nprint(\"Shape of target: \", target.shape)\n# Stacking the species variable to the data.\nresult_data = np.vstack((result_data, target.T)).T\nprint(\"Shape of new Coordinates: \", result_data.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we have only 2 features and 1 target variable.  We converted 4D to 2D so we can visualize the data in 2D"},{"metadata":{"trusted":true},"cell_type":"code","source":"result_df = pd.DataFrame(data=result_data, columns=('first_principal', 'second_principal', 'label'))\nprint(result_df.head())\n\nsn.FacetGrid(result_df, hue='label', height=7).map(plt.scatter, 'first_principal', 'second_principal').add_legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}