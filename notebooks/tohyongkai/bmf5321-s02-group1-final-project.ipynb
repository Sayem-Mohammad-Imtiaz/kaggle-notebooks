{"cells":[{"metadata":{},"cell_type":"markdown","source":"# TABLE OF CONTENTS\n\n\n* [1. INTRODUCTION](#section-one)\n* [2. SETUP](#section-two)\n    - [2.1 Installing Packages](#subsection-two-one)\n    - [2.1 Importing Packages](#subsection-two-two)\n    - [2.2 Wrangle Data](#subsection-two-three)\n* [3. Covid-19 Analysis](#section-three)\n    - [3.1 Covid-19 cases by country](#subsection-three-one)\n    - [3.2 Covid-19 cases by state](#subsection-three-two)\n    - [3.3 Impact of state cases on stocks performance](#subsection-three-three)\n    - [3.4 Predicting future Covid-19 patterns](#subsection-three-four)\n* [4. Stock analysis](#section-four)\n    - [4.1 Stock selection](#subsection-four-one)\n        - [4.1.1 Bear ETF and Treasury ETF](#subsection-four-one-one)\n        - [4.1.2 Technology stocks](#subsection-four-one-two)\n        - [4.1.3 Consumer Cylical stocks](#subsection-four-one-three)\n        - [4.1.4 Real estate stocks](#subsection-four-one-four)\n        - [4.1.5 Healthcare stocks](#subsection-four-one-five)        \n* [5. Portfolio optimization](#section-five)\n    - [5.1 Stock correlation](#subsection-five-one)\n    - [5.2 Simulation of portfolio performance](#subsection-five-two)\n    - [5.3 Portfolio allocation](#subsection-five-three)\n    - [# 5.4 Portfolio returns relationship to new cases](#subsection-five-four)\n* [6. Conclusion](#section-six)"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"section-one\"></a>\n# 1. Introduction"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"section-two\"></a>\n# 2. Set-up"},{"metadata":{},"cell_type":"markdown","source":"- [2.1 Draw Packages](#subsection-two-one)\n#  2.1 Installing pips"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install --upgrade pip","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install yfinance","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"subsection-two-two\"></a>\n# 2.2 Importing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Date\nfrom dateutil import relativedelta as rd\nfrom datetime import datetime, date, timedelta\nfrom datetime import date\n\n#Data Manipulation\nimport pandas as pd\nimport numpy as np\nfrom pandas import DataFrame\nfrom numpy import inf\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport plotly as py\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.offline as pyo\npyo.init_notebook_mode()\nimport seaborn as sns\nimport matplotlib.cm as cm\nimport matplotlib.dates as mdates\nfrom matplotlib.dates import DateFormatter\nimport geopandas as gpd\nimport matplotlib as mpl\nfrom scipy.stats.mstats import winsorize\nfrom matplotlib.patches import Ellipse\nfrom matplotlib.text import OffsetFrom\n\nimport os\n\n# Regression \nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols\nimport statsmodels.graphics.api as smg\nfrom scipy.optimize import curve_fit\nimport yfinance as yf\n\n\n#Prediction\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"subsection-two-three\"></a>\n# 2.3 WRANGLING DATA"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Color Palettes\ncnf, dth, rec, act = '#393e46', '#ff2e63', '#21bf73', '#fe9801' ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# World Data up till july\ncountry_wise = pd.read_csv('../input/corona-virus-report/country_wise_latest.csv')\ncountry_wise = country_wise.replace('', np.nan).fillna(0)\nfull_grouped = pd.read_csv('../input/corona-virus-report/full_grouped.csv')\nfull_grouped['Date'] = pd.to_datetime(full_grouped['Date'])\nday_wise = pd.read_csv('../input/corona-virus-report/day_wise.csv')\nday_wise['Date'] = pd.to_datetime(day_wise['Date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Germany Data up till july\nworld_confirmed = pd.read_csv('../input/covid19-report-2020117/time_series_covid19_confirmed_global.csv')\ngermany_confirmed = world_confirmed[world_confirmed['Country/Region'].isin(['Germany'])]\ngermany_confirmed = germany_confirmed.drop(['Province/State','Country/Region','Lat','Long'],axis=1)\ngermany_confirmed = germany_confirmed.transpose()\ngermany_confirmed.reset_index(inplace = True)\ngermany_confirmed.columns = [\"Date\",'Total Confirmed']\n#print(germany_confirmed)\nworld_deaths = pd.read_csv('../input/covid19-report-2020117/time_series_covid19_deaths_global.csv')\ngermany_deaths = world_deaths[world_deaths['Country/Region'].isin(['Germany'])]\ngermany_deaths = germany_deaths.drop(['Province/State','Country/Region','Lat','Long'],axis=1)\ngermany_deaths = germany_deaths.transpose()\ngermany_deaths.reset_index(inplace = True)\ngermany_deaths.columns = [\"Date\",'Total Deaths']\n#print(germany_deaths)\nworld_recovered = pd.read_csv('../input/covid19-report-2020117/time_series_covid19_recovered_global.csv')\ngermany_recovered = world_recovered[world_recovered['Country/Region'].isin(['Germany'])]\ngermany_recovered = germany_recovered.drop(['Province/State','Country/Region','Lat','Long'],axis=1)\ngermany_recovered = germany_recovered.transpose()\ngermany_recovered.reset_index(inplace = True)\ngermany_recovered.columns = [\"Date\",'Total Recovered']\n#print(germany_recovered)\ngermanycountry= pd.merge(germany_confirmed,germany_deaths,on='Date',how='outer')\ngermanycountry= pd.merge(germanycountry,germany_recovered,on='Date',how='outer')\ngermanycountry['Total Active'] = germanycountry['Total Confirmed']-germanycountry['Total Deaths']-germanycountry['Total Recovered']\ngermanycountry['Date'] = pd.to_datetime(germanycountry['Date'])\n#print(germanycountry)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"## Function to get the pandemic countries\ngermanystate = pd.read_csv('../input/covid19-tracking-germany/covid_de.csv')\ngermanystate['date'] = pd.to_datetime(germanystate['date'])\n\n#print(germanystate['gender'].isnull().sum()) #missing data from gender\n#print(germanystate['age_group'].isnull().sum()) #missing data from age_group\ngermanystate.dropna(subset=['gender','age_group'], how='all',inplace=True)\n\nstate = germanystate.sort_values(['state','date','gender','age_group']).reset_index()\nstate_cases_per_day=state.groupby(['state','date','gender','age_group']).agg({'cases':'sum','deaths':'sum'}).reset_index()\nstate_cases_per_day['Total cases']=state_cases_per_day.groupby('state')['cases'].cumsum()\nstate_cases_per_day['Total deaths']=state_cases_per_day.groupby('state')['deaths'].cumsum()\n\ngermanypop= pd.read_csv('../input/covid19-tracking-germany/demographics_de.csv')\n#print(germanypop.info())\ngermanypop = germanypop.replace('female','F')\ngermanypop = germanypop.replace('male','M')\n#print(germanypop.head(20))\ngermany_cases_pop = pd.merge(germanystate,germanypop,on=['state','gender','age_group'],how='inner')\ngermany_cases_pop['Total cases']=germany_cases_pop.groupby('state')['cases'].cumsum()\ngermany_cases_pop['Total deaths']=germany_cases_pop.groupby('state')['deaths'].cumsum()\ngermany_cases_pop.rename(columns={'cases':'new_cases','deaths':'new_deaths'},inplace=True)\ngermany_cases_pop.drop(columns=['county'],inplace=True)\n#print(germany_cases_pop)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Worldometer data\n# ================\n\nworldometer_data = pd.read_csv('../input/corona-virus-report/worldometer_data.csv')\n\n# Replace missing values '' with NAN and then 0\n# What are the alternatives? Drop or impute. Do they make sense in this context?\nworldometer_data = worldometer_data.replace('', np.nan).fillna(0)\nworldometer_data['Case Positivity'] = round(worldometer_data['TotalCases']/worldometer_data['TotalTests'],2)\nworldometer_data['Case Fatality'] = round(worldometer_data['TotalDeaths']/worldometer_data['TotalCases'],2)\n\n# Case Positivity is infinity when there is zero TotalTests due to division by zero\nworldometer_data[worldometer_data[\"Case Positivity\"] == inf] = 0\n\n# Qcut is quantile cut. Here we specify three equally sized bins and label them low, medium, and high, respectively.\nworldometer_data ['Case Positivity Bin']= pd.qcut(worldometer_data['Case Positivity'], q=3, labels=[\"low\", \"medium\", \"high\"])\n\n# Population Structure\nworldometer_pop_struc = pd.read_csv('../input/covid19-worldometer-snapshots-since-april-18/population_structure_by_age_per_contry.csv')\n\n# Replace missing values with zeros\nworldometer_pop_struc = worldometer_pop_struc.fillna(0)\n#worldometer_pop_struc.info()\n\n# Merge worldometer_data with worldometer_pop_struc\n# Inner means keep only common key values in both datasets\nworldometer_data = worldometer_data.merge(worldometer_pop_struc,how='inner',left_on='Country/Region', right_on='Country')\n\n# Keep observations where column \"Country/Region\" is not 0\nworldometer_data = worldometer_data[worldometer_data[\"Country/Region\"] != 0]\n\n# Inspect worldometer_data's metadata\n#worldometer_data.info()\n\n# Inspect Data\n# worldometer_data.info()\n# worldometer_data.tail(20)\n# worldometer_data[\"Case Positivity\"].describe()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First we wrangle the data, by making datetime format for dates, and removing data that are missing in both age_groups and gender. Next, we found the total cases and deaths per state. Next, we merged the data from population to create find cases and deaths as a percentage of population. "},{"metadata":{},"cell_type":"markdown","source":"<a id=\"subsection-three\"></a>\n# 3. Covid-19 Analysis\n"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"subsection-three-one\"></a>\n# 3.1 **Covid-19 cases by country**"},{"metadata":{"trusted":true},"cell_type":"code","source":"germanycountry['Recovered%'] = round(germanycountry['Total Recovered']/germanycountry['Total Confirmed']*100,2)\ngermanycountry[\"New Active\"] = germanycountry[\"Total Active\"].diff()\ngermanycountry[\"New Cases\"] = germanycountry[\"Total Confirmed\"].diff()\ngermanycountry[\"New Deaths\"] = germanycountry[\"Total Deaths\"].diff()\ngermanycountry = germanycountry.replace('', np.nan).fillna(0)\nprint(germanycountry)\ntemp = germanycountry.melt(id_vars=\"Date\", value_vars=['New Cases', 'New Deaths'],\n                 var_name='Case', value_name='Count')\ntemp.head()\n\nfig = px.area(temp, x=\"Date\", y=\"Count\", color='Case', height=600, width=1200,\n             title='Cases over time (Germany)', color_discrete_sequence = [rec, dth, act])\nfig.update_layout(xaxis_rangeslider_visible=True)\nfig.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> There is a huge spike of covid 19 cases in March to May, at its peak, there were over 7000 cases per day. In October 2020, the second wave came and the daily cases is even higher, reaching its peak at 30k cases per day on November 4"},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = germanycountry[['Date','Total Deaths', 'Total Recovered', 'Total Active']].tail(1)\ntemp.head()\ntemp = temp.melt(id_vars=\"Date\", value_vars=['Total Active', 'Total Deaths', 'Total Recovered'])\nprint(temp)\nfig = px.treemap(temp, path=[\"variable\"], values=\"value\", height=225, \n                 color_discrete_sequence=[act, rec, dth])\nfig.data[0].textinfo = 'label+text+value'\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> By 7 November, all the new active cases has already reached nearly half of the total cases. We expect long lockdowns in order to curb such a growth"},{"metadata":{"trusted":true},"cell_type":"code","source":"comparables = world_confirmed[world_confirmed['Country/Region'].isin(['Turkey','France','Germany'])]\ncomparables = pd.DataFrame.transpose(comparables)\ncomparables.columns = ['116','117','118','119','120','121','122','123','124','125','126','Germany','Turkey']\ncomparables = pd.DataFrame(data = comparables)\n\ncomparables[\"France\"] = comparables[\"116\"] + comparables[\"117\"] + comparables[\"118\"] + comparables[\"119\"] \\\n+ comparables[\"120\"] + comparables[\"121\"] + comparables[\"122\"] + comparables[\"123\"] + comparables[\"124\"] + comparables[\"125\"] + comparables[\"126\"]\ncomparables = comparables.drop(['116','117','118','119','120','121','122','123','124','125','126'],axis = 1)\ncomparables = comparables.drop(['Province/State','Country/Region','Lat','Long'])\ncomparables = comparables.reset_index()\ncomparables = comparables.rename(columns = {'index':'Date'})\ncomparables = pd.melt(comparables, id_vars = [\"Date\"], value_vars = ['Germany','Turkey','France'],var_name = \"Country\",value_name='Confirmed')\ncomparables = comparables[comparables['Confirmed']>100000]\ncomparables['Date'] = pd.to_datetime(comparables['Date'])\n#comparables['min_date'] = comparables.groupby('Country')[\"Date\"].min()\nmin_date = comparables.groupby('Country')[\"Date\"].min()\nmin_date = pd.DataFrame(data = min_date).reset_index()\nmin_date = min_date.rename(columns = {'Date':'min_date'})\ncomparables = pd.merge(comparables,min_date,on='Country',how='left')\n\ncomparables['N days']=(comparables['Date'] - comparables['min_date']).dt.days\nprint(comparables)\n\nfig = px.line(comparables, x='N days', y='Confirmed', color='Country', \n               title='N days from '+ str(100000) +' case', height=600)\nfig.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> France seems to have trouble maintaining the total cases at a lower level, its spike is much higher than that of germany and turkey. Germany curve is turning up as well, suggesting it might follow the pattern of France soon"},{"metadata":{},"cell_type":"markdown","source":"# Estimating real fatality rate\n> These 3 countries are all from Europe with similar patterns in growth of covid cases. As all three has experienced more than 100k total cases, we will like to estimate the true fatality rate of the three countries.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_hbar_wm(col, n, min_pop=1000000):\n    df = worldometer_data[worldometer_data['Population']>min_pop]\n    df = df.sort_values(col, ascending=True).tail(n)\n    df.info()\n    fig = px.bar(df,\n                 x=col, y=\"Country/Region\", color='WHO Region',  \n                 text=col, orientation='h', width=700, \n                 color_discrete_sequence = px.colors.qualitative.Dark2)\n    fig.update_layout(title=col+' (Only countries with Population > ' + str(min_pop), \n                      xaxis_title=\"\", yaxis_title=\"\", \n                      yaxis_categoryorder = 'total ascending',\n                      uniformtext_minsize=8, uniformtext_mode='hide')\n    fig.show()\n    \n# Draw histogram with two arguments\n# 1. variable of interest\n# 2. the number of bins\ndef plot_histogram_wm(col, bins):\n    fig = px.histogram(worldometer_data[col], x=col, nbins=bins)\n    fig.show()\n\n    \ndef compar_wm(col, n):\n    df = worldometer_data[worldometer_data['Country/Region'].isin(['Turkey','France','Germany'])]\n    df = df.sort_values(col, ascending=True).tail(n)\n    \n    fig = px.bar(df,\n                 x=col, y=\"Country/Region\", color='WHO Region',  \n                 text=col, orientation='h', width=700, \n                 color_discrete_sequence = px.colors.qualitative.Dark2)\n    fig.update_layout(title=col, \n                      xaxis_title=\"\", yaxis_title=\"\", \n                      yaxis_categoryorder = 'total ascending',\n                      uniformtext_minsize=8, uniformtext_mode='hide')\n    fig.show()\ncompar_wm('Case Fatality', 15)\ncompar_wm('Tests/1M pop', 15)\ncompar_wm('Tot Cases/1M pop', 15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> While Germany seem to have the highest case fatality rate among all three countries, it also does more tests than the others. Next we will use the average fatality rate of the world as a benchmark to estimate their real fatality rate. "},{"metadata":{"trusted":true},"cell_type":"code","source":"benchmark_countries = worldometer_data[worldometer_data[\"Case Positivity\"]<=0.01]\n# Assume that the number of confirmed cases are close to the true infections rates for countries with gold standard testing regimes \n# Thus, their case fatality rates are closer to the true infection fatality rates\ninfection_fatality_rate = benchmark_countries['TotalDeaths'].sum() / benchmark_countries['TotalCases'].sum()\n\n# Calculate the fraction of total Covid19 deaths for the population aged 65+ among the benchmark countries\nbenchmark_death_65y_pct = sum(benchmark_countries['TotalDeaths'] * benchmark_countries['Fraction age 65+ years']) / sum(benchmark_countries['TotalDeaths'])\n\nprint(infection_fatality_rate)\nprint(benchmark_death_65y_pct)\n\nprint('Estimated Infection Fatality Rate for a benchmark country with %.1f%s of population older than 65 years old \\\nis %.2f%s' %(100 * benchmark_death_65y_pct,'%',100 * infection_fatality_rate,'%'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Case Fatality Rate is positively correlated with the fraction of 65+ in the population. Here we calibrate each country's Infections Fatality Rate following the estimated fraction of total Covid19 deaths for the population aged 65+ (i.e., we expect the Infections Fatality Rate of a country with 20% estimated total Covid19 deaths among 65+ year old population to be twice higher than another country with 10%)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Estimate Infection Fatality Ratio using the estimated fraction of total Covid19 deaths for the population aged 65+\nworldometer_data['Estimated Infection Fatality Ratio'] \\\n    = ((worldometer_data['TotalDeaths'] * worldometer_data['Fraction age 65+ years']\n        /worldometer_data['TotalDeaths']) / benchmark_death_65y_pct) * infection_fatality_rate\n\n# Show descriptive statistics of the columns Estimated Infection Fatality Ratio and Case Fatality\nworldometer_data['Estimated Infection Fatality Ratio'].describe()\nworldometer_data['Case Fatality'].describe()\n\n# Plot histogram of Estimated Infection Fatality Ratio and Case Fatality\npx.histogram(worldometer_data, x='Estimated Infection Fatality Ratio', barmode=\"overlay\")\npx.histogram(worldometer_data, x='Case Fatality', barmode=\"overlay\")\n\n# Overlay both histograms for comparison\nfig = go.Figure()\n\nfig.add_trace(go.Histogram(x=worldometer_data['Estimated Infection Fatality Ratio'], \n    name = 'Estimated Infection Fatality Rate'\n))\n\nfig.add_trace(go.Histogram(x=worldometer_data['Case Fatality'], \n    name = 'Case Fatality Rate'\n))\n\nfig.update_layout(barmode='overlay', \n    title = 'Estimated Infection Fatality Rate vs. Case Fatality Rate',\n    xaxis_title_text='Value', # xaxis label\n    yaxis_title_text='Count', # yaxis label\n)\n                  \nfig.update_traces(opacity=0.75)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"worldometer_data['Estimated Infection Fatality Ratio'] \\\n    = ((worldometer_data['TotalDeaths'] * worldometer_data['Fraction age 65+ years']\n        /worldometer_data['TotalDeaths']) / benchmark_death_65y_pct) * infection_fatality_rate\ndef estim_wm(col):\n    \n    estimated_wm = worldometer_data[worldometer_data['Country/Region'].isin(['Turkey','France','Germany'])]\n\n    \n    fig = px.bar(estimated_wm,\n                 x=col, y=\"Country/Region\", color='WHO Region',  \n                 text=col, orientation='h', width=700, \n                 barmode='overlay')     \n    \n    fig.show()\n\nestim_wm('Estimated Infection Fatality Ratio')\nestim_wm('Case Fatality')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"subsection-three-two\"></a>\n# 3.2 Covid-19 cases by state\n> Based on the estimation, Germany does not have such a high fatality ratio as recorded. Next we will look at cases based on state, gender and age to see how it affects the deaths and cases in Germany."},{"metadata":{"trusted":true},"cell_type":"code","source":"states = ['Baden-Wuerttemberg','Bayern','Berlin','Brandenburg','Bremen',\n          'Hamburg','Hessen','Mecklenburg-Vorpommern','Niedersachsen','Nordrhein-Westfalen',\n          'Rheinland-Pfalz','Saarland','Sachsen','Sachsen-Anhalt','Schleswig-Holstein','Thueringen' ]\n\ntotalcases = state_cases_per_day.groupby('state')[['cases','deaths']].sum()\n#print(totalcases)\ngermanypop = germanypop.replace('female','F')\ngermanypop = germanypop.replace('male','M')\ntotalpop = germanypop.groupby('state').population.sum()\n\ncovid_per_state = pd.merge(totalcases, totalpop, on ='state', how='outer')\ncovid_per_state['cases_per_pop'] = covid_per_state['cases']/covid_per_state['population']\ncovid_per_state['deaths_per_pop'] = covid_per_state['deaths']/covid_per_state['population']\ncovid_per_state = pd.DataFrame(data = covid_per_state, columns = ['cases','deaths','population','cases_per_pop','deaths_per_pop'])\ncovid_per_state.reset_index(inplace=True)\n\n\nfig, ax = plt.subplots(2,2, figsize=(15, 15), facecolor='#f7f7f7')\nfig.subplots_adjust(top=0.92)\nfig.suptitle('Summary of cases by states', fontsize=18)\nfig.tight_layout(pad=15.0)\ncovid_per_state.set_index('state').cases.plot(kind='bar', ax=ax[0][0], color='gold')\ncovid_per_state.set_index('state').cases_per_pop.plot(kind='bar', ax=ax[0][1], color='green')\ncovid_per_state.set_index('state').deaths.plot(kind='bar', ax=ax[1][0], color='gold')\ncovid_per_state.set_index('state').deaths_per_pop.plot(kind='bar', ax=ax[1][1], color='green')\n\n\nax[0][0].set_title('Total Cases per state', fontsize=14)\nax[0][1].set_title('Positivity Rate (%)', fontsize=14)\nax[1][0].set_title('Total deaths', fontsize=14)\nax[1][1].set_title('Death Rate (%)', fontsize=14)\n#print(covid_per_state)\n\n\nfor axes in ax[0]:\n    axes.set_xlabel('')\n    axes.set_xticklabels(axes.get_xticklabels(), rotation=90)\n    axes.grid(axis='y')\n    axes.set_yticklabels(['{:,.1%}'.format(x) for x in axes.get_yticks()])\nfor axes in ax[1]:\n    axes.set_xlabel('')\n    axes.set_xticklabels(axes.get_xticklabels(), rotation=90)\n    axes.grid(axis='y')\n    axes.set_yticklabels(['{:,.1%}'.format(x) for x in axes.get_yticks()])\n\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> As you can see, the cases and deaths for Bayern and Nordrhein-Westfalen are actually very high, however, after scaling to population sizes, it remains at less than 0.01% of cases for the population, and less than 0.00025% death rate. Next we will examine the cases and deaths by age. "},{"metadata":{"trusted":true},"cell_type":"code","source":"germ_pop_sum=germanypop.groupby('age_group').population.sum()\ngerm_covid_sum=germany_cases_pop.groupby('age_group',as_index=False)[['new_cases','new_deaths']].sum()\ngerm_summary = pd.merge(germ_pop_sum,germ_covid_sum,on='age_group')\ngerm_summary['positivity_rate'] = germ_summary['new_cases'] / germ_summary['population']\ngerm_summary['death_rate'] = germ_summary['new_deaths'] / germ_summary['new_cases']\ngerm_summary['prop_positives'] = germ_summary['new_cases'] / germ_summary['new_cases'].sum()\ngerm_summary['prop_deaths'] = germ_summary['new_deaths'] / germ_summary['new_deaths'].sum()\nprint(germ_summary)\n\n\nfig, ax = plt.subplots(3,2, figsize=(15, 15), facecolor='#f7f7f7')\nfig.subplots_adjust(top=0.92)\nfig.suptitle('Summary of the situation in Germany (age)', fontsize=18)\n\ngerm_summary.set_index('age_group').new_cases.plot(kind='bar', ax=ax[0][0], color='gold')\ngerm_summary.set_index('age_group').new_deaths.plot(kind='bar', ax=ax[1][0], color='red')\ngerm_summary.set_index('age_group').positivity_rate.plot(kind='bar', ax=ax[0][1], color='gold')\ngerm_summary.set_index('age_group').death_rate.plot(kind='bar', ax=ax[1][1], color='red')\n\nax[2][0].pie(germ_summary.prop_positives.values, labels=germ_summary.age_group, autopct='%.0f%%')\nax[2][1].pie(germ_summary.prop_deaths.values, labels=germ_summary.age_group, autopct='%.0f%%')\n\nax[0][0].set_title('Total Cases', fontsize=14)\nax[1][0].set_title('Total Deceased', fontsize=14)\nax[0][1].set_title('Positivity Rate (%)', fontsize=14)\nax[1][1].set_title('Death Rate (%)', fontsize=14)\nax[2][0].set_title('Proportion of Positives', fontsize=14)\nax[2][1].set_title('Proportion of Victims', fontsize=14)\n\nfor axes in ax[0]:\n    axes.set_xlabel('')\n    axes.set_xticklabels(axes.get_xticklabels(), rotation=0)\n    axes.grid(axis='y')\nfor axes in ax[1]:\n    axes.set_xlabel('')\n    axes.set_xticklabels(axes.get_xticklabels(), rotation=0)\n    axes.grid(axis='y')\n    axes.set_yticklabels(['{:,.2%}'.format(x) for x in axes.get_yticks()])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Most cases are contacted by age 15-39, even if scaled to population percentages. This can be generally due to the fact most of the working forces are within that age range. However, most deaths are spread between age 60 and above, around nearly 90% of the deaths. "},{"metadata":{"trusted":true},"cell_type":"code","source":"germ_gender_sum=germanypop.groupby('gender').population.sum()\ngerm_covid_sum=germany_cases_pop.groupby('gender',as_index=False)[['new_cases','new_deaths']].sum()\ngerm_summary_2 = pd.merge(germ_gender_sum,germ_covid_sum,on='gender')\n#print(germ_summary_2)\ngerm_summary_2['positivity_rate'] = germ_summary_2['new_cases'] / germ_summary_2['population']\ngerm_summary_2['death_rate'] = germ_summary_2['new_deaths'] / germ_summary_2['new_cases']\ngerm_summary_2['prop_positives'] = germ_summary_2['new_cases'] / germ_summary_2['new_cases'].sum()\ngerm_summary_2['prop_deaths'] = germ_summary_2['new_deaths'] / germ_summary_2['new_deaths'].sum()\nprint(germ_summary_2)\n\n\nfig, ax = plt.subplots(3,2, figsize=(12, 12), facecolor='#f7f7f7')\nfig.subplots_adjust(top=0.92)\nfig.suptitle('Summary of the situation in Germany (gender)', fontsize=18)\n\ngerm_summary_2.set_index('gender').new_cases.plot(kind='bar', ax=ax[0][0], color='gold')\ngerm_summary_2.set_index('gender').new_deaths.plot(kind='bar', ax=ax[1][0], color='red')\ngerm_summary_2.set_index('gender').positivity_rate.plot(kind='bar', ax=ax[0][1], color='gold')\ngerm_summary_2.set_index('gender').death_rate.plot(kind='bar', ax=ax[1][1], color='red')\n\nax[2][0].pie(germ_summary_2.prop_positives.values, labels=germ_summary_2.gender, autopct='%.0f%%')\nax[2][1].pie(germ_summary_2.prop_deaths.values, labels=germ_summary_2.gender, autopct='%.0f%%')\n\nax[0][0].set_title('Total Cases', fontsize=14)\nax[1][0].set_title('Total Deceased', fontsize=14)\nax[0][1].set_title('Positivity Rate (%)', fontsize=14)\nax[1][1].set_title('Death Rate (%)', fontsize=14)\nax[2][0].set_title('Proportion of Positives', fontsize=14)\nax[2][1].set_title('Proportion of Victims', fontsize=14)\n\nfor axes in ax[0]:\n    axes.set_xlabel('')\n    axes.set_xticklabels(axes.get_xticklabels(), rotation=0)\n    axes.grid(axis='y')\nfor axes in ax[1]:\n    axes.set_xlabel('')\n    axes.set_xticklabels(axes.get_xticklabels(), rotation=0)\n    axes.grid(axis='y')\n    axes.set_yticklabels(['{:,.2%}'.format(x) for x in axes.get_yticks()])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Based on the graphs, both genders contact the virus at the same rate, however, males seem to have a higher death rate of 2.5% to 2%"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n# Any results you write to the current directory are saved as output.\npath_to_file_covid = '../input/covid19-tracking-germany/covid_de.csv'\npath_to_file_demo  = '../input/covid19-tracking-germany/demographics_de.csv'\npath_to_file_shape = '../input/covid19-tracking-germany/de_state.shp'\n\n#getting the data\ncovid_de  = pd.read_csv(path_to_file_covid, index_col=\"date\", parse_dates=True) #cases and deaths per state and age and sex\ndemo_de   = pd.read_csv(path_to_file_demo)    # demography file\nshape_de2 = gpd.read_file(path_to_file_shape) # geography file\n\n# replace Umlaute\nshape_tmp = shape_de2.replace({'Baden-Württemberg' : 'Baden-Wuerttemberg', 'Thüringen' : 'Thueringen' }).copy()\nshape_de = shape_tmp.rename(columns={'GEN': 'state'}).copy()\n\n# conversion factor for later\nm2tokm2 = 1/1000000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set the coordinate reference system (CRS) to EPSG 3035\n# Lambert Azimuthal Equal Area -> 3035\nshape_de.crs = {'init': 'epsg:3025'}\n# print(shape_de.geometry.crs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Population and population density"},{"metadata":{"trusted":true},"cell_type":"code","source":"norm_axis1 = 15e6\nnorm_axis2 = 4.1e3\n\n\n# map with population\ndef add_pop_state(state):\n    popu = demo_de[demo_de.state == state].population.sum()\n    #print(popu)\n    shape_de[shape_de.state == state].plot(figsize=(10,10),color= cm.Greens(popu/norm_axis1), edgecolor='gainsboro', zorder=3, ax =  ax1)\n\n#map with population density\n# for this get the area from the polygon, i.e. geometry\ndef get_area(state):   \n    return shape_de[shape_de.state == state].geometry.area\n\ndef add_dens_state(state):\n    dens  = demo_de[demo_de.state == state].population.sum()/float(get_area(state))/(m2tokm2)\n    #print(state , '----' , round((dens)/(m2tokm2),2), 'people/km**2')#properly normalised density people/km**2\n    shape_de[shape_de.state == state].plot(figsize=(10,10),color= cm.Greens(dens/norm_axis2), edgecolor='gainsboro', zorder=3, ax =  ax2)\n    \n    \nplt.figure() \n\n# Create a map\nax1 = plt.axes([0., 0., 1., 2.])\nshape_de['geometry'].plot(color='whitesmoke', edgecolor='gainsboro', zorder=3, ax = ax1)\nfor i in shape_de.state:\n    add_pop_state(i)\nax1.set_title('Population of the states', fontsize=20)\n\n# add colorbar\nfig = ax1.get_figure()\ncax = fig.add_axes([1.1, 0.0, 0.1, 2.0])\nnorm = mpl.colors.Normalize(vmin=0,vmax=norm_axis1)\nsm = plt.cm.ScalarMappable(norm = norm, cmap='Greens')\nsm._A = []\ncbar = fig.colorbar(sm, cax=cax , ax=ax1)\ncbar.ax.tick_params(labelsize=15)\n# Create a second map\nax2 = plt.axes([1.6, 0., 1., 2.])\nshape_de['geometry'].plot(figsize=(10,10),color='whitesmoke', edgecolor='gainsboro', zorder=3, ax = ax2)\nfor i in shape_de.state:\n    add_dens_state(i)\n    \n# add colorbar\nfig2 = ax2.get_figure()\ncax2 = fig.add_axes([2.8, 0.0, 0.1, 2.])\nnorm2 = mpl.colors.Normalize(vmin=0,vmax=norm_axis2)\nsm2 = plt.cm.ScalarMappable(norm=norm2,cmap='Greens')\nsm2._A = []\ncbar = fig.colorbar(sm2, cax=cax2)\ncbar.ax.tick_params(labelsize=15)\nax2.set_title('Population density of the states (ppl/sqkm)', fontsize=20)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here once can see, that the population is large in e.g. NRW, but the density is of course much higher in cities."},{"metadata":{},"cell_type":"markdown","source":"# Cases and deaths per state"},{"metadata":{"trusted":true},"cell_type":"code","source":"norm_axis1 = 90e3\nnorm_axis2 = 1800\n\ndef add_case_per_state(state):\n    case = covid_de.loc[covid_de['state'] == state ].cases.sum()\n    #print(case)\n    shape_de[shape_de.state == state].plot(figsize=(10,10), color= cm.Blues(case/norm_axis1), edgecolor='gainsboro', zorder=3, ax =  ax1)\n\ndef add_death_per_state(state):\n    death = covid_de.loc[covid_de['state'] == state ].deaths.sum()\n    #print(death)\n    shape_de[shape_de.state == state].plot(figsize=(10,10), color= cm.YlOrRd(death/norm_axis2), edgecolor='gainsboro', zorder=3, ax = ax2)\n\nplt.figure() \n\n# Create a map\nax1 = plt.axes([0., 0., 1., 2.])\nshape_de['geometry'].plot(color='whitesmoke', edgecolor='gainsboro', zorder=3, ax = ax1)\nfor i in shape_de.state:\n    add_case_per_state(i)\nax1.set_title('Cases per state', fontsize=20)\n\n# add colorbar\nfig = ax1.get_figure()\ncax = fig.add_axes([1.1, 0.0, 0.1, 2.0])\nnorm = mpl.colors.Normalize(vmin=0,vmax=norm_axis1)\nsm = plt.cm.ScalarMappable(norm = norm, cmap='Blues')\nsm._A = []\ncbar = fig.colorbar(sm, cax=cax , ax=ax1)\ncbar.ax.tick_params(labelsize=15)\n# Create a second map\nax2 = plt.axes([1.6, 0., 1., 2.])\nshape_de['geometry'].plot(figsize=(10,10),color='whitesmoke', edgecolor='gainsboro', zorder=3, ax = ax2)\nfor i in shape_de.state:\n    add_death_per_state(i)\n    \n# add colorbar\nfig2 = ax2.get_figure()\ncax2 = fig.add_axes([2.8, 0.0, 0.1, 2.])\nnorm2 = mpl.colors.Normalize(vmin=0,vmax=norm_axis2)\nsm2 = plt.cm.ScalarMappable(norm=norm2,cmap='YlOrRd')\nsm2._A = []\ncbar = fig.colorbar(sm2, cax=cax2)\ncbar.ax.tick_params(labelsize=15)\nax2.set_title('Deaths per state', fontsize=20)\n\nplt.show()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cases and deaths do mainly occur in highly populated states. In the following, on can check the normalisation per population and population density. Interesting is also that the eastern part of Germany is much less affected than the eastern part."},{"metadata":{},"cell_type":"markdown","source":"# Cases normalised to population"},{"metadata":{"trusted":true},"cell_type":"code","source":"norm_axis1 = 0.012\nnorm_axis2 = 1e9\n\n\ndef add_case_per_pop_state(state):\n    case_norm = covid_de.loc[covid_de['state'] == state ].cases.sum() / demo_de[demo_de.state == state].population.sum()\n    #print(case_norm)\n    shape_de[shape_de.state == state].plot(figsize=(10,10), color= cm.Blues(case_norm/norm_axis1), edgecolor='gainsboro', zorder=3, ax =  ax1)\n\ndef get_area(state):   \n    return shape_de[shape_de.state == state].geometry.area\n    \ndef add_case_per_dens_state(state):\n    case_dens = covid_de.loc[covid_de['state'] == state ].cases.sum() / (demo_de[demo_de.state == state].population.sum()/float(get_area(state)))\n    #print(case_dens)\n    shape_de[shape_de.state == state].plot(figsize=(10,10), color= cm.Blues(case_dens/norm_axis2), edgecolor='gainsboro', zorder=3, ax =  ax2)\n\n    \n\nplt.figure() \n\n# Create a map\nax1 = plt.axes([0., 0., 1., 2.])\nshape_de['geometry'].plot(color='whitesmoke', edgecolor='gainsboro', zorder=3, ax = ax1)\nfor i in shape_de.state:\n    add_case_per_pop_state(i)\nax1.set_title('Cases per state per population', fontsize=20)\n\n# add colorbar\nfig = ax1.get_figure()\ncax = fig.add_axes([1.1, 0.0, 0.1, 2.0])\nnorm = mpl.colors.Normalize(vmin=0,vmax=norm_axis1)\nsm = plt.cm.ScalarMappable(norm = norm, cmap='Blues')\nsm._A = []\ncbar = fig.colorbar(sm, cax=cax , ax=ax1)\ncbar.ax.tick_params(labelsize=15)\n# Create a second map\nax2 = plt.axes([1.6, 0., 1., 2.])\nshape_de['geometry'].plot(figsize=(10,10),color='whitesmoke', edgecolor='gainsboro', zorder=3, ax = ax2)\nfor i in shape_de.state:\n    add_case_per_dens_state(i)\n    \n# add colorbar\nfig2 = ax2.get_figure()\ncax2 = fig.add_axes([2.8, 0.0, 0.1, 2.])\nnorm2 = mpl.colors.Normalize(vmin=0,vmax=norm_axis2)\nsm2 = plt.cm.ScalarMappable(norm=norm2,cmap='Blues')\nsm2._A = []\ncbar = fig.colorbar(sm2, cax=cax2)\ncbar.ax.tick_params(labelsize=15)\nax2.set_title('Cases per state per population density', fontsize=20)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When dividing by the population (left side), one can see that mainly the south has many cases. When normalising by the population density of the state, Bavaria is leading. this is probably due to the fact that the area is rather large compared to the other states. "},{"metadata":{},"cell_type":"markdown","source":"<a id=\"subsection-three-three\"></a>\n# 3.3 Impact of state cases on stocks performance\n> https://www.listenchampion.de/2019/03/23/die-10-groessten-unternehmen-in-bayern-unsere-liste-2019/\nMany companies have set-up physical production plants and retail stores in different states in Germany. Due to the lockdown in the states, these companies might suffer a larger loss than others. We will take a closer look at some examples of stocks that are located in Bavern, one of the states that is hugely populated and is going into a second lockdown. "},{"metadata":{"trusted":true},"cell_type":"code","source":"\nSiemens = yf.download(\"SIEGY\",start = \"2019-11-01\", end = \"2020-11-01\")\nSiemens = Siemens[\"Adj Close\"]\nSiemens = pd.DataFrame(Siemens)\nSiemens.columns = ['Adj_Close']\n\nAdidas = yf.download(\"ADDYY\",start = \"2019-11-01\", end = \"2020-11-01\")\nAdidas = Adidas[\"Adj Close\"]\nAdidas = pd.DataFrame(Adidas)\nAdidas.columns = ['Adj_Close']\n\nBMW = yf.download(\"BMW.DE\",start = \"2019-11-01\", end = \"2020-11-01\")\nBMW = BMW[\"Adj Close\"]\nBMW = pd.DataFrame(BMW)\nBMW.columns = ['Adj_Close']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(3,1, figsize=(15, 15), facecolor='#f7f7f7')\n\n\nfig.subplots_adjust(top=0.92)\nfig.suptitle('Companies in Bayern', fontsize=18)\nfig.tight_layout(pad=8.0)\n\nSiemens.Adj_Close.plot(kind='line', ax=ax[0], color='red')\nAdidas.Adj_Close.plot(kind='line', ax=ax[1], color='red')\nBMW.Adj_Close.plot(kind='line',ax=ax[2], color ='red')\n\n\n\nax[0].set_title('Siemens', fontsize=14)\nax[1].set_title('Adidas', fontsize=14)\nax[2].set_title('BMW', fontsize=14)\n\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> All three companies suffered a dip in prices during march, and have a slow climb back in prices. In November, during the second wave, prices continue to drop. We believe there is a negative correlation between growth in new confirmed cases as well as stock prices. Therefore, we will try to avoid stocks with physical production in Germany states in our portfolio selection. "},{"metadata":{},"cell_type":"markdown","source":"<a id=\"subsection-three-four\"></a>\n# 3.4 Predicting future Covid-19 patterns"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_germany(df,date): \n    \n    df['recent_wave'] = np.where(df['Date'] >= date,1,0)\n    fig = px.line(df, x='Date', y='Total Confirmed', color='recent_wave',\\\n                  title = 'Infections', height=600)      \n    fig.show()\n    \n    fig = px.line(df, x='Date', y='Total Recovered', color='recent_wave', \\\n              title = 'Recovered Patients ', height=600)      \n    fig.show()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_germany(germanycountry,'2020-10-01')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will use the month of october as our recent wave, and predict a SIR model based on it"},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\nfrom statsmodels.formula.api import ols\nimport statsmodels.graphics.api as smg\nfrom datetime import datetime, date, timedelta","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def estimate_sir_param_germany(df,date):\n    \n    # Assume everyone is at risk\n    # Identify the maximum population and the latest date in the time series for the country\n    population = pd.read_csv('../input/covid19-tracking-germany/demographics_de.csv')\n    population['Total population']  = population['population'].cumsum()\n    population = population['Total population'].max()\n    \n    #latest_date = datetime.strptime(df[\"Date\"].max(), '%Y-%m-%d')\n    latest_date = df[\"Date\"].max()\n    time_series_length = (latest_date - datetime.strptime(date,'%Y-%m-%d')).days + 1\n\n    \n    df['recent_wave'] = np.where(df['Date'] >= date,1,0)\n    \n    # Initialize Numpy arrays for total population (the maximum population), \n    # susceptible population (empty), and change in time (i.e., 1 day)\n    N  = np.array([population] * time_series_length)\n    S  = np.array([])\n    dt = np.array([1] * (time_series_length-1))\n\n    # Apply the condition N = S+I+(R+D)\n    # Filter time-series to those of the recent wave\n    I = np.array(df[df['recent_wave']==1]['Total Active'])\n    R = np.array(df[df['recent_wave']==1]['Total Recovered'])\n    D = np.array(df[df['recent_wave']==1]['Total Deaths'])\n\n    # R includes both Recovered and Death for brevity\n    S = N - I - (R + D)\n\n    ## 1. Estimate beta\n    \n    x = (S * I) / N\n    \n    # Copy all elements except the last\n    x = x[:-1].copy()\n    \n    # Take the first difference\n    dS = np.diff(S)\n    y = dS/dt\n\n    # Fit into a linear regression\n    results = sm.OLS(y, x, missing='drop').fit()\n    beta = results.params\n    print(results.summary())\n    print('\\n')\n    print('*'*80)\n    print(f\"Transmission rate or Beta is: {beta}\")\n    print('*'*80)\n    \n    ## 2. Estimate gamma\n    \n    x = I[:-1].copy()\n    dR = np.diff(R+D)\n    y = dR/dt\n\n    results = sm.OLS(endog=y, exog=x, missing='drop').fit()\n    gamma = results.params\n    print (results.summary())\n    print('\\n')\n    print('*'*80)\n    print(f\"Recovery (and Mortality) rate or Gamma is: {gamma}\")\n    print('*'*80)\n    \n    #3. Calculate R\n\n    print('\\n')\n    print('*'*80)\n    print(f\"Reproduction number or R is: {-beta/gamma}\")\n    print('*'*80)\n    \n    \n    return -beta.astype('float'), gamma.astype('float'), datetime.strptime(date,'%Y-%m-%d').date()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"estimate_sir_param_germany(germanycountry,'2020-10-01')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sir_model_betalist(I0 = 0.01, betalist = [0.5,0.8], gammalist = [0.15,0.25,0.5], days = 365):\n    \"\"\"\n    Function takes Initial Infected Population(I0), list of transmission rates (betalist)\n    and list of recovery rates(gammalist) as arguments.\n    Plots Infectious population and Infected Population vs time for input parameters\n    \"\"\"\n    \n    for gamma in gammalist:\n        \n        # A. Plot Infectious Population\n        plt.figure(figsize=(10,6))\n        sns.set(style=\"darkgrid\")\n        plt.title(\"SIR Model: Infectious Population\", fontsize=18)\n        \n        # Initialize model parameters\n        for beta in betalist:\n            N=1\n            I=I0\n            S=N-I\n            gamma=gamma\n            R=beta/gamma\n            \n            # Initialize empty lists\n            inf=[]\n            day=[]\n            \n            # Project into the future\n            for i in range(days):\n                day.append(i)\n                inf.append(I)\n                new_inf= I*S*beta\n                new_rec= I*gamma\n                I=I+new_inf-new_rec\n                S=S-new_inf\n            \n            # Create plot objects by gamma and beta\n            inf_max=round(np.array(inf).max()*100,1)\n            sns.lineplot(day,inf, label=f\"Beta: {beta} Gamma: {gamma} R0: {round(R,2)} Peak: {inf_max}%\")\n            plt.legend()\n            \n        # Show all plots objects\n        plt.show()\n        \n        # B. Plot Total Infected Population\n        plt.figure(figsize=(10,6))\n        plt.title(\"SIR Model: Total Confirmed Cases\", fontsize=18)       \n        \n        # Initialize model parameters\n        for beta in betalist:\n            N=1\n            I=I0\n            S=N-I\n            C=I\n            gamma=gamma\n            R=beta/gamma\n            \n            # Initialize empty lists\n            day=[]\n            conf=[]\n\n            # Project into the future            \n            for i in range(days):\n                day.append(i)\n                conf.append(C)\n\n                new_inf= I*S*beta\n                new_rec= I*gamma\n                I=I+new_inf-new_rec\n                S=S-new_inf\n                C=C+new_inf\n\n            # Create plot objects by gamma and beta\n            conf_max=round(np.array(conf).max()*100,1)\n            sns.lineplot(day,conf, label=f\"Beta: {beta} Gamma: {gamma} R0: {round(R,2)} Total :{conf_max}%\")\n            plt.legend()\n            \n        # Show all plots objects            \n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sir_model_betalist(I0=0.034,betalist=[0.11294725], gammalist=[0.0447071])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sir_model(I0=0.01, beta=0.6, gamma=0.1, days=365, date=date.today()):\n    \"\"\"\n    Function will take in initial state for infected population,\n    Transmission rate (beta) and recovery rate(gamma) as input.\n    \n    The function returns the maximum percentage of infectious population,\n    the number of days to reach the maximum (inflection point),\n    the maximum percentage of population infected,\n    the number of days to reach 80% of the maximum percentage of population infected.\n    \n    \"\"\"\n    ## Initialize model parameters\n    N = 1          #Total population in percentage, i.e., 1 = 100%\n    I = I0         #Initial state of I default value 1% of population, i.e., I0 = 0.01\n    S = N - I      #Initial state of S\n    R = 0          #Initial State of R\n    C = I          #Initial State of Total Cases\n    beta  = beta   #Transmission Rate\n    gamma = gamma  #Recovery Rate\n\n    ## Initialize empty lists\n    inf  = []       # List of Infectious population for each day\n    day  = []       # Time period in day\n    suc  = []       # List of Susceptible population for each day\n    rec  = []       # List of Recovered population for each day\n    conf = []       # List of Total Cases population for each day\n    \n    ## Project into the future\n    for i in range(days):\n        day.append(i)\n        inf.append(I)\n        suc.append(S)\n        rec.append(R)\n        conf.append(C)\n\n        new_inf= I*S*beta/N            #New infections equation (1)   \n        new_rec= I*gamma               #New Recoveries equation (2)\n        \n        I=I+new_inf-new_rec            #Total infectious population for next day\n        S=max(min(S - new_inf, N), 0)  #Total infectious population for next day\n        R=min(R + new_rec, N)          #Total recovered population for next day\n        \n        C=C+new_inf                    #Total confirmed cases for next day\n\n    ## Pinpoint important milestones    \n    max_inf = round(np.array(inf).max()*100,2)        #Peak infectious population in percentage\n    inflection_day = inf.index(np.array(inf).max())   #Peak infectious population in days\n    max_conf = round(np.array(conf).max()*100,2)      #Overall infected population in percentage\n    plateau_day = np.array(np.where(np.array(conf) >= 0.8*np.array(conf).max())).min()   #Peak infectious population in days\n        \n    print(f\"Maximum Infectious population at a time :{max_inf}%\")\n    print(f\"Number of Days to Reach Maximum Infectious Population (Inflection Point):{inflection_day} days or {date + timedelta(days=inflection_day)}\")\n    print(f\"Total Infected population :{max_conf}%\")\n    print(f\"Number of Days to Reach 80% of the Projected Confirmed Cases (Plateau Point):{plateau_day} days or {date + timedelta(days=plateau_day.item())}\")\n\n    ## Visualize the model outputs\n    sns.set(style=\"darkgrid\")\n    plt.figure(figsize=(10,6))\n    plt.title(f\"SIR Model: R = {round(beta/gamma,2)}\", fontsize=18)\n    sns.lineplot(day,inf, label=\"Infectious\")\n    sns.lineplot(day,suc,label=\"Succeptible\")\n    sns.lineplot(day,rec, label=\"Recovered\")\n    \n    plt.legend()\n    plt.xlabel(\"Time (in days)\")\n    plt.ylabel(\"Fraction of Population\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sir_model(I0=0.034,beta=0.11294725, gamma=0.0447071, days=730)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> This is an extremely high infected population and it is under the assumption that intervention is unsuccessful or failed. "},{"metadata":{},"cell_type":"markdown","source":"<a id=\"subsection-four\"></a>\n# 4. Stock analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"germanystock = pd.DataFrame()\ngermanystock = yf.download(\"EWG\",start = \"2019-11-01\", end = \"2020-11-01\")\ngermanystock = germanystock[\"Adj Close\"]\ngermanystock = pd.DataFrame(germanystock)\ngermanystock.columns = ['Adj Close']\n\nplt.plot(germanystock[\"Adj Close\"],label = \"EWG\")\nplt.title(\"Portfolio Adj.Close Price History\")\nplt.xlabel('Date')\nplt.ylabel('Adj. Price ')\nplt.legend(germanystock.columns.values,loc = 'upper left')\nplt.show()\nprint('Volatility: ' + str(germanystock[\"Adj Close\"].std()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\"EWG suffered a huge loss in march after their spike in covid cases. We expect a huge drop in november as well due to the second spike in covid cases in germany. As a result, we hope to diversify into four different areas.\n\n1. Countries with similar correlation, but no spike in cases \n2. Stocks/Funds/Bonds with low correlation with EWG\n3. Stocks/Funds/Bonds with high negative correlation \n4. Stocks/Funds/Bonds from Germany that is doing well despite in spike of Covid cases"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"subsection-four-one\"></a>\n# 4.1 Stock selection"},{"metadata":{},"cell_type":"markdown","source":"\n1. 3690 HK Meituan an investment holding company, provides an e-commerce platform that uses technology to connect consumers and merchants\n2. ZM Zoom Doing well, especially in the covid-19 crisis, e-conferencing stock that is used worldwide\n3. APX.AX  Appen Limited, together with its subsidiaries, provides data solutions and services for machine learning and artificial intelligence application\n4. BNTX Germany stock doing biotech and vaccine for covid, news on vaccine development likely to drive prices even higher\n5. DSD.PA The SHORTDAX X2 INDEX is linked to the performance of the DAX Index in an inverse way\n6. DWNI.DE Deutsche Wohnen SE is a German property company. Housing prices and rental remain one of the most resilient market in Germany\n7. IEF The fund generally invests at least 90% of its assets in the bonds of the underlying index and at least 95% of its assets in U.S. government bonds. Safe protection from negative runs\n8. LEG.DE Germany stock LEG Immobilien AG is a German property company, similar to DWNI\n9. SPTI The index is designed to measure the performance of intermediate term (3-10 years) public obligations of the U.S. Treasury.\n10. Tencent Limited Chinese multinational technology conglomerate holding company.\n"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"subsection-four-one-one\"></a>\n# 4.1.1 Bear ETF and Treasury ETF\n\n1. Lyxor Daily ShortDAX x2 UCITS ETF Acc\n2. SPDR Portfolio Intermediate Term Treasury ETF\n3. iShares 7-10 Year Treasury Bond ETF\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nSPTI = yf.download(\"SPTI\",start = \"2019-11-01\", end = \"2020-11-01\")\nSPTI = SPTI[\"Adj Close\"]\nSPTI = pd.DataFrame(SPTI)\nSPTI.columns = ['Adj_Close']\n\nShort_Dax = yf.download(\"DSD.PA\",start = \"2019-11-01\", end = \"2020-11-01\")\nShort_Dax = Short_Dax[\"Adj Close\"]\nShort_Dax = pd.DataFrame(Short_Dax)\nShort_Dax.columns = ['Adj_Close']\n\nIEF = yf.download(\"IEF\",start = \"2019-11-01\", end = \"2020-11-01\")\nIEF = IEF[\"Adj Close\"]\nIEF = pd.DataFrame(IEF)\nIEF.columns = ['Adj_Close']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(3,1, figsize=(15, 15), facecolor='#f7f7f7')\n\n\nfig.subplots_adjust(top=0.92)\nfig.suptitle('Safety Stocks', fontsize=18)\nfig.tight_layout(pad=8.0)\n\nShort_Dax.Adj_Close.plot(kind='line', ax=ax[0], color='gold')\nSPTI.Adj_Close.plot(kind='line', ax=ax[1], color='green')\nIEF.Adj_Close.plot(kind='line',ax=ax[2], color ='red')\n\n\n\nax[0].set_title('Short_DAX', fontsize=14)\nax[1].set_title('SPTI', fontsize=14)\nax[2].set_title('IEF', fontsize=14)\n\n\n\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These 3 bonds/stocks experienced sharp growth in March 2020. While Short_DAX returned to its normal range, a sharp spike in cases should result in sharp growth in November/December 2020. "},{"metadata":{},"cell_type":"markdown","source":"<a id=\"subsection-four-one-two\"></a>\n# 4.1.2 Technology stocks\n\n1. Zoom\n2. Tencent\n3. Appen\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"Tencent = yf.download(\"0700.HK\",start = \"2019-11-01\", end = \"2020-11-01\")\nTencent = Tencent[\"Adj Close\"]\nTencent = pd.DataFrame(Tencent)\nTencent.columns = ['Adj_Close']\n\nAPX = yf.download(\"APX.AX\",start = \"2019-11-01\", end = \"2020-11-01\")\nAPX = APX[\"Adj Close\"]\nAPX = pd.DataFrame(APX)\nAPX.columns = ['Adj_Close']\n\nZoom = yf.download(\"ZM\",start = \"2019-11-01\", end = \"2020-11-01\")\nZoom = Zoom[\"Adj Close\"]\nZoom = pd.DataFrame(Zoom)\nZoom.columns = ['Adj_Close']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(3,1, figsize=(15, 15), facecolor='#f7f7f7')\n\n\nfig.subplots_adjust(top=0.92)\nfig.suptitle('Technology Stocks', fontsize=18)\nfig.tight_layout(pad=8.0)\n\nTencent.Adj_Close.plot(kind='line', ax=ax[0], color='gold')\nAPX.Adj_Close.plot(kind='line', ax=ax[1], color='green')\nZoom.Adj_Close.plot(kind='line',ax=ax[2], color ='red')\n\n\n\nax[0].set_title('Tencent', fontsize=14)\nax[1].set_title('Appen', fontsize=14)\nax[2].set_title('Zoom', fontsize=14)\n\n\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These 3 technology stocks have shown steady growth from March onwards. Under our assumption of further lockdowns in the next year, reliance on online communication will be higher than before. Appen is also positively correlated to Germany market index, but since it is based on Australia, a relatively Covid-19 unaffected country, we expect a lower dip in future due to rise in cases. "},{"metadata":{},"cell_type":"markdown","source":"<a id=\"subsection-four-one-two\"></a>\n# 4.1.3 Consumer Cylical stocks\n\n1. Meituan\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"Meituan = yf.download(\"3690.HK\",start = \"2019-11-01\", end = \"2020-11-01\")\nMeituan = Meituan[\"Adj Close\"]\nMeituan = pd.DataFrame(Meituan)\nMeituan.columns = ['Adj_Close']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15, 7), facecolor='#f7f7f7')\nfig.subplots_adjust(top=0.92)\nfig.suptitle('Consumer Cyclical Stock', fontsize=18)\nfig.tight_layout(pad=8.0)\nMeituan.Adj_Close.plot(kind='line', color='gold')\nax.set_title('Meituan', fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> China has one of the best management of Covid-19 situation and the country is already preparing to open up for tourism and travel. Meituan is an excellent company that provide services between companies and consumers, and is expected to grow during the opening of China's economy"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"subsection-four-one-four\"></a>\n# 4.1.4 Real estate stocks\n\n1. Deutsche Wohnen\n2. LEG Immobilien AG"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nDWNI = yf.download(\"DWNI.DE\",start = \"2019-11-01\", end = \"2020-11-01\")\nDWNI = DWNI[\"Adj Close\"]\nDWNI = pd.DataFrame(DWNI)\nDWNI.columns = ['Adj_Close']\n\nLEG = yf.download(\"LEG.DE\",start = \"2019-11-01\", end = \"2020-11-01\")\nLEG = LEG[\"Adj Close\"]\nLEG = pd.DataFrame(LEG)\nLEG.columns = ['Adj_Close']\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(2,1, figsize=(15, 15), facecolor='#f7f7f7')\n\n\nfig.subplots_adjust(top=0.92)\nfig.suptitle('Real Estate Stocks', fontsize=18)\nfig.tight_layout(pad=8.0)\n\nDWNI.Adj_Close.plot(kind='line', ax=ax[0], color='gold')\nLEG.Adj_Close.plot(kind='line', ax=ax[1], color='green')\n\n\n\nax[0].set_title('DWNI', fontsize=14)\nax[1].set_title('LEG', fontsize=14)\n\n\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These 2 stocks have a high correlation with the germany stock market. LEG and DWNI are both real estate stocks, and they are expected to \nIn March 2020, they suffered a smaller dip in prices as compared to EWG and has since then recovered to a new high. In addition, many data shown the resilent nature of real estate stocks in downfall as their sales/rental prices continue to remain stable. \nhttps://www.globalpropertyguide.com/Europe/Germany/Price-History\nhttps://www.globalpropertyguide.com/news-germanys-house-price-rises-continue-to-accelerate-4096\nhttps://www.orrick.com/en/Insights/2020/08/Investments-in-Germany-under-COVID-19-Turning-a-Crisis-into-Opportunities"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"subsection-four-one-five\"></a>\n# 4.1.5 Healthcare stocks\n\n1. Biotech\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"Biotech = yf.download(\"BNTX\",start = \"2019-11-01\", end = \"2020-11-01\")\nBiotech = Biotech[\"Adj Close\"]\nBiotech = pd.DataFrame(Biotech)\nBiotech.columns = ['Adj_Close']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15, 7), facecolor='#f7f7f7')\nfig.subplots_adjust(top=0.92)\nfig.suptitle('Healthcare Stocks', fontsize=18)\nfig.tight_layout(pad=8.0)\nBiotech.Adj_Close.plot(kind='line', color='gold')\nax.set_title('BNTX', fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Biotech is one of the leading healthcare companies developing vaccines for Covid-19 and has reportedly partnered with Pfizer to develop a vaccine at 90% effectiveness. Their stock prices, once the vaccine is fully developed, is expected to skyrocket. \nhttps://www.bbc.com/pidgin/tori-54884656\nhttps://www.pfizer.com/news/press-release/press-release-detail/pfizer-and-biontech-announce-vaccine-candidate-against\nhttps://markteinblicke.de/157988/2020/09/biontech-erreicht-neuen-meilenstein/\nhttps://www.fool.com/investing/2020/10/20/3-critical-near-term-milestones-to-watch-with-pfiz/\nhttps://www.clinicaltrialsarena.com/news/pfizer-covid-vaccine-early-data/"},{"metadata":{"trusted":true},"cell_type":"code","source":"symbols_list = [\"BNTX\",\"EURUSD=X\"]\nstart = datetime(2019,11,1)\nend = datetime(2020,11,9)\ndata = yf.download(symbols_list, start=start, end=end)\ndf = data['Adj Close']\ndf =df.pct_change()[1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(18, 10))\nax.plot(df.index,df['BNTX'],'bo',)\nax.set_title('Vaccine Milestones')\nax.set_ylabel('Returns')\n\nax.annotate(\"90% effectiveness\",\n            xy=(pd.Timestamp('2020-11-9'), -0.01),\\\n            xytext=(pd.Timestamp('2020-10-01'), -0.3),\n            arrowprops={'arrowstyle': '->', 'lw': 1, 'color': 'black'},\n            va='center')\n\nax.annotate(\"Testing in Germany authorized\",\n            xy=(pd.Timestamp('2020-9-7'), 0.0251513),\\\n            xytext=(pd.Timestamp('2020-9-01'), 0.3),\n            arrowprops={'arrowstyle': '->', 'lw': 1, 'color': 'black'},\n            va='center')\n\nax.annotate(\"Data from Phase I/II\",\n            xy=(pd.Timestamp('2020-8-13'), 0.027348),\\\n            xytext=(pd.Timestamp('2020-8-01'), 0.6),\n            arrowprops={'arrowstyle': '->', 'lw': 1, 'color': 'black'},\n            va='center')\n\nax.annotate(\"Phase III clinical trial\",\n            xy=(pd.Timestamp('2020-7-27'), 0.028039),\\\n            xytext=(pd.Timestamp('2020-7-01'), -0.3),\n            arrowprops={'arrowstyle': '->', 'lw': 1, 'color': 'black'},\n            va='center')\n\nax.annotate(\"Announcement of Pfizer and BionTech collaboration\",\n            xy=(pd.Timestamp('2020-3-17'), 0.665),\\\n            xytext=(pd.Timestamp('2020-1-01'), 0.45),\n            arrowprops={'arrowstyle': '->', 'lw': 1, 'color': 'black'},\n            va='center')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> The scatter plot shows the return of BNTX throughout 2019 to 2020. Many key dates such as collaboration and testing phases are included in the plot above, and the 90% effectiveness news is expected to drive its price higher. "},{"metadata":{},"cell_type":"markdown","source":"<a id=\"subsection-five\"></a>\n# 5. Portfolio optimization"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"subsection-five-one\"></a>\n# 5.1 Stock correlation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot heatmap of the relationships across different sectors\ncomparisons = [\"0700.HK\", \"3690.HK\",\"ZM\",\"BNTX\",\"DSD.PA\",\"IEF\",\"SPTI\",\"DWNI.DE\",\"LEG.DE\",\"APX.AX\",\"EWG\"]\nstockStartDate= '2000-01-01'\nstockStartDate = datetime.strptime(stockStartDate,'%Y-%m-%d')\ntoday = datetime.today().strftime('%Y-%m-%d')\ndf = yf.download(comparisons, start=stockStartDate, end=today)\ndf = df['Adj Close']\nbaseline_corr = df[[\"0700.HK\", \"3690.HK\",\"ZM\",\"BNTX\",\"DSD.PA\",\"IEF\",\"SPTI\",\"DWNI.DE\",\"LEG.DE\",\"APX.AX\",\"EWG\"]].dropna().corr() # dropna() means drop the missing value\n# light color: strong correlation\n# dark: negative correlation\n# mirror image again\nfig, ax = plt.subplots(figsize=(20,10)) \nsns.heatmap(baseline_corr, annot=True, ax = ax)\n#df.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> The correlation remains positive for most stocks except the short index, designed to precisely hedge against fall in DAX, an index containing the top few companies in Germany. "},{"metadata":{"trusted":true},"cell_type":"code","source":"assets = [\"0700.HK\", \"3690.HK\",\"ZM\",\"BNTX\",\"DSD.PA\",\"IEF\",\"SPTI\",\"DWNI.DE\",\"LEG.DE\",\"APX.AX\"]\n\nstockStartDate= '2000-01-01'\nstockStartDate = datetime.strptime(stockStartDate,'%Y-%m-%d')\ntoday = datetime.today().strftime('%Y-%m-%d')\ndf = pd.DataFrame()\n\ndf = yf.download(assets, start=stockStartDate, end=today)\ndf = df['Adj Close']\ndf = df.drop(df.index[len(df) -1])\n#print(df)\n\n#for stock in assets:\n    #df[stock]= web.DataReader(stock,data_source='yahoo',start = stockStartDate, end = today )['Adj Close']\n#print(df)\n\n\nmy_stocks = df\nfor c in my_stocks.columns.values:\n    plt.plot(my_stocks[c],label = c)\nplt.title(\"Portfolio Adj.Close Price History\")\nplt.xlabel('Date')\nplt.ylabel('Adj. Price ')\nplt.legend(my_stocks.columns.values,loc = 'upper left')\nplt.show()\n\ne_r = df.resample('Y').last().pct_change().mean()\n#print(e_r)\ncov_matrix = df.pct_change().apply(lambda x: np.log(1+x)).cov()\n#print(cov_matrix)\nsd = df.pct_change().apply(lambda x: np.log(1+x)).std().apply(lambda x: x*np.sqrt(250))\n#print(sd)\nassets = pd.concat([e_r,sd],axis = 1)\nassets.columns = ['Returns','Volatility']\n#print(assets)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"subsection-five-two\"></a>\n# 5.2 Simulation of portfolio performance"},{"metadata":{"trusted":true},"cell_type":"code","source":"p_ret = []\np_vol = []\np_weights = []\n\nnum_assets = len(assets)\nnum_portfolios = 10000\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(42)\nfor portfolio in range(num_portfolios):\n    weights = np.random.random(num_assets)\n    weights = weights/np.sum(weights)\n    p_weights.append(weights)\n    \n    returns = np.dot(weights, e_r)\n    p_ret.append(returns)\n    \n    var = cov_matrix.mul(weights,axis=0).mul(weights,axis = 1).sum().sum()\n    sd = np.sqrt(var)\n    ann_sd = sd*np.sqrt(250)\n    p_vol.append(ann_sd)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = {'Returns':p_ret,'Volatility':p_vol}\nfor counter,symbol in enumerate(df.columns.tolist()):\n    data[symbol+ ' weightage'] = [w[counter] for w in p_weights]\nportfolios = pd.DataFrame(data)\nportfolios['Sharpe Ratio']= portfolios['Returns']/portfolios['Volatility']\n#print(portfolios.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,4))\nplt.scatter(portfolios['Volatility'],portfolios['Returns'], c = portfolios['Returns']/portfolios['Volatility'])\nplt.xlabel('Volatility')\nplt.ylabel('Returns')\nplt.colorbar(label= 'Sharpe Ratio')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Using 10000 simulations, we created a efficient frontier of portfolio return vs portfolio volaitility and used it to find the most suitable portfolio for investors"},{"metadata":{"trusted":true},"cell_type":"code","source":"min_variance = portfolios.iloc[portfolios['Volatility'].idxmin()]\nprint(min_variance)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimal_port = portfolios.iloc[portfolios['Sharpe Ratio'].idxmax()]\nprint(optimal_port)\noptimal_port = pd.DataFrame(optimal_port)\noptimal_port.columns = ['Values']\n\nweightage = optimal_port['Values'].tolist()\n\nindex = [0,1,12]\nfor x in sorted(index,reverse = True):\n    del weightage[x]\n#print(weightage)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> We decided to maximize our sharpe ratio for the portfolio to generate the best returns for investors"},{"metadata":{"trusted":true},"cell_type":"code","source":"port_return = pd.DataFrame()\n\nreturns = assets[\"Returns\"].to_list()\n#print(returns)\ntotal_return = [a * b for a,b in zip(weightage,returns)]\ntotal_return = sum(total_return)\n\nprint(total_return)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> The backtesting confirmed that the weightage used will generate the following returns for investors during 2019"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"subsection-five-three\"></a>\n# 5.3 Portfolio allocation"},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = [\"0700.HK\", \"3690.HK\",\"ZM\",\"BNTX\",\"DSD.PA\",\"IEF\",\"SPTI\",\"DWNI.DE\",\"LEG.DE\",\"APX.AX\"]\n#fig, ax = plt.subplots()\n#fig = plt.figure(figsize=(20,20))\n#ax.pie(data, explode=explode, labels=labels, autopct='%1.1f%%',\n        #shadow=True, startangle=90)\n#ax.axis('equal')\n\n#plt.show()\n\nportfolio_weights = DataFrame(dict( Weightage = weightage, tickets = labels)).reset_index()\n#print(portfolio_weights)\nportfolio_weights.plot(kind='pie',\n                            figsize=(15, 15),\n                            autopct='%1.1f%%', \n                            startangle=90,    \n                            shadow=True,       \n                            labels=None,                 # turn off labels on pie chart\n                            pctdistance=1.12,            # the ratio between the pie center and start of text label\n                            y ='Weightage')\nplt.legend(labels = portfolio_weights.tickets)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> The portfolio puts a high amount of weightage in Appen (21.1%), LEG Immobilien AG (20.2%), SPDR Portfolio Intermediate Term Treasury ETF (18.0%). To remain active in Germany, we will only sell a percentage of our previous portfolio to buy into this new portfolio of 10 stocks"},{"metadata":{"trusted":true},"cell_type":"code","source":"port_return = pd.DataFrame()\nreturns = my_stocks.pct_change()\n\nfor i in range(10):\n    port_return[i] = returns.iloc[:,i]*weightage[i]\n\n#print(port_return)\nport_return = port_return.dropna().sum(axis=1)\n#print(port_return)\n\nreturn_acc = 100\nlist_return = []\nfor i,j in enumerate(port_return.dropna()):\n    return_acc = return_acc * (1 + port_return.dropna().iloc[i])\n    list_return.append(return_acc)\n    \nportfolio_index = pd.DataFrame(data = list_return, index = port_return.dropna().index)\nportfolio_index.columns = ['Portfolio Index']\n\n\n\nstockStartDate= '2000-01-01'\nstockStartDate = datetime.strptime(stockStartDate,'%Y-%m-%d')\ntoday = datetime.today().strftime('%Y-%m-%d')\ndf = pd.DataFrame()\n\n\nEWG = yf.download('EWG', start=stockStartDate, end=today)\nEWG = EWG['Adj Close'].pct_change()[1:]\nEWG = pd.DataFrame(EWG).rename(columns={'Adj Close':'EWG'})\n\n\nport_return = port_return.dropna()\nport_return = pd.DataFrame(port_return)\n\n\nfinal_port = port_return.merge(EWG, on='Date',how='inner')\nfinal_port = final_port.rename(columns={0:'Portfolio'})\n\n\nfinal_port_return = pd.DataFrame()\nweights_2 = [0.20,0.75]\nfor i in range(2):\n    final_port_return[2] = final_port.iloc[:,i]*weights_2[i]\n\n\nfinal_port_return = final_port_return.dropna().sum(axis=1)\n\n\nreturn_acc = 100\nlist_return = []\nfor i,j in enumerate(final_port_return.dropna()):\n    return_acc = return_acc * (1 + port_return.dropna().iloc[i])\n    list_return.append(return_acc)\n    \nfinal_portfolio_index = pd.DataFrame(data = list_return, index = final_port_return.dropna().index)\nfinal_portfolio_index.columns = ['Portfolio Index']\n\n\nfig = px.line(final_portfolio_index, x = final_portfolio_index.index, y='Portfolio Index')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> While the graph seems to generate 150% returns and more, it is important to take note that these are due to extraordinary circumstances and it is not likely to last for a  long time. The portfolio selected is aimed to generate profits in the short term, where the cases in Germany continue to rise and lockdowns remain necessary. After the second wave passes, the portfolio must be reinvestigated and readjusted for better returns and risk management. \n\n> The weightage is only at 95% as 5% will be kept as cash. This will be used to take advantage of new opportunities once the second wave died down. "},{"metadata":{},"cell_type":"markdown","source":"<a id=\"subsection-five-four\"></a>\n# 5.4 Portfolio returns relationship to new cases"},{"metadata":{"trusted":true},"cell_type":"code","source":"baseline2020 = port_return[port_return.index >= '2020-01-01']\n\n\nbaseline2020 = pd.merge(baseline2020,germanycountry, how='left', on='Date')\nbaseline2020['New Cases'] = baseline2020['New Cases'].fillna(0)\nbaseline2020 = baseline2020.rename(columns={0:'Returns'})\n\n\nsns.jointplot(x = 'New Cases', y = 'Returns', data = baseline2020, kind='reg')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> There remains little to no correlation between new cases and returns of our portfolio, and we can conclude our portfolio will be able to perform irregardless of the cases in Germany"},{"metadata":{"trusted":true},"cell_type":"code","source":".\nfuture_days = 54\nfinal_portfolio_index['Prediction'] = final_portfolio_index[['Portfolio Index']].shift(-future_days)\n#print(final_portfolio_index)\nX = np.array(final_portfolio_index.drop(['Prediction'],1))[:-future_days]\n#print(X)\ny = np.array(final_portfolio_index['Prediction'])[:-future_days]\n#print(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_test,y_train,y_test = train_test_split(X,y, test_size = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree = DecisionTreeRegressor().fit(x_train,y_train)\nlr = LinearRegression().fit(x_train,y_train)\n\nx_future = final_portfolio_index.drop(['Prediction'],1)[:-future_days]\nx_future = np.array(x_future.tail(future_days))\n#print(final_portfolio_index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_prediction = tree.predict(x_future)\n#print(tree_prediction)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_prediction = lr.predict(x_future)\n#print(lr_prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = tree_prediction\nvalid = final_portfolio_index[X.shape[0]:]\nvalid['Predictions'] = predictions\nplt.figure(figsize=(16,8))\nplt.title('Model')\nplt.xlabel('Days')\nplt.ylabel('Close Price USD ($)')\nplt.plot(final_portfolio_index['Portfolio Index'])\nplt.plot(valid[['Portfolio Index','Predictions']])\nplt.legend(['Orig','Val','Pred'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = lr_prediction\nvalid = final_portfolio_index[X.shape[0]:]\nvalid['Predictions'] = predictions\nplt.figure(figsize=(16,8))\nplt.title('Model')\nplt.xlabel('Days')\nplt.ylabel('Close Price USD ($)')\nplt.plot(final_portfolio_index['Portfolio Index'])\nplt.plot(valid[['Portfolio Index','Predictions']])\nplt.legend(['Orig','Val','Pred'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"subsection-six\"></a>\n# 6.Conclusion\nWhile Germany successfully overcame the 1st wave, a lot of uncertainties are brought by the massive 2nd wave it is experiencing right now. And even though the German Government has provided rescue packages of a huge amount, the outlook remains pessimistic. No significant lowering of new cases can yet be seen in Germany and if this continues the German market is not going to perform well. While the portfolio generates an extraordinarily high return, it is developed in a way to hedge against uncertainty for a short time horizon of maximum of a year. Reallocation might be needed depending on the future state of Germany and the situation of the world also taking into consideration the possibility of the distribution of the vaccine.   "},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}