{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Scraping Debate Transcripts"},{"metadata":{"trusted":false},"cell_type":"code","source":"from bs4 import BeautifulSoup\n\nimport numpy as np\nimport pandas as pd\nimport re\nimport requests","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## List out links to the pages containing the transcripts\nThese transcripts have been created by *Rev: https://www.rev.com/*  \n**Disclaimer: I am not affiliated with this company and do not claim ownership of their data**"},{"metadata":{"trusted":false},"cell_type":"code","source":"# All Transcript Links\n\ntranscript_links = [\n    \"https://www.rev.com/blog/transcripts/new-hampshire-democratic-debate-transcript\",\n    \"https://www.rev.com/blog/transcripts/january-iowa-democratic-debate-transcript\",\n    \"https://www.rev.com/blog/transcripts/december-democratic-debate-transcript-sixth-debate-from-los-angeles\",\n    \"https://www.rev.com/blog/transcripts/november-democratic-debate-transcript-atlanta-debate-transcript\",\n    \"https://www.rev.com/blog/transcripts/october-democratic-debate-transcript-4th-debate-from-ohio\",\n    \"https://www.rev.com/blog/transcripts/democratic-debate-transcript-houston-september-12-2019\",\n    \"https://www.rev.com/blog/transcripts/transcript-of-july-democratic-debate-2nd-round-night-2-full-transcript-july-31-2019\",\n    \"https://www.rev.com/blog/transcripts/transcript-of-july-democratic-debate-night-1-full-transcript-july-30-2019\",\n    \"https://www.rev.com/blog/transcripts/transcript-from-night-2-of-the-2019-democratic-debates\",\n    \"https://www.rev.com/blog/transcripts/transcript-from-first-night-of-democratic-debates\"\n]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create function to extract needed info\nThey all have a similar structure, and most everything we need is found in a `p` tag called `fl-callout-text`.  "},{"metadata":{"trusted":false},"cell_type":"code","source":"# We'll be scraping some info from the structure\n# Speaker: (HH:MM:SS) Text here\n# Where the 'HH:' is optional\npatterns = {'speaker': '^[^\\(\\):\\[\\]]+:',\n            'time': '^\\((\\d{2}:)?\\d{2}:\\d{2}\\)'}\n\ndef get_transcript(transcript_link):\n    response = requests.get(transcript_link)\n    soup = BeautifulSoup(response.text, 'html.parser')\n    # Get the name of the debate\n    debate_name = soup.find('span', class_='fl-heading-text').text\n    # The main content\n    content = soup.find('div', class_='fl-callout-text')\n    # Keep a record of the current section\n    # By default, we call the section \"Entire Debate\"\n    section = 'Entire Debate'\n    data = []\n    for item in content:\n        # h2 or p\n        item_type = item.name\n        # h2 -> this is a section header\n        if item_type == 'h2':\n            section = item.text\n        # p -> this is some speech from a candidate/moderator\n        elif item_type == 'p':\n            # Hold all data for current item\n            item_data = {'debate': debate_name, 'section': section}\n            text = item.text\n            # for each pattern\n            for pattern_name, pattern in patterns.items():\n                # try to find the pattern\n                match_obj = re.match(pattern, text)\n                # if it exists, add it to `item_data` and lstrip from the string\n                if match_obj:\n                    match_str = match_obj.group(0)\n                    item_data[pattern_name] = match_str\n                    text = text.lstrip(match_str).strip()\n                # add the remaining text after the patterns have been removed\n                item_data['speech'] = text\n            data.append(item_data)\n    return data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Call this function for each link, and put all of the results in `df`"},{"metadata":{"trusted":false},"cell_type":"code","source":"transcript_data = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"for link in transcript_links:\n    transcript_data += get_transcript(link)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"df = pd.DataFrame(transcript_data)\n# From the patterns above, our speaker name has a ':', we'll strip that out\ndf['speaker'] = df.speaker.apply(lambda name: name.rstrip(':').strip() if not pd.isnull(name) else name)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Basic Initial Data Quality Check"},{"metadata":{"trusted":false},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Where are the missing speakers?\nIt looks like these are opening remarks or empty speech elements, so we can safely drop them"},{"metadata":{"trusted":false},"cell_type":"code","source":"df.loc[pd.isnull(df.speaker)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df = df.loc[~pd.isnull(df.speaker)].reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## We also had some missing values in `time`\nThese are all coming from `Transcript from Night 1 of the 2019 June Democratic Debates`.  \nUpon checking the link, the site did not post times for this debate"},{"metadata":{"trusted":false},"cell_type":"code","source":"df.loc[pd.isnull(df.time)].debate.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define Function to parse out times `(HH:MM:SS)` -> `n_seconds` (int)\nThese aren't very helpful - represent them in seconds instead"},{"metadata":{"trusted":false},"cell_type":"code","source":"def parse_time_seconds(time_string):\n    if time_string and ':' in time_string:\n        ord_time = time_string[1:-1].split(':')[::-1]\n        n_seconds = 0\n        for i, time_measurement in enumerate(ord_time):\n            n_seconds += int(time_measurement)*(60**i)\n        return n_seconds\n    return None","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Parse out these times as seconds, and estimate the Speaking Time\nThe times we get out of our `parse_time_seconds` are the number of seconds into the debate.  \nAs an example, `(01:05:20)` would mean that we are 1 hour, 5 minutes, and 20 seconds into the debate.  \nParsing this to seconds gives us `n_seconds = 3920`.  \nBut we need the amount each speaker spends speaking...Lets do that below"},{"metadata":{"trusted":false},"cell_type":"code","source":"# We group by debate and section, because for each section, the time resets. Sometimes,\n# The sections aren't labeled, and the time just resets...we'll deal with this.\nfor (debate, section), debate_section_df in df.groupby(by=['debate', 'section']):\n    \n    # Earlier, we noted that this debate has no times, we'll skip it\n    if debate != 'Transcript from Night 1 of the 2019 June Democratic Debates':\n        \n        # get the index of this debate section\n        index = debate_section_df.index\n        \n        # apply the function we created above\n        time_seconds = debate_section_df.time.apply(parse_time_seconds).values\n        df.loc[index, 'time_seconds'] = time_seconds\n        \n        # find the time diff, and append a `np.nan` to the end for the final speaking time.\n        # Unfortunately, we have no idea how long they're speaking for. It is always a\n        # Moderator's closing statements though, so it won't affect our analysis.\n        time_diff = time_seconds[1:]-time_seconds[:-1]\n        \n        # Above, we mentioned that sometimes sections aren't labeled...\n        # This means that sometimes the time in seconds just drops\n        # i.e. [... 3700 3800 25 70 ...]\n        # in terms of the `time_diff`, this results in the first number\n        # after the drop being negative...let's fix that\n        if (time_diff < 0).any():\n            \n            # break into sections\n            section_breaks = np.where(time_diff < 0)[0]+1\n            sections = np.split(index, section_breaks)\n            \n            # for each section, set it individually\n            for i, section in enumerate(sections):\n                df.loc[section, 'section'] = 'Part {}'.format(i+1)\n                time_seconds = df.loc[section, 'time_seconds'].values\n                time_diff = time_seconds[1:]-time_seconds[:-1]\n                total_speaking_time = np.concatenate([time_diff, np.array([np.nan])])\n                df.loc[section, 'total_speaking_time'] = total_speaking_time\n        else:\n            total_speaking_time = np.concatenate([time_diff, np.array([np.nan])])\n            df.loc[index, 'total_speaking_time'] = total_speaking_time","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Do some cleaning on the Speaker Names\nSometimes, the source is inconsistent on the speaker names...  \nThat's okay - we can make a quick mapping dictionary that clears up the inconsistencies"},{"metadata":{"trusted":false},"cell_type":"code","source":"mapping_dct = {'Abby P': 'Abby Phillips',\n               'Abby Phillip': 'Abby Phillips',\n               'Amna': 'Amna Nawaz',\n               'Amy Klobachar': 'Amy Klobuchar',\n               'Bennet': 'Michael Bennet',\n               'Bill De Blasio': 'Bill de Blasio',\n               'Brianne P': 'Brianne P.',\n               'David': 'David Muir',\n               'E. Warren': 'Elizabeth Warren',\n               'Elizabeth W': 'Elizabeth Warren',\n               'Elizabeth W.': 'Elizabeth Warren',\n               'Elizabeth Warre': 'Elizabeth Warren',\n               'George S': 'George S.',\n               'Gillibrand': 'Kirsten Gillibrand',\n               'Kirsten G.': 'Kirsten Gillibrand',\n               'Kristen Gillibr': 'Kirseten Gillibrand',\n               'John H': 'John H.',\n               'Jose': 'Jose D.B.',\n               'Jose D. B.': 'Jose D.B.',\n               'Judy': 'Judy Woodruff',\n               'Lindsey': 'Linsey Davis',\n               'M. Williamson': 'Marianne Williamson',\n               'Marianne W.': 'Marianne Williamson',\n               'Marianne Willia': 'Marianne Williamson',\n               'Mayor Buttigieg': 'Pete Buttigieg',\n               'Mayor de Blasio': 'Bill de Blasio',\n               'Ms. Williamson': 'Marianne Williamson',\n               'Savannah': 'Savannah G.',\n               'Savanagh G': 'Savannah G.',\n               'Sen Klobuchar': 'Amy Klobuchar',\n               'Senator Bennet': 'Michael Bennet',\n               'Senator Booker': 'Cory Booker',\n               'Senator Warren': 'Elizabeth Warren',\n               'Yamiche': 'Yamiche A.',\n               'Yang': 'Andrew Yang'}","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df['speaker'] = df.speaker.apply(lambda name: mapping_dct.get(name) if name in mapping_dct else name)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## `time` and `time_seconds` aren't so useful to me\nI'm more concerned about how much time each speaker spends speaking, which I'll rename to `speaking_time_seconds`"},{"metadata":{"trusted":false},"cell_type":"code","source":"df = df.drop(['time', 'time_seconds'], axis=1)\ndf.columns = ['debate_name', 'debate_section', 'speaker', 'speech', 'speaking_time_seconds']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df = df.loc[df.speech!='']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.to_csv('../data/debate_transcripts.csv', encoding='cp1252', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}