{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Importing and reading the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use('fivethirtyeight')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/heart-failure-clinical-data/heart_failure_clinical_records_dataset.csv',\n                 low_memory = False)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preliminary checks on the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All the columns are numerical"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data has no missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Grouping the columns into numerical and categorical columns\nnum_cols = ['age', 'creatinine_phosphokinase', 'ejection_fraction', 'platelets', 'serum_sodium','serum_creatinine', 'time']\n\n# categorical columns\ncat_cols =list( set(df.columns) - set(num_cols))\n\n# change the data types to categories\nfor col in cat_cols:\n    df[col] = df[col].astype('category')\n\n# Check the dtypes again\ndf.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualising the data"},{"metadata":{},"cell_type":"markdown","source":"## ..Visualising the continuous variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot histogram for age\ndf.age.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot histogram for platelets\ndf.platelets.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot histogram for serum sodium\ndf.serum_sodium.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot histogram for serum creatinine\ndf.serum_creatinine.plot.hist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ...Visualising the categorical variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.sex.value_counts(normalize=True).plot.bar(rot = 0, title = 'Sex');","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df.smoking.value_counts(normalize=True).plot.bar(rot=0, title = 'Smoking?');","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df.anaemia.value_counts(normalize=True).plot.bar(rot = 0, title = 'Has anaemia?');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ..Checking for quick associations between categorical features"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.DEATH_EVENT.value_counts(normalize=True).plot.bar(rot = 0,\n                                                     title = 'Death Event');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is a clear class imbalance in the target column(DEATH_EVENT).Clearly, majority of the patients did not die.\n\nThis will inturn affect the evaluation metrics of interest in machine learning"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(df.sex, df.DEATH_EVENT, normalize='index').plot.bar(rot = 0);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(df.high_blood_pressure,df.DEATH_EVENT, normalize='index').plot.bar(rot=0);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(df.anaemia,df.DEATH_EVENT,normalize='index').plot.bar(rot=0);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(df.diabetes,df.high_blood_pressure,normalize='all')#.plot.bar(rot=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The table above shows that only 37.5% of all the patients did not have any co-morbid condition. The majority had at least one of either high blood pressure or diabetes or both"},{"metadata":{},"cell_type":"markdown","source":"# Preparing data for ML"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Employ the minmax_scale on the continous variables\nfrom sklearn.preprocessing import minmax_scale\n\nfor col in num_cols:\n    df[col] = minmax_scale(df[col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preview changes in the df\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Splitting the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Split the data into features (X) and label (y)\nX = df.iloc[:, :-1]\ny  = df['DEATH_EVENT']\n\n# Split the data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 94)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Importing models"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import models and the cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model performance on cv_scores"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\n# Set random seed\nnp.random.seed(94)\n\n# A function to store the cross-validated scores on the training data\ndef model_metrics(models, X_train, y_train):\n    \n    # Create an empty dataframe to store the metrics for each model\n    metrics_df = pd.DataFrame()\n    \n    # Loop through each model\n    for name, model in models.items():\n        \n        # Compute and store cv_scores in a dictionary\n        metrics_dict = {'accuracy' : round(np.mean(cross_val_score(model, X_train, y_train)), 2),\n                        'precision' : round(np.mean(cross_val_score(model, X_train, y_train, scoring='precision')), 2),\n                        'recall' : round(np.mean(cross_val_score(model, X_train, y_train, scoring='recall')), 2),\n                        'f1' : round(np.mean(cross_val_score(model, X_train, y_train, scoring='f1')), 2)}\n        \n        # Add the scores to the dataframe\n        metrics_df[name] = metrics_dict.values()\n    \n    # Set the indices of the dataframe \n    metrics_df.index = metrics_dict.keys()\n    \n    return metrics_df","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# A dictionary to house the models\nmodels = {'Logistic Regression' : LogisticRegression(),\n          'Random Forest' : RandomForestClassifier()}\n\n# Apply the model_metrics function on the models\ncv_scores = model_metrics(models, X_train, y_train)\n\n# Visualise the metrics dataframe\ncv_scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the metrics from the cv_scores\ncv_scores.plot.bar(rot = 0, title = 'Plot of cross_val_scores on the training data');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Assessing models on the test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import evaluation metrics \nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n# np.random.seed(94)\n\n# An empty dataFrame to house the results\ntest_metrics = pd.DataFrame()\n\n# Loop through the models\nfor name, model in models.items():\n    # Fit the model\n    clf = model.fit(X_train, y_train)\n    \n    # Make predictions on the X_test\n    y_preds = clf.predict(X_test)\n    \n    # Evaluate the predictions\n    test_dict = {'accuracy' : accuracy_score(y_test, y_preds),\n                 'precision': precision_score(y_test, y_preds),\n                 'recall' : recall_score(y_test, y_preds),\n                 'f1' : f1_score(y_test, y_preds)}\n    \n    # Add the evaluation metrics to the dataframe (test_metrics)\n    test_metrics[name] = test_dict.values()\n\n# Set the indices of the dataframe\ntest_metrics.index = test_dict.keys()\n\n# View the test_metrics_df\ntest_metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the test_metrics dataframe\ntest_metrics.plot.bar(rot = 0, title = 'Evaluation metrics on the test set');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Summary ofthe models performaces\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}