{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\n\n# from IPython.core.interactiveshell import InteractiveShell \n# InteractiveShell.ast_node_interactivity = \"all\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#load data\ndf_train=pd.read_csv('/kaggle/input/mobile-price-classification/train.csv')\ndf_test=pd.read_csv('/kaggle/input/mobile-price-classification/test.csv')\ndf_train.info()\ndf_test.info()\n# all numeric columns\n# no null values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#cleaning\n\n# first check for duplicated rows and remove them for test and train separately \ndf_train.duplicated().any()\ndf_test.duplicated().any()\n# no duplicated rows \n\n# next for outliers to remove rows\nbox1=df_train.boxplot()\nbox2=df_test.boxplot()\nplt.setp(box1.get_xticklabels(), rotation=90)\nplt.setp(box2.get_xticklabels(), rotation=90)\ndf_train=df_train[(np.abs(stats.zscore(df_train))<3).all(axis=1)]\ndf_test=df_test[(np.abs(stats.zscore(df_test))<3).all(axis=1)]\n#removed outliers\nprint(\"train shape after outliers:\", np.shape(df_train))\nprint(\"test shape after outliers:\",np.shape(df_test))\n\n# Now it is safe to join train and test to form the main dataset\ntarget=df_train[\"price_range\"]\ndf_train=df_train.drop([\"price_range\"], axis=1)\ntest_id=df_test[\"id\"]\ndf_test=df_test.drop([\"id\"], axis=1)\ndf=pd.concat([df_train, df_test])\nprint(\"full data shape:\", np.shape(df))\n\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#visualization \n\ndf.hist(figsize=(20,20), xlabelsize=8, ylabelsize=8)\nplt.show()\ntarget.hist(figsize=(20,20), xlabelsize=8, ylabelsize=8)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr=df.corr()\nsns.heatmap(corr[(corr>=0.5) | (corr<=-0.5)], vmin=-1, vmax=1, annot=True, annot_kws={'fontsize':8})\n\ndf_copy=df.copy()\n# drop 4g/3g, fc/pc\ndf=df.drop([\"three_g\", \"fc\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.shape(df))\nX_train=df.iloc[:1988]\nX_test=df.iloc[1988:]\nprint(np.shape(X_train), np.shape(X_test))\n\n#model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n#create the train/test split\nx_train, x_test, y_train, y_test = train_test_split(X_train, target, test_size=0.3, random_state=1)\n#Create the model and train\nmodel = RandomForestClassifier(random_state=1)\nmodel.fit(x_train,y_train)\n#predict the results for test\ntest_pred = model.predict(x_test)\n#test the accuracy\nacc=accuracy_score(y_test, test_pred)\nprint(acc)\n\n# important features\nfeat_importances = pd.Series(model.feature_importances_, index=df.columns)\nfeat_importances.nlargest(7).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# improving model\n# 1 combine 4g/3g, fc/pc instead of discarding\nprint(np.shape(df_copy))\ndf_imp0=df_copy.copy()\ndf_imp0[\"g\"]=df_copy[\"three_g\"]+df_copy[\"four_g\"]\ndf_imp0=df_imp0.drop([\"three_g\", \"four_g\"], axis=1)\ndf_imp0[\"c\"]=df_copy[\"fc\"]+df_copy[\"pc\"]\ndf_imp0=df_imp0.drop([\"fc\", \"pc\"], axis=1)\n\nX_train=df_imp0.iloc[:1988]\nX_test=df_imp0.iloc[1988:]\nprint(np.shape(X_train), np.shape(X_test))\n\n#model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n#create the train/test split\nx_train, x_test, y_train, y_test = train_test_split(X_train, target, test_size=0.3, random_state=1)\n#Create the model and train\nmodel = RandomForestClassifier(random_state=1)\nmodel.fit(x_train,y_train)\n#predict the results for test\ntest_pred = model.predict(x_test)\n#test the accuracy\nacc=accuracy_score(y_test, test_pred)\nprint(acc)\n\n# important features\nfeat_importances = pd.Series(model.feature_importances_, index=df_imp0.columns)\nfeat_importances.nlargest(7).plot(kind='barh')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}