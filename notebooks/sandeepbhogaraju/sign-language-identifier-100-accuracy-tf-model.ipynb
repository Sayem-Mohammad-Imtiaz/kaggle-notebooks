{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ntrain_csv = pd.read_csv('/kaggle/input/sign-language-mnist/sign_mnist_train/sign_mnist_train.csv')\ntest_csv = pd.read_csv('/kaggle/input/sign-language-mnist/sign_mnist_test/sign_mnist_test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create X_train (images) and Y_train (labels)\n\nlabels = []\nimages = []\nfor row in train_csv.iterrows():\n    label = row[1][0]\n    image = np.array_split(row[1][1:],28)\n    labels.append(label)\n    images.append(image)\n\n#Get the number of unique classes\nnum_classes = len(np.unique(labels))\n\nlabels = np.array(labels)\nimages = np.array(images)\nprint(labels.shape)\nprint(images.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Expand dims for these 2 np arrays so that they can be set as input to TF model\nlabels = np.expand_dims(labels,axis=1)\nimages = np.expand_dims(images,axis=3)\nprint(labels.shape)\nprint(images.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create X_test (images) and Y_test (labels); we will also use this for Validation\n\nlabels_test = []\nimages_test = []\nfor row in test_csv.iterrows():\n    label = row[1][0]\n    image = np.array_split(row[1][1:],28)\n    labels_test.append(label)\n    images_test.append(image)\n\nlabels_test = np.array(labels_test)\nimages_test = np.array(images_test)\nprint(labels_test.shape)\nprint(images_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Expand dims for these 2 np arrays so that they can be set as input to TF model\nlabels_test = np.expand_dims(labels_test,axis=1)\nimages_test = np.expand_dims(images_test,axis=3)\nprint(labels_test.shape)\nprint(images_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Convert from str to FLoat\nX_train = images.astype(float)\nY_train = labels.astype(float)\nX_test = images_test.astype(float)\nY_test = labels_test.astype(float)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Split the training and test sets\nfrom sklearn.model_selection import train_test_split\nX_train, X_validate, Y_train, Y_validate = train_test_split(X_train, Y_train, test_size = 0.2, random_state = 12345)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape)\nprint(X_validate.shape)\nprint(X_test.shape)\nprint(Y_train.shape)\nprint(Y_validate.shape)\nprint(Y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create a Image Generator for X_train\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(rescale=1/255,rotation_range=45, width_shift_range=0.25,\n    height_shift_range=0.15,shear_range=0.15, zoom_range=0.2, fill_mode='nearest')\ntest_datagen = ImageDataGenerator(rescale=1/255)\nvalid_datagen = ImageDataGenerator(rescale=1/255)\ntrain_generator = train_datagen.flow(X_train, Y_train, batch_size=32)\ntest_generator =  test_datagen.flow(X_test,Y_test,batch_size=32)\nvalid_generator = valid_datagen.flow(X_validate,Y_validate,batch_size=32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Define and compile the TF Model\nimport tensorflow as tf\n\nmodel = tf.keras.Sequential(\n[\n    tf.keras.layers.Conv2D(16, (3,3), padding='same', activation=tf.nn.relu,\n                           input_shape=(28, 28, 1)),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    tf.keras.layers.Conv2D(32, (3,3), padding='same', activation=tf.nn.relu),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation=tf.nn.relu),\n    tf.keras.layers.MaxPooling2D((2,2)),\n     tf.keras.layers.Conv2D(128, (3,3), padding='same', activation=tf.nn.relu),\n    tf.keras.layers.MaxPooling2D((2,2)),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n    tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)\n])\n\n#!!!!! IF YOU USE ADAM , THE ACCURACY STAYS AT 0 , USE SGD OPTIMIZER !!!\nmodel.compile(optimizer='SGD',loss='categorical_crossentropy',metrics = ['accuracy'])\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_generator,\n                    epochs=500,\n                    validation_data=valid_generator,\n                    callbacks = [\n    tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10),\n    tf.keras.callbacks.ModelCheckpoint(filepath='/kaggle/working/',\n    monitor='val_accuracy',\n    save_best_only=True)\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the chart for accuracy and loss on both training and validation\n%matplotlib inline\nimport matplotlib.pyplot as plt\nacc = history.history['accuracy']# Your Code Here\nval_acc =history.history['val_accuracy'] # Your Code Here\nloss = history.history['loss']# Your Code Here\nval_loss = history.history['val_loss']# Your Code Here\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = model.evaluate(test_generator, verbose = 0) \nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}