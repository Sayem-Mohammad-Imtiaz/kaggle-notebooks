{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Loading data and taking a little look..."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"../input/brasilian-houses-to-rent/houses_to_rent_v2.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So city, floor, animal and furniture are categorical dtypes. We better transforme it to numeric types, in the future, before we apply some ML algorithm. But what are the unique values for that attributes?"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in ['city','floor','animal','furniture']:\n    print(col,':')\n    display(df[col].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Let's go to do some simple preprocessing. What about turning the floor attribute numeric, mapping the animal and furniture attributes to a numeric(bool) feature and dummify the city attribute?"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.floor = df.floor.replace('-',0).astype(int)\ndf['animal'] = df['animal'].map({'acept': 1, 'not acept': 0})\ndf['furniture'] = df['furniture'].map({'furnished': 1, 'not furnished': 0})\noriginalNumericColumns = df.select_dtypes(include=np.number).columns.tolist()\ndf = pd.get_dummies(df)\ndisplay(df.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What about the correlation for the numeric attributes?"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.heatmap(df[originalNumericColumns].corr(method='spearman'),annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seens that total and hoa are highly correlated."},{"metadata":{},"cell_type":"markdown","source":"And what about outliers?"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[originalNumericColumns].boxplot(figsize=(10,10), rot=90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seens that hoa,property tax and total contains very significant outliers.\n\nSo, let's go to boxploting removing outliers:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.boxplot(figsize=(10,10), rot=90, showfliers=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok. Let's go to create some ML model to predict the total value.\n\nFirst let's go to pre-processing the data...\n\nThen we are going to try expose what are the most important features (by RandomForestRegressor)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n# shuffling the data\ndf = df.sample(frac=1, random_state = 0).reset_index(drop=True)\n# removing outliers\nq_low = df.quantile(0.005)\nq_hi = df.quantile(0.995)\ndfsOutliers=[]\nfor col in df.columns:\n    if len(df[col].unique()) < 10: continue # only apply to really numeric attributes        \n    print('--------- ',col,' ---------')\n    print('Dataframe size before removing outliers rows: ',len(df))\n    dfsOutliers.append(df[(df[col] < q_low[col]) | (df[col] > q_hi[col])])\n    df = df[(df[col] >= q_low[col]) & (df[col] <= q_hi[col])]\n    print('Dataframe size after removing outliers rows: ',len(df))\n\ndfOutliers = pd.concat(dfsOutliers, ignore_index=True)\n\nXCols = list(df.columns)\nXCols = [x for x in XCols if x not in ['hoa (R$)','rent amount (R$)','property tax (R$)','fire insurance (R$)','total (R$)']]\nyCol = 'total (R$)'\nprint()\nprint('XCols: ',XCols)\nX = df[XCols].values\ny = df[yCol].values\nmodel = RandomForestRegressor(n_estimators=100, random_state=0)\nmodel.fit(X, y)\n\nfeats = {} # a dict to hold feature_name: feature_importance\nfor feature, importance in zip(XCols, model.feature_importances_):\n    feats[feature] = importance #add the name/value pair \n\nimportances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: model.criterion+'-importance'})\nimportances.sort_values(by=model.criterion+'-importance').plot(kind='bar', rot=90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's go take a look in some outliers:"},{"metadata":{"trusted":true},"cell_type":"code","source":"dfOutliers.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok, let's to dirty the hands and try some candidate model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"import collections\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import VotingRegressor\nfrom sklearn.model_selection import cross_val_score\n\nmodels = collections.OrderedDict()\nmodels['KNeighborsRegressor'] = KNeighborsRegressor(n_neighbors=20)\nmodels['LinearRegression'] = LinearRegression()\nmodels['RandomForestRegressor'] = RandomForestRegressor(n_estimators=200, random_state=0)\nmodels['GradientBoostingRegressor'] = GradientBoostingRegressor(n_estimators=200, random_state=0)\nmodels['VotingRegressor'] = VotingRegressor(estimators=[('gb', models['GradientBoostingRegressor']), ('rf', models['RandomForestRegressor']), ('lr', models['LinearRegression'])])\ncv = 10\nfor kModel in models:    \n    print('--------- ',kModel,' ---------')\n    model = models[kModel]\n    scores = cross_val_score(model, X, y, cv=cv, scoring=('r2'))\n    display(scores)\n    print(\"scores mean for\",kModel,\": %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Well, RandomForestRegressor and GradientBoostingRegressor are not so bad. GradientBoostingRegressor is, acctually, very good. But the Voting Regressor ensemble perform better than both, since reduced the variance around the mean. \n\n**So VotingRegressor is our choice.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models['VotingRegressor']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next we will carry out an analysis with training and test sets. We are going to use 20% of all data(without outliers) as our test set."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\nmodel.fit(X_train, y_train)\n\ny_true = y_test\ny_pred = model.predict(X_test)\nprint('r2_score: ',r2_score(y_true, y_pred))\ndfResults = pd.DataFrame()\ndfResults['y_true'] = list(y_true)\ndfResults['y_pred'] = list(y_pred)\ndfResults['%AbsoluteError'] = ((dfResults['y_pred']/dfResults['y_true']-1)*100).abs()\ndisplay(dfResults.head(20))\ndisplay(dfResults.describe())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Well, r2_score is compatible with the cross validation(cross_val_score). But, in a very quick look, in percentage terms, there are very relevant errors(>10%).\n\nBut when we look at the statistics, we can see that 50% of the percentage absolute errors are lower than 24.97%. The average of the errors is about 33.66%.\n"},{"metadata":{},"cell_type":"markdown","source":"And what about the prediction for the outliers?"},{"metadata":{"trusted":true},"cell_type":"code","source":"Xtest = dfOutliers[XCols].values\nytest = dfOutliers[yCol].values\n\ny_true = ytest\ny_pred = model.predict(Xtest)\nprint('r2_score: ',r2_score(y_true, y_pred))\ndfResults = pd.DataFrame()\ndfResults['y_true'] = list(y_true)\ndfResults['y_pred'] = list(y_pred)\ndfResults['%AbsoluteError'] = ((dfResults['y_pred']/dfResults['y_true']-1)*100).abs()\ndisplay(dfResults.head(20))\ndisplay(dfResults.describe())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For outliers, statistics show that 50% of the errors are less than 35.5%. The average of the errors is about 56.77%."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}