{"cells":[{"metadata":{"collapsed":true},"cell_type":"markdown","source":"<b>Importing Necessary Libraries</b>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import confusion_matrix,classification_report\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading the data\nhr=pd.read_csv(\"../input/ibm-hr-analytics-attrition-dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv\")\nhr.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hr.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Observation:</b>\nThere are 1470 rows and 35 columns in the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"hr.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing unnecessary columns in the dataset\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nhr.drop([\"EmployeeNumber\",\"Over18\",\"EmployeeCount\",\"StandardHours\"],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hr.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_data= hr.select_dtypes(include=[\"int64\"])\nnumerical_data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 23 attributes which are of int datatype."},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_data= hr.select_dtypes(include=[\"O\"])\ncategorical_data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 8 attributes which are of object datatype."},{"metadata":{},"cell_type":"markdown","source":"<b>Checking Missing Values</b>"},{"metadata":{"trusted":true},"cell_type":"code","source":"hr.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Observation:</b>\nThere are no missing values in the dataset."},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis"},{"metadata":{},"cell_type":"markdown","source":"<b>Univariate Analysis</b>"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(hr[\"Attrition\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above visualization, we can see that target variable is imbalanced."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(hr[\"BusinessTravel\"],palette=\"Set2\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Observation:</b>\nMost of the Employees Travel Rarely."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(hr[\"Department\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are three departments i.e. Sales, Research & Development, Human Resources. Out of which there are more employees who is in Research & Development."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(hr[\"Gender\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are more number of employees who are Male."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,8))\nsns.countplot(hr[\"JobRole\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Observation:</b>\nThere are more employee who works as a Sales Executive."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(hr[\"MaritalStatus\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Observation:</b>\nMost of the employees who are working are Married."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,4))\nplt.title(\"Distribution of age\")\na = sns.distplot(hr[\"Age\"], color = 'orange')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Observation:</b>\nThe average Age of employees is 35."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,4))\nplt.title(\"Distribution of Daily Rate \")\nb= sns.distplot(hr[\"DailyRate\"], color = 'green')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Observation:</b>\nThe average DailyRate is ~750."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,4))\nplt.title(\"Distribution of Hourly Rate \")\nc= sns.distplot(hr[\"HourlyRate\"], color = 'lime')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Observation:</b>\nThe Hourly Rate of employees are ~ 70."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,4))\nplt.title(\"Distribution of Percentage Salary Hike \")\nd= sns.distplot(hr[\"PercentSalaryHike\"], color = 'green')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Observation:</b>\nThe average percentage salary hike of employees are 12.5"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,4))\nplt.title(\"Distribution of Years at Company \")\ne= sns.distplot(hr[\"YearsAtCompany\"], color = 'springgreen')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Observation:</b>\nThe average years of employees at company is 5 years."},{"metadata":{},"cell_type":"markdown","source":"<b>Bi-Variate Analysis</b>"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=\"BusinessTravel\", hue=\"Attrition\",data=hr,palette=\"Set2\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Observation:</b>\nFrom the above Visualization, it is clear that employees who travel rarely have high attrition."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=\"Department\", hue=\"Attrition\",data=hr,palette=\"Set1\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Observation:</b>\nFrom the above visualization, it is clear that employees who are in Research & Development have high attrition."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=\"Gender\", hue=\"Attrition\",data=hr,palette=\"Set3\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Observation:</b>\nFrom the above visualization, Males have high attrition."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=\"MaritalStatus\", hue=\"Attrition\",data=hr)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Observation:</b>\nEmployees who are single have high attrition."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=\"OverTime\", hue=\"Attrition\",data=hr,palette=\"Set1\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Observation:</b>\nEmployees who do over time have high attrition."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x=\"YearsAtCompany\", y=\"Attrition\",data=hr,palette=\"Set2\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Observation:</b>\nEmployees who are at the company and have experience <=5 have high attrition."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=\"YearsSinceLastPromotion\", hue=\"Attrition\",data=hr,palette=\"Set1\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Observation:</b>\nEmployees who have less experience since last promotion have high attrition."},{"metadata":{},"cell_type":"markdown","source":"<b> Multi-Variate Analysis</b>"},{"metadata":{"trusted":true},"cell_type":"code","source":"hr.hist(figsize=(18,18),grid=True,bins='auto');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hr.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Checking Skewness</b>"},{"metadata":{"trusted":true},"cell_type":"code","source":"hr.skew(axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Treating the skewness in the dataset\nfor index in hr.skew().index:\n    if hr.skew().loc[index]>0.5:\n        hr[index]=np.log1p(hr[index])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hr.skew(axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Label Encoder</b>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets convert the target variable\nfrom sklearn.preprocessing import LabelEncoder\nLE= LabelEncoder()\nhr[\"Attrition\"]=LE.fit_transform(hr[\"Attrition\"])\nhr[\"BusinessTravel\"]=LE.fit_transform(hr[\"BusinessTravel\"])\nhr[\"Department\"]=LE.fit_transform(hr[\"Department\"])\nhr[\"EducationField\"]=LE.fit_transform(hr[\"EducationField\"])\nhr[\"Gender\"]=LE.fit_transform(hr[\"Gender\"])\nhr[\"JobRole\"]=LE.fit_transform(hr[\"JobRole\"])\nhr[\"MaritalStatus\"]=LE.fit_transform(hr[\"MaritalStatus\"])\nhr[\"OverTime\"]=LE.fit_transform(hr[\"OverTime\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Checking Outliers</b>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import zscore\nz_score=abs(zscore(hr))\nprint(\"The shape of dataset before removing outliers\",hr.shape)\nhr=hr.loc[(z_score<3).all(axis=1)]\nprint(\"The shape of dataset after removing outliers\",hr.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Dividing the input and output variables</b>"},{"metadata":{"trusted":true},"cell_type":"code","source":"X= hr.drop([\"Attrition\"],axis=1)\ny= hr[\"Attrition\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets bring the dataset features into same scale\nfrom sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()\nX= scaler.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Splitting into training and testing</b>"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test= train_test_split(X,y, test_size=0.30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will use auc_roc score as the metrics because target variable has imbalance dataset\ndef max_auc_roc_sc(w,X,y):\n    max_auc_roc_sc=0\n    for r_state in range(42,100):\n        X_train,X_test, y_train, y_test= train_test_split(X,y,test_size=0.30, random_state=r_state,stratify=y)\n        w.fit(X_train,y_train)\n        y_pred= w.predict(X_test)\n        auc_roc=roc_auc_score(y_test,y_pred)\n        if auc_roc>max_auc_roc_sc:\n            max_auc_roc_sc=auc_roc\n            a_score=r_state\n    print(\"Maximum AUC_ROC Score corresponding to:\",a_score,\" and it is :\",round((max_auc_roc_sc),3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Machine Learning Models"},{"metadata":{},"cell_type":"markdown","source":"As Target variable(Attrition) is binary, its classification problem, we will use KNN, Decision Tree Classifier, Gradient Boosting Classifier and Random Forest Classifier."},{"metadata":{},"cell_type":"markdown","source":"<b>KNN Classifier</b>"},{"metadata":{"trusted":true},"cell_type":"code","source":"knn= KNeighborsClassifier()\nneighbors={\"n_neighbors\":range(1,30)}\nknn= GridSearchCV(knn, neighbors, cv=5,scoring=\"roc_auc\")\nknn.fit(X,y)\nknn.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn=KNeighborsClassifier(n_neighbors=29)\nmax_auc_roc_sc(knn,X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_knn= knn.predict(X_test)\nm1= knn.score(X_test, y_test)\nprint(\"The accuracy of the KNN Model is:\",round((m1),3))\nprint(confusion_matrix(y_test,pred_knn))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Observations:</b>\n<li> There are 357 observations which are predicted Positive as TP(True Positive) and it is true.</li>\n<li> There are 1 observations which are predicted Negative as TN(True Negative) and it is True.</li>\n<li> There are 0 observations which are predicted Negative as FN(False Negative) and it is False. </li>\n<li> There are 64 observation which are predicted Positive as FP(False Positive) and it is False.</li>"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,pred_knn))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nmean_knn_auc=cross_val_score(knn, X,y,cv=5,scoring=\"roc_auc\").mean()\nprint(\"Mean AUC_ROC Score after cross validation\", cross_val_score(knn, X,y,cv=5,scoring=\"roc_auc\").mean())\nst_knn_auc= cross_val_score(knn, X,y,cv=5,scoring=\"roc_auc\").std()\nprint(\"standard deviation for KNN from mean AUC_ROC score is\",cross_val_score(knn, X,y,cv=5,scoring=\"roc_auc\").std())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_prob= knn.predict_proba(X_test)[:,0]\ntpr,fpr, thresholds= roc_curve(y_test, y_pred_prob)\n\n\n# Plot\nplt.plot([0,1],[0,1],\"k--\")\nplt.plot(fpr,tpr,label=\"KNN\")\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"KNN\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a_c1=roc_auc_score(y_test, knn.predict(X_test))\na_c1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Decision Tree Classifier</b>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndtc = DecisionTreeClassifier(criterion = 'entropy',max_depth=50)\n\nmax_auc_roc_sc(dtc,X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_dtc= dtc.predict(X_test)\ndtc1= dtc.score(X_test, y_test)\nprint(\"The accuracy of the Decision Tree Model is:\",round((dtc1),3))\nprint(confusion_matrix(y_test,pred_dtc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Observations:</b>\n<li> There are 343 observations which are predicted Positive as TP(True Positive) and it is true.</li>\n<li> There are 52 observations which are predicted Negative as TN(True Negative) and it is True.</li>\n<li> There are 14 observations which are predicted Negative as FN(False Negative) and it is False. </li>\n<li> There are 13 observation which are predicted Positive as FP(False Positive) and it is False.</li>"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,pred_dtc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nmean_dtc_auc=cross_val_score(dtc, X,y,cv=5,scoring=\"roc_auc\").mean()\nprint(\"Mean AUC_ROC Score Score after cross validation\", cross_val_score(dtc, X,y,cv=5,scoring=\"roc_auc\").mean())\ns_dtc_auc= cross_val_score(dtc, X,y,cv=5,scoring=\"roc_auc\").std()\nprint(\"standard deviation for Decision Tree Classifier from mean AUC_ROC score is\",cross_val_score(dtc, X,y,cv=5,scoring=\"roc_auc\").std())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\n\ny_pred_prob= dtc.predict_proba(X_test)[:,0]\ntpr,fpr, thresholds= roc_curve(y_test, y_pred_prob)\n\n\n# Plot\nplt.plot([0,1],[0,1],\"k--\")\nplt.plot(fpr,tpr,label=\"Decision Tree\")\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"Decision Tree\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a_c2=roc_auc_score(y_test, dtc.predict(X_test))\na_c2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Gradient Boosting Classifier</b>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\ngb = GradientBoostingClassifier()\nparameters= {'learning_rate': [0.01,0.03,0.05], 'subsample': [0.1, 0.5,0.3], 'n_estimators': [10,50,100], 'max_depth': [2,4,8]}\ngb= GridSearchCV(estimator=gb, param_grid= parameters, cv=5, n_jobs=-1)\ngb.fit(X,y)\ngb.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gb = GradientBoostingClassifier(learning_rate=0.05,max_depth=2,n_estimators=100,subsample=0.1)\nmax_auc_roc_sc(gb,X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_gb= gb.predict(X_test)\ngb1= gb.score(X_test, y_test)\nprint(\"The accuracy of the Grading Boosting Model is:\",round((gb1),3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_test,pred_gb))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Observations:</b>\n<li> There are 352 observations which are predicted Positive as TP(True Positive) and it is true.</li>\n<li> There are 20 observations which are predicted Negative as TN(True Negative) and it is True.</li>\n<li> There are 5 observations which are predicted Negative as FN(False Negative) and it is False. </li>\n<li> There are 45 observations which are predicted Positive as FP(False Positive) and it is False.</li>"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,pred_gb))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nmean_gb_auc=cross_val_score(gb, X,y,cv=5,scoring=\"roc_auc\").mean()\nprint(\"Mean AUC_ROC Score after cross validation\", cross_val_score(gb, X,y,cv=5,scoring=\"roc_auc\").mean())\nstd_gb_auc= cross_val_score(gb, X,y,cv=5,scoring=\"roc_auc\").std()\nprint(\"standard deviation for Gradient  Boosting from mean AUC_ROC score is\",cross_val_score(gb, X,y,cv=5,scoring=\"roc_auc\").std())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\n\ny_pred_prob= gb.predict_proba(X_test)[:,0]\ntpr,fpr, thresholds= roc_curve(y_test, y_pred_prob)\n\n\n# Plot\nplt.plot([0,1],[0,1],\"k--\")\nplt.plot(fpr,tpr,label=\"Gradient Boosting\")\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"Gradient Boosting\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a_c3=roc_auc_score(y_test, gb.predict(X_test))\na_c3","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Random Forest Classifier</b>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrfc= RandomForestClassifier()\nparameters= {'n_estimators':[4,6,8],'max_features':['log2','sqrt','auto'],'criterion':['entropy','gini'],'max_depth':[2,5,10],'min_samples_split':[2,3,5],'min_samples_leaf':[3,5,7]}\nrfc= GridSearchCV(rfc,parameters)\nrfc.fit(X,y)\nrfc.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc=RandomForestClassifier(criterion='gini', max_depth=10,max_features='sqrt',min_samples_leaf=5,min_samples_split=3,n_estimators=8)\nmax_auc_roc_sc(rfc,X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_rfc= rfc.predict(X_test)\nrf= rfc.score(X_test, y_test)\nprint(\"The accuracy of the Random Forest Classifier is:\",round((rf),3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_test,pred_rfc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Observations:</b>\n<li> There are 353 observations which are predicted Positive as TP(True Positive) and it is true.</li>\n<li> There are 19 observations which are predicted Negative as TN(True Negative) and it is True.</li>\n<li> There are 4 observations which are predicted Negative as FN(False Negative) and it is False. </li>\n<li> There are 46 observations which are predicted Positive as FP(False Positive) and it is False.</li>"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,pred_rfc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nmean_rfc_auc=cross_val_score(rfc, X,y,cv=5,scoring=\"roc_auc\").mean()\nprint(\"Mean AUC_ROC Score after cross validation\", cross_val_score(rfc, X,y,cv=5,scoring=\"roc_auc\").mean())\nstd_rfc_auc= cross_val_score(rfc, X,y,cv=5,scoring=\"roc_auc\").std()\nprint(\"standard deviation for Random Forest Classifier from mean AUC_ROC score is\",cross_val_score(rfc, X,y,cv=5,scoring=\"roc_auc\").std())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_prob= rfc.predict_proba(X_test)[:,0]\ntpr,fpr, thresholds= roc_curve(y_test, y_pred_prob)\n\n# Plot\nplt.plot([0,1],[0,1],\"k--\")\nplt.plot(fpr,tpr,label=\"Random Forest\")\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"Random Forest Classifier\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a_c4=roc_auc_score(y_test, rfc.predict(X_test))\na_c4","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluation:"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets initialise the data frame with columns model and f1_score\ndata= [[\"KNN\", m1, mean_knn_auc,st_knn_auc],[\"Decision Tree Classifier\",dtc1,mean_dtc_auc,s_dtc_auc],[\"Gradient Boosting Classifier\", gb1,mean_gb_auc, std_gb_auc],[\"Random Forest Classifier\",rf,mean_rfc_auc,std_rfc_auc]]\ncomparsion_table= pd.DataFrame(data, columns=[\"Model Name\", \"Accuracy\",\"Mean AUC Score\",\" Std from mean AUC Score\"], index=[1,2,3,4])\ncomparsion_table","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Observations:</b>\n<li> From the above models, Decision Tree Classifier performed well with 93.60% accuracy.</li>\n<li>As the data was imbalanced, we used AUC ROC for model evaluation and calculated Mean AUC Score and Standard Deviation mean AUC Score</li>"},{"metadata":{},"cell_type":"markdown","source":"<b>Saving the Prediction</b>"},{"metadata":{},"cell_type":"markdown","source":"As the Decision Tree Classifier performed well, we are saving the prediction."},{"metadata":{"trusted":true},"cell_type":"code","source":"np.savetxt('HR.csv',pred_dtc,delimiter=',')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets save the above model\nfrom sklearn.externals import joblib \n  \n# Save the model as a pickle in a file \njoblib.dump(dtc, 'hr.pkl')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.1"}},"nbformat":4,"nbformat_minor":4}