{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-25T10:08:59.004506Z","iopub.execute_input":"2021-05-25T10:08:59.004905Z","iopub.status.idle":"2021-05-25T10:08:59.844816Z","shell.execute_reply.started":"2021-05-25T10:08:59.004824Z","shell.execute_reply":"2021-05-25T10:08:59.843517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's start on mercedes car\ncclass = pd.read_csv('/kaggle/input/used-car-dataset-ford-and-mercedes/cclass.csv')\nfocus = pd.read_csv('/kaggle/input/used-car-dataset-ford-and-mercedes/focus.csv')\naudi = pd.read_csv('/kaggle/input/used-car-dataset-ford-and-mercedes/audi.csv')\ntoyota = pd.read_csv('/kaggle/input/used-car-dataset-ford-and-mercedes/toyota.csv')\nskoda = pd.read_csv('/kaggle/input/used-car-dataset-ford-and-mercedes/skoda.csv')\nford = pd.read_csv('/kaggle/input/used-car-dataset-ford-and-mercedes/ford.csv')\nvauxhall = pd.read_csv('/kaggle/input/used-car-dataset-ford-and-mercedes/vauxhall.csv')\nbmw = pd.read_csv('/kaggle/input/used-car-dataset-ford-and-mercedes/bmw.csv')\nvw = pd.read_csv('/kaggle/input/used-car-dataset-ford-and-mercedes/vw.csv')\nhyundai = pd.read_csv('/kaggle/input/used-car-dataset-ford-and-mercedes/hyundi.csv')\nmerc = pd.read_csv('/kaggle/input/used-car-dataset-ford-and-mercedes/merc.csv')\ndata = audi.copy()\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:09:01.639145Z","iopub.execute_input":"2021-05-25T10:09:01.63948Z","iopub.status.idle":"2021-05-25T10:09:02.008227Z","shell.execute_reply.started":"2021-05-25T10:09:01.63945Z","shell.execute_reply":"2021-05-25T10:09:02.007281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* mpg - miles per gallon\n* tax - road tax","metadata":{}},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:10:05.392742Z","iopub.execute_input":"2021-05-25T10:10:05.393234Z","iopub.status.idle":"2021-05-25T10:10:05.423958Z","shell.execute_reply.started":"2021-05-25T10:10:05.393182Z","shell.execute_reply":"2021-05-25T10:10:05.422616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"# check price distribution\nsns.histplot(data['price'], bins=30)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:11:55.766998Z","iopub.execute_input":"2021-05-25T10:11:55.767421Z","iopub.status.idle":"2021-05-25T10:11:55.992569Z","shell.execute_reply.started":"2021-05-25T10:11:55.767377Z","shell.execute_reply":"2021-05-25T10:11:55.9916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_numerical(feature):\n    sns.lmplot(x=feature, y='price', data=data)\n    plt.show()\n    \ndef plot_categorical(feature, figsize=None):\n    df = data.groupby([feature])['price'].describe()[['mean', '50%', 'min', 'count']]\n\n    labels = df.index.values\n    x = np.arange(len(labels))\n    width = 0.9\n    fig, ax1 = plt.subplots(figsize=(12, 5))\n\n    # plot bars for min, median and mean house price\n    rects1 = ax1.bar(x-width/2, df['50%'], width/3, label='median')\n    rects2 = ax1.bar(x-width/6, df['mean'], width/3, label='mean')\n    rects3 = ax1.bar(x+width/6, df['min'], width/3, label='min')\n\n    ax1.set_ylabel('price', fontsize=15)\n    ax1.set_title(feature, fontsize=18)\n    ax1.set_xticks(x)\n    ax1.set_xticklabels(labels, rotation=0)\n    ax1.legend()\n\n    # plot counts of data points\n    ax2 = ax1.twinx()\n    ax2.set_ylabel('Counts', fontsize=15)\n    ax2.plot(x-width/2, df['count'], color='red', linestyle='dashed')\n\n    # annotate counts of data points\n    for i, rect in enumerate(rects2):\n        height = int(round(rect.get_height()))\n        ax1.annotate('{}'.format(int(df['count'].iloc[i])),\n                     xy=(rect.get_x() + rect.get_width()/2, height),\n                     xytext=(0, 3), textcoords=\"offset points\",\n                     ha='center', va='bottom', color='red')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:16:07.738016Z","iopub.execute_input":"2021-05-25T10:16:07.738502Z","iopub.status.idle":"2021-05-25T10:16:07.751694Z","shell.execute_reply.started":"2021-05-25T10:16:07.738467Z","shell.execute_reply":"2021-05-25T10:16:07.750666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature in ['model', 'transmission', 'fuelType']:\n    plot_categorical(feature)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:16:09.021683Z","iopub.execute_input":"2021-05-25T10:16:09.022144Z","iopub.status.idle":"2021-05-25T10:16:10.379522Z","shell.execute_reply.started":"2021-05-25T10:16:09.022113Z","shell.execute_reply":"2021-05-25T10:16:10.378397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature in ['year', 'mileage', 'tax', 'mpg', 'engineSize']:\n    plot_numerical(feature)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:19:44.296091Z","iopub.execute_input":"2021-05-25T10:19:44.296477Z","iopub.status.idle":"2021-05-25T10:19:49.056044Z","shell.execute_reply.started":"2021-05-25T10:19:44.296445Z","shell.execute_reply":"2021-05-25T10:19:49.055078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations-**\n* model - R8 models are the costliest ones while A1, A3, A4 & Q3 are the most popular ones\n* transmission - Manual has usually low cost\n* fuelType - Hybrid are the least popular and costliest ones\n* year - new cars are sold at higher prices\n* mileage - lower the mileage or car travelled, higher the price\n* mpg - lower the mpg, higher the car price (usually heavy or luxury cars have lower mpg)\n* engineSize - bigger the enginer, higher the price\n* tax - generally higher the tax, higher the car price","metadata":{}},{"cell_type":"code","source":"data.columns","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:41:14.140446Z","iopub.execute_input":"2021-05-25T10:41:14.140841Z","iopub.status.idle":"2021-05-25T10:41:14.148182Z","shell.execute_reply.started":"2021-05-25T10:41:14.14081Z","shell.execute_reply":"2021-05-25T10:41:14.147207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorical_features = ['model', 'transmission', 'fuelType']\nnumerical_features = ['year', 'mileage', 'tax', 'mpg', 'engineSize']","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:42:16.521795Z","iopub.execute_input":"2021-05-25T10:42:16.522239Z","iopub.status.idle":"2021-05-25T10:42:16.527694Z","shell.execute_reply.started":"2021-05-25T10:42:16.5222Z","shell.execute_reply":"2021-05-25T10:42:16.52631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CORRELATION","metadata":{}},{"cell_type":"markdown","source":"### Label encoding categorical features for correlation","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder, OneHotEncoder\nimport joblib","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:43:00.107455Z","iopub.execute_input":"2021-05-25T10:43:00.107846Z","iopub.status.idle":"2021-05-25T10:43:00.246836Z","shell.execute_reply.started":"2021-05-25T10:43:00.107811Z","shell.execute_reply":"2021-05-25T10:43:00.246163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = data.copy()\npath = '/kaggle/working'\nfor i, feature in enumerate(categorical_features):\n    le = LabelEncoder()\n\n    # create directory to save label encoding models\n    if not os.path.exists(os.path.join(path, \"TextEncoding\")):\n        os.makedirs(os.path.join(path, \"TextEncoding\"))\n\n    # perform label encoding\n    le.fit(df[feature])\n    #print(feature)\n    \n    # save the encoder\n    joblib.dump(le, open(os.path.join(path, \"TextEncoding/le_{}.sav\".format(feature)), 'wb'))\n    \n    # transfrom training data\n    df[feature] = le.transform(df[feature])\n\n    # get classes & remove first column to elude from dummy variable trap\n    columns = list(map(lambda x: feature+' '+str(x), list(le.classes_)))[1:]\n    \n    # save classes\n    joblib.dump(columns, \n                open(os.path.join(path, \"TextEncoding/le_{}_classes.sav\".format(feature)), 'wb'))","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:43:15.255888Z","iopub.execute_input":"2021-05-25T10:43:15.256446Z","iopub.status.idle":"2021-05-25T10:43:15.670157Z","shell.execute_reply.started":"2021-05-25T10:43:15.256412Z","shell.execute_reply":"2021-05-25T10:43:15.669316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Bivariate Analysis Correlation plot for numerical features","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(8, 5))\nsns.heatmap(round(data[numerical_features].corr(method='spearman'), 2), \n            annot=True, mask=None, cmap='GnBu')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:44:00.540872Z","iopub.execute_input":"2021-05-25T10:44:00.54125Z","iopub.status.idle":"2021-05-25T10:44:00.875267Z","shell.execute_reply.started":"2021-05-25T10:44:00.541218Z","shell.execute_reply":"2021-05-25T10:44:00.874539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Bivariate Analysis Correlation plot with the Categorical variables","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 5))\nsns.heatmap(round(df[categorical_features+numerical_features+['price']].corr(method='spearman'), 2), annot=True,\n            mask=None, cmap='GnBu')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:48:23.197488Z","iopub.execute_input":"2021-05-25T10:48:23.19789Z","iopub.status.idle":"2021-05-25T10:48:23.902638Z","shell.execute_reply.started":"2021-05-25T10:48:23.197856Z","shell.execute_reply":"2021-05-25T10:48:23.901328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations-**\n* year - mileage -ve\n* mpg - tax -ve\n* year - mpg - mileage","metadata":{}},{"cell_type":"markdown","source":"# Analyzing features using VIF","metadata":{}},{"cell_type":"code","source":"from statsmodels.stats.outliers_influence import variance_inflation_factor","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:50:41.316126Z","iopub.execute_input":"2021-05-25T10:50:41.316501Z","iopub.status.idle":"2021-05-25T10:50:41.435937Z","shell.execute_reply.started":"2021-05-25T10:50:41.316468Z","shell.execute_reply":"2021-05-25T10:50:41.434994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculating VIF\nvif = pd.DataFrame()\nvif[\"variables\"] = [feature for feature in categorical_features+numerical_features if feature not in ['year']]\nvif[\"VIF\"] = [variance_inflation_factor(df[vif['variables']].values, i) for i in range(len(vif[\"variables\"]))]\nprint(vif)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:51:51.29133Z","iopub.execute_input":"2021-05-25T10:51:51.291696Z","iopub.status.idle":"2021-05-25T10:51:51.354217Z","shell.execute_reply.started":"2021-05-25T10:51:51.291664Z","shell.execute_reply":"2021-05-25T10:51:51.353113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Looking at Outliers","metadata":{}},{"cell_type":"code","source":"NumericData = data[['mileage']]\nNumericMelt = NumericData.melt()\nplt.figure(figsize=(15,10))\nplt.title(\"Boxplots for Numerical variables\")\nbp = sns.boxplot(x='variable', y='value', data=NumericMelt)\nbp = sns.stripplot(x='variable', y='value', data=NumericMelt, jitter=True, edgecolor='gray')\nbp.set_xticklabels(bp.get_xticklabels(), rotation=90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:54:05.630017Z","iopub.execute_input":"2021-05-25T10:54:05.630609Z","iopub.status.idle":"2021-05-25T10:54:05.874702Z","shell.execute_reply.started":"2021-05-25T10:54:05.630554Z","shell.execute_reply":"2021-05-25T10:54:05.873644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NumericData = data[['year']]\nNumericMelt = NumericData.melt()\nplt.figure(figsize=(15,10))\nplt.title(\"Boxplots for Numerical variables\")\nbp = sns.boxplot(x='variable', y='value', data=NumericMelt)\nbp = sns.stripplot(x='variable', y='value', data=NumericMelt, jitter=True, edgecolor='gray')\nbp.set_xticklabels(bp.get_xticklabels(), rotation=90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:54:48.674424Z","iopub.execute_input":"2021-05-25T10:54:48.674777Z","iopub.status.idle":"2021-05-25T10:54:48.901447Z","shell.execute_reply.started":"2021-05-25T10:54:48.674749Z","shell.execute_reply":"2021-05-25T10:54:48.900609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NumericData = data[['engineSize']]\nNumericMelt = NumericData.melt()\nplt.figure(figsize=(15,10))\nplt.title(\"Boxplots for Numerical variables\")\nbp = sns.boxplot(x='variable', y='value', data=NumericMelt)\nbp = sns.stripplot(x='variable', y='value', data=NumericMelt, jitter=True, edgecolor='gray')\nbp.set_xticklabels(bp.get_xticklabels(), rotation=90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:55:30.373462Z","iopub.execute_input":"2021-05-25T10:55:30.373966Z","iopub.status.idle":"2021-05-25T10:55:30.62499Z","shell.execute_reply.started":"2021-05-25T10:55:30.373935Z","shell.execute_reply":"2021-05-25T10:55:30.624126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NumericData = data[['tax', 'mpg']]\nNumericMelt = NumericData.melt()\nplt.figure(figsize=(15,10))\nplt.title(\"Boxplots for Numerical variables\")\nbp = sns.boxplot(x='variable', y='value', data=NumericMelt)\nbp = sns.stripplot(x='variable', y='value', data=NumericMelt, jitter=True, edgecolor='gray')\nbp.set_xticklabels(bp.get_xticklabels(), rotation=90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:56:06.956095Z","iopub.execute_input":"2021-05-25T10:56:06.956597Z","iopub.status.idle":"2021-05-25T10:56:07.295631Z","shell.execute_reply.started":"2021-05-25T10:56:06.956565Z","shell.execute_reply":"2021-05-25T10:56:07.294533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Percentage of outliers present in each variable\noutlier_percentage = {}\nfor feature in numerical_features:\n    tempData = data.sort_values(by=feature)[feature]\n    Q1, Q3 = tempData.quantile([0.25, 0.75])\n    IQR = Q3 - Q1\n    Lower_range = Q1 - (1.5 * IQR)\n    Upper_range = Q3 + (1.5 * IQR)\n    outlier_percentage[feature] = round((((tempData<(Q1 - 1.5 * IQR)) | (tempData>(Q3 + 1.5 * IQR))).sum()/tempData.shape[0])*100,2)\noutlier_percentage","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:56:52.687296Z","iopub.execute_input":"2021-05-25T10:56:52.687636Z","iopub.status.idle":"2021-05-25T10:56:52.720318Z","shell.execute_reply.started":"2021-05-25T10:56:52.687606Z","shell.execute_reply":"2021-05-25T10:56:52.719225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Handling Categorical Features (Label Encoding & One Hot Encoding)","metadata":{}},{"cell_type":"code","source":"df = data.copy()\npath = '/kaggle/working'\nfor i, feature in enumerate(categorical_features):\n    \n    le = LabelEncoder()\n    ohe = OneHotEncoder(sparse=False)\n\n    # create directory to save label encoding models\n    if not os.path.exists(os.path.join(path, \"TextEncoding\")):\n        os.makedirs(os.path.join(path, \"TextEncoding\"))\n\n    # perform label encoding\n    le.fit(df[feature])\n    # save the encoder\n    joblib.dump(le, open(os.path.join(path, \"TextEncoding/le_{}.sav\".format(feature)), 'wb'))\n    \n    # transfrom training data\n    df[feature] = le.transform(df[feature])\n\n    # get classes & remove first column to elude from dummy variable trap\n    columns = list(map(lambda x: feature+' '+str(x), list(le.classes_)))[1:]\n    \n    # save classes\n    joblib.dump(columns, \n                open(os.path.join(path, \"TextEncoding/le_{}_classes.sav\".format(feature)), 'wb'))\n    # load classes\n    columns = joblib.load(\n        open(os.path.join(path, \"TextEncoding/le_{}_classes.sav\".format(feature)), 'rb'))\n\n    if len(le.classes_)>2:\n        # perform one hot encoding\n        ohe.fit(df[[feature]])\n        # save the encoder\n        joblib.dump(ohe, \n                    open(os.path.join(path, \"TextEncoding/ohe_{}.sav\".format(feature)), 'wb'))\n\n        # transfrom training data\n        # removing first column of encoded data to elude from dummy variable trap\n        tempData = ohe.transform(df[[feature]])[:, 1:]\n\n        # create Dataframe with columns as classes\n        tempData = pd.DataFrame(tempData, columns=columns)\n    else:\n        tempData = df[[feature]]\n    \n    # create dataframe with all the label encoded categorical features along with hot encoding\n    if i==0:\n        encodedData = pd.DataFrame(data=tempData, columns=tempData.columns.values.tolist())\n    else:\n        encodedData = pd.concat([encodedData, tempData], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:57:53.497427Z","iopub.execute_input":"2021-05-25T10:57:53.498028Z","iopub.status.idle":"2021-05-25T10:57:53.757889Z","shell.execute_reply.started":"2021-05-25T10:57:53.497981Z","shell.execute_reply":"2021-05-25T10:57:53.757192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# merge numerical features and categorical encoded features\ndf = df[numerical_features+['price']]\ndf = pd.concat([df, encodedData], axis=1)\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:58:05.483538Z","iopub.execute_input":"2021-05-25T10:58:05.483915Z","iopub.status.idle":"2021-05-25T10:58:05.509224Z","shell.execute_reply.started":"2021-05-25T10:58:05.483883Z","shell.execute_reply":"2021-05-25T10:58:05.508293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Model","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics, preprocessing\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import r2_score","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:58:41.585596Z","iopub.execute_input":"2021-05-25T10:58:41.585967Z","iopub.status.idle":"2021-05-25T10:58:41.812856Z","shell.execute_reply.started":"2021-05-25T10:58:41.585935Z","shell.execute_reply":"2021-05-25T10:58:41.811968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = df.copy()\nfeature_cols = [feature for feature in train_data.columns if feature not in(['price'])]\nprint('features used: ', feature_cols)\n\n# RESCALING\n#scaler = MinMaxScaler()\n#scaler.fit(train_data[feature_cols])\n#train_data[feature_cols] = scaler.transform(train_data[feature_cols])","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:59:02.748413Z","iopub.execute_input":"2021-05-25T10:59:02.748737Z","iopub.status.idle":"2021-05-25T10:59:02.755664Z","shell.execute_reply.started":"2021-05-25T10:59:02.7487Z","shell.execute_reply":"2021-05-25T10:59:02.754493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train_data[feature_cols]\ny = train_data['price']\n\nvalidation_size = 0.2\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=validation_size, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:59:44.772169Z","iopub.execute_input":"2021-05-25T10:59:44.772522Z","iopub.status.idle":"2021-05-25T10:59:44.785778Z","shell.execute_reply.started":"2021-05-25T10:59:44.772476Z","shell.execute_reply":"2021-05-25T10:59:44.784731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 1: Linear Regresssion ","metadata":{}},{"cell_type":"code","source":"model = LinearRegression()\nmodel.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T11:00:28.099993Z","iopub.execute_input":"2021-05-25T11:00:28.100345Z","iopub.status.idle":"2021-05-25T11:00:28.137635Z","shell.execute_reply.started":"2021-05-25T11:00:28.100317Z","shell.execute_reply":"2021-05-25T11:00:28.136656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_train)\n\nprint('Train metrics...')\nprint('RMSE: ', np.sqrt(mean_squared_error(y_train, y_pred)))\nprint('r2_score: ', round(r2_score(y_train, y_pred)*100, 2))\n\ny_pred = model.predict(X_test)\n\nprint('Validation metrics...')\nprint('RMSE: ', np.sqrt(mean_squared_error(y_test, y_pred)))\nprint('r2_score: ', round(r2_score(y_test, y_pred)*100, 2))","metadata":{"execution":{"iopub.status.busy":"2021-05-25T11:01:13.81168Z","iopub.execute_input":"2021-05-25T11:01:13.811994Z","iopub.status.idle":"2021-05-25T11:01:13.836293Z","shell.execute_reply.started":"2021-05-25T11:01:13.811967Z","shell.execute_reply":"2021-05-25T11:01:13.835148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.graph_objects as go\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=list(range(len(y_pred[-150:]))), y=y_pred[-150:],\n                         mode='lines',\n                         name='Prediction'))\nfig.add_trace(go.Scatter(x=list(range(len(y_test[-150:]))), y=y_test[-150:],\n                         mode='lines',\n                         name='True value'))\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T11:02:14.689163Z","iopub.execute_input":"2021-05-25T11:02:14.689628Z","iopub.status.idle":"2021-05-25T11:02:14.818644Z","shell.execute_reply.started":"2021-05-25T11:02:14.689591Z","shell.execute_reply":"2021-05-25T11:02:14.817401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 2: XGB","metadata":{"execution":{"iopub.status.busy":"2021-05-25T11:56:20.70531Z","iopub.execute_input":"2021-05-25T11:56:20.705762Z","iopub.status.idle":"2021-05-25T11:56:20.710464Z","shell.execute_reply.started":"2021-05-25T11:56:20.705731Z","shell.execute_reply":"2021-05-25T11:56:20.70918Z"}}},{"cell_type":"code","source":"model = XGBRegressor( \n    n_estimators = 1000,\n    learning_rate=0.09, \n    min_child_weight=5,\n    max_depth = 3,\n    subsample = 0.75,\n    seed=7)\n\n\nmodel = model.fit(\n    X_train, \n    y_train, \n    eval_metric=\"rmse\", \n    #early_stopping_rounds=10,\n    #eval_set=[(X_test, y_test)],\n    verbose=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T11:15:16.686839Z","iopub.execute_input":"2021-05-25T11:15:16.687205Z","iopub.status.idle":"2021-05-25T11:15:21.002609Z","shell.execute_reply.started":"2021-05-25T11:15:16.687176Z","shell.execute_reply":"2021-05-25T11:15:21.001485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_train)\n\nprint('Train metrics...')\nprint('RMSE: ', np.sqrt(mean_squared_error(y_train, y_pred)))\nprint('r2_score: ', round(r2_score(y_train, y_pred)*100, 2))\n\ny_pred = model.predict(X_test)\n\nprint('Validation metrics...')\nprint('RMSE: ', np.sqrt(mean_squared_error(y_test, y_pred)))\nprint('r2_score: ', round(r2_score(y_test, y_pred)*100, 2))","metadata":{"execution":{"iopub.status.busy":"2021-05-25T11:15:21.004419Z","iopub.execute_input":"2021-05-25T11:15:21.004955Z","iopub.status.idle":"2021-05-25T11:15:21.07538Z","shell.execute_reply.started":"2021-05-25T11:15:21.004908Z","shell.execute_reply":"2021-05-25T11:15:21.074077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.graph_objects as go\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=list(range(len(y_pred[-150:]))), y=y_pred[-150:],\n                         mode='lines',\n                         name='Prediction'))\nfig.add_trace(go.Scatter(x=list(range(len(y_test[-150:]))), y=y_test[-150:],\n                         mode='lines',\n                         name='True value'))\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T11:15:31.730017Z","iopub.execute_input":"2021-05-25T11:15:31.730394Z","iopub.status.idle":"2021-05-25T11:15:31.751087Z","shell.execute_reply.started":"2021-05-25T11:15:31.730366Z","shell.execute_reply":"2021-05-25T11:15:31.749795Z"},"trusted":true},"execution_count":null,"outputs":[]}]}