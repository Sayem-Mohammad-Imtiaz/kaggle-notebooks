{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-25T12:19:28.591509Z","iopub.execute_input":"2021-05-25T12:19:28.592116Z","iopub.status.idle":"2021-05-25T12:19:29.454531Z","shell.execute_reply.started":"2021-05-25T12:19:28.591996Z","shell.execute_reply":"2021-05-25T12:19:29.453623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's start on mercedes car\ncclass = pd.read_csv('/kaggle/input/used-car-dataset-ford-and-mercedes/cclass.csv')\nfocus = pd.read_csv('/kaggle/input/used-car-dataset-ford-and-mercedes/focus.csv')\naudi = pd.read_csv('/kaggle/input/used-car-dataset-ford-and-mercedes/audi.csv')\ntoyota = pd.read_csv('/kaggle/input/used-car-dataset-ford-and-mercedes/toyota.csv')\nskoda = pd.read_csv('/kaggle/input/used-car-dataset-ford-and-mercedes/skoda.csv')\nford = pd.read_csv('/kaggle/input/used-car-dataset-ford-and-mercedes/ford.csv')\nvauxhall = pd.read_csv('/kaggle/input/used-car-dataset-ford-and-mercedes/vauxhall.csv')\nbmw = pd.read_csv('/kaggle/input/used-car-dataset-ford-and-mercedes/bmw.csv')\nvw = pd.read_csv('/kaggle/input/used-car-dataset-ford-and-mercedes/vw.csv')\nhyundai = pd.read_csv('/kaggle/input/used-car-dataset-ford-and-mercedes/hyundi.csv')\nmerc = pd.read_csv('/kaggle/input/used-car-dataset-ford-and-mercedes/merc.csv')\ndata = vw.copy()\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:19:40.403392Z","iopub.execute_input":"2021-05-25T12:19:40.403733Z","iopub.status.idle":"2021-05-25T12:19:40.719462Z","shell.execute_reply.started":"2021-05-25T12:19:40.403704Z","shell.execute_reply":"2021-05-25T12:19:40.718424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* mpg - miles per gallon\n* tax - road tax","metadata":{}},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:19:45.994581Z","iopub.execute_input":"2021-05-25T12:19:45.994961Z","iopub.status.idle":"2021-05-25T12:19:46.021999Z","shell.execute_reply.started":"2021-05-25T12:19:45.994928Z","shell.execute_reply":"2021-05-25T12:19:46.020881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"# check price distribution\nsns.histplot(data['price'], bins=30)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:19:53.620882Z","iopub.execute_input":"2021-05-25T12:19:53.621292Z","iopub.status.idle":"2021-05-25T12:19:53.903146Z","shell.execute_reply.started":"2021-05-25T12:19:53.621257Z","shell.execute_reply":"2021-05-25T12:19:53.902238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_numerical(feature):\n    ax = sns.lmplot(x=feature, y='price', data=data)\n    ax.set_xticklabels(rotation=85)\n    plt.show()\n    \ndef plot_categorical(feature, figsize=None):\n    df = data.groupby([feature])['price'].describe()[['mean', '50%', 'min', 'count']]\n\n    labels = df.index.values\n    x = np.arange(len(labels))\n    width = 0.9\n    fig, ax1 = plt.subplots(figsize=(12, 5))\n\n    # plot bars for min, median and mean house price\n    rects1 = ax1.bar(x-width/2, df['50%'], width/3, label='median')\n    rects2 = ax1.bar(x-width/6, df['mean'], width/3, label='mean')\n    rects3 = ax1.bar(x+width/6, df['min'], width/3, label='min')\n\n    ax1.set_ylabel('price', fontsize=15)\n    ax1.set_title(feature, fontsize=18)\n    ax1.set_xticks(x)\n    ax1.set_xticklabels(labels, rotation=85)\n    ax1.legend()\n\n    # plot counts of data points\n    ax2 = ax1.twinx()\n    ax2.set_ylabel('Counts', fontsize=15)\n    ax2.plot(x-width/2, df['count'], color='red', linestyle='dashed')\n\n    # annotate counts of data points\n    for i, rect in enumerate(rects2):\n        height = int(round(rect.get_height()))\n        ax1.annotate('{}'.format(int(df['count'].iloc[i])),\n                     xy=(rect.get_x() + rect.get_width()/2, height),\n                     xytext=(0, 3), textcoords=\"offset points\",\n                     ha='center', va='bottom', color='red')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:19:59.988775Z","iopub.execute_input":"2021-05-25T12:19:59.989139Z","iopub.status.idle":"2021-05-25T12:20:00.001754Z","shell.execute_reply.started":"2021-05-25T12:19:59.989106Z","shell.execute_reply":"2021-05-25T12:20:00.000396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature in ['model', 'transmission', 'fuelType']:\n    plot_categorical(feature)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:20:02.755472Z","iopub.execute_input":"2021-05-25T12:20:02.755838Z","iopub.status.idle":"2021-05-25T12:20:04.277023Z","shell.execute_reply.started":"2021-05-25T12:20:02.7558Z","shell.execute_reply":"2021-05-25T12:20:04.276096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature in ['year', 'mileage', 'tax', 'mpg', 'engineSize']:\n    plot_numerical(feature)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:20:04.278428Z","iopub.execute_input":"2021-05-25T12:20:04.278707Z","iopub.status.idle":"2021-05-25T12:20:10.256656Z","shell.execute_reply.started":"2021-05-25T12:20:04.278677Z","shell.execute_reply":"2021-05-25T12:20:10.255611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations-**\n* model - California models are the costliest ones while Golf and Tiguan are the most popular ones\n* transmission - Manual has cheapest price\n* fuelType - Petrol models are the cheapest and the most popular ones\n* year - new cars are sold at higher prices\n* mileage - lower the mileage or car travelled, higher the price\n* mpg - lower the mpg, higher the car price (usually heavy or luxury cars have lower mpg)\n* engineSize - bigger the enginer, higher the price\n* tax - generally higher the tax, higher the car price","metadata":{}},{"cell_type":"code","source":"categorical_features = ['model', 'transmission', 'fuelType']\nnumerical_features = ['year', 'mileage', 'tax', 'mpg', 'engineSize']","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:22:09.898632Z","iopub.execute_input":"2021-05-25T12:22:09.899008Z","iopub.status.idle":"2021-05-25T12:22:09.903677Z","shell.execute_reply.started":"2021-05-25T12:22:09.898978Z","shell.execute_reply":"2021-05-25T12:22:09.902839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CORRELATION","metadata":{}},{"cell_type":"markdown","source":"### Label encoding categorical features for correlation","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder, OneHotEncoder\nimport joblib","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:22:10.758556Z","iopub.execute_input":"2021-05-25T12:22:10.75905Z","iopub.status.idle":"2021-05-25T12:22:10.908409Z","shell.execute_reply.started":"2021-05-25T12:22:10.759019Z","shell.execute_reply":"2021-05-25T12:22:10.907326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = data.copy()\npath = '/kaggle/working'\nfor i, feature in enumerate(categorical_features):\n    le = LabelEncoder()\n\n    # create directory to save label encoding models\n    if not os.path.exists(os.path.join(path, \"TextEncoding\")):\n        os.makedirs(os.path.join(path, \"TextEncoding\"))\n\n    # perform label encoding\n    le.fit(df[feature])\n    #print(feature)\n    \n    # save the encoder\n    joblib.dump(le, open(os.path.join(path, \"TextEncoding/le_{}.sav\".format(feature)), 'wb'))\n    \n    # transfrom training data\n    df[feature] = le.transform(df[feature])\n\n    # get classes & remove first column to elude from dummy variable trap\n    columns = list(map(lambda x: feature+' '+str(x), list(le.classes_)))[1:]\n    \n    # save classes\n    joblib.dump(columns, \n                open(os.path.join(path, \"TextEncoding/le_{}_classes.sav\".format(feature)), 'wb'))","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:22:11.036939Z","iopub.execute_input":"2021-05-25T12:22:11.037488Z","iopub.status.idle":"2021-05-25T12:22:11.073093Z","shell.execute_reply.started":"2021-05-25T12:22:11.037447Z","shell.execute_reply":"2021-05-25T12:22:11.072209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Bivariate Analysis Correlation plot for numerical features","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(8, 5))\nsns.heatmap(round(data[numerical_features].corr(method='spearman'), 2), \n            annot=True, mask=None, cmap='GnBu')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:22:11.466847Z","iopub.execute_input":"2021-05-25T12:22:11.467339Z","iopub.status.idle":"2021-05-25T12:22:11.802222Z","shell.execute_reply.started":"2021-05-25T12:22:11.467308Z","shell.execute_reply":"2021-05-25T12:22:11.801212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Bivariate Analysis Correlation plot with the Categorical variables","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 5))\nsns.heatmap(round(df[categorical_features+numerical_features+['price']].corr(method='spearman'), 2), annot=True,\n            mask=None, cmap='GnBu')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:22:35.460037Z","iopub.execute_input":"2021-05-25T12:22:35.460522Z","iopub.status.idle":"2021-05-25T12:22:36.140823Z","shell.execute_reply.started":"2021-05-25T12:22:35.460492Z","shell.execute_reply":"2021-05-25T12:22:36.139873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations-**\n* year - mileage -ve\n* mpg - tax -ve\n* fuelType - engineSize -ve","metadata":{}},{"cell_type":"markdown","source":"# Analyzing features using VIF","metadata":{}},{"cell_type":"code","source":"from statsmodels.stats.outliers_influence import variance_inflation_factor","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:23:36.283641Z","iopub.execute_input":"2021-05-25T12:23:36.28401Z","iopub.status.idle":"2021-05-25T12:23:36.404596Z","shell.execute_reply.started":"2021-05-25T12:23:36.283975Z","shell.execute_reply":"2021-05-25T12:23:36.403492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculating VIF\nvif = pd.DataFrame()\nvif[\"variables\"] = [feature for feature in categorical_features+numerical_features if feature not in ['year']]\nvif[\"VIF\"] = [variance_inflation_factor(df[vif['variables']].values, i) for i in range(len(vif[\"variables\"]))]\nprint(vif)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:23:46.651388Z","iopub.execute_input":"2021-05-25T12:23:46.651768Z","iopub.status.idle":"2021-05-25T12:23:46.732883Z","shell.execute_reply.started":"2021-05-25T12:23:46.651738Z","shell.execute_reply":"2021-05-25T12:23:46.731742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Looking at Outliers","metadata":{}},{"cell_type":"code","source":"NumericData = data[['mileage']]\nNumericMelt = NumericData.melt()\nplt.figure(figsize=(15,10))\nplt.title(\"Boxplots for Numerical variables\")\nbp = sns.boxplot(x='variable', y='value', data=NumericMelt)\nbp = sns.stripplot(x='variable', y='value', data=NumericMelt, jitter=True, edgecolor='gray')\nbp.set_xticklabels(bp.get_xticklabels(), rotation=90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:23:50.57622Z","iopub.execute_input":"2021-05-25T12:23:50.576869Z","iopub.status.idle":"2021-05-25T12:23:50.850175Z","shell.execute_reply.started":"2021-05-25T12:23:50.576834Z","shell.execute_reply":"2021-05-25T12:23:50.849181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NumericData = data[['year']]\nNumericMelt = NumericData.melt()\nplt.figure(figsize=(15,10))\nplt.title(\"Boxplots for Numerical variables\")\nbp = sns.boxplot(x='variable', y='value', data=NumericMelt)\nbp = sns.stripplot(x='variable', y='value', data=NumericMelt, jitter=True, edgecolor='gray')\nbp.set_xticklabels(bp.get_xticklabels(), rotation=90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:23:50.851606Z","iopub.execute_input":"2021-05-25T12:23:50.851918Z","iopub.status.idle":"2021-05-25T12:23:51.136456Z","shell.execute_reply.started":"2021-05-25T12:23:50.851888Z","shell.execute_reply":"2021-05-25T12:23:51.135464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NumericData = data[['engineSize']]\nNumericMelt = NumericData.melt()\nplt.figure(figsize=(15,10))\nplt.title(\"Boxplots for Numerical variables\")\nbp = sns.boxplot(x='variable', y='value', data=NumericMelt)\nbp = sns.stripplot(x='variable', y='value', data=NumericMelt, jitter=True, edgecolor='gray')\nbp.set_xticklabels(bp.get_xticklabels(), rotation=90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:23:51.480224Z","iopub.execute_input":"2021-05-25T12:23:51.480575Z","iopub.status.idle":"2021-05-25T12:23:51.746332Z","shell.execute_reply.started":"2021-05-25T12:23:51.480545Z","shell.execute_reply":"2021-05-25T12:23:51.745347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NumericData = data[['tax', 'mpg']]\nNumericMelt = NumericData.melt()\nplt.figure(figsize=(15,10))\nplt.title(\"Boxplots for Numerical variables\")\nbp = sns.boxplot(x='variable', y='value', data=NumericMelt)\nbp = sns.stripplot(x='variable', y='value', data=NumericMelt, jitter=True, edgecolor='gray')\nbp.set_xticklabels(bp.get_xticklabels(), rotation=90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:23:52.000684Z","iopub.execute_input":"2021-05-25T12:23:52.001173Z","iopub.status.idle":"2021-05-25T12:23:52.515351Z","shell.execute_reply.started":"2021-05-25T12:23:52.001142Z","shell.execute_reply":"2021-05-25T12:23:52.514269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Percentage of outliers present in each variable\noutlier_percentage = {}\nfor feature in numerical_features:\n    tempData = data.sort_values(by=feature)[feature]\n    Q1, Q3 = tempData.quantile([0.25, 0.75])\n    IQR = Q3 - Q1\n    Lower_range = Q1 - (1.5 * IQR)\n    Upper_range = Q3 + (1.5 * IQR)\n    outlier_percentage[feature] = round((((tempData<(Q1 - 1.5 * IQR)) | (tempData>(Q3 + 1.5 * IQR))).sum()/tempData.shape[0])*100,2)\noutlier_percentage","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:23:53.604788Z","iopub.execute_input":"2021-05-25T12:23:53.605182Z","iopub.status.idle":"2021-05-25T12:23:53.641749Z","shell.execute_reply.started":"2021-05-25T12:23:53.605147Z","shell.execute_reply":"2021-05-25T12:23:53.640496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Handling Categorical Features (Label Encoding & One Hot Encoding)","metadata":{}},{"cell_type":"code","source":"df = data.copy()\npath = '/kaggle/working'\nfor i, feature in enumerate(categorical_features):\n    \n    le = LabelEncoder()\n    ohe = OneHotEncoder(sparse=False)\n\n    # create directory to save label encoding models\n    if not os.path.exists(os.path.join(path, \"TextEncoding\")):\n        os.makedirs(os.path.join(path, \"TextEncoding\"))\n\n    # perform label encoding\n    le.fit(df[feature])\n    # save the encoder\n    joblib.dump(le, open(os.path.join(path, \"TextEncoding/le_{}.sav\".format(feature)), 'wb'))\n    \n    # transfrom training data\n    df[feature] = le.transform(df[feature])\n\n    # get classes & remove first column to elude from dummy variable trap\n    columns = list(map(lambda x: feature+' '+str(x), list(le.classes_)))[1:]\n    \n    # save classes\n    joblib.dump(columns, \n                open(os.path.join(path, \"TextEncoding/le_{}_classes.sav\".format(feature)), 'wb'))\n    # load classes\n    columns = joblib.load(\n        open(os.path.join(path, \"TextEncoding/le_{}_classes.sav\".format(feature)), 'rb'))\n\n    if len(le.classes_)>2:\n        # perform one hot encoding\n        ohe.fit(df[[feature]])\n        # save the encoder\n        joblib.dump(ohe, \n                    open(os.path.join(path, \"TextEncoding/ohe_{}.sav\".format(feature)), 'wb'))\n\n        # transfrom training data\n        # removing first column of encoded data to elude from dummy variable trap\n        tempData = ohe.transform(df[[feature]])[:, 1:]\n\n        # create Dataframe with columns as classes\n        tempData = pd.DataFrame(tempData, columns=columns)\n    else:\n        tempData = df[[feature]]\n    \n    # create dataframe with all the label encoded categorical features along with hot encoding\n    if i==0:\n        encodedData = pd.DataFrame(data=tempData, columns=tempData.columns.values.tolist())\n    else:\n        encodedData = pd.concat([encodedData, tempData], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:24:25.681403Z","iopub.execute_input":"2021-05-25T12:24:25.681806Z","iopub.status.idle":"2021-05-25T12:24:25.743871Z","shell.execute_reply.started":"2021-05-25T12:24:25.681765Z","shell.execute_reply":"2021-05-25T12:24:25.742818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# merge numerical features and categorical encoded features\ndf = df[numerical_features+['price']]\ndf = pd.concat([df, encodedData], axis=1)\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:24:28.538514Z","iopub.execute_input":"2021-05-25T12:24:28.538894Z","iopub.status.idle":"2021-05-25T12:24:28.565196Z","shell.execute_reply.started":"2021-05-25T12:24:28.538862Z","shell.execute_reply":"2021-05-25T12:24:28.56418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Model","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics, preprocessing\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import r2_score","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:24:36.812133Z","iopub.execute_input":"2021-05-25T12:24:36.812479Z","iopub.status.idle":"2021-05-25T12:24:37.036887Z","shell.execute_reply.started":"2021-05-25T12:24:36.812449Z","shell.execute_reply":"2021-05-25T12:24:37.035798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = df.copy()\nfeature_cols = [feature for feature in train_data.columns if feature not in(['price'])]\nprint('features used: ', feature_cols)\n\n# RESCALING\n#scaler = MinMaxScaler()\n#scaler.fit(train_data[feature_cols])\n#train_data[feature_cols] = scaler.transform(train_data[feature_cols])","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:24:37.057408Z","iopub.execute_input":"2021-05-25T12:24:37.057903Z","iopub.status.idle":"2021-05-25T12:24:37.065792Z","shell.execute_reply.started":"2021-05-25T12:24:37.057872Z","shell.execute_reply":"2021-05-25T12:24:37.064508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train_data[feature_cols]\ny = train_data['price']\n\nvalidation_size = 0.2\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=validation_size, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:24:37.248879Z","iopub.execute_input":"2021-05-25T12:24:37.249311Z","iopub.status.idle":"2021-05-25T12:24:37.269286Z","shell.execute_reply.started":"2021-05-25T12:24:37.249277Z","shell.execute_reply":"2021-05-25T12:24:37.268331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 1: Linear Regresssion ","metadata":{}},{"cell_type":"code","source":"model = LinearRegression()\nmodel.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:24:40.492391Z","iopub.execute_input":"2021-05-25T12:24:40.492752Z","iopub.status.idle":"2021-05-25T12:24:40.539394Z","shell.execute_reply.started":"2021-05-25T12:24:40.492722Z","shell.execute_reply":"2021-05-25T12:24:40.538203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_train)\n\nprint('Train metrics...')\nprint('RMSE: ', np.sqrt(mean_squared_error(y_train, y_pred)))\nprint('r2_score: ', round(r2_score(y_train, y_pred)*100, 2))\n\ny_pred = model.predict(X_test)\n\nprint('Validation metrics...')\nprint('RMSE: ', np.sqrt(mean_squared_error(y_test, y_pred)))\nprint('r2_score: ', round(r2_score(y_test, y_pred)*100, 2))","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:24:40.74079Z","iopub.execute_input":"2021-05-25T12:24:40.741146Z","iopub.status.idle":"2021-05-25T12:24:40.761514Z","shell.execute_reply.started":"2021-05-25T12:24:40.741116Z","shell.execute_reply":"2021-05-25T12:24:40.760565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.graph_objects as go\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=list(range(len(y_pred[-150:]))), y=y_pred[-150:],\n                         mode='lines',\n                         name='Prediction'))\nfig.add_trace(go.Scatter(x=list(range(len(y_test[-150:]))), y=y_test[-150:],\n                         mode='lines',\n                         name='True value'))\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:24:50.684856Z","iopub.execute_input":"2021-05-25T12:24:50.685205Z","iopub.status.idle":"2021-05-25T12:24:50.812049Z","shell.execute_reply.started":"2021-05-25T12:24:50.685176Z","shell.execute_reply":"2021-05-25T12:24:50.811038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 2: XGB","metadata":{"execution":{"iopub.status.busy":"2021-05-25T11:56:20.70531Z","iopub.execute_input":"2021-05-25T11:56:20.705762Z","iopub.status.idle":"2021-05-25T11:56:20.710464Z","shell.execute_reply.started":"2021-05-25T11:56:20.705731Z","shell.execute_reply":"2021-05-25T11:56:20.70918Z"}}},{"cell_type":"code","source":"model = XGBRegressor( \n    n_estimators = 1000,\n    learning_rate=0.09, \n    min_child_weight=5,\n    max_depth = 3,\n    subsample = 0.75,\n    seed=7)\n\n\nmodel = model.fit(\n    X_train, \n    y_train, \n    eval_metric=\"rmse\", \n    #early_stopping_rounds=10,\n    #eval_set=[(X_test, y_test)],\n    verbose=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:24:51.283628Z","iopub.execute_input":"2021-05-25T12:24:51.284107Z","iopub.status.idle":"2021-05-25T12:24:57.547526Z","shell.execute_reply.started":"2021-05-25T12:24:51.284046Z","shell.execute_reply":"2021-05-25T12:24:57.546438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_train)\n\nprint('Train metrics...')\nprint('RMSE: ', np.sqrt(mean_squared_error(y_train, y_pred)))\nprint('r2_score: ', round(r2_score(y_train, y_pred)*100, 2))\n\ny_pred = model.predict(X_test)\n\nprint('Validation metrics...')\nprint('RMSE: ', np.sqrt(mean_squared_error(y_test, y_pred)))\nprint('r2_score: ', round(r2_score(y_test, y_pred)*100, 2))","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:24:57.548946Z","iopub.execute_input":"2021-05-25T12:24:57.549252Z","iopub.status.idle":"2021-05-25T12:24:57.637203Z","shell.execute_reply.started":"2021-05-25T12:24:57.549223Z","shell.execute_reply":"2021-05-25T12:24:57.636212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.graph_objects as go\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=list(range(len(y_pred[-150:]))), y=y_pred[-150:],\n                         mode='lines',\n                         name='Prediction'))\nfig.add_trace(go.Scatter(x=list(range(len(y_test[-150:]))), y=y_test[-150:],\n                         mode='lines',\n                         name='True value'))\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:24:57.641114Z","iopub.execute_input":"2021-05-25T12:24:57.641443Z","iopub.status.idle":"2021-05-25T12:24:57.659443Z","shell.execute_reply.started":"2021-05-25T12:24:57.641413Z","shell.execute_reply":"2021-05-25T12:24:57.65833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}