{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PE05 Assignment using Team Project's dataset\n1. By now, you should have your team project topic finalized. Use the same dataset or a dataset that will help you have a better understanding of the problem you will be dealing with in your team project. Note: In order to make it simple, if your team project is not a binary classification problem, only select two of the classes for this assignment."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport sklearn\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading dataset\ndata = pd.read_csv(\"../input/did-it-rain-in-seattle-19482017/seattleWeather_1948-2017.csv\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I will drop the date column because it's hard to vectorizing date data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data processing\ndata = data.dropna(axis=0)\ndata = data.iloc[:, 1:5]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plotting All Data Points"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (10, 7))\nax = plt.axes(projection =\"3d\")\n\nax.set_xlabel(\"TMIN\")\nax.set_ylabel(\"TMAX\")\nax.set_zlabel(\"PRCP\")\nax.scatter3D(xs=data[\"TMIN\"],ys=data[\"TMAX\"],zs=data[\"PRCP\"], c=data[\"RAIN\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2.\tChoose 70% of your dataset as the training data for your Naïve Bayes classifier."},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2. Spliting Dataset\ntrain_set, test_set = train_test_split(data, train_size=0.7, test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_set.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data, train_lable = train_set.iloc[:, 0:3], train_set[\"RAIN\"].astype('int')\ntest_data, test_lable = test_set.iloc[:, 0:3], test_set[\"RAIN\"].astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3.\tA main assumption in the Naïve Bayes classifier is the independence of the features. Test the independence of features in your dataset. Does this satisfy the conditions of the Naïve Bayes algorithm?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlations between columns\ndata['RAIN'] = data['RAIN'].astype('int')\ncorr =data.corr()\ncorr.style.background_gradient(cmap='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Answer: The Maximum Temperature depends on the Minimum Temperature. RAIN depends on PRCP."},{"metadata":{"trusted":true},"cell_type":"code","source":"# NB_classifier with Full features\nfrom sklearn.naive_bayes import GaussianNB\nNB_classifier = GaussianNB().fit(train_data, train_lable)\nNB_classifier.score(test_data, test_lable)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# NB_classifier with PRCP + TMAX\ntrain_PRCP_TMAX = train_data[['PRCP','TMAX']]\nNB_classifier = GaussianNB().fit(train_PRCP_TMAX, train_lable)\nNB_classifier.score(test_data[['PRCP','TMAX']], test_lable)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# NB_classifier with PRCP + TMIN\ntrain_PRCP_TMAX = train_data[['PRCP','TMIN']]\nNB_classifier = GaussianNB().fit(train_PRCP_TMAX, train_lable)\nNB_classifier.score(test_data[['PRCP','TMIN']], test_lable)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# NB_classifier with TMAX + TMIN\ntrain_PRCP_TMAX = train_data[['TMAX','TMIN']]\nNB_classifier = GaussianNB().fit(train_PRCP_TMAX, train_lable)\nNB_classifier.score(test_data[['TMAX','TMIN']], test_lable)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# NB_classifier with only one column\n# PRCP\ntrain_PRCP_TMAX = train_data[['PRCP']]\nNB_classifier = GaussianNB().fit(train_PRCP_TMAX, train_lable)\nNB_classifier.score(test_data[['PRCP']], test_lable)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# TMAX\ntrain_PRCP_TMAX = train_data[['TMAX']]\nNB_classifier = GaussianNB().fit(train_PRCP_TMAX, train_lable)\nNB_classifier.score(test_data[['TMAX']], test_lable)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# TMIN\ntrain_PRCP_TMAX = train_data[['TMIN']]\nNB_classifier = GaussianNB().fit(train_PRCP_TMAX, train_lable)\nNB_classifier.score(test_data[['TMIN']], test_lable)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Conclusion: The PRCP is the key feature to predict whether it rains or not rain."},{"metadata":{},"cell_type":"markdown","source":"4.\tUse the additional 30% of your data as a testing dataset to predict which class they belong to and calculate the accuracy of the classifier and compare it with other classifiers you have used for this dataset. Which classifier fits best with this dataset so far?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# KNN Model\nfrom sklearn.neighbors import KNeighborsClassifier\nknn_cls = KNeighborsClassifier(n_neighbors=1).fit(train_data, train_lable)\nknn_cls.score(test_data, test_lable)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# DT Model\nfrom sklearn.tree import DecisionTreeClassifier\nDT_cls = DecisionTreeClassifier().fit(train_data, train_lable)\nDT_cls.score(test_data, test_lable)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Conclusion: Decision Tree Model == Naive Bayes >> K-Nearest Neighbors\nDecision Tree and Naive Bayes classifiers have the same accuracy, KNN has relatively low accuracy."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}