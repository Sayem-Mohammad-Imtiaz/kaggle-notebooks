{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ndf = pd.read_csv('/kaggle/input/brasilian-houses-to-rent/houses_to_rent_v2.csv')\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()['rent amount (R$)']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['hoa (R$)','total (R$)']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sns.pairplot(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1 Data Cleaning and Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,10))\nsns.heatmap(df.corr(),cmap='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()['rent amount (R$)'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Fire insurance has a very strong positive correlation with rent amount which may indicate that the value is proportional to the value of rent. As such, we should consider taking this feature out of the data set\nOn another note, it would also make sense to exclude total, property tax, and hoa from the data set, like fire insurance, are computed during the point of knowing the rent. Retaining these features would only cause data leakage."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['total (R$)','property tax (R$)','hoa (R$)','fire insurance (R$)'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in df.select_dtypes('object'):\n    print(i,df[i].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Based on the observed unique instances of the feature `floor`, '1' and '-' seem to indicated the same thing. However, a better inference would be that `floor` indicates which floor of an appartment/condominium building is located. As such it would make sense to add another column to identify whether the property being rented is an appartment unit or not. Another, interpretation could be to to treat '-' as a null value and will be imputed and partnered with a isnull column. For the sake of having a baselin, let's indicate the '-' value first as 0 and observe performance and revisit abovementioned ideas later on."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['floor'] = df['floor'].apply(lambda x: 0 if x == '-' else x).astype(int)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2 Feature Engineering"},{"metadata":{},"cell_type":"markdown","source":"> Below are some feature engineering ideas that would also be interesting to explore apart from the usual OneHotEncoding."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['avg_area_per_division'] = df['area']/(df['bathroom']+df['rooms']+1) # plus 1 for common/living area\ndf['bathroom_room_ratio'] = df['bathroom']/df['rooms']\ndf['unique_inclusions_cnt'] = np.where(df['parking spaces']>0,1,0)+np.where(df['furniture']=='furnished',1,0)+np.where(df['animal']=='acept',1,0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split,cross_validate\nfrom sklearn.preprocessing import OneHotEncoder,StandardScaler,PowerTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\n\n\nonehot = OneHotEncoder(sparse=False,handle_unknown='ignore')\nscaler = PowerTransformer()\nsd = StandardScaler()\n\n\nX = df.drop(columns=['rent amount (R$)'])\ny = df['rent amount (R$)']\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_cols = X_train.select_dtypes('object').columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_cols = X_train.select_dtypes('int').columns.tolist()+X_train.select_dtypes('float').columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_transform_sd = ColumnTransformer([('onehot',onehot,cat_cols),('scaler',sd,num_cols)])\ncol_transform_pt = ColumnTransformer([('onehot',onehot,cat_cols),('scaler',scaler,num_cols)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3 Baseline Model & Scaler Comparison"},{"metadata":{"trusted":true},"cell_type":"code","source":"baseline = Pipeline(steps=[('preprocess',col_transform_sd),('model',LinearRegression())])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_score = cross_validate(baseline,X_train,y_train,scoring='r2',cv=5,return_train_score=True)\nprint(\"Train Score: \",np.mean(base_score['train_score']))\nprint(\"Test Score: \",np.mean(base_score['test_score']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"power_tranform = Pipeline(steps=[('preprocess',col_transform_pt),('model',LinearRegression())])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pt_score = cross_validate(power_tranform,X_train,y_train,scoring='r2',cv=5,return_train_score=True)\nprint(\"Train Score: \",np.mean(pt_score['train_score']))\nprint(\"Test Score: \",np.mean(pt_score['test_score']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> It is clear that applying an exponential scaling transforms the numerical data into normal distributions which are highly compatible with LinearRegression models. Apart from this, we can also observe that with StandardScaler the model overfits. As such, we shall be using PowerTransformer moving forward."},{"metadata":{},"cell_type":"markdown","source":"# 4 Feature Interactions & Improvements"},{"metadata":{"trusted":true},"cell_type":"code","source":"add_cat = []\nfor x in cat_cols:\n    for y in cat_cols:\n        pass\n    add_cat.append(pd.Series(df[x]+'_'+df[y],name=x+'_'+y))\ncat_interactions = pd.concat(add_cat,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_interactions = pd.concat([df,cat_interactions],axis=1)\n\nX = df_interactions.drop(columns=['rent amount (R$)'])\ny = df_interactions['rent amount (R$)']\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Update ColumnTransformer\nnum_cols = X_train.select_dtypes('int').columns.tolist()+X_train.select_dtypes('float').columns.tolist()\ncat_cols = X_train.select_dtypes('object').columns.tolist()\n\ncol_transform_pt = ColumnTransformer([('onehot',onehot,cat_cols),('scaler',scaler,num_cols)])\n\npower_tranform = Pipeline(steps=[('preprocess',col_transform_pt),('model',LinearRegression())])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pt_score = cross_validate(power_tranform,X_train,y_train,scoring='r2',cv=5,return_train_score=True)\nprint(\"Train Score: \",np.mean(pt_score['train_score']))\nprint(\"Test Score: \",np.mean(pt_score['test_score']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Slight Improvement on Train and Test scores. However, the model overfits slightly as well."},{"metadata":{},"cell_type":"markdown","source":"> Now let's try feature interactions on numerical features via PolynomialFeatures to see if there is improvement on the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import PolynomialFeatures\n\nnum_inter = PolynomialFeatures(interaction_only=True)\n\nX = df.drop(columns=['rent amount (R$)'])\ny = df['rent amount (R$)']\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_cols = X_train.select_dtypes('int').columns.tolist()+X_train.select_dtypes('float').columns.tolist()\ncat_cols = X_train.select_dtypes('object').columns.tolist()\n\nnum_preprocess = Pipeline(steps=[('interactions',num_inter),('scaler',scaler)])\n\ncol_transform_pt = ColumnTransformer([('onehot',onehot,cat_cols),('num_preprocess',num_preprocess,num_cols)])\n\npower_tranform = Pipeline(steps=[('preprocess',col_transform_pt),('model',LinearRegression())])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pt_score = cross_validate(power_tranform,X_train,y_train,scoring='r2',cv=5,return_train_score=True)\nprint(\"Train Score: \",np.mean(pt_score['train_score']))\nprint(\"Test Score: \",np.mean(pt_score['test_score']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> There is a sizeable increase on performance with Numerical Feature Interactions. Let's see what happens when we incorporate both numerical and categorical."},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_interactions.drop(columns=['rent amount (R$)'])\ny = df_interactions['rent amount (R$)']\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_cols = X_train.select_dtypes('int').columns.tolist()+X_train.select_dtypes('float').columns.tolist()\ncat_cols = X_train.select_dtypes('object').columns.tolist()\n\nnum_preprocess = Pipeline(steps=[('interactions',num_inter),('scaler',scaler)])\n\ncol_transform_pt = ColumnTransformer([('onehot',onehot,cat_cols),('num_preprocess',num_preprocess,num_cols)])\n\npower_tranform = Pipeline(steps=[('preprocess',col_transform_pt),('model',LinearRegression())])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pt_score = cross_validate(power_tranform,X_train,y_train,scoring='r2',cv=5,return_train_score=True)\nprint(\"Train Score: \",np.mean(pt_score['train_score']))\nprint(\"Test Score: \",np.mean(pt_score['test_score']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Very minute improvement. We can get away with not including Categorical Feature Interactions but for now let's just stick with it as if we are fighting for every point of improvement."},{"metadata":{},"cell_type":"markdown","source":"# 5 Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"power_tranform.fit(X_train,y_train)\ntrain_preds = power_tranform.predict(X_train)\ntest_preds = power_tranform.predict(X_test)\n\nprint(\"Train Score :\",r2_score(y_train,train_preds))\nprint(\"Test Score :\",r2_score(y_test,test_preds))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}