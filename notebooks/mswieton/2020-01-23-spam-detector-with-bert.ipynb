{"cells":[{"metadata":{},"cell_type":"markdown","source":"This notebook contains a simple spam classifier trained on the SMS Spam Collection Dataset (data source: https://www.kaggle.com/uciml/sms-spam-collection-dataset).\n\nIn this version, a pre-trained BERT model is adopted and fine-tuned on the SMS texts corpus. A tensorflow_hub version of BERT - easily accessible as a Keras layer - is applied. To allow for fine-tuning, its 'trainable' parameter is set to 'True'. This part of code, as well as an inspiration for using the BERT model this way, was taken from this great notebook: https://www.kaggle.com/xhlulu/disaster-nlp-keras-bert-using-tfhub.\n\nImbalance of classes (only 747 instances of \"spam\") is compensated by setting custom class weights for the training loss function.\n\nOnce trained, the model can be used for inference, i.e. predicting whether a particular SMS would be classified as \"spam\" or not. For test purposes, I handcrafted a bunch of messages which I would definitely not want to appear on my phone. A helper function 'check_if_spam' can be used to check for any other message (try it yourself...). Notice that due to very small size of the training sample, model predictions frequently run counterintuitive. More precisely, plenty of 'suspicious' texts are classified as non-spam.\n\nI took an inspiration for this project from the book: \nGULLI, KAPOOR, PAL [2019]: Deep Learning with TensorFlow 2 and Keras - Second Edition, Packt Publishing."},{"metadata":{},"cell_type":"markdown","source":"### Setup & Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"PATH = '/kaggle/input/sms-spam-collection-dataset/'\n!ls $PATH","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\ntf.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Model\n\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nimport tensorflow_hub as hub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing the official tokenization script created by the Google team\n!wget https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py\n\nimport tokenization","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data loading & inspection"},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_data = pd.read_csv(PATH+'spam.csv', encoding='latin_1')\nsms_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking for missing values\n\nsms_data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dropping (almost) empty columns as not important\n\ncols_to_drop = ['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4']\nsms_data.drop(columns=cols_to_drop, inplace=True)\nsms_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# renaming feature and target columns\nfeat_name = 'sms_text'\ntarget_name = 'spam'\nsms_data.columns = [target_name, feat_name]\n\n# encoding (binary) target variable\nsms_data['target'] = [1 if is_spam == 'spam' else 0 for is_spam in sms_data['spam']]\n\nsms_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking (binary) target distribution\n\nsms_data['spam'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking if all sms texts are unique\n\nlen(sms_data['sms_text'].unique()) == len(sms_data['sms_text'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model import & data preparation"},{"metadata":{},"cell_type":"markdown","source":"#### model architecture: \n\nBERT model available from the TensorFlow Hub\n\nembedding weights are fine-tuned as a part of model training\n\nSOURCE for code and inspiration: https://www.kaggle.com/xhlulu/disaster-nlp-keras-bert-using-tfhub; sincere thanks @xhlulu for sharing"},{"metadata":{},"cell_type":"markdown","source":"##### BERT helper functions to encode texts and build model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def bert_encode(texts, tokenizer, max_len=512):\n    all_tokens = []\n    all_masks = []\n    all_segments = []\n    \n    for text in texts:\n        text = tokenizer.tokenize(text)\n            \n        text = text[:max_len-2]\n        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n        pad_len = max_len - len(input_sequence)\n        \n        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n        tokens += [0] * pad_len\n        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n        segment_ids = [0] * max_len\n        \n        all_tokens.append(tokens)\n        all_masks.append(pad_masks)\n        all_segments.append(segment_ids)\n    \n    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# setting model optimization parameters:\noptimizer = Adam(lr=2e-6)\nloss = 'binary_crossentropy'\nmetrics = ['accuracy']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(bert_layer, max_len=512):\n    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n    input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n    segment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n\n    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n    clf_output = sequence_output[:, 0, :]\n    out = Dense(1, activation='sigmoid')(clf_output)\n    \n    model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Loading BERT from TensorFlow Hub"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nmodule_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\"\nbert_layer = hub.KerasLayer(module_url, trainable=True)\nbert_layer","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Data tokenization"},{"metadata":{"trusted":true},"cell_type":"code","source":"# setting the tokenizer parameters\nvocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\ndo_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n\ntokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# encoding \"train\" and \"test\" datasets with the 'bert_encode' helper function\n\ntrain_input = bert_encode(sms_data['sms_text'].values, tokenizer, max_len=189)\n\nnum_seq = train_input[0].shape[0]\nlen_seq = train_input[0].shape[1]\n\nprint('Encoded {} sequences and padded for equal length of {} tokens'\n      .format(num_seq, len_seq))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels = sms_data['target'].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Modelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_model(bert_layer, max_len=189)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### setting training parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 16\nepochs = 10\n\n# setting up the \"EarlyStopping\" callback\nearly_stop = EarlyStopping(monitor='val_loss', \n                           min_delta=0, \n                           patience=3, \n                           verbose=True, \n                           mode='auto', \n                           baseline=None, \n                           restore_best_weights=False)\n\ncallbacks = [early_stop]\n\nvalidation_split = 0.20\n\n# setting class weights for the loss function to adjust for class imbalance\n# 'spam' is set to weight 8x more\nclass_weight = {0: 1, 1: 8}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# training model with validation and early stopping\n\nmodel.fit(x=train_input, y=train_labels, \n          batch_size=batch_size, epochs=epochs, \n          verbose=True, callbacks=callbacks, \n          validation_split=validation_split, \n          class_weight=class_weight)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Learning history"},{"metadata":{"trusted":true},"cell_type":"code","source":"# showing history of 'accuracy'\n\nplt.figure()\nplt.plot(model.history.history['accuracy'], label='TRAIN ACC')\nplt.plot(model.history.history['val_accuracy'], label='VAL ACC')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# showing history of 'loss'\n\nplt.figure()\nplt.plot(model.history.history['loss'], label='TRAIN LOSS')\nplt.plot(model.history.history['val_loss'], label='VAL LOSS')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Model evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# making predictions for training sequences (in-sample check)\n\npredictions = model.predict(train_input)\npredictions.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_classes = (predictions > 0.5).astype(int)\npred_classes.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# showing confusion matrix\n\ncm = confusion_matrix(y_true=train_labels, y_pred=pred_classes)\ncm = pd.DataFrame(cm)\ncm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting the confusion matrix heatmap\n\nplt.figure(figsize=(6,4))\nsns.heatmap(cm, annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Re-training the model on full train data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# setting the optimal number of epochs\n\nepochs = early_stop.stopped_epoch + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x=train_input, y=train_labels, \n          batch_size=batch_size, epochs=epochs, \n          verbose=True, \n          class_weight=class_weight)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predicting"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nhelper function: check if a SMS text provided would be classified as spam or not\nargument: <string> with SMS text to be checked\nif no argument provided, read the user's input\n\"\"\"\n\ndef check_if_spam(sms=None):\n\n    # read user's input if no argument provided\n    if sms is None:\n        sms = input('Enter SMS text: ')\n    \n    # tokenize the SMS text and pad sequence to match training sequences length\n    sms = [sms,]\n    sequence = bert_encode(sms, tokenizer, max_len=189)\n        \n    # predict class and give feedback\n    prediction = model.predict(sequence)\n    pred_class = (prediction > 0.5).astype(int)\n    is_spam = 'This is SPAM !!!' if pred_class == 1 else 'This is not spam.'\n        \n    return is_spam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_sample = ['Final chance to win free tickets. Call now!', \n             'Suspicious activity detected. Follow this link to change password immediately.',\n             'Get over here and call me tonite. Only 2 USD for minute.',\n             'What are you waiting for! These are final days of our xmass promo deals.',\n             'We have new offers for you. Visit our webpage and see.',\n             'Binary FX options trading and 100 USD on your account. Hurry up.',\n             'Huge discounts this weekend. Check this site to learn more.',\n             'You can also earn easy money. Call us now.',\n             'Congratulations! to claim your reward you must reply immediately',\n             'For our database update we need a contact from you. Call us at.'\n            ]\n\nfor text in my_sample:\n    print('\\nChecking:     ', text)\n    print(check_if_spam(text))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# call the 'check_if_spam' function with no arguments to provide custom text\n# uncomment to see in action\n\n# check_if_spam()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# helper script to show random \"spam message\"\n\nspams = sms_data[sms_data['spam'] == 'spam']\nidx = np.random.randint(len(spams))\nspam = spams.iloc[idx]['sms_text']\nprint(spam)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}