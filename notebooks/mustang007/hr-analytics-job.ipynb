{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# important libraries\nimport numpy as np # linear algebra\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import tree\n\nfrom kmodes.kprototypes import KPrototypes\nfrom sklearn.metrics import silhouette_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/hr-analytics-job-change-of-data-scientists/aug_train.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_col = 'target'\n\nprint('Total number of rows =',train.shape[0])\nprint('Total number of columns =',train.shape[1])\nprint('===================================')\nprint(train.info())\nprint('===================================')\nfor i in train.columns:\n    null_value = train[i].isnull().sum()\n    if null_value > 0 :\n        print(f'This column {i} has = {null_value}')\n        \n# Majority of our data is object type","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# last_new_job \nprint(train.last_new_job.value_counts())\nprint(train.last_new_job.shape)\ntrain.last_new_job.fillna('never',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# company_size\nprint(train.company_size.value_counts())\nprint(train.company_size.shape)\nprint('==================================')\n# company_type\nprint(train.company_type.value_counts())\nprint(train.company_type.shape)\n\n\n# we will deal with them together, if both are null values let create our own company\n# with company_size = 100, company_type = other\ntrain.company_size.fillna('0-100',inplace=True)\ntrain.company_type.fillna('Other',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# experience\nprint(train.experience.value_counts())\nprint(train.experience.shape)\n\n# Lets fill null values with 0 \ntrain.experience.fillna(0 ,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# major_discipline\nprint(train.major_discipline.value_counts())\nprint(train.major_discipline.shape)\n\n# With high school as education level, major discipline has null values \n# lets give another category to them as 'Not_applicable'\ntrain.major_discipline.fillna('Not_applicable',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# education_level\nprint(train.education_level.value_counts())\nprint(train.education_level.shape)\n# if you notice if education level is null then major too is none, lets drop them as per now\ntrain.dropna(subset=['education_level'], inplace=True)\nprint(train.education_level.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# enrolled_university\nprint(train.enrolled_university.value_counts())\n# lets assume null values that they have not enrolled\ntrain.enrolled_university.fillna('no_enrollment',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets impute null values after understanding each column one by one\n# gender\nprint(train.gender.value_counts())\n# as there are 4508 null values, that mean either they forget of mention or they dont want to reveal\n# lets give them with other category only\ntrain.gender.fillna('Other',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# As we are done with filling null values, Lets do some visualization to understand data\n# our main agenda to find which factor contribute more towards our target col i.e target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.city.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfig, axs = plt.subplots(nrows=4,ncols=2, figsize=(15,20))\nsns.countplot(x=\"relevent_experience\",hue='target', data=train, ax=axs[0,0])\nsns.countplot(x=\"enrolled_university\",hue='target', data=train, ax=axs[0,1])\nsns.countplot(x=\"education_level\",hue='target', data=train, ax=axs[1,0])\nsns.countplot(x=\"major_discipline\",hue='target', data=train, ax=axs[1,1])\nsns.countplot(x=\"experience\",hue='target', data=train, ax=axs[2,0])\nsns.countplot(x=\"company_size\",hue='target', data=train, ax=axs[2,1])\nsns.countplot(x=\"company_type\",hue='target', data=train, ax=axs[3,0])\nsns.countplot(x=\"last_new_job\",hue='target', data=train, ax=axs[3,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cdi = train.sort_values(by='city_development_index', ascending=True)[:1000]\nfigure = plt.figure(figsize=(10,6))\nsns.barplot(y=cdi.city, x=cdi.city_development_index)\nplt.xticks()\nplt.xlabel('city_development_index')\nplt.ylabel('city')\nplt.title('City by city development index')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(train['city_development_index'])","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"! pip install dython\nfrom dython.model_utils import roc_graph\nfrom dython.nominal import associations\n\n# we will use this for finding corrleation between cateogrical columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Cat_data = train[['city_development_index','training_hours',\n                 'city','gender','relevent_experience',\n               'enrolled_university','education_level',\n              'major_discipline','experience','company_size','company_type',\n              'last_new_job','target']]\ndef associations_example():\n    cols = associations(Cat_data,nominal_columns=['city','gender','relevent_experience',\n                                           'enrolled_university','education_level',\n                                          'major_discipline','experience','company_size','company_type',\n                                          'last_new_job','target'])\n    df = pd.DataFrame(cols['corr'])\n    return df\n#     cm = data[cols].corr()\n    \nplt.rcParams[\"figure.figsize\"]=15,10\ndf = associations_example()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df.tail(1)\ndf = df.sort_values('target', axis=0, ascending=False, inplace=False, kind='quicksort', na_position='last')\ndf[['target']]\n\n# these help us to know how these fators has correlation with target col.\n# as we will be using tree classifier so no need to worry about high correalation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=train.drop(['target'],axis=1)\nX.corrwith(train['target']).plot.bar(\n        figsize = (10, 5), title = \"Correlation with Target\", fontsize = 10,\n        rot = 50, grid = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets use decsion tree for seeing which col are determining factor\n#first we need to convert categorical column into integer\ncat_cols = ['city','relevent_experience','gender','relevent_experience',\n           'enrolled_university','education_level',\n           'major_discipline','experience','company_size',\n           'company_type','last_new_job']\nfor i in cat_cols:\n    # empty dictionary\n    my_dict = {}\n    u_v = pd.DataFrame(train[i].value_counts())\n    u_v['index'] = u_v.index\n    for p,q in enumerate(u_v.index):\n        my_dict.update({q:p})        \n    train[i] = train[i].replace(my_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop(columns='enrollee_id')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.drop(columns='target')\nY = train['target']\nX_train, X_test, y_train, y_test = train_test_split( X, Y, test_size=0.23, random_state=42, stratify=Y)\nclf = tree.DecisionTreeClassifier()\nclf = clf.fit(X_train, y_train)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valuable_cols = pd.DataFrame(clf.feature_importances_)\nvaluable_cols['index'] = X_train.columns\nvaluable_cols = valuable_cols.sort_values(by=0, ascending=False)\nsns.barplot(y='index',x=0,data=valuable_cols)\n\n\n# This tells us feature which will act as deciding factor","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" K-Prototype clustering"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Getting the list of Numerical and Categorical Variables\nnum_cols = train._get_numeric_data().columns\nprint (num_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Choosing optimal K value\n# cost = []\n# X = train\n# for num_clusters in list(range(2,7)):\n#     kproto = KPrototypes(n_clusters=num_clusters, init='Huang', random_state=42,n_jobs=-2,max_iter=15,n_init=50) \n#     kproto.fit_predict(X, categorical=[0])\n#     cost.append(kproto.cost_)\n\n# plt.plot(cost)\n# plt.xlabel('K')\n# plt.ylabel('cost')\n# plt.show\n\n\n# it came to be 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Running K-Prototype clustering\nX = train\nkproto = KPrototypes(n_clusters=2, init='Huang', verbose=0, random_state=42,max_iter=20, n_init=50,n_jobs=-2,gamma=.25) \nclusters = kproto.fit_predict(X, categorical=[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate Silhoutte Score\n#\nscore = silhouette_score(X, clusters, metric='euclidean')\n#\n# Print the score\n# \nprint('Kprototype Silhouetter Score: %.3f' % score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We have segregated into two cluster lets analysze it\ncluster_data = train.copy()\ncluster_data['cluster'] = clusters\ncluster_data_0 = cluster_data[cluster_data['cluster']==0].reset_index(drop=True)\ncluster_data_1 = cluster_data[cluster_data['cluster']==1].reset_index(drop=True)\n\n#################################################################\n\n\nfig, axs = plt.subplots(nrows=4,ncols=2, figsize=(15,20))\nsns.countplot(x=\"relevent_experience\",hue='target', data=cluster_data_0, ax=axs[0,0])\nsns.countplot(x=\"relevent_experience\",hue='target', data=cluster_data_1, ax=axs[0,1])\nsns.countplot(x=\"education_level\",hue='target', data=cluster_data_0, ax=axs[1,0])\nsns.countplot(x=\"education_level\",hue='target', data=cluster_data_1, ax=axs[1,1])\nsns.countplot(x=\"experience\",hue='target', data=cluster_data_0, ax=axs[2,0])\nsns.countplot(x=\"experience\",hue='target', data=cluster_data_1, ax=axs[2,1])\nsns.countplot(x=\"company_type\",hue='target', data=cluster_data_0, ax=axs[3,0])\nsns.countplot(x=\"company_type\",hue='target', data=cluster_data_1, ax=axs[3,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feat=train.drop(['target'],axis=1)\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=4)\npca_result = pca.fit_transform(feat.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"components = pd.DataFrame(np.round(pca.components_, 6), columns = list(feat.keys()))\ncomponents","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ratios = pca.explained_variance_ratio_.reshape(len(pca.components_), 1)\nvariance_ratios = pd.DataFrame(np.round(ratios, 4), columns = ['Explained Variance'])\nvariance_ratios.index = [1,2,3,4]\nvariance_ratios\n\n# In Pca first component explain 88% of the data followed by other components","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(nrows=2,figsize = (15,15))\n\n#  Plot the feature weights as a function of the components\ncomponents.iloc[:,5:].plot(ax = ax[0], kind = 'bar')\ncomponents.iloc[:,:5].plot(ax = ax[1], kind = 'bar')\n\n# we can see training_hours,city, experince, company_size are quite important which is already explained above","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **If you like my work please upvote**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}