{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":" ## IMPORTING LIBRARIES","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n","metadata":{"execution":{"iopub.status.busy":"2021-09-09T16:48:41.114611Z","iopub.execute_input":"2021-09-09T16:48:41.11524Z","iopub.status.idle":"2021-09-09T16:48:41.12135Z","shell.execute_reply.started":"2021-09-09T16:48:41.115173Z","shell.execute_reply":"2021-09-09T16:48:41.119901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CREATING PIPELINES","metadata":{}},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nmy_pipeline= Pipeline([('std_scaler',StandardScaler())])","metadata":{"execution":{"iopub.status.busy":"2021-09-09T16:48:41.123571Z","iopub.execute_input":"2021-09-09T16:48:41.124063Z","iopub.status.idle":"2021-09-09T16:48:41.138727Z","shell.execute_reply.started":"2021-09-09T16:48:41.124016Z","shell.execute_reply":"2021-09-09T16:48:41.137028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = pd.read_csv('../input/breast-cancer-wisconsin-data/data.csv')","metadata":{"execution":{"iopub.status.busy":"2021-09-09T16:48:41.140828Z","iopub.execute_input":"2021-09-09T16:48:41.14141Z","iopub.status.idle":"2021-09-09T16:48:41.172415Z","shell.execute_reply.started":"2021-09-09T16:48:41.141375Z","shell.execute_reply":"2021-09-09T16:48:41.171195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"dataset.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T16:48:41.173888Z","iopub.execute_input":"2021-09-09T16:48:41.174367Z","iopub.status.idle":"2021-09-09T16:48:41.207994Z","shell.execute_reply.started":"2021-09-09T16:48:41.174336Z","shell.execute_reply":"2021-09-09T16:48:41.206833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.drop('Unnamed: 32', axis =1)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T16:48:41.209685Z","iopub.execute_input":"2021-09-09T16:48:41.21006Z","iopub.status.idle":"2021-09-09T16:48:41.21623Z","shell.execute_reply.started":"2021-09-09T16:48:41.210027Z","shell.execute_reply":"2021-09-09T16:48:41.215114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.describe()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T16:48:41.217518Z","iopub.execute_input":"2021-09-09T16:48:41.218069Z","iopub.status.idle":"2021-09-09T16:48:41.321801Z","shell.execute_reply.started":"2021-09-09T16:48:41.217983Z","shell.execute_reply":"2021-09-09T16:48:41.321019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.isnull().values.any()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T16:48:41.32295Z","iopub.execute_input":"2021-09-09T16:48:41.32338Z","iopub.status.idle":"2021-09-09T16:48:41.330019Z","shell.execute_reply.started":"2021-09-09T16:48:41.323347Z","shell.execute_reply":"2021-09-09T16:48:41.329276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"No null values have been detected in the dataset,so we can move ahead.","metadata":{}},{"cell_type":"code","source":"dataset.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T16:48:41.332838Z","iopub.execute_input":"2021-09-09T16:48:41.333389Z","iopub.status.idle":"2021-09-09T16:48:41.347911Z","shell.execute_reply.started":"2021-09-09T16:48:41.333344Z","shell.execute_reply":"2021-09-09T16:48:41.346932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-09T16:48:41.349966Z","iopub.execute_input":"2021-09-09T16:48:41.350509Z","iopub.status.idle":"2021-09-09T16:48:41.361985Z","shell.execute_reply.started":"2021-09-09T16:48:41.35046Z","shell.execute_reply":"2021-09-09T16:48:41.360698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset['diagnosis'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T16:48:41.363622Z","iopub.execute_input":"2021-09-09T16:48:41.364016Z","iopub.status.idle":"2021-09-09T16:48:41.380885Z","shell.execute_reply.started":"2021-09-09T16:48:41.363981Z","shell.execute_reply":"2021-09-09T16:48:41.379835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plotting Features in the form of Histograms","metadata":{}},{"cell_type":"code","source":"dataset.hist(bins=50,figsize=(20,15),color='violet',lw=0)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T16:48:41.382529Z","iopub.execute_input":"2021-09-09T16:48:41.383149Z","iopub.status.idle":"2021-09-09T16:48:49.132849Z","shell.execute_reply.started":"2021-09-09T16:48:41.383102Z","shell.execute_reply":"2021-09-09T16:48:49.13168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Splitting the data into test & train set","metadata":{}},{"cell_type":"code","source":"X = dataset.iloc[:,2:].values\nY = dataset.iloc[:, 1:2].values\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nY = le.fit_transform(Y.ravel())\n\nfrom sklearn.model_selection import train_test_split\nX_train_set,X_test_set,Y_train,Y_test= train_test_split(X,Y,test_size=0.2,random_state=42)\nprint(f\"Rows in X train set: {len(X_train_set)}\\nRows in X test set: {len(X_test_set)}\")","metadata":{"execution":{"iopub.status.busy":"2021-09-09T16:48:49.134584Z","iopub.execute_input":"2021-09-09T16:48:49.135038Z","iopub.status.idle":"2021-09-09T16:48:49.147601Z","shell.execute_reply.started":"2021-09-09T16:48:49.134984Z","shell.execute_reply":"2021-09-09T16:48:49.146462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train=my_pipeline.fit_transform(X_train_set)\nX_test= my_pipeline.transform(X_test_set)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T16:48:49.149083Z","iopub.execute_input":"2021-09-09T16:48:49.14943Z","iopub.status.idle":"2021-09-09T16:48:49.165165Z","shell.execute_reply.started":"2021-09-09T16:48:49.149399Z","shell.execute_reply":"2021-09-09T16:48:49.163935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20, 12))\nmatrix = np.triu(dataset.corr())\nsns.heatmap(dataset.corr(), annot=True, linewidth=1, mask=matrix, cmap=\"magma\");","metadata":{"execution":{"iopub.status.busy":"2021-09-09T16:48:49.167559Z","iopub.execute_input":"2021-09-09T16:48:49.168141Z","iopub.status.idle":"2021-09-09T16:48:52.368105Z","shell.execute_reply.started":"2021-09-09T16:48:49.168093Z","shell.execute_reply":"2021-09-09T16:48:52.366903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#**We can see that some features have very strong positive correlations and some have very strong negative correlations,hence,we plot these features.Here,we have perimeter_mean,radius_mean,area_mean,perimeter_worst,radius_worst,fractal_dimension_worst,fractal_dimension_meansmoothness_se,symmetry_se these features which give us these correlations.Now,we plot these features with respect to each other**","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(2, 4, figsize=(18, 12))\nsns.scatterplot(x='perimeter_mean', y='radius_mean', hue=\"diagnosis\",\n                data=dataset, ax=ax[0][0], palette='magma')\nsns.scatterplot(x='area_mean', y='radius_mean', hue=\"diagnosis\",\n                data=dataset, ax=ax[0][1], palette='magma')\nsns.scatterplot(x='area_mean', y='perimeter_mean', hue=\"diagnosis\",\n                data=dataset, ax=ax[0][2], palette='magma')\nsns.scatterplot(x='perimeter_worst', y='radius_worst', hue=\"diagnosis\",\n                data=dataset, ax=ax[0][3], palette='magma')\nsns.scatterplot(x='fractal_dimension_mean', y='area_mean', hue=\"diagnosis\",\n                data=dataset, ax=ax[1][0], palette='magma')\nsns.scatterplot(x='fractal_dimension_worst', y='area_worst', hue=\"diagnosis\",\n                data=dataset, ax=ax[1][1], palette='magma')\nsns.scatterplot(x='smoothness_se', y='radius_worst', hue=\"diagnosis\",\n                data=dataset, ax=ax[1][2], palette='magma')\nsns.scatterplot(x='symmetry_se', y='radius_worst', hue=\"diagnosis\",\n                data=dataset, ax=ax[1][3], palette='magma');\n","metadata":{"execution":{"iopub.status.busy":"2021-09-09T16:48:52.369663Z","iopub.execute_input":"2021-09-09T16:48:52.370011Z","iopub.status.idle":"2021-09-09T16:48:54.824639Z","shell.execute_reply.started":"2021-09-09T16:48:52.369974Z","shell.execute_reply":"2021-09-09T16:48:54.823841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EVALUATING EACH MODEL:","metadata":{}},{"cell_type":"markdown","source":" ## Logistic Regression Model","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nmodel1=LogisticRegression(random_state=0)\nmodel1.fit(X_train,Y_train)\n\nfrom sklearn.model_selection import cross_val_score\nscores1=cross_val_score(model1,X_train,Y_train,scoring=\"accuracy\",cv=10)\n#rmse would be required in regression\n#rmse_scores=np.sqrt(-scores)\n#rmse_scores\n\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\nprint('''Prediciting Test Set Result for Logistic Regression''')\nY_pred = model1.predict(X_test)\nresult = np.concatenate((Y_pred.reshape(len(Y_pred), 1),Y_test.reshape(len(Y_test), 1)), 1)\nprint(result,'\\n')\nprint('''Making Confusion Matrix''')\nY_pred = model1.predict(X_test)\ncm = confusion_matrix(Y_test, Y_pred)\nprint(cm,'\\n')\nprint('True Positives :',cm[0][0])\nprint('False Positives :',cm[0][1])\nprint('False Negatives :',cm[1][0])\nprint('True Negatives :', cm[0][1],'\\n')\n\nprint('''Classification Report''')\nprint(classification_report(Y_test, Y_pred,target_names=['M', 'B'], zero_division=1))\n\nprint('''Evaluating Logistic Regression Model Performance''')\naccuracy = accuracy_score(Y_test, Y_pred)\nprint(accuracy,'\\n')\n\nprint('''Applying Cross validation''')\nfrom sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(model1, X_train, Y_train, cv=10)\nprint(\"Accuracy for Linear Regression: {:.2f} %\".format(accuracies.mean()*100))\nprint(\"Standard Deviation for Linear Regression: {:.2f} %\".format(accuracies.std()*100),'\\n')","metadata":{"execution":{"iopub.status.busy":"2021-09-09T16:48:54.825857Z","iopub.execute_input":"2021-09-09T16:48:54.826257Z","iopub.status.idle":"2021-09-09T16:48:55.3114Z","shell.execute_reply.started":"2021-09-09T16:48:54.826226Z","shell.execute_reply":"2021-09-09T16:48:55.31022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Decision Tree Classifier Model","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nmodel2=DecisionTreeClassifier()\nmodel2.fit(X_train,Y_train)\n\nfrom sklearn.model_selection import cross_val_score\nscores2=cross_val_score(model2,X_train,Y_train,scoring=\"accuracy\",cv=10)\n\n\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\nprint('''Prediciting Test Set Result for Decision Tree Classifier''')\nY_pred2 = model2.predict(X_test)\nresult2 = np.concatenate((Y_pred2.reshape(len(Y_pred2), 1),Y_test.reshape(len(Y_test), 1)), 1)\nprint(result2,'\\n')\nprint('''Making Confusion Matrix''')\nY_pred2 = model2.predict(X_test)\ncm2 = confusion_matrix(Y_test, Y_pred2)\nprint(cm2,'\\n')\nprint('True Positives :',cm2[0][0])\nprint('False Positives :',cm2[0][1])\nprint('False Negatives :',cm2[1][0])\nprint('True Negatives :', cm2[0][1],'\\n')\n\nprint('''Classification Report''')\nprint(classification_report(Y_test, Y_pred2,target_names=['M', 'B'], zero_division=1))\n\nprint('''Evaluating Decision Tree Classifier Model Performance''')\naccuracy2 = accuracy_score(Y_test, Y_pred2)\nprint(accuracy2,'\\n')\n\nprint('''Applying Cross validation''')\nfrom sklearn.model_selection import cross_val_score\naccuracies2 = cross_val_score(model2, X_train, Y_train, cv=10)\nprint(\"Accuracy for Decision Tree: {:.2f} %\".format(accuracies2.mean()*100))\nprint(\"Standard Deviation for Decision Tree: {:.2f} %\".format(accuracies2.std()*100),'\\n')","metadata":{"execution":{"iopub.status.busy":"2021-09-09T16:48:55.3132Z","iopub.execute_input":"2021-09-09T16:48:55.313894Z","iopub.status.idle":"2021-09-09T16:48:55.539306Z","shell.execute_reply.started":"2021-09-09T16:48:55.313838Z","shell.execute_reply":"2021-09-09T16:48:55.538451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random Forest Classifier Model","metadata":{"execution":{"iopub.status.busy":"2021-09-09T15:55:20.623233Z","iopub.execute_input":"2021-09-09T15:55:20.623617Z","iopub.status.idle":"2021-09-09T15:55:20.62841Z","shell.execute_reply.started":"2021-09-09T15:55:20.623587Z","shell.execute_reply":"2021-09-09T15:55:20.627338Z"}}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nmodel3=RandomForestClassifier()\nmodel3.fit(X_train,Y_train)\n\nfrom sklearn.model_selection import cross_val_score\nscores3=cross_val_score(model3,X_train,Y_train,scoring=\"accuracy\",cv=10)\n\n\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\nprint('''Prediciting Test Set Result for Random Forest Classifier''')\nY_pred3 = model3.predict(X_test)\nresult3 = np.concatenate((Y_pred3.reshape(len(Y_pred3), 1),Y_test.reshape(len(Y_test), 1)), 1)\nprint(result3,'\\n')\nprint('''Making Confusion Matrix''')\nY_pred3 = model3.predict(X_test)\ncm3 = confusion_matrix(Y_test, Y_pred3)\nprint(cm3,'\\n')\nprint('True Positives :',cm3[0][0])\nprint('False Positives :',cm3[0][1])\nprint('False Negatives :',cm3[1][0])\nprint('True Negatives :', cm3[0][1],'\\n')\n\nprint('''Classification Report''')\nprint(classification_report(Y_test, Y_pred3,target_names=['M', 'B'], zero_division=1))\n\nprint('''Evaluating Random Forest Classifier Model Performance''')\naccuracy3 = accuracy_score(Y_test, Y_pred3)\nprint(accuracy3,'\\n')\n\nprint('''Applying Cross validation''')\nfrom sklearn.model_selection import cross_val_score\naccuracies3 = cross_val_score(model3, X_train, Y_train, cv=10)\nprint(\"Accuracy for Random Forest Classifier: {:.2f} %\".format(accuracies3.mean()*100))\nprint(\"Standard Deviation for Random Forrest Classifier: {:.2f} %\".format(accuracies3.std()*100),'\\n')","metadata":{"execution":{"iopub.status.busy":"2021-09-09T16:48:55.540491Z","iopub.execute_input":"2021-09-09T16:48:55.540947Z","iopub.status.idle":"2021-09-09T16:49:00.825686Z","shell.execute_reply.started":"2021-09-09T16:48:55.540913Z","shell.execute_reply":"2021-09-09T16:49:00.82453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Support Vector Machines Model","metadata":{}},{"cell_type":"code","source":"from sklearn import svm\nmodel4 = svm.SVC(kernel='linear') # Linear Kernel\nmodel4.fit(X_train, Y_train)\n\nfrom sklearn.model_selection import cross_val_score\nscores4=cross_val_score(model4,X_train,Y_train,scoring=\"accuracy\",cv=10)\n\n\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\nprint('''Prediciting Test Set Result for SVM''')\nY_pred4 = model4.predict(X_test)\nresult4 = np.concatenate((Y_pred4.reshape(len(Y_pred4), 1),Y_test.reshape(len(Y_test), 1)), 1)\nprint(result4,'\\n')\nprint('''Making Confusion Matrix''')\nY_pred4 = model4.predict(X_test)\ncm4 = confusion_matrix(Y_test, Y_pred4)\nprint(cm4,'\\n')\nprint('True Positives :',cm4[0][0])\nprint('False Positives :',cm4[0][1])\nprint('False Negatives :',cm4[1][0])\nprint('True Negatives :', cm4[0][1],'\\n')\n\nprint('''Classification Report''')\nprint(classification_report(Y_test, Y_pred4,target_names=['M', 'B'], zero_division=1))\n\nprint('''Evaluating SVM Performance''')\naccuracy4 = accuracy_score(Y_test, Y_pred4)\nprint(accuracy4,'\\n')\n\nprint('''Applying Cross validation''')\nfrom sklearn.model_selection import cross_val_score\naccuracies4 = cross_val_score(model4, X_train, Y_train, cv=10)\nprint(\"Accuracy for SVM: {:.2f} %\".format(accuracies4.mean()*100))\nprint(\"Standard Deviation for SVM: {:.2f} %\".format(accuracies4.std()*100),'\\n')","metadata":{"execution":{"iopub.status.busy":"2021-09-09T16:49:00.827366Z","iopub.execute_input":"2021-09-09T16:49:00.828014Z","iopub.status.idle":"2021-09-09T16:49:00.938109Z","shell.execute_reply.started":"2021-09-09T16:49:00.827967Z","shell.execute_reply":"2021-09-09T16:49:00.937002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## K Neighbors Classifier Model","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nmodel5 = KNeighborsClassifier(n_neighbors = 8)\nmodel5.fit(X_train, Y_train)\n\nfrom sklearn.model_selection import cross_val_score\nscores5=cross_val_score(model5,X_train,Y_train,scoring=\"accuracy\",cv=10)\n\n\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\nprint('''Prediciting Test Set Result for KNeighbors Classifier''')\nY_pred5 = model5.predict(X_test)\nresult5 = np.concatenate((Y_pred5.reshape(len(Y_pred5), 1),Y_test.reshape(len(Y_test), 1)), 1)\nprint(result5,'\\n')\nprint('''Making Confusion Matrix''')\nY_pred5 = model5.predict(X_test)\ncm5 = confusion_matrix(Y_test, Y_pred5)\nprint(cm5,'\\n')\nprint('True Positives :',cm5[0][0])\nprint('False Positives :',cm5[0][1])\nprint('False Negatives :',cm5[1][0])\nprint('True Negatives :', cm5[0][1],'\\n')\n\nprint('''Classification Report''')\nprint(classification_report(Y_test, Y_pred5,target_names=['M', 'B'], zero_division=1))\n\nprint('''Evaluating K Neighbours Classifier Model Performance''')\naccuracy5 = accuracy_score(Y_test, Y_pred5)\nprint(accuracy5,'\\n')\n\nprint('''Applying Cross validation''')\nfrom sklearn.model_selection import cross_val_score\naccuracies5 = cross_val_score(model5, X_train, Y_train, cv=10)\nprint(\"Accuracy for K  Neighbours Classifier: {:.2f} %\".format(accuracies5.mean()*100))\nprint(\"Standard Deviation for K neighbours Classifiers: {:.2f} %\".format(accuracies5.std()*100),'\\n')","metadata":{"execution":{"iopub.status.busy":"2021-09-09T16:49:00.93943Z","iopub.execute_input":"2021-09-09T16:49:00.939739Z","iopub.status.idle":"2021-09-09T16:49:01.095652Z","shell.execute_reply.started":"2021-09-09T16:49:00.939708Z","shell.execute_reply":"2021-09-09T16:49:01.094563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Naive Bayes Classifier Model","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nmodel6 = GaussianNB()\nmodel6.fit(X_train, Y_train)\n\nfrom sklearn.model_selection import cross_val_score\nscores6=cross_val_score(model6,X_train,Y_train,scoring=\"accuracy\",cv=10)\n\n\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\nprint('''Prediciting Test Set Result for Naive Bayes''')\nY_pred6 = model6.predict(X_test)\nresult6 = np.concatenate((Y_pred6.reshape(len(Y_pred6), 1),Y_test.reshape(len(Y_test), 1)), 1)\nprint(result6,'\\n')\nprint('''Making Confusion Matrix''')\nY_pred = model6.predict(X_test)\ncm6 = confusion_matrix(Y_test, Y_pred6)\nprint(cm6,'\\n')\nprint('True Positives :',cm6[0][0])\nprint('False Positives :',cm6[0][1])\nprint('False Negatives :',cm6[1][0])\nprint('True Negatives :', cm6[0][1],'\\n')\n\nprint('''Classification Report''')\nprint(classification_report(Y_test, Y_pred6,target_names=['M', 'B'], zero_division=1))\n\nprint('''Evaluating Naive Bayes Model Performance''')\naccuracy6 = accuracy_score(Y_test, Y_pred6)\nprint(accuracy6,'\\n')\n\nprint('''Applying Cross validation''')\nfrom sklearn.model_selection import cross_val_score\naccuracies6 = cross_val_score(model6, X_train, Y_train, cv=10)\nprint(\"Accuracy for Naive Bayes: {:.2f} %\".format(accuracies6.mean()*100))\nprint(\"Standard Deviation for Naive Bayes: {:.2f} %\".format(accuracies6.std()*100),'\\n')","metadata":{"execution":{"iopub.status.busy":"2021-09-09T16:49:01.097211Z","iopub.execute_input":"2021-09-09T16:49:01.097631Z","iopub.status.idle":"2021-09-09T16:49:01.159978Z","shell.execute_reply.started":"2021-09-09T16:49:01.097584Z","shell.execute_reply":"2021-09-09T16:49:01.158906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Finding out which model works best for our dataset","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nmodel_accuracies = [accuracies.mean()*100,accuracies2.mean()*100,accuracies3.mean()*100,accuracies4.mean()*100,accuracies5.mean()*100,accuracies6.mean()*100]\nmodel_names = ['LogisticRegression','Decisiontree','RandomForest','SVM', 'KNN','Naive Bayes']\nsns.barplot(x=model_accuracies,y=model_names,palette='magma');","metadata":{"execution":{"iopub.status.busy":"2021-09-09T16:49:01.161294Z","iopub.execute_input":"2021-09-09T16:49:01.161609Z","iopub.status.idle":"2021-09-09T16:49:01.348916Z","shell.execute_reply.started":"2021-09-09T16:49:01.161577Z","shell.execute_reply":"2021-09-09T16:49:01.347578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"length=len(model_names)\nfor i in range(length):\n    print(model_names[i],'Model Accuracy is:', model_accuracies[i],'%')","metadata":{"execution":{"iopub.status.busy":"2021-09-09T16:49:01.353267Z","iopub.execute_input":"2021-09-09T16:49:01.353782Z","iopub.status.idle":"2021-09-09T16:49:01.362677Z","shell.execute_reply.started":"2021-09-09T16:49:01.353708Z","shell.execute_reply":"2021-09-09T16:49:01.361373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The Logistic Regression Model works best here for our dataset**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}