{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nweather_data = pd.read_csv('../input/weather-dataset-rattle-package/weatherAUS.csv')\n\nweather_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **CÁC ĐỊNH NGHĨA VỀ KHOẢNG CÁCH**","metadata":{}},{"cell_type":"markdown","source":"> 1. Chuẩn 2 ( L2 Norm) Khoảng cách Euclide","metadata":{}},{"cell_type":"markdown","source":"√(x₁₂-x₂₂)²+(y₁₂-y₂₂)² =  ||x₁-x₂||₂\n\nWe can also rewrite this as \n\n||x₁-x₂||₂ =   (∑(x₁ᵢ-x₂ᵢ)²)¹/² where i=1 to n\n\nThe right side of this equation is called L2 Norm","metadata":{}},{"cell_type":"markdown","source":"> 2. Chuẩn 1 (L1 Norm) khoảng cách mahattan","metadata":{}},{"cell_type":"markdown","source":"distance =(x₁₂-x₂₂)  which can also be rewritten as\n\n∑ abs(x₁ᵢ-x₂ᵢ) where i=1 to n\n\nThis is called L1 norm","metadata":{}},{"cell_type":"markdown","source":"3. > Chuẩn p (Lp Norm) khoảng cách Minkowski","metadata":{}},{"cell_type":"markdown","source":"||x₁-x₂||ₚ =(∑(x₁ᵢ-x₂ᵢ)ᵖ)¹/ᵖ\n\nThis is also called the Lp norm\n\nIf p=1, then it is Manhattan distance\n\nIf p=2, then it is Euclidean distance","metadata":{}},{"cell_type":"markdown","source":"# **CHỌN K NHƯ THẾ NÀO ?**","metadata":{}},{"cell_type":"markdown","source":"Với bài toán phân loại nhị phân, chúng ta sẽ chọn K lẻ để đảm bảo nhãn sẽ được phân loại\n\nTrong tất cả các trường hợp người ta chưa có thống kê nào cho thấy giá trị K nào là tốt nhất.\n\nVậy Chúng ta sẽ cho K chạy trong 1 tập hữu hạn và chọn giá trị K làm cho giá trị hàm error là nhỏ nhất. ","metadata":{}},{"cell_type":"markdown","source":"# **XỬ LÝ THẾ NÀO KHI 2 NHÃN CÓ CÙNG SỐ LƯỢNG HÀNG XÓM VOTE ?**","metadata":{}},{"cell_type":"markdown","source":"- Random \n- Tăng hoặc giảm K cho đến khi có sự chênh lệch lượng vote giữa 2 nhãn ( giảm accuracy)\n- Đánh trọng số cho mỗi ứng viên và lấy giá trị trọng số này để so sánh giữa 2 nhãn nếu có số lượng vote = nhau","metadata":{}},{"cell_type":"markdown","source":"# **TẠI SAO LÀM VIỆC VỚI KNN PHẢI NORMALIZE DATA ?**","metadata":{}},{"cell_type":"markdown","source":"- Vì các feature sẽ có những đặc trưng khác nhau và không thuộc cùng 1 dài giá trị để tính khoảng cách\n\n- Ví dụ : Người 1 : Age = 25 , income = 80.000 ; Người 2 : Age = 30 , income = 100.000\n\nKhoảng cách d = ((Age1-Ag2)^2 + (income1-income2)^2)^(1/2) = 20000.000625 \n\nVậy ảnh hưởng của Age không quá lớn đối với hàm khoảng cách nhưng trên thực tế Age có ảnh hưởng khá lớn tới thu nhập cũng như các feature khác thì model sẽ rất tệ.\n\n- Chúng ta cần tập dữ liệu có phân phối xác suất vậy thì cần phải nomalize","metadata":{}},{"cell_type":"markdown","source":"# **CÁC KĨ THUẬT NORMALIZE DATA ?**","metadata":{}},{"cell_type":"markdown","source":"> 1. Scalling \n\nThay đổi khoảng giá trị của Data\n\nminmax_scaling trong mlxtend.preprocessing\n\n> 2. Normalizing\n\nThay đổi phân phối xác suất của các điểm dữ liệu\n\nboxcox trong Stats thư viện scipy","metadata":{}},{"cell_type":"markdown","source":"# **IMPLEMENT THUẬT TOÁN KNN**","metadata":{}},{"cell_type":"code","source":"weather_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weather_data['RainTomorrow'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weather_data.isnull().sum().sort_values(ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****Xóa các cột có số lượng NULL > 28%****","metadata":{}},{"cell_type":"code","source":"max_nan = len(weather_data)*0.28\nweather_data = weather_data.loc[:,(weather_data.isnull().sum(axis=0) <= max_nan) ]\nweather_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weather_data.isnull().sum().sort_values(ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"**Điền các giá trị còn thiếu bởi next value**","metadata":{}},{"cell_type":"code","source":"weather_data.dropna(subset = [\"RainTomorrow\"], inplace = True)\nweather_data.fillna(method='bfill' , inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weather_data.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loại bỏ 1 số cột không có ý nghĩa\nweather_data.drop(columns= ['Date','Location'] , inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weather_data['RainToday'] = weather_data['RainToday'].astype('category')\nweather_data['RainTomorrow'] = weather_data['RainTomorrow'].astype('category')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Chuyển về numeric\nweather_data['RainToday'] = weather_data['RainToday'].cat.codes\nweather_data['RainTomorrow'] = weather_data['RainTomorrow'].cat.codes\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col_is_numeric = [col for col in weather_data.columns if weather_data[col].dtype in ['int64','float64','int8']]\nweather_data = weather_data[col_is_numeric]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Full_Data_X = weather_data\nX = Full_Data_X.drop(columns= 'RainTomorrow' , axis = 1)\n# X = Full_Data_X.drop(columns= 'RainToday' , axis = 1)\ny = Full_Data_X['RainTomorrow']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X=pd.get_dummies(X,columns=['WindDir9am','WindDir3pm','WindGustDir'],drop_first=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Scale data\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nscaler.fit(X)\nX = pd.DataFrame(scaler.transform(X), index=X.index, columns=X.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train , X_test , y_train , y_test = train_test_split(X,y,test_size=0.25 ,random_state=0,stratify=y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Chọn K\nK = 101","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\n\nclassifier = KNeighborsClassifier(n_neighbors = 13 , p = 2 , weights = 'distance')\nclassifier.fit(X_train,y_train)\ny_pred = classifier.predict(X_test)\nscore = accuracy_score(y_test,y_pred)\nprint(\"Predicted labels: \", y_pred[1:20])\nprint(\"Ground truth    : \", np.array(y_test[1:20]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nprint(\"Accuracy of KNN: %.2f %%\" %(100*accuracy_score(y_test, y_pred)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def knn(row):\n    x = np.array(row)\n    candidate = []\n    for i in range(len(X_train)):\n        y = np.array(X_train.iloc[i])\n        score = (y-x).dot(y-x)\n        candidate.append([math.sqrt(score),y_train.iloc[i]])\n    candidate.sort()\n    candidate = candidate[0:K]\n    vote = 0\n    for i in candidate:\n        if i[1]==1:\n            vote+=1\n    if vote>K//2:\n        return 1\n    else:\n        return 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict = []\n# for i in range(len(X_test)):\n#     predict.append(knn(X_test.iloc[i]))\n# print(\"Accuracy of KNN: %.2f %%\" %(100*accuracy_score(y_test, np.array(predict))))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nsecond = time.time()\nx = np.array(X_train)\ny = np.array(X_test.iloc[0])\ncandidate = np.zeros(len(x))\nfor i in range(x.shape[0]):\n    score = (x[i]-y).dot(x[i]-y)\n    candidate[i] = math.sqrt(score)\ncandidate.sort(kind = 'quicksort')\ncandidate = candidate[0:K]\n\nprint(candidate)\nprint(time.time() - second)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **các kĩ thuật tối ưu khi search các hàng xóm gần nhất ?**","metadata":{}},{"cell_type":"markdown","source":"> 1. KD-Tree\n\nThuật toán tìm kiếm dựa trên binary search tree\n\nmỗi khi đi xuống 1 nhánh sử dụng 1 chiều dữ liệu luân phiên\n\n>2. KNN with LSH ( locality sensitive hashing)\n\nChia tập dữ liệu ra thành các region. Nếu test_point thuộc region nào thì chỉ xét các neighbor thuộc region đó.\n\n>3. KNN with Inverted List","metadata":{}}]}