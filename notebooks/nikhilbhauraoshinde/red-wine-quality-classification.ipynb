{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.api as sm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **`Importing the WINE DATA and Eyeballing the Data`**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_wine = pd.read_csv(\"/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* What might be an interesting thing to do, is aside from using regression modelling, is to set an arbitrary cutoff for your dependent variable (wine quality) at e.g. 7 or higher getting classified as 'good/1' and the remainder as 'not good/0'.\nThis allows you to practice with hyper parameter tuning on e.g. decision tree algorithms looking at the ROC curve and the AUC value.\nWithout doing any kind of feature engineering or overfitting you should be able to get an AUC of .88 (without even using random forest algorithm)`"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_wine.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **The Data shows that the data has is having appropriate Datatypes and has no null values**"},{"metadata":{},"cell_type":"markdown","source":"`Lets Check the min max and median of the data `"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_wine.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* After  looking at the Data we can see that the mean and median(50%) of the density is normally distributed"},{"metadata":{},"cell_type":"markdown","source":"* We are converting the following problem into the Classification Problem \n    \n    `Wine Quality>7 is Good `\n    \n    `Wine Quality<7 is not Good`"},{"metadata":{},"cell_type":"markdown","source":"* Lets Create a feature \n\n    `0 for the Wine quality<7` \n\n    `1 for the Wine quality>=7`\n"},{"metadata":{},"cell_type":"markdown","source":"* Check the Value counts for the Quality in the dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_wine[\"quality\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **We are converting the Problem in the classification problem**\n\n    `Creating the Feature Wine_Cat by distinguishing into the quality`"},{"metadata":{"trusted":true},"cell_type":"code","source":"wine_cat=[]\nfor i in df_wine[\"quality\"]:\n    if i >=7:\n        wine_cat.append(1)\n    else:\n        wine_cat.append(0)\ndf_wine[\"wine_cat\"]=wine_cat","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **` Check the value_counts for 0 and 1`** "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_wine.wine_cat.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Lets create a full model on the Data using Classification Algorithm and checking the Accuracy metrics"},{"metadata":{},"cell_type":"markdown","source":"* **Assinging the Df_predictor and Df_Target**   "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_Predictors=df_wine.drop([\"quality\",\"wine_cat\"],axis=1)\ndf_target=df_wine.wine_cat","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Creating the train-test Split on the data and check for the shape of the Train test split**"},{"metadata":{"trusted":true},"cell_type":"code","source":"Xtrain,Xtest,ytrain,ytest=train_test_split(df_Predictors,df_target,random_state=10,test_size=0.2)\nprint(\"Shape of Xtrain:{} and Shape of ytrain:{} \".format(Xtrain.shape,ytrain.shape))\nprint(\"Shape of Xtest:{} and Shape of ytest:{} \".format(Xtest.shape,ytest.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression "},{"metadata":{"trusted":true},"cell_type":"code","source":"logit_regression=sm.Logit(ytrain,Xtrain).fit()\nlogit_regression.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **The Features with pvalues less than 0.05 are to considered significant hence the Features below are significant**\n\n       "},{"metadata":{},"cell_type":"markdown","source":"**`volatile acidity`\n`chlorides`\n`total sulfur dioxide`\n`density`\n`sulphates`\n`alcohol`** "},{"metadata":{},"cell_type":"markdown","source":"**We got Pseudo Rsquared as 0.2871**\n\n**Which seems to be good Fit**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# we are creating a different Performance metrics for the Logistic Regression giving different threshold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_card = pd.DataFrame(columns=['Probability Cutoff', 'AUC Score', 'Precision Score', 'Recall Score',\n                                       'Accuracy Score', 'Kappa Score', 'f1-score'])\ndef update_score_card(model, cutoff):\n    from sklearn import metrics\n    # let 'y_pred_prob' be the predicted values of y\n    y_pred_prob = logit_regression.predict(Xtest)\n    \n    # convert probabilities to 0 and 1 using 'if_else'\n    y_pred = [ 0 if x < cutoff else 1 for x in y_pred_prob]\n\n# assign 'score_card' as global variable\n    global score_card\n\n# append the results to the dataframe 'score_card'\n# 'ignore_index = True' do not consider the index labels\n    score_card = score_card.append({'Probability Cutoff': cutoff,\n                                    'AUC Score' : metrics.roc_auc_score(ytest, y_pred),\n                                    'Precision Score': metrics.precision_score(ytest, y_pred),\n                                    'Recall Score': metrics.recall_score(ytest, y_pred),\n                                    'Accuracy Score': metrics.accuracy_score(ytest, y_pred),\n                                    'Kappa Score':metrics.cohen_kappa_score(ytest, y_pred),\n                                    'f1-score': metrics.f1_score(ytest, y_pred)}, \n                                    ignore_index = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nupdate_score_card(logit_regression,0.2)\nupdate_score_card(logit_regression,0.4)\nupdate_score_card(logit_regression,0.6)\n\nupdate_score_card(logit_regression,0.8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_card","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_prob=logit_regression.predict(Xtest)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **As we know that the Logistic Regression gives us the Probability we need to convert the Probabilities to `0 and 1`**"},{"metadata":{"trusted":true},"cell_type":"code","source":"ypred=[1 if x>0.5 else 0 for x in y_pred_prob]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### The Following is the confusion Matrix for Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nsns.heatmap(metrics.confusion_matrix(ytest,ypred),annot=True,annot_kws={\"size\":25},fmt=\"d\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**This is the  List Comprehension for Converting the ypredicted_probalities to 0 and 1**"},{"metadata":{},"cell_type":"markdown","source":"### Naive Bayes Classification\n* Lets Use the Naive Bayes Classification and  check the  Accuracy"},{"metadata":{},"cell_type":"markdown","source":"* We Import Naives Bayes from Gaussian NB"},{"metadata":{"trusted":true},"cell_type":"code","source":"Naive_bayes=GaussianNB()\nNaive_bayes_model=Naive_bayes.fit(X=Xtrain,y=ytrain)\nNBpred=Naive_bayes.predict(Xtest)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Getting the confusion Matrix for the Bayesian Classification with the Help of Heatmap"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nsns.heatmap(metrics.confusion_matrix(ytest,NBpred),annot=True,annot_kws={\"size\":25},fmt=\"d\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest Classification"},{"metadata":{},"cell_type":"markdown","source":"* We are taking the Random Forest Classification with Hyperparameter n_estimator=1000 that is we want 1000 trees "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nrf=RandomForestClassifier(n_estimators=1000)\nmodelrf=rf.fit(Xtrain,ytrain)\nrf_predict=rf.predict(Xtest)\nmetrics.accuracy_score(ytest,rf_predict)\nsns.heatmap(metrics.confusion_matrix(ytest,rf_predict),annot=True,annot_kws={\"size\":25},linewidths=0.2,fmt='d',cmap=\"viridis\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### K-Nearest Neighbors\n*  We are using the n_neighbors=5 which tells us the value of top 5 nearest Neighbors to be considered"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nKNN=KNeighborsClassifier(n_neighbors=5)\nKNN=KNN.fit(Xtrain,ytrain)\nKnn_predict=KNN.predict(Xtest)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics.accuracy_score(ytest,Knn_predict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def accuracy(ytest,pred):\n    return metrics.accuracy_score(ytest,pred)*100\n\n    \nprint(\"The Accuracy for the Logistic regression is {},\\nThe Accuracy for the 1000 Random forest is {} and \\nThe Accuracy for the Bayesian classifier is {}\\n The Accuracy for the K-Nearest Neighbors is {}\".format(accuracy(ytest,ypred),accuracy(ytest,rf_predict),accuracy(ytest,NBpred),accuracy(ytest,Knn_predict)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We Have Created the following Models without dropping the Features we will generate the Model using K fold Cross Validation after the Model Is built"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}