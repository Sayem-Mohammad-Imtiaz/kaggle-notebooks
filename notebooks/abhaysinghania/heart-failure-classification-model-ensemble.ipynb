{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport plotly\nimport os\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-26T07:48:06.568617Z","iopub.execute_input":"2021-06-26T07:48:06.569183Z","iopub.status.idle":"2021-06-26T07:48:08.062779Z","shell.execute_reply.started":"2021-06-26T07:48:06.569095Z","shell.execute_reply":"2021-06-26T07:48:08.061701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"text-align:center\"><img src=\"https://www.verywellhealth.com/thmb/PjK68gYYU57mdcDj0XdIcTe7GHQ=/1001x1001/smart/filters:no_upscale()/heart-failure-causes-40-5ae0bcdec673350037cb2ddd.png\", width=\"500\" height=\"500\"></div>","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"## Index\n\n1. <a href='#1'> Data Ingestion and Exploration </a>\n    - <a href='#1.1'>1.1 Data Preparation </a>\n    - <a href='#1.2'>1.2 Visualize the dataset </a>\n    - <a href='#1.3'>1.3 Feature Engineering </a>\n2. <a href='#2'> Integrating Classification Labels </a>\n3. <a href='#3'> Resampling Techniques </a>\n4. <a href='#4'> Prediction </a>\n5. <a href='#5'> Evaluation </a>","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(r'/kaggle/input/heart-failure-clinical-data/heart_failure_clinical_records_dataset.csv', \n                               error_bad_lines=False)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-26T07:48:11.615107Z","iopub.execute_input":"2021-06-26T07:48:11.615466Z","iopub.status.idle":"2021-06-26T07:48:11.629677Z","shell.execute_reply.started":"2021-06-26T07:48:11.615436Z","shell.execute_reply":"2021-06-26T07:48:11.628619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-26T07:48:12.40528Z","iopub.execute_input":"2021-06-26T07:48:12.405673Z","iopub.status.idle":"2021-06-26T07:48:12.413635Z","shell.execute_reply.started":"2021-06-26T07:48:12.405639Z","shell.execute_reply":"2021-06-26T07:48:12.412566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-06-26T07:48:13.06376Z","iopub.execute_input":"2021-06-26T07:48:13.064114Z","iopub.status.idle":"2021-06-26T07:48:13.080391Z","shell.execute_reply.started":"2021-06-26T07:48:13.064083Z","shell.execute_reply":"2021-06-26T07:48:13.079663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['DEATH_EVENT'].unique()","metadata":{"execution":{"iopub.status.busy":"2021-06-26T07:48:13.812518Z","iopub.execute_input":"2021-06-26T07:48:13.813033Z","iopub.status.idle":"2021-06-26T07:48:13.822697Z","shell.execute_reply.started":"2021-06-26T07:48:13.813001Z","shell.execute_reply":"2021-06-26T07:48:13.821624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-26T07:48:14.730591Z","iopub.execute_input":"2021-06-26T07:48:14.730932Z","iopub.status.idle":"2021-06-26T07:48:14.798367Z","shell.execute_reply.started":"2021-06-26T07:48:14.730902Z","shell.execute_reply":"2021-06-26T07:48:14.797333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the missing values in the column\nmissing_data = df.isna().sum().sort_values(ascending=False)\nmissing_data = missing_data.reset_index(drop=False)\nmissing_data = missing_data.rename(columns={\"index\": \"Columns\", 0: \"Value\"})\nmissing_data['Proportion'] = (missing_data['Value']/len(df))*100\nmissing_data","metadata":{"execution":{"iopub.status.busy":"2021-06-26T07:48:15.484571Z","iopub.execute_input":"2021-06-26T07:48:15.48498Z","iopub.status.idle":"2021-06-26T07:48:15.521355Z","shell.execute_reply.started":"2021-06-26T07:48:15.484925Z","shell.execute_reply":"2021-06-26T07:48:15.520271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.pie(df, names='DEATH_EVENT',\n             color_discrete_sequence=px.colors.sequential.Viridis_r,\n             title='Proportion of data for Class column')\nfig.update_traces(textposition='inside', textinfo='percent+label')\nfig.update_layout(paper_bgcolor='rgba(0,0,0,0)',\n                  plot_bgcolor='rgba(0,0,0,0)',\n                  font=dict(family='Cambria, monospace', size=12, color='#000000'))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-26T07:48:16.404083Z","iopub.execute_input":"2021-06-26T07:48:16.404505Z","iopub.status.idle":"2021-06-26T07:48:17.626445Z","shell.execute_reply.started":"2021-06-26T07:48:16.404467Z","shell.execute_reply":"2021-06-26T07:48:17.625663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The proportion of Class 0 is double than of Class 1. Thus the dataset is imbalanced. We need to use resampling techniques and different performance metrics to evaluate the results.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.figure(figsize=(12,12))\n\n# Compute the correlation matrix\ncorr = df.corr()\n\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=\"GnBu\", vmax=.3, center=0,\n            square=True, linewidths=.7, cbar_kws={\"shrink\": .7})","metadata":{"execution":{"iopub.status.busy":"2021-06-26T07:48:19.66291Z","iopub.execute_input":"2021-06-26T07:48:19.663256Z","iopub.status.idle":"2021-06-26T07:48:20.872487Z","shell.execute_reply.started":"2021-06-26T07:48:19.663226Z","shell.execute_reply":"2021-06-26T07:48:20.871437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statsmodels.stats.outliers_influence import variance_inflation_factor\n\ndef calc_vif(X):\n\n    # Calculating VIF\n    vif = pd.DataFrame()\n    vif[\"variables\"] = X.columns\n    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n\n    return(vif)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T07:48:21.742172Z","iopub.execute_input":"2021-06-26T07:48:21.742579Z","iopub.status.idle":"2021-06-26T07:48:21.867548Z","shell.execute_reply.started":"2021-06-26T07:48:21.742548Z","shell.execute_reply":"2021-06-26T07:48:21.866471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df.iloc[:,:-1]\nnew_X = calc_vif(X)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T07:48:22.979293Z","iopub.execute_input":"2021-06-26T07:48:22.980067Z","iopub.status.idle":"2021-06-26T07:48:23.016222Z","shell.execute_reply.started":"2021-06-26T07:48:22.980025Z","shell.execute_reply":"2021-06-26T07:48:23.015045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_X","metadata":{"execution":{"iopub.status.busy":"2021-06-26T07:48:23.363376Z","iopub.execute_input":"2021-06-26T07:48:23.363917Z","iopub.status.idle":"2021-06-26T07:48:23.373803Z","shell.execute_reply.started":"2021-06-26T07:48:23.363882Z","shell.execute_reply":"2021-06-26T07:48:23.373044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.figure(figsize=(14,6))\nsns.set(style=\"darkgrid\")\nsns.countplot(x='age',data = df, hue = 'DEATH_EVENT',palette='RdBu')\nplt.title(\"Count Plot of DEATH EVENT per age\\n\", fontsize=16)\nsns.set_context(\"paper\", font_scale=1.4)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-26T07:48:25.921602Z","iopub.execute_input":"2021-06-26T07:48:25.922109Z","iopub.status.idle":"2021-06-26T07:48:26.911842Z","shell.execute_reply.started":"2021-06-26T07:48:25.922074Z","shell.execute_reply":"2021-06-26T07:48:26.910781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(14,6))\nsns.set(style=\"darkgrid\")\nsns.countplot(x='sex',data = df, hue = 'DEATH_EVENT',palette='RdBu')\nplt.title(\"Count Plot of DEATH EVENT per sex\\n\", fontsize=16)\nsns.set_context(\"paper\", font_scale=1.4)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-26T07:48:26.913539Z","iopub.execute_input":"2021-06-26T07:48:26.914137Z","iopub.status.idle":"2021-06-26T07:48:27.093503Z","shell.execute_reply.started":"2021-06-26T07:48:26.914092Z","shell.execute_reply":"2021-06-26T07:48:27.092648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n# Using 5 folds cross-validation\ndef CrossVal(trainX, trainY, model):\n    f1=cross_val_score(model,trainX , trainY, cv=5, scoring='f1')\n    return(f1)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T07:48:29.963226Z","iopub.execute_input":"2021-06-26T07:48:29.963754Z","iopub.status.idle":"2021-06-26T07:48:30.291505Z","shell.execute_reply.started":"2021-06-26T07:48:29.963723Z","shell.execute_reply":"2021-06-26T07:48:30.290504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom imblearn.ensemble import BalancedRandomForestClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom imblearn.ensemble import BalancedBaggingClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score,confusion_matrix,f1_score,recall_score,precision_recall_curve,average_precision_score\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.ensemble import StackingClassifier","metadata":{"execution":{"iopub.status.busy":"2021-06-26T07:48:31.143086Z","iopub.execute_input":"2021-06-26T07:48:31.143464Z","iopub.status.idle":"2021-06-26T07:48:31.880462Z","shell.execute_reply.started":"2021-06-26T07:48:31.14343Z","shell.execute_reply":"2021-06-26T07:48:31.879421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define meta learner model\nlevel1 = SVC()\n# define the stacking ensemble\nestimates = list()\nestimates.append(('rf', RandomForestClassifier(n_estimators=500,\n                                          max_depth = 8,\n                                          min_samples_leaf=10,\n                                          # max_features='sqrt',\n                                          max_features = 0.7,\n                                          class_weight={0:1, 1:5},\n                                          n_jobs=4)))\nestimates.append(('brf', BalancedRandomForestClassifier(n_estimators=500, \n                                                   max_depth = 8,\n                                                   random_state=330, \n                                                   # max_features='sqrt', \n                                                   max_features = 0.7,\n                                                   class_weight={0:1, 1:5},\n                                                   n_jobs=4)))\nestimates.append(('xgb', XGBClassifier(max_depth=8,\n                                  learning_rate=0.7,\n                                  n_estimators=500,\n                                  # max_features='sqrt',\n                                  max_features = 0.7,\n                                  min_samples_leaf=10,\n                                  eval_metric=\"logloss\",\n                                  n_jobs=4)))\nestimates.append(('lgbm', LGBMClassifier(boosting_type='gbdt',\n                                    num_leaves=10,\n                                    max_depth=5,\n                                    learning_rate=0.7,\n                                    n_estimators=500,\n                                    # max_features='sqrt',\n                                    max_features = 0.7,\n                                    eval_metric=\"logloss\",\n                                    class_weight={0:1, 1:5},\n                                    n_jobs=4)))\nestimates.append(('bbc', BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(),\n                                              n_estimators=500,\n                                              sampling_strategy='auto',\n                                              max_features = 0.5,\n                                              replacement=False,\n                                              random_state=330)))\n\n# Stacking Classifier\nstack = StackingClassifier(estimators = estimates, final_estimator=level1)\n# Voting Classifier with hard voting\nvot_hard = VotingClassifier(estimators = estimates, voting ='hard')","metadata":{"execution":{"iopub.status.busy":"2021-06-26T07:48:59.237707Z","iopub.execute_input":"2021-06-26T07:48:59.238064Z","iopub.status.idle":"2021-06-26T07:48:59.249983Z","shell.execute_reply.started":"2021-06-26T07:48:59.238033Z","shell.execute_reply":"2021-06-26T07:48:59.24877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_models():\n    models = {}\n    models['rf'] = RandomForestClassifier(n_estimators=500,\n                                          max_depth = 8,\n                                          min_samples_leaf=10,\n                                          # max_features='sqrt',\n                                          max_features = 0.7,\n                                          class_weight={0:1, 1:5},\n                                          n_jobs=4)\n    models['brf'] = BalancedRandomForestClassifier(n_estimators=500, \n                                                   max_depth = 8,\n                                                   random_state=330, \n                                                   # max_features='sqrt', \n                                                   max_features = 0.7,\n                                                   class_weight={0:1, 1:5},\n                                                   n_jobs=4)\n    models['xgb'] = XGBClassifier(max_depth=8,\n                                  learning_rate=0.7,\n                                  n_estimators=500,\n                                  # max_features='sqrt',\n                                  max_features = 0.7,\n                                  min_samples_leaf=10,\n                                  n_jobs=4)\n    models['lgbm'] = LGBMClassifier(boosting_type='gbdt',\n                                    num_leaves=10,\n                                    max_depth=5,\n                                    learning_rate=0.7,\n                                    n_estimators=500,\n                                    # max_features='sqrt',\n                                    max_features = 0.7,\n                                    class_weight={0:1, 1:5},\n                                    n_jobs=4)\n    models['bbc'] = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(),\n                                              n_estimators=500,\n                                              sampling_strategy='auto',\n                                              max_features = 0.5,\n                                              replacement=False,\n                                              random_state=330)\n    models['stack'] = stack\n    models['vot_hard'] = vot_hard\n    return models","metadata":{"execution":{"iopub.status.busy":"2021-06-26T07:49:13.906136Z","iopub.execute_input":"2021-06-26T07:49:13.906661Z","iopub.status.idle":"2021-06-26T07:49:13.917362Z","shell.execute_reply.started":"2021-06-26T07:49:13.906627Z","shell.execute_reply":"2021-06-26T07:49:13.916416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.utils import resample\n# Separate input features and target\nY = df['DEATH_EVENT']\nX = df.drop('DEATH_EVENT', axis=1)\n\n# setting up testing and training sets\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=2727)\n\n# concatenate our training data back together\nX = pd.concat([X_train, Y_train], axis=1)\n\nnormal = X[X['DEATH_EVENT']==0]\nanamoly = X[X['DEATH_EVENT']!=0]\n\n# upsample minority\nanamoly_upsampled = resample(anamoly,\n                          replace=True, # sample with replacement\n                          n_samples=len(normal), # match number in majority class\n                          random_state=2727) # reproducible results\n\n# combine majority and oversampled minority\noversampled = pd.concat([normal, anamoly_upsampled])\n\n# check new class counts\noversampled['DEATH_EVENT'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-26T07:49:18.575954Z","iopub.execute_input":"2021-06-26T07:49:18.576342Z","iopub.status.idle":"2021-06-26T07:49:18.603338Z","shell.execute_reply.started":"2021-06-26T07:49:18.576284Z","shell.execute_reply":"2021-06-26T07:49:18.60234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Proportion before Oversampling\nprint(Y_train.value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-06-26T07:49:20.699194Z","iopub.execute_input":"2021-06-26T07:49:20.699785Z","iopub.status.idle":"2021-06-26T07:49:20.706861Z","shell.execute_reply.started":"2021-06-26T07:49:20.699732Z","shell.execute_reply":"2021-06-26T07:49:20.705883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Unseen data proportion of class\nprint(Y_test.value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-06-26T07:49:22.200729Z","iopub.execute_input":"2021-06-26T07:49:22.201075Z","iopub.status.idle":"2021-06-26T07:49:22.207506Z","shell.execute_reply.started":"2021-06-26T07:49:22.201045Z","shell.execute_reply":"2021-06-26T07:49:22.206288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = get_models()","metadata":{"execution":{"iopub.status.busy":"2021-06-26T07:49:23.254985Z","iopub.execute_input":"2021-06-26T07:49:23.255601Z","iopub.status.idle":"2021-06-26T07:49:23.260756Z","shell.execute_reply.started":"2021-06-26T07:49:23.255539Z","shell.execute_reply":"2021-06-26T07:49:23.25964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import RobustScaler\n\nscaler = RobustScaler()\n\n# trying xgboost again with the balanced dataset\ny_train = oversampled['DEATH_EVENT']\nX_train = oversampled.drop('DEATH_EVENT', axis=1)\nprint(\"Class Proportion after oversampling\",y_train.value_counts())\n\nprint(\"Train Size\", X_train.shape)\nprint(\"Test Size\", X_test.shape)\n\nX_train_scaled = scaler.fit_transform(X_train)\nX_train_scaled = pd.DataFrame(X_train_scaled)\n\nX_test_scaled = scaler.transform(X_test)\nX_test_scaled = pd.DataFrame(X_test_scaled)\n\nprediction_smote = {}\nfor model in models.keys():\n    print(\"Model {0}\".format(model))\n    smote = models[model]\n    f1 = CrossVal(X_train_scaled, y_train, smote)\n    print(\"Cross-Validation F1 Score is {:.2f}%\".format(f1.mean()))\n    smote.fit(X_train_scaled, y_train)\n    # Predict on test\n    smote_pred = smote.predict(X_test_scaled)\n    # predict probabilities\n    #probs = smote.predict_proba(X_test_scaled)\n    # keep probabilities for the positive outcome only\n    #probs = probs[:, 1]\n    prediction_smote[model] = smote_pred","metadata":{"execution":{"iopub.status.busy":"2021-06-26T07:50:00.661376Z","iopub.execute_input":"2021-06-26T07:50:00.661958Z","iopub.status.idle":"2021-06-26T07:53:43.216724Z","shell.execute_reply.started":"2021-06-26T07:50:00.661924Z","shell.execute_reply":"2021-06-26T07:53:43.215499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction_smote","metadata":{"execution":{"iopub.status.busy":"2021-06-26T07:54:43.555957Z","iopub.execute_input":"2021-06-26T07:54:43.556375Z","iopub.status.idle":"2021-06-26T07:54:43.565612Z","shell.execute_reply.started":"2021-06-26T07:54:43.556336Z","shell.execute_reply":"2021-06-26T07:54:43.564596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shap\nexplainer = shap.TreeExplainer(models['xgb'])\nshap_values = explainer.shap_values(X_test_scaled)\nshap.summary_plot(shap_values, X_test_scaled, plot_type=\"bar\")","metadata":{"execution":{"iopub.status.busy":"2021-06-26T07:54:46.074522Z","iopub.execute_input":"2021-06-26T07:54:46.074895Z","iopub.status.idle":"2021-06-26T07:54:54.813765Z","shell.execute_reply.started":"2021-06-26T07:54:46.074863Z","shell.execute_reply":"2021-06-26T07:54:54.812504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking Balanced accuracy\nfrom sklearn.metrics import balanced_accuracy_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef evaluate(Y_test, smote_pred):\n    b_a = balanced_accuracy_score(Y_test, smote_pred)\n    print(\"Balanced Test Accuracy is {:.2f}%\".format(b_a * 100.0))\n    f1_over = f1_score(Y_test, smote_pred)\n    print(\"F1 Score is {:.2f}%\".format(f1_over))\n    # assign cnf_matrix with result of confusion_matrix array\n    cnf_matrix = confusion_matrix(Y_test,smote_pred)\n    #create a heat map\n    sns.heatmap(pd.DataFrame(cnf_matrix), annot = True, cmap = 'Blues', fmt = 'd')\n    plt.xlabel('Predicted')\n    plt.ylabel('Expected')\n    plt.show()\n    recall = np.diag(cnf_matrix) / np.sum(cnf_matrix, axis = 1)\n    precision = np.diag(cnf_matrix) / np.sum(cnf_matrix, axis = 0)\n    print(\"Mean Recall\", np.mean(recall))\n    print(\"Mean Precision\", np.mean(precision))\n    return b_a, f1_over, recall, precision\n","metadata":{"execution":{"iopub.status.busy":"2021-06-26T07:54:58.832419Z","iopub.execute_input":"2021-06-26T07:54:58.832789Z","iopub.status.idle":"2021-06-26T07:54:58.842351Z","shell.execute_reply.started":"2021-06-26T07:54:58.83276Z","shell.execute_reply":"2021-06-26T07:54:58.841181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"b_accuracy = []\nf1_scores = []\nrecalls = []\nprecisions = []\nfor model in prediction_smote.keys():\n    print(\"\\nModel is {0}\".format(model))\n    a,b,c,d = evaluate(np.array(Y_test.astype(int)), prediction_smote[model])\n    b_accuracy.append(a)\n    f1_scores.append(b)\n    recalls.append(c)\n    precisions.append(d)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T07:55:03.380525Z","iopub.execute_input":"2021-06-26T07:55:03.380861Z","iopub.status.idle":"2021-06-26T07:55:04.734894Z","shell.execute_reply.started":"2021-06-26T07:55:03.380832Z","shell.execute_reply":"2021-06-26T07:55:04.733687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Name List of ML Models used\nmodels = ['Random Forest', 'Balanced Random Forest', 'XGB', 'LGBM', 'Balanced Bagging', 'Stacking', 'Voting']\ny_pos = np.arange(len(models)) #Position = 0,1,2,3,4,5,6\n# Plot Cross Validation Accuracy\nplt.figure(figsize=(12, 6))  \nplt.bar(y_pos, b_accuracy, align='center', alpha=0.8, color=sns.color_palette(\"PuRd\"))\nplt.xticks(y_pos, models)\nplt.ylabel('Balanced Accuracy')\nplt.title('Performance based on Balanced Accuracy')\n\n# Plot F1 Score\nplt.figure(figsize=(12, 6))  \nplt.bar(y_pos, f1_scores, align='center', alpha=0.8, color=sns.color_palette(\"RdPu\"))\nplt.xticks(y_pos, models)\nplt.ylabel('F1 Score')\nplt.title('Performance based on F1 Score')","metadata":{"execution":{"iopub.status.busy":"2021-06-26T07:56:37.75233Z","iopub.execute_input":"2021-06-26T07:56:37.752715Z","iopub.status.idle":"2021-06-26T07:56:38.168572Z","shell.execute_reply.started":"2021-06-26T07:56:37.75268Z","shell.execute_reply":"2021-06-26T07:56:38.16766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}