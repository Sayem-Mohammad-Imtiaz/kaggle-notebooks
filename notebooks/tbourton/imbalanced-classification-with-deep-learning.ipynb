{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imbalanced classification using tf","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import random\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nimport sklearn.metrics\nfrom sklearn.metrics import confusion_matrix as cm, classification_report as cr\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nrandom.seed(0)\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/company-bankruptcy-prediction/data.csv')\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"counts = df['Bankrupt?'].value_counts()\nn_neg = counts[counts.index == 0].values[0]\nn_pos = counts[counts.index == 1].values[0]\nprint(n_neg, n_pos)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ' Net Income Flag'\ndf = df.drop(columns=df.std()[(df.std() == 0)].index)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df, test_df = train_test_split(df, test_size=0.2)\ntrain_df, val_df = train_test_split(df, test_size=0.2)\n\n# Form np arrays of labels and features.\ny_train = np.array(train_df.pop('Bankrupt?'))\ny_val = np.array(val_df.pop('Bankrupt?'))\ny_test = np.array(test_df.pop('Bankrupt?'))\n\nx_train = np.array(train_df)\nx_val = np.array(val_df)\nx_test = np.array(test_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = StandardScaler()\nx_train = scaler.fit_transform(x_train)\n\nx_val = scaler.transform(x_val)\nx_test = scaler.transform(x_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns = train_df.columns  # [kbest.get_support()]\ntemp_df = pd.DataFrame(x_train, columns=columns)\ntemp_df['y'] = y_train\ncorr = temp_df.corr()\nplt.figure(figsize=(15, 15))\nsns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns)\nplt.show()\nplt.close()\n\ncorr = corr['y'].drop('y').abs().sort_values(ascending=False)\nprint(corr)\nprint(len(corr[corr > 0.05]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8), sharey=True, sharex=True)\nbins = ax1.hist(temp_df[temp_df['y'] == 0][' Net Income to Total Assets'], bins='auto', density=True)\nax2.hist(temp_df[temp_df['y'] == 1][' Net Income to Total Assets'], bins=bins[1], density=True)\nplt.show()\nplt.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots()\nscatter = ax.scatter(temp_df[' Net Income to Total Assets'], temp_df['y'], c=temp_df['y'], s=1)\nlegend1 = ax.legend(*scatter.legend_elements(), loc=\"upper left\", title=\"Classes\")\nax.add_artist(legend1)\nplt.show()\nplt.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest\n\nkbest = SelectKBest(k=50)\nx_train = kbest.fit_transform(x_train, y_train)\nx_test = kbest.transform(x_test)\nx_val = kbest.transform(x_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class PrintLRCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        print(f'LR at end of epoch {epoch} = {tf.keras.backend.eval(self.model.optimizer.lr(self.model.optimizer.iterations))}')\n        \n\ndef plot_history(history):\n    metrics = ['loss', 'prc', 'precision', 'recall']\n    for n, metric in enumerate(metrics):\n        name = metric.replace(\"_\",\" \").capitalize()\n        plt.subplot(2,2,n+1)\n        plt.plot(history.epoch, history.history[metric], label='Train')\n        plt.plot(history.epoch, history.history['val_'+metric], linestyle=\"--\", label='Val')\n        plt.xlabel('Epoch')\n        plt.ylabel(name)\n        if metric == 'loss':\n            plt.ylim([0, plt.ylim()[1]])\n        elif metric == 'auc':\n            plt.ylim([0.8,1])\n        else:\n            plt.ylim([0,1])\n            \n        plt.legend()\n    plt.show()\n\n    \ndef report(y_true, y_pred, p=0.5):\n    y_pred = y_pred = np.where(y_pred >= 0.5, 1, 0).squeeze()\n    cm_ = cm(y_true=y_true, y_pred=y_pred)\n    plt.figure(figsize=(5,5))\n    sns.heatmap(cm_, annot=True, fmt=\"d\")\n    plt.title('Confusion matrix @{:.2f}'.format(p))\n    plt.ylabel('Actual label')\n    plt.xlabel('Predicted label')\n    plt.show()\n\n    print('TN: ', cm_[0][0])\n    print('FP: ', cm_[0][1])\n    print('FN: ', cm_[1][0])\n    print('TP: ', cm_[1][1])\n\n    print(cr(y_true=y_true, y_pred=y_pred))\n    \n    \ndef plot_roc(y_true, y_pred, **kwargs):\n    fp, tp, _ = sklearn.metrics.roc_curve(y_true, y_pred)\n\n    plt.plot(100*fp, 100*tp, linewidth=2, **kwargs)\n    plt.xlabel('False positives [%]')\n    plt.ylabel('True positives [%]')\n    plt.xlim([-0.5,20])\n    plt.ylim([80,100.5])\n    plt.grid(True)\n    ax = plt.gca()\n    ax.set_aspect('equal')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Stupid baselines","metadata":{}},{"cell_type":"code","source":"def guess_all_neg(x):\n    return np.zeros(len(x), dtype='float32')\n\n\ny_pred = guess_all_neg(x_train)\nreport(y_train, y_pred)\n\ny_pred = guess_all_neg(x_test)\nreport(y_test, y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model with class weights + bias init","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 2048\nMETRICS = [\n      keras.metrics.TruePositives(name='tp'),\n      keras.metrics.FalsePositives(name='fp'),\n      keras.metrics.TrueNegatives(name='tn'),\n      keras.metrics.FalseNegatives(name='fn'), \n      keras.metrics.BinaryAccuracy(name='accuracy'),\n      keras.metrics.Precision(name='precision'),\n      keras.metrics.Recall(name='recall'),\n      keras.metrics.AUC(name='auc'),\n      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n]\n\n\ndef make_model(metrics=METRICS, output_bias=None, lr=1e-3, dropout=0.5):\n    if output_bias is not None:\n        output_bias = tf.keras.initializers.Constant(output_bias)\n    model = keras.Sequential([\n        keras.layers.Dense(128, activation='relu', input_shape=(x_train.shape[-1],)),\n        keras.layers.Dense(128, activation='relu'),\n        keras.layers.Dropout(dropout),\n        keras.layers.Dense(1, activation='sigmoid', bias_initializer=output_bias),\n    ])\n\n    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr),\n                  loss=keras.losses.BinaryCrossentropy(),\n                  metrics=metrics)\n\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We want initial loss to be around n_pos/(n_pos + n_neg)=220/6819~0.03\n# https://karpathy.github.io/2019/04/25/recipe/#2-set-up-the-end-to-end-trainingevaluation-skeleton--get-dumb-baselines\n\n# To do this we set the initial_bias = log(n_pos/n_neg)\nEPOCHS = 200\n\ninitial_bias = np.log([n_pos / n_neg])\nprint(initial_bias)\n\nrandom.seed(0)\nlr = 1e-3\nlr = tf.keras.experimental.CosineDecay(lr, decay_steps=EPOCHS * len(x_train)//BATCH_SIZE)\nmodel = make_model(output_bias=initial_bias, lr=lr)\nmodel.summary()\nmodel.save_weights('initial_weights')\n\nresults = model.evaluate(x_train, y_train, batch_size=BATCH_SIZE, verbose=0)\nprint(results)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random.seed(0)\n\ncallbacks = [\n    tf.keras.callbacks.EarlyStopping(monitor='val_prc', verbose=1, patience=20, mode='max', restore_best_weights=True),\n    # PrintLRCallback()\n    # tf.keras.callbacks.ReduceLROnPlateau(monitor='val_prc', verbose=1, patience=10, mode='max', min_lr=0, factor=0.2)\n]\n\ntotal = n_pos + n_neg\nclass_weight = {0: (total / n_neg)/2.0, 1: (total / n_pos)/2.0}\nprint(class_weight)\n\nhistory = model.fit(\n    x_train,\n    y_train,\n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS,\n    callbacks=callbacks,\n    validation_data=(x_val, y_val),\n    class_weight=class_weight,\n    verbose=1\n)\n\nresults = model.evaluate(x_train, y_train, batch_size=BATCH_SIZE, verbose=0)\nfor name, value in zip(model.metrics_names, results):\n    print(name, ': ', value)\n\nresults = model.evaluate(x_val, y_val, batch_size=BATCH_SIZE, verbose=0)\nfor name, value in zip(model.metrics_names, results):\n    print(name, ': ', value)\n\nplot_history(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(x_train)\nreport(y_train, y_pred)\nplot_roc(y_train, y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(x_test)\nreport(y_test, y_pred)\nplot_roc(y_test, y_pred)\n\nresults = model.evaluate(x_test, y_test, batch_size=BATCH_SIZE, verbose=0)\nfor name, value in zip(model.metrics_names, results):\n    print(name, ': ', value)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SMOTE","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE \n\nsm = SMOTE(random_state=0)\nx_train_res, y_train_res = sm.fit_resample(x_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random.seed(0)\n\nmodel = make_model()\nmodel.load_weights('initial_weights')\nmodel.layers[-1].bias.assign([0])\n\nhistory = model.fit(\n    x_train_res,\n    y_train_res,\n    epochs=EPOCHS,\n    callbacks=callbacks,\n    batch_size=BATCH_SIZE,\n    verbose=1,\n    validation_data=(x_val, y_val)\n)\n\nresults = model.evaluate(x_train_res, y_train_res, batch_size=BATCH_SIZE, verbose=0)\nfor name, value in zip(model.metrics_names, results):\n    print(name, ': ', value)\n\nresults = model.evaluate(x_val, y_val, batch_size=BATCH_SIZE, verbose=0)\nfor name, value in zip(model.metrics_names, results):\n    print(name, ': ', value)\n\nplot_history(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(x_train)\nreport(y_train, y_pred)\nplot_roc(y_train, y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(x_test)\nreport(y_test, y_pred)\nplot_roc(y_test, y_pred)\n\nresults = model.evaluate(x_test, y_test, batch_size=BATCH_SIZE, verbose=0)\nfor name, value in zip(model.metrics_names, results):\n    print(name, ': ', value)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}