{"cells":[{"metadata":{"_uuid":"24c9e273-6b0e-4f04-8e92-3932e2ef3991","_cell_guid":"bd94d1eb-d41b-4d94-8e00-2d0355a66a47","trusted":true},"cell_type":"code","source":"#!/usr/bin/env python\n# coding: utf-8\n\n# In[4]:\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\nimport seaborn as sns\n\n\n# In[5]:\n\n\npd.set_option('display.max_columns',500)\npd.set_option('display.max_rows',1400000)\nnp.set_printoptions(suppress=True)\n\n\n# In[6]:\n\n\ndframe =pd.read_csv('C:/Users/user/Desktop/IVY WORK BOOK/PYTHON/Python Datasets/Regression Datasets/epl2020.csv')\n\n\n# In[7]:\n\n\ndframe\n\n\n# In[8]:\n\n\ndframe=dframe.drop(labels=['Unnamed: 0','matchDay'], axis=1)\n\n\n# In[9]:\n\n\ndframe.info()\n\n\n# In[10]:\n\n\ndframe.isnull().sum().any()\n\n\n# In[11]:\n\n\ndframe.nunique()\n\n\n# In[10]:\n\n\ndframe.hist(figsize=(150,200))\n\n\n# In[11]:\n\n\ndframe.plot.scatter(x='npxGD',y='tot_points',figsize=(15,10))\n\n\n# In[12]:\n\n\ndframe=dframe.drop(labels=['result','date','matchtime','pts'], axis=1)\n\n\n# In[13]:\n\n\nfrom sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\ndframe['h_a']=le.fit_transform(dframe['h_a'])\ndframe['teamId']=le.fit_transform(dframe['teamId'])\n\n\n# In[61]:\n\n\nlen(le.classes_)\n\n\n# In[14]:\n\n\ndframe.head()\n\n\n# In[15]:\n\n\ndframe.groupby('teamId')['tot_points'].sum().plot(kind='bar',figsize=(15,10))\n\n\n# In[16]:\n\n\ndframe.groupby('teamId')['tot_points'].sum().sort_values(ascending=False)\n\n\n# In[17]:\n\n\nArr=np.array(dframe)\n\n\n# In[18]:\n\n\nmu = np.mean(Arr)\nsigma = np.std(Arr)\nprint(mu)\nprint(sigma)\nx =np.random.normal(mu, sigma, size=200)\nfig, ax = plt.subplots()\nax.hist(x, 20)\nax.set_title('Historgram')\nax.set_xlabel('bin range')\nax.set_ylabel('frequency')\n\n\nfig.tight_layout()\nplt.show()\n\n\n# In[19]:\n\n\ndframe['tot_points'].values\n\n\n# In[20]:\n\n\ndframe.nunique()\n\n\n# In[21]:\n\n\ndframe.head(5)\n\n\n# In[22]:\n\n\ndframe['npxGA'].isin(dframe['npxG']).all()\n\n\n# In[33]:\n\n\ncat_cols=['h_a','deep','deep_allowed','scored','missed','wins','draws','loses','teamId','round','HS.x',\n           'HST.x','HF.x','HC.x','HY.x','HR.x','AS.x','AST.x','AF.x','AC.x','AY.x','AR.x']\n\nTarget=['tot_points']\n\ncont_cols=['xG','xGA','npxG','npxGA','xpts','npxGD','ppda_cal','allowed_ppda','tot_goal','tot_con','B365H.x',\n            'B365D.x','B365A.x','HtrgPerc','AtrgPerc']\n\n\n# In[23]:\n\n\ndframe.shape\n\n\n# In[24]:\n\n\nvariables=dframe.columns\n\n\n# In[25]:\n\n\nfrom sklearn.covariance import EllipticEnvelope\n\n\n# In[26]:\n\n\nX=dframe[variables].values\nelp=EllipticEnvelope(random_state=10)\noutlier_X=elp.fit_predict(X)\n\n\n# In[27]:\n\n\ndframe['outliers']=outlier_X\n\n\n# In[28]:\n\n\ndframe.groupby('outliers').size().value_counts()\n\n\n# In[29]:\n\n\ncon=dframe['outliers']==-1\ndelete=dframe[con].index\ndframe=dframe.drop(delete)\n\n\n# In[30]:\n\n\nfrom sklearn.linear_model import Lasso\nfrom sklearn.feature_selection import SelectFromModel\n\n\n# In[34]:\n\n\ny_train=dframe[Target]\nX_train=dframe.drop(labels='tot_points', axis=1)\n\n\n# In[35]:\n\n\nX_train.head()\n\n\n# In[36]:\n\n\ny_train.head()\n\n\n# In[37]:\n\n\nfeature_sel_model = SelectFromModel(Lasso(alpha=0.05, random_state=5)) \nfeature_sel_model.fit(X_train, y_train)\n\n\n# In[38]:\n\n\nselected_feat = X_train.columns[feature_sel_model.get_support()]\n\n\n# In[39]:\n\n\nprint('total features: {}'.format((X_train.shape[1])))\nprint('selected features: {}'.format(len(selected_feat)))\n\n\n# In[40]:\n\n\nselected_feat\n\n\n# In[41]:\n\n\nX=X_train[selected_feat].values\ny=y_train[Target].values\n\n\n# In[42]:\n\n\nprint(X[0:10])\nprint(y[0:10])\n\n\n# In[43]:\n\n\nfrom sklearn.preprocessing import StandardScaler\n\nPredictorscalar=StandardScaler()\nTargetscalar=StandardScaler()\nX=Predictorscalar.fit_transform(X)\ny=Targetscalar.fit_transform(y)\n\n\n# In[52]:\n\n\ndframe2=pd.DataFrame(X,columns=selected_feat)\ndframe2['target']=y\n\n\n# In[53]:\n\n\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import metrics\n\n\n# In[54]:\n\n\nkf = KFold(n_splits=8)\nkf.get_n_splits(X)\nfor train_index, test_index in kf.split(X):\n    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n\n\n# In[55]:\n\n\nmetrics.SCORERS.keys()\n\n\n# In[48]:\n\n\ndframe2=pd.to_pickle(dframe2,'C:/Users/user/Desktop/IVY WORK BOOK/PYTHON/pickle files/dframe2.pkl')\n\n\n# In[57]:\n\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import metrics\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n\n\n# In[59]:\n\n\nfrom catboost import CatBoostRegressor\n\n\n# In[60]:\n\n\nparams={\n    \"iterations\": [100,200,300],\n    \"learning_rate\" : [0.05,0.01,0.007,0.02],\n    \"loss_function\":['MAE','RMSE'],\n    \"bagging_temperature\":[8,10,5],\n     \"max_depth\":[2,3,5]\n     }\n\n\n# In[61]:\n\n\nclf=CatBoostRegressor()\n\n\n# In[62]:\n\n\nGrid_search=GridSearchCV(clf,param_grid=params,scoring='neg_mean_absolute_error',n_jobs=-1,cv=7,verbose=3)\n\n\n# In[63]:\n\n\npredictmodel=Grid_search.fit(X_train, y_train)\npredictions=predictmodel.predict(X_test)\nprint(\"R2 score\",metrics.r2_score(y_test,predictions))\nerror=metrics.mean_squared_error(y_test,predictions)\nprint(\"mean Absolute error\",metrics.mean_absolute_error(y_test,predictions))\nprint(\"Accuracy\",(100-error))\n\n\n# In[65]:\n\n\ncross_val=cross_val_score(Grid_search,X,y,cv=2)\ncross_val.mean()\nprint(cross_val)\n\n\n# In[74]:\n\n\nplt.hist(y_test,bins=10,align='right')\n\n\n# In[75]:\n\n\nplt.hist(predictions,bins=10,align='right')\n\n\n# In[95]:\n\n\nplt.scatter(y_test,predictions,c=predictions,s=50)\nplt.show()\nplt.tight_layout()\n\n\n# In[1]:\n\n\nfrom pytorch_tabnet.tab_model import TabNetRegressor\n\n\n# In[60]:\n\n\ndframe2.nunique()\n\n\n# In[162]:\n\n\ndframe2.info()\n\n\n# In[292]:\n\n\nif \"Set\" not in dframe2.columns:\n    dframe2[\"Set\"] = np.random.choice([\"train\", \"valid\", \"test\"], p =[.8, .1, .1], size=(dframe2.shape[0],))\n\ntrain_indices = dframe2[dframe2.Set==\"train\"].index\nvalid_indices = dframe2[dframe2.Set==\"valid\"].index\ntest_indices = dframe2[dframe2.Set==\"test\"].index    \n    \n\n\n# In[293]:\n\n\nprint(train_indices)\nprint(valid_indices)\nprint(test_indices)\n\n\n# In[294]:\n\n\ncategorical_dims={}\n\n\n# In[295]:\n\n\nunused_feat='set'\nTARGET='target'\n\nfeatures = [ col for col in dframe2.columns if col not in unused_feat]\n\ncat_idxs = [ i for i, f in enumerate(features) if f in cat_cols]\n\n\ncat_dims = [ categorical_dims[f] for i, f in enumerate(features) if f in cat_cols]\n\n\n# In[296]:\n\n\ncat_cols=[['teamId']]\ncat_dims=[20]\ncat_idxs=['teamId']\n\n\n# In[297]:\n\n\nTabnetmodel=TabNetRegressor(cat_dims=cat_dims, cat_emb_dim=cat_emb_dim)\n\n\n# In[298]:\n\n\nfeautres=['npxGA', 'deep', 'deep_allowed', 'scored', 'missed', 'wins', 'loses',\n       'teamId', 'ppda_cal', 'allowed_ppda', 'round', 'tot_goal', 'tot_con',\n       'HS.x', 'HST.x', 'HF.x', 'HY.x', 'AS.x', 'AST.x', 'AC.x', 'AY.x',\n       'B365H.x', 'B365A.x']\n\n\n# In[299]:\n\n\nX_train = dframe2[feautres].values[train_indices]\ny_train = dframe2[TARGET].values[train_indices].reshape(-1,1)\n\nX_valid = dframe2[feautres].values[valid_indices]\ny_valid = dframe2[TARGET].values[valid_indices].reshape(-1,1)\n\nX_test = dframe2[feautres].values[test_indices]\ny_test = dframe2[TARGET].values[test_indices].reshape(-1,1)\n\n\n# In[300]:\n\n\nprint(X_train)\nprint(y_train)\nprint(X_valid)\nprint(y_valid)\nprint(X_test)\nprint(y_test)\n\n\n# In[301]:\n\n\npredictmodel=Tabnetmodel.fit(X_train, y_train,X_valid, y_valid,max_epochs=500,patience=50,batch_size=1024,virtual_batch_size=128,\nnum_workers=0,drop_last=False)\n\n\n# In[302]:\n\n\npredictions=Tabnetmodel.predict(X_test)\n\n\n# In[303]:\n\n\nTabnetmodel.feature_importances_\n\n\n# In[304]:\n\n\nTabnetmodel.history['valid']['loss']\n\n\n# In[305]:\n\n\nprint('Best Valid score',Tabnetmodel.best_cost)\n\n\n# In[306]:\n\n\nprint(\"Accuracy\",100-metrics.mean_absolute_error(predictions,y_test))\n\n\n# In[307]:\n\n\nX=Predictorscalar.inverse_transform(X_test).astype('float64')\n\n\n# In[308]:\n\n\nEPL=pd.DataFrame(X, columns=feautres)\n\n\n# In[310]:\n\n\nY=Targetscalar.inverse_transform(y_test)\n\n\n# In[311]:\n\n\nEPL['Total_Point']=Y\n\n\n# In[312]:\n\n\npreds=Targetscalar.inverse_transform(predictions)\n\n\n# In[313]:\n\n\nEPL['predicted_Point']=preds\n\n\n# In[317]:\n\n\nEPL.groupby('teamId')['predicted_Point'].sum().plot(kind='bar',figsize=(15,10))\n\n\n# In[318]:\n\n\nEPL.groupby('teamId')['predicted_Point'].sum().sort_values(ascending=False)\n\n\n# In[319]:\n\n\ndframe.groupby('teamId')['tot_points'].sum().sort_values(ascending=False)\n\n\n# In[324]:\n\n\nEPL['Diiferance']=EPL['Total_Point']-EPL['predicted_Point']\nEPL['Diiferance'].hist(figsize=(15,10))\n\n\n# In[ ]:","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}