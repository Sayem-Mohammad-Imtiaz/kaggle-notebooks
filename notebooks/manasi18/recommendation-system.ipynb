{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":" Myself [Manasi Pandharkar](\nhttps://www.linkedin.com/in/manasi-kulkarni-pandharkar-094784a/) is creating an ML based Recommendation Engine in collaboration with [Mr. Rocky Jagtiani](https://www.linkedin.com/today/author/rocky-jagtiani-3b390649/)\n \n> This is a simple Data Science project on Movies Recommendation System which recommends you the movie based on the Review of previous movie.\n\n> Dataset: tmdb_5000_credits.csv,tmdb_5000_movies.csv from kaggle itself\n\n> Tech Stack used: pandas, Scikit-learn,Python\n\n> Recommended links : \n\n> https://datascience.suvenconsultants.com  ( For DS / AI / ML )\n\n> https://monster.suvenconsultants.com  ( For Web development )","metadata":{}},{"cell_type":"markdown","source":"Recommender systems are among the most popular applications of data science today. They are used to predict the \"rating\" or \"preference\" that a user would give to an item. Almost every major tech company has applied them in some form. Amazon uses it to suggest products to customers, YouTube uses it to decide which video to play next on autoplay, and Facebook uses it to recommend pages to like and people to follow.\n\nRecommender systems have also been developed to explore research articles and experts, collaborators, and financial services. ","metadata":{}},{"cell_type":"markdown","source":"Recommender systems can be classified into Two types:\n\n> **Content-based recommenders**: suggest similar items based on a particular item. This system uses item metadata, such as genre, director, description, actors, etc. for movies, to make these recommendations. The general idea behind these recommender systems is that if a person likes a particular item, he or she will also like an item that is similar to it. And to recommend that, it will make use of the user's past item metadata. A good example could be YouTube, where based on your history, it suggests you new videos that you could potentially watch.\n\n> **Collaborative filtering engines**: these systems are widely used, and they try to predict the rating or preference that a user would give an item-based on past ratings and preferences of other users. Collaborative filters do not require item metadata like its content-based counterparts.","metadata":{}},{"cell_type":"markdown","source":"Here we are going to implement **Content Based Filtering**","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import Pandas\nimport pandas as pd\n\n# Loading Data sets\nfull_url='/kaggle/input/tmdb-movie-metadata/tmdb_5000_credits.csv'\n\nfull_url1='/kaggle/input/tmdb-movie-metadata/tmdb_5000_movies.csv'\n\ncredits = pd.read_csv(full_url)\nmovies=pd.read_csv(full_url1)","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Printing 1st 5 elements of credits dataset\ncredits.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Printing 1st 5 elements of movies dataset\nmovies.head(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Printing the shapes of both the datasets\nprint(\"Credits:\",credits.shape)\nprint(\"Movies:\",movies.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Renaming the column of credits data set\ncredits_renamed=credits.rename(index=str,columns={'movie_id':'id'})\ncredits_renamed.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Merging both data sets\nmerge=movies.merge(credits_renamed,on='id')\nmerge.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dropping unnecessary columns \ncleaned=merge.drop(columns=['homepage','title_x','title_y','status','production_countries'])\ncleaned.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cleaned['overview'].head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cleaned['overview'].isnull().sum() #checking for Null vaules for overview column","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Replace NaN with an empty string\ncleaned['overview'] = cleaned['overview'].fillna('')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Import TfIdfVectorizer from scikit-learn\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n#Define a TF-IDF Vectorizer Object. Remove all english stop words such as 'the', 'a'\ntfidf = TfidfVectorizer(stop_words='english',ngram_range=(1,3),min_df=3,analyzer='word')\n#refernce: http://www.tfidf.com/\n\n#Construct the required TF-IDF matrix by fitting and transforming the data\ntfidf_matrix = tfidf.fit_transform(cleaned['overview'])\n\n#Output the shape of tfidf_matrix\ntfidf_matrix.shape\n\n#Ref:https://deepai.org/machine-learning-glossary-and-terms/cosine-similarity","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity\n\n# Compute the cosine similarity matrix\ncosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(cosine_sim.shape)\nprint(cosine_sim[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are going to define a function that takes in a movie title as an input and outputs a list of 10 most similar movies. Firstly, for this , we need a reverse mapping of movie titles and DataFrame indices. In other words , we need a mechanism to identify the index of a movie in our metadata DataFrame, given its title.","metadata":{}},{"cell_type":"code","source":"#Construct a reverse map of indices and movie titles\nindices = pd.Series(cleaned.index, index=cleaned['original_title']).drop_duplicates()\n\nindices[ :5]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Steps:\n1. Get the index of the movie given its title\n2. Get the list of cosine similarity scores for that particular movie with all movies. Convert it into a list of tuples where the first element is its position and second is the similarity score.\n3. Sort the list of tuples based on similarity score. i,e the second element.\n4. Get the top 10 elements of the list. Ignore the first element as it refers to self.\n5. Return the titles corresponding to the indices of the top elements.","metadata":{}},{"cell_type":"code","source":"def get_recommendations(title, cosine_sim=cosine_sim):\n    # Get the index of the movie that matches the title\n    idx = indices[title]\n\n    # Get the pairwsie similarity scores of all movies with that movie\n    sim_scores = list(enumerate(cosine_sim[idx]))\n    print(sim_scores[ :5])\n    print(\"--------------------\")\n\n    # Sort the movies based on the similarity scores\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n\n    # Get the scores of the 10 most similar movies\n    sim_scores = sim_scores[1:11]\n    print(sim_scores[ :5])\n    print(\"--------------------\")\n    # Get the movie indices\n    movie_indices = [i[0] for i in sim_scores]\n\n    # Return the top 10 most similar movies\n    return cleaned['original_title'].iloc[movie_indices]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting the recommendation\nget_recommendations('Avatar',cosine_sim)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_recommendations('The Dark Knight Rises',cosine_sim)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Enhancement","metadata":{}},{"cell_type":"code","source":"cleaned.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cleaned['crew'].values[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## From new features cast , crew and features\n## we need to extract the three neq most important actors\n## the directors and the keywords associated with that movie\n\n## First convert the data into a way that is usable\n\n##parse the stringified features into their corresponding python objects\nfrom ast import literal_eval\n\nfeatures = ['cast', 'crew','keywords','genres']\nfor feature in features:\n    cleaned[feature]= cleaned[feature].apply(literal_eval)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cleaned['crew'].values[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##function to get director's name\ndef get_director(x):\n    for i in x:\n        if i['job'] == 'Director':\n            return i['name']\n    return np.nan","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next we will write a function that will return the top 3 elements or the entire list, whichever is more. Here the list refers to the cast, keyword or genres","metadata":{}},{"cell_type":"code","source":"def get_list(x):\n    if isinstance(x,list):\n        names = [i['name'] for i in x]\n        #check if more than 3 elements exist, if yes then return only first three\n        if len(x) > 3:\n            names = names[ :3]\n        return names\n    ## return empty list in case of missing or mal formed data\n    return []","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cleaned['director']= cleaned['crew'].apply(get_director)\n\nfeatures= ['cast','keywords','genres']\nfor feature in features:\n    cleaned[feature]=cleaned[feature].apply(get_list)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Print the fetures of the first three movies\ncleaned[['original_title','cast','director','keywords','genres']].head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## function to convert all strings to lowercase and strip names of spaces\ndef cleaned_data(x):\n    if isinstance(x,list):\n        return [str.lower(i.replace(\" \",\"\")) for i in x]\n    else:\n        if isinstance(x,str):\n            return str.lower(x.replace(\" \",\"\"))\n        else:\n            return ''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Apply clean_data function to your features\nfeatures = ['cast','keywords','director','genres']\nfor feature in features:\n    cleaned[feature]=cleaned[feature].apply(cleaned_data)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_metadata(x):\n    return ' '.join(x['keywords']) + ' ' + ' '.join(x['cast']) + ' ' + ' '.join(x['director']) + ' ' + ' '.join(x['genres'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## create a new metadata feature\ncleaned['metadata']= cleaned.apply(create_metadata, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cleaned[['metadata']].head(2)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"## import the CountVectorizer and create the count matrix\n\nfrom sklearn.feature_extraction.text import CountVectorizer\ncount = CountVectorizer(stop_words ='english')\ncount_matrix = count.fit_transform(cleaned['metadata'])\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_matrix.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Compute the cosine similarity matrix based on the count_matrix\nfrom sklearn.metrics.pairwise import cosine_similarity\ncosine_sim2 = cosine_similarity(count_matrix, count_matrix)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Reset index of your main Dataframe  and construct reverse mapping as before\n\nindices = pd.Series(cleaned.index, index = cleaned['original_title'])\nindices[ :2]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## You can now reusse your get_recommendation() function by passing in the new cosine_sim2 matrix as your second argument\nget_recommendations('The Dark Knight Rises',cosine_sim2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_recommendations('The Godfather',cosine_sim2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I would like to humbly and sincerely thank my mentor [Rocky Jagtiani](https://www.linkedin.com/today/author/rocky-jagtiani-3b390649/). He is more of a friend to me then mentor. The Machine Learning course taught by him and various projects we did and are still doing is the best way to learn and skill in Data Science field. See https://datascience.suvenconsultants.com once for more.","metadata":{}}]}