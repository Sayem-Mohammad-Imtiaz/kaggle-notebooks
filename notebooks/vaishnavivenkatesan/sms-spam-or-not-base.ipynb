{"cells":[{"metadata":{},"cell_type":"markdown","source":"Source:\n\nhttps://docs.python.org/3/library/codecs.html#standard-encodings\n\nhttps://www.kaggle.com/devghiles/step-by-step-solution-with-f1-score-as-a-metric\n\nhttps://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n\nTo rename:\nhttps://stackoverflow.com/questions/11346283/renaming-columns-in-pandas\n\nTo change cols:\nhttps://stackoverflow.com/questions/12329853/how-to-rearrange-pandas-column-sequence/23741704\n\nhttps://rajacsp.github.io/mlnotes/python/data-wrangling/advanced-custom-lambda/\n","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FILEPATH = '/kaggle/input/sms-spam-collection-dataset/spam.csv'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(FILEPATH, encoding='iso-8859-1', engine = 'c') # engine 'c' used instead of 'python' for higher performance\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# delete unnecessary cols\ncols = ['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4']\n\ndf.drop(cols, axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Title change v1 = result, v2 = input\n\ndf.rename(columns={'v1':'Classification','v2':'Sms content'},inplace=True)\n\n# we can also use df.rename() option here","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reorder options - must be applicable for all cols\ndf = df[['Sms content','Classification']]\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.count()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print first string\n\ndf.iloc[0][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.iloc[2][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def message_length(msg):\n    \n    msg_words = msg.split(' ')\n    \n    msg_len = len(msg_words)\n    \n    return msg_len","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(message_length(df.iloc[1][0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a new col called 'message_word_length' showing how many words in the message\ndf['words_count'] = df['Sms content'].apply(message_length)\ndf.head()\n\n\n# ref: https://rajacsp.github.io/mlnotes/python/data-wrangling/advanced-custom-lambda/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# show the unique labels\n\ndf['Classification'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(find_length(df.iloc[0][0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a new col called 'message_word_length' showing how many words in the message\ndf['msg_length'] = df['Sms content'].apply(lambda x:len(x))\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# History words count\n\nimport matplotlib.pyplot as plt\n\n# to avoid popups use inline\n%matplotlib inline ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plt.hist(data['label'], bins=3, weights=np.ones(len(data['label'])) / len(data['label']))\n\nimport numpy as np\n\nplt.hist(df['words_count'], bins = 50, alpha=0.5)\nplt.hist(df['msg_length'], bins=50 ,alpha=0.3)\nplt.xlabel('Word Length')\nplt.ylabel('Group Count')\nplt.title('Word Length Histogram')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find more than 80 words\ndf['words_count']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df[(df['words_count'] > 80) & (df['msg_length'] > 100)]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# encode\nfrom sklearn import preprocessing\n\nencode = preprocessing.LabelEncoder()\ndf['find spam'] = encode.fit_transform(df['Classification'])\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import string\nstring.punctuation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_punctuation(text):\n    new_text=''.join([char for char in text if char not in string.punctuation])\n    return new_text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['new_sms']=df['Sms content'].apply(lambda row : remove_punctuation(row))\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\ndef tokenize(text):\n    tokens=re.split('\\W+',text)\n    return tokens ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['tokenized_text']=df['new_sms'].apply(lambda row : tokenize(row.lower()))\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nstopwords=nltk.corpus.stopwords.words('english')\nstopwords[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_stopwords(text):\n    clean_text=[word for word in text if word not in stopwords]\n    return clean_text ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['clean_text'] = df['tokenized_text'].apply(lambda row : remove_stopwords(row))\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ps = nltk.PorterStemmer()\ndir(ps)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom nltk.stem import PorterStemmer\ndef stemming(tokenized_text):\n    stemmed_text=[ps.stem(word) for word in tokenized_text]\n    return stemmed_text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['stemmed_text']=df['clean_text'].apply(lambda row : stemming(row))\ndf[['Sms content','stemmed_text']].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_final_text(stemmed_text):\n    final_text=\" \".join([word for word in stemmed_text])\n    return final_text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['final_text']=df['stemmed_text'].apply(lambda row : get_final_text(row))\ndf.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}