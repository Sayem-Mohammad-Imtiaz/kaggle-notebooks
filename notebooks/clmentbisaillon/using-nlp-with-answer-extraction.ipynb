{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install transformers","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Question: \n# What do we know about vaccines and therapeutics?"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\ndata_path = \"/kaggle/input/CORD-19-research-challenge/2020-03-13/\"\n\nsources = pd.read_csv(data_path + \"all_sources_metadata_2020-03-13.csv\")\nsources = sources[[\"title\", \"abstract\", \"Microsoft Academic Paper ID\"]].dropna(subset=['title', 'abstract'])\n\n\n\n\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Initialize the model and tokenizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import AutoModelForQuestionAnswering, AutoTokenizer\nimport torch\n\ntokenizer = AutoTokenizer.from_pretrained(\"bert-large-cased-whole-word-masking-finetuned-squad\")\nmodel = AutoModelForQuestionAnswering.from_pretrained(\"bert-large-cased-whole-word-masking-finetuned-squad\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# todo: Probably a better way \nsources = sources[sources['abstract'].str.contains(\"ADE\")]\n\n# Just a test\n# Put all the titles together and try answer extraction\n\n\ndef chunkTitles(titles, nb):\n    total = len(titles)\n    delta = int(total / nb)\n    \n    chunks = []\n    for i in range(0, total, nb):\n        chunks.append(titles[i: i + nb])\n        \n    return chunks\n\n\nabstracts = sources['abstract'].astype(str)\n\nquestion = \"What are the methods for evaluating complication of Antibody-Dependent Enhancement?\"\n\n\nfor abstracts_chunked in chunkTitles(abstracts, 1):\n    abstracts_together = \" \".join((\"\".join(abstracts_chunked)).split(\" \")[:200])\n    \n    encoded_question = tokenizer.encode_plus(question, abstracts_together, add_special_tokens=True, return_tensors=\"pt\")\n    input_ids = encoded_question[\"input_ids\"]\n    answer_start_scores, answer_end_scores = model(input_ids)\n\n    answer_start = torch.argmax(answer_start_scores)\n    answer_end = torch.argmax(answer_end_scores)\n\n    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[0][answer_start.data:answer_end.data].tolist()))\n    \n    \n    if len(answer) > 0:\n        print(answer)\n        print()\n        \n        \n#todo: Maybe take all the responses and make a summary?\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}