{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Breast Cancer Diagnostic Classification Models and their performace comparison\n- The following notebook contains exploratory data analysis and ML classification models to classify if a cancer is benign or malignant \n- Dataset used: Breast Cancer Wisconsin (Diagnostic) Data Set (https://www.kaggle.com/uciml/breast-cancer-wisconsin-data).\n- In this notebook we are going to compare the various ML classification algorithms using metrics like:\n - Classification Accuracy\n - Confusion Matrix\n - Precision and Recall\n - F1 score","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2021-09-08T03:48:42.297359Z","iopub.execute_input":"2021-09-08T03:48:42.297785Z","iopub.status.idle":"2021-09-08T03:48:43.91025Z","shell.execute_reply.started":"2021-09-08T03:48:42.297671Z","shell.execute_reply":"2021-09-08T03:48:43.909222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ntrain = pd.read_csv(os.path.join(dirname, filename))\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-08T03:48:43.911674Z","iopub.execute_input":"2021-09-08T03:48:43.911987Z","iopub.status.idle":"2021-09-08T03:48:43.981239Z","shell.execute_reply.started":"2021-09-08T03:48:43.911956Z","shell.execute_reply":"2021-09-08T03:48:43.980227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.drop([\"Unnamed: 32\"], axis=1)\ntrain.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-08T03:48:49.937939Z","iopub.execute_input":"2021-09-08T03:48:49.938265Z","iopub.status.idle":"2021-09-08T03:48:49.948284Z","shell.execute_reply.started":"2021-09-08T03:48:49.938238Z","shell.execute_reply":"2021-09-08T03:48:49.947421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Heatmap to mark all the missing values in white colour.\nsns.heatmap(train.isnull(), cbar=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T03:48:51.021603Z","iopub.execute_input":"2021-09-08T03:48:51.021935Z","iopub.status.idle":"2021-09-08T03:48:51.726004Z","shell.execute_reply.started":"2021-09-08T03:48:51.021906Z","shell.execute_reply":"2021-09-08T03:48:51.725015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"diagnosis\"].replace({\"M\":2, \"B\":1}, inplace=True)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-08T03:48:53.097887Z","iopub.execute_input":"2021-09-08T03:48:53.099111Z","iopub.status.idle":"2021-09-08T03:48:53.136395Z","shell.execute_reply.started":"2021-09-08T03:48:53.099074Z","shell.execute_reply":"2021-09-08T03:48:53.135347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_corr = train.corr()","metadata":{"execution":{"iopub.status.busy":"2021-09-08T03:48:54.428307Z","iopub.execute_input":"2021-09-08T03:48:54.428875Z","iopub.status.idle":"2021-09-08T03:48:54.439527Z","shell.execute_reply.started":"2021-09-08T03:48:54.428825Z","shell.execute_reply":"2021-09-08T03:48:54.438498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Heatmap to show the correlation matrix of the features.","metadata":{}},{"cell_type":"code","source":"plt.subplots(figsize=(30, 30))\nax = sns.heatmap(\n    train_corr,\n    vmin = -1.0, vmax = 1.0, center=0,\n    cmap = sns.diverging_palette(20, 220),\n    annot = True,\n    square = True\n)\n\nax.set_xticklabels(\n    ax.get_xticklabels(),\n    horizontalalignment='right'\n)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T03:48:56.922777Z","iopub.execute_input":"2021-09-08T03:48:56.923145Z","iopub.status.idle":"2021-09-08T03:49:02.661412Z","shell.execute_reply.started":"2021-09-08T03:48:56.923106Z","shell.execute_reply":"2021-09-08T03:49:02.660058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Selecting features\nThe approach is to choose the features that the correlation of >=0.5 w.r.t. diagnosis","metadata":{}},{"cell_type":"code","source":"corr_target = abs(train_corr[\"diagnosis\"])\nfeatures = corr_target[corr_target>=0.5]\nfeatures = features.keys()\nfeatures = features.delete(0)\nfeatures = features.tolist()\nfeatures","metadata":{"execution":{"iopub.status.busy":"2021-09-08T03:49:02.663548Z","iopub.execute_input":"2021-09-08T03:49:02.663885Z","iopub.status.idle":"2021-09-08T03:49:02.841808Z","shell.execute_reply.started":"2021-09-08T03:49:02.663843Z","shell.execute_reply":"2021-09-08T03:49:02.840521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train[features]\nX.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-08T03:49:04.584526Z","iopub.execute_input":"2021-09-08T03:49:04.585843Z","iopub.status.idle":"2021-09-08T03:49:04.612748Z","shell.execute_reply.started":"2021-09-08T03:49:04.585761Z","shell.execute_reply":"2021-09-08T03:49:04.611684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = train[\"diagnosis\"]\ny.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-08T03:49:05.58928Z","iopub.execute_input":"2021-09-08T03:49:05.589784Z","iopub.status.idle":"2021-09-08T03:49:05.595972Z","shell.execute_reply.started":"2021-09-08T03:49:05.589747Z","shell.execute_reply":"2021-09-08T03:49:05.595044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Splitting the dataset into train and test dataset.\n- The dataset is split into Train and Test dataset in 2 ways:\n - First is in a ratio of 80% - 20%.\n - Second is in a ratio of 70% - 20%.","metadata":{}},{"cell_type":"code","source":"# 80% - 20% Split\nX_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=0.20, random_state=42, shuffle=False)\n\n# 70% - 30% Split\nX_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=0.30, random_state=42)\n\nalgo = [\"XGBoost Classifier\", \"Random Forest Classifier\", \"Logistic Regression\", \"AdaBoost Classifier\", \"Gradient Boosting\", \"Bagging Classifier\", \"CatBoost Classifier\"]\naccuracy1=[]\nprecision1 = []\nrecall1 = []\nf1_score1 = []\n\naccuracy2=[]\nprecision2 = []\nrecall2 = []\nf1_score2 = []","metadata":{"execution":{"iopub.status.busy":"2021-09-08T03:49:07.915511Z","iopub.execute_input":"2021-09-08T03:49:07.915849Z","iopub.status.idle":"2021-09-08T03:49:07.926003Z","shell.execute_reply.started":"2021-09-08T03:49:07.915819Z","shell.execute_reply":"2021-09-08T03:49:07.925022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating and training models\nThese are the following algorithms that are used in this exercise.\n1. XGBoost Classifier\n2. Random Forest Classifier\n3. Logistic Regression \n4. AdaBoost Classifier\n5. Gradient Boosting\n6. Bagging Classifier\n7. CatBoost Classifier","metadata":{}},{"cell_type":"markdown","source":"### 1) XGBoost Classifier","metadata":{}},{"cell_type":"code","source":"# Model 1 with 80% - 20% split\nxg_model1 = XGBClassifier()\nxg_model1.fit(X_train1, y_train1)\ny_pred_xg1 = xg_model1.predict(X_test1)\n\n# Model 2 with 70% - 30% split\nxg_model2 = XGBClassifier()\nxg_model2.fit(X_train2, y_train2)\ny_pred_xg2 = xg_model2.predict(X_test2)\n\n# The statement below is meant to be used for continuous target variable not categorical\n# predictions = [round(value) for value in y_pred]\n\n# Calculating Evaluation Metrics for the Model 1\nxg_accuracy1 = accuracy_score(y_test1, y_pred_xg1) * 100\nxg_confusion1 = confusion_matrix(y_test1, y_pred_xg1)\nxg_precision1 = xg_confusion1[0][0]/(xg_confusion1[0][0] + xg_confusion1[1][0]) * 100\nxg_recall1 = xg_confusion1[0][0]/(xg_confusion1[0][0] + xg_confusion1[0][1]) * 100\nxg_f1_score1 = ((2 * xg_precision1 * xg_recall1) / (xg_precision1 + xg_recall1)) / 100\n\n# Calculating Evaluation Metrics for the Model 2\nxg_accuracy2 = accuracy_score(y_test2, y_pred_xg2) * 100\nxg_confusion2 = confusion_matrix(y_test2, y_pred_xg2)\nxg_precision2 = xg_confusion2[0][0]/(xg_confusion2[0][0] + xg_confusion2[1][0]) * 100\nxg_recall2 = xg_confusion2[0][0]/(xg_confusion2[0][0] + xg_confusion2[0][1]) * 100\nxg_f1_score2 = ((2 * xg_precision2 * xg_recall2) / (xg_precision2 + xg_recall2)) / 100\n\n# Storing all the metrics in values for Model 1 in common lists\naccuracy1.append(round(xg_accuracy1, 2))\nprecision1.append(round(xg_precision1, 2))\nrecall1.append(round(xg_recall1, 2))\nf1_score1.append(round(xg_f1_score1, 4))\n\n# Storing all the metrics in values for Model 2 in common lists\naccuracy2.append(round(xg_accuracy2, 2))\nprecision2.append(round(xg_precision2, 2))\nrecall2.append(round(xg_recall2, 2))\nf1_score2.append(round(xg_f1_score2, 4))","metadata":{"execution":{"iopub.status.busy":"2021-09-08T03:49:11.166502Z","iopub.execute_input":"2021-09-08T03:49:11.166854Z","iopub.status.idle":"2021-09-08T03:49:11.329812Z","shell.execute_reply.started":"2021-09-08T03:49:11.166821Z","shell.execute_reply":"2021-09-08T03:49:11.328261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluation Metrics for the Model 1\nprint(\"Results for the 80 - 20 split\")\nprint(\"Accuracy:\", xg_accuracy1)\nprint(\"Precision:\", xg_precision1)\nprint(\"Recall:\", xg_recall1)\nprint(\"F1 Score:\", xg_f1_score1)\n\nprint(\"----------------------------------\")\nprint(\"----------------------------------\")\n\n# Evaluation Metrics for the Model 2\nprint(\"Results for the 70 - 30 split\")\nprint(\"Accuracy:\", xg_accuracy2)\nprint(\"Precision:\", xg_precision2)\nprint(\"Recall:\", xg_recall2)\nprint(\"F1 Score:\", xg_f1_score2)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-08T03:49:12.474358Z","iopub.execute_input":"2021-09-08T03:49:12.474681Z","iopub.status.idle":"2021-09-08T03:49:12.488204Z","shell.execute_reply.started":"2021-09-08T03:49:12.474651Z","shell.execute_reply":"2021-09-08T03:49:12.487085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2) Random Forest Classifier","metadata":{}},{"cell_type":"code","source":"# Model 1 with 80% - 20% split\nrfc_model1 = RandomForestClassifier()\nrfc_model1.fit(X_train1, y_train1)\ny_pred_rf1 = rfc_model1.predict(X_test1)\n\n# Model 2 with 70% - 30% split\nrfc_model2 = RandomForestClassifier()\nrfc_model2.fit(X_train2, y_train2)\ny_pred_rf2 = rfc_model2.predict(X_test2)\n\n# Calculating Evaluation Metrics for the Model 1\nrf_accuracy1 = accuracy_score(y_test1, y_pred_rf1) * 100\nrf_confusion1 = confusion_matrix(y_test1, y_pred_rf1)\nrf_precision1 = xg_confusion1[0][0]/(rf_confusion1[0][0] + rf_confusion1[1][0]) * 100\nrf_recall1 = xg_confusion1[0][0]/(rf_confusion1[0][0] + rf_confusion1[0][1]) * 100\nrf_f1_score1 = ((2 * rf_precision1 * rf_recall1) / (rf_precision1 + rf_recall1)) / 100\n\n# Calculating Evaluation Metrics for the Model 2\nrf_accuracy2 = accuracy_score(y_test2, y_pred_rf2) * 100\nrf_confusion2 = confusion_matrix(y_test2, y_pred_rf2)\nrf_precision2 = xg_confusion2[0][0]/(rf_confusion2[0][0] + rf_confusion2[1][0]) * 100\nrf_recall2 = xg_confusion2[0][0]/(rf_confusion2[0][0] + rf_confusion2[0][1]) * 100\nrf_f1_score2 = ((2 * rf_precision2 * rf_recall2) / (rf_precision2 + rf_recall2)) / 100\n\n# Storing all the metrics in values for Model 1 in common lists\naccuracy1.append(round(rf_accuracy1, 2))\nprecision1.append(round(rf_precision1, 2))\nrecall1.append(round(rf_recall1, 2))\nf1_score1.append(round(rf_f1_score1, 4))\n\n# Storing all the metrics in values for Model 2 in common lists\naccuracy2.append(round(rf_accuracy2, 2))\nprecision2.append(round(rf_precision2, 2))\nrecall2.append(round(rf_recall2, 2))\nf1_score2.append(round(rf_f1_score2, 4))","metadata":{"execution":{"iopub.status.busy":"2021-09-08T03:49:14.14653Z","iopub.execute_input":"2021-09-08T03:49:14.146891Z","iopub.status.idle":"2021-09-08T03:49:14.5741Z","shell.execute_reply.started":"2021-09-08T03:49:14.146861Z","shell.execute_reply":"2021-09-08T03:49:14.573111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluation Metrics for the Model 1\nprint(\"Results for the 80% - 20% split\")\nprint(\"Accuracy:\", rf_accuracy1)\nprint(\"Precision:\", rf_precision1)\nprint(\"Recall:\", rf_recall1)\nprint(\"F1 Score:\", rf_f1_score1)\n\nprint(\"----------------------------------\")\nprint(\"----------------------------------\")\n\n# Evaluation Metrics for the Model 2\nprint(\"Results for the 70% - 30% split\")\nprint(\"Accuracy:\", rf_accuracy2)\nprint(\"Precision:\", rf_precision2)\nprint(\"Recall:\", rf_recall2)\nprint(\"F1 Score:\", rf_f1_score2)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T03:49:15.063291Z","iopub.execute_input":"2021-09-08T03:49:15.063648Z","iopub.status.idle":"2021-09-08T03:49:15.072607Z","shell.execute_reply.started":"2021-09-08T03:49:15.063619Z","shell.execute_reply":"2021-09-08T03:49:15.071467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3) Logistic Regression","metadata":{}},{"cell_type":"code","source":"# Model 1 with 80% - 20% split\nlr_model1 = LogisticRegression(class_weight='dict', max_iter=500, random_state=42)\nlr_model1.fit(X_train1, y_train1)\ny_pred_lr1 = lr_model1.predict(X_test1)\n\n# Model 2 with 70% - 30% split\nlr_model2 = LogisticRegression(solver = 'liblinear', max_iter=300, random_state=42)\nlr_model2.fit(X_train2, y_train2)\ny_pred_lr2 = lr_model2.predict(X_test2)\n\n# Calculating Evaluation Metrics for the Model 1\nlr_accuracy1 = accuracy_score(y_test1, y_pred_lr1) * 100\nlr_confusion1 = confusion_matrix(y_test1, y_pred_lr1)\nlr_precision1 = lr_confusion1[0][0]/(lr_confusion1[0][0] + lr_confusion1[1][0]) * 100\nlr_recall1 = lr_confusion1[0][0]/(lr_confusion1[0][0] + lr_confusion1[0][1]) * 100\nlr_f1_score1 = ((2 * lr_precision1 * lr_recall1) / (lr_precision1 + lr_recall1)) / 100\n\n# Calculating Evaluation Metrics for the Model 2\nlr_accuracy2 = accuracy_score(y_test2, y_pred_lr2) * 100\nlr_confusion2 = confusion_matrix(y_test2, y_pred_lr2)\nlr_precision2 = lr_confusion2[0][0]/(lr_confusion2[0][0] + lr_confusion2[1][0]) * 100\nlr_recall2 = lr_confusion2[0][0]/(lr_confusion2[0][0] + lr_confusion2[0][1]) * 100\nlr_f1_score2 = ((2 * lr_precision2 * lr_recall2) / (lr_precision2 + lr_recall2)) / 100\n\n# Storing all the metrics in values for Model 1 in common lists\naccuracy1.append(round(lr_accuracy1, 2))\nprecision1.append(round(lr_precision1, 2))\nrecall1.append(round(lr_recall1, 2))\nf1_score1.append(round(lr_f1_score1, 4))\n\n# Storing all the metrics in values for Model 2 in common lists\naccuracy2.append(round(lr_accuracy2, 2))\nprecision2.append(round(lr_precision2, 2))\nrecall2.append(round(lr_recall2, 2))\nf1_score2.append(round(lr_f1_score2, 4))","metadata":{"execution":{"iopub.status.busy":"2021-09-08T03:49:16.641076Z","iopub.execute_input":"2021-09-08T03:49:16.641429Z","iopub.status.idle":"2021-09-08T03:49:16.850216Z","shell.execute_reply.started":"2021-09-08T03:49:16.6414Z","shell.execute_reply":"2021-09-08T03:49:16.849298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluation Metrics for the Model 1\nprint(\"Results for the 80% - 20% split\")\nprint(\"Accuracy:\", lr_accuracy1)\nprint(\"Precision:\", lr_precision1)\nprint(\"Recall:\", lr_recall1)\nprint(\"F1 Score:\", lr_f1_score1)\n\nprint(\"----------------------------------\")\nprint(\"----------------------------------\")\n\n# Evaluation Metrics for the Model 2\nprint(\"Results for the 70% - 30% split\")\nprint(\"Accuracy:\", lr_accuracy2)\nprint(\"Precision:\", lr_precision2)\nprint(\"Recall:\", lr_recall2)\nprint(\"F1 Score:\", lr_f1_score2)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T03:49:17.223097Z","iopub.execute_input":"2021-09-08T03:49:17.223431Z","iopub.status.idle":"2021-09-08T03:49:17.233024Z","shell.execute_reply.started":"2021-09-08T03:49:17.223403Z","shell.execute_reply":"2021-09-08T03:49:17.230103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4) AdaBoost Classifier","metadata":{}},{"cell_type":"code","source":"# Model 1 with 80% - 20% split\nab_model1 = AdaBoostClassifier(n_estimators=500, learning_rate=0.1, random_state=42)\nab_model1.fit(X_train1, y_train1)\ny_pred_ab1 = ab_model1.predict(X_test1)\n\n# Model 2 with 70% - 30% split\nab_model2 = AdaBoostClassifier(n_estimators=500, learning_rate=0.1, random_state=42)\nab_model2.fit(X_train2, y_train2)\ny_pred_ab2 = ab_model2.predict(X_test2)\n\n# Calculating Evaluation Metrics for the Model 1\nab_accuracy1 = accuracy_score(y_test1, y_pred_ab1) * 100\nab_confusion1 = confusion_matrix(y_test1, y_pred_ab1)\nab_precision1 = ab_confusion1[0][0]/(ab_confusion1[0][0] + ab_confusion1[1][0]) * 100\nab_recall1 = ab_confusion1[0][0]/(ab_confusion1[0][0] + ab_confusion1[0][1]) * 100\nab_f1_score1 = ((2 * ab_precision1 * ab_recall1) / (ab_precision1 + ab_recall1)) / 100\n\n# Calculating Evaluation Metrics for the Model 2\nab_accuracy2 = accuracy_score(y_test2, y_pred_ab2) * 100\nab_confusion2 = confusion_matrix(y_test2, y_pred_ab2)\nab_precision2 = ab_confusion2[0][0]/(ab_confusion2[0][0] + ab_confusion2[1][0]) * 100\nab_recall2 = ab_confusion2[0][0]/(ab_confusion2[0][0] + ab_confusion2[0][1]) * 100\nab_f1_score2 = ((2 * ab_precision2 * ab_recall2) / (ab_precision2 + ab_recall2)) / 100\n\n# Storing all the metrics in values for Model 1 in common lists\naccuracy1.append(round(ab_accuracy1, 2))\nprecision1.append(round(ab_precision1, 2))\nrecall1.append(round(ab_recall1, 2))\nf1_score1.append(round(ab_f1_score1, 4))\n\n# Storing all the metrics in values for Model 2 in common lists\naccuracy2.append(round(ab_accuracy2, 2))\nprecision2.append(round(ab_precision2, 2))\nrecall2.append(round(ab_recall2, 2))\nf1_score2.append(round(ab_f1_score2, 4))","metadata":{"execution":{"iopub.status.busy":"2021-09-08T03:49:18.662152Z","iopub.execute_input":"2021-09-08T03:49:18.662523Z","iopub.status.idle":"2021-09-08T03:49:20.946074Z","shell.execute_reply.started":"2021-09-08T03:49:18.662488Z","shell.execute_reply":"2021-09-08T03:49:20.94503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluation Metrics for the Model 1\nprint(\"Results for the 80% - 20% split\")\nprint(\"Accuracy:\", ab_accuracy1)\nprint(\"Precision:\", ab_precision1)\nprint(\"Recall:\", ab_recall1)\nprint(\"F1 Score:\", ab_f1_score1)\n\nprint(\"----------------------------------\")\nprint(\"----------------------------------\")\n\n# Evaluation Metrics for the Model 2\nprint(\"Results for the 70% - 30% split\")\nprint(\"Accuracy:\", ab_accuracy2)\nprint(\"Precision:\", ab_precision2)\nprint(\"Recall:\", ab_recall2)\nprint(\"F1 Score:\", ab_f1_score2)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T03:49:20.947522Z","iopub.execute_input":"2021-09-08T03:49:20.947796Z","iopub.status.idle":"2021-09-08T03:49:20.956238Z","shell.execute_reply.started":"2021-09-08T03:49:20.947769Z","shell.execute_reply":"2021-09-08T03:49:20.955075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5) Gradient Boosting Classifier","metadata":{}},{"cell_type":"code","source":"# Model 1 with 80% - 20% split\ngb_model1 = GradientBoostingClassifier()\ngb_model1.fit(X_train1, y_train1)\ny_pred_gb1 = gb_model1.predict(X_test1)\n\n# Model 2 with 70% - 30% split\ngb_model2 = GradientBoostingClassifier()\ngb_model2.fit(X_train2, y_train2)\ny_pred_gb2 = gb_model2.predict(X_test2)\n\n# Calculating Evaluation Metrics for the Model 1\ngb_accuracy1 = accuracy_score(y_test1, y_pred_gb1) * 100\ngb_confusion1 = confusion_matrix(y_test1, y_pred_gb1)\ngb_precision1 = gb_confusion1[0][0]/(gb_confusion1[0][0] + gb_confusion1[1][0]) * 100\ngb_recall1 = gb_confusion1[0][0]/(gb_confusion1[0][0] + gb_confusion1[0][1]) * 100\ngb_f1_score1 = ((2 * gb_precision1 * gb_recall1) / (gb_precision1 + gb_recall1)) / 100\n\n# Calculating Evaluation Metrics for the Model 2\ngb_accuracy2 = accuracy_score(y_test2, y_pred_gb2) * 100\ngb_confusion2 = confusion_matrix(y_test2, y_pred_gb2)\ngb_precision2 = gb_confusion2[0][0]/(gb_confusion2[0][0] + gb_confusion2[1][0]) * 100\ngb_recall2 = gb_confusion2[0][0]/(gb_confusion2[0][0] + gb_confusion2[0][1]) * 100\ngb_f1_score2 = ((2 * gb_precision2 * gb_recall2) / (gb_precision2 + gb_recall2)) / 100\n\n# Storing all the metrics in values for Model 1 in common lists\naccuracy1.append(round(gb_accuracy1, 2))\nprecision1.append(round(gb_precision1, 2))\nrecall1.append(round(gb_recall1, 2))\nf1_score1.append(round(gb_f1_score1, 4))\n\n# Storing all the metrics in values for Model 2 in common lists\naccuracy2.append(round(gb_accuracy2, 2))\nprecision2.append(round(gb_precision2, 2))\nrecall2.append(round(gb_recall2, 2))\nf1_score2.append(round(gb_f1_score2, 4))","metadata":{"execution":{"iopub.status.busy":"2021-09-08T03:49:20.96052Z","iopub.execute_input":"2021-09-08T03:49:20.960817Z","iopub.status.idle":"2021-09-08T03:49:21.427659Z","shell.execute_reply.started":"2021-09-08T03:49:20.96079Z","shell.execute_reply":"2021-09-08T03:49:21.426658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluation Metrics for the Model 1\nprint(\"Results for the 80% - 20% split\")\nprint(\"Accuracy:\", gb_accuracy1)\nprint(\"Precision:\", gb_precision1)\nprint(\"Recall:\", gb_recall1)\nprint(\"F1 Score:\", gb_f1_score1)\n\nprint(\"----------------------------------\")\nprint(\"----------------------------------\")\n\n# Evaluation Metrics for the Model 2\nprint(\"Results for the 70% - 30% split\")\nprint(\"Accuracy:\", gb_accuracy2)\nprint(\"Precision:\", gb_precision2)\nprint(\"Recall:\", gb_recall2)\nprint(\"F1 Score:\", gb_f1_score2)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T03:49:21.611081Z","iopub.execute_input":"2021-09-08T03:49:21.611416Z","iopub.status.idle":"2021-09-08T03:49:21.621291Z","shell.execute_reply.started":"2021-09-08T03:49:21.611386Z","shell.execute_reply":"2021-09-08T03:49:21.620087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6) Bagging Classifier","metadata":{}},{"cell_type":"code","source":"# Model 1 with 80% - 20% split\nbc_model1 = BaggingClassifier(n_estimators=200, random_state=42)\nbc_model1.fit(X_train1, y_train1)\ny_pred_bc1 = bc_model1.predict(X_test1)\n\n# Model 2 with 70% - 30% split\nbc_model2 = BaggingClassifier(n_estimators=200, random_state=42)\nbc_model2.fit(X_train2, y_train2)\ny_pred_bc2 = bc_model2.predict(X_test2)\n\n\n# Calculating Evaluation Metrics for the Model 1\nbc_accuracy1 = accuracy_score(y_test1, y_pred_bc1) * 100\nbc_confusion1 = confusion_matrix(y_test1, y_pred_bc1)\nbc_precision1 = bc_confusion1[0][0]/(bc_confusion1[0][0] + bc_confusion1[1][0]) * 100\nbc_recall1 = bc_confusion1[0][0]/(bc_confusion1[0][0] + bc_confusion1[0][1]) * 100\nbc_f1_score1 = ((2 * bc_precision1 * bc_recall1) / (bc_precision1 + bc_recall1)) / 100\n\n# Calculating Evaluation Metrics for the Model 2\nbc_accuracy2 = accuracy_score(y_test2, y_pred_bc2) * 100\nbc_confusion2 = confusion_matrix(y_test2, y_pred_bc2)\nbc_precision2 = bc_confusion2[0][0]/(bc_confusion2[0][0] + bc_confusion2[1][0]) * 100\nbc_recall2 = bc_confusion2[0][0]/(bc_confusion2[0][0] + bc_confusion2[0][1]) * 100\nbc_f1_score2 = ((2 * bc_precision2 * bc_recall2) / (bc_precision2 + bc_recall2)) / 100\n\n# Storing all the metrics in values for Model 1 in common lists\naccuracy1.append(round(bc_accuracy1, 2))\nprecision1.append(round(bc_precision1, 2))\nrecall1.append(round(bc_recall1, 2))\nf1_score1.append(round(bc_f1_score1, 4))\n\n# Storing all the metrics in values for Model 2 in common lists\naccuracy2.append(round(bc_accuracy2, 2))\nprecision2.append(round(bc_precision2, 2))\nrecall2.append(round(bc_recall2, 2))\nf1_score2.append(round(bc_f1_score2, 4))","metadata":{"execution":{"iopub.status.busy":"2021-09-08T03:49:23.31608Z","iopub.execute_input":"2021-09-08T03:49:23.316408Z","iopub.status.idle":"2021-09-08T03:49:24.712544Z","shell.execute_reply.started":"2021-09-08T03:49:23.316379Z","shell.execute_reply":"2021-09-08T03:49:24.711527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluation Metrics for the Model 1\nprint(\"Results for the 80% - 20% split\")\nprint(\"Accuracy:\", bc_accuracy1)\nprint(\"Precision:\", bc_precision1)\nprint(\"Recall:\", bc_recall1)\nprint(\"F1 Score:\", bc_f1_score1)\n\nprint(\"----------------------------------\")\nprint(\"----------------------------------\")\n\n# Evaluation Metrics for the Model 2\nprint(\"Results for the 70% - 30% split\")\nprint(\"Accuracy:\", bc_accuracy2)\nprint(\"Precision:\", bc_precision2)\nprint(\"Recall:\", bc_recall2)\nprint(\"F1 Score:\", bc_f1_score2)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T03:49:24.714214Z","iopub.execute_input":"2021-09-08T03:49:24.714516Z","iopub.status.idle":"2021-09-08T03:49:24.724849Z","shell.execute_reply.started":"2021-09-08T03:49:24.714486Z","shell.execute_reply":"2021-09-08T03:49:24.723546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 7) CatBoost Classifier","metadata":{}},{"cell_type":"code","source":"# Model 1 with 80% - 20% split\ncb_model1 = CatBoostClassifier(iterations=200, logging_level='Silent')\ncb_model1.fit(X_train1, y_train1)\ny_pred_cb1 = cb_model1.predict(X_test1)\n\n# Model 2 with 70% - 30% split\ncb_model2 = CatBoostClassifier(iterations=200, logging_level='Silent')\ncb_model2.fit(X_train2, y_train2)\ny_pred_cb2 = cb_model2.predict(X_test2)\n\n# Calculating Evaluation Metrics for the Model 1\ncb_accuracy1 = accuracy_score(y_test1, y_pred_cb1) * 100\ncb_confusion1 = confusion_matrix(y_test1, y_pred_cb1)\ncb_precision1 = cb_confusion1[0][0]/(cb_confusion1[0][0] + cb_confusion1[1][0]) * 100\ncb_recall1 = cb_confusion1[0][0]/(cb_confusion1[0][0] + cb_confusion1[0][1]) * 100\ncb_f1_score1 = ((2 * cb_precision1 * cb_recall1) / (cb_precision1 + cb_recall1)) / 100\n\n# Calculating Evaluation Metrics for the Model 2\ncb_accuracy2 = accuracy_score(y_test2, y_pred_cb2) * 100\ncb_confusion2 = confusion_matrix(y_test2, y_pred_cb2)\ncb_precision2 = cb_confusion2[0][0]/(cb_confusion2[0][0] + cb_confusion2[1][0]) * 100\ncb_recall2 = cb_confusion2[0][0]/(cb_confusion2[0][0] + cb_confusion2[0][1]) * 100\ncb_f1_score2 = ((2 * cb_precision2 * cb_recall2) / (cb_precision2 + cb_recall2)) / 100\n\n# Storing all the metrics in values for Model 1 in common lists\naccuracy1.append(round(cb_accuracy1, 2))\nprecision1.append(round(cb_precision1, 2))\nrecall1.append(round(cb_recall1, 2))\nf1_score1.append(round(cb_f1_score1, 4))\n\n# Storing all the metrics in values for Model 2 in common lists\naccuracy2.append(round(cb_accuracy2, 2))\nprecision2.append(round(cb_precision2, 2))\nrecall2.append(round(cb_recall2, 2))\nf1_score2.append(round(cb_f1_score2, 4))\n\n# To see the hyper-parameters for this model use \"cb_model.get_all_params()\"","metadata":{"execution":{"iopub.status.busy":"2021-09-08T03:49:25.942179Z","iopub.execute_input":"2021-09-08T03:49:25.942556Z","iopub.status.idle":"2021-09-08T03:49:27.196805Z","shell.execute_reply.started":"2021-09-08T03:49:25.942518Z","shell.execute_reply":"2021-09-08T03:49:27.195913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluation Metrics for the Model 1\nprint(\"Results for the 80% - 20% split\")\nprint(\"Accuracy Score:\", cb_accuracy1)\nprint(\"Precision:\", cb_precision1)\nprint(\"Recall:\", cb_recall1)\nprint(\"F1 Score:\", cb_f1_score1)\n\nprint(\"----------------------------------\")\nprint(\"----------------------------------\")\n\n# Evaluation Metrics for the Model 2\nprint(\"Results for the 70% - 30% split\")\nprint(\"Accuracy Score:\", cb_accuracy2)\nprint(\"Precision:\", cb_precision2)\nprint(\"Recall:\", cb_recall2)\nprint(\"F1 Score:\", cb_f1_score2)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T03:49:27.198098Z","iopub.execute_input":"2021-09-08T03:49:27.198552Z","iopub.status.idle":"2021-09-08T03:49:27.209632Z","shell.execute_reply.started":"2021-09-08T03:49:27.198508Z","shell.execute_reply":"2021-09-08T03:49:27.208397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tabular Performance Comparison of all the algorithm w.r.t. the train-test data split","metadata":{}},{"cell_type":"code","source":"metric1 = pd.DataFrame({\n    'Alogrithms':algo,\n    'Accuracy':accuracy1,\n    'Precision':precision1,\n    'Recall':recall1,\n    'F1 Score':f1_score1\n})\n\nmetric2 = pd.DataFrame({\n    'Alogrithms':algo,\n    'Accuracy':accuracy2,\n    'Precision':precision2,\n    'Recall':recall2,\n    'F1 Score':f1_score2\n})","metadata":{"execution":{"iopub.status.busy":"2021-09-08T03:49:28.231045Z","iopub.execute_input":"2021-09-08T03:49:28.231411Z","iopub.status.idle":"2021-09-08T03:49:28.239457Z","shell.execute_reply.started":"2021-09-08T03:49:28.231376Z","shell.execute_reply":"2021-09-08T03:49:28.238325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Metrics in the 80% - 20% setting","metadata":{}},{"cell_type":"code","source":"metric1","metadata":{"execution":{"iopub.status.busy":"2021-09-08T03:49:29.706032Z","iopub.execute_input":"2021-09-08T03:49:29.706407Z","iopub.status.idle":"2021-09-08T03:49:29.723194Z","shell.execute_reply.started":"2021-09-08T03:49:29.70637Z","shell.execute_reply":"2021-09-08T03:49:29.721982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Metrics in the 70% - 30% setting","metadata":{}},{"cell_type":"code","source":"metric2","metadata":{"execution":{"iopub.status.busy":"2021-09-08T03:49:31.414633Z","iopub.execute_input":"2021-09-08T03:49:31.415041Z","iopub.status.idle":"2021-09-08T03:49:31.429975Z","shell.execute_reply.started":"2021-09-08T03:49:31.415007Z","shell.execute_reply":"2021-09-08T03:49:31.428781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Conclusion\n<p>In my opinion I think that choosing the 80-20 setting is always a better in small or medium sized datasets. But I have observed that in 70-30 setting Logistic Regression has outperformed all the algorithms irrespective of the settings by a very narrow margin.</p>\nOverall it would be a good idea to choose XGBoost Classifier in 80-20 setting.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}