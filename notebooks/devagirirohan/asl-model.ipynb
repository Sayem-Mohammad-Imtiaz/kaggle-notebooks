{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-03T16:13:50.186963Z","iopub.execute_input":"2021-07-03T16:13:50.187436Z","iopub.status.idle":"2021-07-03T16:13:50.222847Z","shell.execute_reply.started":"2021-07-03T16:13:50.187334Z","shell.execute_reply":"2021-07-03T16:13:50.221661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Installing required packages using pip install package_name**","metadata":{}},{"cell_type":"code","source":"!pip install tensorflowjs\n!pip3 install gTTS \n!pip install playsound","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Importing the necessary packages**","metadata":{}},{"cell_type":"code","source":"import csv\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import accuracy_score\nfrom gtts import gTTS as tts\nfrom playsound import playsound\nfrom IPython.display import Audio\nimport time\nimport os\n#import os.system","metadata":{"execution":{"iopub.status.busy":"2021-07-03T16:13:50.224263Z","iopub.execute_input":"2021-07-03T16:13:50.224748Z","iopub.status.idle":"2021-07-03T16:13:55.986077Z","shell.execute_reply.started":"2021-07-03T16:13:50.224714Z","shell.execute_reply":"2021-07-03T16:13:55.985032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" **Converting the .csv data into images**\n\nAs, the data is in the form of csv file, created a function using numpy to convert the data into numpy array","metadata":{}},{"cell_type":"code","source":"def get_data(filename):\n    with open(filename) as training_file:\n        reader = csv.reader(training_file, delimiter=',')    \n        imgs = []\n        labels = []\n\n        next(reader, None)\n        \n        for row in reader:\n            label = row[0]\n            data = row[1:]\n            img = np.array(data).reshape((28, 28))\n\n            imgs.append(img)\n            labels.append(label)\n\n        images = np.array(imgs).astype(float)\n        labels = np.array(labels).astype(float)\n    return images, labels\n\n\ntraining_images, training_labels = get_data('/kaggle/input/sign-language-mnist/sign_mnist_train.csv')\ntesting_images, testing_labels = get_data('/kaggle/input/sign-language-mnist/sign_mnist_test.csv')\n\nprint(training_images.shape)\nprint(training_labels.shape)\nprint(testing_images.shape)\nprint(testing_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T17:01:31.066892Z","iopub.execute_input":"2021-07-03T17:01:31.067461Z","iopub.status.idle":"2021-07-03T17:01:58.469309Z","shell.execute_reply.started":"2021-07-03T17:01:31.067413Z","shell.execute_reply":"2021-07-03T17:01:58.468288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Augmenting the data using ImageDataGenerator**","metadata":{}},{"cell_type":"code","source":"\ntraining_images = np.expand_dims(training_images, axis=3)\ntesting_images = np.expand_dims(testing_images, axis=3)\n# ImageDataGenerator to do Image Augmentation\ntrain_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n    )\n\nvalidation_datagen = ImageDataGenerator(rescale=1. / 255)\n    \nprint(training_images.shape)\nprint(testing_images.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T17:02:26.273409Z","iopub.execute_input":"2021-07-03T17:02:26.273915Z","iopub.status.idle":"2021-07-03T17:02:26.281354Z","shell.execute_reply.started":"2021-07-03T17:02:26.273878Z","shell.execute_reply":"2021-07-03T17:02:26.280308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***","metadata":{}},{"cell_type":"code","source":"# Define the CNN model\nmodel = tf.keras.models.Sequential([\n        tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n        tf.keras.layers.MaxPooling2D(2,2),\n        tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n        tf.keras.layers.MaxPooling2D(2,2),\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(512, activation='relu'),\n        tf.keras.layers.Dense(26, activation='softmax')\n])\n\n# Compiling the model\nmodel.compile(optimizer='adam',\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy'])\n    \n\ntrain_gen = train_datagen.flow(\n    training_images,\n    training_labels,\n    batch_size=64\n)\n\nval_gen = validation_datagen.flow(\n    testing_images,\n    testing_labels,\n    batch_size=64\n)\n\n# Training the Model\nhistory = model.fit_generator(\n    train_gen,\n    epochs=25,\n    validation_data=val_gen\n)\n\n","metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"execution":{"iopub.status.busy":"2021-07-03T17:02:31.6343Z","iopub.execute_input":"2021-07-03T17:02:31.634664Z","iopub.status.idle":"2021-07-03T17:09:28.414555Z","shell.execute_reply.started":"2021-07-03T17:02:31.634631Z","shell.execute_reply":"2021-07-03T17:09:28.413821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluating the model with test images and test labels\n\nmodel.evaluate(testing_images, testing_labels, verbose=0)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-03T17:11:54.962484Z","iopub.execute_input":"2021-07-03T17:11:54.963267Z","iopub.status.idle":"2021-07-03T17:11:56.227472Z","shell.execute_reply.started":"2021-07-03T17:11:54.963207Z","shell.execute_reply":"2021-07-03T17:11:56.226398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the chart for accuracy and loss on both training and validation\n%matplotlib inline\nimport matplotlib.pyplot as plt\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-03T16:23:47.876288Z","iopub.execute_input":"2021-07-03T16:23:47.87657Z","iopub.status.idle":"2021-07-03T16:23:48.279346Z","shell.execute_reply.started":"2021-07-03T16:23:47.876543Z","shell.execute_reply":"2021-07-03T16:23:48.278592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n    \n# Predict the label of the test_images\npred = model.predict(testing_images)\npred = np.argmax(pred,axis=1)\n\n# Accuracy score\nacc = accuracy_score(testing_labels,pred)\n\n# Print results\nprint(acc*100)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T16:27:24.070348Z","iopub.execute_input":"2021-07-03T16:27:24.071028Z","iopub.status.idle":"2021-07-03T16:27:25.878791Z","shell.execute_reply.started":"2021-07-03T16:27:24.070986Z","shell.execute_reply":"2021-07-03T16:27:25.877581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Map the numbers into letters for plotting\nalphabets = 'abcdefghijklmnopqrstuvwxyz'\nletter_map = {}\n\nfor i,j in enumerate(alphabets):\n    letter_map[j] = i\nletter_map = {v:k for k,v in letter_map.items()}\n\ntesting_letters = [letter_map[x] for x in testing_labels]\npredicted_letters = [letter_map[x] for x in pred]","metadata":{"execution":{"iopub.status.busy":"2021-07-03T16:27:29.377544Z","iopub.execute_input":"2021-07-03T16:27:29.377938Z","iopub.status.idle":"2021-07-03T16:27:29.395077Z","shell.execute_reply.started":"2021-07-03T16:27:29.377903Z","shell.execute_reply":"2021-07-03T16:27:29.393843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plotting test images vs predicted values for each sign\ncorrect = np.nonzero(pred == testing_labels)[0]\nplt.figure(figsize=(10, 10))\ni = 0\nfor c in correct[:9]:\n    plt.subplot(3,3,i+1)\n    plt.axis('off')\n    plt.imshow(testing_images[c], cmap = \"gray\", interpolation='none')\n    plt.title(\"{}\".format(predicted_letters[c].upper()))\n    i += 1","metadata":{"execution":{"iopub.status.busy":"2021-07-03T16:27:32.035555Z","iopub.execute_input":"2021-07-03T16:27:32.035923Z","iopub.status.idle":"2021-07-03T16:27:32.514002Z","shell.execute_reply.started":"2021-07-03T16:27:32.035894Z","shell.execute_reply":"2021-07-03T16:27:32.512947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Saving the weights of our model using model.save()\nmodel.save('/kaggle/working/model_2.h5')\nmodel.save('./model_2.h5')","metadata":{"execution":{"iopub.status.busy":"2021-07-03T16:16:33.73136Z","iopub.status.idle":"2021-07-03T16:16:33.732152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from random import randint\ntesting_images[randint(0,7171)].reshape(-1,28,28,1).shape","metadata":{"execution":{"iopub.status.busy":"2021-07-03T16:33:00.026549Z","iopub.execute_input":"2021-07-03T16:33:00.026912Z","iopub.status.idle":"2021-07-03T16:33:00.033577Z","shell.execute_reply.started":"2021-07-03T16:33:00.026881Z","shell.execute_reply":"2021-07-03T16:33:00.032613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Using gtts to convert the output label into voice output**","metadata":{}},{"cell_type":"code","source":"alphabets = 'abcdefghijklmnopqrstuvwxyz'\nindex = randint(0,7171)\nimage = testing_images[index].reshape(-1,28,28,1)\nprint(alphabets[int(testing_labels[index])].upper())\na = model.predict(image)\nout  = alphabets[np.where(a == a.max())[1][0]]\nplt.imshow(image[0])\nplt.title(alphabets[int(testing_labels[index])].upper())\ntext = \"The alphabet captured is  \" + alphabets[int(testing_labels[index])].upper()\nspeech = tts(text,lang=\"en\")\nspeech.save(\"test.mp3\")\nAudio(\"./test.mp3\",autoplay = True )\n#pause()","metadata":{"execution":{"iopub.status.busy":"2021-07-03T16:34:06.13861Z","iopub.execute_input":"2021-07-03T16:34:06.139016Z","iopub.status.idle":"2021-07-03T16:34:06.657466Z","shell.execute_reply.started":"2021-07-03T16:34:06.138981Z","shell.execute_reply":"2021-07-03T16:34:06.656334Z"},"trusted":true},"execution_count":null,"outputs":[]}]}