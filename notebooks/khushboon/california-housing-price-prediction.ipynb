{"cells":[{"metadata":{},"cell_type":"markdown","source":"## California Housing Price Prediction ."},{"metadata":{},"cell_type":"markdown","source":"## 1.Importing required libraries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"# Read the dataset\nhousing = pd.read_csv(\"../input/california-housing-prices/housing.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Perform Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.shape\n\n# describe function gives a summary like mean, quartiles, median, std, count, etc for the numeric columns\nhousing.describe()\n\n# %% [code]\n# info functions helps us to understand the data type of all the columns\nhousing.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets check if there are missing values in the data\nhousing.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## As we can see only ``total_bedrooms`` column has 207 NAN values, lets treat it.\n#### There are 2 ways to treat NAN\n\n#### 1. We can delete those records which are missing (Not Recommended)\n#### 2. or we can fill those columns using the mean or median - which in this case is a pretty much easier.\n## *But what should we be using ``Mean`` or ``Median``*\n#### So to decide this we need to first check the outliers.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(5,5))\nplt.hist(housing[housing[\"total_bedrooms\"].notnull()][\"total_bedrooms\"],bins=30,color=\"purple\")\n#histogram of totalbedrooms\n#data has some outliers..??\n(housing[\"total_bedrooms\"]>4000).sum()\nplt.title(\"Historgram\")\nplt.xlabel(\"Total Bedrooms\")\nplt.ylabel(\"Frequency\")\n\n# We can clearly see there are some outliers in the column, but let check with the help of box plot once more","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,5))\nsns.boxplot(y=\"total_bedrooms\",data=housing, orient=\"h\", palette=\"plasma\")\nplt.plot\n\n#As we can see there are a lot of outliers, so to fill them we should be using ``Median`` instead of ``Mean``, \n# as the mean would vary a lot because of outliers and can affect the accuracy of our model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill missing values\nhousing['total_bedrooms'] = housing['total_bedrooms'].fillna((housing['total_bedrooms'].median()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets plot and see what our dependent variable ie; \"Y\" column - (\"median house price\") looks like\n# Histogram would be the best way to do it\n\nplt.figure(figsize=(20,5))\nsns.set_color_codes(palette=\"bright\")\nsns.distplot(housing['median_house_value'],color='g')\n\n# We can see there is sudden increase in the median house value at >= 5,00,000, \n# & this could be outliers. We should definately be removing them.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing[housing[\"median_house_value\"]>300000][\"median_house_value\"].value_counts().head(10)\nhousing = housing.loc[housing[\"median_house_value\"]<500001,:]\nplt.figure(figsize=(20,5))\nsns.set_color_codes(palette=\"bright\")\nsns.distplot(housing[\"median_house_value\"], color=\"r\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The bins parameter is used to customize the number of bins shown on the plots.\nhousing.hist(bins=50,figsize=(10,10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Since we have some geographical data, lets see if get some meaning insights from it..\n\nplt.figure(figsize=(10,5))\nplt.scatter(housing[\"longitude\"],housing[\"latitude\"],c=housing[\"median_house_value\"],\n            s=housing[\"population\"]/50, alpha=0.1, cmap=\"Oranges\")\nplt.colorbar()\nplt.xlabel(\"Longitude\")\nplt.ylabel(\"Latitude\")\nplt.title(\"House price based of geographical co-ordinates\")\n\n# We can see there are some high density areas in california, so we can say the price of house is a bit realted to\n# location as well. \n\n# Earlier when I saw the data, I thought longitude & latitude would not be weak predictors\n# but after plotting this, we can conclude even they are useful features.``\n# So never judge it by visually seeing the data just in the first time.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Before we split our data, we can also see that the feature - total_rooms has no significance, as this talks \n# about the rooms in the entire district. \n# Instead, we should find out, how many rooms are there in individual household, that would be more informative\n# for our analysis...\n\nhousing[\"rooms_household\"] = housing.total_rooms / housing.households\n\n# now we can remove this feature\nhousing.drop(\"total_rooms\", axis=1, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We have one categorical column (\"Ocean Proximity\") in the data set, lets see if we should keep this column or remove it\n\n# Barplot of categorical column\nplt.figure(figsize=(7,4))\nsns.countplot(data=housing,x='ocean_proximity', palette = \"YlOrBr_r\")\n\n# It is very definate we should be keeping this feautre, but since this is a categorical feature, we should perform \n# preprocessing on it to convert it into numerical data.\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Performing Linear Regression\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# to conviently split the data into x & y part, I am rearranging the output column and bring it in the last\n\nhousing=housing[[\"longitude\", \"latitude\", \"housing_median_age\", \"total_bedrooms\", \"population\", \n                 \"households\", \"median_income\", \"ocean_proximity\", \"rooms_household\", \"median_house_value\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Spliting the data\nx = housing.iloc[:,0:9].values\ny = housing.iloc[:,9].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting Categorical attribute to numeric\n\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nlabel_encode_x = LabelEncoder()\nx[:, 7] = label_encode_x.fit_transform(x[:, 7])\n\nonehot = OneHotEncoder(categories=\"auto\")\nx = onehot.fit_transform(x).toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Spliting the train & test data set \nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Scaling /  Normalization\n\n# from sklearn.preprocessing import StandardScaler\n# scale  = StandardScaler()\n# x_train = scale.fit_transform(x_train)\n# x_test = scale.transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.linear_model import LinearRegression\n# lin_reg = LinearRegression()\n# lin_reg.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model for future prediction\n# y_pred = lin_reg.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n# score = lin_reg.score(x_test, y_test)\n\n# Output of score = 0.6524213016981026\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot Actual vs. Predicted\n\n# test = pd.DataFrame({'Predicted':y_pred,'Actual':y_test})\n# fig= plt.figure(figsize=(16,8))\n# test = test.reset_index()\n# test = test.drop(['index'],axis=1)\n# plt.plot(test[:80])\n# plt.legend(['Actual','Predicted'])\n# sns.jointplot(x='Actual',y='Predicted',data=test,kind='reg',color=\"grey\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Some memory issues with the kernel, that is why I have written the rest of the codes in comments, you can try at your end I am sure it would work.\n\n### Thank you all for understanding & reading...\n \n#### If you found this helpful an upvote would be really appreciated..."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}