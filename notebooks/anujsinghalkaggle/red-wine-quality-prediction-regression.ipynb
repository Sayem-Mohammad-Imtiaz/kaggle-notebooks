{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Red Wine Quality Prediction (Regression)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import all libraries\nimport numpy as np\n\nimport pandas as pd\n\nfrom matplotlib import pyplot as plt\n\nimport seaborn as sns\nsns.set_style('darkgrid')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## A) Exploratory Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# get red wine dataset\ndf = pd.read_csv('/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# stats of all the features\nprint(df.shape)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# get first 10 and last 10 values of the dataset\ndf.head(10)\ndf.tail(10)\n# have a look at the values of all the features, all make sense, no data currupt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check the unique values of out target feature\ndf.quality.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## B) Distribution and Segmentation between Numeric features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# check the numeric and catagorical features in the dataset\ndf.dtypes\n# all the features except target are float64\n# target feature is int64","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display stats of all numeric features\ndf.describe()\n# observations\n# 1. Quality(our target feature) has min 3 and max 8 value\n# 2. There is no null values in any of the feature\n# 3. count of all the features are same with the len(df)\n# 4. all the features with their values makes sense\n# 5. all the mean, min, max and std for all the features make sense","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# display distributions of numeric features is by using Pandas histograms\ndf.hist(figsize=(10,10), xrot=45)\nplt.show()\n# observe all the features how all they distributed based on a scale of 0 to 1000 and 0.00 to 1.00","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check the count of some features like quality\nsns.countplot(x='quality', data=df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get some correlations between our numeric features\ncorr = df.corr()\nsns.set_style('whitegrid')\nplt.figure(figsize=(10,10))\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)] = 1\nsns.heatmap(corr, cmap='RdBu_r', annot=True, cbar=False, mask=mask)\nplt.show()\n# observations\n# fixed acid is +ve correlated with density and -ve correlated with citric acid and pH\n# quality is +ve correlated with alcohal","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets see how our target feature related with other features\n# quality with fixed acidity\nsns.boxplot(x='quality', y='fixed acidity', data=df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# quality with pH\nsns.boxplot(x='quality', y='pH', data=df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# quality with density\nsns.boxplot(x='quality', y='density', data=df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# quality with alcohol\nsns.boxplot(x='quality', y='alcohol', data=df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# quality with citric acid\nsns.boxplot(x='quality', y='citric acid', data=df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# check is there any outliers with fixed acidity using violinplot\nsns.violinplot(x='quality',y='fixed acidity' ,data=df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check is there any outliers with density using violinplot\nsns.violinplot(x='quality',y='density' ,data=df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# check the relation of fixed acidity, alcohal and quality\nsns.lmplot(x='fixed acidity', y='alcohol', hue='quality', fit_reg=False, data=df)\nplt.show()\n# some observations\n# there are some values might be outliers where fixed acidity > 14","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# check the data where fixed aacidity > 14\ndf[df['fixed acidity'] > 14]\n# in those records we found one record where alcohal is high and fixed acidity is high but quality is 5, it might be not\n# good for our model, but we need to pick","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## C) Data cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove all the duplicates\ndf = df.drop_duplicates()\ndf.shape\n# there are 240 duplicates in the dataset, removed all duplicate records","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## D) Algorithm selection and evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import all algorithms, processing and metrics \n# algorithms\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n# model selection\nfrom sklearn.model_selection import train_test_split, GridSearchCV\n# scaling and tuning\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\n# evaluation\nfrom sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split datasets into test and train\nX = df.drop('quality', axis=1)\ny= df.quality\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=123, test_size=0.2)\nprint(len(X_train), len(X_test), len(y_train), len(y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model and evaluate with default parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"# scale datasets manually\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train_scaled = scaler.transform(X_train)\nX_test_scaled = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create a function to fit and eveluate scores for default\ndef fit_and_evaluate_default(model, name):\n    model.fit(X_train_scaled, y_train)\n    pred = model.predict(X_test_scaled)\n    print('------------- {} default -------------'.format(name))\n    print('R^2 score - ', r2_score(y_test, pred))\n    print('MSE score - ', mean_squared_error(y_test, pred))\n    print('MAE score - ', mean_absolute_error(y_test, pred))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# get some scores\n# linear models\nfit_and_evaluate_default(LinearRegression(), 'LinearRegression')\nfit_and_evaluate_default(Lasso(random_state=123), 'Lasso')\nfit_and_evaluate_default(Ridge(random_state=123), 'Ridge')\nfit_and_evaluate_default(ElasticNet(random_state=123), 'ElasticNet')\n# bagging and boosting\nfit_and_evaluate_default(RandomForestRegressor(random_state=123), 'RandomForestRegressor')\nfit_and_evaluate_default(GradientBoostingRegressor(random_state=123), 'GradientBoostingRegressor')\n# observations\n# in Linear models\n#  - Lasso and ElasticNet is doing very poor\n#  - LinearRegression and Ridge is doing ok and same\n# in bagging and boosting\n#  - Random Forest is worst than linear model\n#  - Boosting is the winner with minimum MAE, MSE and good R2 score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model and evaluate with Hyperparameters and tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"# make pipeline and hyperparameters\npipeline = {\n    'lasso': make_pipeline(StandardScaler(), Lasso(random_state=123)),\n    'ridge': make_pipeline(StandardScaler(), Ridge(random_state=123)),\n    'enet': make_pipeline(StandardScaler(), ElasticNet(random_state=123)),\n    'rf': make_pipeline(StandardScaler(), RandomForestRegressor(random_state=123)),\n    'gb': make_pipeline(StandardScaler(), GradientBoostingRegressor(random_state=123))\n}\nlasso_hyperparameters = {\n    'lasso__alpha' : [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000]\n}\nridge_hyperparameters = {\n     'ridge__alpha' : [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000]\n}\nenet_hyperparameters = {\n    'elasticnet__alpha' : [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000],\n    'elasticnet__l1_ratio' : [0.1, 0.3, 0.5, 0.7, 0.9]\n}\nrf_hyperparameters = {\n    'randomforestregressor__n_estimators': [100, 200],\n    'randomforestregressor__max_features': ['auto', 'sqrt', 0.33],\n    'randomforestregressor__min_samples_leaf': [1, 3, 5, 10]\n}\ngb_hyperparameters = {\n    'gradientboostingregressor__n_estimators': [100, 200],\n    'gradientboostingregressor__learning_rate': [0.05, 0.1, 0.2],\n    'gradientboostingregressor__max_depth': [1, 3, 5]\n}\nhyperparameters = {\n    'lasso': lasso_hyperparameters,\n    'ridge': ridge_hyperparameters,\n    'enet': enet_hyperparameters,\n    'rf': rf_hyperparameters,\n    'gb': gb_hyperparameters\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit, tune and evaluate the models with hyperparameters\nfitted_models = {}\nfor name, pip in pipeline.items():\n    model = GridSearchCV(pip, hyperparameters[name], cv=10, n_jobs=-1)\n    model.fit(X_train, y_train)\n    pred = model.predict(X_test)\n    print('-------------- {} HyperParameters --------------'.format(name))\n    fitted_models[name] = model\n    print('R^2 Score - ', r2_score(y_test, pred))\n    print('MSE Score - ', mean_squared_error(y_test, pred))\n    print('MAE Score - ', mean_absolute_error(y_test, pred))\n# observations\n# As we can see all the models with hyperparameters is doing great than default\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#\tDefault parameters evaluation\t                        ||\tHyper parameters evaluation\n#\t------------- LinearRegression default -------------\t||\t\n#\tR^2 score -  0.34950893422968987\t||\t\n#\tMSE score -  0.40176510124316495\t||\t\n#\tMAE score -  0.49586161191064304\t||\t\n\n#\t------------- Lasso default -------------\t            ||\t-------------- lasso HyperParameters --------------\n#\tR^2 score -  -9.415671320400776e-06\t                    ||\tR^2 Score -  0.343088183112235\n#\tMSE score -  0.6176393578219748\t                        ||\tMSE Score -  0.4057307725006274\n#\tMAE score -  0.6701018723956923\t                        ||\tMAE Score -  0.4988708354252194\n\n#\t------------- Ridge default -------------\t            ||\t-------------- Ridge HyperParameters --------------\n#\tR^2 score -  0.3495702136164457\t                        ||\tR^2 Score -  0.351485902258056\n#\tMSE score -  0.40172725303844764\t                    ||\tMSE Score -  0.40054405947661825\n#\tMAE score -  0.49582317783992663\t                    ||\tMAE Score -  0.49512066432203716\n\n#\t------------- ElasticNet default -------------\t        ||\t-------------- ElasticNet HyperParameters --------------\n#\tR^2 score -  -9.415671320400776e-06\t                    ||\tR^2 Score -  0.3410166818641156\n#\tMSE score -  0.6176393578219748\t                        ||\tMSE Score -  0.4070102011545636\n#\tMAE score -  0.6701018723956923\t                        ||\tMAE Score -  0.5007868122635286\n\n#\t------------- RandomForestRegressor default ----------\t||\t-------------- RandomForestRegressor HyperParameters --------------\n#\tR^2 score -  0.31135397745924054\t                    ||\tR^2 Score -  0.4151273888148237\n#\tMSE score -  0.42533088235294114\t                    ||\tMSE Score -  0.3612369426917526\n#\tMAE score -  0.5040441176470588\t                        ||\tMAE Score -  0.47408980640988907\n\n#\t----------- GradientBoostingRegressor default --------\t||\t-------------- GradientBoostingRegressor HyperParameters --------------\n#\tR^2 score -  0.3791890903531926\t                        ||\tR^2 Score -  0.3855813826539055\n#\tMSE score -  0.3834336412779906\t                        ||\tMSE Score -  0.37948554714032473\n#\tMAE score -  0.48444528046587343\t                    ||\tMAE Score -  0.4793086003776446\n\n# GradientBoostingRegressor did good in their default parameters\n# but RandomForestRegressor improved more than GradientBoostingRegressor with hyperparameters\n\n# Winner model is \"RandomForestRegressor HyperParameters\"\n#----------------------------------------\n#R^2 Score -  0.4151273888148237\n#MSE Score -  0.3612369426917526\n#MAE Score -  0.47408980640988907\n#----------------------------------------\n# RandomForestRegressor best estimation by setting those parameters:\n#  - max_features='sqrt', n_estimators=200, min_samples_leaf=3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# finally get the best estimator of the model\nprint(fitted_models['rf'].best_estimator_)\n# RandomForestRegressor best estimation by setting those parameters:\n#  - max_features='sqrt', n_estimators=200, min_samples_leaf=3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot our predicted values with our sample test values\npred = fitted_models['rf'].predict(X_test)\nplt.scatter(pred, y_test)\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\n# observations\n# 5 and 6 are predicted well almost close","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save the final model\nimport pickle\nwith open('final_model.pkl', 'wb') as f:\n    pickle.dump(fitted_models['rf'].best_estimator_, f)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}