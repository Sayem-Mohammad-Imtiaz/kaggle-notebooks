{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression for fake job identifying"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport math\n%matplotlib inline\nsns.set_context('notebook')\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report,confusion_matrix, accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/real-or-fake-fake-jobposting-prediction/fake_job_postings.csv')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA"},{"metadata":{},"cell_type":"markdown","source":"*Output of a number of visualisations to explore possible relations between the variables*"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Visualise the completness of the dataset.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(24, 6))\nsns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*As  we can see there are a number of columns that have a high number missing values. Such as the salary range  and department.   hunch lets see if the there any relationship between the employment tpye and the ad being fraudulent*"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['employment_type'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df['employment_type'], hue = df['fraudulent'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*As there are only five catergoris it might be worth obtaining dummy variables for these.\nInvestigate the make up of the salary range*"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['salary_range'].head(15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*As we can see there is a upper band and an lower band. This means we could split the field to obtain two new variables.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df['has_company_logo'], hue = df['fraudulent'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df['telecommuting'], hue = df['fraudulent'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creation of extra variables"},{"metadata":{},"cell_type":"markdown","source":"*First the creation of dummy variables for employment type*"},{"metadata":{"trusted":true},"cell_type":"code","source":"type_job = pd.get_dummies(df['employment_type'], drop_first = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> *Split of Salery Range and creation of new variables to include in the model*"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['salary_min'] = df['salary_range'][df['salary_range'].notnull()].apply(lambda x :x.split('-')[0])\ndf['salary_max'] = df['salary_range'][df['salary_range'].notnull()].apply(lambda x :x.split('-')[-1])\ndf['salary_min'] = pd.to_numeric(df['salary_min'], errors='coerce').fillna(\"0\")\ndf['salary_max'] = pd.to_numeric(df['salary_max'], errors='coerce').fillna(\"0\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Combine the new type dummy variables and the dataframe*"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([df, type_job], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Application of logistic regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"X= df[['telecommuting', 'has_company_logo', 'has_questions', 'Full-time', 'Other',\n       'Part-time', 'Temporary', 'salary_min', 'salary_max']]\ny = df['fraudulent']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state = 101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logmodel = LogisticRegression()\nlogmodel.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = logmodel.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(accuracy_score(y_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*As we can see there is thus far no predictive power in the model. I believe it is due to the fact that the number of positives is very low and it skews training of the model to predict only negtives.*"},{"metadata":{},"cell_type":"markdown","source":"## Next Steps"},{"metadata":{},"cell_type":"markdown","source":"*It might be worth to investigate wether some NLP on the title column will yield improvement in the model.*"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":4}