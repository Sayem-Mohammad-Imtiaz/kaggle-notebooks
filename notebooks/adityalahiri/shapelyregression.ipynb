{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv(\"../input/housesalesprediction/kc_house_data.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# just take continuous variables for now\ncols=['bedrooms', 'bathrooms', 'sqft_living',\n       'sqft_lot', 'floors','sqft_above', 'sqft_basement','sqft_lot15']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df[cols]\ny = df['price']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import Normalizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Normalize\nscalar = Normalizer()\nX_scaled = scalar.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Function to calculate permutation weight\nfrom math import factorial\ndef shapWt(num_total_features,num_current_features):\n    return ( ( factorial(num_current_features) ) * ( factorial( num_total_features - num_current_features -1 ) ) )/( factorial(num_total_features) )\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# function to get powerset\n\nfrom itertools import chain, combinations\n\ndef powerset(iterable):\n    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n    s = list(iterable)\n    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Computes shapely regression value for a feature value\n\ndef shapleyRegression(X,y,feature_index_find,total_features,instance):\n    \n    fts = [i for i in range(total_features)]\n    fts.remove(feature_index_find)\n    \n    all_subsets = list(powerset(fts))\n    shap = 0.0\n    total_wt = shapWt(total_features,0)\n    shap = shap + shapWt(total_features,0)*LinearRegression().fit(X[:,[feature_index_find]],y).predict(instance[feature_index_find].reshape(-1,1))\n    for each_set in all_subsets[1:]:\n        wt = shapWt(total_features,len(each_set))\n        total_wt += wt\n        cols = list(each_set)\n        model1 = LinearRegression().fit(X[:,cols],y)\n        cols_with_ft = cols.copy()\n        cols_with_ft.append(feature_index_find)\n        #print(cols)\n        model2 = LinearRegression().fit(X[:,cols_with_ft],y)\n        #print(instance.shape)\n        #print(instance.reshape(1,-1).shape)\n        f1 = model1.predict(instance[cols].reshape(1,-1))\n        f2 = model2.predict(instance[cols_with_ft].reshape(1,-1))\n        \n        shap = shap + (wt*(f2-f1))\n    \n    return shap\n        \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# find shapely value for all features\nshap_vals=[]\nfor i in range(8):\n    shap_vals.append(shapleyRegression(X_scaled,y,i,8,X_scaled[0,:]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compute phi(i)*b(i)\nweighted_shaps = np.multiply(np.asarray(shap_vals).reshape(-1,1),(X_scaled[0,:].reshape(-1,1)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#find phi(0) which is prediction - summation(phi(i)*b(i)). This should ideally \n#be a constant for different prediction. But if you run this whole experiment for \n#data point index 1 instead of index 0 and compare phi_0 for both, they are different.\n\nphi_0 = LinearRegression().fit(X_scaled,y).predict(X_scaled[0].reshape(1,-1)) - weighted_shaps.sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}