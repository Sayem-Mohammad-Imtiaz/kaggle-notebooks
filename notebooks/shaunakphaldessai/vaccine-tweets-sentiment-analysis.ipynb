{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n# TextBlob - Python library for processing textual data\nfrom textblob import TextBlob\n\n#GeoText to get country alpha-2 codes and identify cities and countries in text\n!pip install GeoText\nfrom geotext import GeoText\n\n#libraries to extract country name from cities and textual data\n!pip install geopandas\n!pip install geopy\nimport geopandas\nimport geopy\nfrom geopy.extra.rate_limiter import RateLimiter\nfrom geopy.geocoders import Nominatim\n\n#time library to space-out requests\nimport time\n\n#pycountry library to get alpha-2 country and continent codes\n!pip install pycountry-convert\nfrom pycountry_convert import country_alpha2_to_continent_code, country_name_to_country_alpha2\n\n#Using folium maps to create visualization\n!pip install folium\nimport folium\nfrom folium.plugins import MarkerCluster\n\nfrom tqdm.notebook import tqdm_notebook\ntqdm_notebook.pandas()\n\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/pfizer-vaccine-tweets/vaccination_tweets.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data2 = data.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('no. of unique users:', len(data['user_name'].unique()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*There are users who have tweeted more than once.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"username_counts = data['user_name'].value_counts()\npd.DataFrame(username_counts[username_counts>1]).reset_index().rename(columns = {'index': 'username', 'user_name': 'counts'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"usernamecounts_dict = dict(username_counts[username_counts>1])\nusernamecounts_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['user_location'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_loc = data[['id', 'user_name', 'user_location']]\ndata_loc.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_loc.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loc_obj_types = list()\nloc_obj_types = [type(x) for x in data_loc['user_location'] if (type(x) != str)]\nprint('no. of data types other than string', len(set(loc_obj_types)))\nprint('no. of objects that are not string', len(loc_obj_types))\nprint('non-string \"user_locations\" are ', (len(loc_obj_types)/data_loc.shape[0])*100, '%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_loc.dropna(subset=['user_location'], inplace = True)\ndata_loc.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_loc['user_location'] = data_loc['user_location'].progress_apply(lambda x: x.title() if (type(x) == str) else 'Unknown')\ndata_loc['country_location'] = data_loc['user_location'].progress_apply(lambda x: GeoText(str(x)).countries[0] if len(GeoText(str(x)).countries) != 0 else 'Unknown')\ndata_loc['city_location'] = data_loc['user_location'].progress_apply(lambda x: GeoText(str(x)).cities[0] if len(GeoText(str(x)).cities) != 0 else 'Unknown')\ndata_loc.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_loc = data_loc[~((data_loc['country_location'] == 'Unknown') & (data_loc['city_location'] == 'Unknown'))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_loc.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Using RateLimiter to gap-out requests to geocode servers.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"locator = Nominatim(user_agent='myGeocoder')\ngeocode = RateLimiter(locator.geocode, min_delay_seconds=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_loc['city_location'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_loc['country_location'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_loc.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_loc['country_location2'] = data_loc.progress_apply(lambda x: geocode(x['city_location']).address.split(', ')[-1:][0] if((x['country_location'] == 'Unknown') and (x['city_location'] != 'Unknown')) else x['country_location'], axis = 1)\ndata_loc.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_loc.drop(['country_location'], axis = 1, inplace = True)\ndata_loc.rename(columns = {'country_location2': 'country_location'}, inplace = True)\ndata_loc.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_loc['country_location'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def translate_text(text):\n    if ('/' in text):\n        text = text.split('/')[1].strip()\n    Text = TextBlob(u'\"'+text+'\"')\n    time.sleep(1)\n    if(Text.detect_language() != 'en'):\n        print(text)\n        if(Text.detect_language() == 'el'):\n            return 'Greece'        \n        time.sleep(1)\n        try:    \n            return str(Text.translate(to='en')).strip('\"')\n        except:\n            return text\n    else:\n        time.sleep(1)\n        return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"locs = list(data_loc['country_location'])\nu_locs = list(set(locs))\nprint(len(locs))\nprint(len(u_locs))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loc_trans = {text: translate_text(text) for text in u_locs}\nprint(loc_trans)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_loc['country_location2'] = data_loc['country_location'].apply(lambda x: loc_trans[x])\ndata_loc.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_loc['country_location2'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_continent_code(text):\n    try:\n        return country_alpha2_to_continent_code(text)\n    except:\n        return ' Un'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_country_code(text):\n    try:\n        return country_name_to_country_alpha2(text)\n    except:\n        return 'Un'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_loc['country_code'] = data_loc['country_location2'].progress_apply(lambda x: get_country_code(x))\ndata_loc.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_loc[data_loc['country_code'] == 'Un']['country_location2'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"difcount_codes = {'The United Arab Emirates' : 'AE', 'The Netherlands': 'NL', 'Asia': 'IN', 'Saudi': 'SA', 'Chili': 'CL', 'Luzon': 'PH', 'Sri Lanka Sri Lanka': 'LK', 'Free Kashmir': 'IN', 'Swiss': 'CH'}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list(difcount_codes.keys())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_loc['country_code'] = data_loc.progress_apply(lambda x: difcount_codes[x['country_location2']] if (x['country_code'] == 'Un') else x['country_code'], axis = 1)\ndata_loc.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_loc['country_code'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_loc['continent_code'] = data_loc['country_code'].progress_apply(lambda x: get_continent_code(x))\ndata_loc.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"u_countrycodes = list(set(list(data_loc['country_code'])))\nprint(len(u_countrycodes))\nprint(u_countrycodes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"geolocator = Nominatim(user_agent='myGeocoder')\ndef geolocate(country):\n    try:\n        # Geolocate the center of the country\n        loc = geolocator.geocode(country)\n        # And return latitude and longitude\n        return (loc.latitude, loc.longitude)\n    except:\n        # Return missing value\n        return (np.nan, np.nan)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_coords = {cc: geolocate(cc) for cc in u_countrycodes}\nprint(country_coords)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i,v in country_coords.items():\n    if(v == (np.nan, np.nan)):\n        print(i)\n        if( i == 'IN'):\n            country_coords[i] = geolocate('India')\n        elif( i == 'IL'):\n            country_coords[i] = geolocate('Israel')\n        elif(i == 'ET'):\n            country_coords[i] = geolocate('Ethiopia')\nprint(country_coords)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Geopy's Geocode function could not return the correct coordinates for regions based on their country codes. Regions such as Cayman Islands ('KY'), Albania ('AL') etc were mis-identified as U.S. states.*\n\n*I recently came across a gist of country data much like what we are after over here. I'm using the coordinates specified through this publicly available csv file.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"country_data = pd.read_csv('https://gist.githubusercontent.com/cpl/3dc2d19137588d9ae202d67233715478/raw/3d801e76e1ec3e6bf93dd7a87b7f2ce8afb0d5de/countries_codes_and_coordinates.csv')\ncountry_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_data['Country'] = country_data['Country'].progress_apply(lambda x: str(x))\ncountry_data['Alpha-2 code'] = country_data['Alpha-2 code'].progress_apply(lambda x: str(x.replace('\"', \"\").strip(' ')))\ncountry_data['Alpha-3 code'] = country_data['Alpha-3 code'].progress_apply(lambda x: str(x.replace('\"', \"\").strip(' ')))\ncountry_data['Numeric code'] = country_data['Numeric code'].progress_apply(lambda x: int(x.replace('\"', \"\").strip(' ')))\ncountry_data['Latitude (average)'] = country_data['Latitude (average)'].progress_apply(lambda x: float(x.replace('\"', \"\").strip(' ')))\ncountry_data['Longitude (average)'] = country_data['Longitude (average)'].progress_apply(lambda x: float(x.replace('\"', \"\").strip(' ')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_data['Country'] = country_data['Country'].astype(str)\n\ncountry_data['country_code'] = country_data['Alpha-2 code'].astype(str)\ncountry_data.drop(['Alpha-2 code'], axis = 1, inplace = True)\ncountry_data['Alpha-3 code'] = country_data['Alpha-3 code'].astype(str)\ncountry_data['Numeric code'] = country_data['Numeric code'].astype(int)\ncountry_data['Latitude (average)'] = country_data['Latitude (average)'].astype(float)\ncountry_data['Longitude (average)'] = country_data['Longitude (average)'].astype(float)\ncountry_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_tweets = data_loc.shape[0]\nprint('tweets with locations: ', n_tweets)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wrld_map = data_loc.groupby(['country_code']).size().to_frame(name = 'count').reset_index()\nwrld_map.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wrld_map['percentage'] = wrld_map['count'].progress_apply(lambda x: (x/n_tweets))\nwrld_map.drop(['count'], axis = 1, inplace = True)\nwrld_map.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wrld_map = pd.merge(wrld_map, country_data, on='country_code')\nwrld_map.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wrld_map['continent_code'] = wrld_map['country_code'].progress_apply(lambda x: get_continent_code(x))\nwrld_map.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#empty map\nworld_map= folium.Map(tiles=\"cartodbpositron\")\nmarker_cluster = MarkerCluster().add_to(world_map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#for each coordinate, create circlemarker of user percent\nfor i in range(len(wrld_map)):\n        lat = wrld_map.iloc[i]['Latitude (average)']\n        long = wrld_map.iloc[i]['Longitude (average)']\n        radius=5\n        popup_text = \"\"\"Country : {}<br>\n                    %of Users : {}<br>\"\"\"\n        popup_text = popup_text.format(wrld_map.iloc[i]['country_code'],\n                                   wrld_map.iloc[i]['percentage']\n                                   )\n        folium.CircleMarker(location = [lat, long], radius=radius, popup= popup_text, fill =True).add_to(marker_cluster)\n#show the map\nworld_map","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['user_name'].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***There are no records with empty user names.***"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['user_location'].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# *There are 1250 missing user locations*"},{"metadata":{},"cell_type":"markdown","source":"# **Dropping user_locations feature as the number of missing columns are more than 34% of data**"},{"metadata":{},"cell_type":"markdown","source":"# *We will drop user_descriptions as well, as they don't seem to contribute much.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['user_created'].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# *All the user creation dates seem to be present.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['user_followers'].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\nfig = px.histogram(data, x=\"user_followers\", range_x  = (0,500000))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# *User Followers seem fine.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cleaning the tweets\n\ndef cleanUpTweet(txt):\n    # Remove mentions\n    txt = re.sub(r'@[A-Za-z0-9_]+', '', txt)\n    # Remove hashtags\n    txt = re.sub(r'#', '', txt)\n    # Remove retweets:\n    txt = re.sub(r'RT : ', '', txt)\n    # Remove urls\n    txt = re.sub(r'https?:\\/\\/[A-Za-z0-9\\.\\/]+', '', txt)\n    return txt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['text'] = data['text'].apply(cleanUpTweet)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Determining Subjectivity and Polarity of text using TextBlob*"},{"metadata":{"trusted":true},"cell_type":"code","source":"def getTextSubjectivity(txt):\n    return TextBlob(txt).sentiment.subjectivity\n\ndef getTextPolarity(txt):\n    return TextBlob(txt).sentiment.polarity","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Subjectivity'] = data['text'].apply(getTextSubjectivity)\ndata['Polarity'] = data['text'].apply(getTextPolarity)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# negative, nautral, positive analysis\ndef getTextAnalysis(a):\n    if a < 0:\n        return \"Negative\"\n    elif a == 0:\n        return \"Neutral\"\n    else:\n        return \"Positive\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Sentiment'] = data['Polarity'].apply(getTextAnalysis)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"positive_tweets = data[data['Sentiment'] == 'Positive']\n\nprint(str(positive_tweets.shape[0]/(data.shape[0])*100) + \" % of positive tweets\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = data.groupby('Sentiment').count().index.values\n\nvalues = data.groupby('Sentiment').size().values\n\nplt.bar(labels, values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for index, row in data.iterrows():\n    if row['Sentiment'] == 'Positive':\n        plt.scatter(row['Polarity'], row['Subjectivity'], color=\"green\")\n    elif row['Sentiment'] == 'Negative':\n        plt.scatter(row['Polarity'], row['Subjectivity'], color=\"red\")\n    elif row['Sentiment'] == 'Neutral':\n        plt.scatter(row['Polarity'], row['Subjectivity'], color=\"blue\")\n\nplt.title('Vaccine Sentiment Analysis')\nplt.xlabel('Polarity')\nplt.ylabel('Subjectivity')\n# add legend\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Initial Analysis using TextBlob shows more Positive tweets than Negative or Neutral*"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Sentiment'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Calculating Influence of Tweets by User Profile Size**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def tweet_influence(row):\n    #print(row['text'])\n    followers = row['user_followers']\n    retweets = row['retweets']\n    is_retweet = int(row['is_retweet'])\n    #print(is_retweet)\n    friends = row['user_friends']\n    #print('tweet influence: ', ((followers + retweets)/pow(2, is_retweet)) + friends)\n    tweet_influence = ((followers + retweets)/pow(2, is_retweet)) + friends\n    return tweet_influence","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}