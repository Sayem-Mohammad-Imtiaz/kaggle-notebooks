{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n#from sklearn.cross_validation import train_test_split\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nimport cv2\ndataset_path = '../input/fer2013/fer2013.csv'\nimage_size=(48,48)\n \ndef load_fer2013():\n    data = pd.read_csv(dataset_path)\n    pixels = data['pixels'].tolist()\n    width, height = 48, 48\n    faces = []\n    for pixel_sequence in pixels:\n        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n        face = np.asarray(face).reshape(width, height)\n        face = cv2.resize(face.astype('uint8'),image_size)\n        faces.append(face.astype('float32'))\n    faces = np.asarray(faces)\n    faces = np.expand_dims(faces, -1)\n    emotions = pd.get_dummies(data['emotion']).as_matrix()\n    return faces, emotions\n \ndef preprocess_input(x, v2=True):\n    x = x.astype('float32')\n    x = x / 255.0\n    if v2:\n        x = x - 0.5\n        x = x * 2.0\n    return x\n \nfaces, emotions = load_fer2013()\nfaces = preprocess_input(faces)\nxtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)\nprint(xtrain.shape) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\n\nfor ix in range(10):\n    print(ytrain[ix])\n    plt.figure(ix)\n    plt.imshow(xtrain[ix].reshape((48, 48)), interpolation='none', cmap='gray')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nbatch_size = 128\nnum_classes = 7\nepochs = 12\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" \nprint('xtrain shape:', xtrain.shape)\nprint(xtrain.shape[0], 'train samples')\nprint(xtest.shape[0], 'test samples')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=(48,48,1)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(7, activation='softmax'))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#modified\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=(48,48,1)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(7, activation='softmax'))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\nmodel.fit(xtrain, ytrain,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(xtest, ytest))\nscore = model.evaluate(xtest, ytest, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\nypred = model.predict(xtest)\nlabels = np.argmax(ypred, axis=-1) \nprint(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BS=3\nimport pandas as pd \nfrom keras_preprocessing.image import ImageDataGenerator\naug = ImageDataGenerator(rotation_range=20, zoom_range=0.15,\n     width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n      horizontal_flip=True, fill_mode=\"nearest\")\n \n# train the network\nH = model.fit_generator(aug.flow(xtrain, ytrain, batch_size=BS),\nvalidation_data=(xtest, ytest), steps_per_epoch=len(xtrain) // BS,\nepochs=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain.shape\ntest2[0].shape\ntest2[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nFACE_CLASSIFIER = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\nEYE_CLASSIFIER = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\nSCALE_FACTOR = 1.3\nBLUE_COLOR = (255, 0, 0)\nMIN_NEIGHBORS = 5\nframe=cv2.imread('../input/angrydata/angry2.jpg')\ngray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\nfaces = FACE_CLASSIFIER.detectMultiScale(gray, SCALE_FACTOR, MIN_NEIGHBORS)\nprint (faces)\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom keras.preprocessing.image import img_to_array\nEMOTIONS = [\"angry\",\"disgust\",\"scared\", \"happy\", \"sad\", \"surprised\",\"neutral\"]\n#img_path='../input/testimage/'\n#frame=cv2.imread('../input/testimage/mohanlalangry.jpg')\n#reading the frame\n#orig_frame = cv2.imread(img_path)\n#frame = cv2.imread(img_path,0)\n#faces = face_detection.detectMultiScale(frame,scaleFactor=1.1,minNeighbors=5,minSize=(30,30),flags=cv2.CASCADE_SCALE_IMAGE)\n \nif len(faces) > 0:\n    print(faces)\n    faces = sorted(faces, reverse=True,key=lambda x: (x[2] - x[0]) * (x[3] - x[1]))[0]\n    (fX, fY, fW, fH) = faces\n    print(fX, fY, fW, fH)\n    roi = gray[fY:fY + fH, fX:fX + fW]\n    roi = cv2.resize(roi, (48, 48))\n    roi = roi.astype(\"float\") / 255.0\n    roi = img_to_array(roi)\n    roi = np.expand_dims(roi, axis=0)\n    preds = model.predict(roi)[0]\n    emotion_probability = np.max(preds)\n    label = EMOTIONS[preds.argmax()]\n    #cv2.putText(orig_frame, label, (fX, fY - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n    #cv2.rectangle(orig_frame, (fX, fY), (fX + fW, fY + fH),(0, 0, 255), 2)\n \n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\nprint(label)\nprint(roi[0].shape)\nplt.figure(1)\nplt.imshow(roi[0].reshape(48, 48), interpolation='none', cmap='gray')\nplt.show()\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}