{"cells":[{"metadata":{"_uuid":"eb3f9660c8a0ddc34058d7c1832e106c7387a128"},"cell_type":"markdown","source":" <h1><center><span style=\"color:red\">Breast Cancer Classification</span> </center></h1>"},{"metadata":{"_uuid":"6cb447ff13a61b62032d34f2207b6b4c37a36927"},"cell_type":"markdown","source":" <h3><center>There are two main classifications of tumors. One is known as benign and the other as malignant. A benign tumor is a tumor that does not invade its surrounding tissue or spread around the body. A malignant tumor is a tumor that may invade its surrounding tissue or spread around the body.</center></h3>\n \n  <h3><center>- This notebook is used to classify a breast cancer patient by wheather it is malignant or benign</center></h3>"},{"metadata":{"trusted":false,"_uuid":"a36bb5ae201619bdf395a3beb9c028a6a5229056"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score, precision_score,recall_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1d4f5ed1802bc5d69e01354d6cb52f65b08643f6"},"cell_type":"markdown","source":"## 1.0 Analyzing the dataset to understand the data"},{"metadata":{"trusted":false,"_uuid":"abcd140b0e648c8aad9319a435c26bde7b0cfe6f"},"cell_type":"code","source":"data = pd.read_csv('../input/data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"b3a9b41903b516713e9da8ac1e3c33d99b529ebd"},"cell_type":"code","source":"data=data.drop('Unnamed: 32',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"5a83979890819010d0aea747e57b448a52981667"},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"23f913daa54fd1b9d5770e4d42a1d51c033392d1"},"cell_type":"markdown","source":"### 1.1 Null values"},{"metadata":{"trusted":false,"_uuid":"5b4bfaff24d55eb2ed9762196f1f766ed5c25283"},"cell_type":"code","source":"data.apply(lambda x: sum(x.isnull()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2814915a8b26e3593c7a95d2d5d0168523f209de"},"cell_type":"markdown","source":"### 1.2 Unique Values"},{"metadata":{"trusted":false,"_uuid":"46578f8c64a4c9ffe2feac0d6a9f15d2f91ec4a6"},"cell_type":"code","source":"print(data.shape[0])\ndata.apply(lambda x : len(x.unique()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c16e225430450012c7e3682fd4c37f2c66b78202"},"cell_type":"markdown","source":"### 1.3 Comparing the valus in the dependant variable"},{"metadata":{"trusted":false,"_uuid":"a93c60e2444ca30c895ffe2535868fcf1b2f6220"},"cell_type":"code","source":"plt.figure(1)\ndata['diagnosis'].value_counts(normalize=True).plot.bar( title= 'dependant variable')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"411103dce0eaed68ce9e5353463e095a834c78a8"},"cell_type":"markdown","source":"### 1.4 Analyzing the variables, after normalizing the variables and after log transforming the variable"},{"metadata":{"trusted":false,"_uuid":"6e0e47fc3e88944c4773ac9fada627f84dd0af3c"},"cell_type":"code","source":"def dist(variable):\n    plt.subplot(222)\n    ax1=plt.subplot(221)\n    sns.distplot(data[variable]);\n    ax2=plt.subplot(222)\n    sns.distplot(np.log1p(data[variable]));\n    ax2=plt.subplot(223)\n    mms = MinMaxScaler()\n    sns.distplot(mms.fit_transform(data[variable].values.reshape(-1,1)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e739a690f728ba4d18a5f73ed734438f83f40cd4"},"cell_type":"markdown","source":"### 1.5 Analyzing the correlation of variables "},{"metadata":{"trusted":false,"_uuid":"4af14254ba8e4b7b49de0fafda5659fed07bd3e9"},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20,20)) \nsns.heatmap(data.corr(),cmap=sns.diverging_palette(220, 20, as_cmap=True))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"832913a47eed12a1de12703f8e356c49825abce8"},"cell_type":"markdown","source":"### 1.6 Excluding one variable that is correlated"},{"metadata":{"trusted":false,"_uuid":"72429a63b79159e2489a34a15e7516aba0f16d0e"},"cell_type":"code","source":"data = data.drop('radius_mean',axis=1)\ndata = data.drop('perimeter_mean',axis=1)\ndata = data.drop('area_mean',axis=1)\ndata = data.drop('perimeter_worst',axis=1)\ndata = data.drop('area_worst',axis=1)\ndata = data.drop('radius_se',axis=1)\ndata = data.drop('perimeter_se',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"df6a6f1ad418f6c5b12043363134490cde78154e"},"cell_type":"markdown","source":"### 1.7 Analyzing the distribution of each numerical variable "},{"metadata":{"trusted":false,"_uuid":"1edeff1ca37b9c08d56c3301ebb2edc4e63ccbcc"},"cell_type":"code","source":"dist('smoothness_mean')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"ee260e2c5e6c20f2a15a7f1e9175126001953a49"},"cell_type":"code","source":"dist('texture_mean')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"a206b27ad3e0b6ba2a322ae98b11cd75b2406d5d"},"cell_type":"code","source":"dist('compactness_mean')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"3c5334bd1dfd3887f7cc71435e88e343f360afbf"},"cell_type":"code","source":"dist('concavity_mean')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"0e4e6e5cc4ff4f4da659a949093fd5199dbf5c75"},"cell_type":"code","source":"dist('concave points_mean')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"80aa5bcf653bd94367b69aff6becef18c375667c"},"cell_type":"code","source":"dist('symmetry_mean')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f58a2ddd01a80aceb13a0b7c85b2d499fb65977b"},"cell_type":"code","source":"dist('fractal_dimension_mean')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"3328c29ece9485e1f7c3e29090698fe3db969f03"},"cell_type":"code","source":"dist('texture_se')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"2a74cbed932245e9f0fbd033f4ecb3d713235189"},"cell_type":"code","source":"dist('area_se')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"b4cfc03ae68d9de9de6843b5cf37055581d4c625"},"cell_type":"code","source":"dist('smoothness_se')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"7509bd6df989385997db9cfee2ce1c0a2c1e05aa"},"cell_type":"code","source":"dist('compactness_se')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"445ec7327db068e65554930050328c11d0619d81"},"cell_type":"code","source":"dist('concavity_se')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"4c5e2a5a17d526b655f3548bbbbf704ed5e2f9d4"},"cell_type":"code","source":"dist('concave points_se')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"df68f9c912e502b47d1a13f15a59023de576f002"},"cell_type":"code","source":"dist('symmetry_se')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"7db1db72ac227803fd3e84ad3cf91587b1a2a741"},"cell_type":"code","source":"dist('fractal_dimension_se')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"75621297632332041ebd709e5b02d12028179ddc"},"cell_type":"code","source":"dist('radius_worst')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"9eac05a15c5d9fc207da6b1ccc70e2108c1d7f22"},"cell_type":"code","source":"dist('texture_worst')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"ad11c55032db96f1078bfb47c3e855060e3fdc9a"},"cell_type":"code","source":"dist('smoothness_worst')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"dac5e521bc8b65b9808e66dda1b9f428c7e484ce"},"cell_type":"code","source":"dist('compactness_worst')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"60c82313fa61f669b0f3019f9e8f2e82a7b6d813"},"cell_type":"code","source":"dist('concavity_worst')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"6a3f3cd54085eb586313cfb73f0699e04dca4ead"},"cell_type":"code","source":"dist('concave points_worst')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"b89b500c37b5170dcb373d2038181f9ff36ed1bc"},"cell_type":"code","source":"dist('symmetry_worst')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"a13cb4c25cedb6209bad1ace25f3717ef2990a1f"},"cell_type":"code","source":"dist('fractal_dimension_worst')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d4cfcd7a34cdd3b5e2759a7a06de4813e9cfd06a"},"cell_type":"markdown","source":"### 1.8 Create a copy of the dataset to predict the model performance before and after remove outliers"},{"metadata":{"trusted":false,"_uuid":"069911178574dee14c07bdfeae9eaad4580a86be"},"cell_type":"code","source":"data_outliers_removed = data.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"12250c21e8417c24ede8f523190e0d1b9ac63e0d"},"cell_type":"code","source":"ax = sns.boxplot(y=\"texture_mean\",  data=data_outliers_removed, linewidth=2.5)\ndescription = data_outliers_removed.texture_mean.describe()\nQ1 = description[4]\nQ3 = description[6]\noutliers_low = Q1 - (1.5 * (Q3-Q1))\noutliers_high = Q3 + (1.5 * (Q3-Q1))\nprint(outliers_low,outliers_high)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"78d0120155c03ba3daab15429996c8df2b82debd"},"cell_type":"code","source":"numerical = ['radius_mean', 'texture_mean', 'perimeter_mean',\n       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n       'perimeter_worst', 'area_worst', 'smoothness_worst',\n       'compactness_worst', 'concavity_worst', 'concave points_worst',\n       'symmetry_worst', 'fractal_dimension_worst']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"02dd3066a58e7c065792395d06751e3a5c2b12e6"},"cell_type":"code","source":"for i in numerical:\n    if i in data.columns:\n        print (i + ' : ' + str(data_outliers_removed[i].mean()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"d7993d701e8485d8d49371bddc6b1e4943114156"},"cell_type":"code","source":"for i in numerical:\n    if i in data.columns:\n        description = data_outliers_removed[i].describe()\n        Q1 = description[4]\n        Q3 = description[6]\n        outliers_low = Q1 - (1.5 * (Q3-Q1))\n        outliers_high = Q3 + (1.5 * (Q3-Q1))\n        median = data_outliers_removed[i].median()\n        temp_high = data_outliers_removed[i]>outliers_high\n        temp_low = data_outliers_removed[i]>outliers_low\n        data_outliers_removed.loc[temp_high == True,i]= median\n        data_outliers_removed.loc[temp_low == True,i]= median","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"4b0c11f859846a6db3ec5fba5df6a5834deac403"},"cell_type":"code","source":"for i in numerical:\n    if i in data.columns:\n        print (i + ' : ' + str(data_outliers_removed[i].mean()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3756ed9e4b7dfeaeb682b67bf8db1c465999daeb"},"cell_type":"markdown","source":"### 1.9 Converting numerical variables to the log of each variable"},{"metadata":{"trusted":false,"_uuid":"3be6a20552148b260b0b67f7f69fe707a6295527"},"cell_type":"code","source":"for i in numerical:\n    if i in data.columns:\n        data_outliers_removed[i] = np.log1p(data_outliers_removed[i])\n        data[i] = np.log1p(data[i])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"606a57224a450534395cfff507c53af6cf0b0744"},"cell_type":"markdown","source":"### 1.10 Removing the ID variable"},{"metadata":{"trusted":false,"_uuid":"f5c96aaf001b629689beaeb82dfd7925086e6be0"},"cell_type":"code","source":"data = data.drop('id',axis=1)\ndata_outliers_removed = data_outliers_removed.drop('id',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e09694b80b48026dc5279015533a31418efec0a1"},"cell_type":"markdown","source":"## 2.0 Model Training and Prediction"},{"metadata":{"_uuid":"2d9decff49e0414282c3e2986230bee3f4e02fd1"},"cell_type":"markdown","source":"### 2.1 Using Logistic Regression to predict the model's preformance"},{"metadata":{"trusted":false,"_uuid":"a50f3b689949ab6fe799cc810b064cc8d776d4ce"},"cell_type":"code","source":"def prediction(x,y,regressor):\n    le = LabelEncoder()\n    y=le.fit_transform(y)\n    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.33)\n    regressor.fit(x_train,y_train)\n    y_pred = regressor.predict(x_test)\n    return accuracy_score(y_test,y_pred)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f8afae7ff96dda69f552dc72f27c07b1a22b2b2b"},"cell_type":"code","source":"LR = LogisticRegression()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"298dcc2d8734bdfd92d850684950735393e38770"},"cell_type":"markdown","source":"### 2.2  performance without outliers"},{"metadata":{"trusted":false,"_uuid":"d8826bdf5c24a8498ce2a4e6604d906bbc71d71b"},"cell_type":"code","source":"prediction(data_outliers_removed.drop('diagnosis',axis=1),data['diagnosis'],LR)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b294ee7c259bb31347e2e519a6c0bf6f358b504b"},"cell_type":"markdown","source":"### 2.3 Performance with outliers"},{"metadata":{"trusted":false,"_uuid":"436d70202e818195afc45a5fa12f1301da82d3d3"},"cell_type":"code","source":"prediction(data.drop('diagnosis',axis=1),data['diagnosis'],LR)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"754f8b57ac14dceac5af6b6bc442267aeb79bff8"},"cell_type":"markdown","source":"### 2.4 Using support vector machine by using different parameters"},{"metadata":{"trusted":false,"_uuid":"6d2aa18a847ff97be24cfe35f36e5e3933244369"},"cell_type":"code","source":"le = LabelEncoder()\nx = data.drop('diagnosis',axis=1)\ny = le.fit_transform(data['diagnosis'])\nX_train,X_test,y_train,y_test = train_test_split(x,y,test_size=0.33)\ntuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n                     'C': [1, 10, 100, 1000]},\n                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n\nscores = ['precision', 'recall']\n\nfor score in scores:\n    print(\"# Tuning hyper-parameters for %s\" % score)\n    print()\n\n    clf = GridSearchCV(SVC(), tuned_parameters, cv=5,\n                       scoring='%s_macro' % score)\n    clf.fit(X_train, y_train)\n\n    print(\"Best parameters set found on development set:\")\n    print()\n    print(clf.best_params_)\n    print()\n    print(\"Grid scores on development set:\")\n    print()\n    means = clf.cv_results_['mean_test_score']\n    stds = clf.cv_results_['std_test_score']\n    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n        print(\"%0.3f (+/-%0.03f) for %r\"\n              % (mean, std * 2, params))\n    print()\n\n    print(\"Detailed classification report:\")\n    print()\n    print(\"The model is trained on the full development set.\")\n    print(\"The scores are computed on the full evaluation set.\")\n    print()\n    y_true, y_pred = y_test, clf.predict(X_test)\n    print(classification_report(y_true, y_pred))\n    print()\n    #print(accuracy_score(y_pred = y_pred, y_true = y_test),precision_score(y_pred = y_pred, y_true = y_test),recall_score(y_pred = y_pred, y_true = y_test))\n\n# Note the problem is too easy: the hyperparameter plateau is too flat and the\n# output model is the same for precision and recall with ties in quality","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"50b0a9dcae12781b4d151ee97c1038ef0e69c025"},"cell_type":"code","source":"x = data.drop('diagnosis',axis=1)\ny = le.fit_transform(data['diagnosis'])\nclf = SVC(kernel='linear', C=1000)\nscores = cross_val_score(clf, x, y, cv=10, scoring='accuracy')\nscores.mean()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"98ead1b80b3a72a0c1c193f279c8948c8f15b5c3"},"cell_type":"markdown","source":"## 3.0 Comparing different techniques and optimizing the algorithm"},{"metadata":{"_uuid":"49ecd5d5757ff91d9034cb6a80ae2443cadd05eb"},"cell_type":"markdown","source":"### 3.1 Using cross validation and fitting SVM, Decision Tree Classifier"},{"metadata":{"trusted":false,"_uuid":"cb9e98b189c655428fc3aaa376130648e335740c"},"cell_type":"code","source":"x = data.drop('diagnosis',axis=1)\ny = le.fit_transform(data['diagnosis'])\nX_train,X_test,y_train,y_test = train_test_split(x,y,test_size=0.33,random_state=4)\nmetrics = pd.DataFrame(index = ['accuracy','precision','recall'],\n                       columns = ['Tree','SVM'])\ndef crossval(model,parameters):\n    clf = GridSearchCV(model, parameters)\n    clf.fit(X_train,y_train)\n    y_pred = clf.best_estimator_.predict(X_test)\n    accuracy = np.average(cross_val_score(clf, X_test, y_test, scoring='accuracy'))\n    precision = np.average(cross_val_score(clf, X_test, y_test, scoring='precision'))\n    recall = np.average(cross_val_score(clf, X_test, y_test, scoring='recall'))\n    f1= np.average(cross_val_score(clf, X_test, y_test, scoring='f1'))\n    if model==svm:\n        metrics.loc['accuracy','SVM'] = accuracy\n        metrics.loc['precision','SVM'] = precision\n        metrics.loc['recall','SVM'] = recall\n    if model==tree:\n        metrics.loc['accuracy','Tree'] = accuracy\n        metrics.loc['precision','Tree'] = precision\n        metrics.loc['recall','Tree'] = recall\n    return accuracy,precision,recall,f1,clf.best_estimator_,metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"bb08d18c6998fd6454b6dc22635f86f087b0fa3c"},"cell_type":"code","source":"svm = SVC()\ntree= DecisionTreeClassifier()\nparameters = {'kernel':('linear', 'rbf'), 'C':(1,10,100),'gamma': (1,2,3,'auto'),'decision_function_shape':('ovo','ovr'),'shrinking':(True,False)}\naccuracy,precision,recall,f1,model,metrics = crossval(svm,parameters)\nprint(metrics)\nparameters = {'max_depth':(1,6,12,15)}\naccuracy,precision,recall,f1,model,metrics = crossval(tree,parameters)\nprint(metrics)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"efb3e633547a57476f2a145fec57550ed2128e49"},"cell_type":"markdown","source":"### 3.2 Accuracy, Precision and Recall values of SVM and Decision Tree Classifier"},{"metadata":{"trusted":false,"_uuid":"6f2b81128856728cfad22df18b453521611688d7"},"cell_type":"code","source":"fig,ax = plt.subplots(figsize = (10,5))\nmetrics.plot(kind='barh', ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"854fb529fd564ab45f99627b850319149c56829a"},"cell_type":"markdown","source":"### Since We are dealing with two different types of cancers and not True or False, I believe that our prediction has a good accuracy score and can be improved further"},{"metadata":{"_uuid":"c9c3b155b754d979f6075e7572416bad729288b6"},"cell_type":"markdown","source":" <h1><center><span style=\"color:red\">END</span> </center></h1>"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}