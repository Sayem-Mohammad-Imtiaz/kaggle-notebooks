{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"cell_type":"markdown","source":"<font size=\"10\" color=\"black\">Clusterização</font>\n\nEduardo Chaves Ferreira\n\n"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true},"cell_type":"markdown","source":"## O que será tratado no curso\n\n- Clustering\n\n\n"},{"metadata":{"_uuid":"b89ace3ccc30394de0b5c6cfe3df4353822b30b3"},"cell_type":"markdown","source":"# 1- Importação de bibliotecas e funções gerais usadas no caderno"},{"metadata":{"_uuid":"f37277b0a0b0d139417f496eb641102f2d8c77a5","trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport math\nimport random\nimport pandas as pd\nimport scipy.stats as stat\nimport seaborn as sns\nimport os\nimport pandas\nimport sklearn\n\nfrom IPython.display import Image\nfrom scipy import stats\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\nfrom sklearn.decomposition import PCA\nfrom sklearn import preprocessing\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\n\n# Para ter repetibilidade nos resultados\nrandom_state = 1\n\n# Tratar valores infinitos como np.NaN\npandas.options.mode.use_inf_as_na = True\n\n# IMPORTANTE para tornar figuras interativas\n%matplotlib notebook\n\n# Tamanho padrão das figuras\nfigsize=(10,6)\n\n# Verificação do local para carga de dados\npath = os.environ['PATH']\n\nif path.startswith('C'):\n    IN_KAGGLE = False\nelse:\n    IN_KAGGLE = True\n    \n\n# Bibliotecas específicas do livro Introduction to Machine Learning with Python\n# https://github.com/amueller/introduction_to_ml_with_python\n# pip install mglearn\n\nimport mglearn\n\n\n# Configuração do número de linhas e colunas a serem apresentadas em listagens\npd.set_option('display.max_row', 1000)\n\npd.set_option('display.max_columns', 50)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f1fcbffb5dd4c49ffb0cbd6c87bdb3623b3a623a"},"cell_type":"code","source":"os.listdir('../input')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e9014ec6968dc5613ac6d28aae8d7afea7a24771"},"cell_type":"code","source":"# Função de conversão de dados copiada de https://github.com/shakedzy/dython/blob/master/dython/_private.py\n# Autor Shaked Zychlinski\n\ndef convert(data, to):\n    converted = None\n    if to == 'array':\n        if isinstance(data, np.ndarray):\n            converted = data\n        elif isinstance(data, pd.Series):\n            converted = data.values\n        elif isinstance(data, list):\n            converted = np.array(data)\n        elif isinstance(data, pd.DataFrame):\n            converted = data.as_matrix()\n    elif to == 'list':\n        if isinstance(data, list):\n            converted = data\n        elif isinstance(data, pd.Series):\n            converted = data.values.tolist()\n        elif isinstance(data, np.ndarray):\n            converted = data.tolist()\n    elif to == 'dataframe':\n        if isinstance(data, pd.DataFrame):\n            converted = data\n        elif isinstance(data, np.ndarray):\n            converted = pd.DataFrame(data)\n    else:\n        raise ValueError(\"Unknown data conversion: {}\".format(to))\n    if converted is None:\n        raise TypeError('cannot handle data conversion of type: {} to {}'.format(type(data),to))\n    else:\n        return converted","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6a3f09bce6c0d925ac7b1050023ce6291d3eb870"},"cell_type":"markdown","source":"## Treinamento de rede neural para regressão\n\nUsada ao longo do caderno para testar efeitos da redução de dimensionalidade\n\nhttp://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html"},{"metadata":{"_uuid":"5eced01f10b015a9c1ec3a23447aaf196cb496a3","trusted":true},"cell_type":"code","source":"from sklearn.neural_network import MLPRegressor\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\n\n\ndef redes_neurais_regressao(X_, Y_, to_scale=True):\n\n    X_ = convert(X_, 'array')\n        \n    Y_ = convert(Y_, 'array')\n    \n    # Transforma Y em array 1-D\n    #Y_ = np.ravel(Y_)\n    \n    if to_scale:\n        # Escala variáveis\n        scaler = MinMaxScaler(feature_range=(0, 1))\n\n        X_escale = scaler.fit_transform(X_) \n        Y_escale = scaler.fit_transform(Y_) \n    else:\n        X_escale = X_\n        Y_escale = Y_\n\n    x_train, x_test, y_train, y_test = train_test_split(\n        X_escale, Y_escale, test_size=0.1, random_state=random_state,shuffle =True)\n\n    estimatorNN = MLPRegressor(\n                              learning_rate = 'adaptive',\n                              random_state = random_state,\n                              verbose=False,\n                                max_iter = 200,\n                            hidden_layer_sizes = [100,50,40,30,20,10],   \n                    solver = 'adam',\n                    alpha = 0.0001,\n                    activation = 'relu'\n                            )\n\n    estimatorNN.fit(x_train,y_train)\n    \n    plt.subplots(figsize=figsize)\n    plt.plot(range(len(y_test)), y_test,'ro')\n    plt.plot(range(len(y_test)), estimatorNN.predict(x_test),'b*')\n    \n\n    plt.ylabel('Estimativa')\n    plt.title('Estimativa (*) X real (o)')\n    plt.grid(True)\n    plt.show()\n    \n    mean_error = mean_absolute_error(y_test, estimatorNN.predict(x_test))\n    print('\\nErro {}'.format(mean_error))\n    \n    mean_s_error = mean_squared_error(y_test, estimatorNN.predict(x_test))\n    print('\\nErro {}'.format(mean_s_error))\n    \n    r2 = r2_score(y_test, estimatorNN.predict(x_test)) \n    print('\\nR2 Score {}'.format(r2))\n    \n    return estimatorNN,r2","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aff2949bdf0163433a74054dad0958d245a1c08e"},"cell_type":"markdown","source":"## Treinamento de rede neural para classificação\n\nUsada ao longo do caderno para testar efeitos da redução de dimensionalidade\n\nhttp://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"},{"metadata":{"_uuid":"5eced01f10b015a9c1ec3a23447aaf196cb496a3","trusted":true},"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import classification_report\n\ndef redes_neurais_classificacao(X_, Y_, to_scale=True):\n\n    X_ = convert(X_, 'array')\n        \n    Y_ = convert(Y_, 'array')\n    \n    # Transforma Y em array 1-D\n    Y_ = np.ravel(Y_)\n    \n    if to_scale:\n        # Escala variáveis\n        scaler = MinMaxScaler(feature_range=(0, 1))\n\n        X_escale = scaler.fit_transform(X_) \n        #Y_escale = scaler.fit_transform(Y_) \n    else:\n        X_escale = X_\n\n    x_train, x_test, y_train, y_test = train_test_split(\n        X_escale, Y_, test_size=0.1, random_state=random_state,shuffle =True)\n\n    estimatorNN = MLPClassifier(\n                              learning_rate = 'adaptive',\n                              random_state = random_state,\n                              verbose=False,\n                                max_iter = 200,\n                            hidden_layer_sizes = [100,50,40,30,20,10],   \n                    solver = 'adam',\n                    alpha = 0.0001,\n                    activation = 'relu'\n                            )\n\n    estimatorNN.fit(x_train,y_train)\n    \n    plt.subplots(figsize=figsize)\n    plt.plot(range(len(y_test)), y_test,'ro')\n    plt.plot(range(len(y_test)), estimatorNN.predict(x_test),'b*')\n    \n\n    plt.ylabel('Estimativa')\n    plt.title('Estimativa (*) X real (o)')\n    plt.grid(True)\n    plt.show()\n    \n    # TN FP\n    # FN TP\n    confusion = confusion_matrix(y_test, estimatorNN.predict(x_test))\n    print(\"\\nConfusion matrix:\\n{}\".format(confusion))\n    \n    f1 = f1_score(y_test, estimatorNN.predict(x_test), average ='micro')\n    print(\"\\nf1 score: {:.2f}\".format( f1   ))\n    \n    erro = np.sum(np.abs(estimatorNN.predict(x_test)-y_test))/len(y_test)\n    print('\\nErro {}'.format(erro))\n    \n    \n    print(classification_report(y_test, estimatorNN.predict(x_test),\n        target_names=[\"Falso\", \"Positivo\"]))\n    \n    return estimatorNN,erro","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9d9992b33438f4c538e84a84bfd2e0f5205296da"},"cell_type":"markdown","source":"## Treinamento de árvore de decisão para regressão\n\nUsada ao longo do caderno para testar efeitos da redução de dimensionalidade\n\nhttp://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html"},{"metadata":{"_uuid":"07b481b67566137b174f98dfd739244708b06bb8","trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\n\ndef arvore_regressao(X_, Y_, to_scale=True):\n    \n    X_ = convert(X_, 'array')\n        \n    Y_ = convert(Y_, 'array')\n    \n    # Transforma Y em array 1-D\n    Y_ = np.ravel(Y_)\n    \n    if to_scale:\n        # Escala variáveis\n        scaler = MinMaxScaler(feature_range=(0, 1))\n\n        X_escale = scaler.fit_transform(X_) \n        #Y_escale = scaler.fit_transform(Y_) \n    else:\n        X_escale = X_\n\n    x_train, x_test, y_train, y_test = train_test_split(\n        X_escale, Y_, test_size=0.1, random_state=random_state,shuffle =True)\n    \n    estimatorTree = DecisionTreeRegressor(max_depth=5, random_state = random_state)\n    estimatorTree.fit(x_train,y_train)\n    \n    plt.subplots(figsize=figsize)\n    plt.plot(range(len(y_test)), y_test,'ro')\n    plt.plot(range(len(y_test)), estimatorTree.predict(x_test),'b*')\n    \n\n    plt.ylabel('Estimativa')\n    plt.title('Estimativa (*) X real (o)')\n    plt.grid(True)\n    plt.show()\n    \n    print('Importâncias {}'.format(estimatorTree.feature_importances_))\n    \n    mean_error = mean_absolute_error(y_test, estimatorTree.predict(x_test))\n    print('\\nErro {}'.format(mean_error))\n    \n    mean_s_error = mean_squared_error(y_test, estimatorTree.predict(x_test))\n    print('\\nErro {}'.format(mean_s_error))\n    \n    r2 = r2_score(y_test, estimatorTree.predict(x_test)) \n    print('\\nR2 Score {}'.format(r2))\n    \n    return estimatorTree,r2\n    \n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9d9992b33438f4c538e84a84bfd2e0f5205296da"},"cell_type":"markdown","source":"## Treinamento de árvore de decisão para classificação\n\nUsada ao longo do caderno para testar efeitos da redução de dimensionalidade\n\nhttp://scikit-learn.org/stable/auto_examples/tree/plot_tree_Classifier.html"},{"metadata":{"_uuid":"07b481b67566137b174f98dfd739244708b06bb8","trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ndef arvore_classificacao(X_, Y_, to_scale=True):\n    \n    X_ = convert(X_, 'array')\n        \n    Y_ = convert(Y_, 'array')\n    \n    # Transforma Y em array 1-D\n    Y_ = np.ravel(Y_)\n    \n    if to_scale:\n        # Escala variáveis\n        scaler = MinMaxScaler(feature_range=(0, 1))\n\n        X_escale = scaler.fit_transform(X_) \n        #Y_escale = scaler.fit_transform(Y_) \n    else:\n        X_escale = X_\n\n    x_train, x_test, y_train, y_test = train_test_split(\n        X_escale, Y_, test_size=0.1, random_state=random_state,shuffle =True)\n    \n    estimatorTree = DecisionTreeClassifier(max_depth=5, random_state = random_state)\n    estimatorTree.fit(x_train,y_train)\n    \n    plt.subplots(figsize=figsize)\n    plt.plot(range(len(y_test)), y_test,'ro')\n    plt.plot(range(len(y_test)), estimatorTree.predict(x_test),'b*')\n    \n\n    plt.ylabel('Estimativa')\n    plt.title('Estimativa (*) X real (o)')\n    plt.grid(True)\n    plt.show()\n\n    \n    \n    print('Importâncias {}'.format(estimatorTree.feature_importances_))\n    \n    confusion = confusion_matrix(y_test, estimatorTree.predict(x_test))\n    print(\"\\nConfusion matrix:\\n{}\".format(confusion))\n    \n    f1 = f1_score(y_test, estimatorNN.predict(x_test), average ='micro')\n    print(\"\\nf1 score: {:.2f}\".format( f1   ))\n    \n    erro = np.sum(np.abs(estimatorTree.predict(x_test)-y_test))/len(y_test)\n    print('\\nErro {}'.format(erro))\n    \n    \n    print(classification_report(y_test, estimatorTree.predict(x_test),\n        target_names=[\"Falso\", \"Positivo\"]))\n    \n    return estimatorTree,erro\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a9d0b6d33af5ef15943cdaeced9a80462aa70fd3"},"cell_type":"markdown","source":"# 2- Carga de dados\n\n\n"},{"metadata":{"_uuid":"bf6d83547c87e91c887dfd0d90feeebcc9994541"},"cell_type":"markdown","source":"## Dados de exemplo\n\nWorld happiness report (http://worldhappiness.report/).\n\nSomente variáveis numéricas"},{"metadata":{"_uuid":"a33e914fc27cbdb5d46cd13d4cf36ab031ae8c89","trusted":true},"cell_type":"code","source":"if IN_KAGGLE:\n    world_happiness = pd.read_csv(\"../input/world-happiness/2016.csv\")\nelse:\n    world_happiness = pd.read_csv(\"2016.csv\")\n\n# Conjunto completo\nworld_happiness = world_happiness.loc[:,['Country', 'Region', 'Happiness Rank', 'Happiness Score',\n       'Economy (GDP per Capita)', 'Family', 'Health (Life Expectancy)',\n       'Freedom', 'Trust (Government Corruption)', 'Generosity',\n       'Dystopia Residual']]\n\n\n\n#world_happiness = shuffle(world_happiness).reset_index(drop=True)\n\n# Conjunto resumido para treinamento de modelos\nworld_happiness_resumido = world_happiness.loc[:,[ 'Happiness Score',\n       'Economy (GDP per Capita)', 'Family', 'Health (Life Expectancy)',\n       'Freedom', 'Trust (Government Corruption)', 'Generosity']]\n\n# Cria variáveis para treinamento de modelos\n\ncolunas_fonte = [ \n       'Economy (GDP per Capita)', 'Family', 'Health (Life Expectancy)',\n       'Freedom', 'Trust (Government Corruption)', 'Generosity'\n]\n\ncolunas_objetivo = [ \n       'Happiness Score'\n]\n\nworld_happiness_resumido_X = world_happiness_resumido.loc[:,colunas_fonte] \nworld_happiness_resumido_Y = world_happiness_resumido.loc[:,colunas_objetivo]\n\n\nworld_happiness.head(35)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"648bdf45822c79f5d3ea778738fa8f204a28abca"},"cell_type":"markdown","source":"## Carrega dados para exercício\n"},{"metadata":{"_uuid":"f19b485f7b6db74b6b9a046a57ef90b2f4a2eb72"},"cell_type":"markdown","source":"Data set de gorgetas com variáveis categóricas"},{"metadata":{"trusted":true,"_uuid":"18be13ca95dc229a6244ae0045fcad0f0c84f6ae"},"cell_type":"code","source":"if IN_KAGGLE:\n    tips = pd.read_csv('../input/snstips/tips.csv')\n    if 'Unnamed: 0' in tips.columns:\n        tips.drop(['Unnamed: 0'], inplace=True, axis=1)\nelse:\n    tips = sns.load_dataset('tips')\n\ntips.head()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"71a8aef273babfb3ab3f8366694517ea9f80dcca"},"cell_type":"markdown","source":"Dados sobre tumores (somente informações numéricas)\n\nhttp://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html"},{"metadata":{"_uuid":"fbd3fcbc4e5624d48f4c41e6bf16ce31a609158d","trusted":true},"cell_type":"code","source":"from sklearn.datasets import load_breast_cancer\n\ncancer = load_breast_cancer()\n\ncancer_data = cancer['data']\n# 1 benigno, 0 maligno\ncancer_target = cancer['target']\ncancer_target_names  = cancer['target_names']\ncancer_feature_names = cancer['feature_names']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"847b2f3ad98bfc2256612d5cacfd724bd290ff09"},"cell_type":"code","source":"cancer_data_DF = pd.DataFrame(cancer_data,columns=cancer_feature_names) \ncancer_data_DF.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bd7c3e30d711a5dcd04fd474c987484bf3acd9f8"},"cell_type":"code","source":"cancer_target_DF = pd.DataFrame(cancer_target,columns=['target']) \ncancer_target_DF.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d2189a60a78dc4a43535c991ed241d7e9bd4e4fb"},"cell_type":"markdown","source":"## 10- Clusterização\n\nClusterização é o processo de formação de agrupamentos (clusters) de dados baseados em suas características, normalmente a geometria.\n\nSão algoritmos em geral não supervisionados, que recebem como parâmetro o número de clusters a serem formados e dividem os dados em agrupamentos que maximizam algum critério de separação.\n\nUma vez treinado o algoritmo, pode ser usado para estudo das características de cada cluster (ponto central, dispersão, etc) e para estimar a qual cluster novos pontos, não usados no treinamento, pertencem.\n\nSendo, em geral, não supervisionados, torna-se difícil medir a qualidade dos clusters formados. O link a seguir traz a comparação de alguns algoritmos X diferentes geometrias de pontos\n\nhttp://scikit-learn.org/stable/modules/clustering.html"},{"metadata":{"_uuid":"5f28b559e4098998fee91568a347d99b7c2d5d73"},"cell_type":"markdown","source":"## K-Means\n\nCria agrupamentos de forma a minimizar as distâncias entreo os pontos pertencentes a cada cluster e seu centroide (ponto central do cluster).\n\nAbaixo exemplo do funcionamento do algoritmo. Pontos iniciais são aleatoriamente escolhidos como centros dos clusteres e os demais são atribuídos aos custers por proximidade. Os centros dos clusters formados são usados como novos centros e nova rodada de reposicionamento ocorre. O processo continua até que a diferença de distância entre os novos centros e os centros anteriores seja menos que um limite."},{"metadata":{"trusted":true,"_uuid":"027c5d51539280a3db8f71f4d476e401351dc3c7"},"cell_type":"code","source":"# fonte Introduction to Machine Learning with Python\n# by Andreas C. Müller and Sarah Guido\n\nmglearn.plots.plot_kmeans_algorithm()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5305e83c2e33300fa86da82800c8b4b5d09d34e9","trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\nscaler = StandardScaler()\nscaler.fit(world_happiness_resumido_X)\nworld_happiness_resumido_X_scaled = scaler.transform(world_happiness_resumido_X)\n\ny_pred = KMeans(n_clusters=3, random_state=random_state).fit_predict(world_happiness_resumido_X_scaled)\n\n\nworld_happiness['Cluster'] = y_pred\n\nworld_happiness.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f07ca41b985cafdc4ddfc367a55371e2a1a34b53"},"cell_type":"markdown","source":"## Avaliação de clusterização\n\nSe houver algum critério (coluna) que possa ser usada para julgar a clusterização, a plotagem dos clusters X variável de análise é uma ótima forma de avaliação.\n\nNo problema em questão, há um critério para julgamento da clusterização: a medida de felicidade.\n\nAssim, a comparação das medidas de felicidade com os clusters formados dá uma ideia da qualidade do algoritmo.\n\nA clusterização deve ter sido capaz de separar países com níveis semelhantes de felicidade nos mesmos clusters. A questão aqui é a separação dos clusters, dado que não há critério claro de separação no índice.\n\n"},{"metadata":{"_uuid":"21544dac440b597205f11d28102ed95dc5ef4c19","trusted":true},"cell_type":"code","source":"\n\nworld_happiness.plot.scatter(x='Cluster',y='Happiness Score')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a0f6652103a063749bd66df4d73a084df39bff8"},"cell_type":"code","source":"f, (ax) = plt.subplots(1, 1, figsize=(12, 4))\nf.suptitle(' ', fontsize=14)\n\nsns.boxplot(x=\"Cluster\", y=\"Happiness Score\", data=world_happiness,  ax=ax)\nax.set_xlabel(\" \",size = 12,alpha=0.8)\nax.set_ylabel(\" \",size = 12,alpha=0.8)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b9d69ad3b486f8b9ba0dea3d7de9229e3fce5239"},"cell_type":"markdown","source":"## Avaliação de clusterização\n\nCaso não haja critério para medir a qualidade da separação, um recurso é analisar a separabilidade dos clusters pela análise de suas características"},{"metadata":{"_uuid":"db1edd3873289eec0a35f9df28e7e891bba98f34","trusted":true},"cell_type":"code","source":"from pandas.tools.plotting import parallel_coordinates\nfig, ax = plt.subplots(1, 1, figsize=(19,10))\nparallel_coordinates(frame=world_happiness, class_column='Cluster', color = ('r','g','b','y'), ax = ax, cols=['Happiness Score',\n       'Economy (GDP per Capita)', 'Family', 'Health (Life Expectancy)',\n       'Freedom', 'Trust (Government Corruption)', 'Generosity',\n       'Dystopia Residual'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"283e6a53a507ffce0b3b538d291480bc0811864e","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6269915922d8afd1d4d7a181f3952d2082439035"},"cell_type":"markdown","source":"## Avaliação de clusterização\n\n\nSilhouette score calcula a realação entre a distância das amostras para os demais pontos de seu cluster X a distância da amostra para o cluster mais próximo.\n\nVaria entre -1 (pior) e 1 (melhor)"},{"metadata":{"trusted":true,"_uuid":"154b8e4f62d6c41f90c9657bc867d2d8a0d457d7"},"cell_type":"code","source":"from sklearn.metrics.cluster import silhouette_score\n\nsilhouette_score(world_happiness_resumido_X_scaled, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"f7b63fea5bfa89b378bc1d0025591a57222f3e15"},"cell_type":"code","source":"# Código copiado de https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html#sphx-glr-auto-examples-cluster-plot-kmeans-silhouette-analysis-py\n# com alterações\nfrom sklearn.metrics import silhouette_samples\nimport matplotlib.cm as cm\n\nX = world_happiness_resumido_X_scaled\n\nrange_n_clusters = [2, 3, 4, 5, 6]\n\nfor n_clusters in range_n_clusters:\n    # Create a subplot with 1 row and 2 columns\n    fig, (ax1, ax2) = plt.subplots(1, 2)\n    fig.set_size_inches(18, 7)\n\n    # The 1st subplot is the silhouette plot\n    # The silhouette coefficient can range from -1, 1 but in this example all\n    # lie within [-0.1, 1]\n    ax1.set_xlim([-0.1, 1])\n    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n    # plots of individual clusters, to demarcate them clearly.\n    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n\n    # Initialize the clusterer with n_clusters value and a random generator\n    # seed of 10 for reproducibility.\n    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n    cluster_labels = clusterer.fit_predict(X)\n\n    # The silhouette_score gives the average value for all the samples.\n    # This gives a perspective into the density and separation of the formed\n    # clusters\n    silhouette_avg = silhouette_score(X, cluster_labels)\n    print(\"For n_clusters =\", n_clusters,\n          \"The average silhouette_score is :\", silhouette_avg)\n\n    # Compute the silhouette scores for each sample\n    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n\n    y_lower = 10\n    for i in range(n_clusters):\n        # Aggregate the silhouette scores for samples belonging to\n        # cluster i, and sort them\n        ith_cluster_silhouette_values = \\\n            sample_silhouette_values[cluster_labels == i]\n\n        ith_cluster_silhouette_values.sort()\n\n        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n        y_upper = y_lower + size_cluster_i\n\n        color = cm.nipy_spectral(float(i) / n_clusters)\n        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n                          0, ith_cluster_silhouette_values,\n                          facecolor=color, edgecolor=color, alpha=0.7)\n\n        # Label the silhouette plots with their cluster numbers at the middle\n        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n\n        # Compute the new y_lower for next plot\n        y_lower = y_upper + 10  # 10 for the 0 samples\n\n    ax1.set_title(\"The silhouette plot for the various clusters.\")\n    ax1.set_xlabel(\"The silhouette coefficient values\")\n    ax1.set_ylabel(\"Cluster label\")\n\n    # The vertical line for average silhouette score of all the values\n    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n\n    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n\n    # 2nd Plot showing the actual clusters formed\n    colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n    ax2.scatter(X[:, 0], X[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n                c=colors, edgecolor='k')\n\n    # Labeling the clusters\n    centers = clusterer.cluster_centers_\n    # Draw white circles at cluster centers\n    ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n                c=\"white\", alpha=1, s=200, edgecolor='k')\n\n    for i, c in enumerate(centers):\n        ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n                    s=50, edgecolor='k')\n\n    ax2.set_title(\"The visualization of the clustered data.\")\n    ax2.set_xlabel(\"Feature space for the 1st feature\")\n    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n\n    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n                  \"with n_clusters = %d\" % n_clusters),\n                 fontsize=14, fontweight='bold')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3212318056fa4b26d1de8dbe4dc1f1a9424f2b44"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"9713a683ffcec9737eb4fffcb13205e6c502aa00"},"cell_type":"markdown","source":"## DBSCAN\n\nDBScan procura áreas de maior e menor densidade de pontos, utilizando tal critério para formação de clusters.\n\nDiferente de KMeans, que busca proximidade, DBScan se preocupa somente com densidade, o que o torna excelente para definição de cluster irregulares.\n\nTambém diferente de KMeans, não é passada informação sobre o número de clusters, o que pode levar a resultados não desejados, como no próximo exemplo."},{"metadata":{"trusted":true,"_uuid":"b642bf040c581ded4fe28bee599ab66b07d410f6"},"cell_type":"code","source":"from sklearn.cluster import DBSCAN\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"432f23ac8d3065ad2334a3170942aa18deb0ca5d"},"cell_type":"code","source":"dbscan = DBSCAN()\nclusters = dbscan.fit_predict(world_happiness_resumido_X)\nworld_happiness['Cluster_DBSCAN'] = clusters\nworld_happiness.plot.scatter(x='Cluster_DBSCAN',y='Happiness Rank')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1616802d1ae50b02a3d505de180338f8031e9eaa"},"cell_type":"markdown","source":"#### <br>\n<font size=\"8\" color=\"red\">EXERCÍCIO</font>\n\nRealize a análise acima com clusterização KMeans para cancer_data_DF_scaled\n"},{"metadata":{"_uuid":"5305e83c2e33300fa86da82800c8b4b5d09d34e9","trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\nfrom sklearn.cluster import KMeans\nscaler = StandardScaler()\nscaler.fit(cancer_data_DF)\ncancer_data_DF_scaled = scaler.transform(cancer_data_DF)\ny_pred = KMeans(n_clusters=2, random_state=random_state).fit_predict(cancer_data_DF_scaled)\n\n\nplt.subplots(figsize=figsize)\nplt.plot(cancer_target_DF.values, y_pred,'b.')\nplt.plot(range(len(y_pred)), cancer_target_DF.values,'r.')\n\n\nplt.ylabel('Estimativa')\nplt.title('Estimativa (*) X real (o)')\nplt.grid(True)\nplt.show()\n\nconfusion = confusion_matrix(y_pred, cancer_target_DF.values)\nprint(\"\\nConfusion matrix:\\n{}\".format(confusion))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"060915bd6f225186dd76e68bdc3d3f95c69a50e3"},"cell_type":"markdown","source":"# Referências\n\nLivros usados como referência:\n\nIntroduction to Machine Learning with Python\n\nPython Data Science Handbook (https://www.oreilly.com/library/view/python-data-science/9781491912126/)\n\nVisualização:\n\nhttps://python-graph-gallery.com/\n\nhttp://www.apnorton.com/blog/2016/12/19/Visualizing-Multidimensional-Data-in-Python/\n\nhttps://towardsdatascience.com/the-art-of-effective-visualization-of-multi-dimensional-data-6c7202990c57\n\nhttps://www.oreilly.com/library/view/python-data-science/9781491912126/ch04.html\n\nhttps://matplotlib.org/mpl_toolkits/mplot3d/tutorial.html"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}