{"cells":[{"metadata":{},"cell_type":"markdown","source":"## OVERVIEW\n---\n* Exploratory Data Analysis\n* Data Cleaning and Feature selection\n* Data Sampling\n* Text Preprocessing\n    * Punctuation, Stopwords\n    * Stemming and Lemmatizing\n* Predictive Modelling\n    * Random Forest Classifier\n    * LinearSVC\n    * Logistic Regression\n    * XGBClassifier\n    * Stochastic Gradient Descent","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\nsns.set_style('whitegrid')\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk import pos_tag\nfrom nltk.corpus import wordnet\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize,sent_tokenize\n\nfrom wordcloud import WordCloud,STOPWORDS\nfrom string import punctuation\nfrom bs4 import BeautifulSoup\nimport re,string,unicodedata\nfrom tqdm import tqdm\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import MultinomialNB, BernoulliNB\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.gaussian_process import GaussianProcessClassifier\n\n\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score,plot_confusion_matrix\n\nimport keras\nfrom keras.models import Sequential, Model\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing import sequence\nfrom keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, Masking\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### GET THE DATA","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/dataisbeautiful/r_dataisbeautiful_posts.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA\n---","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#show dataframe\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#show feature data types\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#show data basic stats by over_18 feature\ndf.groupby('over_18').describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#replace the boolean values on over_18 to numerical values\ndef replace_labels(x):\n    if x == False:\n        return 0\n    else:\n        return 1\n\ndf['over_18'] = df['over_18'].apply(replace_labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### CHECK NULL VALUES","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.heatmap(df.isnull(), yticklabels=False);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### FEATURE SELECTION","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['id', 'author_flair_text', 'removed_by',\n         'total_awards_received', 'awarders', 'created_utc', 'full_link'],\n        axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#add title character length feature\ndf['title_length'] = df['title'].apply(lambda x: len(str(x)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.dropna()\nprint('DATAFRAME SHAPE: ',df.shape)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### SHOW COUNTPLOT OF OVER_18 LABELS","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(7,5))\nplt.title('COUNTPLOT')\nplt.xlabel('Class')\nplt.ylabel('Count')\nsns.barplot(x=['Under 18', 'Over 18'],y= df.over_18.value_counts(), palette='viridis');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.over_18.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### DISTRIBUTION PER TITLE CHARACTER LENGHT","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,2, figsize=(14,5))\nax[0].set_title('UNDER_18')\nax[1].set_title('OVER_18')\n\nsns.distplot(df[df['over_18']==0]['title_length'], ax=ax[0], color='steelblue');\nsns.distplot(df[df['over_18']==1]['title_length'], ax=ax[1], color='salmon');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop data which title character lenght is less than 5\ndf.drop(df[df['title_length']<5].index, inplace =True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# combine author and title\ndf['text'] = df['title'] + ' ' + df['author']\ndf.drop(['title', 'author'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.over_18.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"#### REDUCING THE DATA BY ONLY TAKING SAMPLES\n* From the distribution plot above, we can see that most of data in under_18 class have a 25-75 character length. so i'll take samples from that range.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"SAMPLES = 10000\n\nunder_18 = df[df['over_18']==0]\nunder_18 = under_18[(under_18['title_length']>25) & (under_18['title_length']<75)].sample(frac=1)\nunder_18 = under_18[:SAMPLES]\nover_18 = df[df['over_18']==1]\n\ndf_train = pd.concat([under_18, over_18])\ndf_train.index = np.arange(len(df_train))\n\n#check data frame\nprint('SHAPE: ', df_train.shape)\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX = df_train.drop(['score', 'num_comments', 'over_18', 'title_length'], axis=1)\ny = df_train['over_18']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### WORDCLOUD UNDER 18","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,10))\nwc_under18 = WordCloud(min_font_size=3, max_font_size=3000, \n                       width=1920, height=1080, \n                       stopwords=STOPWORDS).generate(str(''.join(df_train[df_train['over_18']==0]['text'])))\n\nplt.imshow(wc_under18, interpolation='bilinear');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### WORDCLOUD OVER_18","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,10))\nwc_over18 = WordCloud(min_font_size=3, max_font_size=3000, \n                       width=1920, height=1080, \n                       stopwords=STOPWORDS).generate(str(''.join(df_train[df_train['over_18']==1]['text'])))\n\nplt.imshow(wc_over18, interpolation='bilinear');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### MOST FREQUENT WORDS OF OVER 18","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"topwords_over_18 = pd.Series(wc_over18.process_text(str(''.join(df_train[df_train['over_18']==1]['text'])))).sort_values(ascending=False)[:15]\n\nplt.figure(figsize=(10,7))\nsns.barplot(topwords_over_18.values, topwords_over_18.index, palette='magma');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### MOST FREQUENT WORDS OF UNDER 18","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"topwords_under_18 = pd.Series(wc_over18.process_text(str(''.join(df_train[df_train['over_18']==0]['text'])))).sort_values(ascending=False)[:15]\n\nplt.figure(figsize=(10,7))\nsns.barplot(topwords_under_18.values, topwords_under_18.index, palette='coolwarm');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* OC, OC deleted, deleted are on top words, I'll remove them later by including them on stopwords because it may confuse the model.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### TEXT PREPROCESSING","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the stop words, punctuation, and also add the OC, deleted and OC deleted\nstop = set(stopwords.words('english'))\npunctuation = list(string.punctuation)\nstop.update(punctuation)\nremoved_topwords = ['deleted', 'oc', 'deleted oc', 'oc deleted']\nstop.update(removed_topwords)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_simple_pos(tag):\n    if tag.startswith('J'):\n        return wordnet.ADJ\n    elif tag.startswith('V'):\n        return wordnet.VERB\n    elif tag.startswith('N'):\n        return wordnet.NOUN\n    elif tag.startswith('R'):\n        return wordnet.ADV\n    else:\n        return wordnet.NOUN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lematizing function\nlemmatizer = WordNetLemmatizer()\ndef lemmatize_words(text):\n    final_text = []\n    for i in text.split():\n        if i.strip().lower() not in stop:\n            pos = pos_tag([i.strip()])\n            word = lemmatizer.lemmatize(i.strip(),get_simple_pos(pos[0][1]))\n            final_text.append(word.lower())\n    return final_text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#process the text data\nX.text = X.text.apply(lemmatize_words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.text = X.text.apply(lambda i: ' '.join(i))\n#check data\nX.text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#split the data\nX_train, X_test, y_train, y_test = train_test_split(X.text, y, test_size=0.2, random_state=101)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## PREDICTIVE MODELLING\n---","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### RANDOM FOREST CLASSIFIER","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline = Pipeline([\n    ('count', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('model', RandomForestClassifier())\n])\n\npipeline.fit(X_train, y_train)\npredictions = pipeline.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#classification report\nprint(classification_report(y_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### CONFUSION MATRIX","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(5,5))\ncon_mat = confusion_matrix(y_test, predictions)\n\nsns.heatmap(con_mat, annot=True, square=True);\n\nplt.xlabel('Y_TRUE');\nplt.ylabel('PREDICTIONS');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### LOGISTIC REGRESSION","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline = Pipeline([\n    ('count', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('model', LogisticRegression())\n])\n\npipeline.fit(X_train, y_train)\npredictions = pipeline.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#classification report\nprint(classification_report(y_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### CONFUSION MATRIX","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(5,5))\ncon_mat = confusion_matrix(y_test, predictions)\n\nsns.heatmap(con_mat, annot=True, square=True);\n\nplt.xlabel('Y_TRUE');\nplt.ylabel('PREDICTIONS');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### LINEAR SVC","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline = Pipeline([\n    ('count', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('model', LinearSVC())\n])\n\npipeline.fit(X_train, y_train)\npredictions = pipeline.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#classification report\nprint(classification_report(y_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### CONFUSION MATRIX","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(5,5))\ncon_mat = confusion_matrix(y_test, predictions)\n\nsns.heatmap(con_mat, annot=True, square=True);\n\nplt.xlabel('Y_TRUE');\nplt.ylabel('PREDICTIONS');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### XGBOOST CLASSIFIER","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline = Pipeline([\n    ('count', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('model', XGBClassifier(loss = 'deviance',\n                                    learning_rate = 0.02,\n                                    n_estimators = 10,\n                                    max_depth = 7,\n                                    random_state=101))\n])\n\npipeline.fit(X_train, y_train)\npredictions = pipeline.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#classification report\nprint(classification_report(y_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### CONFUSION MATRIX","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(5,5))\ncon_mat = confusion_matrix(y_test, predictions)\n\nsns.heatmap(con_mat, annot=True, square=True);\n\nplt.xlabel('Y_TRUE');\nplt.ylabel('PREDICTIONS');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### SGD CLASSIFIER","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline = Pipeline([\n    ('count', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('model', SGDClassifier(n_jobs=-1))\n])\n\npipeline.fit(X_train, y_train)\npredictions = pipeline.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#classification report\nprint(classification_report(y_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### CONFUSION MATRIX","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(5,5))\ncon_mat = confusion_matrix(y_test, predictions)\n\nsns.heatmap(con_mat, annot=True, square=True);\n\nplt.xlabel('Y_TRUE');\nplt.ylabel('PREDICTIONS');","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}