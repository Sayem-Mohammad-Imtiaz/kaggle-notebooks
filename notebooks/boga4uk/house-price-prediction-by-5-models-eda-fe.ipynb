{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **House Price Prediction by 5 models + EDA & FE**"},{"metadata":{},"cell_type":"markdown","source":"![](https://images.pexels.com/photos/106399/pexels-photo-106399.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=650&w=940)\n###### Thanks for the photo Binyamin Mellish: https://www.pexels.com/photo/home-real-estate-106399/"},{"metadata":{},"cell_type":"markdown","source":"### **Below screenshot explains what all headers mean.**"},{"metadata":{},"cell_type":"markdown","source":"![](https://storage.googleapis.com/kaggle-forum-message-attachments/479761/11440/Screenshot%202019-02-27%20at%205.26.24%20PM.png)\n###### Thanks for the screenshot: https://www.kaggle.com/harlfoxem/housesalesprediction/discussion/82135"},{"metadata":{},"cell_type":"markdown","source":"## **Acknowledgements**\n#### This kernel uses such good kernels:\n   - https://www.kaggle.com/vbmokin/used-cars-fe-eda-with-3d\n   - https://www.kaggle.com/vbmokin/used-cars-price-prediction-by-15-models\n   - https://www.kaggle.com/vbmokin/feature-importance-xgb-lgbm-logreg-linreg\\\n   - https://www.kaggle.com/shanroy1999/house-price-prediction-using-linear-regression\n   - https://www.kaggle.com/fulrose/copy-fix-house-price-prediction-1-2\n   - https://www.kaggle.com/sid321axn/house-price-prediction-gboosting-adaboost-etc\n   - https://www.kaggle.com/dnzcihan/house-sales-prediction-and-eda\n   - https://www.kaggle.com/darkcore/house-sales-visualization"},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"0.1\"></a>\n## **Table of Contents**\n1. [Import libraries](#1)\n2. [Download datasets](#2)\n3. [EDA](#3)\n4. [FE: building the feature importance diagrams](#4)\n  -  [LGBM](#4.1)\n  -  [XGB](#4.2)\n  -  [Logistic Regression](#4.3)\n  -  [Linear Reagression](#4.4)\n5. [Comparison of the all feature importance diagrams](#5)\n6. [Dada for modeling](#6)\n7. [Preparing to modeling](#7)\n8. [Tuning models](#8)\n  -  [Random Forest](#8.1)\n  -  [XGB](#8.2)\n  -  [LGBM](#8.3)\n  -  [BaggingRegressor](#8.4)\n  -  [ExtraTreesRegressor](#8.5)\n9. [Models comparison](#9)\n10. [Prediction](#10)"},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"1\"></a>\n## 1. Import libraries \n##### [Back to Table of Contents](#0.1)"},{"metadata":{"_uuid":"eca43558-16dd-4cec-91d3-85a9489ac759","_cell_guid":"33b58135-4270-408a-bd41-1b245407a0ce","trusted":true},"cell_type":"code","source":"import copy\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.style as style\nimport matplotlib.gridspec as gridspec\nimport seaborn as sns\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode,iplot\nfrom mpl_toolkits import mplot3d\nfrom scipy import stats\n%matplotlib inline\n\n# WordCloud\nfrom wordcloud import WordCloud\n\n# map visualization\nimport folium \nfrom folium import plugins\n\n# preprocessing\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\nimport pandas_profiling as pp\n\n# models\nfrom sklearn.linear_model import LinearRegression,LogisticRegression, SGDRegressor, RidgeCV\nfrom sklearn.svm import SVR, LinearSVR\nfrom sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor \nfrom sklearn.ensemble import BaggingRegressor\nimport sklearn.model_selection\nfrom sklearn.model_selection import cross_val_predict as cvp\nfrom sklearn import metrics\nfrom sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom scipy.stats import pearsonr\n\nimport xgboost as xgb\nimport lightgbm as lgb\n\n# model tuning\nfrom hyperopt import STATUS_OK, Trials, fmin, hp, tpe, space_eval\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"2\"></a>\n## 2. Download datasets\n##### [Back to Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['price','bedrooms','bathrooms','sqft_living','sqft_lot','floors','waterfront','view',\n            'condition','grade','sqft_above','sqft_basement','yr_built','yr_renovated',\n            'zipcode','lat','long','sqft_living15','sqft_lot15']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"57913feb-e6dc-45fd-9304-e040f639b57a","_cell_guid":"e5adc5d7-1115-4018-91d6-583c2a61b6f4","trusted":true},"cell_type":"code","source":"valid_part = 0.3\npd.set_option('max_columns',100)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"701f1e3f-7594-4ca9-888a-647ff8447bc8","_cell_guid":"2fb55532-7bc0-4053-84ba-f6d1645a766b","trusted":true},"cell_type":"code","source":"train0 = pd.read_csv('../input/housesalesprediction/kc_house_data.csv')\ntrain0 = train0[features]\ntrain0.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dfbdd757-4008-4ea6-9d90-a8c0547f57f5","_cell_guid":"ab81df9c-403b-49a5-9701-1813f7df3446","trusted":true},"cell_type":"code","source":"train0.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"18d9085b-c56c-457b-a486-668747350549","_cell_guid":"38fc197b-dcb5-4afd-9306-b8a11374ccb9","trusted":true},"cell_type":"code","source":"train0 = train0.dropna()\ntrain0.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"70c2d553-5528-4896-9ad0-63a121db9845","_cell_guid":"1ece3350-a58f-452c-ba87-e3ec0111485e","trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-fe-eda-with-3d\n# Determination categorical features\nnumerics = ['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\ncategorical_columns = []\nfeatures = train0.columns.values.tolist()\nfor col in features:\n    if train0[col].dtype in numerics: continue\n    categorical_columns.append(col)\n# Encoding categorical features\nfor col in categorical_columns:\n    if col in train0.columns:\n        le = LabelEncoder()\n        le.fit(list(train0[col].astype(str).values))\n        train0[col] = le.transform(list(train0[col].astype(str).values))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"331fde7e-0297-4449-9d13-efafba0e3860","_cell_guid":"26b43f85-1282-46e3-9f3e-a891907fec9a","trusted":true},"cell_type":"code","source":"train0['price'] = (train0['price']).astype(int)\ntrain0['floors'] = (train0['floors']).astype(int)\ntrain0['bedrooms'] = (train0['bedrooms']).astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"3\"></a>\n## 3. EDA\n##### [Back to Table of Contents](#0.1)"},{"metadata":{"_uuid":"6c0ef99b-93ff-44f5-a94d-b364889cedaf","_cell_guid":"39383a2b-19b6-4e5d-a830-d1ded957da97","trusted":true},"cell_type":"code","source":"train0.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"055f76b9-e79a-4687-8a88-330f70fba50e","_cell_guid":"2bc2cb78-d99a-457f-ae6f-3da560ce23c6","trusted":true},"cell_type":"code","source":"train0.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4992553e-9d71-4060-b1d2-6210338df4ce","_cell_guid":"c1f9e8b1-8e98-4ef5-925a-b9036451b8cb","trusted":true},"cell_type":"code","source":"train0['price'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5ef29fc1-62ce-40ec-a023-23e76dfe69d3","_cell_guid":"7dbeac4f-04ae-495b-8e71-f4c9c09aff2e","trusted":true},"cell_type":"code","source":"train0.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#Thanks to: https://www.kaggle.com/arthurtok/feature-ranking-rfe-random-forest-linear-models\nstr_list = [] # empty list to contain columns with strings (words)\nfor colname, colvalue in train0.iteritems():\n    if type(colvalue[1]) == str:\n         str_list.append(colname)\n# Get to the numeric columns by inversion            \nnum_list = train0.columns.difference(str_list) \n# Create Dataframe containing only numerical features\nhouse_num = train0[num_list]\nf, ax = plt.subplots(figsize=(16, 12))\nplt.title('Pearson Correlation of features')\n# Draw the heatmap using seaborn\nsns.heatmap(house_num.astype(float).corr(),linewidths=0.25,vmax=1.0, square=True, cmap=\"cubehelix\", linecolor='k', annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# FINDING CORRELATION\n# Thanks to: https://www.kaggle.com/sid321axn/house-price-prediction-gboosting-adaboost-etc\n# As id and date columns are not important to predict price so we are discarding it for finding correlation\nfeaturess = train0.iloc[:,3:].columns.tolist()\ntarget = train0.iloc[:,0].name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Finding Correlation of price woth other variables to see how many variables are strongly correlated with price\ncorrelations = {}\nfor f in featuress:\n    data_temp = train0[[f,target]]\n    x1 = data_temp[f].values\n    x2 = data_temp[target].values\n    key = f + ' vs ' + target\n    correlations[key] = pearsonr(x1,x2)[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Printing all the correlated features value with respect to price which is target variable\ndata_correlations = pd.DataFrame(correlations, index=['Value']).T\ndata_correlations.loc[data_correlations['Value'].abs().sort_values(ascending=False).index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(train0['yr_built'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3f1c3902-3b01-4353-ab91-af9fc29b7239","_cell_guid":"e82f0cbe-264d-4dda-8526-b1edd77a394c","trusted":true},"cell_type":"code","source":"train0.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# As zipcode is negatively correlated with sales price , so we can discard it for sales price prediction.\ndrop_columns = ['zipcode', 'view', 'waterfront', 'yr_renovated']\ntrain0 = train0.drop(columns = drop_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train0.describe(percentiles=[.01, .05, .1, .5, .9, .92, .93, .94, .96, .97, .99])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(train0['condition'] > 2.5).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(train0['grade'] == 4).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train0 = train0[(\n                (train0['price'] <= 1000000) & \n                (train0['price'] > 170000) & \n                (train0['bathrooms'] <= 4) & \n                (train0['condition'] > 2.5) & \n                (train0['grade'] != 4) &\n                (train0['sqft_lot15'] > 1300) &\n                (train0['sqft_lot15'] < 44000) &\n                (train0['sqft_lot'] > 1500) &\n                (train0['sqft_lot'] < 70000) &\n                (train0['sqft_living'] > 700) & \n                (train0['yr_built'] > 1925) & \n                (train0['bedrooms'] > 0) & \n                (train0['bedrooms'] < 7) \n                )]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train0.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bde18cf4-d8ca-4089-813f-0d076293e42f","_cell_guid":"0fcb994a-6926-4583-b1b3-df23e25a0ce7","trusted":true},"cell_type":"code","source":"pp.ProfileReport(train0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-fe-eda-with-3d\ndef plotting_3_chart(df, feature):\n    ## Importing seaborn, matplotlab and scipy modules. \n    style.use('fivethirtyeight')\n\n    ## Creating a customized chart. and giving in figsize and everything. \n    fig = plt.figure(constrained_layout=True, figsize=(15,10))\n    ## creating a grid of 3 cols and 3 rows. \n    grid = gridspec.GridSpec(ncols=3, nrows=3, figure=fig)\n    \n    ## Customizing the histogram grid. \n    ax1 = fig.add_subplot(grid[0, :2])\n    ## Set the title. \n    ax1.set_title('Histogram')\n    ## plot the histogram. \n    sns.distplot(df.loc[:,feature], norm_hist=True, ax = ax1)\n\n    # customizing the QQ_plot. \n    ax2 = fig.add_subplot(grid[1, :2])\n    ## Set the title. \n    ax2.set_title('QQ_plot')\n    ## Plotting the QQ_Plot. \n    stats.probplot(df.loc[:,feature], plot = ax2)\n\n    ## Customizing the Box Plot. \n    ax3 = fig.add_subplot(grid[:, 2])\n    ## Set title. \n    ax3.set_title('Box Plot')\n    ## Plotting the box plot. \n    sns.boxplot(df.loc[:,feature], orient='v', ax = ax3 );\n    \nplotting_3_chart(train0, 'price')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-fe-eda-with-3d\ny = np.array(train0.price)\nplt.subplot(131)\nplt.plot(range(len(y)),y,'.');plt.ylabel('price');plt.xlabel('index');\nplt.subplot(132)\nsns.boxplot(y=train0.price)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#Thanks to https://towardsdatascience.com/an-easy-introduction-to-3d-plotting-with-matplotlib-801561999725\nfig = plt.figure(figsize=(10,10))\nax = plt.axes(projection=\"3d\")\n\nz_points = train0['price']\nx_points = train0['condition']\ny_points = train0['yr_built']\nax.scatter3D(x_points, y_points, z_points, c=z_points, cmap='hsv');\n\nax.set_xlabel('condition')\nax.set_ylabel('yr_built')\nax.set_zlabel('price')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/shanroy1999/house-price-prediction-using-linear-regression\nfig=plt.figure(figsize=(19,12.5))\nax=fig.add_subplot(2,2,2, projection=\"3d\")\nax.scatter(train0['floors'],train0['bedrooms'],train0['sqft_living'],c=\"darkgreen\",alpha=.5)\nax.set(xlabel='\\nFloors',ylabel='\\nBedrooms',zlabel='\\nsqft Living')\nax.set(ylim=[0,12])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/shanroy1999/house-price-prediction-using-linear-regression\ngrpby_bedrooms_df = train0[[\"price\", \"bedrooms\"]].groupby(by = \"bedrooms\", as_index = False)\ngrpby_bedrooms_df = grpby_bedrooms_df.mean().astype(int)\ngrpby_bedrooms_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/shanroy1999/house-price-prediction-using-linear-regression\nf, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\nax1.set(yscale = \"log\")\nsns.stripplot(x = \"bedrooms\", y = \"price\", data = train0, ax = ax1, jitter=True, palette=\"Blues_d\")\nsns.barplot(x = \"bedrooms\", y = \"price\", data = grpby_bedrooms_df, ax = ax2, palette=\"Blues_d\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/fulrose/copy-fix-house-price-prediction-1-2\nhouses_map = folium.Map(location = [train0['lat'].mean(), train0['long'].mean()], zoom_start = 10)\nlat_long_data = train0[['lat', 'long']].values.tolist()\nh_cluster = folium.plugins.FastMarkerCluster(lat_long_data).add_to(houses_map)\nhouses_map","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/darkcore/house-sales-visualization\n#Create Grade Frame\ngradeframe = pd.DataFrame({\"Grades\":train0.grade.value_counts().index,\"House_Grade\":train0.grade.value_counts().values})\ngradeframe[\"Grades\"] = gradeframe[\"Grades\"].apply(lambda x : \"Grade \" + str(x))\ngradeframe.set_index(\"Grades\",inplace=True)\n#gradeframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/darkcore/house-sales-visualization\np1 = [go.Pie(labels = gradeframe.index,values = gradeframe.House_Grade,hoverinfo=\"percent+label+value\",hole=0.1,marker=dict(line=dict(color=\"#000000\",width=2)))]\nlayout4 = go.Layout(title=\"Grade Pie Chart\")\nfig4 = go.Figure(data=p1,layout=layout4)\niplot(fig4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/darkcore/house-sales-visualization\n#Create Bedrooms Frame\nbedroomsframe = pd.DataFrame({\"Bedrooms\":train0.bedrooms.value_counts().index,\"House_bedrooms\":train0.bedrooms.value_counts().values})\nbedroomsframe[\"Bedrooms\"] = bedroomsframe[\"Bedrooms\"].apply(lambda x : \"Bedrooms \" + str(x))\nbedroomsframe.set_index(\"Bedrooms\",inplace=True)\n#bedroomsframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/darkcore/house-sales-visualization\np1 = [go.Pie(labels = bedroomsframe.index,values = bedroomsframe.House_bedrooms,hoverinfo=\"percent+label+value\",hole=0.1,marker=dict(line=dict(color=\"#000000\",width=2)))]\nlayout4 = go.Layout(title=\"Bedrooms Pie Chart\")\nfig4 = go.Figure(data=p1,layout=layout4)\niplot(fig4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/darkcore/house-sales-visualization\n#Create Floors Frame\nfloorsframe = pd.DataFrame({\"Floors\":train0.floors.value_counts().index,\"House_floors\":train0.floors.value_counts().values})\nfloorsframe[\"Floors\"] = floorsframe[\"Floors\"].apply(lambda x : \"Floors \" + str(x))\nfloorsframe.set_index(\"Floors\",inplace=True)\n#floorsframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/darkcore/house-sales-visualization\np1 = [go.Pie(labels = floorsframe.index,values = floorsframe.House_floors,hoverinfo=\"percent+label+value\",hole=0.1,marker=dict(line=dict(color=\"#000000\",width=2)))]\nlayout4 = go.Layout(title=\"Floors Pie Chart\")\nfig4 = go.Figure(data=p1,layout=layout4)\niplot(fig4)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/darkcore/house-sales-visualization\n#Create Condition Frame\nconditionframe = pd.DataFrame({\"Condition\":train0.condition.value_counts().index,\"House_condition\":train0.condition.value_counts().values})\nconditionframe[\"Condition\"] = conditionframe[\"Condition\"].apply(lambda x : \"Condition \" + str(x))\nconditionframe.set_index(\"Condition\",inplace=True)\n#conditionframe","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/darkcore/house-sales-visualization\np1 = [go.Pie(labels = conditionframe.index,values = conditionframe.House_condition,hoverinfo=\"percent+label+value\",hole=0.1,marker=dict(line=dict(color=\"#000000\",width=2)))]\nlayout4 = go.Layout(title=\"Condition Pie Chart\")\nfig4 = go.Figure(data=p1,layout=layout4)\niplot(fig4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/darkcore/house-sales-visualization\nbuiltyear = pd.DataFrame({\"Years\":train0.yr_built})\nbuiltyear[\"Years\"] = builtyear[\"Years\"].apply(lambda x: \"y\" + str(x)) #I can't use wordcloud with integers so I put y on head\n#builtyear[\"Years\"].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/darkcore/house-sales-visualization\nplt.subplots(figsize=(8,8))\nwcloud  = WordCloud(background_color=\"white\",width=500,height=500).generate(\",\".join(builtyear[\"Years\"]))\nplt.imshow(wcloud)\nplt.title(\"Years for Most Built Homes\",fontsize=40)\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"4\"></a>\n## 4. FE: building the feature importance diagrams\n##### [Back to Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Clone data for FE \ntrain_fe = copy.deepcopy(train0)\ntarget_fe = train_fe['price']\ndel train_fe['price']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"4.1\"></a>\n### 4.1 LGBM "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-fe-eda-with-3d\nX = train_fe\nz = target_fe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-fe-eda-with-3d\n#%% split training set to validation set\nXtrain, Xval, Ztrain, Zval = train_test_split(X, z, test_size=0.2, random_state=0)\ntrain_set = lgb.Dataset(Xtrain, Ztrain, silent=False)\nvalid_set = lgb.Dataset(Xval, Zval, silent=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-fe-eda-with-3d\nparams = {\n        'boosting_type':'gbdt',\n        'objective': 'regression',\n        'num_leaves': 31,\n        'learning_rate': 0.05,\n        'max_depth': -1,\n        'subsample': 0.8,\n        'bagging_fraction' : 1,\n        'max_bin' : 5000 ,\n        'bagging_freq': 20,\n        'colsample_bytree': 0.6,\n        'metric': 'rmse',\n        'min_split_gain': 0.5,\n        'min_child_weight': 1,\n        'min_child_samples': 10,\n        'scale_pos_weight':1,\n        'zero_as_missing': True,\n        'seed':0,        \n    }\n\nmodelL = lgb.train(params, train_set = train_set, num_boost_round=1000,\n                   early_stopping_rounds=50,verbose_eval=10, valid_sets=valid_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-fe-eda-with-3d\nfig =  plt.figure(figsize = (15,15))\naxes = fig.add_subplot(111)\nlgb.plot_importance(modelL,ax = axes,height = 0.5)\nplt.show();plt.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-fe-eda-with-3d\nfeature_score = pd.DataFrame(train_fe.columns, columns = ['feature']) \nfeature_score['score_lgb'] = modelL.feature_importance()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"4.2\"></a>\n### 4.2 XGB\n##### [Back to Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-fe-eda-with-3d\n#%% split training set to validation set \ndata_tr  = xgb.DMatrix(Xtrain, label=Ztrain)\ndata_cv  = xgb.DMatrix(Xval   , label=Zval)\nevallist = [(data_tr, 'train'), (data_cv, 'valid')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-fe-eda-with-3d\nparms = {'max_depth':8, #maximum depth of a tree\n         'objective':'reg:squarederror',\n         'eta'      :0.3,\n         'subsample':0.8,#SGD will use this percentage of data\n         'lambda '  :4, #L2 regularization term,>1 more conservative \n         'colsample_bytree ':0.9,\n         'colsample_bylevel':1,\n         'min_child_weight': 10}\nmodelx = xgb.train(parms, data_tr, num_boost_round=200, evals = evallist,\n                  early_stopping_rounds=30, maximize=False, \n                  verbose_eval=10)\n\nprint('score = %1.5f, n_boost_round =%d.'%(modelx.best_score,modelx.best_iteration))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-fe-eda-with-3d\nfig =  plt.figure(figsize = (15,15))\naxes = fig.add_subplot(111)\nxgb.plot_importance(modelx,ax = axes,height = 0.5)\nplt.show();plt.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-fe-eda-with-3d\nfeature_score['score_xgb'] = feature_score['feature'].map(modelx.get_score(importance_type='weight'))\nfeature_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"4.3\"></a>\n### 4.3 Logistic Regression\n##### [Back to Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-fe-eda-with-3d\n# Standardization for regression model\ntrain_fe = pd.DataFrame(\n    preprocessing.MinMaxScaler().fit_transform(train_fe),\n    columns=train_fe.columns,\n    index=train_fe.index\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-fe-eda-with-3d\n# Logistic Regression\n\nlogreg = LogisticRegression()\nlogreg.fit(train_fe, target_fe)\ncoeff_logreg = pd.DataFrame(train_fe.columns.delete(0))\ncoeff_logreg.columns = ['feature']\ncoeff_logreg[\"score_logreg\"] = pd.Series(logreg.coef_[0])\ncoeff_logreg.sort_values(by='score_logreg', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-fe-eda-with-3d\n# the level of importance of features is not associated with the sign\ncoeff_logreg[\"score_logreg\"] = coeff_logreg[\"score_logreg\"].abs()\nfeature_score = pd.merge(feature_score, coeff_logreg, on='feature')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"4.4\"></a>\n### 4.4 Linear Regression\n##### [Back to Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-fe-eda-with-3d\n# Linear Regression\n\nlinreg = LinearRegression()\nlinreg.fit(train_fe, target_fe)\ncoeff_linreg = pd.DataFrame(train_fe.columns.delete(0))\ncoeff_linreg.columns = ['feature']\ncoeff_linreg[\"score_linreg\"] = pd.Series(linreg.coef_)\ncoeff_linreg.sort_values(by='score_linreg', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-fe-eda-with-3d\ncoeff_linreg[\"score_linreg\"] = coeff_linreg[\"score_linreg\"].abs()\nfeature_score = pd.merge(feature_score, coeff_linreg, on='feature')\nfeature_score = feature_score.fillna(0)\nfeature_score = feature_score.set_index('feature')\nfeature_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"5\"></a>\n## 5. Comparison of the all feature importance diagrams \n##### [Back to Table of Contents](#0.1)"},{"metadata":{},"cell_type":"markdown","source":"###### These wonderful charts are taken in [vbmokin](https://www.kaggle.com/vbmokin)\n###### Thanks to: https://www.kaggle.com/vbmokin/feature-importance-xgb-lgbm-logreg-linreg"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/feature-importance-xgb-lgbm-logreg-linreg\n# Thanks to: https://www.kaggle.com/nanomathias/feature-engineering-importance-testing\n# MinMax scale all importances\nfeature_score = pd.DataFrame(\n    preprocessing.MinMaxScaler().fit_transform(feature_score),\n    columns=feature_score.columns,\n    index=feature_score.index\n)\n\n# Create mean column\nfeature_score['mean'] = feature_score.mean(axis=1)\n\n# Plot the feature importances\nfeature_score.sort_values('mean', ascending=False).plot(kind='bar', figsize=(20, 10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_score.sort_values('mean', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Thanks to: Thanks to: https://www.kaggle.com/vbmokin/feature-importance-xgb-lgbm-logreg-linreg\n# Create total column with different weights\nfeature_score['total'] = 0.5*feature_score['score_lgb'] + 0.3*feature_score['score_xgb'] \\\n                       + 0.1*feature_score['score_logreg'] + 0.1*feature_score['score_linreg']\n\n# Plot the feature importances\nfeature_score.sort_values('total', ascending=False).plot(kind='bar', figsize=(20, 10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_score.sort_values('total', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"6\"></a>\n## 6. Dada for modeling\n##### [Back to Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-price-prediction-by-15-models\ntarget_name = 'price'\ntrain_target0 = train0[target_name]\ntrain0 = train0.drop([target_name], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Synthesis test0 from train0\ntrain0, test0, train_target0, test_target0 = train_test_split(train0, train_target0, test_size=0.2, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For boosting model\ntrain0b = train0\ntrain_target0b = train_target0\n# Synthesis valid as test for selection models\ntrainb, testb, targetb, target_testb = train_test_split(train0b, train_target0b, test_size=valid_part, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#For models from Sklearn\nscaler = StandardScaler()\ntrain0 = pd.DataFrame(scaler.fit_transform(train0), columns = train0.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train0.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Synthesis valid as test for selection models\ntrain, test, target, target_test = train_test_split(train0, train_target0, test_size=valid_part, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"7\"></a>\n## 7. Preparing to modeling\n##### [Back to Table of Contents](#0.1)"},{"metadata":{"_uuid":"97d4671e-597d-44e1-ae68-27f64c9fcd29","_cell_guid":"ce17d222-443b-48a3-aa4f-fbbe86039d36","trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-price-prediction-by-15-models\nacc_train_r2 = []\nacc_test_r2 = []\nacc_train_d = []\nacc_test_d = []\nacc_train_rmse = []\nacc_test_rmse = []","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"079ac4de-f2ee-467a-9a12-183e9dbb5747","_cell_guid":"f48efa7a-87ad-4922-a10f-1870b6bc2215","trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-price-prediction-by-15-models\ndef acc_d(y_meas, y_pred):\n    # Relative error between predicted y_pred and measured y_meas values\n    return mean_absolute_error(y_meas, y_pred)*len(y_meas)/sum(abs(y_meas))\n\ndef acc_rmse(y_meas, y_pred):\n    # RMSE between predicted y_pred and measured y_meas values\n    return (mean_squared_error(y_meas, y_pred))**0.5","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9b25162d-13f8-4091-ab2d-f9b2c361e708","_cell_guid":"9d0c274a-f805-47b8-a980-8f46b5eaeded","trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-price-prediction-by-15-models\ndef acc_boosting_model(num,model,train,test,num_iteration=0):\n    # Calculation of accuracy of boosting model by different metrics\n    \n    global acc_train_r2, acc_test_r2, acc_train_d, acc_test_d, acc_train_rmse, acc_test_rmse\n    \n    if num_iteration > 0:\n        ytrain = model.predict(train, num_iteration = num_iteration)  \n        ytest = model.predict(test, num_iteration = num_iteration)\n    else:\n        ytrain = model.predict(train)  \n        ytest = model.predict(test)\n\n    print('target = ', targetb[:5].values)\n    print('ytrain = ', ytrain[:5])\n\n    acc_train_r2_num = round(r2_score(targetb, ytrain) * 100, 2)\n    print('acc(r2_score) for train =', acc_train_r2_num)   \n    acc_train_r2.insert(num, acc_train_r2_num)\n\n    acc_train_d_num = round(acc_d(targetb, ytrain) * 100, 2)\n    print('acc(relative error) for train =', acc_train_d_num)   \n    acc_train_d.insert(num, acc_train_d_num)\n\n    acc_train_rmse_num = round(acc_rmse(targetb, ytrain) * 100, 2)\n    print('acc(rmse) for train =', acc_train_rmse_num)   \n    acc_train_rmse.insert(num, acc_train_rmse_num)\n\n    print('target_test =', target_testb[:5].values)\n    print('ytest =', ytest[:5])\n    \n    acc_test_r2_num = round(r2_score(target_testb, ytest) * 100, 2)\n    print('acc(r2_score) for test =', acc_test_r2_num)\n    acc_test_r2.insert(num, acc_test_r2_num)\n    \n    acc_test_d_num = round(acc_d(target_testb, ytest) * 100, 2)\n    print('acc(relative error) for test =', acc_test_d_num)\n    acc_test_d.insert(num, acc_test_d_num)\n    \n    acc_test_rmse_num = round(acc_rmse(target_testb, ytest) * 100, 2)\n    print('acc(rmse) for test =', acc_test_rmse_num)\n    acc_test_rmse.insert(num, acc_test_rmse_num)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7340f5a8-f04b-4f09-8655-488b4c5629fd","_cell_guid":"d79ddc1c-1799-4554-a35f-992608aba04f","trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-price-prediction-by-15-models\ndef acc_model(num,model,train,test):\n    # Calculation of accuracy of model from Sklearn by different metrics   \n  \n    global acc_train_r2, acc_test_r2, acc_train_d, acc_test_d, acc_train_rmse, acc_test_rmse\n    \n    ytrain = model.predict(train)  \n    ytest = model.predict(test)\n\n    print('target = ', target[:5].values)\n    print('ytrain = ', ytrain[:5])\n\n    acc_train_r2_num = round(r2_score(target, ytrain) * 100, 2)\n    print('acc(r2_score) for train =', acc_train_r2_num)   \n    acc_train_r2.insert(num, acc_train_r2_num)\n\n    acc_train_d_num = round(acc_d(target, ytrain) * 100, 2)\n    print('acc(relative error) for train =', acc_train_d_num)   \n    acc_train_d.insert(num, acc_train_d_num)\n\n    acc_train_rmse_num = round(acc_rmse(target, ytrain) * 100, 2)\n    print('acc(rmse) for train =', acc_train_rmse_num)   \n    acc_train_rmse.insert(num, acc_train_rmse_num)\n\n    print('target_test =', target_test[:5].values)\n    print('ytest =', ytest[:5])\n    \n    acc_test_r2_num = round(r2_score(target_test, ytest) * 100, 2)\n    print('acc(r2_score) for test =', acc_test_r2_num)\n    acc_test_r2.insert(num, acc_test_r2_num)\n    \n    acc_test_d_num = round(acc_d(target_test, ytest) * 100, 2)\n    print('acc(relative error) for test =', acc_test_d_num)\n    acc_test_d.insert(num, acc_test_d_num)\n    \n    acc_test_rmse_num = round(acc_rmse(target_test, ytest) * 100, 2)\n    print('acc(rmse) for test =', acc_test_rmse_num)\n    acc_test_rmse.insert(num, acc_test_rmse_num)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"8\"></a>\n## 8. Tuning models\n##### [Back to Table of Contents](#0.1)"},{"metadata":{"_uuid":"0801af65-818c-4465-ac24-f9c9345ace33","_cell_guid":"9a856092-1847-4bf5-8040-77caf6d393b9","trusted":true},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"8.1\"></a>\n### 8.1 Random Forest\n##### [Back to Table of Contents](#0.1)"},{"metadata":{"_uuid":"fada7c50-db25-4bc3-a211-060a22e73c44","_cell_guid":"6e862fe5-e6e9-47fd-b220-96ec769d0d2f","trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-price-prediction-by-15-models\n# Random Forest\n\n#random_forest = GridSearchCV(estimator=RandomForestRegressor(), param_grid={'n_estimators': [100, 1000]}, cv=5)\nrandom_forest = RandomForestRegressor()\nrandom_forest.fit(train, target)\nacc_model(1,random_forest,train,test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6331d5d8-5bd4-49e0-aaaa-061b77fa8c90","_cell_guid":"5351fb26-c10e-4eb5-958d-154dd257d69b","trusted":true},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"8.2\"></a>\n### 8.2 XGB\n##### [Back to Table of Contents](#0.1)"},{"metadata":{"_uuid":"84273375-e396-4643-a7e0-c96e8be2004f","_cell_guid":"7ff0656a-7b9c-4644-afb5-8734de144d8a","trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-price-prediction-by-15-models\nxgb_clf = xgb.XGBRegressor({'objective': 'reg:squarederror'}) \nparameters = {'n_estimators': [60, 100, 120, 140], \n              'learning_rate': [0.01, 0.1],\n              'max_depth': [5, 7],\n              'reg_lambda': [0.5]}\nxgb_reg = GridSearchCV(estimator=xgb_clf, param_grid=parameters, cv=5, n_jobs=-1).fit(trainb, targetb)\nprint(\"Best score: %0.3f\" % xgb_reg.best_score_)\nprint(\"Best parameters set:\", xgb_reg.best_params_)\nacc_boosting_model(2,xgb_reg,trainb,testb)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da9e4703-7337-46cf-9665-0484fe43cf8b","_cell_guid":"fad6fdbd-49af-4134-bc02-0e80664306ca","trusted":true},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"8.3\"></a>\n### 8.3 LGBM\n##### [Back to Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-price-prediction-by-15-models\n#%% split training set to validation set\nXtrain, Xval, Ztrain, Zval = train_test_split(trainb, targetb, test_size=0.2, random_state=0)\ntrain_set = lgb.Dataset(Xtrain, Ztrain, silent=False)\nvalid_set = lgb.Dataset(Xval, Zval, silent=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"def9aad9-13f6-4fa2-9eb5-2c457a056937","_cell_guid":"9d9b51ed-efa3-4902-8466-4c41dd223664","trusted":true},"cell_type":"code","source":"params = {\n        'boosting_type':'gbdt',\n        'objective': 'regression',\n        'num_leaves': 31,\n        'learning_rate': 0.01,\n        'max_depth': -1,\n        'subsample': 0.8,\n        'bagging_fraction' : 1,\n        'max_bin' : 5000 ,\n        'bagging_freq': 20,\n        'colsample_bytree': 0.6,\n        'metric': 'rmse',\n        'min_split_gain': 0.5,\n        'min_child_weight': 1,\n        'min_child_samples': 10,\n        'scale_pos_weight':1,\n        'zero_as_missing': False,\n        'seed':0,        \n    }\nmodelL = lgb.train(params, train_set = train_set, num_boost_round=10000,\n                   early_stopping_rounds=8000,verbose_eval=500, valid_sets=valid_set)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"41829f4b-08a8-407d-9850-265a12ecd791","_cell_guid":"c074d449-4a5e-4d6a-9df4-f98b5549d80b","trusted":true},"cell_type":"code","source":"acc_boosting_model(3,modelL,trainb,testb,modelL.best_iteration)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig =  plt.figure(figsize = (5,5))\naxes = fig.add_subplot(111)\nlgb.plot_importance(modelL,ax = axes,height = 0.5)\nplt.show();\nplt.close()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"8.4\"></a>\n### 8.4 Bagging Regressor\n##### [Back to Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-price-prediction-by-15-models\n# Bagging Regressor\n\nbagging = BaggingRegressor()\nbagging.fit(train, target)\nacc_model(4,bagging,train,test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"8.5\"></a>\n### 8.5 Extra Trees Regressor\n##### [Back to Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-price-prediction-by-15-models\n# Extra Trees Regressor\n\netr = ExtraTreesRegressor()\netr.fit(train, target)\nacc_model(5,etr,train,test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"9\"></a>\n### 9 Models comparison\n##### [Back to Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-price-prediction-by-15-models\nmodels = pd.DataFrame({\n    'Model': ['Random Forest', 'XGB', 'LGBM', 'BaggingRegressor', 'ExtraTreesRegressor'],\n    \n    'r2_train': acc_train_r2,\n    'r2_test': acc_test_r2,\n    'd_train': acc_train_d,\n    'd_test': acc_test_d,\n    'rmse_train': acc_train_rmse,\n    'rmse_test': acc_test_rmse\n                     })","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.display.float_format = '{:,.2f}'.format","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print('Prediction accuracy for models by R2 criterion - r2_test')\nmodels.sort_values(by=['r2_test', 'r2_train'], ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print('Prediction accuracy for models by relative error - d_test')\nmodels.sort_values(by=['d_test', 'd_train'], ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print('Prediction accuracy for models by RMSE - rmse_test')\nmodels.sort_values(by=['rmse_test', 'rmse_train'], ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-price-prediction-by-15-models\n# Plot\nplt.figure(figsize=[15,6])\nxx = models['Model']\nplt.tick_params(labelsize=14)\nplt.plot(xx, models['r2_train'], label = 'r2_train')\nplt.plot(xx, models['r2_test'], label = 'r2_test')\nplt.legend()\nplt.title('R2-criterion for 5 popular models for train and test datasets')\nplt.xlabel('Models')\nplt.ylabel('R2-criterion, %')\nplt.xticks(xx, rotation='vertical')\nplt.savefig('graph.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-price-prediction-by-15-models\n# Plot\nplt.figure(figsize=[15,6])\nxx = models['Model']\nplt.tick_params(labelsize=14)\nplt.plot(xx, models['d_train'], label = 'd_train')\nplt.plot(xx, models['d_test'], label = 'd_test')\nplt.legend()\nplt.title('Relative errors for 5 popular models for train and test datasets')\nplt.xlabel('Models')\nplt.ylabel('Relative error, %')\nplt.xticks(xx, rotation='vertical')\nplt.savefig('graph.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-price-prediction-by-15-models\n# Plot\nplt.figure(figsize=[15,6])\nxx = models['Model']\nplt.tick_params(labelsize=14)\nplt.plot(xx, models['rmse_train'], label = 'rmse_train')\nplt.plot(xx, models['rmse_test'], label = 'rmse_test')\nplt.legend()\nplt.title('RMSE for 5 popular models for train and test datasets')\nplt.xlabel('Models')\nplt.ylabel('RMSE, %')\nplt.xticks(xx, rotation='vertical')\nplt.savefig('graph.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"10\"></a>\n### 10 Prediction\n##### [Back to Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"test0.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test0.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#For models from Sklearn\ntestn = pd.DataFrame(scaler.transform(test0), columns = test0.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Linear Regression model for basic train\nlinreg.fit(train0, train_target0)\nlinreg_predict = linreg.predict(testn)\nlinreg_predict[:3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Random Forest model for basic train\nrandom_forest.fit(train0, train_target0)\nrf_predict = random_forest.predict(testn)\nrf_predict[:3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Bagging Regressor model for basic train\nbagging.fit(train0, train_target0)\nbg_predict = bagging.predict(testn)\nbg_predict[:3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# XGB Regression model for basic train\nxgb_reg.fit(train0, train_target0)\nxgb_predict = xgb_reg.predict(testn)\nxgb_predict[:3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LGB Regression model for basic train\nlgb_predict = modelL.predict(test0)\nlgb_predict[:3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extra Trees Regressor model for basic train\netr.fit(train0, train_target0)\netr_predict = etr.predict(testn)\netr_predict[:3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/dnzcihan/house-sales-prediction-and-eda\nfinal_df = test_target0.values\nfinal_df = pd.DataFrame(final_df,columns=['Real_price'])\nfinal_df['predicted_prices'] = lgb_predict.astype(int)\nfinal_df['difference'] = abs(final_df['Real_price'] - final_df['predicted_prices']).astype(int)\nfinal_df.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"mean_real_price = round(final_df['Real_price'].mean(), 0)\nmean_predicted_prices = round(final_df['predicted_prices'].mean(), 0)\nmean_difference = round(final_df['difference'].mean(), 0)\n# Create and append mean values to DataFrame \nmean_val = []\nmean_val.append(('real_price', mean_real_price))\nmean_val.append(('predicted_prices', mean_predicted_prices))\nmean_val.append(('difference', mean_difference))\npd.DataFrame(mean_val, columns = ('Name', 'Average'))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}