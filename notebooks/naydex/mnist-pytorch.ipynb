{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport torch.optim as optim\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\n\nfrom tqdm import trange","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"class MLP(nn.Module):\n    def __init__(self, h_sizes, out_size):\n        super(MLP, self).__init__()\n        self.layers = nn.ModuleList()\n        for k in range(len(h_sizes) - 1):\n            self.layers.append(nn.Linear(h_sizes[k], h_sizes[k+1]).cuda())\n\n        self.out = nn.Linear(h_sizes[-1], out_size).cuda()\n        self.logsoftmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        for layer in self.layers:\n            x = F.relu(layer(x))\n        output = self.logsoftmax(self.out(x))\n        return output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pd.read_csv(\"/kaggle/input/mnist-in-csv/mnist_train.csv\")\nX_test = pd.read_csv(\"/kaggle/input/mnist-in-csv/mnist_test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(X.iloc[1,1:].to_numpy().reshape((28, 28)))\nplt.title(f\"{X.iloc[1,0]} sample\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 60_000\nN_EPOCH = 100\nN_BATCHES = X.shape[0] // BATCH_SIZE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = MLP((28 * 28, 1024, 1024), 10)\nloss = nn.NLLLoss()\nopt = optim.SGD(model.parameters(), lr=1e-3)\n\nr = trange(N_EPOCH * N_BATCHES)\nlosses = []\naccuracies = []\nfor j in r:\n    i = 0\n    model.train()\n    batch_data = X.iloc[i*BATCH_SIZE:(i+1)*BATCH_SIZE,1:].to_numpy().reshape((-1, 28 * 28))\n    batch_labels = X.iloc[i*BATCH_SIZE:(i+1)*BATCH_SIZE,0].to_numpy()\n\n    batch_data = torch.Tensor(batch_data).cuda()\n    batch_labels = torch.Tensor(batch_labels).to(torch.int64).cuda()\n\n    preds = model(batch_data)\n    loss_val = loss(preds, batch_labels)\n    loss_val.backward()\n    opt.step()\n\n    model.eval()\n    test_data = torch.Tensor(X_test.iloc[:, 1:].to_numpy().reshape((-1, 28 * 28))).cuda()\n    test_labels = torch.Tensor(X_test.iloc[:,0].to_numpy()).cuda()\n\n    with torch.no_grad():\n        preds = model(test_data).argmax(dim=1)\n        acc = float(sum(preds == test_labels)) / X_test.shape[0]\n\n    losses.append(loss_val.item())\n    accuracies.append(acc * 100)\n    r.set_description(f\"loss: {loss_val.item():.2f}\\t acc: {acc*100:.2f}%\\t\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(range(N_EPOCH), losses)\nplt.plot(range(N_EPOCH), accuracies)\nplt.title(\"Training loss and testing accuracy over the training\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On the previous plot we can see that the convergence seems to be happening at epoch nÂ°20. We are going to see more in depth over a random sample."},{"metadata":{"trusted":true},"cell_type":"code","source":"rand_idx = np.random.randint(X_test.shape[0])\nsample = X_test.iloc[rand_idx, 1:].to_numpy()\nlabel = X_test.iloc[rand_idx, 0]\n\nmodel.eval()\nwith torch.no_grad():\n    sample_tensor = torch.Tensor([sample]).cuda()\n    preds = model(sample_tensor)[0]\n\nplt.imshow(sample.reshape((28, 28)))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = preds.exp().cpu().numpy()\nsns.barplot(list(range(10)), preds)\nplt.title(f\"Probabilities for sample of label {label}\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = preds.argmax()\nf\"Predicted label {prediction} for label {label}\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weights = model.layers[0].weight.detach().cpu().numpy()\nplt.imshow(weights)\nplt.title(\"Weights of the first linear layer\")\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}