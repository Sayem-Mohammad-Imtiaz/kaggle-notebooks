{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Import dataset\ndataset = pd.read_csv(\"../input/sms-spam-collection-dataset/spam.csv\", encoding = \"latin-1\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = dataset.drop(columns = [\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = dataset.rename(columns = {\"v1\" : \"target\", \"v2\" : \"sms\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset[\"length\"] = dataset[\"sms\"].str.len()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.countplot(data = dataset, x=\"target\")\nprint(dataset[\"target\"].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Spam mails tend to have more lengthy messages!\nplt.figure(figsize=(15,7))\nplt.xlim(0,200)\nsns.distplot(dataset.loc[dataset[\"target\"] == \"ham\"][\"length\"], \n                     kde_kws={\"label\": \"Ham\"}, bins = 100)\nsns.distplot(dataset.loc[dataset[\"target\"] == \"spam\"][\"length\"], \n                     kde_kws={\"label\": \"Spam\"}, bins = 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create copy dataset to manipulate\nmanip_dataset = dataset.copy()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"manip_dataset.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" manip_dataset[\"sms\"][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport nltk\nnltk.download('stopwords') #download non relevant words\nfrom nltk.corpus import stopwords\nfrom nltk.stem.snowball import SnowballStemmer # Stemming is taking the root of every word (containing what it means)\nsms = [] # will contain all the different reviews cleaned\nfor i in range(0, len(dataset)):\n    string = re.sub(\"[^a-zA-Z]\", \" \", manip_dataset[\"sms\"][i]) # replaces anything NOT in a-z or A-Z by a space, in the variable \n    string = string.lower()\n    string = string.split()\n    stemmer = SnowballStemmer(\"english\")\n    all_stopwords = stopwords.words(\"english\")\n    #if the word is not in the stopwords vocabulary then go ahead with the word iter and stem it\n    string = [stemmer.stem(word) for word in string if not word in set(all_stopwords)]\n    string = ' '.join(string) # joins the words again with a space in between them\n    sms.append(string) # add the review to our corpus","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(sms)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# See the first 5 stemmed messages\nsms[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(0,len(sms)):\n    manip_dataset[\"sms\"][i] = sms[i] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"manip_dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"manip_dataset[\"after_length\"] = manip_dataset[\"sms\"].str.len()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"manip_dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Length distributions more discrete in initial length, so i will not use the after_length attr\nplt.figure(figsize=(15,7))\nplt.xlim(0,200)\nsns.distplot(manip_dataset.loc[manip_dataset[\"target\"] == \"ham\"][\"after_length\"], \n                     kde_kws={\"label\": \"Ham\"}, bins = 100)\nsns.distplot(manip_dataset.loc[manip_dataset[\"target\"] == \"spam\"][\"after_length\"], \n                     kde_kws={\"label\": \"Spam\"}, bins = 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"manip_dataset = manip_dataset.drop(columns = [\"after_length\"])\nmanip_dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reindexing our columns\nmanip_dataset = manip_dataset.reindex(columns = [\"sms\", \"length\", \"target\"])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"manip_dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encoding the target values\ntarget_encoder = LabelEncoder()\nmanip_dataset[\"target\"] = target_encoder.fit_transform(manip_dataset[\"target\"])\nmanip_dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = manip_dataset.drop(columns = [\"target\"])\ny = manip_dataset[\"target\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(max_features = 4001) # the one is because i'll use the last one for the length","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create our vectors for our bag-of-words model\nX_sms = cv.fit_transform(sms).toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(X_sms[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_sms","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Assign the last value of each vector to the length feature\nfor i in range(0,len(X_sms)):\n    X_sms[i][-1] = X[\"length\"][i]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(X_sms)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display first five vectors\nX_sms[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split our data to train/test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_sms, y, test_size=0.20, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create function running models\ndef run_model(model, X_train, y_train, X_test, y_test):\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n    print(\"The confusion matrix is : \\n\", confusion_matrix(y_test, y_pred), \"\\n\")\n    print(\"The accuracy score is : \\n\",accuracy_score(y_test, y_pred), \"\\n\")\n    print(\"The precision is : \\n\",precision_score(y_test,y_pred), \"\\n\")\n    print(\"The recall is : \\n\",recall_score(y_test,y_pred), \"\\n\")\n    print(\"The f1 score is : \\n\",f1_score(y_test,y_pred), \"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nrun_model(GaussianNB(),X_train, y_train, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nrun_model(AdaBoostClassifier(),X_train, y_train, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nrun_model(GradientBoostingClassifier(),X_train, y_train, X_test, y_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrun_model(RandomForestClassifier(),X_train, y_train, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1=RandomForestClassifier()\nmodel1.fit(X_train, y_train)\ny_pred = model1.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" ex='Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate) T&Cs apply 08452810075over18s'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ex","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stemming is taking the root of every word (containing what it means)\nsms_ex = [] # will contain all the different reviews cleaned\n\nstring = re.sub(\"[^a-zA-Z]\", \" \", ex) # replaces anything NOT in a-z or A-Z by a space, in the variable \nstring = string.lower()\nstring = string.split()\nstemmer = SnowballStemmer(\"english\")\nall_stopwords = stopwords.words(\"english\")\n#if the word is not in the stopwords vocabulary then go ahead with the word iter and stem it\nstring = [stemmer.stem(word) for word in string if not word in set(all_stopwords)]\nstring = ' '.join(string) # joins the words again with a space in between them\nsms_ex.append(string) # add the review to our corpus","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_ex","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(sms_ex)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_copy=sms.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_copy.append(sms_ex)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_copy[len(sms_copy)-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(sms_copy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(sms)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\ncv_new = CountVectorizer(max_features = 4001) # the one is because i'll use the last one for the length","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_sms_new = cv_new.fit_transform(sms).toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_sms_new","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(0,len(X_sms)):\n    X_sms_new[i][-1] = X[\"length\"][i]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(X_sms_new[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction= model1.predict(X_sms_new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction[len(prediction)-1]","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}