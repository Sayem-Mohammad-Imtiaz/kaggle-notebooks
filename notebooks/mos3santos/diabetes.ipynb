{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">  Análise Exploratória dos Dado"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/pima-indians-diabetes-database/diabetes.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info(verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.dtypes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calcule o valor médio do IMC\nmedian_bmi = df['BMI'].median()\n# Substitua-o na coluna de IMC do\n# conjunto de dados onde os valores são 0\ndf['BMI'] = df['BMI'].replace(\n    to_replace=0, value=median_bmi)\n\nmedian_bloodp = df['BloodPressure'].median()\n# Substitua-o na coluna BloodP do\n# conjunto de dados onde os valores são 0\ndf['BloodPressure'] = df['BloodPressure'].replace(\n    to_replace=0, value=median_bloodp)\n\n# Calcule o valor mediano para PlGlcConc\nmedian_plglcconc = df['Glucose'].median()\n# Substitua-o na coluna PlGlcConc do\n# conjunto de dados onde os valores são 0\ndf['Glucose'] = df['Glucose'].replace(\n    to_replace=0, value=median_plglcconc)\n\n# Calcule o valor médio para SkinThick\nmedian_skinthick = df['SkinThickness'].median()\n# Substitua-o na coluna SkinThick do\n# conjunto de dados onde os valores são 0\ndf['SkinThickness'] = df['SkinThickness'].replace(\n    to_replace=0, value=median_skinthick)\n\n# Calcule o valor médio para SkinThick\nmedian_skinthick = df['Insulin'].median()\n# Substitua-o na coluna SkinThick do\n# conjunto de dados onde os valores são 0\ndf['Insulin'] = df['Insulin'].replace(\n    to_replace=0, value=median_skinthick)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Outcome'].value_counts().plot.bar();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Feature Engineering¶¶\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def set_bmi(row):\n    if row[\"BMI\"] < 18.5:\n        return \"Under\"\n    elif row[\"BMI\"] >= 18.5 and row[\"BMI\"] <= 24.9:\n        return \"Healthy\"\n    elif row[\"BMI\"] >= 25 and row[\"BMI\"] <= 29.9:\n        return \"Over\"\n    elif row[\"BMI\"] >= 30:\n        return \"Obese\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.assign(BM_DESC=df.apply(set_bmi, axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Característica 2: Faixa indicativa de insulina Se o nível de insulina (insulina sérica de 2 horas (mu U / ml)) for> = 16 e <= 166, então é uma faixa normal, caso contrário, é considerada anormal"},{"metadata":{"trusted":true},"cell_type":"code","source":"def set_insulin(row):\n    if row[\"Insulin\"] >= 16 and row[\"Insulin\"] <= 166:\n        return \"Normal\"\n    else:\n        return \"Abnormal\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.assign(INSULIN_DESC=df.apply(set_insulin, axis=1))\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Característica de segregação e variável de destino¶\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=pd.get_dummies(df)\ncols_drop=['Outcome','BM_DESC_Under']\nX=X.drop(cols_drop,axis=1)\n\ny = df['Outcome']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Divisão de teste de trem¶\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"y.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,stratify=y, random_state = 1234)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"Normalização de Dados\n\nUsei a normalização Z-score. Os escores Z são valores de dados transformados linearmente com uma média de zero e um desvio padrão de 1. Os escores Z também são conhecidos como escores padronizados; são pontuações (ou valores de dados) que receberam um padrão comum.\n\nSe a média populacional e o desvio padrão populacional forem conhecidos, a pontuação padrão de uma pontuação bruta x [1] é calculada como"},{"metadata":{"trusted":true},"cell_type":"code","source":"min_train = X_train.min()\nrange_train = (X_train - min_train).max()\nX_train = (X_train - min_train)/range_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"min_test = X_test.min()\nrange_test = (X_test - min_test).max()\nX_test = (X_test - min_test)/range_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Modelo teste\n"},{"metadata":{},"cell_type":"markdown","source":"Random Forest:¶\n\nA random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting.RandomForestClassifie"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Model=RandomForestClassifier(max_depth=2)\nModel.fit(X_train,y_train)\ny_pred=Model.predict(X_test)\nprint(classification_report(y_pred, y_test))\nprint(confusion_matrix(y_pred,y_test))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Pontuação de precisão\nprint('accuracy is ',accuracy_score(y_pred,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fazendo a matriz de confusão e o relatório de classificação\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(data =  cm , annot = True , cmap = \"Blues\" , linewidths= 1 , linecolor= \"black\")\n\nreport = classification_report(y_test , y_pred)\nprint(report)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclui-se**\n\nUma floresta aleatória é um metaestimador que ajusta uma série de classificadores de árvore de decisão em várias subamostras do conjunto de dados e usa média para melhorar a a precisão da previsão para controlar o sobreajuste.RandomForestClassifie. O tamanho da subamostra é sempre o mesmo tal qual o tamanho da amostra de entrada original.Assim Matriz de Confusão, uma ferramenta muito usada para avaliações de modelos de classificação em Aprendizado de Máquina (mais comumente chamado de Machine Learning).Para termos dados de exemplo, imagine que eu tivesse um modelo que, dada as características fisiológicas de uma paciente, dissesse que a mesma está em diabetes ou não. Porém, para o nosso contexto, eu só trarei uma lista com os dados reais, e uma lista de dados preditos pelo modelo, ambos dados fake(falsos)."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}