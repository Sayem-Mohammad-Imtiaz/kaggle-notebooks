{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import svm\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestRegressor\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\npaths=[]\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        path = os.path.join(dirname, filename)\n        paths.append(path)\n        print(path)\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(paths[0])\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data.drop(0, axis=0, inplace=True) Deleting first because it has maximum values, probably initial malfunction\ndata['SST'].replace(-99.9, data['SST'].values.mean(), inplace=True) # I am gonna predict temp, so i need to make sure that there won't be any -99 suddenly","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['SST'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.hist(figsize=(10,10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"figure = plt.figure(figsize=(10,8))\ncorr_matrix = data.corr()\nplt.matshow(corr_matrix, fignum=figure.number)\nplt.xticks(np.arange(6), data.columns[1:])\nplt.yticks(np.arange(6), data.columns[1:])\nlegend=plt.colorbar()\nlegend.ax.tick_params(labelsize=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix.style.background_gradient(cmap='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30,10), dpi=96)\n# input comes every 30 minutes, so for one year we will have 17520 records\nyear=17520\nmonth = 1440\nday = 48\nx_temp = data.iloc[:year,0]\ny_temp = data.iloc[:year,6]\nx=x_temp[23::day]\ny=y_temp[23::day]\nplt.plot(x,y)\n\nstep = month\nxs = x[::31]\nplt.xticks(xs)\nplt.gca().set(title='temperature at every day in 2018 gathered at 12:00',xlabel='date', ylabel='temperature')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We gonna train on a dates from one year"},{"metadata":{"trusted":true},"cell_type":"code","source":"i = 1 # as 01.01.2018 01:00\nX_tmp = data.iloc[:17520,0]\nX_tmp = X_tmp[1::2]\nXs = [i for i in range(len(X_tmp))]\nX = [Xs]\n\n\n# Adjusting y\n\ny_tmp = data.iloc[:17520,6]\ny_tmp = y_tmp[1::2]\nys = [i for i in y_tmp]\ny = [ys]\n\n\n\nprint(f\"Oryginal data: {data['Date/Time'][1:10:2]} : {data['SST'][1:10:2]} \\n\\n\")\nprint(f\"Fromated data: {X[0][:5]} : {y[0][:5]}\")\n#everything is correct","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X[0], y[0], test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LinearRegression()\nX_train_tmp = np.asarray(X_train).reshape(-1,1)\ny_train_tmp = np.asarray(y_train).reshape(-1,1)\nX_train_tmp = np.asarray(X_test).reshape(-1,1)\ny_train_tmp = np.asarray(y_test).reshape(-1,1)\n\nmodel.fit(X_train_tmp,y_train_tmp)\nmodel.score(X_train_tmp, y_train_tmp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2 = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial')\n\nlab_encoder = LabelEncoder()\nX_train_tmp = lab_encoder.fit_transform(X_train)\ny_train_tmp = lab_encoder.fit_transform(y_train)\nX_train_tmp = np.asarray(X_train_tmp).reshape(-1,1)\n\n\nmodel2.fit(X_train_tmp,y_train_tmp)\nmodel2.score(X_train_tmp, y_train_tmp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model3 = svm.SVC(gamma='scale')\nmodel3.fit(X_train_tmp,y_train_tmp)\nmodel3.score(X_train_tmp, y_train_tmp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"well...shit\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}