{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import svm\nfrom sklearn import metrics\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.impute import KNNImputer\nimport matplotlib.pylab as pylab\nimport warnings\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import PCA\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom imblearn.over_sampling import SMOTE","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=pd.read_csv('../input/credit-card-customers/BankChurners.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#First few rows of the dataframe\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get all types of colums\ndata.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Can Statistic data on each column to understand the data better\ndata.describe(include='all')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# View all dublicate row\ndata.duplicated().sum()\ndata[data.duplicated()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove uneccecry colums\ndata = data.drop(columns=['CLIENTNUM','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1', 'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Finding number of null values in individual column\ndata.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nullTable=round((data.isnull().sum()/data.shape[0])*100,2)\nnullValueCols=pd.DataFrame(nullTable,columns=['Missing Value %'])\nnullValueCols.reset_index(inplace=True)\nnullValueCols.rename(columns={'index': 'Column Name'},inplace=True)\nnullValueCols[nullValueCols['Missing Value %']!=0]\nprint(nullTable)\n\nsns.heatmap(data.isnull(), yticklabels=False, cbar=False, cmap='plasma')\nplt.title(\"Heat map plotting the missing values in the columns\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NewNumeric=data[['Customer_Age','Months_on_book','Total_Relationship_Count','Months_Inactive_12_mon', 'Contacts_Count_12_mon']]\nNewNumericMelt=NewNumeric.melt()\nplt.figure(figsize=(15,10))\nplt.title(\"Boxplots for Numerical variables\")\nbp=sns.boxplot(x='variable',y='value',data=NewNumericMelt)\nbp.set_xticklabels(bp.get_xticklabels(),rotation=90)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NewNumeric=data[['Total_Revolving_Bal']]\nNewNumericMelt=NewNumeric.melt()\nplt.figure(figsize=(15,10))\nplt.title(\"Boxplots for Numerical variables\")\nbp=sns.boxplot(x='variable',y='value',data=NewNumericMelt)\nbp.set_xticklabels(bp.get_xticklabels(),rotation=90)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NewNumeric=data[['Credit_Limit']]\nNewNumericMelt=NewNumeric.melt()\nplt.figure(figsize=(15,10))\nplt.title(\"Boxplots for Numerical variables\")\nbp=sns.boxplot(x='variable',y='value',data=NewNumericMelt)\nbp.set_xticklabels(bp.get_xticklabels(),rotation=90)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NewNumeric=data[['Avg_Open_To_Buy']]\nNewNumericMelt=NewNumeric.melt()\nplt.figure(figsize=(15,10))\nplt.title(\"Boxplots for Numerical variables\")\nbp=sns.boxplot(x='variable',y='value',data=NewNumericMelt)\nbp.set_xticklabels(bp.get_xticklabels(),rotation=90)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NewNumeric=data[['Total_Amt_Chng_Q4_Q1']]\nNewNumericMelt=NewNumeric.melt()\nplt.figure(figsize=(15,10))\nplt.title(\"Boxplots for Numerical variables\")\nbp=sns.boxplot(x='variable',y='value',data=NewNumericMelt)\nbp.set_xticklabels(bp.get_xticklabels(),rotation=90)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NewNumeric=data[['Total_Trans_Amt']]\nNewNumericMelt=NewNumeric.melt()\nplt.figure(figsize=(15,10))\nplt.title(\"Boxplots for Numerical variables\")\nbp=sns.boxplot(x='variable',y='value',data=NewNumericMelt)\nbp.set_xticklabels(bp.get_xticklabels(),rotation=90)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NewNumeric=data[['Total_Trans_Ct']]\nNewNumericMelt=NewNumeric.mdrlt()\nplt.figure(figsize=(15,10))\nplt.title(\"Boxplots for Numerical variables\")\nbp=sns.boxplot(x='variable',y='value',data=NewNumericMelt)\nbp.set_xticklabels(bp.get_xticklabels(),rotation=90)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NewNumeric=data[['Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio']]\nNewNumericMelt=NewNumeric.melt()\nplt.figure(figsize=(15,10))\nplt.title(\"Boxplots for Numerical variables\")\nbp=sns.boxplot(x='variable',y='value',data=NewNumericMelt)\nbp.set_xticklabels(bp.get_xticklabels(),rotation=90)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (10, 8))\nAttrplot=sns.countplot(x = 'Gender', data = data.sample(n=1000))\nplt.title(\"Countplot for last_evaluation Column\")\nplt.show()\n\nplt.figure(figsize = (10, 8))\nAttrplot=sns.countplot(x = 'Education_Level', data = data.sample(n=1000))\nplt.title(\"Countplot for last_evaluation Column\")\nplt.show()\n\nplt.figure(figsize = (10, 8))\nAttrplot=sns.countplot(x = 'Marital_Status', data = data.sample(n=1000))\nplt.title(\"Countplot for last_evaluation Column\")\nplt.show()\n\nplt.figure(figsize = (10, 8))\nAttrplot=sns.countplot(x = 'Income_Category', data = data.sample(n=1000))\nplt.title(\"Countplot for last_evaluation Column\")\nplt.show()\n\nplt.figure(figsize = (10, 8))\nAttrplot=sns.countplot(x = 'Card_Category', data = data.sample(n=1000))\nplt.title(\"Countplot for last_evaluation Column\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (10, 8))\nAttrplot=sns.countplot(x = 'Attrition_Flag', data = data.sample(n=1000))\nplt.title(\"Countplot for last_evaluation Column\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert 'Left' for 1 and 'Employed' for 0\nY = np.where(data['Attrition_Flag'].values == 'Attrited Customer', 1, 0)\n\n# dropping the target column and create the matrix of features\nX = data.drop(['Attrition_Flag'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = pd.get_dummies(X, drop_first=True)\nX.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_cols=['Customer_Age','Months_on_book','Total_Relationship_Count','Months_Inactive_12_mon', 'Contacts_Count_12_mon', 'Total_Revolving_Bal', 'Credit_Limit', 'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt', 'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio']\nscaler = StandardScaler()\nX[num_cols] = scaler.fit_transform(X[num_cols])\nX.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train test split\n\n\ny_left = Y[Y == 1]\nx_left = X[Y == 1]\ny_stay = Y[Y == 0]\nx_stay = X[Y == 0]\n\nx_train_left, x_test_left, y_train_left, y_test_left = train_test_split(x_left,y_left , test_size = .25, random_state=45)\nx_train_stay, x_test_stay, y_train_stay, y_test_stay = train_test_split(x_stay,y_stay , test_size = .25, random_state=45)\nx_train = np.concatenate((x_train_left, x_train_stay), axis=0)\ny_train = np.concatenate((y_train_left, y_train_stay), axis=0)\nx_test = np.concatenate((x_test_left, x_test_stay), axis=0)\ny_test = np.concatenate((y_test_left, y_test_stay), axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(y_train == 0).sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(y_train == 1).sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oversample = SMOTE()\nx_train, y_train = oversample.fit_resample(x_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dt=DecisionTreeClassifier()\nparam_grid={\n    'criterion':['gini','entropy'],\n    'max_depth':np.arange(4,20,1),\n    'min_samples_split':np.arange(0.001,0.1,0.01),\n    'max_features':['log2','sqrt','auto'],\n    'min_weight_fraction_leaf':np.arange(0.001,0.25,0.05)\n}\nr_search=RandomizedSearchCV(dt,param_distributions=param_grid,n_iter=10,verbose=1)\nr_search.fit(x_train,y_train)\nm_best = r_search.best_estimator_\nrf_predictions_val_y=m_best.predict(x_test)\nprint(classification_report(y_test,rf_predictions_val_y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param_grid = {'criterion':['gini','entropy'],\n    'max_depth':np.arange(4,20,1),\n    'min_samples_split':np.arange(0.001,0.1,0.01),\n    'max_features':['log2','sqrt','auto'],\n    'min_weight_fraction_leaf':np.arange(0.001,0.25,0.05),\n    'n_estimators': np.arange(50,500,50)}\nrandom_forest=RandomForestClassifier()\ngrid_search=RandomizedSearchCV(estimator=random_forest,param_distributions=param_grid,n_iter=50,verbose=1)\ngrid_search.fit(x_train,y_train)\ngrid_search.best_params_#getting best parameters of grid search\nm_best = grid_search.best_estimator_\nrf_predictions_val_y=m_best.predict(x_test)\nprint(classification_report(y_test,rf_predictions_val_y))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = RandomForestClassifier(max_depth=18, random_state=45)\nclf.fit(x_train, y_train)\nrf_predictions_val_y=clf.predict(x_test)\nprint(classification_report(y_test,rf_predictions_val_y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param_grid = {'learning_rate': np.arange(0.1,1,0.05),\n 'max_depth': np.arange(1,15,2),\n 'max_features': ['auto', 'sqrt', 'log2'],\n 'max_depth': np.arange(15,20,1),\n 'n_estimators': np.arange(80,150,20)}\ngradient_boosting=GradientBoostingClassifier()\ngrid_search=RandomizedSearchCV(estimator=gradient_boosting,param_distributions=param_grid,n_iter=50,verbose=1)\ngrid_search.fit(x_train,y_train)\ngrid_search.best_params_#getting best parameters of grid search\nm_best = grid_search.best_estimator_\nrf_predictions_val_y=m_best.predict(x_test)\nprint(classification_report(y_test,rf_predictions_val_y))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1, max_depth=1, random_state=45)\nclf.fit(x_train, y_train)\nrf_predictions_val_y=clf.predict(x_test)\nprint(classification_report(y_test,rf_predictions_val_y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}