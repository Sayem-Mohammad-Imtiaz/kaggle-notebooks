{"cells":[{"metadata":{},"cell_type":"markdown","source":"Since the dataset is pretty small and the attributes or columns do not make much sense i would not be making use of visualization plots . \n\nWhat is being done in this notebook : \n\n- Reading in the csv file \n\n- Removing the unknown and ID columns \n\n- Splitting the attributes into 3 groups : \n          - mean columns ( radius_mean, texture_mean etc )\n          - se columns (area_se , perimeter_se etc )  \n          - worst columns (area_worst,perimeter_worst etc )\n          \n - Using **Variance Inflation Factor** (Using methods) to check the collinearity of columns and removing the ones that are not needed . \n \n - Splitting the dataset using Train-Test split \n \n - Running/fitting the train models and predicting the target variable using \n             \n             Random Forest \n             SVM \n             Logistic Regression\n             Decision Trees Classifier \n             \n  - Checking the classification report for each of the above models \n  \n  - Checking the confusion matrix for each of the above models \n \n          "},{"metadata":{"_cell_guid":"f3440bbb-f887-4a41-b4bb-96720efcdb0c","_uuid":"6a7b209442b7d18390950d51871cc1bb30d4c9d7"},"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n\ndf = pd.read_csv(\"../input/data.csv\")\n# Any results you write to the current directory are saved as output.","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"d88b8150-67bb-4f29-a7c3-87e284a0e88d","_uuid":"7d916039cb9e6abec830b2a3f5a0de37fa61dded"},"source":"df.info()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"9422b5e8-1406-48b0-8c5d-233d7ba37bfd","_uuid":"4e7bf7d15c15f8938e8e7e12a226d3ecb5d2873e"},"source":"list = ['Unnamed: 32','id']\n\ndf.drop(list,axis=1,inplace=True)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"67f80e56-9205-4a21-96e3-09956cb14f3a","_uuid":"2d749e73323e6429eb942302bd1be1bbd0e87c54"},"source":"df.head()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"ee384e6a-7404-40e2-816e-8aace1ccd933","_uuid":"801742b8323a007884efc46eda3dccc711f17162"},"source":"X = df.drop(\"diagnosis\",axis=1)\ny = df['diagnosis']","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"ddeebbe8-ed2a-46a0-884e-db2fd40b4f8f","_uuid":"2abb2c65da5f1ca2302f63e2e0e99fd037235755"},"source":"diag_map = {\"M\":1,\"B\":0}\n\ndf['diagnosis'] = df['diagnosis'].map(diag_map)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"26da4f1d-ce44-4494-aa53-eb2e490e1479","_uuid":"8884895bb170b5ea4694dcc2b78cc9faae222827"},"source":"df.head()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"09787931-313c-4086-9612-301c5408f798","_uuid":"83d9d06c5b424a6f8254caecd295a212cf5ae301"},"source":"mean_feats = [i for i in df.columns if i.endswith(\"mean\")]\nse_feats = [i for i in df.columns if i.endswith(\"se\")]\nworst_feats = [i for i in df.columns if i.endswith(\"worst\")]","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"83c7053d-16cd-4f5d-b905-de4e7c2ccd7e","_uuid":"7beb070a763f5163eef9bad657a6995c3e09b137"},"source":"# from sklearn.preprocessing import StandardScaler\n# scaler = StandardScaler()\n# X[mean_feats] = scaler.fit_transform(X[mean_feats].as_matrix())","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"49d068ef-95e0-4a9d-9e2f-2c8f24d34193","_uuid":"eae9caa718b172a54da8580bf42aa3cd4d0b0dfc"},"source":"from sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.preprocessing import Imputer\n\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nclass ReduceVIF(BaseEstimator, TransformerMixin):\n    def __init__(self, thresh=5.0, impute=True, impute_strategy='median'):\n        # From looking at documentation, values between 5 and 10 are \"okay\".\n        # Above 10 is too high and so should be removed.\n        self.thresh = thresh\n        \n        # The statsmodel function will fail with NaN values, as such we have to impute them.\n        # By default we impute using the median value.\n        # This imputation could be taken out and added as part of an sklearn Pipeline.\n        if impute:\n            self.imputer = Imputer(strategy=impute_strategy)\n\n    def fit(self, X, y=None):\n        print('ReduceVIF fit')\n        if hasattr(self, 'imputer'):\n            self.imputer.fit(X)\n        return self\n\n    def transform(self, X, y=None):\n        print('ReduceVIF transform')\n        columns = X.columns.tolist()\n        if hasattr(self, 'imputer'):\n            X = pd.DataFrame(self.imputer.transform(X), columns=columns)\n        return ReduceVIF.calculate_vif(X, self.thresh)\n\n    @staticmethod\n    def calculate_vif(X, thresh=5.0):\n        # Taken from https://stats.stackexchange.com/a/253620/53565 and modified\n        dropped=True\n        while dropped:\n            variables = X.columns\n            dropped = False\n            vif = [variance_inflation_factor(X[variables].values, X.columns.get_loc(var)) for var in X.columns]\n            \n            max_vif = max(vif)\n            if max_vif > thresh:\n                maxloc = vif.index(max_vif)\n                print(f'Dropping {X.columns[maxloc]} with vif={max_vif}')\n                X = X.drop([X.columns.tolist()[maxloc]], axis=1)\n                dropped=True\n        return X\n    \n    def calculate_vif_2(X, thresh=5.0):\n        \n        variables = range(X.shape[1])\n        dropped=True\n        while dropped:\n            dropped=False\n            vif = [variance_inflation_factor(X[variables].values, ix) for ix in range(X[variables].shape[1])]\n\n            maxloc = vif.index(max(vif))\n            if max(vif) > thresh:\n                print('dropping \\'' + X[variables].columns[maxloc] + '\\' at index: ' + str(maxloc))\n                del variables[maxloc]\n                dropped=True\n\n        print('Remaining variables:')\n        print(X.columns[variables])\n        return X[variables]","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"1437ddd0-c28d-4c00-8e62-9b177f2fb13e","_uuid":"f60ee9ecb710416629012ef552bbb3eae970a3ab"},"source":"transformer = ReduceVIF()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"56489b07-c560-4e38-8647-0f42df0ccda9","_uuid":"196c4fa489fe32f31651779114f4b0561e207ed0"},"source":"X = transformer.fit_transform(df[mean_feats], y)\n\nX.head()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"15442658-823c-4bf7-a8f0-5027185829ea","_uuid":"59bccd4d8b5f4da2edf72bfac74efabb7d07048a"},"source":"important_feats = []","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"7494adcf-2f83-4888-9b6b-81abe8d668d4","_uuid":"2fab1eaad0388e0b41802718455b4c87467c211a"},"source":"important_feats.append('concavity_mean')\nimportant_feats.append('symmetry_mean')","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"4f4a12a1-f9e5-4baf-b844-225f1bc91495","_uuid":"33199100bcaf6027dcd5ddb123b7f6a132b8b7d3"},"source":"X = transformer.fit_transform(df[se_feats], y)\nX.head()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"5da6e734-c92e-4236-985c-df5a832d7f17","_uuid":"367aabb78c47b1c4ca9ac36762dc83919e5522d7"},"source":"important_feats.extend(['texture_se','area_se','concavity_se'])","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"f114b0c7-18d4-4459-94d8-c216a5f2f339","_uuid":"f54268237ea0a562bcfd2e2c0615dbaa674ee6d8"},"source":"X = transformer.fit_transform(df[worst_feats], y)\nX.head()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"aa144a95-03bc-48bc-bd80-12eba26cc1e2","_uuid":"a184e67105dc226500f482c6e6645b9fe9d38348"},"source":"important_feats.extend(['area_worst','concavity_worst','symmetry_worst'])","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"7d257ccd-f02e-4e94-8c92-5ec42d94b1d3","_uuid":"05ed52f204aedcb51a574ff299950ebafb469bf1"},"source":"important_feats","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"de59c188-80e1-4fbf-95f2-c1acc8a97875","_uuid":"7558875d6f9d5902864fbd8ca14587ec3e70a615"},"source":"X = df[important_feats]\ny = df['diagnosis']","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"de35ce34-c927-4e45-94e0-2c0456f8dce3","_uuid":"5bd032bde05b0b18f17555985e212cff5056933d"},"source":"from sklearn.linear_model import LogisticRegression \n\nlmodel = LogisticRegression()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"1550ce2d-0a43-4a42-84b2-74e5089c87ee","_uuid":"6a5033351d95e777951d1749b11bd6f5c325481b"},"source":"from sklearn.model_selection import train_test_split\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.4)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"01f57645-a38d-4ca1-b909-54514d68225a","_uuid":"3be26d0b671046dcdcfce9bade74c5f5e2ec1b57"},"source":"lmodel.fit(X_train,y_train)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"cc4ffd05-fa84-43e3-a1ec-6ce578fd3ffb","_uuid":"a64616063ba1a43c29e7a79da98db19dc846aef3"},"source":"log_y_preds = lmodel.predict(X_test)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"de6adf91-d588-455f-898d-8c96efb37ff6","_uuid":"e51eb37ec4fedb85413a5f349b853936bb0d3cba"},"source":"from sklearn.metrics import confusion_matrix,classification_report\n\nprint(confusion_matrix(y_test,log_y_preds))\nprint(classification_report(y_test,log_y_preds))","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"fdceb9b7-3ddb-4deb-819a-d38c867b5daa","_uuid":"a2b0c39945a7dc006a60a12de86834abeec5470f"},"source":"from sklearn.tree import DecisionTreeClassifier \n\ndtree = DecisionTreeClassifier()\ndtree.fit(X_train,y_train)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"d2b80053-24d7-4996-8421-8870475b9410","_uuid":"9d9dd3f3f53c47d1b0a8a7eb03f3f10e52c6ae80"},"source":"dtree_y_preds = dtree.predict(X_test)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"d311632c-2e5e-495b-86a2-253a491cf4b4","_uuid":"21147754d56338bac19c6b2bed2a509a27452f01"},"source":"print(confusion_matrix(y_test,dtree_y_preds))\nprint(classification_report(y_test,dtree_y_preds))","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"f81c6cb8-17ec-4ce6-bb83-9bd88e4a0961","_uuid":"ee52d5727a3b9b9514711ab2e64d6271cfefd377"},"source":"from sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier(n_estimators = 80)\n\nrfc.fit(X_train,y_train)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"29d6ca26-12e1-404c-99ea-fd6fb558d43b","_uuid":"1a17ef9089ac67bf95b539e45091c9eada00b70a"},"source":"rfc_y_preds = rfc.predict(X_test)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"c4f93913-a82e-4c56-b9dc-0062d2e3228c","_uuid":"297c64716818d28266b0378c1bf72e132cf658b4"},"source":"print(confusion_matrix(y_test,rfc_y_preds))\nprint(classification_report(y_test,rfc_y_preds))","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"c2d25294-b4eb-42b6-b87f-5952880d0556","_uuid":"2429e4d5a9ee6b44b6ee82ac89a9a3fd4d5c774b"},"source":"from sklearn.svm import SVC \n\nsvc_model = SVC()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"b60cab23-a47c-47d1-948b-d449ff1a787e","_uuid":"e5002ca891ef5ca9512c65a8f1fba4ac2a83fcf1"},"source":"svc_model.fit(X_train,y_train)\nsvc_y_preds = svc_model.predict(X_test)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"90100ea3-d23f-4ad6-8dcf-aa79607f2c3e","_uuid":"bcb27f2ed7a25b0e43395957888e868c6c237787"},"source":"print(confusion_matrix(y_test,svc_y_preds))\nprint(classification_report(y_test,svc_y_preds))","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"0e2dff2a-2bfe-4bcf-82db-f1ca0eb04890","_uuid":"23a0366e588f0f00c31f0f36838e4ec2057b1f46"},"source":"from sklearn.model_selection import GridSearchCV\nparam_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001]} \n\ngrid = GridSearchCV(SVC(),param_grid,refit=True,verbose=2)\ngrid.fit(X_train,y_train)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"72293e89-35f1-4aab-b365-f5ad5053dfc5","_uuid":"f49f2c049644e820f465c33dd04a344d4796be0e"},"source":"grid.best_params_","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"549ce5b0-490b-4a47-a3d6-4a34bd1daea1","_uuid":"27b207b5e94d5f3347fb9fdad8c690a2f00e1398"},"source":"svc_model = SVC(C=1,gamma=0.001)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"564846ab-8c21-4e3b-97bd-0b6ca5b96e2d","_uuid":"49f570d8b7af5e8dd1294b6c528eedbc820233a5"},"source":"svc_model.fit(X_train,y_train)\nsvc_y_preds = svc_model.predict(X_test)\nprint(confusion_matrix(y_test,svc_y_preds))\nprint(classification_report(y_test,svc_y_preds))","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**As we can see from the above results , Random Forest does the best in predicting the right result with 96% accuracy and mislabeling only 9 of the rows . **\n\nPlease feel free to comment in case you have any questions in terms of implementation or if you find anything wrong . "},{"metadata":{"collapsed":true},"source":"","execution_count":null,"cell_type":"code","outputs":[]}],"nbformat":4,"metadata":{"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","name":"python","codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","version":"3.6.1"},"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"}},"nbformat_minor":1}