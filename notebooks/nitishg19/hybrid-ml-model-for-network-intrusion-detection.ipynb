{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import relevant modules\n%matplotlib inline\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport sklearn\nimport imblearn\nimport time\n\n# Ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Settings\npd.set_option('display.max_columns', None)\nnp.set_printoptions(threshold=np.nan)\nnp.set_printoptions(precision=3)\nsns.set(style=\"darkgrid\")\nplt.rcParams['axes.labelsize'] = 14\nplt.rcParams['xtick.labelsize'] = 12\nplt.rcParams['ytick.labelsize'] = 12","metadata":{"_uuid":"5059b293b34a18afd43e6185dfcba4521bd87878","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LOAD DATA","metadata":{"_uuid":"2d5309ee0cd9b2f807af7a3ad8a783f066a99d0d"}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/Train_data.csv\")\ntrainB = pd.read_csv(\"../input/Test_data.csv\")","metadata":{"_uuid":"14c15b2699fed6d95c4e3e4de5e4595b4e650920","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train.shape)\n\nprint(\"Training data has {} rows & {} columns\".format(train.shape[0],train.shape[1]))","metadata":{"_uuid":"f3ca7cc2b990447e1a401f5b91ba8df21e33c845","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(trainB.shape)\n\nprint(\"Testing data has {} rows & {} columns\".format(trainB.shape[0],trainB.shape[1]))","metadata":{"_uuid":"5ed1bc1c00f047f5fed78fb18100b3be7c3b7852","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EXPLORATORY ANALYSIS","metadata":{"_uuid":"bde409f4fe8da1fcb52751bf8c397ac346a2409f"}},{"cell_type":"code","source":"# Descriptive statistics\ntrain.describe()\n","metadata":{"_uuid":"f231cec911b59adb7de03dd877fb38fbc270e09a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainB.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train['num_outbound_cmds'].value_counts())\nprint(trainB['num_outbound_cmds'].value_counts())","metadata":{"_uuid":"06b94b1d1a0c6ba604a7d69c1495132c3f38710c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#'num_outbound_cmds' is a redundant column so remove it from both train & test datasets\ntrain.drop(['num_outbound_cmds'], axis=1, inplace=True)\ntrainB.drop(['num_outbound_cmds'], axis=1, inplace=True)\ntrain.drop(['dst_host_srv_count'],axis=1, inplace =True)\ntrainB.drop(['dst_host_srv_count'],axis=1, inplace =True)\ntrain.drop(['src_bytes'],axis=1, inplace =True)\ntrainB.drop(['src_bytes'],axis=1, inplace =True)\ntrain.drop(['flag'],axis=1, inplace =True)\ntrainB.drop(['flag'],axis=1, inplace =True)\ntrain.drop(['dst_bytes'],axis=1, inplace =True)\ntrainB.drop(['dst_bytes'],axis=1, inplace =True)\ntrain.drop(['same_srv_rate'],axis=1, inplace =True)\ntrainB.drop(['same_srv_rate'],axis=1, inplace =True)\ntrain.drop(['dst_host_same_srv_rate'],axis=1, inplace =True)\ntrainB.drop(['dst_host_same_srv_rate'],axis=1, inplace =True)","metadata":{"_uuid":"4e0f8a1adcd11b17c9bda454c8c29e486ac10f64","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Attack Class Distribution\ntrain['class'].value_counts()","metadata":{"_uuid":"df0fc1cc89e3a82a7b07e1662c99abf42deddbc9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SCALING NUMERICAL ATTRIBUTES","metadata":{"_uuid":"d472d5c2705a8d322b20fa1994139a4c9cdaebce"}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\n# extract numerical attributes and scale it to have zero mean and unit variance  \ncols = train.select_dtypes(include=['float64','int64']).columns\nsc_train = scaler.fit_transform(train.select_dtypes(include=['float64','int64']))\nsc_trainB = scaler.fit_transform(trainB.select_dtypes(include=['float64','int64']))\n\n# turn the result back to a dataframe\nsc_traindf = pd.DataFrame(sc_train, columns = cols)\nsc_trainBdf = pd.DataFrame(sc_trainB, columns = cols)","metadata":{"_uuid":"654b1e6dfb83362b836ed892df4deae0d48ce4b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ENCODING CATEGORICAL ATTRIBUTES","metadata":{"_uuid":"bd7451b8802bfb2201a978469b0636d082aa3a0a"}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\n\n# extract categorical attributes from both training and test sets \ncattrain = train.select_dtypes(include=['object']).copy()\ncattrainB = trainB.select_dtypes(include=['object']).copy()\n\n# encode the categorical attributes\ntraincat = cattrain.apply(encoder.fit_transform)\ntrainBcat = cattrainB.apply(encoder.fit_transform)\n\n# separate target column from encoded data \nenctrain = traincat.drop(['class'], axis=1)\ncat_Ytrain = traincat[['class']].copy()\n","metadata":{"_uuid":"e3d637225809dfcc6aa3ea7ef4a9b1d55d2b436c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#cols = train.select_dtypes(include=['float64','int64']).columns\n#colval = train.select_dtypes(include=['float64','int64'])\n#sc_traindf = pd.DataFrame(colval, columns = cols)\ntrain_x = pd.concat([sc_traindf,enctrain],axis=1)\ntrain_y = train['class']\ntrain_x.shape","metadata":{"_uuid":"227915d0f6d7a22ec344d4a016049acecb0323f6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#cols = test.select_dtypes(include=['float64','int64']).columns\n#colval = test.select_dtypes(include=['float64','int64'])\n#sc_traindf = pd.DataFrame(colval, columns = cols)\ntrainB_df = pd.concat([sc_trainBdf,trainBcat],axis=1)\n\ntrainB_df.shape","metadata":{"_uuid":"ca90e6da174743f665a1fc640ff3070e502a3535","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# FEATURE SELECTION","metadata":{"_uuid":"58212e80c11969c02f35adbf42d2bba7881dfde0"}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier();\n\n# fit random forest classifier on the training set\nrfc.fit(train_x, train_y);\n# extract important features\nscore = np.round(rfc.feature_importances_,3)\nimportances = pd.DataFrame({'feature':train_x.columns,'importance':score})\nimportances = importances.sort_values('importance',ascending=False).set_index('feature')\n# plot importances\nplt.rcParams['figure.figsize'] = (11, 4)\nimportances.plot.bar();","metadata":{"_uuid":"6608ad7beebd4cd2ca3cbc0999da5def00d0c4e5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_selection import RFE\nimport itertools\nrfc = RandomForestClassifier()\n\n# create the RFE model and select 10 attributes\nrfe = RFE(rfc, n_features_to_select=15)\nrfe = rfe.fit(train_x, train_y)\n\n# summarize the selection of the attributes\nfeature_map = [(i, v) for i, v in itertools.zip_longest(rfe.get_support(), train_x.columns)]\nselected_features = [v for i, v in feature_map if i==True]\n\nlen(selected_features)","metadata":{"_uuid":"4d9cffa96fadfddb552370e614d3e9ccc7a2c420","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DATASET PARTITION","metadata":{"_uuid":"c20a81752c216722f4fdfb8ce2837956823c1b6d"}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n#train_x= train_x[selected_features]\nX_train,X_test,Y_train,Y_test = train_test_split(train_x,train_y,train_size=0.80, random_state=35)\nX_train,X_trainB,Y_train,Y_trainB = train_test_split(X_train,Y_train,train_size=0.50, random_state=25)\nX_test,X_testB,Y_test,Y_testB = train_test_split(X_test,Y_test,train_size=0.50, random_state=25)\nprint(X_train.shape, Y_train.shape)\nprint(X_trainB.shape, Y_trainB.shape)\nprint(X_test.shape, Y_test.shape)\nprint(X_testB.shape, Y_testB.shape)","metadata":{"_uuid":"6a5e5c54d8c5d760085d104bdc8c5eb44b6372b4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# FITTING MODELS","metadata":{"_uuid":"bb80c25403d2e9030d20e37eefa4d54c83dfb056"}},{"cell_type":"code","source":"from sklearn.svm import SVC \nfrom sklearn.naive_bayes import BernoulliNB \nfrom sklearn import tree\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\n\"\"\"\n# Train KNeighborsClassifier Model\nKNN_Classifier = KNeighborsClassifier(n_jobs=-1)\nKNN_Classifier.fit(X_train, Y_train); \n\n# Train LogisticRegression Model\nLGR_Classifier = LogisticRegression(n_jobs=-1, random_state=0)\nLGR_Classifier.fit(X_train, Y_train);\n\"\"\"\n# Train Gaussian Naive Baye Model\nBNB_Classifier = BernoulliNB()\nBNB_Classifier.fit(X_train, Y_train)\n\n# Train Decision Tree Model\nt1=time.time()\nDTC_Classifier = tree.DecisionTreeClassifier(criterion='gini',max_depth=2, random_state=10)\nDTC_Classifier.fit(X_train, Y_train)\nt2=time.time()\nprint(\"Training time for Decision Tree: \", t2-t1)\nprint()\n\nt1=time.time()\nXGB_Classifier = XGBClassifier(base_score=0.3, n_estimators=5)\nXGB_Classifier.fit(X_train, Y_train)\nt2=time.time()\nprint(\"Training time for XGBoost: \", t2-t1)\nprint()\n\nt1=time.time()\nRandomForest_Classifier = RandomForestClassifier(n_estimators=1)\nRandomForest_Classifier.fit(X_train, Y_train)\nt2=time.time()\nprint(\"Training time for Random Forest: \", t2-t1)\nprint()\n","metadata":{"_uuid":"9ab0f6c11f8772d9f1c008ee2b4d1f181af3effb","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EVALUATE MODELS","metadata":{"_uuid":"9753eed4eab0e0587d016b78efce930aa782f29f"}},{"cell_type":"code","source":"from sklearn import metrics\nfrom sklearn.metrics import f1_score\nmodels = []\nmodels.append(('Naive Baye Classifier', BNB_Classifier))\nmodels.append(('Decision Tree Classifier', DTC_Classifier))\nmodels.append(('XG Boost Classifier', XGB_Classifier))\nmodels.append(('Random Forest Classifier', RandomForest_Classifier))\n\n\n\nfor i, v in models:\n    scores = cross_val_score(v, X_test, Y_test, cv=10)\n    accuracy = metrics.accuracy_score(Y_test, v.predict(X_test))\n    confusion_matrix = metrics.confusion_matrix(Y_test, v.predict(X_test))\n    classification = metrics.classification_report(Y_test, v.predict(X_test), digits=8)\n    print()\n    print('============================== {} Model Evaluation =============================='.format(i))\n    print()\n    print (\"Cross Validation Mean Score:\" \"\\n\", scores.mean())\n    print()\n    print (\"Model Accuracy:\" \"\\n\", accuracy)\n    print()\n    print(\"Confusion matrix:\" \"\\n\", confusion_matrix)\n    print()\n    print(\"Classification report:\" \"\\n\", classification) \n    print()\n    ","metadata":{"_uuid":"56a6d972dfc7236bddc02b254416331a45e1b57a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# VALIDATING MODELS","metadata":{"_uuid":"304fddb4f81dbe6893caf007ffdde527243fa119"}},{"cell_type":"code","source":"for i, v in models:\n    t1=time.time()\n    accuracy = metrics.accuracy_score(Y_test, v.predict(X_test))\n    t2=time.time()\n    confusion_matrix = metrics.confusion_matrix(Y_test, v.predict(X_test))\n    classification = metrics.classification_report(Y_test, v.predict(X_test))\n    print()\n    print('============================== {} Model Test Results =============================='.format(i))\n    print()\n    print(\"Prediction time of \", i, t2-t1)\n    print()\n    print (\"Model Accuracy:\" \"\\n\", accuracy)\n    print()\n    print(\"Confusion matrix:\" \"\\n\", confusion_matrix)\n    print()\n    print(\"Classification report:\" \"\\n\", classification) \n    print()        \n","metadata":{"_uuid":"5ab78f517053e419f6c6667e90a0b352ccb5f531","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Functions to extract locations of FP, FN as a pandas series","metadata":{}},{"cell_type":"markdown","source":"# To generate the last row after NB prediction function ","metadata":{}},{"cell_type":"code","source":"def genPredRow(y_actual, y_pred):\n    FP = []\n\n    for i in range(len(y_pred)): \n        if y_pred[i]=='anomaly' and y_actual.iat[i]!=y_pred[i]:\n           FP.append(1)\n        elif y_pred[i]=='normal' and y_actual.iat[i]!=y_pred[i]:\n           FP.append(1) \n        else:\n            FP.append(0)\n    return (pd.Series(FP))\n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Combining Decision Tree and XG Boost","metadata":{}},{"cell_type":"markdown","source":"## Getting FP and FN row location from NB output as pd.Series","metadata":{}},{"cell_type":"code","source":"\"\"\"models = []\nmodels.append(('Naive Baye Classifier', BNB_Classifier))\nmodels.append(('Decision Tree Classifier', DTC_Classifier))\nmodels.append(('XG Boost Classifier', XGB_Classifier))\nmodels.append(('Random Forest Classifier', RandomForest_Classifier))\n\n\"\"\"\n\nt1= time.time()\n\n##USING DECISION TREE TO PREDICT PREVIOUS VALUES\nX_testB_XGB_DCT = X_testB.copy()\nY_testB_XGB_DCT = Y_testB.copy()\nX_trainB_XGB_DCT = X_trainB.copy()\nY_trainB_XGB_DCT = Y_trainB.copy()\nfinalPred= genPredRow(Y_trainB_XGB_DCT, models[1][1].predict(X_trainB_XGB_DCT))\nprint(\"Size of number of FP:\", finalPred.size) \n\nfinalPredTest = genPredRow(Y_testB_XGB_DCT, models[1][1].predict(X_testB_XGB_DCT))\n\nX_trainB_XGB_DCT['prevPred'] = np.array(finalPred)\nX_testB_XGB_DCT['prevPred'] = np.array(finalPredTest)\nprint(X_trainB_XGB_DCT.shape)\nprint(X_testB.shape)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## PASSING X_TRAIN B TO TRAIN XGBOOST \n","metadata":{}},{"cell_type":"code","source":"XGB_Classifier_DCT = XGBClassifier(base_score=0.3, n_estimators=5)\nXGB_Classifier_DCT.fit(X_trainB_XGB_DCT, Y_trainB_XGB_DCT)\nprint()\n\nt2=time.time()\nprint (\"Training Time for Decision Tree and XG Boost: \", t2-t1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing new XG Boost Model","metadata":{}},{"cell_type":"code","source":"t1=time.time()\nY_testB_XGB_DCT_pred = XGB_Classifier_DCT.predict(X_testB_XGB_DCT)\nt2=time.time()\nprint (\"Prediction Time for Decision Tree and XG Boost: \", t2-t1)\nprint()\nscores_XGB_DCT = cross_val_score(XGB_Classifier_DCT, X_testB_XGB_DCT, Y_testB_XGB_DCT, cv=10)\naccuracy_XGB_DCT = metrics.accuracy_score(Y_testB_XGB_DCT, Y_testB_XGB_DCT_pred)\nconfusion_matrix_XGB_DCT = metrics.confusion_matrix(Y_testB_XGB_DCT,Y_testB_XGB_DCT_pred)\nclassification_XGB_DCT = metrics.classification_report(Y_testB_XGB_DCT,Y_testB_XGB_DCT_pred, digits=8)\nprint()\nprint('============================== {} Model Evaluation =============================='.format('Decision tree + XG Boost'))\nprint()\nprint (\"Cross Validation Mean Score:\" \"\\n\", scores_XGB_DCT.mean())\nprint()\nprint (\"Model Accuracy:\" \"\\n\", accuracy_XGB_DCT)\nprint()\nprint(\"Confusion matrix:\" \"\\n\", confusion_matrix_XGB_DCT)\nprint()\nprint(\"Classification report:\" \"\\n\", classification_XGB_DCT) \nprint()\n ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Combining Random Forest with XG BOOST ","metadata":{}},{"cell_type":"code","source":"\"\"\"models = []\nmodels.append(('Naive Baye Classifier', BNB_Classifier))\nmodels.append(('Decision Tree Classifier', DTC_Classifier))\nmodels.append(('XG Boost Classifier', XGB_Classifier))\nmodels.append(('Random Forest Classifier', RandomForest_Classifier))\n\n\"\"\"\n\nt1=time.time()\n##USING DECISION TREE TO PREDICT PREVIOUS VALUES\nX_testB_XGB_RF = X_testB.copy()\nY_testB_XGB_RF = Y_testB.copy()\nX_trainB_XGB_RF = X_trainB.copy()\nY_trainB_XGB_RF = Y_trainB.copy()\nfinalPred= genPredRow(Y_trainB_XGB_RF, models[1][1].predict(X_trainB_XGB_RF))\nprint(\"Size of number of FP:\", finalPred.size) \n\nfinalPredTest = genPredRow(Y_testB_XGB_RF, models[1][1].predict(X_testB_XGB_RF))\n\nX_trainB_XGB_RF['prevPred'] = np.array(finalPred)\nX_testB_XGB_RF['prevPred'] = np.array(finalPredTest)\nprint(X_trainB_XGB_RF.shape)\nprint(X_testB.shape)\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Passing updated dataframe to XG BOOST","metadata":{}},{"cell_type":"code","source":"XGB_Classifier_RF = XGBClassifier(base_score=0.3, n_estimators=5)\nXGB_Classifier_RF.fit(X_trainB_XGB_RF, Y_trainB_XGB_RF)\nprint()\n\nt2=time.time()\nprint (\"Training Time for Random Forest with XG BOOST: \", t2-t1)\nprint()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing new XG Boost Model","metadata":{}},{"cell_type":"code","source":"t1=time.time()\nY_testB_XGB_RF_pred = XGB_Classifier_RF.predict(X_testB_XGB_RF)\nt2=time.time()\nprint (\"Prediction Time for Random Forest with XG BOOST: \", t2-t1)\nprint()\nscores_XGB_RF = cross_val_score(XGB_Classifier_RF, X_testB_XGB_RF, Y_testB_XGB_RF, cv=10)\naccuracy_XGB_RF = metrics.accuracy_score(Y_testB_XGB_RF, Y_testB_XGB_RF_pred)\nconfusion_matrix_XGB_RF = metrics.confusion_matrix(Y_testB_XGB_RF,Y_testB_XGB_RF_pred)\nclassification_XGB_RF = metrics.classification_report(Y_testB_XGB_RF,Y_testB_XGB_RF_pred, digits=8)\nprint()\nprint('============================== {} Model Evaluation =============================='.format('Random Forest + XG Boost'))\nprint()\nprint (\"Cross Validation Mean Score:\" \"\\n\", scores_XGB_RF.mean())\nprint()\nprint (\"Model Accuracy:\" \"\\n\", accuracy_XGB_RF)\nprint()\nprint(\"Confusion matrix:\" \"\\n\", confusion_matrix_XGB_RF)\nprint()\nprint(\"Classification report:\" \"\\n\", classification_XGB_RF) \nprint()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Random Forest + Decsion tree","metadata":{}},{"cell_type":"code","source":"\"\"\"models = []\nmodels.append(('Naive Baye Classifier', BNB_Classifier))\nmodels.append(('Decision Tree Classifier', DTC_Classifier))\nmodels.append(('XG Boost Classifier', XGB_Classifier))\nmodels.append(('Random Forest Classifier', RandomForest_Classifier))\n\n\"\"\"\n\nt1=time.time()\n\n##USING DECISION TREE TO PREDICT PREVIOUS VALUES\nX_testB_DCT_RF = X_testB.copy()\nY_testB_DCT_RF = Y_testB.copy()\nX_trainB_DCT_RF = X_trainB.copy()\nY_trainB_DCT_RF = Y_trainB.copy()\nfinalPred= genPredRow(Y_trainB_DCT_RF, models[1][1].predict(X_trainB_DCT_RF))\nprint(\"Size of number of FP:\", finalPred.size) \n\nfinalPredTest = genPredRow(Y_testB_DCT_RF, models[1][1].predict(X_testB_DCT_RF))\n\nX_trainB_DCT_RF['prevPred'] = np.array(finalPred)\nX_testB_DCT_RF['prevPred'] = np.array(finalPredTest)\nprint(X_trainB_DCT_RF.shape)\nprint(X_testB.shape)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## passing updated dataframe to Decision tree classifier","metadata":{}},{"cell_type":"code","source":"DTC_Classifier_RF = tree.DecisionTreeClassifier(criterion='gini',max_depth=2, random_state=10)\nDTC_Classifier_RF.fit(X_trainB_DCT_RF, Y_trainB_DCT_RF)\nprint()\n\nt2=time.time()\nprint (\"Training Time for Random Forest with XG BOOST: \", t2-t1)\nprint()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing new Decision Tree Model","metadata":{}},{"cell_type":"code","source":"t1=time.time()\nY_testB_DCT_RF_pred = XGB_Classifier_RF.predict(X_testB_DCT_RF)\nt2=time.time()\nprint (\"Prediction Time for Random Forest with XG BOOST: \", t2-t1)\nprint()\nscores_DCT_RF = cross_val_score(XGB_Classifier_RF, X_testB_DCT_RF, Y_testB_DCT_RF, cv=10)\naccuracy_DCT_RF = metrics.accuracy_score(Y_testB_DCT_RF, Y_testB_DCT_RF_pred)\nconfusion_matrix_DCT_RF = metrics.confusion_matrix(Y_testB_DCT_RF,Y_testB_DCT_RF_pred)\nclassification_DCT_RF = metrics.classification_report(Y_testB_DCT_RF,Y_testB_DCT_RF_pred, digits=8)\nprint()\nprint('============================== {} Model Evaluation =============================='.format('Random Forest + Decision'))\nprint()\nprint (\"Cross Validation Mean Score:\" \"\\n\", scores_DCT_RF.mean())\nprint()\nprint (\"Model Accuracy:\" \"\\n\", accuracy_DCT_RF)\nprint()\nprint(\"Confusion matrix:\" \"\\n\", confusion_matrix_DCT_RF)\nprint()\nprint(\"Classification report:\" \"\\n\", classification_DCT_RF) \nprint()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}