{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data=pd.read_csv('/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data.isnull()].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.drop('quality', axis=1)\ny = data.quality","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ****2. Detect Columns that contains outliers...****"},{"metadata":{"trusted":true},"cell_type":"code","source":"# For each feature find the data points with extreme high or low values\nfor feature in X.keys():\n\n    # Q1 (25th percentile of the data) for the given feature\n    Q1 = np.percentile(X[feature], q=25)\n \n    # Q3 (75th percentile of the data) for the given feature\n    Q3 = np.percentile(X[feature], q=75)\n \n    # We use the interquartile range to calculate an outlier step (1.5 times the interquartile range)\n    interquartile_range = Q3 - Q1\n    step = 1.5 * interquartile_range\n \n    # Display the outliers\n    print(\"Data points considered outliers for the feature '{}':\".format(feature))\n    display(X[~((X[feature] >= Q1 - step) & (X[feature] <= Q3 + step))])\n ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**What kind of a ML problem is this?If Regression,then can this also be solved as a classification problem?**"},{"metadata":{},"cell_type":"markdown","source":"This is a supervised learning problem and it can be solved in both regression and classification method, though in classification we will try to minimize the range label to few encoded lables for better correlation and accuracy.We will see both the implementation below after a while."},{"metadata":{},"cell_type":"markdown","source":"****EXPLORATORY DATA ANALYSIS****"},{"metadata":{"trusted":true},"cell_type":"code","source":"X.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**From the above scatterplot we can get some interesting details. For some of the features, the distribution appears to be fairly linear. For some others, the distribution appears to be negatively skewed. So this confirms our initial suspicions — there are indeed some interesting co-dependencies(relying on other features) between some of the features.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### we can plot heat map to examin the correlation\ncorrelation = X.corr()\n# display(correlation)\nplt.figure(figsize=(14, 12))\nheatmap = sns.heatmap(correlation, annot=True, linewidths=0, vmin=-1, cmap=\"RdBu_r\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The squares with positive values show direct co-relationships between features. The higher the values, the stronger these relationships are — they’ll be more reddish. That means, if one feature increases, the other one also tends to increase, and vice-versa.**\n\n\n**The squares that have negative values show an inverse co-relationship. The more negative these values get, the more inversely proportional they are, and they’ll be more blue. This means that if the value of one feature is higher, the value of the other one gets lower.**\n\n**Finally, squares close to zero indicate almost no co-dependency between those sets of features.**"},{"metadata":{},"cell_type":"markdown","source":"**Fixed Acidity vs. Citric Acid**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fixedAcidity_citricAcid = X[['citric acid', 'fixed acidity']]\ng = sns.JointGrid(x=\"fixed acidity\", y=\"citric acid\", data=fixedAcidity_citricAcid, size=10)\ng = g.plot_joint(sns.regplot, scatter_kws={\"s\": 10})\ng = g.plot_marginals(sns.distplot)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**As the citric acid increases the fixed acid also increases linearly.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# A new dataframe containing only pH and fixed acidity columns to visualize their co-relations\nfixedAcidity_pH = X[['pH', 'fixed acidity']]\ngridA = sns.JointGrid(x=\"fixed acidity\", y=\"pH\", data=fixedAcidity_pH, size=10)\n#Regression plot in the grid \ngridA = gridA.plot_joint(sns.regplot, scatter_kws={\"s\": 10})\n#Distribution plot in the same grid\ngridA = gridA.plot_marginals(sns.distplot)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Fixed acidity levels increase, the pH levels.A lower pH level is, after all, an indicator of high acidity.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"volatileAcidity_quality=data[['volatile acidity','quality']]\nfig, axs = plt.subplots(ncols=1,figsize=(15,10))\nsns.barplot(x='quality', y='volatile acidity', data=volatileAcidity_quality)\nplt.title('quality VS volatile acidity')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We can clearly see that lower the volatile acidity better is the quality of the wine**"},{"metadata":{"trusted":true},"cell_type":"code","source":"alcohol_quality=data[['alcohol','quality']]\nfig, axs = plt.subplots(ncols=1,figsize=(15,10))\nsns.barplot(x='quality', y='alcohol', data=alcohol_quality)\nplt.title('quality VS alcohol content')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**More the alcohol content better is the quality of wine.**"},{"metadata":{},"cell_type":"markdown","source":"****DATA PRE-PROCESSING****"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = sc_X.fit_transform(X_train)\nX_test = sc_X.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**BUILDING  MODEL AND OPTIMIZATION**"},{"metadata":{},"cell_type":"markdown","source":"**Regression model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlr=LinearRegression()\nlr.fit(X_train,y_train)\npred=lr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nprint('MAE:', metrics.mean_absolute_error(y_test, pred)*100)\nprint('MSE:', metrics.mean_squared_error(y_test, pred)*100)\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, pred))*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Classification method**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier(n_estimators=100, max_depth=5,random_state=0)\nclf.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred=clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score,f1_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"accuracy:\",(accuracy_score(y_test,pred)*100))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}