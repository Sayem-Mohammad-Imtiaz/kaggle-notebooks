{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\ndf = pd.read_csv('/kaggle/input/breast-cancer-wisconsin-data/data.csv')\ndf.drop(['id'], axis=1, inplace=True)\nprint(df.shape)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The whole freaking column is null, lol. Screw it, drop it\nprint(df.isna().sum())\ndf.drop(['Unnamed: 32'], axis=1, inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\ndf = pd.get_dummies(df)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(32, 32))\ncorr = df.corr().round(3)\nsns.heatmap(corr, annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(corr)\n# Just coz i couldn't see in the heatmap, lol","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_this(df, plot_type='boxplot'):\n    fig = plt.figure(figsize=(32, 32))\n    for i in range(df.shape[1]):\n        plt.subplot(4, 8, i + 1)\n        if plot_type=='boxplot':\n            sns.boxplot(df.iloc[:, i])\n        elif plot_type == 'distplot':\n            sns.distplot(df.iloc[:, i], color=(0.2 + (i+1)/50.0, 0.0 + (i+1)/100.0, 1.0 - (i+1)/50.0, 0.3))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Just checking the boxplot for each features to determine the IQR's, to help us choosing the right scaler model\nplot_this(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the distribution\nplot_this(df, plot_type='distplot')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The dataset looks pretty much normalised, hence we only have to focus on bringin our data within the IGR range,\n# we can do so using the RobustScaler in sklean.preprocessing\n# Before that let's seperate the features and labels\ntrain = df.copy()\nX = train.drop(['diagnosis_B', 'diagnosis_M'], axis=1)\ny = train[['diagnosis_B', 'diagnosis_M']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Robust Scaling the data to bring it to the IQR range\n# IDK whytf RobustScaler wasn't working, so i decided i'll use my own RobustScaler\nmedian_values = X.median().values\nstd_values = X.std().values\n\nX = (X - median_values) / std_values\nX.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Still no use\nplot_this(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's not waste time and continue with model selection part, first let's implement without info gain, info gain\n# is not necessary since almost all of the data features have a pretty good correlation with the output labels\ndef train_model(model, x_t, y_t, x_v, y_v):\n    model.fit(x_t, y_t)\n    print('Training Score', model.score(x_t, y_t))\n    print('Validation Score', model.score(x_v, y_v))\n    print('f1_score', f1_score(model.predict(x_v), y_v))\n    print('Classification Report\\n', classification_report(y_v, model.predict(x_v)))\n    print('Confusion Matrix\\n', confusion_matrix(y_v, model.predict(x_v)))\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# converting 2 categorical labels to a single one, so that the standard models can fit.\nfrom sklearn.model_selection import train_test_split\nY = []\nfor ele in y.values:\n    if ele[0] == 1:\n        Y.append(0)\n    elif ele[1] == 1:\n        Y.append(1)\nY = np.array(Y)\nprint(Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_t, x_v, y_t, y_v = train_test_split(X.values, Y, test_size=0.25, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score, classification_report, confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nlgs = LogisticRegression(solver='lbfgs')\nknn = KNeighborsClassifier()\nxgb = XGBClassifier(n_estimators=500, max_depth=5,learning_rate=0.1,scale_pos_weight=1.4266790777602751)\ndtc = DecisionTreeClassifier()\n\nprint('\\nLogistic Regression\\n')\nlgs = train_model(lgs, x_t, y_t, x_v, y_v)\n\nprint('\\nKNN\\n')\nknn = train_model(knn, x_t, y_t, x_v, y_v)\n\nprint('\\nXGBoost\\n')\nxgb = train_model(xgb, x_t, y_t, x_v, y_v)\n\nprint('\\nDecision Trees\\n')\ndtc = train_model(dtc, x_t, y_t, x_v, y_v)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looks like we got our results and it's pretty clear that Logistic Regression performs the best, with the highest\n# Accuracy, f1_score and Recall(which plays the most crucial role, since we are trying reduce the number of \n# True Negatives).","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":1}