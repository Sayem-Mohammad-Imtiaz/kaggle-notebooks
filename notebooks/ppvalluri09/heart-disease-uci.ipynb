{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\ndf = pd.read_csv('/kaggle/input/heart-disease-uci/heart.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To ignore nasty warnings\ndef warn(*args, **kwargs):\n    pass\nimport warnings\nwarnings.warn = warn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking for distribution of values in the dataframe\ncolors = ['r', 'g', 'b', 'c', 'm', 'y'] * 3\nplt.figure(figsize=(32, 8))\nfor i in range(13):\n    if df.columns[i] not in ['cp', 'sex', 'restecg', 'fbs', 'exang', 'slope', 'ca']:\n        plt.subplot(2,7, i + 1)\n        sns.distplot(df.iloc[:, i], color=colors[i])\nplt.plot()\n# We check for box or dist plots to check whether data is normalized or not","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()\n# Our dataset does not have any null values, which is good","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# df['cp'][df['cp'] == 1] = 'typical angina'\n# df['cp'][df['cp'] == 2] = 'atypical angina'\n# df['cp'][df['cp'] == 3] = 'non-anginal pain'\n# df['cp'][df['cp'] == 4] = 'asymptomatic'\n\n# df = pd.get_dummies(df, drop_first=True)\n# print(df.shape)\n# df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = df.corr().round(2)\nplt.figure(figsize=(16, 16))\nsns.heatmap(corr, annot=True)\nplt.show()\n\n# though from correlation heatmap we see that some features have very less correlation with the target\n# we know from personal knowledge that those features are a crucial factors in deciding whether a person has heart disease\n# or not, therefore we won't be dropping any columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting the training features and labels\ny = df['target']\ntrain = df.copy()\ntrain.drop(['target'], axis=1, inplace=True)\ndropped_categorical_features = train['cp']\ntrain.drop(['cp'], axis=1, inplace=True)\n# print(y.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature scaling the data using StandardScaler (also can use MinMaxScaler)\nfrom sklearn.preprocessing import StandardScaler\nscl = StandardScaler()\ntrain = pd.DataFrame(scl.fit_transform(train), columns=train.columns)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# adding the categorical values to the feature set\ntrain['cp'] = dropped_categorical_features\ntrain['cp'][train['cp'] == 1] = 'typical angina'\ntrain['cp'][train['cp'] == 2] = 'atypical angina'\ntrain['cp'][train['cp'] == 3] = 'non-anginal pain'\ntrain['cp'][train['cp'] == 4] = 'asymptomatic'\n\ntrain = pd.get_dummies(train, drop_first=True)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting our data into training and testing data\nfrom sklearn.model_selection import train_test_split\nx_t, x_v, y_t, y_v = train_test_split(train.values, y, test_size=0.25, random_state=42)\nprint('Train Data Size', x_t.shape, y_t.shape)\nprint('Test Data Shape', x_v.shape, y_v.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to train our model\n\ndef train_model(model, x_t, y_t, x_v=None, y_v=None):\n    model.fit(x_t, y_t)\n    print('Training Accuracy', model.score(x_t, y_t))\n    \n    if x_v is not None:\n        print('Validation Accuracy', model.score(x_v, y_v))\n        print('F1_Score', f1_score(model.predict(x_v), y_v))\n        print('Confusion Matrix\\n', confusion_matrix(y_v, model.predict(x_v)))\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We are using different models for training our data\n# XGBoost, Logistic, DecisionTrees, KMeans\nfrom sklearn.metrics import f1_score, confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.neural_network import MLPClassifier\n\nxgb = XGBClassifier(n_estimators=500, max_depth=5,learning_rate=0.1,scale_pos_weight=1.4266790777602751)\nlgs = LogisticRegression(n_jobs=1)\ndtc = DecisionTreeClassifier()\nrfc = RandomForestClassifier(n_estimators=100)\nmlp = MLPClassifier(hidden_layer_sizes=(32, 32, 16))\n\nprint('XGBoost...')\nxgb = train_model(xgb, x_t, y_t, x_v, y_v)\n\nprint('Logistic Regression...')\nlgs = train_model(lgs, x_t, y_t, x_v, y_v)\n\nprint('Decision Tree...')\ndtc = train_model(dtc, x_t, y_t, x_v, y_v)\n\nprint('Random Forest...')\nrfc = train_model(rfc, x_t, y_t, x_v, y_v)\n\nprint('MLP...')\nmlp = train_model(mlp, x_t, y_t, x_v, y_v)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Though f1_scores are higher for Random Forest and Logistic Regression the FNs are higher for these, so we will\n# apply grid search to reduce the FNs, since recall is more important in this case.","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# We can see that the training accuracy is close to 1 or 1 in some cases but the validation accuracy is pretty bad\n# implying a classical case of overfitting, hence we actually included features which donot correlate much with \n# the label, hence let's use a process known as Information Gain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\n\ndef train_model_with_info_gain(model, x_t, y_t, x_v, y_v):\n    scores = []\n    included = [0]\n    model.fit(x_t[:, included], y_t)\n    score_prev = model.score(x_v[:, included], y_v)\n    scores.append(score_prev)\n    for i in range(1, x_t.shape[1]):\n        data = x_t[:, included + [i]]\n        model.fit(data, y_t)\n        score = model.score(x_v[:, included + [i]], y_v)\n        scores.append(score)\n        if score > score_prev:\n            score_prev = score\n            included.append(i)\n    \n    plt.figure(figsize=(8, 4))\n    plt.plot(scores, 'yo--', alpha=0.7)\n    plt.xticks(range(x_t.shape[1]))\n    plt.xlabel('Columns Included')\n    plt.ylabel('Validation Scores')\n    model.fit(x_t[:, included], y_t)\n    print('Validation Score', model.score(x_v[:, included], y_v))\n    return (model, included)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score, confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.neural_network import MLPClassifier\n\nxgb = XGBClassifier(n_estimators=500, max_depth=5,learning_rate=0.1,scale_pos_weight=1.4266790777602751)\nlgs = LogisticRegression(n_jobs=1, solver='lbfgs')\ndtc = DecisionTreeClassifier()\nrfc = RandomForestClassifier(n_estimators=100)\nmlp = MLPClassifier(hidden_layer_sizes=(32, 32, 16))\n\nprint('\\nXGBoost...')\nxgb, included_xgb = train_model_with_info_gain(xgb, x_t, y_t, x_v, y_v)\nprint('Columns Included', included_xgb)\nprint('F1 Score', f1_score(xgb.predict(x_v[:, included_xgb]), y_v))\n\nprint('\\nLogistic Regression...')\nlgs, included_lgs = train_model_with_info_gain(lgs, x_t, y_t, x_v, y_v)\nprint('Columns Included', included_lgs)\nprint('F1 Score', f1_score(lgs.predict(x_v[:, included_lgs]), y_v))\n\nprint('\\nDecision Tree...')\ndtc, included_dtc = train_model_with_info_gain(dtc, x_t, y_t, x_v, y_v)\nprint('Columns Included', included_dtc)\nprint('F1 Score', f1_score(dtc.predict(x_v[:, included_dtc]), y_v))\n\nprint('\\nRandom Forest...')\nrfc, included_rfc = train_model_with_info_gain(rfc, x_t, y_t, x_v, y_v)\nprint('Columns Included', included_rfc)\nprint('F1 Score', f1_score(rfc.predict(x_v[:, included_rfc]), y_v))\n\nprint('\\nNeural Networks...')\nmlp, included_mlp = train_model_with_info_gain(mlp, x_t, y_t, x_v, y_v)\nprint('Columns Included', included_mlp)\nprint('F1 Score', f1_score(mlp.predict(x_v[:, included_mlp]), y_v))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We have an improved Validation accuracy and also the f1_score in case of every model which is a good thing, \n# moreover we now have a clear picture of which features are actually necessary which knowledge we were void of in \n# the correlation matrix, out of all these models Logistic Regression seemed to have performed well, but we have \n# another aim which is to reduce the number of False Negatives\nprint('XGBoost\\n', confusion_matrix(xgb.predict(x_v[:, included_xgb]), y_v))\nprint('\\nLogistic Regression\\n', confusion_matrix(lgs.predict(x_v[:, included_lgs]), y_v))\nprint('\\nDecision Tree\\n', confusion_matrix(dtc.predict(x_v[:, included_dtc]), y_v))\nprint('\\nRandom Forest\\n', confusion_matrix(rfc.predict(x_v[:, included_rfc]), y_v))\nprint('\\nNeural Networks\\n', confusion_matrix(mlp.predict(x_v[:, included_mlp]), y_v))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":1}