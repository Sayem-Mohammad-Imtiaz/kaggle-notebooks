{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<center><h1>ML project on KNN</h1> </center>","metadata":{}},{"cell_type":"markdown","source":"<center><h4> Project By: Swati Tripathi</h4> </center>","metadata":{}},{"cell_type":"markdown","source":"________________________________________________________________________________________________________________________________","metadata":{}},{"cell_type":"markdown","source":"# KNN Algorithm - Finding Nearest Neighbors \n## Dataset used :Red Wine Quality","metadata":{}},{"cell_type":"markdown","source":"________________________________________________________________________________________________________________________________","metadata":{}},{"cell_type":"markdown","source":"> This notebook is divided into two parts A and B which shows two different ways of implementing KNN <br>\n<b>PART A<b>: Implementation from scratch<br>\n<b>PART B<b>: Implementation using scikit-learn <br> ","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2021-09-01T16:02:17.721168Z","iopub.execute_input":"2021-09-01T16:02:17.721704Z","iopub.status.idle":"2021-09-01T16:02:17.734053Z","shell.execute_reply.started":"2021-09-01T16:02:17.721591Z","shell.execute_reply":"2021-09-01T16:02:17.732654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### DETAILS ABOUT THE RED WINE QUALITY DATASET","metadata":{}},{"cell_type":"code","source":"reddata = pd.read_csv('/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')","metadata":{"execution":{"iopub.status.busy":"2021-09-01T16:02:17.735994Z","iopub.execute_input":"2021-09-01T16:02:17.736485Z","iopub.status.idle":"2021-09-01T16:02:17.859705Z","shell.execute_reply.started":"2021-09-01T16:02:17.736436Z","shell.execute_reply":"2021-09-01T16:02:17.858587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reddata","metadata":{"execution":{"iopub.status.busy":"2021-09-01T16:02:17.861698Z","iopub.execute_input":"2021-09-01T16:02:17.862033Z","iopub.status.idle":"2021-09-01T16:02:17.906065Z","shell.execute_reply.started":"2021-09-01T16:02:17.862003Z","shell.execute_reply":"2021-09-01T16:02:17.905328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = reddata\ndf.describe().T","metadata":{"execution":{"iopub.status.busy":"2021-09-01T16:02:17.907409Z","iopub.execute_input":"2021-09-01T16:02:17.90789Z","iopub.status.idle":"2021-09-01T16:02:17.96176Z","shell.execute_reply.started":"2021-09-01T16:02:17.907857Z","shell.execute_reply":"2021-09-01T16:02:17.960851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-09-01T16:02:17.962977Z","iopub.execute_input":"2021-09-01T16:02:17.963273Z","iopub.status.idle":"2021-09-01T16:02:17.97602Z","shell.execute_reply.started":"2021-09-01T16:02:17.963244Z","shell.execute_reply":"2021-09-01T16:02:17.974701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reddata.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-01T16:02:17.977663Z","iopub.execute_input":"2021-09-01T16:02:17.978104Z","iopub.status.idle":"2021-09-01T16:02:18.001377Z","shell.execute_reply.started":"2021-09-01T16:02:17.978058Z","shell.execute_reply":"2021-09-01T16:02:18.000121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gb = reddata.groupby('quality')\nprint(gb.first())","metadata":{"execution":{"iopub.status.busy":"2021-09-01T16:02:18.002866Z","iopub.execute_input":"2021-09-01T16:02:18.00327Z","iopub.status.idle":"2021-09-01T16:02:18.029645Z","shell.execute_reply.started":"2021-09-01T16:02:18.003227Z","shell.execute_reply":"2021-09-01T16:02:18.028801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(reddata['quality'].head())","metadata":{"execution":{"iopub.status.busy":"2021-09-01T16:02:18.032403Z","iopub.execute_input":"2021-09-01T16:02:18.032726Z","iopub.status.idle":"2021-09-01T16:02:18.039132Z","shell.execute_reply.started":"2021-09-01T16:02:18.032696Z","shell.execute_reply":"2021-09-01T16:02:18.037903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Let us see the steps for implementing KNN\nSteps given are: \n1. <b>Handle Data:</b> Open the dataset from CSV and split into test/train datasets.\n2. <b>Similarity:</b> Calculate the distance between two data instances.\n3. <b>Neighbors:</b> Locate k most similar data instances.\n4. <b>Response:</b> Generate a response from a set of data instances.\n5. <b>Accuracy:</b> Summarize the accuracy of predictions.\n6. <b>Main:</b> Tie it all together.","metadata":{}},{"cell_type":"markdown","source":"\n\n\n## PART A: Implementation from scratch","metadata":{}},{"cell_type":"markdown","source":">","metadata":{}},{"cell_type":"code","source":"import csv\nimport random\nimport math\nimport operator","metadata":{"execution":{"iopub.status.busy":"2021-09-01T16:02:18.041055Z","iopub.execute_input":"2021-09-01T16:02:18.041472Z","iopub.status.idle":"2021-09-01T16:02:18.053726Z","shell.execute_reply.started":"2021-09-01T16:02:18.041431Z","shell.execute_reply":"2021-09-01T16:02:18.052625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## only in order to do feature scaling we are using scikit-learn\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler","metadata":{"execution":{"iopub.status.busy":"2021-09-01T16:02:18.055153Z","iopub.execute_input":"2021-09-01T16:02:18.055542Z","iopub.status.idle":"2021-09-01T16:02:18.978522Z","shell.execute_reply.started":"2021-09-01T16:02:18.055498Z","shell.execute_reply":"2021-09-01T16:02:18.976563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sc1 = MinMaxScaler()\nsc2 = StandardScaler()\n\ndef loadDataset(filename, split, trainingSet=[] , testSet=[]):\n\twith open(filename, 'r') as csvfile:\n\t    lines = csv.reader(csvfile)\n\t    dataset = list(lines)\n\t    for x in dataset[1:]:\n\t        if float(x[-1]) >6.5:\n\t            x[-1] = 1\n\t        else: \n\t            x[-1] = 0\n\t    for x in range(1,len(dataset)-1):\n\t        for y in range(11):\n\t            dataset[x][y] = float(dataset[x][y])\n\t        if random.random() < split:\n\t            trainingSet.append(dataset[x])\n\t        else:\n\t            testSet.append(dataset[x])\n\n\ndef euclideanDistance(instance1, instance2, length):\n\tdistance = 0\n\tfor x in range(length):\n\t\tdistance += pow((instance1[x] - instance2[x]), 2)\n\treturn math.sqrt(distance)\n\ndef chebyshevDistance(instance1, instance2, length):\n\tdistance = []\n\tfor x in range(length):\n\t\t#distance += pow((instance1[x] - instance2[x]), 2)\n\t\tdistance.append(abs(instance1[x] - instance2[x]))\n\treturn max(distance)\n\ndef getNeighbors(trainingSet, testInstance, k):\n\tdistances = []\n\tlength = len(testInstance)-1\n\tfor x in range(len(trainingSet)):\n\t\tdist = euclideanDistance(testInstance, trainingSet[x], length)\n\t\tdistances.append((trainingSet[x], dist))\n\tdistances.sort(key=operator.itemgetter(1))\n\tneighbors = []\n\tfor x in range(k):\n\t\tneighbors.append(distances[x][0])\n\treturn neighbors\n\ndef getNeighborsWithchebyshev(trainingSet, testInstance, k):\n\tdistances = []\n\tlength = len(testInstance)-1\n\tfor x in range(len(trainingSet)):\n\t\tdist = chebyshevDistance(testInstance, trainingSet[x], length)\n\t\tdistances.append((trainingSet[x], dist))\n\tdistances.sort(key=operator.itemgetter(1))\n\tneighbors = []\n\tfor x in range(k):\n\t\tneighbors.append(distances[x][0])\n\treturn neighbors\n\ndef getResponse(neighbors):\n\tclassVotes = {}\n\tfor x in range(len(neighbors)):\n\t\tresponse = neighbors[x][-1]\n\t\tif response in classVotes:\n\t\t\tclassVotes[response] += 1\n\t\telse:\n\t\t\tclassVotes[response] = 1\n\tsortedVotes = sorted(classVotes.items(), key=operator.itemgetter(1), reverse=True)\n\treturn sortedVotes[0][0]\n\ndef getAccuracy(testSet, predictions):\n\tcorrect = 0\n\tfor x in range(len(testSet)):\n\t\tif testSet[x][-1] == predictions[x]:\n\t\t\tcorrect += 1\n\treturn (correct/float(len(testSet))) * 100.0\n\t\ndef main():\n    # prepare data\n    trainingSet=[]\n    testSet=[]\n    split = 0.67\n    loadDataset('/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv', split, trainingSet, testSet)\n    print('Train set: %d' % len(trainingSet))\n    print('Test set: %d' % len(testSet))\n    predictions=[]\n    k = 3\n    print(\"Here we have taken : K=3  \")\n    \n    ## ACCURACY BEFORE FEATURE SCALING \n    for x in range(len(testSet)):\n        neighbors = getNeighbors(trainingSet, testSet[x], k)\n        result = getResponse(neighbors)\n        predictions.append(result)\n        #print('> predicted=' + repr(result) + ', actual=' + repr(testSet[x][-1]))\n    accuracy = getAccuracy(testSet, predictions)\n    print('Accuracy before feature scaling is done: ' + str(accuracy) + '%')\n    \n    ## ACCURACY AFTER FEATURE SCALING \n    \n    ## ACCURACY AFTER MinMax way of scaling was done\n    trainingSet=[]\n    testSet=[]\n    predictions=[]\n    loadDataset('/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv', split, trainingSet, testSet)\n    trainingSet = sc1.fit_transform(trainingSet)\n    testSet = sc1.transform(testSet)\n    for x in range(len(testSet)):\n        neighbors = getNeighbors(trainingSet, testSet[x], k)\n        result = getResponse(neighbors)\n        predictions.append(result)\n        #print('> predicted=' + repr(result) + ', actual=' + repr(testSet[x][-1]))\n    accuracy = getAccuracy(testSet, predictions)\n    print('Accuracy after Min-Max scaler was used for feature scaling: ' + str(accuracy) + '%')\n    \n    ## ACCURACY AFTER StandardScaler was used for scaling\n    trainingSet=[]\n    testSet=[]\n    predictions=[]\n    loadDataset('/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv', split, trainingSet, testSet)\n    trainingSet = sc2.fit_transform(trainingSet)\n    testSet = sc2.transform(testSet)\n    for x in range(len(testSet)):\n        neighbors = getNeighbors(trainingSet, testSet[x], k)\n        result = getResponse(neighbors)\n        predictions.append(result)\n    accuracy = getAccuracy(testSet, predictions)\n    print('Accuracy after StandardScaler was used for feature scaling: ' + str(accuracy) + '%')\n   \n\n    ## ACCURACY after chebyshev distance is used\n    trainingSet=[]\n    testSet=[]\n    predictions=[]\n    loadDataset('/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv', split, trainingSet, testSet)\n    trainingSet = sc2.fit_transform(trainingSet)\n    testSet = sc2.transform(testSet)\n    for x in range(len(testSet)):\n        neighbors = getNeighborsWithchebyshev(trainingSet, testSet[x], k)\n        result = getResponse(neighbors)\n        predictions.append(result)\n    accuracy = getAccuracy(testSet, predictions)\n    print('Accuracy after we use chebyshev distance formula: ' + str(accuracy) + '%')\n   \n    \nmain()","metadata":{"execution":{"iopub.status.busy":"2021-09-01T16:02:18.980621Z","iopub.execute_input":"2021-09-01T16:02:18.981032Z","iopub.status.idle":"2021-09-01T16:02:54.637392Z","shell.execute_reply.started":"2021-09-01T16:02:18.980985Z","shell.execute_reply":"2021-09-01T16:02:54.636387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def collectallaccuracy(k):\n   \n    trainingSet=[]\n    testSet=[]\n    split = 0.67\n    loadDataset('/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv', split, trainingSet, testSet)\n    trainingSet = sc2.fit_transform(trainingSet)\n    testSet = sc2.transform(testSet)\n   \n    predictions=[]\n    for x in range(len(testSet)):\n        neighbors = getNeighbors(trainingSet, testSet[x], k)\n        result = getResponse(neighbors)\n        predictions.append(result)\n    accur = getAccuracy(testSet, predictions)\n    return accur","metadata":{"execution":{"iopub.status.busy":"2021-09-01T16:02:54.638778Z","iopub.execute_input":"2021-09-01T16:02:54.6391Z","iopub.status.idle":"2021-09-01T16:02:54.645955Z","shell.execute_reply.started":"2021-09-01T16:02:54.639068Z","shell.execute_reply":"2021-09-01T16:02:54.644791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Accuracies = []\nprint('Let us see when standardScaler is used for feature scaling and euclidean distance is used \\nthen for different k what is the respective accuracy we obtain')\nprint()\nprint('For different K its accuracy is : ')\n\nfor i in range(1, 21):\n        val = collectallaccuracy(i)\n        Accuracies.append(val)\n        print('K = '+str(i)+' Accuracy = '+str(val))","metadata":{"execution":{"iopub.status.busy":"2021-09-01T16:02:54.647781Z","iopub.execute_input":"2021-09-01T16:02:54.64812Z","iopub.status.idle":"2021-09-01T16:07:00.374466Z","shell.execute_reply.started":"2021-09-01T16:02:54.648065Z","shell.execute_reply":"2021-09-01T16:07:00.373315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Max Accuracy we get is = \"+str(max(Accuracies))+\" at k = \"+ str(Accuracies.index(max(Accuracies))+1))","metadata":{"execution":{"iopub.status.busy":"2021-09-01T16:07:00.375872Z","iopub.execute_input":"2021-09-01T16:07:00.376162Z","iopub.status.idle":"2021-09-01T16:07:00.381618Z","shell.execute_reply.started":"2021-09-01T16:07:00.376133Z","shell.execute_reply":"2021-09-01T16:07:00.38044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":">","metadata":{}},{"cell_type":"markdown","source":">","metadata":{}},{"cell_type":"markdown","source":">","metadata":{}},{"cell_type":"markdown","source":">","metadata":{}},{"cell_type":"markdown","source":"\n>","metadata":{}},{"cell_type":"markdown","source":">","metadata":{}},{"cell_type":"markdown","source":">","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt \nplt.figure(figsize=(12, 6))\nplt.plot(range(1, 21),  Accuracies, color='green', linestyle='dashed', marker='o',\n         markerfacecolor='red', markersize=10)\nplt.title('Relationship between K and its respective accuracy')\nplt.xlabel('K Value')\nplt.ylabel('Accuracy')","metadata":{"execution":{"iopub.status.busy":"2021-09-01T16:07:00.383002Z","iopub.execute_input":"2021-09-01T16:07:00.383449Z","iopub.status.idle":"2021-09-01T16:07:00.624869Z","shell.execute_reply.started":"2021-09-01T16:07:00.383292Z","shell.execute_reply":"2021-09-01T16:07:00.62385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"___","metadata":{}},{"cell_type":"markdown","source":"\n\n\n## PART B: Implementation using scikit-learn","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nimport numpy as np \nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2021-09-01T16:07:00.62609Z","iopub.execute_input":"2021-09-01T16:07:00.626418Z","iopub.status.idle":"2021-09-01T16:07:00.835297Z","shell.execute_reply.started":"2021-09-01T16:07:00.626386Z","shell.execute_reply":"2021-09-01T16:07:00.834503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"redwine = pd.read_csv('/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')\ndf = redwine.copy()","metadata":{"execution":{"iopub.status.busy":"2021-09-01T16:07:00.836278Z","iopub.execute_input":"2021-09-01T16:07:00.836704Z","iopub.status.idle":"2021-09-01T16:07:00.851535Z","shell.execute_reply.started":"2021-09-01T16:07:00.836673Z","shell.execute_reply":"2021-09-01T16:07:00.85047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['quality'] = [1 if x>6.5 else 0 for x in df['quality']]\ny = df[\"quality\"]\nX = df.drop(\"quality\", axis=1)\nX = pd.DataFrame(X)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=40, stratify=y)","metadata":{"execution":{"iopub.status.busy":"2021-09-01T16:07:00.852601Z","iopub.execute_input":"2021-09-01T16:07:00.853003Z","iopub.status.idle":"2021-09-01T16:07:00.86511Z","shell.execute_reply.started":"2021-09-01T16:07:00.852973Z","shell.execute_reply":"2021-09-01T16:07:00.863957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn_model = KNeighborsClassifier().fit(X_train, y_train)\ny_pred = knn_model.predict(X_test)\naccuracy_score(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-09-01T16:07:00.866712Z","iopub.execute_input":"2021-09-01T16:07:00.867043Z","iopub.status.idle":"2021-09-01T16:07:00.901916Z","shell.execute_reply.started":"2021-09-01T16:07:00.867015Z","shell.execute_reply":"2021-09-01T16:07:00.901042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn_cv = GridSearchCV(KNeighborsClassifier(), {\"n_neighbors\": np.arange(1,50)}, cv=10)\nknn_cv.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-01T16:07:00.903181Z","iopub.execute_input":"2021-09-01T16:07:00.903512Z","iopub.status.idle":"2021-09-01T16:07:07.409284Z","shell.execute_reply.started":"2021-09-01T16:07:00.903483Z","shell.execute_reply":"2021-09-01T16:07:07.4082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Best score is:\" + str(knn_cv.best_score_),\"and Best params is: \" + str(knn_cv.best_params_))","metadata":{"execution":{"iopub.status.busy":"2021-09-01T16:07:07.410535Z","iopub.execute_input":"2021-09-01T16:07:07.410819Z","iopub.status.idle":"2021-09-01T16:07:07.416267Z","shell.execute_reply.started":"2021-09-01T16:07:07.410792Z","shell.execute_reply":"2021-09-01T16:07:07.415145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn = KNeighborsClassifier(2)\nknn_tuned = knn.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-01T16:07:07.41797Z","iopub.execute_input":"2021-09-01T16:07:07.418414Z","iopub.status.idle":"2021-09-01T16:07:07.431678Z","shell.execute_reply.started":"2021-09-01T16:07:07.41836Z","shell.execute_reply":"2021-09-01T16:07:07.430606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn_tuned.score(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-01T16:07:07.435866Z","iopub.execute_input":"2021-09-01T16:07:07.436224Z","iopub.status.idle":"2021-09-01T16:07:07.464772Z","shell.execute_reply.started":"2021-09-01T16:07:07.436194Z","shell.execute_reply":"2021-09-01T16:07:07.463826Z"},"trusted":true},"execution_count":null,"outputs":[]}]}