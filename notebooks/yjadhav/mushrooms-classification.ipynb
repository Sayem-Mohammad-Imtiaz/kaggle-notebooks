{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_uuid":"0649d4230d6b1b955cfe4a51e6a91156ce31cca3"},"outputs":[],"source":"import os\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nINPUT_FILE = \"mushrooms.csv\"\n\ndef load_data(file=INPUT_FILE, header=True):\n    csv_path = os.path.join(\"\", file)\n    if header:\n        return pd.read_csv(csv_path)\n    else:\n        return pd.read_csv(csv_path, header=None)\n\n\ndata = load_data(INPUT_FILE)\ndata.head()"},{"cell_type":"code","execution_count":2,"metadata":{"_uuid":"1e8b5f7dbeedeb35bf51dfc20d2e432eb49ff74d"},"outputs":[],"source":"data.info()"},{"cell_type":"code","execution_count":3,"metadata":{"_uuid":"a59ca7c8f6173c4050f2da2e4c82b67554222176"},"outputs":[],"source":"datacopy = data.copy()"},{"cell_type":"code","execution_count":4,"metadata":{"_uuid":"2f84bd91668b9d5ec74651758f0d3ce52c3fb1b6"},"outputs":[],"source":"from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n\nencoders = {}\nbinarizers = {}\nfor column in list(data):\n    encoder = LabelEncoder()\n    encoder.fit(data[column])\n    binarizer = LabelBinarizer()\n    binarizer.fit(data[column])\n    data[column] = encoder.transform(data[column])\n    encoders[column] = encoder\n    binarizers[column] = binarizer"},{"cell_type":"code","execution_count":5,"metadata":{"_uuid":"16f328e3b3f91a6b1c22262e1a70779631bc89a0"},"outputs":[],"source":"data.head()"},{"cell_type":"code","execution_count":6,"metadata":{"_uuid":"23fdb63ce77444858ecceed98c03f3391932efc5"},"outputs":[],"source":"%matplotlib inline\nimport matplotlib.pyplot as plt\ndata.hist(bins=50, figsize=(20,15))\nplt.show()"},{"cell_type":"code","execution_count":7,"metadata":{"_uuid":"a82caf8b1833e8076c950535cb3b98eec6dd1a47"},"outputs":[],"source":"corr_features = data.corr()\ncorr_features[\"class\"]"},{"cell_type":"code","execution_count":8,"metadata":{"_uuid":"188052feb06c1f26e06b2fe5b6126d8dd5dede5c"},"outputs":[],"source":"columns_removed = []\ncolumns_removed.append(\"veil-type\")"},{"cell_type":"code","execution_count":9,"metadata":{"_uuid":"06a98ef62bcbfb23ac138a05ddb113d2f99403bc"},"outputs":[],"source":"data = datacopy.copy()"},{"cell_type":"code","execution_count":10,"metadata":{"_uuid":"feb8d214c46c87a8a15332a1796412cc69e36707"},"outputs":[],"source":"from sklearn .model_selection import StratifiedShuffleSplit\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\nfor train_index, test_index in split.split(data, data[\"class\"]):\n    train_features = data.loc[train_index]\n    test_features = data.loc[test_index]\n    \ntrain_labels = train_features[\"class\"].copy().values\ntrain_features.drop(\"class\", axis=1, inplace=True)\n\ntest_labels = test_features[\"class\"].copy().values\ntest_features.drop(\"class\", axis=1, inplace=True)"},{"cell_type":"code","execution_count":11,"metadata":{"_uuid":"8409823ed408d0295e6e2eebe050e28f36fd020e"},"outputs":[],"source":"for set in (train_features, test_features):\n    for column_removed in columns_removed:\n        set.drop([column_removed], axis=1, inplace=True)"},{"cell_type":"code","execution_count":12,"metadata":{"_uuid":"41034b82de4aa1c06662198f35b748e621237d82"},"outputs":[],"source":"train_features.info()"},{"cell_type":"code","execution_count":13,"metadata":{"_uuid":"d77826135a3943caaaffb229ef00edbf2207b078"},"outputs":[],"source":"import numpy as np\n\nX = []\nX_test = []\nfor column in list(train_features):\n    if len(X) == 0:\n        X = binarizers[column].transform(train_features[column])\n        X_test = binarizers[column].transform(test_features[column])\n        continue\n        \n    X = np.concatenate((X, binarizers[column].transform(train_features[column])), axis=1)\n    X_test = np.concatenate((X_test, binarizers[column].transform(test_features[column])), axis=1)\n    \nY = binarizers[\"class\"].transform(train_labels).flatten()\nY_test = binarizers[\"class\"].transform(test_labels).flatten()"},{"cell_type":"code","execution_count":14,"metadata":{"_uuid":"5060cfe5eb9b8716513189c1ffac06b1c30aeb0a"},"outputs":[],"source":"print(np.shape(Y), np.shape(Y_test), np.shape(X), np.shape(X_test))"},{"cell_type":"code","execution_count":15,"metadata":{"_uuid":"ac801375dfa4c402b69aa0320b0726fad13550ac"},"outputs":[],"source":"from sklearn.decomposition import PCA\nimport numpy as np\n\ndef get_dims_variances(min_dim, max_dim, threshold=0.1, capToThreshold=False):\n    dims = []\n    variances = []\n    optimum_dim = min_dim\n    for dim in range(min_dim, max_dim):\n        pca = PCA(n_components=dim)\n        pca.fit(X)\n        variance = np.array(pca.explained_variance_ratio_)\n        variance = variance.min()\n        if threshold < variance:\n            optimum_dim = dim\n            dims.append(dim)\n            variances.append(variance)\n        else:\n            if capToThreshold:\n                break\n        \n    return dims, variances, optimum_dim"},{"cell_type":"code","execution_count":16,"metadata":{"_uuid":"7f8598e87a88c84b8c7079006684efe50ee4a29f"},"outputs":[],"source":"dims, variances, optimum_dim = get_dims_variances(2,  np.shape(X)[1], 0.01, capToThreshold=True)\nprint(optimum_dim)\nimport matplotlib.pyplot as plt\nplt.plot(dims, variances)\nplt.show()"},{"cell_type":"code","execution_count":17,"metadata":{"_uuid":"ee26b30e418f9edb7066b52b23891be2b3ffba8c"},"outputs":[],"source":"print(variances)"},{"cell_type":"code","execution_count":18,"metadata":{"_uuid":"fd2bccf0404a7919cc384f709b624e5765240c4d"},"outputs":[],"source":"pca = PCA(n_components=optimum_dim)\npca.fit(X)\nprint(pca.explained_variance_ratio_)\nX = pca.transform(X)\nX_test = pca.transform(X_test)"},{"cell_type":"code","execution_count":19,"metadata":{"_uuid":"3298fbe0e11d145319ec18d7bb2fc2c2ef0e7a6f"},"outputs":[],"source":"from sklearn.preprocessing import Imputer\nimputer = Imputer(strategy=\"median\")\nimputer.fit(X)\n\nX = imputer.transform(X)\nX_test = imputer.transform(X_test)"},{"cell_type":"code","execution_count":20,"metadata":{"_uuid":"8a705e3d89044c74c0dd60a0751bf11c20bc61b2"},"outputs":[],"source":"from sklearn.preprocessing import StandardScaler\n\nscalar = StandardScaler()\nscalar.fit(X)\n\nX = scalar.transform(X)\nX_test = scalar.transform(X_test)"},{"cell_type":"code","execution_count":21,"metadata":{"_uuid":"8112d9f0c88d5bda3c917f9e6a1dd824a0635ac2"},"outputs":[],"source":"print(Y)\nprint(binarizers[\"class\"].classes_)"},{"cell_type":"code","execution_count":22,"metadata":{"_uuid":"3c3597029b0f517b414ee5d231613301d1e7a8f3"},"outputs":[],"source":"from sklearn.metrics import roc_curve\nimport matplotlib.pyplot as plt\ndef plot_roc_curve(clf_sets):\n    for clf_set in clf_sets:\n        y = clf_set[0]\n        y_pred = clf_set[1]\n        label = clf_set[2]\n        fpr, tpr, thresholds = roc_curve(y, y_pred)\n        plt.plot(fpr, tpr, linewidth=1, label=label)\n    \n    plt.plot([0,1],[0,1],'k--')\n    plt.axis([0,1,0,1])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.legend(loc=\"bottom right\")\n    plt.show()"},{"cell_type":"code","execution_count":23,"metadata":{"_uuid":"d71646f44a3e6f12d3380b15d6d576e425aa4300"},"outputs":[],"source":"# SGD Classifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.model_selection import cross_val_score, cross_val_predict\nfrom sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\nfrom sklearn.base import clone\n\nclf_sets = []\nsgd_clf = SGDClassifier(random_state=42)\n\nprint(\"Cross Val Scores on training set\\n\", cross_val_score(clone(sgd_clf), X, Y, cv=3, scoring=\"accuracy\"))\nY_pred = cross_val_predict(clone(sgd_clf), X, Y, cv=3)\nprint(\"confusion_matrix\\n\", confusion_matrix(Y, Y_pred))\nprint(\"f1_score\\n\", f1_score(Y, Y_pred))\nprint(\"precision_score\\n\", precision_score(Y, Y_pred))\nprint(\"recall_score\\n\", recall_score(Y, Y_pred))\nclf_sets.append((Y, Y_pred, \"SGDClassifier-train\"))\n\nprint(\"\\n\\nCross Val Scores on testing set\\n\", cross_val_score(clone(sgd_clf), X_test, Y_test, cv=3, scoring=\"accuracy\"))\nY_test_pred = cross_val_predict(clone(sgd_clf), X_test, Y_test, cv=3)\nprint(\"confusion_matrix\\n\", confusion_matrix(Y_test, Y_test_pred))\nprint(\"f1_score\\n\", f1_score(Y_test, Y_test_pred))\nprint(\"precision_score\\n\", precision_score(Y_test, Y_test_pred))\nprint(\"recall_score\\n\", recall_score(Y_test, Y_test_pred))\nclf_sets.append((Y_test, Y_test_pred, \"SGDClassifier-test\"))\n\nsgd_clf.fit(X, Y)\nprint(\"\\n\\nAccuracy on testing data set\\n\", sum(Y_test == sgd_clf.predict(X_test)) / len(X_test))\n\nplot_roc_curve(clf_sets)\n"},{"cell_type":"code","execution_count":24,"metadata":{"_uuid":"5bc9dc8283d882e32775172f1eb4fdde617d84fb"},"outputs":[],"source":"# KNeighbors Classifier\n\nfrom sklearn.neighbors import KNeighborsClassifier \n\nknn_clf = KNeighborsClassifier()\nprint(\"Cross Val Scores on training set\\n\", cross_val_score(clone(knn_clf), X, Y, cv=3, scoring=\"accuracy\"))\nY_pred = cross_val_predict(clone(knn_clf), X, Y, cv=3)\nprint(\"confusion_matrix\\n\", confusion_matrix(Y, Y_pred))\nprint(\"f1_score\\n\", f1_score(Y, Y_pred))\nprint(\"precision_score\\n\", precision_score(Y, Y_pred))\nprint(\"recall_score\\n\", recall_score(Y, Y_pred))\nclf_sets.append((Y, Y_pred, \"KNN-train\"))\n\nprint(\"\\n\\nCross Val Scores on testing set\\n\", cross_val_score(clone(knn_clf), X_test, Y_test, cv=3, scoring=\"accuracy\"))\nY_test_pred = cross_val_predict(clone(knn_clf), X_test, Y_test, cv=3)\nprint(\"confusion_matrix\\n\", confusion_matrix(Y_test, Y_test_pred))\nprint(\"f1_score\\n\", f1_score(Y_test, Y_test_pred))\nprint(\"precision_score\\n\", precision_score(Y_test, Y_test_pred))\nprint(\"recall_score\\n\", recall_score(Y_test, Y_test_pred))\nclf_sets.append((Y_test, Y_test_pred, \"KNN-test\"))\n\nknn_clf.fit(X, Y)\nprint(\"\\n\\nAccuracy on testing data set\\n\", sum(Y_test == knn_clf.predict(X_test)) / len(X_test))\n\nplot_roc_curve(clf_sets)\n"},{"cell_type":"code","execution_count":25,"metadata":{"_uuid":"f4e8d941db41cef5eb56fd2c8747ee07ed5e87d7"},"outputs":[],"source":"# Random Forest Classifier\n\nfrom sklearn.ensemble import RandomForestClassifier \n\nforest_clf = RandomForestClassifier(random_state=42)\nprint(\"Cross Val Scores on training set\\n\", cross_val_score(clone(forest_clf), X, Y, cv=3, scoring=\"accuracy\"))\nY_pred = cross_val_predict(clone(forest_clf), X, Y, cv=3)\nprint(\"confusion_matrix\\n\", confusion_matrix(Y, Y_pred))\nprint(\"f1_score\\n\", f1_score(Y, Y_pred))\nprint(\"precision_score\\n\", precision_score(Y, Y_pred))\nprint(\"recall_score\\n\", recall_score(Y, Y_pred))\nclf_sets.append((Y, Y_pred, \"RandomForest-train\"))\n\nprint(\"\\n\\nCross Val Scores on testing set\\n\", cross_val_score(clone(forest_clf), X_test, Y_test, cv=3, scoring=\"accuracy\"))\nY_test_pred = cross_val_predict(clone(forest_clf), X_test, Y_test, cv=3)\nprint(\"confusion_matrix\\n\", confusion_matrix(Y_test, Y_test_pred))\nprint(\"f1_score\\n\", f1_score(Y_test, Y_test_pred))\nprint(\"precision_score\\n\", precision_score(Y_test, Y_test_pred))\nprint(\"recall_score\\n\", recall_score(Y_test, Y_test_pred))\nclf_sets.append((Y_test, Y_test_pred, \"RandomForest-test\"))\n\nforest_clf.fit(X, Y)\nprint(\"\\n\\nAccuracy on testing data set\\n\", sum(Y_test == forest_clf.predict(X_test)) / len(X_test))\n\nplot_roc_curve(clf_sets)\n"},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"2f30b6774fe1b187615ed4d2b51ff03b4e914975"},"outputs":[],"source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":2}