{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Spam SMS Detection using LSTM","metadata":{}},{"cell_type":"code","source":"!pip install contractions","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-02T13:31:17.091364Z","iopub.execute_input":"2021-06-02T13:31:17.091942Z","iopub.status.idle":"2021-06-02T13:31:30.787114Z","shell.execute_reply.started":"2021-06-02T13:31:17.091849Z","shell.execute_reply":"2021-06-02T13:31:30.785721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Importing the required libraries","metadata":{}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport pandas as pd\nimport numpy as np\nimport re\nimport collections\nimport contractions\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.style.use('dark_background')\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nimport warnings\nwarnings.simplefilter(action='ignore', category=Warning)\nimport keras\nfrom keras.layers import Dense, Embedding, LSTM, Dropout\nfrom keras.models import Sequential\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences","metadata":{"execution":{"iopub.status.busy":"2021-06-02T13:31:30.789231Z","iopub.execute_input":"2021-06-02T13:31:30.789686Z","iopub.status.idle":"2021-06-02T13:31:38.237964Z","shell.execute_reply.started":"2021-06-02T13:31:30.789624Z","shell.execute_reply":"2021-06-02T13:31:38.236892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Importing the spam sms dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/sms-spam-collection-dataset/spam.csv\", encoding='latin-1')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T13:31:38.239944Z","iopub.execute_input":"2021-06-02T13:31:38.24025Z","iopub.status.idle":"2021-06-02T13:31:38.303112Z","shell.execute_reply.started":"2021-06-02T13:31:38.24022Z","shell.execute_reply":"2021-06-02T13:31:38.301935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-02T13:31:38.305013Z","iopub.execute_input":"2021-06-02T13:31:38.30544Z","iopub.status.idle":"2021-06-02T13:31:38.311858Z","shell.execute_reply.started":"2021-06-02T13:31:38.305396Z","shell.execute_reply":"2021-06-02T13:31:38.310991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### There are some unwanted columns in our dataset, so we are removing it","metadata":{}},{"cell_type":"code","source":"df.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T13:31:38.313067Z","iopub.execute_input":"2021-06-02T13:31:38.313336Z","iopub.status.idle":"2021-06-02T13:31:38.32597Z","shell.execute_reply.started":"2021-06-02T13:31:38.313311Z","shell.execute_reply":"2021-06-02T13:31:38.324871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# renaming the columns\ndf.columns = [\"Spam or Ham\",\"Tweet\"]\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T13:31:42.37977Z","iopub.execute_input":"2021-06-02T13:31:42.380191Z","iopub.status.idle":"2021-06-02T13:31:42.391056Z","shell.execute_reply.started":"2021-06-02T13:31:42.380149Z","shell.execute_reply":"2021-06-02T13:31:42.389859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Plotting the value counts","metadata":{}},{"cell_type":"code","source":"sns.countplot(df[\"Spam or Ham\"])","metadata":{"execution":{"iopub.status.busy":"2021-06-02T13:31:45.238528Z","iopub.execute_input":"2021-06-02T13:31:45.238941Z","iopub.status.idle":"2021-06-02T13:31:45.406844Z","shell.execute_reply.started":"2021-06-02T13:31:45.238907Z","shell.execute_reply":"2021-06-02T13:31:45.405775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"Spam or Ham\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T13:31:46.400394Z","iopub.execute_input":"2021-06-02T13:31:46.401003Z","iopub.status.idle":"2021-06-02T13:31:46.411914Z","shell.execute_reply.started":"2021-06-02T13:31:46.400966Z","shell.execute_reply":"2021-06-02T13:31:46.410839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Creating a function for visualizing the count of words in the sms","metadata":{}},{"cell_type":"code","source":"def word_count_plot(data):\n     \n     word_counter = collections.Counter([word for sentence in data for word in sentence.split()])\n     most_count = word_counter.most_common(30)\n     \n     most_count = pd.DataFrame(most_count, columns=[\"Word\", \"Count\"]).sort_values(by=\"Count\")\n     most_count.plot.barh(x = \"Word\", y = \"Count\", color=\"green\", figsize=(10, 15))\nword_count_plot(df[\"Tweet\"])","metadata":{"execution":{"iopub.status.busy":"2021-06-02T13:31:51.249073Z","iopub.execute_input":"2021-06-02T13:31:51.249423Z","iopub.status.idle":"2021-06-02T13:31:51.68187Z","shell.execute_reply.started":"2021-06-02T13:31:51.249393Z","shell.execute_reply":"2021-06-02T13:31:51.681166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Performing data preprocessing techniques","metadata":{}},{"cell_type":"code","source":"lem = WordNetLemmatizer()\ndef preprocessing(data):\n      sms = contractions.fix(data) \n      sms = sms.lower()\n      sms = re.sub(r'https?://S+|www.S+', \"\", sms).strip() #removing url\n      sms = re.sub(\"[^a-z ]\", \"\", sms) # removing symbols and numbes\n      sms = sms.split() \n      sms = [lem.lemmatize(word) for word in sms if not word in set(stopwords.words(\"english\"))]\n      sms = \" \".join(sms)\n      return sms\nX = df[\"Tweet\"].apply(preprocessing)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T13:31:59.725783Z","iopub.execute_input":"2021-06-02T13:31:59.726146Z","iopub.status.idle":"2021-06-02T13:32:13.322366Z","shell.execute_reply.started":"2021-06-02T13:31:59.726116Z","shell.execute_reply":"2021-06-02T13:32:13.321492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Word count plotting after preprocessing techniques","metadata":{}},{"cell_type":"code","source":"word_count_plot(X)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T13:32:13.323765Z","iopub.execute_input":"2021-06-02T13:32:13.324272Z","iopub.status.idle":"2021-06-02T13:32:13.732269Z","shell.execute_reply.started":"2021-06-02T13:32:13.324223Z","shell.execute_reply":"2021-06-02T13:32:13.731518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Encoding the output variables","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlb_enc = LabelEncoder()\ny = lb_enc.fit_transform(df[\"Spam or Ham\"])","metadata":{"execution":{"iopub.status.busy":"2021-06-02T13:32:18.017938Z","iopub.execute_input":"2021-06-02T13:32:18.018493Z","iopub.status.idle":"2021-06-02T13:32:18.02564Z","shell.execute_reply.started":"2021-06-02T13:32:18.018441Z","shell.execute_reply":"2021-06-02T13:32:18.024823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Tokenizing the input text using keras tokenizer","metadata":{}},{"cell_type":"code","source":"tokenizer = Tokenizer() \ntokenizer.fit_on_texts(X)\ntext_to_sequence = tokenizer.texts_to_sequences(X) ","metadata":{"execution":{"iopub.status.busy":"2021-06-02T13:32:55.153506Z","iopub.execute_input":"2021-06-02T13:32:55.154196Z","iopub.status.idle":"2021-06-02T13:32:55.317122Z","shell.execute_reply.started":"2021-06-02T13:32:55.154141Z","shell.execute_reply":"2021-06-02T13:32:55.31631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Padding the input tokenized text sequence to make all the sequence of equal length","metadata":{}},{"cell_type":"code","source":"max_length_sequence = max([len(i) for i in text_to_sequence])\n \npadded_sequence = pad_sequences(text_to_sequence, maxlen=max_length_sequence, \n                                    padding = \"pre\") \npadded_sequence","metadata":{"execution":{"iopub.status.busy":"2021-06-02T13:33:04.675364Z","iopub.execute_input":"2021-06-02T13:33:04.675957Z","iopub.status.idle":"2021-06-02T13:33:04.733717Z","shell.execute_reply.started":"2021-06-02T13:33:04.67592Z","shell.execute_reply":"2021-06-02T13:33:04.732967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Creating the LSTM Model","metadata":{}},{"cell_type":"code","source":"VOC_SIZE = len(tokenizer.word_index)+1\ndef create_model():\n    \n      model = Sequential()\n      model.add(Embedding(VOC_SIZE, 32, input_length=max_length_sequence))\n      model.add(LSTM(100))\n      model.add(Dropout(0.4))\n      model.add(Dense(20, activation=\"relu\"))\n      model.add(Dropout(0.5))\n      model.add(Dense(1, activation = \"sigmoid\"))\n      return model\nlstm_model = create_model()\nlstm_model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\nlstm_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T13:35:14.856598Z","iopub.execute_input":"2021-06-02T13:35:14.856982Z","iopub.status.idle":"2021-06-02T13:35:15.256184Z","shell.execute_reply.started":"2021-06-02T13:35:14.856951Z","shell.execute_reply":"2021-06-02T13:35:15.255145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Training the model","metadata":{}},{"cell_type":"code","source":"lstm_model.fit(padded_sequence, y, epochs = 5, batch_size=16, validation_split=0.2)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-02T13:35:29.731773Z","iopub.execute_input":"2021-06-02T13:35:29.732274Z","iopub.status.idle":"2021-06-02T13:36:54.564719Z","shell.execute_reply.started":"2021-06-02T13:35:29.732243Z","shell.execute_reply":"2021-06-02T13:36:54.563617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Both validation and training accuracy is good.\n#### Also refer my article about sms spam detection using lstm - [here](https://www.analyticsvidhya.com/blog/2021/05/sms-spam-detection-using-lstm-a-hands-on-guide/)\n#### Do upvote if you like this notebook","metadata":{}}]}