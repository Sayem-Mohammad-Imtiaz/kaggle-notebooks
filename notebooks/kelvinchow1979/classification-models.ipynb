{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"##Import\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LogisticRegression, lars_path\nfrom sklearn import svm\nfrom sklearn.model_selection import train_test_split, KFold, GridSearchCV, cross_val_score\nfrom sklearn.metrics import precision_score, recall_score, accuracy_score, roc_auc_score, f1_score, make_scorer, confusion_matrix\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.inspection import permutation_importance\nfrom xgboost.sklearn import XGBRegressor\nfrom sklearn.naive_bayes import GaussianNB","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Data Import\ndata=pd.read_csv('../input/churn-modelling/Churn_Modelling.csv',index_col='RowNumber')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Geography.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask=np.zeros_like(data.corr())\nmask[np.triu_indices_from(mask)] = True\nf, ax = plt.subplots(figsize=(13, 5))\nsns.heatmap(data.corr(), mask=mask, cmap='seismic', annot=True, vmin=-1, vmax=1,)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data, height=1.2, aspect=1.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The Target column\ny=data['Exited']\ny.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Remove unnecessary columns for X\nX=data.drop(['CustomerId','Surname','Exited'],axis='columns')\nX.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Transform categorical date to numerical with one-hot\nX_numerical=pd.get_dummies(X)\nX_numerical.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Drop each of categorical first columns\nX_num=X_numerical.drop(['Geography_Spain','Gender_Male'],axis='columns')\nX_num.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scale all the numerical columns\nscaler=StandardScaler()\nX_scaled=scaler.fit_transform(X_num)\nX_scaled","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(pd.DataFrame(X_scaled), height=1.2, aspect=1.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Train Test Split\nX_train_val, X_test, y_train_val, y_test = train_test_split(X_scaled, y, test_size=.2, random_state=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=.25, random_state=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lasso Path\nprint(\"Computing regularization path using the LARS ...\")\nalphas, _, coefs = lars_path(X_scaled, y.values, method='lasso')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot Lasso Path\nxx = np.sum(np.abs(coefs.T), axis=1)\nxx /= xx[-1]\n\nplt.figure(figsize=(10,10))\nplt.plot(xx, coefs.T)\nymin, ymax = plt.ylim()\nplt.vlines(xx, ymin, ymax, linestyle='dashed')\nplt.xlabel('|coef| / max|coef|')\nplt.ylabel('Coefficients')\nplt.title('LASSO Path')\nplt.axis('tight')\nplt.legend(X_num.columns)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Gaussian Naive Bayes model\nnb = GaussianNB()\nnb.fit(X_train_val, y_train_val)\npredictionnb=nb.predict(X_test)\nf1_score(y_test, predictionnb), precision_score(y_test, predictionnb), recall_score(y_test, predictionnb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Logistic Regression Model\nlogit = LogisticRegression(solver= 'liblinear', C=1)\nlogit.fit(X_train_val, y_train_val)\npredictionL = logit.predict(X_test)\nconfusion_matrix(y_test, predictionL), f1_score(y_test, predictionL), precision_score(y_test, predictionL), recall_score(y_test, predictionL)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Logistic GridSearchCV\nsolver_list = ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\nparameters = dict(solver=solver_list)\nlogit = LogisticRegression(random_state=34, C=1)\nf1score=make_scorer(f1_score)\nGrid1 = GridSearchCV(logit, parameters, scoring=f1score, cv=5)\nGrid1.fit(X_train_val, y_train_val)\nGrid1.best_params_, Grid1.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Grid1.cv_results_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = Grid1.cv_results_['mean_test_score']\n\nfor score, solver, in zip(scores, solver_list):\n    print(f\"{solver}: {score:.3f}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#K Nearest Neighbor model\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train_val, y_train_val)\npredictionKn=knn.predict(X_test)\nf1_score(y_test, predictionKn),precision_score(y_test, predictionKn), recall_score(y_test, predictionKn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#KNN GridSearchCV\nknn_params={\n    'n_neighbors':[3,5,7,9,11],\n    'weights':['uniform','distance'],\n    'algorithm':['ball_tree','kd_tree','brute']\n}\nknng=GridSearchCV(KNeighborsClassifier(),knn_params,verbose=1,cv=5)\nGridK=knng.fit(X_train_val, y_train_val)\npredictionKnn=knng.predict(X_test)\nf1_score(y_test, predictionKnn), precision_score(y_test, predictionKnn), recall_score(y_test, predictionKnn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GridK.best_params_, GridK.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Linear SVC Model\nsv=svm.LinearSVC()\nsv.fit(X_train_val, y_train_val)\npredictionSV=sv.predict(X_test)\nf1_score(y_test, predictionSV),precision_score(y_test, predictionSV), recall_score(y_test, predictionSV)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#SVC Radial Model\nsvRa=svm.SVC(kernel='rbf', gamma=\"scale\")\nsvRa.fit(X_train_val, y_train_val)\npredictionSVra=svRa.predict(X_test)\nf1_score(y_test, predictionSVra), precision_score(y_test, predictionSVra), recall_score(y_test, predictionSVra)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#SVC Poly Model\nsvPoly=svm.SVC(kernel='poly', degree=4, gamma=\"scale\")\nsvPoly.fit(X_train_val, y_train_val)\npredictionSVpoly=svPoly.predict(X_test)\nf1_score(y_test, predictionSVpoly), precision_score(y_test, predictionSVpoly), recall_score(y_test, predictionSVpoly)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Random Forest Model\nrand=RandomForestClassifier(n_estimators=300)\nrand.fit(X_train_val, y_train_val)\npredictionRand=rand.predict(X_test)\nconfusion_matrix(y_test, predictionRand), f1_score(y_test, predictionRand), precision_score(y_test, predictionRand), recall_score(y_test, predictionRand)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Random Forest with adjusted threshold\nthress=0.39\npredictionRandt = (rand.predict_proba(X_test)[:,1] > thress)\nprint(\"Threshold of {:6.2f}:\".format(thress))\nprint(\"Precision: {:6.4f},   Recall: {:6.4f},   F1: {:6.4f}\".format(precision_score(y_test, predictionRandt), \n                                                     recall_score(y_test, predictionRandt),f1_score(y_test, predictionRandt)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test, predictionRandt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#XGBoost Model\nxgbr = XGBRegressor(n_estimators=300, learning_rate=0.01)\nxgbr.fit(X_train_val, y_train_val)\npredictionXgbr=xgbr.predict(X_test)\nconfusion_matrix(y_test, predictionXgbr.round()), f1_score(y_test, predictionXgbr.round()), precision_score(y_test, predictionXgbr.round()), recall_score(y_test, predictionXgbr.round())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#XGBoost GridSearchCV\nxgb1 = XGBRegressor()\nparameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n              'objective':['reg:linear'],\n              'learning_rate': [.03, 0.05, .07], #so called `eta` value\n              'max_depth': [5, 6, 7],\n              'min_child_weight': [4],\n              'silent': [1],\n              'subsample': [0.7],\n              'colsample_bytree': [0.7],\n              'n_estimators': [500]}\n\nxgb_grid = GridSearchCV(xgb1,\n                        parameters,\n                        cv = 2,\n                        n_jobs = 5,\n                        verbose=True)\n\nxgb_grid.fit(X_train_val,\n         y_train_val)\n\nprint(xgb_grid.best_score_)\nprint(xgb_grid.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#XGBoost Score\npredictionXgbrCV=xgb_grid.predict(X_test)\nprecision_score(y_test, predictionXgbrCV.round()), recall_score(y_test, predictionXgbrCV.round()), f1_score(y_test, predictionXgbrCV.round())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Feature Importance with Random Forest\nimport eli5\nfrom eli5.sklearn import PermutationImportance\nperm=PermutationImportance(rand, random_state=1).fit(X_scaled,y)\neli5.show_weights(perm, feature_names=X_num.columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Drop Less Importance Feature Columns\nX_RF=X_numerical.drop(['Geography_Spain','Gender_Male','HasCrCard','Geography_France','Gender_Female'],axis='columns')\nX_scaled_RF=scaler.fit_transform(X_RF)\nX_train_val_RF, X_test_RF, y_train_val_RF, y_test_RF = train_test_split(X_scaled_RF, y, test_size=.2, random_state=50)\nrand_F=RandomForestClassifier(n_estimators=300)\nrand_F.fit(X_train_val_RF, y_train_val_RF)\npredictionRand_F=rand_F.predict(X_test_RF)\nprecision_score(y_test_RF, predictionRand_F), recall_score(y_test_RF, predictionRand_F),f1_score(y_test_RF, predictionRand_F)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Default threshold\nthress=0.5\npredictionRand_F = (rand_F.predict_proba(X_test_RF)[:,1] > thress)\nprint(\"Threshold of {:6.2f}:\".format(thress))\nprint(\"Precision: {:6.4f},   Recall: {:6.4f},   F1: {:6.4f}\".format(precision_score(y_test_RF, predictionRand_F), \n                                                     recall_score(y_test_RF, predictionRand_F),f1_score(y_test_RF, predictionRand_F)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Optimum threshold\nthress=0.33\npredictionRand_F = (rand_F.predict_proba(X_test_RF)[:,1] > thress)\nprint(\"Threshold of {:6.2f}:\".format(thress))\nprint(\"Precision: {:6.4f},   Recall: {:6.4f},   F1: {:6.4f}\".format(precision_score(y_test_RF, predictionRand_F), \n                                                     recall_score(y_test_RF, predictionRand_F),f1_score(y_test_RF, predictionRand_F)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test_RF, predictionRand_F)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}