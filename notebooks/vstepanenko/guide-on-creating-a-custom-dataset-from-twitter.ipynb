{"cells":[{"metadata":{},"cell_type":"markdown","source":"#### The intention of this notebook is to provide the high level guidlines how to create an arbitrary dataset from twitter.\n#### As an example, a small dataset will be created, similar to the one used in [this challenge](https://www.kaggle.com/c/nlp-getting-started)."},{"metadata":{},"cell_type":"markdown","source":"Note, you will not be run this notebook as is, unless you use your access tokens (`Access Token`, `Access Token Secret`, `Consumer Key`, `Consumer Secret`).\n\nTo access to twitter api, you will need to go through the registration proccess (free, but limited access) at https://developer.twitter.com/en.\n\nAfter that you will obtain the private keys&tokens."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install twitter","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\npd.options.display.max_colwidth = 100\nimport twitter","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will start from the end: [here](https://www.kaggle.com/vstepanenko/disaster-tweets) is the dataset that has been created, following the steps described in this notebook.\nYou can find more info about the content and time of creation following that link."},{"metadata":{"trusted":true},"cell_type":"code","source":"disaster_tweets_df = pd.read_csv('../input/disaster-tweets/tweets.csv',\n                                 usecols=['keyword', 'location', 'text', 'target'])\ndisaster_tweets_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It has the same structure as in this competition and contains 11370 tweets."},{"metadata":{"trusted":true},"cell_type":"code","source":"disaster_tweets_df['target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And now we start building a new smaller dataset from twitter from scratch"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Establishing the access to twitter api\n# Here I used my twitter credentials (there are now invalidated)\n# You will need to plug in yours.\n\n# VERY IMPORTANT!\n# Regenerate/revoke your keys, if you decide to publish your version of the notebook\n\ntw={\n    'Consumer Key': 'your_consumer_key',\n    'Consumer Secret': 'your_consumer_secret',\n    'Access Token': 'your_access_token',\n    'Access Token Secret': 'your_access_secret',\n   }\n\n\nauth = twitter.oauth.OAuth(tw['Access Token'],\n                           tw['Access Token Secret'],\n                           tw['Consumer Key'],\n                           tw['Consumer Secret'])\n\ntwitter_api = twitter.Twitter(auth=auth)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Set the variable `q` to any disaster related keyword, or anything else of your interest.\n\nNote: The below cell will not run normally (`TwitterHTTPError` will be raised), unless you use your private keys.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"q = 'covid19'\nnumber = 10 # number of tweets to query\nsearch_results = twitter_api.search.tweets(q=q, count=number)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The search_results contains two keys: `statuses` (lots of details about the tweet) and `search_metadata` (info about search parameters).\n\nFrom all available data in `statuses`, we will extract only `keyword`, `location`, `text`."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(search_results.keys())\nstatuses = search_results['statuses']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here is how to extract `keyword`, `location`, `text` to replicate the structure of the dataset used in this competition.\nAlso we add column `target` and set it to `None`"},{"metadata":{"trusted":true},"cell_type":"code","source":"example_df = pd.DataFrame(\n    data=[[q, s['user']['location'], s['text'], None] for s in statuses],\n    columns = ['keyword', 'location', 'text', 'target'],\n            )\n\nexample_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's try some more keywords, and using `for-loop` to iterate over.\n\nAll keywords that could be found in `train` and `test` datasets (provided in the competition) have been reused to create [Disaster Tweets](https://www.kaggle.com/vstepanenko/disaster-tweets)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Just as example, here I use four topics.\n# Feel free to complement/ammend the list with yours.\nkeywords=['pandemic', 'lockdown', 'fire', 'crush']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def collect_tweets(keywords, count=10):\n    df = pd.DataFrame(columns=['keyword', 'location', 'text', 'target'])\n    for q in keywords:\n        search_results = twitter_api.search.tweets(q=q, count=count)\n        tmp_df = pd.DataFrame(\n            data=[[q, s['user']['location'], s['text'], None] for s in search_results['statuses']],\n             columns = ['keyword', 'location', 'text', 'target'],\n            )\n        df = df.append(tmp_df, ignore_index=True)\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We collect 20 tweets in total. 5 tweets over 4 topics.\ntweet_collection_df = collect_tweets(keywords, count=5)\ntweet_collection_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The tweets have been collected into the dataframe. It is all done!\n\nYou may want to save your work to continue to tune the collected tweets off-line."},{"metadata":{"trusted":true},"cell_type":"code","source":"tweet_collection_df.to_csv('tweet_collection_df.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls tweet_collection_df.csv -l","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}