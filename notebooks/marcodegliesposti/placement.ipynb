{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/factors-affecting-campus-placement/Placement_Data_Full_Class.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = df.drop(['sl_no'], axis=1)\n# df['status'][df['status']=='Placed']=1.0\n# df['status'][df['status']=='Not Placed']=0.0\n# df['gender'][df['gender']=='M']=1.0\n# df['gender'][df['gender']=='F']=0.0\ndf = df.replace('Placed', 1)\ndf = df.replace('Not Placed', -1)\ndf = df.replace('M', 1.0)\ndf = df.replace('F', -1.0)\ndf = pd.get_dummies(df)\ndf.fillna(0.0, inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(df['salary'][3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\ns = df.corr()\ng = s['status'].sort_values(ascending=False)\ncol = g.index[(abs(g)>0.1) & (abs(g)<1)]\ng = g[(abs(g)>0.1) & (abs(g)<1)]\nplt.figure(figsize=(20,5))\nplt.scatter(col,g)\nplt.title('Correlation with status')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,5))\nplt.bar(col,g,orientation ='vertical')\nplt.title('Correlation with status')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn \nfrom sklearn.preprocessing import MinMaxScaler\nScaler = MinMaxScaler(feature_range=(-1.0,1.0), copy=True)\ny = df['status'].values\nx_nomi = list(df.columns)\nx_nomi.remove('status')\nx = df[x_nomi].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nimport numpy as np\nfrom sklearn import linear_model\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import accuracy_score\nimport random, torch\nfrom torch.autograd import Variable\nfrom sklearn import svm\n\nclassifiers = [\n    svm.SVR(),\n    linear_model.SGDRegressor(),\n    linear_model.BayesianRidge(),\n    linear_model.LassoLars(),\n    linear_model.ARDRegression(),\n    linear_model.PassiveAggressiveRegressor(),\n    linear_model.LinearRegression()]\n\nrandom.seed(1)\nnumero_split = 10\nkf = KFold(n_splits=numero_split,random_state=1,shuffle=True)\nmae = []\nfor c in classifiers:\n    model1 = c\n    contatore = 0\n    for train_index, test_index in kf.split(x):\n        contatore += 1\n        X_train, X_test = x[train_index], x[test_index]\n        Y_train, Y_test = y[train_index], y[test_index]\n        Scaler.fit(X_train)\n        X_train, X_test = Scaler.transform(X_train),Scaler.transform(X_test)\n\n        x_train = Variable(torch.Tensor(X_train))\n        y_train = Variable(torch.Tensor(Y_train))\n        x_test = Variable(torch.Tensor(X_test))\n        y_test = Variable(torch.Tensor(Y_test))\n\n        model1.fit(x_train, y_train)\n        mae.append(accuracy_score(y_test, np.sign(model1.predict(x_test))))\n        if contatore == numero_split:\n            print('Classifiers {} has average test accuracy {}'.format(str(c),np.mean(mae)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nimport sklearn \nfrom sklearn.preprocessing import MinMaxScaler\nScaler = MinMaxScaler(feature_range=(-1.0,1.0), copy=True)\ny = df['status'].values\nx_nomi = list(df.columns)\nx_nomi.remove('status')\nx = df[x_nomi].values\n\n\ndef prev(classif):\n    if classif == 'RF':\n        model = RandomForestClassifier(random_state=0)\n    elif classif == 'GB':\n        model = GradientBoostingClassifier(n_estimators=100,max_depth=9,random_state=0)\n    elif classif == 'TREE':\n        model = DecisionTreeClassifier(random_state=0)\n    nsplit = 10\n    score = []\n    conta = 0\n    for train_index, test_index in kf.split(x):\n        conta += 1\n        X_train, X_test = x[train_index], x[test_index]\n        Y_train, Y_test = y[train_index], y[test_index]\n        Scaler.fit(X_train)\n        X_train, X_test = Scaler.transform(X_train),Scaler.transform(X_test)\n\n        x_train = Variable(torch.Tensor(X_train))\n        y_train = [i for i in Y_train]\n        x_test = Variable(torch.Tensor(X_test))\n        y_test = [i for i in Y_test]\n\n        model.fit(x_train, y_train)\n        score.append(model.score(x_test,y_test))\n        if conta == nsplit:\n            print('Average test Accuracy of {} is {}'.format(classif, np.mean(score)))\n                  \nprev('TREE')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}