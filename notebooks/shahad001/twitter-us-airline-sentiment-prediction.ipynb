{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# import packages\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Embedding, LSTM, SpatialDropout1D\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.preprocessing.text import Tokenizer\nimport re\nimport pandas as pd\npd.set_option('display.max_colwidth', -1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# read dataset\ntweets = pd.read_csv(\"../input/twitter-airline-sentiment/Tweets.csv\")\ntweets.head(4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets['tweet_len'] = tweets['text'].apply(len)\ntweets.groupby(['tweet_len', 'airline_sentiment']).size().unstack().plot(kind='line', stacked=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = tweets[['text','airline_sentiment']]\nprint(data['airline_sentiment'][:10])\n#cleaning data set. Consider only the positive and negative ones\ndata = data[data.airline_sentiment != 'neutral']\nprint(data['airline_sentiment'][:10])\nprint(data['text'][:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cleaning data set\ndata['text'] = data['text'].apply(lambda x: x.lower()) # convert all to lower\ndata['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x))) # remove anything except alphanumeric\nprint(data['text'][:10])\ndata['airline_sentiment'].value_counts().plot(kind='bar')\ndata['airline_sentiment'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#tokenization\n\nmnax_words = 1500\ntokenizer = Tokenizer(num_words=mnax_words, split=' ')\ntokenizer.fit_on_texts(data['text'].values)\nX = tokenizer.texts_to_sequences(data['text'].values)\n# print('Tokenized sentences', X[:5])\nX = pad_sequences(X)\n# print(X[:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"enbedding_out_dim = 256\nlstm_out_dim = 256\n\nmodel = Sequential()\nmodel.add(Embedding(mnax_words, enbedding_out_dim,input_length = X.shape[1]))\nmodel.add(LSTM(lstm_out_dim))\nmodel.add(Dense(2,activation='softmax'))\nmodel.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data set to train\nY = pd.get_dummies(data['airline_sentiment']).values\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.2, random_state = 50)\nprint(X_train.shape,Y_train.shape)\nprint(X_test.shape,Y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_val = X_train[:500]\nY_val = Y_train[:500]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"partial_X_train = X_train[500:]\npartial_Y_train = Y_train[500:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train the net\nbatch_size = 512\nhistory = model.fit(X_train,Y_train, \n                    epochs = 20, \n                    batch_size=batch_size,\n                    validation_data=(X_val, Y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.plot(epochs, loss, 'r', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# validation\npositive_count, negative_count, positive_correct, neg_correct = 0, 0, 0, 0\nfor x in range(len(X_val)):\n\n    result = model.predict(X_val[x].reshape(1, X_test.shape[1]), batch_size=1)[0]\n\n    if np.argmax(result) == np.argmax(Y_val[x]):\n        if np.argmax(Y_val[x]) == 0:\n            neg_correct += 1\n        else:\n            positive_correct += 1\n\n    if np.argmax(Y_val[x]) == 0:\n        negative_count += 1\n    else:\n        positive_count += 1\nprint(\"positive accuracy\", positive_correct / positive_count * 100, \"%\")\nprint(\"negative accuracy\", neg_correct / negative_count * 100, \"%\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}