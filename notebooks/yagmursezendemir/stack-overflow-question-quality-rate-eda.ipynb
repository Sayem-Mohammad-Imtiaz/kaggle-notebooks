{"cells":[{"metadata":{},"cell_type":"markdown","source":" ## Introduction \n\n\n<font color = \"blue\">\nContent:\n\n1. [Load and check Data](#1)\n2. [Variable Description](#2)\n3. [Data Preprocessing](#3)\n\n1. [MODELLING](#4)\n    * [Cross-Validation Hyperparameter Tuning](#5)\n    * [CONCLUSION](#6)\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport warnings \nwarnings.filterwarnings('ignore')\nimport seaborn as sns\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"1\"></a>\n## Load and Check Data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/60k-stack-overflow-questions-with-quality-rate/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"2\"> </a> \n## Variable Description\n\n* Id: Unique number of each questions\n* Title: The title of questions\n* Body: The questions\n* CreationDate: Which time question created\n* Y: Quality class \n    * HQ: High-quality posts with a total of 30+ score and without a single edit. (2)\n    * LQ_EDIT: Low-quality posts with a negative score, and multiple community edits. However, they still remain open after those changes. (1)\n    * LQ_CLOSE: Low-quality posts that were closed by the community without a single edit. (0)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"3\"></a>\n## Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[['Body','Y']]\ntrain = train[:10000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"Body\"] = train['Body'].str.replace('<p>','')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import string\ndef remove_punctuations(text):\n    for punctuation in string.punctuation:\n        text = text.lower().replace(punctuation, '')\n    return text\ntrain[\"Body\"] = train['Body'].apply(remove_punctuations)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain.loc[train['Y'] == 'LQ_CLOSE', 'Y'] = 0\ntrain.loc[train['Y'] == 'LQ_EDIT', 'Y'] = 1\ntrain.loc[train['Y'] == 'HQ', 'Y'] = 2\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Y = train.Y.astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Y.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = train.Y).set_title('Category')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\nimport re\nimport nltk as nlp\nnltk.download('stopwords') \nnltk.download('punkt')\nnltk.download('wordnet') \n\nlemma = nlp.WordNetLemmatizer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntext_list = []\nfor description in train.Body:\n    \n    description = re.sub('[^a-zA-Z]',' ',description)\n    #description = description.lower()\n    description = nltk.word_tokenize(description)\n    #description = [ word for word in description if not word in set(stopwords.words('english'))]\n    #lemma = nlp.WordNetLemmatizer()\n    #description = [lemma.lemmatize(word)for word in description]\n    description = ' '.join(description)\n    text_list.append(description)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(text_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nmax_features = 300\n\ncount_vectorizer = CountVectorizer(max_features=max_features,stop_words = \"english\")\n\nspace_matrix = count_vectorizer.fit_transform(text_list).toarray()  # x\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"space_matrix.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = '4'></a>\n## MODELLING"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train.iloc[:,1].values   \nx = space_matrix\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(x,y, test_size = 0.1, random_state = 42)\nprint('X_train shape', X_train.shape)\nprint('X_test shape', X_test.shape)\nprint('y_train shape', y_train.shape)\nprint('y_test shape', y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"5\"></a>\n## Cross-Validation  Hyperparameter Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Libraries\n\nfrom sklearn.linear_model import  LogisticRegression\nfrom sklearn.ensemble import RandomForestRegressor , RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nrandom_state = 42\nclassifier = [LogisticRegression(random_state = random_state),\n                  RandomForestClassifier(random_state = random_state),\n                  DecisionTreeClassifier(),\n                  KNeighborsClassifier()]\n\nlogreg_param_grid = {'C': np.logspace(-3,3,7),\n                    'penalty': ['l1','l2']}\n\n\nrf_param_grid = rf_param_grid = {'max_features':[1,5],\n                'min_samples_split': [2,3],\n                'min_samples_leaf':[1,3],\n                'bootstrap':[False],\n                'n_estimators':[100],\n                'criterion': ['gini']}\n\ndt_param_grid = {'min_samples_split': range(10,50,2),\n                'max_depth': range(1,10,2)}\n\nknn_param_grid = {'n_neighbors': np.linspace(1,6,2, dtype = int).tolist()}\n\nclassifier_param = [logreg_param_grid ,rf_param_grid,dt_param_grid, knn_param_grid]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold,GridSearchCV\nfrom sklearn.metrics import accuracy_score \ncv_results = []\nbest_estimators = []\nfor i in range(len(classifier)):\n    clf = GridSearchCV(classifier[i],param_grid= classifier_param[i],cv = StratifiedKFold(n_splits = 10),scoring = 'accuracy',n_jobs = -1,verbose = 1)\n    clf.fit(X_train,y_train)\n    cv_results.append(clf.best_score_)\n    best_estimators.append(clf.best_estimator_)\n    print(cv_results[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = '6'></a>\n## CONCLUSION"},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_result = pd.DataFrame({'Cross Validation Means': cv_results, 'ML Models': ['LogisticRegression',\n              'RandomForestClassifier',\n              'DecisionTreeClassifier',\n              'KNeighborsClassifier'\n                ] })\n\ng = sns.barplot('Cross Validation Means','ML Models',data = cv_result)\ng.set_xlabel('Mean Accuracy')\ng.set_title('Cross Validation Scores')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_estimators","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}