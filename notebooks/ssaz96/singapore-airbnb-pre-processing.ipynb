{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Singapore Airbnb"},{"metadata":{},"cell_type":"markdown","source":"## Part 1: Cleaning"},{"metadata":{"trusted":false},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom scipy import stats","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def describe_attribute(df,x):\n    print(df[x].value_counts().sort_values())\n    print('NA values count: ', df[x].isna().sum())\n    print('Unique values count: ', df[x].nunique())\n    print('Data Type: ', df[x].dtype)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def detect_outlier(data_1):\n    threshold = 3\n    mean_1 = np.mean(data_1)\n    std_1 = np.std(data_1)\n    \n    for y in data_1:\n        z_score= (y - mean_1)/std_1 \n        if np.abs(z_score) > threshold:\n            outliers.append(y)\n    return outliers","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df = pd.read_csv('singapore_airbnb_dirty_data.csv')\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#check missing values in data\ndf.isnull().sum().sort_values(ascending=True)\n# df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Count of unique values in each attribute\ndf.nunique().sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Missing values in name column: 44\n# Strange values in name column:  Fix case, remove extra spaces and characters. Number and Letters.\ndf['name'] = df['name'].apply(lambda x: str(x).capitalize().strip().replace('@', ' at ').replace('  ', ' '))\n\n# Fill with concatenated neighbourhood and room_type\ndf['name'].fillna(str(df['neighbourhood'] +\" \"+  df['room_type']).capitalize(), inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Remove string values in id column\n# df['id'] = pd.to_numeric(df['id'],  downcast='integer' ,errors='coerce')\n# Missing values in id column: 12\n# df['id1'].isna().sum()\n\n# Drop Column\ndf.drop('id', axis = 1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# df['host_id'].nunique() #2707 values\n\n# Remove date values in host_id column\ndf['host_id'] = pd.to_numeric(df['host_id'],  downcast='integer' ,errors='coerce')\ndf['host_id'].isna().sum()\ndf['host_id'].fillna('-1', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Strange values in host_name column : Encoding issue\n# Incomplete name values in host_name column\ndf['host_name'] = df['host_name'].str.capitalize()\n# Remove Numbers from Host Name\ndf['host_name'] = df['host_name'].str.replace(r\"\\d\", \"\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Missing values in room_type column\ndf['room_type'].fillna(df['room_type'].value_counts().idxmax(), inplace=True)\n\n# Numbers in room_type column\nvc = df['room_type'].value_counts() \n# Get value_counts with occurrence < 2\nvc = vc[vc < 2]\n# Replace these values with mode.\ndf['room_type'].replace(vc.index.tolist(), df['room_type'].value_counts().idxmax(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Negative values in price column : Take absolute\ndf['price']= df['price'].apply(lambda x: np.abs(x))\n\n# Potential outliers in price column\nimport seaborn as sns\n%matplotlib inline\n\nsns.boxplot(x = df['price'])\ndf['price'].describe()\n\n# sns.boxplot(x = df[df['price'] < 500]['price'])\n# df[df['price'] < 500]['price'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Predict outliers in price\ndf['price'] = np.abs(df['price'])\nprice_df = (df['price'])\noutliers=[]\n\n# these are valid prices how ever they are special cases so we drop these values.\noutlier_datapoints = detect_outlier(price_df)\nprint(np.sort(outlier_datapoints))\n\n# replace outliers with nan\n# df['price'].replace(outlier_datapoints, np.nan, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# String values in minimum_nights column\ndf['minimum_nights'] = pd.to_numeric(df['minimum_nights'], errors='coerce', downcast='integer')\n\n# Missing values in minimum_nights column\ndf['minimum_nights'].fillna(1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Convert to datetime\ndf['last_review'] = pd.to_datetime(df['last_review'], errors='coerce')\n\n# Missing values in last_review column : 1990-01-01\ndf['last_review'].fillna('1990-01-01', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Missing values in reviews_per_month column : 0\ndf['reviews_per_month'].fillna(0.0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Negative values in calculated_host_listings_count column\ndf_copy = df.copy()\n\n# Calculate count of each host_id \ncount_df = df_copy.groupby('host_id').size().to_frame().reset_index()\n\n# Merge the output and rename column\ndf_copy = pd.merge(df_copy, count_df, left_on='host_id', right_on='host_id')\ndf_copy = df_copy.drop('calculated_host_listings_count', axis = 1)\ndf_copy.rename(columns={0: 'calculated_host_listings_count'}, inplace=True)\ndf = df_copy","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Missing values in availability_365 column\ndf['availability_365'] = pd.to_numeric('availability_365', errors='coerce', downcast='integer')\ndf['availability_365'].fillna('0', inplace=True)\ndf['availability_365'] = df['availability_365'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Check for potential dirty values in the remaining columns as well (latitude, longitude, number_of_reviews)\ndescribe_attribute(df, 'number_of_reviews')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Missing values in neighbourhood_group column\n# describe_attribute(df, 'neighbourhood_group')\n\n# Part 1: Eport unique rows where neighbourhood_group is na\ndf_temp = df[['neighbourhood_group', 'neighbourhood']].drop_duplicates()\ndf_temp = df_temp[df_temp['neighbourhood_group'].isna()]\n# df_temp.to_csv('neighbourhood_group_mappings.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Part 2: Read as dictionary\ndf_temp = df.copy()\ndf_neighbourhood_group = pd.read_csv('neighbourhood_group_mappings.csv');\ndict_neighbourhood_group = df_neighbourhood_group.set_index('neighbourhood').to_dict()['neighbourhood_group']\ndict_neighbourhood_group.get('Outram')\n\n# Copy the neighbourhood where neighbourhood_group is na.\ndf_temp['neighbourhood_group'].fillna(df_temp['neighbourhood'], inplace=True)\n# Replace with dictionary\ndf_temp['neighbourhood_group'].replace(dict_neighbourhood_group,regex=False,inplace=True)\ndescribe_attribute(df_temp, 'neighbourhood_group')\ndf = df_temp","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Missing values in neighbourhood column\n# describe_attribute(df, 'neighbourhood')\n\nfrom geopy.geocoders import Nominatim\nfrom geopy.extra.rate_limiter import RateLimiter\n\ngeolocator = Nominatim(user_agent=\"singapore_airbnb_cleaning\",timeout=2)\nlocation = geolocator.reverse('1.31267,103.87457')\nprint(location.raw.get('address').get('suburb'))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(action='once')\n\nreverse = RateLimiter(geolocator.reverse, min_delay_seconds=1)\n\ndef geodecode(la, ln):\n    return reverse((str(la)+','+str(ln)), language='en')\n\ndf_copy = df.copy()\ndf_copy2 = df_copy[df_copy['neighbourhood'].isna()]\n\n# Fetch addresses where neighbourhood is na.\nfor index, row in df_copy2.iterrows():\n    df_copy2.at[index,'neighbourhood'] = geodecode(row['latitude'],row['longitude']).raw.get('address').get('suburb')\n\ndf_copy.loc[df_copy['neighbourhood'].isna() , 'neighbourhood'] = df_copy2['neighbourhood'].apply(lambda x: x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# df_copy.loc[df_copy['neighbourhood'].str.contains(',')]['neighbourhood'].tolist()\n# df_copy['neighbourhood'].isna().sum()\n\n# Check Where none is\ndf_copy.loc[df_copy['neighbourhood'].isna()] \n# Fill single value to Boon Keng (Google coordinates)\ndf_copy['neighbourhood'] = df_copy['neighbourhood'].fillna('Boon Keng')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# df_copy['neighbourhood'].unique().tolist()\n# df_copy['neighbourhood'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Final Check\ndf_copy.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Export \ndf_copy.to_csv('singapore_airbnb_clean_data.csv', index_label='row_id')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":4}