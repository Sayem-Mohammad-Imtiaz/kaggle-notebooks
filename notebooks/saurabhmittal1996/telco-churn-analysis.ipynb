{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Importing all the Libraries","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Importing Required Library\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#SMOTE to balance the Imbalance Data\nfrom imblearn.over_sampling import SMOTE\n\n#for Spliting Data and Hyperparameter Tuning \nfrom sklearn.model_selection import train_test_split, GridSearchCV\n\n#Importing Machine Learning Model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import BernoulliNB\nfrom catboost import CatBoostClassifier\nfrom sklearn import svm\nfrom sklearn.neural_network import MLPClassifier\n\n#Bagging Algo\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n\n#To tranform data\nfrom sklearn import preprocessing\n\n#statistical Tools\nfrom sklearn.metrics import roc_auc_score,accuracy_score,precision_score,recall_score,f1_score\nfrom sklearn.metrics import confusion_matrix, roc_curve, auc, plot_confusion_matrix\n\n#Setting Format\npd.options.display.float_format = '{:.5f}'.format\npd.options.display.max_columns = None\npd.options.display.max_rows = None","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Importing Data","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lets get some Insight in our data ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe(include='all').T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(data['Churn'].value_counts()/data.shape[0]).plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets Convert Churn column into Numerical data\ndata['Churn'] = data['Churn'].map({'Yes':1, 'No':0})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Churn'] = data['Churn'].astype('int')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let check for missing values or nan","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data==0].sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Description","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in data.columns:\n    print(i,'(', data[i].dtype, ')' ,\": Distinct Values\")\n    print(data[i].nunique(), \"Total Unique Values\")\n    print(data.shape[0], \"Total Values\")\n    print(data[i].unique())\n    print(\"-\"*30)\n    print(\"\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let's Transform Our data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Senior Citizen should be int dtype lets change it to object\n#This Columns means whether or not customer is Senior so it should be Object Type \ndata['SeniorCitizen'] = data['SeniorCitizen'].astype(object)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Total Charges should be numeric not object\n\ndata['TotalCharges'] = pd.to_numeric(data['TotalCharges'], errors='coerce')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now after converting TotalCharges to Numerical value we now have 11 Nan Values lets dive into it","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data.isna().any(axis=1)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All the data with nan value does not leave our company, are dependents,they are not senior citizens and doesn't have any tenure.\n\nLets fill them with Monthly Charges","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = data[data.isna().any(axis=1)]\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['TotalCharges'] = df['MonthlyCharges']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.concat([data,df],ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dropna(inplace=True)\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualization","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=data['SeniorCitizen'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in data.select_dtypes(include='O'):\n    sns.countplot(data[i])\n    plt.xticks(rotation = 90)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in data.select_dtypes(exclude='O'):\n    sns.distplot(data[i], bins=10)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['tenure'] = np.log1p(data['tenure'])\ndata['MonthlyCharges'] = np.log1p(data['MonthlyCharges'])\ndata['TotalCharges'] = np.log1p(data['TotalCharges'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in data.select_dtypes(exclude='O'):\n    sns.distplot(data[i], bins=10)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets drop customerID as it will always be Unique and Doesn't add any value to our Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(['customerID'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_col = data.select_dtypes(include=\"O\").columns\ncat_col","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = data.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.get_dummies(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(24,12))\nsns.heatmap(df.corr())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()['Churn'].sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop(['Churn'], axis=1)\ny = df['Churn']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let's balance our Imbalance Dataset using SMOTE","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sm = SMOTE(random_state=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_tf,y_tf = sm.fit_resample(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = preprocessing.RobustScaler()\ndf_x = scaler.fit_transform(X_tf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Spliting our data into Train and Validation set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using Skicit-learn to split data into training and testing sets \n# Split the data into training and testing sets \nx_train,x_test,y_train,y_test = train_test_split(df_x,y_tf,test_size=.2, random_state = 100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Importing ML Models","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression(C=5.0)\nknn = KNeighborsClassifier(weights='distance', algorithm='auto', n_neighbors=15)\nrfc = RandomForestClassifier(n_estimators=200,criterion='gini', n_jobs=-1)\ndtc = DecisionTreeClassifier()\nbnb = BernoulliNB()\nxgb = XGBClassifier(n_jobs=-1)\ncat = CatBoostClassifier(verbose=0)\nada = AdaBoostClassifier()\ngbc = GradientBoostingClassifier()\nsvc = svm.SVC(kernel = 'poly', C=4, gamma='scale', degree = 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model):\n    # Checking accuracy\n    model = model.fit(x_train, y_train)\n    pred = model.predict(x_test)\n    print('accuracy_score',accuracy_score(y_test, pred)*100)\n    print('precision_score',precision_score(y_test, pred)*100)\n    print('recall_score',recall_score(y_test, pred)*100)\n    print('f1_score',f1_score(y_test, pred)*100)\n    print('roc_auc_score',roc_auc_score(y_test, pred)*100)\n    # confusion matrix\n    print('confusion_matrix')\n    print(pd.DataFrame(confusion_matrix(y_test, pred)))\n    fpr, tpr, threshold = roc_curve(y_test, pred)\n    roc_auc = auc(fpr, tpr)*100\n\n    plt.title('Receiver Operating Characteristic')\n    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n    plt.legend(loc = 'lower right')\n    plt.plot([0, 1], [0, 1],'r--')\n    plt.xlim([0, 1])\n    plt.ylim([0, 1])\n    plt.ylabel('True Positive Rate')\n    plt.xlabel('False Positive Rate')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_model(lr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_model(dtc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_model(rfc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_model(xgb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_model(ada)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_model(gbc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_model(cat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_model(bnb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_model(knn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mlp = MLPClassifier()\ntrain_model(mlp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_model(svc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Confusion Matrix's","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicted values\ny_head_lr = lr.predict(x_test)\ny_head_rfc = rfc.predict(x_test)\ny_head_xgb = xgb.predict(x_test)\ny_head_ada = ada.predict(x_test)\ny_head_dtc = dtc.predict(x_test)\ny_head_gbc = gbc.predict(x_test)\ny_head_cat = cat.predict(x_test)\ny_head_knn = knn.predict(x_test)\ny_head_nb = bnb.predict(x_test)\ny_head_mlp = mlp.predict(x_test)\ny_head_svm = svc.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ncm_lr = confusion_matrix(y_test,y_head_lr)\ncm_rfc = confusion_matrix(y_test,y_head_rfc)\ncm_xgb = confusion_matrix(y_test,y_head_xgb)\ncm_ada = confusion_matrix(y_test,y_head_ada)\ncm_dtc = confusion_matrix(y_test,y_head_dtc)\ncm_gbc = confusion_matrix(y_test,y_head_gbc)\ncm_cat = confusion_matrix(y_test,y_head_cat)\n\ncm_knn = confusion_matrix(y_test,y_head_knn)\ncm_nb = confusion_matrix(y_test,y_head_nb)\ncm_mlp = confusion_matrix(y_test,y_head_mlp)\ncm_svm = confusion_matrix(y_test,y_head_svm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30,20))\n\nplt.suptitle(\"Confusion Matrixes\",fontsize=24)\nplt.subplots_adjust(wspace = 0.4, hspace= 0.4)\n\nplt.subplot(4,3,5)\nplt.title(\"Logistic Regression Confusion Matrix\")\nsns.heatmap(cm_lr,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False, annot_kws={\"size\": 24})\n\nplt.subplot(4,3,6)\nplt.title(\"K Nearest Neighbors Confusion Matrix\")\nsns.heatmap(cm_knn,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False, annot_kws={\"size\": 24})\n\nplt.subplot(4,3,2)\nplt.title(\"XGB Confusion Matrix\")\nsns.heatmap(cm_xgb,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False, annot_kws={\"size\": 24})\n\n\nplt.subplot(4,3,4)\nplt.title(\"Naive Bayes Confusion Matrix\")\nsns.heatmap(cm_nb,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False, annot_kws={\"size\": 24})\n\nplt.subplot(4,3,11)\nplt.title(\"Decision Tree Classifier Confusion Matrix\")\nsns.heatmap(cm_dtc,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False, annot_kws={\"size\": 24})\n\nplt.subplot(4,3,1)\nplt.title(\"Random Forest Gini Confusion Matrix\")\nsns.heatmap(cm_rfc,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False, annot_kws={\"size\": 24})\n\nplt.subplot(4,3,7)\nplt.title(\"CatBooost Confusion Matrix\")\nsns.heatmap(cm_cat,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False, annot_kws={\"size\": 24})\n\n\nplt.subplot(4,3,8)\nplt.title(\"Ada Boost Confusion Matrix\")\nsns.heatmap(cm_ada,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False, annot_kws={\"size\": 24})\n\nplt.subplot(4,3,9)\nplt.title(\"Gradient boost Classifier Confusion Matrix\")\nsns.heatmap(cm_gbc,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False, annot_kws={\"size\": 24})\n\nplt.subplot(4,3,10)\nplt.title(\"MLP CLassifier Confusion Matrix\")\nsns.heatmap(cm_mlp,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False, annot_kws={\"size\": 24})\n\nplt.subplot(4,3,3)\nplt.title(\"Support Vector CLassifier Confusion Matrix\")\nsns.heatmap(cm_svm,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False, annot_kws={\"size\": 24})\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# HyperParameter Tuning","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We will use Random Forest Classifer as it is giving Good Accuracy and it gives less error rate as it has 171 False Positive and 123 False Negative which is less than all other Alogorithms","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nmax_feature = ['auto', 'sqrt']\n\nn_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [1, 2, 5, 10]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\n\ngrid = GridSearchCV(rfc, random_grid, cv=3, verbose=True, n_jobs=-1)\ngrid.fit(x_train, y_train)'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc_1 = RandomForestClassifier(bootstrap=False, max_depth=90, max_features='auto',\n                              min_samples_leaf=2, min_samples_split=5, n_estimators=600, )\n\ntrain_model(rfc_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}