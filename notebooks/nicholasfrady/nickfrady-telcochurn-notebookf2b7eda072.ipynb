{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport xgboost as xgb\nfrom sklearn import model_selection\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.metrics import plot_confusion_matrix\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv')\ndf = df.set_index('customerID')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Illustrates the data types in the Telco data","metadata":{}},{"cell_type":"code","source":"def utils_recognize_type(dtf, col, max_cat=20):\n    if (dtf[col].dtype == \"O\") | (dtf[col].nunique() < max_cat):\n        return \"cat\"\n    else:\n        return \"num\"\n    \ndic_cols = {col:utils_recognize_type(df, col, max_cat=20) for col in df.columns}\nheatmap = df.isnull()\n#print(heatmap)\nfor k,v in dic_cols.items():\n if v == \"num\":\n   heatmap[k] = heatmap[k].apply(lambda x: 0.5 if x is False else 1)\n else:\n   heatmap[k] = heatmap[k].apply(lambda x: 0 if x is False else 1)\n   \nsns.heatmap(heatmap, cbar=False).set_title('Dataset Overview')\n\nplt.show()\n\nprint(\"\\033[1;37;40m Categerocial \", \"\\033[1;30;41m Numeric \", \"\\033[1;30;47m NaN \")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Total charges columns has some whitespace in the column- only occurs when tenure = 0 meaning the customer hasn't been billed yet, so we make totalcharges=0.0","metadata":{}},{"cell_type":"code","source":"df.loc[(df['TotalCharges'] == ' '), 'TotalCharges'] = 0\ndf.loc[df['tenure'] == 0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['TotalCharges'] = pd.to_numeric(df['TotalCharges']) #make sure the TotalCharges column is actually a number\ndf.replace(' ', '_', regex=True, inplace = True) #replace all the white space in the entire dataframe\n\ndf['Churn_value'] = np.where(df['Churn'] == 'Yes', 1, 0)\ndf.drop('Churn', axis =1, inplace = True)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create training data dataframe","metadata":{}},{"cell_type":"code","source":"X = df.drop('Churn_value', axis = 1).copy()\nX.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create y value series","metadata":{}},{"cell_type":"code","source":"y = df['Churn_value'].copy()\ny.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Select all the columns of the X dataframe that are objects. We are going to One-hot encode these columns","metadata":{}},{"cell_type":"code","source":"df_object = df.select_dtypes(exclude=[np.number])\ndf_object.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_encoded = pd.get_dummies(X, columns = df_object.columns)\nX_encoded","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"26.5% of customers leave","metadata":{}},{"cell_type":"code","source":"sum(y)/ len(y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will split using stratification in order to maintain the same percentage of people who left in both the training and test set","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, random_state = 42, stratify = y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our training and test datasets retain the same percentage of customers who leave","metadata":{}},{"cell_type":"code","source":"sum(y_train)/ len(y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sum(y_test)/ len(y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf_xgb = xgb.XGBClassifier(objective='binary:logistic', seed = 42)\nclf_xgb.fit(X_train,y_train, verbose = False, eval_metric='aucpr', eval_set=[(X_test,y_test)])\nplot_confusion_matrix(clf_xgb,X_test,y_test,values_format = 'd',display_labels=['Did not leave','Left'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We correctly identify ~50% of customers that leave ","metadata":{}},{"cell_type":"code","source":"(237 / 467)* 100","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Round 2\nparam_grid1 = {\n    'max_depth': [3,4],\n    'learning_rate': [0.01,0.05,0.03],\n    'gamma': [0.25,1.0,1.5],\n    'reg_lamda': [0],\n    'scale_pos_weight': [3,4,5]\n}\n\noptimal_params = GridSearchCV(\n    estimator=xgb.XGBClassifier(objective='binary:logistic',\n    seed = 42,\n    use_label_encoder=False,\n    subsample=0.9,\n    colsample_bytree=0.5),\n    param_grid=param_grid1,\n    scoring='roc_auc',\n    verbose=0,\n    n_jobs=10,\n    cv=3\n)\n\n\"\"\" optimal_params.fit(\n    X_train,\n    y_train,\n    early_stopping_rounds = 10,\n    eval_metric='auc',\n    eval_set=[(X_test, y_test)],\n    verbose = False)\n \"\"\"\noptimal_params.fit(X_train,y_train)\nprint(optimal_params.best_params_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf_xgb = xgb.XGBClassifier(\n    seed=42,\n    objective='binary:logistic',\n    gamma = 0.25,\n    learn_rate = 0.05,\n    max_depth=3,\n    reg_lamda = 0,\n    scale_pos_weight = 3,\n    subsample =0.9,\n    colsample_bytree=0.5)\n\nclf_xgb.fit(\n    X_train,\n    y_train,\n    verbose=False,\n    early_stopping_rounds=10,\n    eval_metric='aucpr',\n    eval_set=[(X_test,y_test)])\n\nplot_confusion_matrix(clf_xgb,X_test,y_test,values_format = 'd',display_labels=['Did not leave','Left'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We caught 82% of the people that left.","metadata":{}},{"cell_type":"code","source":"(1- (85/467))*100","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}