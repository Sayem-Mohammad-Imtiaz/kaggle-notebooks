{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"f55bc919-8bc8-f603-26eb-8ac71e1ebab0"},"source":"This is a fork of the script [here](https://www.kaggle.com/kinguistics/d/crowdflower/twitter-user-gender-classification/classifying-user-gender-based-on-tweet-text) - I wanted to look at some other models like Logistic Regresion and tree-based models. Also I wanted to look at the coefficients in the Logistic Regssion and see what words it finds to be predictive of different genders.\n--------------------------------------------------------------------------------------------"},{"cell_type":"markdown","metadata":{"_cell_guid":"c9b0c7e7-85bf-cd39-f3da-6c8e8148cdad"},"source":"Crowdflower's [post](https://www.crowdflower.com/using-machine-learning-to-predict-gender/) on this dataset is pretty lacking in details about what kind of model they used to predict Twitter user gender. All they say about it is \"we ran the tweets through our AI feature\", and that they achieved about 60% accuracy on their three-way (male, female, brand/organization) classification task.\n\nLet's see how well we can do in a quick run-through.\n\nI'm going to crib a lot of code from [my notebook on classifying types of news](https://www.kaggle.com/kinguistics/d/uciml/news-aggregator-dataset/classifying-news-headlines-with-scikit-learn)."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7b039c5f-8f85-27ab-d378-316822cd4e73"},"outputs":[],"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# we'll want this for plotting\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# we'll want this for text manipulation\nimport re\n\n# for quick and dirty counting\nfrom collections import defaultdict\n\n# the Naive Bayes model\nfrom sklearn.naive_bayes import MultinomialNB\n# function to split the data for cross-validation\nfrom sklearn.model_selection import train_test_split\n# function for transforming documents into counts\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n# function for encoding categories\nfrom sklearn.preprocessing import LabelEncoder\n\n# have to use latin1 even though it results in a lot of dead characters\ntwigen = pd.read_csv(\"../input/gender-classifier-DFE-791531.csv\", encoding='latin1')\ntwigen.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"67c516df-2b1d-7368-08c0-c703ad2e7ac1"},"outputs":[],"source":"def normalize_text(s):\n    # just in case\n    s = str(s)\n    s = s.lower()\n    \n    # remove punctuation that is not word-internal (e.g., hyphens, apostrophes)\n    s = re.sub('\\s\\W',' ',s)\n    s = re.sub('\\W\\s',' ',s)\n    \n    # make sure we didn't introduce any double spaces\n    s = re.sub('\\s+',' ',s)\n    \n    return s\n\ntwigen['text_norm'] = [normalize_text(s) for s in twigen['text']]\ntwigen['description_norm'] = [normalize_text(s) for s in twigen['description']]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a32707af-fd43-ef73-70db-08ca98854e34"},"outputs":[],"source":"twigen.shape"},{"cell_type":"markdown","metadata":{"_cell_guid":"85c37765-50d9-fc8d-e955-eba6e53d2189"},"source":"Let's grab some info about the gold standard and about the dataset's confidence in its gender classifications so we have some idea of what would be good to train on."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"89ab3525-95ba-a8fd-9014-622176c85519"},"outputs":[],"source":"\n# how many observations are gold standard?\ngold_values = defaultdict(int)\nfor val in twigen._golden:\n    gold_values[val] += 1\nprint(gold_values)\n\n# what does the confidence look like?\nprint(np.any(np.isnan(twigen['gender:confidence'])))\n# we've got at least one NaN, so let's remove\ngender_confidence = twigen['gender:confidence'][np.where(np.invert(np.isnan(twigen['gender:confidence'])))[0]]\nprint(len(gender_confidence))\ngender_nonones = gender_confidence[np.where(gender_confidence < 1)[0]]\nprint(len(gender_nonones))"},{"cell_type":"markdown","metadata":{"_cell_guid":"18b37850-d415-84bc-d5ed-2c741596251e"},"source":"About 30% of the observations have less than 100% confidence in the gender classification, so we'll ignore those."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"030e3477-1b9a-1eb9-07ab-250caf6699f5"},"outputs":[],"source":"twigen_confident = twigen[twigen['gender:confidence']==1]\ntwigen_confident.shape"},{"cell_type":"markdown","metadata":{"_cell_guid":"5a025ca5-8cb0-5a65-7ff0-e524925eaf62"},"source":"Let's look at the distribution of the labels:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b81b0412-7965-c6e9-c1db-adb7724b1632"},"outputs":[],"source":"gender_counts= twigen_confident['gender'].value_counts()\ngender_counts/sum(gender_counts)"},{"cell_type":"markdown","metadata":{"_cell_guid":"e5e89758-003c-505f-2a53-38b6b0e9a570"},"source":"Okay, now let's see how well a Naive Bayes classifier can do by just looking at the words in the randomly chosen tweet."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fd7f2412-6c0e-287e-314e-fd687982840e"},"outputs":[],"source":"# pull the data into vectors\nvectorizer = TfidfVectorizer(min_df=3)\nx = vectorizer.fit_transform(twigen_confident['text_norm'])\n\nencoder = LabelEncoder()\ny = encoder.fit_transform(twigen_confident['gender'])\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"45e94b01-77da-62f9-78a4-8703b85fe216"},"outputs":[],"source":"encoder.classes_"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e63bf949-7e96-45d6-ed57-5e664ec3daae"},"outputs":[],"source":"x.shape"},{"cell_type":"markdown","metadata":{"_cell_guid":"7c39d5cb-462b-290a-5433-afeb5d54f8cc"},"source":"Let's set a random state here and stratify the validation since the classes are slightly unbalanced:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7d5d13cf-28ed-0654-da47-e6aa770b2635"},"outputs":[],"source":"# split into train and test sets\nx_train, x_test, y_train, y_test = train_test_split(x, y,\n                                                    test_size=0.2,\n                                                    stratify = y,\n                                                    random_state = 4)\n\n# take a look at the shape of each of these\nprint(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)"},{"cell_type":"markdown","metadata":{"_cell_guid":"7119e588-cee1-d929-4cfa-ede86f19b803"},"source":"Alright, let's make the classifier\n\nI am defining a function that evaulates the model on a given model and then loop over a bunch of different models:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f5f0b442-82cf-f5d1-fef5-0002206f8abf"},"outputs":[],"source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ac74cccf-4040-d64a-b639-dc553375534f"},"outputs":[],"source":"def eval_accuracy(model):\n    model.fit(x_train, y_train)\n    return model.score(x_test, y_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1e04873e-c672-7fb7-14cf-82a744ab6ada"},"outputs":[],"source":"models = [LogisticRegression(),\n          MultinomialNB(),\n          RandomForestClassifier(n_estimators=50),\n          KNeighborsClassifier()]"},{"cell_type":"markdown","metadata":{"_cell_guid":"8be9c125-c52c-7da4-0597-36af1443d337"},"source":"Note that here we could have spent more time tuning the parameters of the different models but the models above tend to be pretty decent directly out of the box without any fine tuning so we'll just leave them."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5f567017-c49a-5f61-648e-791ea76bbfb9"},"outputs":[],"source":"results = pd.Series([eval_accuracy(model) for model in models],\n                    index = [\"logit\", \"nb\", \"rf\", \"knn\"])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8937d05b-ebac-310a-d427-a85b60099724"},"outputs":[],"source":"results.plot(kind = \"barh\", title=\"Accuracy by Model\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"cf1043e6-d441-72e8-1986-0a9769aa88cf"},"source":"We get pretty similar results for Random Forests, Logistic Regssison and Naive Baise with Knn giving worse results."},{"cell_type":"markdown","metadata":{"_cell_guid":"f8c4f620-a4f2-68db-3bfa-9aff20e3b667"},"source":"### A closer look at the logistic regression:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fc49cf66-d23c-a643-85ec-2a0590893fbd"},"outputs":[],"source":"vectorizer = CountVectorizer(min_df=5) #5 here to get only actual words.\nx = vectorizer.fit_transform(twigen_confident['text_norm'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9ca19484-ec2e-23d1-04c6-b21dba369bad"},"outputs":[],"source":"model = LogisticRegression()\nmodel.fit(x, y)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c13e91d9-b47e-1267-84b3-ce2e8454e44f"},"outputs":[],"source":"encoder.classes_"},{"cell_type":"markdown","metadata":{"_cell_guid":"c027275a-b9b1-01d7-298e-065388ff5912"},"source":"### Highest male coefficients:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c1f43453-e8de-a82b-68ff-c24913a90f2a"},"outputs":[],"source":"coeffs_male = pd.Series(model.coef_[2], index = vectorizer.get_feature_names())\ncoeffs_male.sort_values(ascending=False)[:10].plot.barh()"},{"cell_type":"markdown","metadata":{"_cell_guid":"f8a98b95-94d8-bb48-f9eb-9a0ffabf787d"},"source":"Ok, seems reasonable enough - we've got some politics, bromance and 420 related tokens."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bd9d6cc1-2609-e315-2c11-2489c8382c2e"},"outputs":[],"source":"### Highest female coefficients:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0d4e6716-b630-6145-5c07-b9b242f223c5"},"outputs":[],"source":"coeffs_female = pd.Series(model.coef_[1], index = vectorizer.get_feature_names())\ncoeffs_female.sort_values(ascending=False).head(10).plot.barh()"},{"cell_type":"markdown","metadata":{"_cell_guid":"c9f8f2cb-cd1c-9683-fd99-2f220bd22bc3"},"source":"Hmm this isn't so convincing at first glance. "},{"cell_type":"markdown","metadata":{"_cell_guid":"002030e0-a8c3-d918-8600-7e9572f261a4"},"source":"### Highest brand coefficients:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3210678a-af11-13f9-026a-467fef10e489"},"outputs":[],"source":"(pd.Series(model.coef_[0], index = vectorizer.get_feature_names())\n        .sort_values(ascending=False)\n        .head(10)\n        .plot.barh())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4f076d6e-fd7e-2da2-5595-c6261a65b541"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}