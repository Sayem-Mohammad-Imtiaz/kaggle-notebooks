{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Data Management\nfrom dateutil import relativedelta as rd\nimport pandas as pd\nimport numpy as np\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport plotly as py\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.offline as pyo\npyo.init_notebook_mode()\nimport seaborn as sns\n\n# Regression \nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols\nimport statsmodels.graphics.api as smg","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"cty_info = pd.read_csv('../input/countryinfo/covid19countryinfo.csv').rename(columns={'country':'Country'})\n\n# Filter observations with aggregate country-level information\n# The column region for region-level observations is populated\ncty_info = cty_info[cty_info.region.isnull()]\n\n# Convert string data type to floating data type\n# Remove comma from the fields\ncty_info['healthexp'] = cty_info[~cty_info['healthexp'].isnull()]['healthexp'].str.replace(',','').astype('float')\ncty_info['gdp2019'] = cty_info[~cty_info['gdp2019'].isnull()]['gdp2019'].str.replace(',','').astype('float')\n\n# Convert to date objects with to_datetime method\ngov_actions = ['quarantine', 'schools', 'gathering', 'nonessential', 'publicplace']\n\nfor gov_action in gov_actions:\n    cty_info[gov_action] = pd.to_datetime(cty_info[gov_action], format = '%m/%d/%Y')\n    \n# Filter columns of interest\n# Note: feel free to explore other variables or datasets\ncty_info = cty_info[['Country','avghumidity', 'avgtemp', 'fertility', 'medianage', 'urbanpop', 'quarantine', 'schools', \\\n                    'publicplace', 'gatheringlimit', 'gathering', 'nonessential', 'hospibed', 'smokers', \\\n                    'sex0', 'sex14', 'sex25', 'sex54', 'sex64', 'sex65plus', 'sexratio', 'lung', 'femalelung', \\\n                    'malelung', 'gdp2019', 'healthexp', 'healthperpop']]\n\n# cty_info.describe()\ncty_info.info()\n#cty_info.head(20)\ncty_info.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cty_info[cty_info['schools'].isna()==0].head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Worldometer data\n# ================\n\nworldometer_data = pd.read_csv('../input/corona-virus-report/worldometer_data.csv')\n\n# Replace missing values '' with NAN and then 0\nworldometer_data = worldometer_data.replace('', np.nan).fillna(0)\n\n# Transform variables and round them up to the two decimal points\n# Note that there are instances of division by zero issue when there are either zero total tests or total cases\nworldometer_data['Case Positivity'] = round(worldometer_data['TotalCases']/worldometer_data['TotalTests'],2)\nworldometer_data['Case Fatality'] = round(worldometer_data['TotalDeaths']/worldometer_data['TotalCases'],2)\n\n# Resolve the division by zero issue by replacing infinity value with zero\nworldometer_data[worldometer_data[\"Case Positivity\"] == np.inf] = 0\nworldometer_data[worldometer_data[\"Case Fatality\"] == np.inf] = 0\n\n# Place case positivity into three bins\nworldometer_data ['Case Positivity Bin']= pd.qcut(worldometer_data['Case Positivity'], q=3, labels=[\"low\", \"medium\", \"high\"])\n\n# Population Structure\nworldometer_pop_struc = pd.read_csv('../input/covid19-worldometer-snapshots-since-april-18/population_structure_by_age_per_contry.csv')\n\n# Replace missing values with zeros\nworldometer_pop_struc = worldometer_pop_struc.fillna(0)\n\n# Merge datasets by common key country\nworldometer_data = worldometer_data.merge(worldometer_pop_struc,how='inner',left_on='Country/Region', right_on='Country')\nworldometer_data = worldometer_data[worldometer_data[\"Country/Region\"] != 0]\n\n# Country information\nworldometer_data = worldometer_data.merge(cty_info, how='left', on='Country')\n\n# Replace space in variable names with '_'\nworldometer_data.columns = worldometer_data.columns.str.replace(' ', '_')\n\nworldometer_data.describe()\nworldometer_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Full data\n# =========\n\nfull_table = pd.read_csv('../input/corona-virus-report/covid_19_clean_complete.csv')\nfull_table['Date'] = pd.to_datetime(full_table['Date'])\n\n# Examine DataFrame (object type, shape, columns, dtypes)\nfull_table.info()\n\n#type(full_table)\n#full_table.shape\n#full_table.columns\n#full_table.dtypes\n\n# Deep dive into the DataFrame\nfull_table.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Grouped by day, country\n# =======================\n\nfull_grouped = pd.read_csv('../input/corona-virus-report/full_grouped.csv')\nfull_grouped['Date'] = pd.to_datetime(full_grouped['Date'])\n#full_grouped.loc[full_grouped['Country/Region'] == 'US', 'Country/Region'] = 'USA'\nfull_grouped.head()\n\n# Correct country names in worldometer to make them consistent with dataframe full_grouped column Country/Region before merging \nworldometer_data['Country/Region'].replace({'USA':'US', 'UAE':'United Arab Emirates', 'S. Korea':'South Korea', \\\n                                           'UK':'United Kingdom'}, inplace=True)\n\n# Draw population and country-level data\nfull_grouped = full_grouped.merge(worldometer_data[['Country/Region', 'Population']], how='left', on='Country/Region')\nfull_grouped = full_grouped.merge(cty_info, how = 'left', left_on = 'Country/Region', right_on = 'Country')\nfull_grouped['Confirmed per 1000'] = full_grouped['Confirmed'] / full_grouped['Population'] * 1000\n\n# Backfill data\nfull_grouped = full_grouped.fillna(method='ffill')\n\n# Create post-invention indicators\ngov_actions = ['quarantine', 'schools', 'gathering', 'nonessential', 'publicplace']\n\nfor gov_action in gov_actions:\n    full_grouped['post_'+gov_action] = full_grouped['Date'] >= full_grouped[gov_action]\n    full_grouped['day_rel_to_' + gov_action] = (full_grouped['Date'] - full_grouped[gov_action]).dt.days\n\n# Create percent changes in covid19 outcomes\ncovid_outcomes = ['Confirmed', 'Deaths', 'Recovered', 'Active', 'Confirmed per 1000']\n\nfor covid_outcome in covid_outcomes:\n    full_grouped['pct_change_' + covid_outcome] = full_grouped.groupby(['Country/Region'])[covid_outcome].pct_change()\n    full_grouped[full_grouped['pct_change_' + covid_outcome] == np.inf] = 0\n    \n\n\n\n# Replace space in variable names with '_'\nfull_grouped.columns = full_grouped.columns.str.replace(' ', '_')\n\nfor gov_action in gov_actions:\n    full_grouped['Confirmed_per_1000_at_'+gov_action] = full_grouped[full_grouped['Date'] == full_grouped[gov_action]]['Confirmed_per_1000']\n    \nfull_grouped['log_Confirmed_per_1000'] = np.log(full_grouped['Confirmed_per_1000']+1)\nfull_grouped.info()\n#full_grouped.tail(20)\n#print(full_grouped.iloc[0,0])\n# full_grouped[full_grouped[\"quarantine\"] != None][\"Country/Region\"].unique()\n# full_grouped[full_grouped['Country/Region'] == 'Germany'][['quarantine','day_rel_to_quarantine']]\n# list(full_grouped.columns.values)\n# full_grouped.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plt.matshow(full_grouped.corr())\n#plt.show()\n\nf, ax = plt.subplots(figsize=(10, 8))\ncorr = full_grouped.corr()\n\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\n\n# Plot heatmap\nsns.heatmap(corr, mask=mask, cmap=cmap, square=True, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create interaction term\nfull_grouped['quarXurbanpop'] = full_grouped['post_quarantine'] * full_grouped['urbanpop']\n\n# OLS regression\ny = full_grouped['log_Confirmed_per_1000']\nX = full_grouped[['day_rel_to_quarantine','avghumidity', 'avgtemp', 'urbanpop']]\nX = sm.add_constant(X)\n\nols_model=sm.OLS(y,X.astype(float), missing='drop')\nresult=ols_model.fit()\nprint(result.summary2())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Q1: How is the days to quarantine related to confirmed cases."},{"metadata":{},"cell_type":"markdown","source":"we can see that there is a positive correlation, which is opposite to our intuition. this is because most country can not immediately make the quanrantine effective and the virus is still spreading fast day by day"},{"metadata":{},"cell_type":"markdown","source":"Q2: does New Zealand Dollar have lower currency exchange rate during recession?\n    \n    "},{"metadata":{"trusted":true},"cell_type":"code","source":"NZD= pd.read_csv('../input/nzdusd/NZDUSD.csv')\nrecession=pd.read_csv('../input/nber-based-recession-indicators-united-states/USRECD.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NZD.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NZD['Date'] = pd.to_datetime(NZD['Date']) #转换成date\nNZD.rename(columns={'Adj Close':'nzdusd'}, inplace=True)\nNZD['nzd_return'] = NZD['nzdusd'].pct_change()\nNZD = NZD[['Date','nzdusd','nzd_return']]\n\nrecession[\"Date\"] = pd.to_datetime(recession[\"date\"])\nrecession[\"recession\"] = recession[\"value\"].astype('bool')\n\n# Subset data columns\n\nrecession = recession[[\"Date\",\"recession\"]]\nbaseline = pd.merge(NZD,recession,how='left',on='Date') #how=left把snp的东西都留下","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"baseline.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nplt.hist(baseline[baseline['recession']==0]['nzdusd'], bins=100, label=\"non-recession\")\nplt.hist(baseline[baseline['recession']==1]['nzdusd'], bins=100, label=\"recession\")\n\nplt.legend(loc='upper right')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that NZD are generally weaker in recession. But we still need to evaluate the significance using statistics\nH0: Recession has no impact on NZD/USD (i.e., the difference is equal zero).\nH1: Recession has an impact on NZD/USD (i.e., the difference is not zero)."},{"metadata":{"trusted":true},"cell_type":"code","source":"len(baseline)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we have enough data points, we can proceed to the t-test\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import t\n\nmean_diff=baseline[baseline['recession']==0]['nzdusd'].mean()-baseline[baseline['recession']==1]['nzdusd'].mean()\n#MSE=(S1^2+S2^2)/2\nMSE=(baseline[baseline['recession']==0]['nzdusd'].var()+baseline[baseline['recession']==1]['nzdusd'].var())/2\nS_diff=np.sqrt(4*MSE/len(baseline))\ntt=mean_diff/S_diff\ndf=len(baseline)-2\n\npval=t.sf(np.abs(tt),df)*2\nprint(\"Point estimate of difference: \" + str(mean_diff))\nprint(\"MSE : \" + str(MSE))\nprint(\"Degree of freedom : \" + str(df))\nprint(\"T-statistic : \" + str(tt))\n\nalpha = 0.05\nprint(\"P-value : \" + str(pval))\nif pval <= alpha: \n    print('There is a difference in NZD/USD in recession(reject H0)') \nelse: \n    print('There is no difference in in NZD/USD in recession(fail to reject H0)') \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confidence_level = 0.95\n\nconfidence_interval = t.interval(confidence_level, df, mean_diff, S_diff)\n\nprint(\"Point estimate : \" + str(mean_diff))\nprint(\"Confidence interval (0.025, 0.975) : \" + str(confidence_interval))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In a regression, the NZD performance will be worse at around 0.0617"},{"metadata":{},"cell_type":"raw","source":""},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Question 3: How does the stimulus affect the economy"},{"metadata":{"trusted":true},"cell_type":"code","source":"stimulus = pd.read_csv('../input/stimulus1/CESI_3.csv')\nstimulus.head()\nstimulus.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# OLS regression\ny = stimulus['CESI_3']\nX = stimulus[['fiscal','ratecut', 'reserve requirement and buffer', 'macrofin']]\nX = sm.add_constant(X)\n\nols_model=sm.OLS(y,X.astype(float), missing='drop')\nresult=ols_model.fit()\nprint(result.summary2())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"We can see that all stimulus methods are effective to the economy, especially fiscal (based on % of GDP used) and macrofin\nwith 1% of GDP to put into the market as fiscal stimulus, CESI index will increase 0.1241"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}