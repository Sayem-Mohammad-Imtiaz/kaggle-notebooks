{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Customer Segmentation**\n\nCustomer segmentation is the activity of dividing a broad consumer or business market, normally consisting of existing and potential customers, into sub-groups of consumers (known as segments) based on some type of shared characteristics. The overall aim of segmentation is to identify high yield segments – that is, those segments that are likely to be the most profitable or that have growth potential – so that these can be selected for special attention  ([Reference](https://en.wikipedia.org/wiki/Market_segmentation))"},{"metadata":{},"cell_type":"markdown","source":"**What is in this Kernel?**\n\n* Cleaning/Transforming the Data\n* Univariate Analysis\n* Analyzing the KPIs\n  1. Annual Revenue\n  2. Monthly Revenue\n  3. Monthly Revenue growth rate\n  4. Monthly Active Customers\n  5. Average Sales per Order\n  6. New Customers Growth Rate\n* Clustering with arbitrary number of clusters\n  1. Calculating Recency, Frequency and Monetary value for each customer\n  2. Calculating RFM Score\n  3. Dividing the customers into segments\n* KMeans Clustering\n  1. Data Preprocessing for KMeans\n      1. Removing the Skewness for achieving Normal distribution using Log Transformation\n      2. Standardizing the variables using Standard Scaler for eual variance and equal mean\n      3. Choosing the number of clusters using Elbow Method\n      4. Implementing KMeans\n      5. Building Customer Personas\n         1. Snake Plot\n         2. Calculation relative importance of each cluster compared to the population\n\n  "},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing the required libraries\nimport pandas as pd\nimport numpy as np\n\n#viz Libraries\nimport matplotlib.pyplot as plt\n\nplt.style.use('ggplot')\nimport seaborn as sns\n\n#warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n#datetime\nimport datetime as dt\n\n#StandardSccaler\nfrom sklearn.preprocessing import StandardScaler\n\n#KMeans\nfrom sklearn.cluster import KMeans\n\n#file directoryy\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Reading the data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#reading the data\ndf = pd.read_csv('../input/sample-sales-data/sales_data_sample.csv', encoding = 'unicode_escape')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape #Dimensions of the data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head() #Glimpse of the data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Dropping columns **"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Removing the variables which dont add significant value fot the analysis.\nto_drop = ['PHONE','ADDRESSLINE1','ADDRESSLINE2','STATE','POSTALCODE']\ndf = df.drop(to_drop, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Checking for null values**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Not dealing with the mising values of 'Territory' Variable as it may not have a significant effect on the analysis."},{"metadata":{},"cell_type":"markdown","source":"**Checking for inconsistent data types**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Changing the data type of variable 'ORDERDATE' from object to datetime"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['ORDERDATE'] = pd.to_datetime(df['ORDERDATE'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Summary stats of Quantitative variables**"},{"metadata":{"trusted":true},"cell_type":"code","source":"quant_vars = ['QUANTITYORDERED','PRICEEACH','SALES','MSRP']\ndf[quant_vars].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is observed that there are no negative values for the quantitative variables, which is a good sign because we cannot have negative prices or quantities."},{"metadata":{},"cell_type":"markdown","source":"# Exploring the variables"},{"metadata":{},"cell_type":"markdown","source":"**Order Quantity Distribution**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(9,6))\nsns.distplot(df['QUANTITYORDERED'])\nplt.title('Order Quantity Distribution')\nplt.xlabel('Quantity Ordered')\nplt.ylabel('Frequency')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the distribution plot of quantity, we can infer that the orders are bulk orders. Majority of the order's quantity are between 20 -40 units."},{"metadata":{},"cell_type":"markdown","source":"**Price Distribution**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(9,6))\nsns.distplot(df['PRICEEACH'])\nplt.title('Price Distribution')\nplt.xlabel('Price Ordered')\nplt.ylabel('Frequency')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The distribution of Price is Left Skewed with max price of 100$. Interestingly, many of the orders recieved are of this price. Not investigating further about this particular product line which has the highest price beacuse the target is to segment the customers."},{"metadata":{},"cell_type":"markdown","source":"**Sales Distribution**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(9,6))\nsns.distplot(df['SALES'])\nplt.title('Sales Distribution')\nplt.xlabel('Sales')\nplt.ylabel('Frequency')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Analyzing the STATUS variable**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['STATUS'].value_counts(normalize = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Checking the time range of the data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(['YEAR_ID'])['MONTH_ID'].nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We dont have the complete data for 2005."},{"metadata":{},"cell_type":"markdown","source":"**Dealsize Distribution**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(9,6))\ndf['DEALSIZE'].value_counts(normalize = True).plot(kind = 'bar')\nplt.title('DealSize distribution')\nplt.xlabel('Deal Size')\nplt.ylabel('% Proportion')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Analyzing KPIs"},{"metadata":{},"cell_type":"markdown","source":"# Annual Revenue"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#Annual Revenue\nplt.figure(figsize=(9,6))\ndf.groupby(['YEAR_ID'])['SALES'].sum().plot()\nplt.xlabel('Year')\nplt.ylabel('Revenue')\nplt.title('Annual Revenue')\nplt.xticks(np.arange(2003,2006,1))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we dont have the complete data for 2005, analyzing the Annual Revenue can be misleading. Instead, we can analyze Monthy Revenue."},{"metadata":{},"cell_type":"markdown","source":"# Monthly Revenue"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#Monthly Revenue\nplt.figure(figsize=(9,6))\n\nmonthly_revenue = df.groupby(['YEAR_ID','MONTH_ID'])['SALES'].sum().reset_index()\nmonthly_revenue\nsns.lineplot(x=\"MONTH_ID\", y=\"SALES\",hue=\"YEAR_ID\", data=monthly_revenue)\nplt.xlabel('Month')\nplt.ylabel('Sales')\nplt.title('Monthly Revenue')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This clearly shows that the revenue is growing especially in October and November. It can be the result of the seasonality(Thnaks Giving and other festivitues). We can also observe that 2005 is performing better than the other years in terms of revenue having the maximum sales in all the months(Jan - May). The reason behind this spike of sales in 2005 can be further investigated to maintain high sales in future."},{"metadata":{},"cell_type":"markdown","source":"# Monthly Revenue Growth Rate:"},{"metadata":{"trusted":true},"cell_type":"code","source":"monthly_revenue['MONTHLY GROWTH'] = monthly_revenue['SALES'].pct_change()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"monthly_revenue.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#Monthly Sales Growth Rate\nplt.figure(figsize=(9,6))\nsns.lineplot(x=\"MONTH_ID\", y=\"MONTHLY GROWTH\",hue=\"YEAR_ID\", data=monthly_revenue)\nplt.xlabel('Month')\nplt.ylabel('Sales')\nplt.title('Monthly Sales Growth Rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Apart from expected high/low growth rates during the seasonal months, there is hig growth rate from Apr 2005 to May 2005."},{"metadata":{},"cell_type":"markdown","source":"# Top 10 countries by Sales"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(9,6))\ntop_cities = df.groupby(['COUNTRY'])['SALES'].sum().sort_values(ascending=False)\ntop_cities.plot(kind = 'bar')\nplt.title('Top 10 countries by Sales')\nplt.xlabel('Country')\nplt.ylabel('Total Sales')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Monthly Active Customers"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#plt.figure(figsize=(10,8))\ndf['YEAR_MONTH'] = df['YEAR_ID'].map(str)+df['MONTH_ID'].map(str).map(lambda x: x.rjust(2,'0'))\nmonthly_active = df.groupby(['YEAR_MONTH'])['CUSTOMERNAME'].nunique().reset_index()\nmonthly_active.plot(kind='bar',x='YEAR_MONTH',y='CUSTOMERNAME')\n#plt.figure(figsize=(10,8))\nplt.title('Monthly Active Customers')\nplt.xlabel('Month/Year')\nplt.ylabel('Number of Unique Customers')\nplt.xticks(rotation=90)\n#plt.figure(figsize=(10,8))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As expected, customers are highly active during the months of November and October. The number of active customers increased from 2003 to 2004 which indicates that the company is successful in retention/acquisition of ol/new customers."},{"metadata":{},"cell_type":"markdown","source":"# Average Sales per Order"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#Average Sales per Order\naverage_revenue = df.groupby(['YEAR_ID','MONTH_ID'])['SALES'].mean().reset_index()\nplt.figure(figsize=(10,6))\nsns.lineplot(x=\"MONTH_ID\", y=\"SALES\",hue=\"YEAR_ID\", data=average_revenue)\nplt.xlabel('Month')\nplt.ylabel('Average Sales')\nplt.title('Average Sales per Order')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# New Customers Growth Rate"},{"metadata":{},"cell_type":"markdown","source":"New customer is whoever did his/her first purchase in the time window we defined, i.e., Mothly in this analysis."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#New Customers Growth Rate\ndf_first_purchase = df.groupby('CUSTOMERNAME').YEAR_MONTH.min().reset_index()\ndf_first_purchase.columns = ['CUSTOMERNAME','FirstPurchaseDate']\n\nplt.figure(figsize=(10,6))\ndf_first_purchase.groupby(['FirstPurchaseDate'])['CUSTOMERNAME'].nunique().pct_change().plot(kind='bar')\nplt.title('New Customers Growth Rate')\nplt.xlabel('YearMonth')\nplt.ylabel('Percentage Growth Rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The highest growth rate is observed in February 2002. This can be investigated further to betetr understand what factors contributed the growth."},{"metadata":{},"cell_type":"markdown","source":"# Segmentation with number of clusters chosen randomly"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['ORDERDATE'] = [d.date() for d in df['ORDERDATE']]\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Calculate Recency, Frequency and Monetary value for each customer**"},{"metadata":{},"cell_type":"markdown","source":"Assuming that we are analyzing the next day of latest order date in the data set. Creating a variable '*snapshot date*****' which is the latest date in data set.\n\n**Recency** : Recency is the number of days between the customer's latest order date and the snapshot date<br>\n**Frequency**: Number of purchases made by the customer<br>\n**MonetaryValue**: Revenue generated by the customer"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate Recency, Frequency and Monetary value for each customer\nsnapshot_date = df['ORDERDATE'].max() + dt.timedelta(days=1) #latest date in the data set\ndf_RFM = df.groupby(['CUSTOMERNAME']).agg({\n    'ORDERDATE': lambda x: (snapshot_date - x.max()).days,\n    'ORDERNUMBER': 'count',\n    'SALES':'sum'})\n\n#Renaming the columns\ndf_RFM.rename(columns={'ORDERDATE': 'Recency',\n                   'ORDERNUMBER': 'Frequency',\n                   'SALES': 'MonetaryValue'}, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_RFM.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Dividing the customer into 4 segments(Randomly Chosen)**"},{"metadata":{},"cell_type":"markdown","source":"**Recency/Frequency/MonetaryValue** : Level 4 > Level 3> Level 2 > Level 1\n\n* Lower the recency, higher the Recency level<br>\n* Higher the number of orders, higher the Frequency level<br>\n* Higher the monetary value, higher the MonetaryValue level\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dividing into segments\n\n# Create a spend quartile with 4 groups - a range between 1 and 5\nMonetaryValue_quartile = pd.qcut(df_RFM['MonetaryValue'], q=4, labels=range(1,5))\nRecency_quartile = pd.qcut(df_RFM['Recency'], q=4, labels=list(range(4, 0, -1)))\nFrequency_quartile = pd.qcut(df_RFM['Frequency'], q=4, labels=range(1,5))\n\n\n# Assign the quartile values to the Spend_Quartile column in data\ndf_RFM['R'] = Recency_quartile\ndf_RFM['F'] = Frequency_quartile\ndf_RFM['M'] = MonetaryValue_quartile\n\n#df_RFM[['MonetaryValue_Quartile','Recency_quartile','Frequency_quartile']] = [MonetaryValue_quartile,Recency_quartile,Frequency_quartile]\n\n# Print data with sorted Spend values\n#print(df_RFM.sort_values('MonetaryValue'))\n\ndf_RFM.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Calculating RFM Score**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate RFM_Score\ndf_RFM['RFM_Score'] = df_RFM[['R','F','M']].sum(axis=1)\ndf_RFM.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Labelling the levels**"},{"metadata":{},"cell_type":"markdown","source":"* RFM Score > 10 - **High Value Customer**<br>\n* RFM SCore < 10 and RFM Score >= 6 - **Mid Value Customer**<br>\n* RFM Score < 6 - **Low Value Customer**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Naming Levels\n# Define rfm_level function\ndef rfm_level(df):\n    if np.bool(df['RFM_Score'] >= 10):\n        return 'High Value Customer'\n    elif np.bool((df['RFM_Score'] < 10) & (df['RFM_Score'] >= 6)):\n        return 'Mid Value Customer'\n    else:\n        return 'Low Value Customer'\n\n# Create a new variable RFM_Level\ndf_RFM['RFM_Level'] = df_RFM.apply(rfm_level, axis=1)\n\n# Print the header with top 5 rows to the console\ndf_RFM.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\ndf_RFM['RFM_Level'].value_counts(normalize = True).plot(kind='bar')\nplt.title('RFM_level Distribution')\nplt.xlabel('RFM_Level')\nplt.ylabel('% Proportion')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Higher the monetary value, higher the MonetaryValue level**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Analyzing customer segments\n# Calculate average values for each RFM_Level, and return a size of each segment \nrfm_level_agg = df_RFM.groupby(['RFM_Level']).agg({\n    'Recency': 'mean',\n    'Frequency': 'mean',\n    'MonetaryValue':['mean','count']}).round(1)\n\n# Print the aggregated dataset\nprint(rfm_level_agg)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Segmentation using KMeans Clustering"},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing for KMeans\n\n**K Means Assumptions**\n\n* All variables have symmetrical (Normal) Distribution <br>\n* All Variables have same average value(approx)<br>\n* All Variables have same variance(approx)"},{"metadata":{},"cell_type":"markdown","source":"**Check the distribution of the variables **"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = df_RFM[['Recency','Frequency','MonetaryValue']]\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\n\nplt.subplot(1,3,1)\ndata['Recency'].plot(kind='hist')\nplt.title('Recency')\n\nplt.subplot(1,3,2)\ndata['Frequency'].plot(kind='hist')\nplt.title('Frequency')\n\nplt.subplot(1,3,3)\ndata['MonetaryValue'].plot(kind='hist')\nplt.xticks(rotation = 90)\nplt.title('MonetaryValue')\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Removing the skewness by performing log transformation on the variables**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_log = np.log(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_log.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Distribution of Recency, Frequency and MonetaryValue after Log Transformation**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\n\n#plt.subplot(1,3,1)\nsns.distplot(data_log['Recency'],label='Recency')\n\n#plt.subplot(1,3,1)\nsns.distplot(data_log['Frequency'],label='Frequency')\n\n#plt.subplot(1,3,1)\nsns.distplot(data_log['MonetaryValue'],label='MonetaryValue')\n\nplt.title('Distribution of Recency, Frequency and MonetaryValue after Log Transformation')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Standardizing the variables using StandardScaler() for equal variance and mean**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialize a scaler\nscaler = StandardScaler()\n\n# Fit the scaler\nscaler.fit(data_log)\n\n# Scale and center the data\ndata_normalized = scaler.transform(data_log)\n\n# Create a pandas DataFrame\ndata_normalized = pd.DataFrame(data_normalized, index=data_log.index, columns=data_log.columns)\n\n# Print summary statistics\ndata_normalized.describe().round(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Choosing number of Clusters using Elbow Method"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit KMeans and calculate SSE for each k\nsse={}\nfor k in range(1, 21):\n    kmeans = KMeans(n_clusters=k, random_state=1)\n    kmeans.fit(data_normalized)\n    sse[k] = kmeans.inertia_ \n\n    \nplt.figure(figsize=(10,6))\n# Add the plot title \"The Elbow Method\"\nplt.title('The Elbow Method')\n\n# Add X-axis label \"k\"\nplt.xlabel('k')\n\n# Add Y-axis label \"SSE\"\nplt.ylabel('SSE')\n\n# Plot SSE values for each key in the dictionary\nsns.pointplot(x=list(sse.keys()), y=list(sse.values()))\nplt.text(4.5,60,\"Largest Angle\",bbox=dict(facecolor='lightgreen', alpha=0.5))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Running KMeans with 5 clusters"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialize KMeans\nkmeans = KMeans(n_clusters=5, random_state=1) \n\n# Fit k-means clustering on the normalized data set\nkmeans.fit(data_normalized)\n\n# Extract cluster labels\ncluster_labels = kmeans.labels_\n\n# Assigning Cluster Labels to Raw Data\n# Create a DataFrame by adding a new cluster label column\ndata_rfm = data.assign(Cluster=cluster_labels)\ndata_rfm.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Group the data by cluster\ngrouped = data_rfm.groupby(['Cluster'])\n\n# Calculate average RFM values and segment sizes per cluster value\ngrouped.agg({\n    'Recency': 'mean',\n    'Frequency': 'mean',\n    'MonetaryValue': ['mean', 'count']\n  }).round(1)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building Customer Personas"},{"metadata":{},"cell_type":"markdown","source":"Customer Pesonas can build by determining the summary stats of RFM values or Snake Plot. Snake Plots is a Market Research technique used to compare segments.\nVisual representation of each segment's attributes helps us to determine the relative Importance of segment attributes"},{"metadata":{},"cell_type":"markdown","source":"# Snake Plot"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data_rfm_melt = pd.melt(data_rfm.reset_index(), id_vars=['CUSTOMERNAME', 'Cluster'],\n                        value_vars=['Recency', 'Frequency', 'MonetaryValue'], \n                        var_name='Metric', value_name='Value')\n\nplt.figure(figsize=(10,6))\n# Add the plot title\nplt.title('Snake plot of normalized variables')\n\n# Add the x axis label\nplt.xlabel('Metric')\n\n# Add the y axis label\nplt.ylabel('Value')\n\n# Plot a line for each value of the cluster variable\nsns.lineplot(data=data_rfm_melt, x='Metric', y='Value', hue='Cluster')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Calculating relative importance of each attribute"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate average RFM values for each cluster\ncluster_avg = data_rfm.groupby(['Cluster']).mean() \nprint(cluster_avg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate average RFM values for the total customer population\npopulation_avg = data.mean()\nprint(population_avg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate relative importance of cluster's attribute value compared to population\nrelative_imp = cluster_avg / population_avg - 1\n\n# Print relative importance score rounded to 2 decimals\nprint(relative_imp.round(2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot Relative Importance\n\n# Initialize a plot with a figure size of 8 by 2 inches \nplt.figure(figsize=(8, 2))\n\n# Add the plot title\nplt.title('Relative importance of attributes')\n\n# Plot the heatmap\nsns.heatmap(data=relative_imp, annot=True, fmt='.2f', cmap='RdYlGn')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}