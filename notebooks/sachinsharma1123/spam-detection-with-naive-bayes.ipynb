{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport string\nimport re\nfrom nltk.stem.porter import PorterStemmer\nimport random\nfrom sklearn.model_selection import train_test_split\n\ndf = pd.read_csv(\"../input/sms-spam-collection-dataset/spam.csv\", encoding='latin-1')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Drop unwanted columns and rename remaining columns \ndf = df.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis = 1)\ndf = df.rename(columns={'v1': 'label', 'v2': 'text'})\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets make another column i.e the length of the text\nlen_text=[]\nfor i in df['text']:\n    len_text.append(len(i))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#adding length column in dataframe\ndf['text_length']=len_text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure(figsize=(12,5))\ndf[df['label']=='spam']['text_length'].plot(bins=35,kind='hist',color='blue',label='spam',alpha=0.5)\nplt.legend()\nplt.xlabel('message length')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,5))\ndf[df['label']=='ham']['text_length'].plot(bins=35,kind='hist',color='red',label='spam',alpha=0.5)\nplt.legend()\nplt.xlabel('message length')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from the above two histograms we can conclude that spam messages are mostly of length bw 150-200\n#and ham messages are of shorter length","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,5))\ndf['label'].value_counts().plot(kind='bar',color='green',label='spam-vs-nonspam')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count observations in each label\ndf.label.value_counts()\n#data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets convert the target variable into numerical from for classification\ndf['label']=np.where(df['label']=='spam',1,0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"930ba9fae25d64593e87ad58a044433c2a4c9c17"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ac5e59cd8f5a753a643fff92e06b459ef5ac3398"},"cell_type":"code","source":"# Extract every text \ntexts = []\nfor index, row in df.iterrows():\n    texts.append((row['text'], row['label']))\ntexts[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5b5b53c87fadb0ba551c1dd04d3ae1e6538c62d"},"cell_type":"code","source":"# * * * PREPROCESSING * * * \n# Remove whitespace and punctutation \ntokenized = []\nfor t in texts:\n    m = t[0]\n    text = re.sub('[' + string.punctuation + ']', ' ', m)\n    text = re.sub('[\\n\\t\\r]', '', text)\n    words = text.split()\n    tokenized.append((words, t[1]))\ntokenized[0] # First element","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1fcea6859e3b53e53cba6b2e436f3ad749e33574"},"cell_type":"code","source":"# Remove stopwords\nstopwords = []\ntry:\n    f = open('../input/stopword-lists-for-19-languages/englishST.txt', 'r')\n    stopwords = f.read().split('\\n')\nexcept IOError:\n    print('Problem opening file')\nfinally:\n    f.close()\nprint('Sentence before stopwrods removed: \\n', tokenized[51])\nfiltered = []\nfor t in tokenized:\n    text = t[0]\n    f_text = []\n    for word in text:\n        if word not in stopwords and len(word) > 2:\n            f_text.append(word)\n    filtered.append((f_text, t[1]))\n\nprint('\\nSentence after stopwords removed: \\n', filtered[51])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"216c8e2fb348ecd67ec64487adb8c1ec68ab2711"},"cell_type":"code","source":"# Stem the words\nstemmer = PorterStemmer()\nstemmed = []\nfor t in filtered:\n    text = t[0]\n    stemmed_text = []\n    for word in text:\n        stemmed_word = stemmer.stem(word.lower())\n        stemmed_text.append(stemmed_word)\n    stemmed.append((stemmed_text, t[1]))\n\nstemmed[51]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b5113b3596323ff5f313cd81185085c771002dc"},"cell_type":"code","source":"# Counting number of texts each word occurs\nword_count = {}\nfor t in stemmed:\n    text = t[0]\n    already_counted = []\n    for word in text:\n        if word not in word_count:\n            word_count[word] = 1\n        elif word not in already_counted:\n            word_count[word] += 1\n            already_counted.append(word)\n\n#  Removing the words that only occurs once\nfor i in range(len(stemmed)):\n    stemmed[i] = (list(filter(lambda x: word_count[x] > 4, stemmed[i][0])), stemmed[i][1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bcdc5e719ccce59c7abf1b7580084d60db5fbb6a"},"cell_type":"code","source":"# Splitting data in trainingdata and testdata (80-20 ratio)\ntotaltexts = df.label.value_counts()\ntotal = totaltexts[0] + totaltexts[1] # Total number of texts\ntest_number = int(0.20 * total) # Number of testing mails\n# Picking randomly\ntest_set = []\ntaken = {}\nwhile len(test_set) < test_number:\n    #print(len(train_texts))\n    num = random.randint(0, test_number - 1)\n    if num not in taken.keys():\n        test_set.append(stemmed.pop(num))\n        taken[num] = 1\n\ntrain_set = stemmed # Trainset is the remaining texts\n        \n# Total number of hams and spams\nnumber_of_hams = df.label.value_counts()[0]\nnumber_of_spams = df.label.value_counts()[1]\n\nlen(train_set)/total, len(test_set)/total","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8fdb9ca97b76cae9e82986fa1ff03cb6c857f724"},"cell_type":"markdown","source":"###### Probability that a text containing a given word is spam (Bayes' theorem):\n$P(Spam|Word) =  \\frac{P(Word|Spam)P(Spam)}{P(Word|Spam)P(Spam) + P(Word|Ham)P(Ham)} $"},{"metadata":{"trusted":true,"_uuid":"32fda77aae69fe5a9d07d5bba050c266ae09172c"},"cell_type":"code","source":"# * * * TRAINING THE MODEL * * * \n\n# meaning: Computing probabilities needed for P(Spam|Word)\n\n# Need to train these 4 possibilities:\n# 1) Probability that a word appears in spam messages\n# 2) Probability that a word appears in ham messages\n# 3) Overall probability that any given message is spam\n# 4) Overall probability that any given message is not spam (is ham)\n\ndef p_appears_in_spam(word):\n    count = 0\n    total_spams = 0\n    for t in train_set:\n        text = t[0]\n        if t[1] == 1:\n            total_spams += 1\n            if word in text:\n                count += 1\n    return count/total_spams\n             \n\ndef p_appears_in_ham(word):\n    count = 0\n    total_hams = 0\n    for t in train_set:\n        text = t[0]\n        if t[1] == 0:\n            total_hams += 1\n            if word in text:\n                count += 1\n    return count/total_hams\n\ndef total_spams_and_hams(tset):\n    spams = 0\n    hams = 0\n    for t in tset:\n        spams += 1 if t[1] == 1 else 0\n        hams += 1 if t[1] == 0 else 0\n    return spams, hams\n\n\np_spam = total_spams_and_hams(train_set)[0]/len(train_set) # Probability that a message is spam\np_ham = total_spams_and_hams(train_set)[1]/len(train_set) # Probability that a message is ham\n\n# Finally we can compute P(Spam | Word)\ndef p_is_spam_given_word(word):\n    return (p_appears_in_spam(word)*p_spam)/((p_appears_in_spam(word)*p_spam + p_appears_in_ham(word)*p_ham))\n\nword = 'free'\nprint('Probability that a message is spam given the word \"{}\" is: {}'.format(word, p_is_spam_given_word(word)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"269ade28228e79ab2368f486985c5a6ed6a9fabf"},"cell_type":"code","source":"# Collecting the probabilities in a dictionary\nprobabilities = {}\nfor t in train_set:\n    text = t[0]\n    for word in text:\n        if word not in probabilities:\n            p = p_is_spam_given_word(word)\n            if p == 0:\n                probabilities[word] = 0.2 # To deal with the zero probability problem. Tweaking this value\n            elif p == 1:\n                probabilities[word] = 0.98 # Tweaking this value\n            else:\n                probabilities[word] = p","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"594d5eb0b650154b6fdc7d9e6255c5523fd0fabc"},"cell_type":"markdown","source":"### Combining Individual Probabilities\nDetermining whether a message is spam or ham based only on the presence of one word is error-prone, must try to consider all the words (or the most interesting) in the message\n###### Probability that a text is spam: $P(Spam) =  \\frac{p_1p_2...p_n}{p_1p_2...p_n + (1-p_1)(1-p_2)...(1-p_n)} $\n\n$p_1$: The probability $P(S|W_1)$, that it is spam knowing it contains a first word (for example \"free\")"},{"metadata":{"trusted":true,"_uuid":"d699adb3ca123001676b31e8f3e3b44fec17032d"},"cell_type":"code","source":"# * * * TESTING THE MODEL * * * \n# Training is done\n# This function will be used to classify new messages, using the trained probabilities \n\nfrom functools import reduce\ndef p_is_spam(words):\n    probs = []\n    for word in words:\n        if word in probabilities:\n            probs.append(probabilities[word])\n        # 'else' is for unseen word, a value to tweak\n        # Assumes it is somewhat higher probability that an unseen word belongs to a ham message than a spam message\n        # as \n        else:\n            probs.append(0.4) \n    probs_not = list(map(lambda prob: 1-prob, probs))\n    product = reduce(lambda x, y: x * y, probs, 1) \n    product_not = reduce(lambda x, y: x * y, probs_not, 1)\n    return product/(product + product_not)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9517ace1b443297300e41ca138ec77441730ae49"},"cell_type":"code","source":"total_correct = 0\ntrue_spam_as_spam = 0\ntrue_spam_as_ham = 0\ntrue_ham_as_ham = 0\ntrue_ham_as_spam = 0\n\n# Care most about minimizing false positives, that is: labeling non-spam messages as spam\nfalse_positives = []\n\n\nfor t in test_set:\n    guess = -1\n    words = t[0]\n    answer = t[1]\n    p_spam = p_is_spam(words)\n    # If p > 0.95, predict 'yes' (is spam)\n    guess = 1 if p_spam > 0.95 else 0\n    if guess == answer:\n        total_correct += 1\n        if answer == 0: # true negative\n            true_ham_as_ham += 1\n        else: # true positive\n            true_spam_as_spam += 1 \n    else:\n        if answer == 0: # false positive\n            true_ham_as_spam += 1\n            false_positives.append((words, p_spam))\n        else: # true negative\n            true_spam_as_ham += 1\n\n            \ntrue_spams = total_spams_and_hams(test_set)[0]\ntrue_hams = total_spams_and_hams(test_set)[1]\n\nprint('Total test texts: ', len(test_set))\nprint('Number of correct: ', total_correct)\nprint('Accuracy: ', total_correct*100/(true_spams+true_hams))\nprint('-------------------------------')\nprint('Ham precision: ', true_ham_as_ham/(true_ham_as_ham + true_spam_as_ham))\nprint('Ham recall: ', true_ham_as_ham/(true_ham_as_ham + true_ham_as_spam))\nprint('Spam precision: ', true_spam_as_spam/(true_spam_as_spam + true_ham_as_spam)) # Most important \nprint('Spam recall: ', true_spam_as_spam/(true_spam_as_spam + true_spam_as_ham))\nprint('-------------------------------')\nprint('False Positives (hams that got labeled as spam):')\nfor i, (text, p) in enumerate(false_positives):\n    print('{}: Words in text: {} | Degree of certainty: {}'.format(i+1, text, p))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ec4fa251aa91f28d11f83aa9e6b8290b40864c6"},"cell_type":"code","source":"# * * * VISUALISATIONS * * * \nfrom wordcloud import WordCloud\n\nspam_words = \"\"\nham_words = \"\"\n\nall = train_set + test_set\n\nfor t in all:\n    text = t[0]\n    s = \"\"\n    for word in text:\n        s += word + ' '\n    if t[1] == 0:\n        ham_words += s\n    else:\n        spam_words += s + ' '\n\n# # Generate a word cloud image\nspam_wordcloud = WordCloud(width=600, height=400).generate(spam_words)\nham_wordcloud = WordCloud(width=600, height=400).generate(ham_words)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"995e6df9c2da12211164674ba154416f260863cb"},"cell_type":"code","source":"#Spam Word cloud\nplt.figure( figsize=(10,8), facecolor='k')\nplt.imshow(spam_wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9e4e2fb58c38ef62d01d54794fb16ff4950be16"},"cell_type":"code","source":"# Ham Word cloud\nplt.figure( figsize=(10,8), facecolor='k')\nplt.imshow(ham_wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"10c7dc42157abd7ef074ec0197e2b33cd0e68fe6"},"cell_type":"code","source":"#another approach for the naive bayes implementation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spam=[]\nham=[]\nspam_class=df[df['label']==1]['text']\nham_class=df[df['label']==0]['text']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_ham(ham_class):\n    global ham\n    words = [word.lower() for word in word_tokenize(ham_class) if word.lower() not in stopwords.words(\"english\") and word.lower().isalpha()]\n    ham=ham+words","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_spam(spam_class):\n    global spam\n    words = [word.lower() for word in word_tokenize(spam_class) if word.lower() not in stopwords.words(\"english\") and word.lower().isalpha()]\n    spam=spam+words","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"spam_class.apply(extract_spam)\nham_class.apply(extract_ham )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom wordcloud import WordCloud\nspam_wordcloud = WordCloud(width=600, height=400).generate(\" \".join(spam))\nplt.figure( figsize=(10,8), facecolor='k')\nplt.imshow(spam_wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ham_cloud=WordCloud(width=600,height=400,background_color='black').generate(\" \".join(ham))\nplt.figure(figsize=(10,8),facecolor='k')\nplt.imshow(ham_cloud)\nplt.tight_layout(pad=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#top 10 spam words=\nspam_words=np.array(spam)\npd.Series(spam_words).value_counts().head(n=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#top 10 ham words\nham_words=np.array(ham)\npd.Series(ham_words).value_counts().head(n=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now  we are done with visualizations task,next move into text ceaning\nfrom nltk.stem import SnowballStemmer\nimport string\nstemmer = SnowballStemmer(\"english\")\n\ndef cleanText(message):\n    \n    message = message.translate(str.maketrans('', '', string.punctuation))\n    words = [stemmer.stem(word) for word in message.split() if word.lower() not in stopwords.words(\"english\")]\n    \n    return \" \".join(words)\n\ndf[\"text\"] = df[\"text\"].apply(cleanText)\ndf.head(n = 10)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#we have done with the text cleaning and analysis,now next step is the model building","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#here x is the independent variable and y is the dependent variable\nx=df['text']\ny=df['label']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#to train and test the model we have to split into training and testing sets\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.feature_extraction.text import CountVectorizer\ncv=CountVectorizer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#as our feature variable x is in the form of string or texts ,for the algorithm we have to convert into vectors with the help of countvectorizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train=cv.fit_transform(x_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fit method is used to train the model with features and labels\nfrom sklearn.naive_bayes import MultinomialNB\nnb=MultinomialNB()\nnb.fit(x_train,y_train)\npredictions=nb.predict(cv.transform(x_test))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#evaluate the model on various metrics\naccuracy=accuracy_score(y_test,predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix=confusion_matrix(y_test,predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"true_negatives=confusion_matrix[0][0]\nfalse_positives=confusion_matrix[0][1]\nfalse_negatives=confusion_matrix[1][0]\ntrue_positives=confusion_matrix[1][1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"true negative predcitons:\",true_negatives)\nprint(\"false positive predictions:\",false_positives)\nprint(\"false negative predictions:\",false_negatives)\nprint(\"true postive predictions:\",true_positives)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nplt.figure(figsize=(12,5))\ngroup_names =['True Neg','False Pos','False Neg','True Pos']\ngroup_counts =['{0:0.0f}'.format(value) for value in\n                confusion_matrix.flatten()]\ngroup_percentages =['{0:.2%}'.format(value) for value in\n                     confusion_matrix.flatten()/np.sum(confusion_matrix)]\nlabels=[f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in\n          zip(group_names,group_counts,group_percentages)]\nlabels=np.asarray(labels).reshape(2,2)\nsns.heatmap(confusion_matrix, annot=labels, fmt='', cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets also calculate the recall and precision score\nfrom sklearn.metrics import recall_score,precision_score\nrecall=recall_score(y_test,predictions)\nprecision=precision_score(y_test,predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"precision","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"recall","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}