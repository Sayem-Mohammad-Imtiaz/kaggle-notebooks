{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#1. Load a dataset of your choice, display the first 3 rows, display a row of that dataset having missing values and replace missing values with Nan\n\nimport pandas as pd\nimport numpy as np\n\n\nexam_data  = {'name': ['Natasa', 'Eva', 'Ritesh', 'James', 'John', 'Michael', 'Alisa', 'Laura', 'Kevin', 'Roma'],\n        'score': [10.5, 8.5, 14, np.nan, 9, 5, 7, np.nan, 8, 19],\n        'attempts': [1, 3, 2, 0, 0, 3, 5, 1, 2, 1],\n        'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes']}\nlabels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n\ndf = pd.DataFrame(exam_data , index=labels)\n\ndf = pd.DataFrame(exam_data , index=labels)\nprint(\"--First three rows of the data frame:\\n\")\nprint(df.iloc[:3])\n\ndf = pd.DataFrame(exam_data , index=labels)\nprint(\"\\n--Rows where score is missing:\\n\")\nprint(df[df['score'].isnull()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#2. Given score of CSK, KKR, DC and MI such that no two team has same score, chalk out an appropriate graph for best display of the scores.\n#Also highlight the team having highest score in the graph\n\nipl_data  = {'name': ['CSK', 'MI', 'KKR', 'DC','RPG','RAJROYAL','SRH'],\n        'score': [12.5, 9, 16.5,  9, 20, 14.5,  8],\n        'attempts': [1, 3, 2, 3, 2, 3, 1],\n        }\n\ndf = pd.DataFrame(ipl_data )\ndf.head()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas import DataFrame\ncol=['c' for i in range(8)]\ncol[4]='red'\ndf.plot(x ='name', y='score', kind = 'bar',color=col)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# 3.Take two numpy array of your choice, find the common items between the arrays and remove the matching items but only from one array such that they exist in the second one.\n\nimport numpy as np\na = np.array([11,23,17,34,5])\nprint(\"Array 1: \",a)\nb = np.array([11,34,27])\nprint(\"Array 2: \",b)\nprint(\"Common values between two arrays:\")\nprint(np.intersect1d(a, b))\n\nfor i, val in enumerate(a):\n    if val in b:\n        a = np.delete(a, np.where(a == val)[0][0])\nfor i, val in enumerate(b):\n    if val in a:\n        a = np.delete(a, np.where(a == val)[0][0])\nprint(\"Arrays after deletion of common elements : \")\nprint(a)\nprint(b)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#4.Write a program to display the confusion matrix and f1_score on the titanic dataset\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import f1_score\n\ntrain = pd.read_csv(\"../input/titanic/train_data.csv\")\n                    \n\n\nX = train.drop(\"Survived\",axis=1)\ny = train[\"Survived\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 101)\n\nlogmodel = LogisticRegression()\nlogmodel.fit(X_train,y_train)\n\npredictions = logmodel.predict(X_test)\n\nprint(\"F1 Score:\",f1_score(y_test, predictions))\n \nprint(\"\\nConfusion Matrix(below):\\n\")\nconfusion_matrix(y_test, predictions)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}