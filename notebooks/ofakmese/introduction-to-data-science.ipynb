{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns  # visualization tool\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"77d2bf3663ad36e84b72ef0d293189a7c9c56c1e"},"cell_type":"markdown","source":"**IN THIS PART YOU LEARN:**\n\n* how to import csv file\n* plotting line,scatter and histogram\n* basic dictionary features\n*  basic pandas features like filtering that is actually something always used and main for being data scientist\n*  for loops"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/master.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"82630823c60782964bf7eb731b9265969244f17c"},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3901d4f3367cf443076f5b65c446ec9f8ffef41a"},"cell_type":"code","source":"data.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b69ed60433d5b74bc1b41e0caa961d8b666caf1f"},"cell_type":"code","source":"f,ax = plt.subplots(figsize=(13, 13))\nsns.heatmap(data.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6c34b93781d9611d4b3f081df01ba926774c1a2"},"cell_type":"code","source":"data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9b8f5bdd8bac5f680a487c59a4ebc4fae2a4a97"},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2d51fd843b12956041633de46b732aa7d204c1a3"},"cell_type":"markdown","source":"**MATPLOTLIB**\nMatplot is a python library that help us to plot data. The easiest and basic plots are line, scatter and histogram plots.\n* Line plot is better when x axis is time.\n* Scatter is better when there is correlation between two variables\n* Histogram is better when we need to see distribution of numerical data.\n* Customization: Colors,labels,thickness of line, title, opacity, grid, figsize, ticks of axis and linestyle  "},{"metadata":{"trusted":true,"_uuid":"e37401405de8823f1a4b89fcc89cd5d0124ffbb5"},"cell_type":"code","source":"# Line Plot\n# color = color, label = label, linewidth = width of line, alpha = opacity, grid = grid, linestyle = sytle of line\ndata.year.plot(kind = 'line', color = 'r',label = 'year',linewidth=1,alpha = 0.5,grid = True,linestyle = '-.')\ndata.suicides_no.plot(color = 'g',label = 'suicides_no',linewidth=1, alpha = 0.5,grid = True,linestyle = ':')\nplt.legend(loc='upper right')     # legend = puts label into plot\nplt.xlabel('x axis')              # label = name of label\nplt.ylabel('y axis')\nplt.title('Line Plot')            # title = title of plot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4df5dea194df96c169365e5cb056f4397bb0cead"},"cell_type":"code","source":"# Line Plot \n# x = year, y = suicides_no\ndata.plot(kind='line', x='year', y='suicides_no',alpha = 0.5,color = 'blue', grid = True,linestyle = ':', figsize = (10,8))\nplt.xlabel('year')              # label = name of label\nplt.ylabel('suicides_no')\nplt.title('year, suicides_no Scatter Plot')            # title = title of plot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d2d9d98f0e11648148e6a208c9053d2a34698287"},"cell_type":"code","source":"# Scatter Plot \n# x = year, y = suicides_no\ndata.plot(kind='scatter', x='year', y='suicides_no',alpha = 0.5,color = 'red', figsize = (8,6))\nplt.xlabel('year')              # label = name of label\nplt.ylabel('suicides_no')\nplt.title('year suicides_no Scatter Plot')            # title = title of plot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3586bb85a98bd70c281498e7929be0843532f32c"},"cell_type":"code","source":"plt.scatter(data.year, data.suicides_no, color = \"red\", alpha = 0.5) # other notation\nplt.xlabel('year')              # label = name of label\nplt.ylabel('suicides_no')\nplt.title('year suicides_no Scatter Plot')            # title = title of plot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"959e2223d0a65f3f91a5e85510f7c9adc0285b2a"},"cell_type":"code","source":"# Histogram\n# bins = number of bar in figure\ndata.year.plot(kind = 'hist',bins = 40,figsize = (6,6))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"711da2084456667bcee3274bd54b6ae138b64f29"},"cell_type":"code","source":"# clf() = cleans it up again you can start a fresh\ndata.year.plot(kind = 'hist',bins = 50)\nplt.clf()\n# We cannot see plot due to clf()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0eb5e380aaf112ea046702ca25ad0a640bc11d6c"},"cell_type":"markdown","source":"**PANDAS**\nWhat we need to know about pandas?\n* CSV: comma - separated values"},{"metadata":{"trusted":true,"_uuid":"2fb11eb265d6d6b236cddb8cf9271000676100ff"},"cell_type":"code","source":"data = pd.read_csv('../input/master.csv') # data import ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5ddfa41a81bfd05672f777b39d2d02b2b7a37de"},"cell_type":"code","source":"series = data['year']        # data['Defense'] = series\nprint(type(series))\ndata_frame = data[['suicides_no']]  # data[['Defense']] = data frame\nprint(type(data_frame))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"280d2de81acfa01e2a2bf3254db889f477f7bd12"},"cell_type":"code","source":"# 1 - Filtering Pandas data frame\nx = data['year']>2014     # There are only 3 pokemons who have higher defense value than 200\ndata[x]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2f9e2d4352abca455adaa3dcf58e70d04d81efc4"},"cell_type":"code","source":"# 2 - Filtering pandas with logical_and\n# There are only 2 pokemons who have higher defence value than 2oo and higher attack value than 100\ndata[np.logical_and(data['year']>2014, data['suicides_no']>5000 )]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"afed8e3e6d3e5ba402adb7638213f89a60554cbb"},"cell_type":"code","source":"# This is also same with previous code line. Therefore we can also use '&' for filtering.\ndata[(data['year']>2014) & (data['suicides_no']>5000)] # other notation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b5cbacabefee3038b730de5141c6806facbdde2f"},"cell_type":"code","source":"# Stay in loop if condition( i is not equal 5) is true\nlis = [1,2,3,4,5]\nfor i in lis:\n    print('i is: ',i)\nprint('')\n\n# Enumerate index and value of list\n# index : value = 0:1, 1:2, 2:3, 3:4, 4:5\nfor index, value in enumerate(lis):\n    print(index,\" : \",value)\nprint('')   \n\n# For dictionaries\n# We can use for loop to achive key and value of dictionary. We learnt key and value at dictionary part.\ndictionary = {'spain':'madrid','france':'paris'}\nfor key,value in dictionary.items():\n    print(key,\" : \",value)\nprint('')\n\n# For pandas we can achieve index and value \n# select specific indexes in a column\nfor index,value in data[['year']][47:49].iterrows(): # 47 include, 49 exclude\n    print(index,\" : \",value)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"71834536640f26d9b1a39718a7b8e31a9ada0cc0"},"cell_type":"markdown","source":"**PYTHON DATA SCIENCE TOOLBOX**\n\n**In this part, you learn:**\n\n* Diagnose data for cleaning\n* Exploratory data analysis\n* Visual exploratory data analysis\n* Tidy data\n* Concatenating data\n* Data types\n* Missing data and testing with assert"},{"metadata":{"trusted":true,"_uuid":"484b009136d37ccfc70555eb2121e1c0002f7a31"},"cell_type":"code","source":"# lets return pokemon csv and make one more list comprehension example\n# lets classify pokemons whether they have high or low speed. Our threshold is average speed.\nthreshold = sum(data.suicides_no)/len(data.suicides_no)\nprint(\"threshold: \", threshold)\ndata[\"suicides_no_level\"] = [\"High\" if i > threshold else \"Low\" for i in data.suicides_no]  # list comprehension\ndata.loc[1450:1460,[\"suicides_no_level\",\"suicides_no\"]] # we will learn loc more detailed later","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4992797da669721bc380a2ce87327ef8572114db"},"cell_type":"markdown","source":"**DIAGNOSE DATA for CLEANING**\n\nWe need to diagnose and clean data before exploring.\n<br>Unclean data:\n* Column name inconsistency like upper-lower case letter or space between words\n* missing data\n* different language\n\n<br> We will use head, tail, columns, shape and info methods to diagnose data"},{"metadata":{"trusted":true,"_uuid":"a241c65d96efee87b48bec41c12f3f711c8a00b2"},"cell_type":"code","source":"data = pd.read_csv('../input/master.csv')\ndata.head()  # head shows first 5 rows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1de7679ffe1ab6c3756aaeb6de7e80b82eb5465a"},"cell_type":"code","source":"# tail shows last 5 rows\ndata.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5f77de6728163e80e473b2754a1fb0f3dfe13de7"},"cell_type":"code","source":"# columns gives column names of features\ndata.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"09fddc36913ff532f28adf5649b6f70ea5281d2b"},"cell_type":"code","source":"# shape gives number of rows and columns in a tuble\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"7a07238e05a9fd7b7dfe3cfeacd7b5987d26165b"},"cell_type":"code","source":"# info gives data type like dataframe, number of sample or row, number of feature or column, feature types and memory usage\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d76f3eaec3c32301285d95231316fc261f090354"},"cell_type":"markdown","source":"### EXPLORATORY DATA ANALYSIS\nvalue_counts(): Frequency counts\n\n**outliers: the value that is considerably higher or lower from rest of the data**\n* Lets say value at 75% is Q3 and value at 25% is Q1. \n* Outlier are smaller than Q1 - 1.5(Q3-Q1) and bigger than Q3 + 1.5(Q3-Q1). (Q3-Q1) = IQR\n\n**We will use describe() method. Describe method includes:**\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry\n\n**What is quantile?**\n\n* 1,4,5,6,8,9,11,12,13,14,15,16,17\n* The median is the number that is in **middle** of the sequence. In this case it would be 11.\n\n* The lower quartile is the median in between the smallest number and the median i.e. in between 1 and 11, which is 6.\n* The upper quartile, you find the median between the median and the largest number i.e. between 11 and 17, which will be 14 according to the question above."},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"4f27b2070e6d6ab01c25bcd2caf38f88e145d09c"},"cell_type":"code","source":"# For example lets look frequency of sex types\nprint(data['sex'].value_counts(dropna =False))  # if there are nan values that also be counted\n# As it can be seen below there are 13910 male, 13910 female  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"423483f564db44faf7a78434c648074af9b26e07"},"cell_type":"code","source":"data.describe() #ignore null entries","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0da2d98ebdd8a8b2c36fe634e1ae2d6679504979"},"cell_type":"markdown","source":"**VISUAL EXPLORATORY DATA ANALYSIS**\n* Box plots: visualize basic statistics like outliers, min/max or quantiles"},{"metadata":{"trusted":true,"_uuid":"020f71a3b892a9bf3954816b8528bb6867cae2af"},"cell_type":"code","source":"# For example: comparison of generation by year\n# Black line at top is max\n# Blue line at top is 75%\n# Red line is median (50%)\n# Blue line at bottom is 25%\n# Black line at bottom is min\n# There are no outliers\n# outlier data is not seen in this analysis\ndata.boxplot(column='year',by = 'generation', figsize = (10,8)) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a9f8593d0e05e2c6f41a336b4d43e46bf9fcfc62"},"cell_type":"markdown","source":"**TIDY DATA**\n\nWe tidy data with melt().\nDescribing melt is confusing. Therefore lets make example to understand it."},{"metadata":{"trusted":true,"_uuid":"613ed6eed9cd690efa935ab6dd94df15472a1b16"},"cell_type":"code","source":"# Firstly I create new data from pokemons data to explain melt nore easily.\ndata_new = data.head()    # I only take 5 rows into new data\ndata_new","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d813ac08c098581ff933464cece8098a2f053a84"},"cell_type":"code","source":"# lets melt\n# id_vars = what we do not wish to melt\n# value_vars = what we want to melt\nmelted = pd.melt(frame=data_new,id_vars = 'country', value_vars= ['year','suicides_no'])\nmelted","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2afc16f295250f21f569bd338e126eb026d5d7b8"},"cell_type":"markdown","source":"** CONCATENATING DATA**\n \nWe can concatenate two dataframe "},{"metadata":{"trusted":true,"_uuid":"3dfd03d741687f76f253221bae839d4f382a7f25"},"cell_type":"code","source":"# Firstly lets create 2 data frame\ndata1 = data.head()\ndata2= data.tail()\nconc_data_row = pd.concat([data1,data2],axis =0,ignore_index =True) # axis = 0 : adds dataframes in row\nconc_data_row","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49be95b4bf336e3e630e696c35283c92495c366e"},"cell_type":"code","source":"data1 = data['country'].head()\ndata2= data['year'].head()\nconc_data_col = pd.concat([data1,data2],axis =1) # axis = 1 : adds dataframes in row\nconc_data_col","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c2b3cd24c210fc37852bd12a56e5d4fddc6f0df6"},"cell_type":"markdown","source":"**DATA TYPES**\n\nThere are 5 basic data types: object(string),booleab,  integer, float and categorical.\n<br> We can make conversion data types like from str to categorical or from int to float\n<br> Why is category important: \n* make dataframe smaller in memory \n* can be utilized for anlaysis especially for sklearn(we will learn later)"},{"metadata":{"trusted":true,"_uuid":"03e2e889471dd51078e68b53adec2a662b509c8a"},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb531f712d43f422da922853c8554af6944ad532"},"cell_type":"code","source":"# lets convert object(str) to categorical\ndata['sex'] = data['sex'].astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fb5961c74000a65a7b1a5bae3e37f43547c74eda"},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"75f99c409f4c04b55f6e54d47d22d3143542fa47"},"cell_type":"markdown","source":"**MISSING DATA and TESTING WITH ASSERT**\n\nIf we encounter with missing data, what we can do:\n* leave as is\n* drop them with dropna()\n* fill missing value with fillna()\n* fill missing values with test statistics like mean\n<br>Assert statement: check that you can turn on or turn off when you are done with your testing of the program"},{"metadata":{"trusted":true,"_uuid":"1803c63bc9f421308a38920f163c8242ff37d067"},"cell_type":"code","source":"# Lets look at does master data have nan value\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd00a9358a47c9b70339fbe598fbc041ccf2b385"},"cell_type":"code","source":"# Lets chech HDI for year\ndata[\"HDI for year\"].value_counts(dropna =False)\n# As you can see, there are 19456 NAN value","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3d3f61860ac907724d86eb49db066c0e767727ea"},"cell_type":"code","source":"# Lets drop NaN values\ndata1=data   # also we will use data to fill missing value so I assign it to data1 variable\ndata1[\"HDI for year\"].dropna(inplace = True)  # inplace = True means we do not assign it to new variable. Changes automatically assigned to data\n# So does it work ?","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"09e7490393c2e746088911bbde1e97f7bdba1bc0"},"cell_type":"code","source":"#  Lets check with assert statement\n# Assert statement:\nassert 1==1 # return nothing because it is true","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"75c9c12dfa28c6c72f5dc7d5863925d779d0679d"},"cell_type":"code","source":"assert  data['HDI for year'].notnull().all() # returns nothing because we drop NaN values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"67a3408e51bdf9da2df43203af0e2a504343dd34"},"cell_type":"code","source":"data[\"HDI for year\"].fillna('empty',inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4f50b6bb1a39596e6af7f0140566468cc77f5a83"},"cell_type":"code","source":"assert  data['HDI for year'].notnull().all() # returns nothing because we do not have nan values","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"48981e4ed57fb58433d5c5db1eff47188ba0da90"},"cell_type":"markdown","source":"**PANDAS FOUNDATION **\n\n**REVİEW of PANDAS**\n\nAs you notice, I do not give all idea in a same time. Although, we learn some basics of pandas, we will go deeper in pandas.\n* single column = series\n* NaN = not a number\n* dataframe.values = numpy"},{"metadata":{"_uuid":"58669fa6eb5b53bc37e3b2c0f0669bf93b405733"},"cell_type":"markdown","source":"**BUILDING DATA FRAMES FROM SCRATCH**\n\n* We can build data frames from csv as we did earlier.\n* Also we can build dataframe from dictionaries\n    * zip() method: This function returns a list of tuples, where the i-th tuple contains the i-th element from each of the argument sequences or iterables.\n* Adding new column\n* Broadcasting: Create new column and assign a value to entire column"},{"metadata":{"trusted":true,"_uuid":"efdf669bed5507721aef4cc33147bce786e3dc4e"},"cell_type":"code","source":"country = [\"Spain\",\"France\"]\npopulation = [\"11\",\"12\"]\nlist_label = [\"country\",\"population\"]\nlist_col = [country,population]\nzipped = list(zip(list_label,list_col))\ndata_dict = dict(zipped)\ndf = pd.DataFrame(data_dict)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"439d3ac7c1d01ac983f945dddd0f73044ad685e8"},"cell_type":"code","source":"# Add new columns\ndf[\"capital\"] = [\"madrid\",\"paris\"]\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b6e10496b12cb42729aabfb6217d3ca93839dffa"},"cell_type":"code","source":"df[\"income\"] = 0 #Broadcasting entire column\ndf","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b3fb1be910427dc2887a3514240ded3267f3ebd4"},"cell_type":"markdown","source":"**VISUAL EXPLORATORY DATA ANALYSIS**\n\n* Plot\n* Subplot\n* Histogram:\n    * bins: number of bins\n    * range(tuble): min and max values of bins\n    * normed(boolean): normalize or not\n    * cumulative(boolean): compute cumulative distribution"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"f7158d86c96d6fded2f5d998fd64de8ddccb13d9"},"cell_type":"code","source":"# Plotting all data \ndata1 = data.loc[:,[\"suicides_no\",\"population\",\"gdp_per_capita ($)\"]]\ndata1.plot()\n# it is confusing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a7266a08eb42221c822c838d0607c3803900b45"},"cell_type":"code","source":"data1.plot(subplots = True, figsize=(10,8))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d148c90b56806324a5e3ba2165529493f2a6d430"},"cell_type":"code","source":"# scatter plot  \ndata1.plot(kind = \"scatter\",x=\"suicides_no\",y = \"gdp_per_capita ($)\", figsize=(10,8))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a94a7bdc659339e3ff59aac9a92298848b8fcb5c"},"cell_type":"code","source":"# hist plot  \ndata1.plot(kind = \"hist\",y = \"suicides_no\",bins = 50,range= (0,250),normed = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"646f46706787eec01a392e67333a6d50fa714213"},"cell_type":"code","source":"# histogram subplot with non cumulative and cumulative\nfig, axes = plt.subplots(nrows=2,ncols=1)\ndata1.plot(kind = \"hist\",y = \"suicides_no\",bins = 50,range= (0,250),normed = True,ax = axes[0])\ndata1.plot(kind = \"hist\",y = \"suicides_no\",bins = 50,range= (0,250),normed = True,ax = axes[1],cumulative = True)\nplt.savefig('graph.png')\nplt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"000f7068cf34f0ab2b1d6668e5ae6eae73ed975a"},"cell_type":"markdown","source":"**INDEXING PANDAS TIME SERIES**\n\n* datetime = object\n* parse_dates(boolean): Transform date to ISO 8601 (yyyy-mm-dd hh:mm:ss ) format"},{"metadata":{"trusted":true,"_uuid":"0da8fb07cc9c09740c77b09d2970b0c8e2d87e22"},"cell_type":"code","source":"time_list = [\"1992-03-08\",\"1992-04-12\"]\nprint(type(time_list[1])) # As you can see date is string\n# however we want it to be datetime object\ndatetime_object = pd.to_datetime(time_list)\nprint(type(datetime_object))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8bc339d0977e2c8c0fbc05fdc761e949ce0dd7d4"},"cell_type":"code","source":"data.head() # index of our data is 012345","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8423643fc5d7ec3a95fc9debccf5c0b3c84e0faf"},"cell_type":"code","source":"# close warning\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# In order to practice lets take head of pokemon data and add it a time list\ndata2 = data.head()\ndate_list = [\"1992-01-10\",\"1992-02-10\",\"1992-03-10\",\"1993-03-15\",\"1993-03-16\"]\ndatetime_object = pd.to_datetime(date_list)\ndata2[\"date\"] = datetime_object\n# lets make date as index\ndata2= data2.set_index(\"date\") # index of our data is date\ndata2 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"2105be7a9adf0bcfb014f61278cfcb87c3b7c0f1"},"cell_type":"code","source":"# Now we can select according to our date index\nprint(data2.loc[\"1993-03-16\"])\nprint(data2.loc[\"1992-03-10\":\"1993-03-16\"])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"35c1b03ce45e22f035162b6719fd1de8b2f0e895"},"cell_type":"markdown","source":"**RESAMPLING PANDAS TIME SERIES**\n\n* Resampling: statistical method over different time intervals\n    * Needs string to specify frequency like \"M\" = month or \"A\" = year\n* Downsampling: reduce date time rows to slower frequency like from daily to weekly\n* Upsampling: increase date time rows to faster frequency like from daily to hourly\n* Interpolate: Interpolate values according to different methods like ‘linear’, ‘time’ or index’ \n    * https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.interpolate.html"},{"metadata":{"trusted":true,"_uuid":"48738a863b09ccd86a01bf34d455eb356631671e"},"cell_type":"code","source":"# We will use data2 that we create at previous part\ndata2.resample(\"A\").mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9273862210e5fad563122b9574b44c1dd79da91b"},"cell_type":"code","source":"# Lets resample with month\ndata2.resample(\"M\").mean()\n# As you can see there are a lot of nan because data2 does not include all months","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5f47a7ce7b8397e5febe22804718cb8092079f81"},"cell_type":"code","source":"# In real life (data is real. Not created from us like data2) we can solve this problem with interpolate\n# We can interpolete from first value\ndata2.resample(\"M\").first().interpolate(\"linear\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"249e1ebb4714fd2f1885bece1b6e3e63b1ff8af1"},"cell_type":"code","source":"# Or we can interpolate with mean()\ndata2.resample(\"M\").mean().interpolate(\"linear\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"05ed64632a04266e93bfc8217a22e5dce3a18347"},"cell_type":"markdown","source":"**MANIPULATING DATA FRAMES WITH PANDAS**\n\nINDEXING DATA FRAMES\n* Indexing using square brackets\n* Using column attribute and row label\n* Using loc accessor\n* Selecting only some columns"},{"metadata":{"trusted":true,"_uuid":"9a67e9f0f6359c8a9ea9aab18cfc7ed6ac2bf351"},"cell_type":"code","source":"# read data\ndata = pd.read_csv('../input/master.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"14ad4e3f72021f81f0465e9a45db6d5b315cb296"},"cell_type":"code","source":"# indexing using square brackets\ndata[\"generation\"][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"222253951cc5cf600419f5e664acfda68c512f0b"},"cell_type":"code","source":"# using column attribute and row label\ndata.generation[0] # a different method","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1111539a4d06325fc3b8e333b0c68bf6387a8522"},"cell_type":"code","source":"# using loc accessor\ndata.loc[0,[\"generation\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cba0a487f54ec92823abe9efa3d8cdc9b21ddf66"},"cell_type":"code","source":"# Selecting only some columns\ndata[[\"age\",\"generation\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"28a2ae941c6655f52fa0ec6f92d5ee7e80ae665d"},"cell_type":"code","source":"# Difference between selecting columns: series and dataframes\nprint(type(data[\"generation\"]))     # series\nprint(type(data[[\"generation\"]]))   # data frames","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc2c115f2ee6cc7a8e2c75586386ced4ce35cdc1"},"cell_type":"code","source":"# Slicing and indexing series\ndata.loc[1:10,\"age\":\"population\"]   # 10 and \"Defense\" are inclusive","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"42ed79f509faf06316543861e10b67df2dbd4d5d"},"cell_type":"code","source":"# Reverse slicing \ndata.loc[10:1:-1,\"age\":\"population\"] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f26ceb5cb09a2152a2d735d667d6af2a084d31f8"},"cell_type":"code","source":"# From something to end\ndata.loc[0:10,\"country-year\":] ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3603dffaa3195e80f2ebb0324cda3bd1a803d092"},"cell_type":"markdown","source":"**FILTERING DATA FRAMES**\n\nCreating boolean series\nCombining filters\nFiltering column based others"},{"metadata":{"trusted":true,"_uuid":"d8a0c4bb6ca1fe034257971522249e63829ff9f9"},"cell_type":"code","source":"boolean = data.year > 2000\ndata[boolean]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"183af13e90071124b88f8e4b5d2e02edff5482f4"},"cell_type":"code","source":"# Combining filters\nfirst_filter = data.year > 2014\nsecond_filter = data.suicides_no > 5000\ndata[first_filter & second_filter]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ac2183f65ae7d6376918320a0c673b5c3dd28a11"},"cell_type":"code","source":"# Filtering column based others\ndata.year[data.suicides_no>20000]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e24d49c6af8928201e08c12c35d3109bcd11f0af"},"cell_type":"markdown","source":"**TRANSFORMING DATA**\n\n* Plain python functions\n* Lambda function: to apply arbitrary python function to every element\n* Defining column using other columns"},{"metadata":{"trusted":true,"_uuid":"3f5e373f2e3ba1d32ebb11c2c2240389356d0f41"},"cell_type":"code","source":"# Plain python functions\ndef div(n):\n    return n/2\ndata.suicides_no.apply(div)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc0626edb943b53be5cf23b3eb3b4f3b2e2ae90d"},"cell_type":"code","source":"# Or we can use lambda function\ndata.suicides_no.apply(lambda n : n/2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c925d6bed5e23bbb908a824e4d487199fcb2e53"},"cell_type":"code","source":"# Defining column using other columns\ndata[\"total_power\"] = data.population + data.suicides_no\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5c360445f4c2d81fbe4c25689f726858bf57d482"},"cell_type":"markdown","source":"**INDEX OBJECTS AND LABELED DATA**\n\nindex: sequence of label"},{"metadata":{"trusted":true,"_uuid":"08d417debfcfd1e3277745aa247720597605218a"},"cell_type":"code","source":"# our index name is this:\nprint(data.index.name)\n# lets change it\ndata.index.name = \"index_name\"\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eff866c6b1589cddf04e34904abb57043e9351e9"},"cell_type":"code","source":"# first copy of our data to data3 then change index \ndata3 = data.copy()\n# lets make index start from 100. It is not remarkable change but it is just example\ndata3.index = range(100,27920,1)\ndata3.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7530f71711d8e6dc1c7a89ad97821d583dfa84f3"},"cell_type":"markdown","source":"**HIERARCHICAL INDEXING**\n\n* Setting indexing"},{"metadata":{"trusted":true,"_uuid":"f2d4777632b41b6846bf9acc075a42faf26f99f8"},"cell_type":"code","source":"# lets read data frame one more time to start from beginning\ndata = pd.read_csv('../input/master.csv')\ndata.head()\n# As you can see there is index. However we want to set one or more column to be index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe83d784605fd000aec899267084aa91d04e84e9"},"cell_type":"code","source":"# Setting index : type 1 is outer type 2 is inner index\ndata1 = data.set_index([\"year\",\"generation\"]) \ndata1.head(100)\n# data1.loc[\"Fire\",\"Flying\"] # howw to use indexes","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fde9886f406d20a1f4002a2bae0f969accef8535"},"cell_type":"markdown","source":"**PIVOTING DATA FRAMES**\n\n* pivoting: reshape tool"},{"metadata":{"trusted":true,"_uuid":"cb5120fc99da1fe60ec275a5b39a696e74ac5713"},"cell_type":"code","source":"dic = {\"treatment\":[\"A\",\"A\",\"B\",\"B\"],\"gender\":[\"F\",\"M\",\"F\",\"M\"],\"response\":[10,45,5,9],\"age\":[15,4,72,65]}\ndf = pd.DataFrame(dic)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa5d4cd0a3d6616de4a814ad2930c3816ec605fe"},"cell_type":"code","source":"# pivoting\ndf.pivot(index=\"treatment\",columns = \"gender\",values=\"response\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5d5eb5bc47534fcf2d8c314fbcdb3fbeeec7691c"},"cell_type":"markdown","source":"**STACKING and UNSTACKING DATAFRAME**\n\n* deal with multi label indexes\n* level: position of unstacked index\n* swaplevel: change inner and outer level index position"},{"metadata":{"trusted":true,"_uuid":"15e56faf36d99be92c2e119a1c330e0a07fd1176"},"cell_type":"code","source":"df1 = df.set_index([\"treatment\",\"gender\"])\ndf1\n# lets unstack it","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df3bff75d1fa2ab69476a7a6b1c98ff7b1a8e62d"},"cell_type":"code","source":"# level determines indexes\ndf1.unstack(level=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"182500ff050132767fd0395571a9cc7eacfff9aa"},"cell_type":"code","source":"df1.unstack(level=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"029dc4d76e61f614211ef1bfb2efb2a5a12e1b65"},"cell_type":"code","source":"# change inner and outer level index position\ndf2 = df1.swaplevel(0,1)\ndf2","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7067abd34c9dd210b0b7cf79f80b17c871d91726"},"cell_type":"markdown","source":"**MELTING DATA FRAMES**\n\n* Reverse of pivoting"},{"metadata":{"trusted":true,"_uuid":"65a9422c14c5ac14acace18b17cbb0a492682d4a"},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df57ce2b56bd42d77ac99c530cc1410408fa747f"},"cell_type":"code","source":"# df.pivot(index=\"treatment\",columns = \"gender\",values=\"response\")\npd.melt(df,id_vars=\"treatment\",value_vars=[\"age\",\"response\"])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fdf92cf7ac10567321217708680a30530a59914f"},"cell_type":"markdown","source":"**CATEGORICALS AND GROUPBY**"},{"metadata":{"trusted":true,"_uuid":"2af9069f8ee7f12c994a38bd8e18cbe4db89f2e1"},"cell_type":"code","source":"# according to treatment take means of other features\ndf.groupby(\"treatment\").mean()   # mean is aggregation / reduction method\n# there are other methods like sum, std,max or min","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"90f7ef153f80081ae4924940b00d9cc9fa68876e"},"cell_type":"code","source":"# we can only choose one of the feature\ndf.groupby(\"treatment\").age.max() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59df8919a8efa5bbd834da484d385045592d5e9a"},"cell_type":"code","source":"df.groupby(\"treatment\")[[\"age\",\"response\"]].min() ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}