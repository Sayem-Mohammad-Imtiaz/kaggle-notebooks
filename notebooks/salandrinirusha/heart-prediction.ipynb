{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"## DATASET COLUMNS \n1. Age (age in years)\n2. Sex (1 = male; 0 = female)\n3. CP (chest pain type)\n4. TRESTBPS (resting blood pressure (in mm Hg on admission to the hospital))\n5. CHOL (serum cholestoral in mg/dl)\n6. FPS (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n7. RESTECH (resting electrocardiographic results)\n8. THALACH (maximum heart rate achieved)\n9. EXANG (exercise induced angina (1 = yes; 0 = no))\n10. OLDPEAK (ST depression induced by exercise relative to rest)\n11. SLOPE (the slope of the peak exercise ST segment)\n12. CA (number of major vessels (0-3) colored by flourosopy)\n13. THAL (3 = normal; 6 = fixed defect; 7 = reversable defect)\n14. TARGET (1 or 0)"},{"metadata":{},"cell_type":"markdown","source":"# Import necessary Python modules and Read the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Heart_Disease =pd.read_csv('/kaggle/input/heart-disease-uci/heart.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Heart_Disease.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis (EDA)"},{"metadata":{"trusted":true},"cell_type":"code","source":"Heart_Disease.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Heart_Disease.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Heart_Disease.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Heart_Disease.shape ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Heart_Disease.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Heart_Disease.isnull().values.any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking for Outlier's\nsns.boxplot(x=Heart_Disease)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Discover outliers with mathematical function\n#Z-Score\n#if the Z-score value is greater than or less than 3 or -3 respectively, that data point will be identified as outliers.\nfrom scipy import stats\nimport numpy as np\nz = np.abs(stats.zscore(Heart_Disease))\nprint(z)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.heatmap(Heart_Disease.corr(),annot=True,fmt='.1f')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(Heart_Disease)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x=Heart_Disease.age.value_counts()[:10].index,y=Heart_Disease.age.value_counts()[:10].values)\nplt.xlabel('Age')\nplt.ylabel('Age Counter')\nplt.title('Age Analysis')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"minAge=min(Heart_Disease.age)\nmaxAge=max(Heart_Disease.age)\nmeanAge=Heart_Disease.age.mean()\nprint('Min Age :',minAge)\nprint('Max Age :',maxAge)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"young_ages=Heart_Disease[(Heart_Disease.age>=29)&(Heart_Disease.age<40)]\nmiddle_ages=Heart_Disease[(Heart_Disease.age>=40)&(Heart_Disease.age<55)]\nelderly_ages=Heart_Disease[(Heart_Disease.age>55)]\nprint('Young Ages :',len(young_ages))\nprint('Middle Ages :',len(middle_ages))\nprint('Elderly Ages :',len(elderly_ages))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x=['young ages','middle ages','elderly ages'],y=[len(young_ages),len(middle_ages),len(elderly_ages)])\nplt.xlabel('Age Range')\nplt.ylabel('Age Counts')\nplt.title('Ages State in Dataset')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = ['blue','green','yellow']\nexplode = [0,0,0.1]\nplt.figure(figsize = (5,5))\n#plt.pie([target_0_agerang_0,target_1_agerang_0], explode=explode, labels=['Target 0 Age Range 0','Target 1 Age Range 0'], colors=colors, autopct='%1.1f%%')\nplt.pie([len(young_ages),len(middle_ages),len(elderly_ages)],labels=['young ages','middle ages','elderly ages'],explode=explode,colors=colors, autopct='%1.1f%%')\nplt.title('Age States',color = 'blue',fontsize = 15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Sex (1 = male; 0 = female)\nsns.countplot(Heart_Disease.sex)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(Heart_Disease.cp)\nplt.xlabel('Chest Type')\nplt.ylabel('Count')\nplt.title('Chest Type vs Count State')\nplt.show()\n#0 status at least\n#1 condition slightly distressed\n#2 condition medium problem\n#3 condition too bad","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show the results of a linear regression within each dataset\nsns.lmplot(x=\"trestbps\", y=\"chol\",data=Heart_Disease,hue=\"cp\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x=Heart_Disease.thalach.value_counts()[:20].index,y=Heart_Disease.thalach.value_counts()[:20].values)\nplt.xlabel('Thalach')\nplt.ylabel('Count')\nplt.title('Thalach Counts')\nplt.xticks(rotation=45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(Heart_Disease.thal)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's see the correlation values between them\nHeart_Disease.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Splitting Data into train and test with 70% and 20% respectively \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=Heart_Disease.drop(['target','slope'],axis=1)\n#removing 'slope' to reduce the strong negative multicollinearity between 'slope' and 'oldpeak'\nY=Heart_Disease['target']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# All Classification Algorithms with Default Parameters\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)\nlogit = sm.Logit(y_train, X_train).fit()\nprint(logit.summary())\n# attributes with p value less than 0.05 are statistically significant","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=X.drop(['restecg','fbs','chol','trestbps','age'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)\nlogit = sm.Logit(y_train, X_train).fit()\nprint(logit.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = logit.predict(X_test)\nprediction = list(map(round, y_pred)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\ncm1= confusion_matrix(y_test,prediction)\nprint('Confusion Matrix : ')\nprint(cm1)\nfrom sklearn.metrics import accuracy_score\nprint (\"Accuracy Score : \", accuracy_score(y_test, prediction))\nprint ('Report : ')\nprint (classification_report(y_test, prediction))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Sensitivity and Specificity\n#A test with a sensitivity and specificity of around 90% would be considered to have good diagnostic performance)\n\nsensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\nprint('Sensitivity : ', sensitivity )\n\nspecificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\nprint('Specificity : ', specificity)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Logistic Regression Algorithm\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\nfrom sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()\nmodel.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(X_test)\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, roc_curve, auc\nacclog = accuracy_score(y_test, y_pred)*100\nreclog = recall_score(y_test, y_pred)*100\npreclog = precision_score(y_test, y_pred)*100\nfprlog, tprlog, _ = roc_curve(y_test, y_pred)\nauclog=auc(fprlog, tprlog)*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm1= confusion_matrix(y_test,y_pred)\nprint('Confusion Matrix :' )\nprint(cm1)\nfrom sklearn.metrics import accuracy_score\nprint (\"Accuracy Score: \", accuracy_score(y_test, y_pred))\nprint ('Report : ')\nprint (classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Sensitivity and Specificity\n#A test with a sensitivity and specificity of around 90% would be considered to have good diagnostic performance)\n\nsensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\nprint('Sensitivity : ', sensitivity )\n\nspecificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\nprint('Specificity : ', specificity)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yl = model.predict_proba(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. K Nearest Neighbor Algorithm\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\n# Fitting K-NN to the Training set\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 5, metric = 'euclidean')\nknn.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred = knn.predict(X_test)\n\nyk = knn.predict_proba(X_test)\n\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, roc_curve, auc\naccknn = accuracy_score(y_test, y_pred)*100\nrecknn = recall_score(y_test, y_pred)*100\nprecknn = precision_score(y_test, y_pred)*100\nfprknn, tprknn, _ = roc_curve(y_test, y_pred)\naucknn=auc(fprknn, tprknn)*100\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm2 = confusion_matrix(y_test, y_pred)\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\n\nresults = confusion_matrix(y_test, y_pred)\nprint ('Confusion Matrix :')\nprint(results)\nprint ('Accuracy Score :',accuracy_score(y_test, y_pred))\nprint ('Report : ')\nprint (classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sensitivity = cm2[0,0]/(cm2[0,0]+cm2[0,1])\nprint('Sensitivity : ', sensitivity )\n\nspecificity = cm2[1,1]/(cm2[1,0]+cm2[1,1])\nprint('Specificity : ', specificity)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3.Support Vector Machine Algorithm\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting Kernel SVM to the Training set\nfrom sklearn.svm import SVC\nsvm = SVC(kernel = 'rbf', random_state = 0, probability=True)\nsvm.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred = svm.predict(X_test)\n\nys = svm.predict_proba(X_test)\n\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, roc_curve, auc\naccsvm = accuracy_score(y_test, y_pred)*100\nrecsvm = recall_score(y_test, y_pred)*100\nprecsvm = precision_score(y_test, y_pred)*100\nfprsvm, tprsvm, _ = roc_curve(y_test, y_pred)\naucsvm=auc(fprsvm, tprsvm)*100\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm3 = confusion_matrix(y_test, y_pred)\n\nresults = confusion_matrix(y_test, y_pred)\nprint ('Confusion Matrix :')\nprint(results)\nprint ('Accuracy Score :',accuracy_score(y_test, y_pred))\nprint ('Report : ')\nprint (classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sensitivity = cm3[0,0]/(cm3[0,0]+cm3[0,1])\nprint('Sensitivity : ', sensitivity )\n\nspecificity = cm3[1,1]/(cm3[1,0]+cm3[1,1])\nprint('Specificity : ', specificity)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Gaussian Naive Bayes Algorithm\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()\ngnb.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred = gnb.predict(X_test)\n\nyg = gnb.predict_proba(X_test)\n\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, roc_curve, auc\naccgnb = accuracy_score(y_test, y_pred)*100\nrecgnb = recall_score(y_test, y_pred)*100\nprecgnb = precision_score(y_test, y_pred)*100\nfprgnb, tprgnb, _ = roc_curve(y_test, y_pred)\naucgnb=auc(fprgnb, tprgnb)*100\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm4 = confusion_matrix(y_test, y_pred)\n\nresults = confusion_matrix(y_test, y_pred)\nprint ('Confusion Matrix :')\nprint(results)\nprint ('Accuracy Score :',accuracy_score(y_test, y_pred))\nprint ('Report : ')\nprint (classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sensitivity = cm4[0,0]/(cm4[0,0]+cm4[0,1])\nprint('Sensitivity : ', sensitivity )\n\nspecificity = cm4[1,1]/(cm4[1,0]+cm4[1,1])\nprint('Specificity : ', specificity)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Comparison of all the Machine Learning Algorithms by Comparing some Evaluation Metrics\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"algos=[\"Logistic Regression\",\"K Nearest Neighbor\",\"Support Vector Machine\",\"Gaussian Naive Bayes\"]\nacc=[acclog,accknn,accsvm,accgnb]\nauc=[auclog,aucknn,aucsvm,aucgnb]\nrecall=[reclog,recknn,recsvm,recgnb]\nprec=[preclog,precknn,precsvm,precgnb]\ncomp={\"Algorithms\":algos,\"Accuracies\":acc,\"Area Under the Curve\":auc,\"Recall\":recall,\"Precision\":prec}\ncompdf=pd.DataFrame(comp)\ndisplay(compdf)\n#display(compdf.sort_values(by=[\"Accuracies\",\"Area Under the Curve\",\"Recall\",\"Precision\"], ascending=False))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ROC of all the Machine Learning Algorithms on default parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn.metrics as metrics\nroc_auc1=metrics.auc(fprlog,tprlog)\nroc_auc2=metrics.auc(fprknn,tprknn)\nroc_auc3=metrics.auc(fprsvm,tprsvm)\nroc_auc4=metrics.auc(fprgnb,tprgnb)\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.figure(figsize=(20,10))\nplt.title(\"Performance Comparison of Classification Models (ROC Curve)\", fontsize=25)\nplt.plot(fprlog,tprlog,\"b\",label=\"AUC of Logistic Regression = %0.2f\" % roc_auc1)\nplt.plot(fprknn,tprknn,\"g\",label=\"AUC of K Nearest Neighbor = %0.2f\" % roc_auc2)\nplt.plot(fprsvm,tprsvm,\"m\",label=\"AUC of Support Vector Machine = %0.2f\" % roc_auc3)\nplt.plot(fprgnb,tprgnb,\"c\",label=\"AUC of Gaussian Naive Bayes = %0.2f\" % roc_auc4)\nplt.rcParams.update({'font.size': 16})\nplt.legend(loc=\"lower right\")\nplt.plot([0, 1],[0, 1],\"r--\")\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel(\"True Positive Rate\", fontsize = 18)\nplt.xlabel(\"False Positive Rate\", fontsize = 18)\n\nplt.rc('axes', labelsize=15)\nplt.rc('axes', titlesize=22)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cross Validation Score "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_log1 = cross_val_score(model, X, Y, scoring='accuracy', cv = 10)\n#print('CVS for log1 : ', accuracy_svc)\nprint(\"Accuracy of LOG with Cross Validation is:\",accuracy_log1.mean() * 100)\n#accuracy_log = cross_val_score(log, X, Y, cv = 10)\n#print('CVS for LOG : ', accuracy_svc)\n#print(\"Accuracy of LOG with Cross Validation is:\",accuracy_log.mean() * 100)\naccuracy_svc = cross_val_score(svm, X, Y, cv = 10)\n#print('CVS for SVC : ', accuracy_svc)\nprint(\"Accuracy of SVC with Cross Validation is:\",accuracy_svc.mean() * 100)\naccuracy_gnb = cross_val_score(gnb, X, Y, scoring='accuracy', cv = 10)\n#print('CVS for GNB : ', accuracy_gnb)\nprint(\"Accuracy of GNB with Cross Validation is:\",accuracy_gnb.mean() * 100)\naccuracy_knn = cross_val_score(knn, X, Y, scoring='accuracy', cv = 10)\n#print('CVS for knn : ', accuracy_gnb)\nprint(\"Accuracy of KNN with Cross Validation is:\",accuracy_knn.mean() * 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"algos=[\"Logistic Regression\",\"K Nearest Neighbor\",\"Support Vector Machine\",\"Gaussian Naive Bayes\"]\nacc1=[acclog,accknn,accsvm,accgnb]\nacc2=[accuracy_log1.mean() * 100, accuracy_knn.mean() * 100, accuracy_svc.mean() * 100, accuracy_gnb.mean() * 100]\ncomp={\"Algorithms\":algos,\"Accuracies without Cross Validation\":acc1,\"Accuracies with Cross Validation\":acc2}\ncompdf=pd.DataFrame(comp)\ndisplay(compdf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}