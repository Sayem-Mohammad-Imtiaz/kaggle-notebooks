{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom tqdm.auto import tqdm\nfrom torchvision import transforms\nimport torchvision.datasets as datasets\nfrom torchvision.datasets import Cityscapes,FashionMNIST,QMNIST\nfrom torchvision.datasets import EMNIST # Training dataset\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nprint(os.listdir(\"../input\"))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from os import walk\nfor (dirpath, dirnames, filenames) in walk(\"../input/\"):\n    print(\"Directory path: \", dirpath)\n    print(\"Folder name: \", dirnames)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nimport torch\nfrom torchvision import datasets,transforms","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = '../input/pokemon-images-and-types/images/'\ndataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.manual_seed(0) # Set for testing purposes, please do not change!\n\ndef show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28)):\n    '''\n    Function for visualizing images: Given a tensor of images, number of images, and\n    size per image, plots and prints the images in a uniform grid.\n    '''\n    image_unflat = image_tensor.detach().cpu().view(-1, *size)\n    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n# GRADED FUNCTION: get_generator_block\ndef get_generator_block(input_dim, output_dim):\n    '''\n    Function for returning a block of the generator's neural network\n    given input and output dimensions.\n    Parameters:\n        input_dim: the dimension of the input vector, a scalar\n        output_dim: the dimension of the output vector, a scalar\n    Returns:\n        a generator neural network layer, with a linear transformation \n          followed by a batch normalization and then a relu activation\n    '''\n    return nn.Sequential(\n        # Hint: Replace all of the \"None\" with the appropriate dimensions.\n        # The documentation may be useful if you're less familiar with PyTorch:\n        # https://pytorch.org/docs/stable/nn.html.\n        #### START CODE HERE ####\n        nn.Linear(input_dim, output_dim),\n        nn.BatchNorm1d(output_dim),\n        nn.ReLU(inplace=True),\n        #### END CODE HERE ####\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verify the generator block function\ndef test_gen_block(in_features, out_features, num_test=1000):\n    block = get_generator_block(in_features, out_features)\n\n    # Check the three parts\n    assert len(block) == 3\n    assert type(block[0]) == nn.Linear\n    assert type(block[1]) == nn.BatchNorm1d\n    assert type(block[2]) == nn.ReLU\n    \n    # Check the output shape\n    test_input = torch.randn(num_test, in_features)\n    test_output = block(test_input)\n    assert tuple(test_output.shape) == (num_test, out_features)\n    assert test_output.std() > 0.55\n    assert test_output.std() < 0.65\n\ntest_gen_block(25, 12)\ntest_gen_block(15, 28)\nprint(\"Success!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# UNQ_C2 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n# GRADED FUNCTION: Generator\nclass Generator(nn.Module):\n    '''\n    Generator Class\n    Values:\n        z_dim: the dimension of the noise vector, a scalar\n        im_dim: the dimension of the images, fitted for the dataset used, a scalar\n          (MNIST images are 28 x 28 = 784 so that is your default)\n        hidden_dim: the inner dimension, a scalar\n    '''\n    def __init__(self, z_dim=10, im_dim=784, hidden_dim=128):\n        super(Generator, self).__init__()\n        # Build the neural network\n        self.gen = nn.Sequential(\n            get_generator_block(z_dim, hidden_dim),\n            get_generator_block(hidden_dim, hidden_dim * 2),\n            get_generator_block(hidden_dim * 2, hidden_dim * 4),\n            get_generator_block(hidden_dim * 4, hidden_dim * 8),\n            # There is a dropdown with hints if you need them! \n            #### START CODE HERE ####\n            nn.Linear(hidden_dim * 8, im_dim),\n            nn.Sigmoid()\n            \n            #### END CODE HERE ####\n        )\n    def forward(self, noise):\n        '''\n        Function for completing a forward pass of the generator: Given a noise tensor, \n        returns generated images.\n        Parameters:\n            noise: a noise tensor with dimensions (n_samples, z_dim)\n        '''\n        return self.gen(noise)\n    \n    # Needed for grading\n    def get_gen(self):\n        '''\n        Returns:\n            the sequential model\n        '''\n        return self.gen","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verify the generator class\ndef test_generator(z_dim, im_dim, hidden_dim, num_test=10000):\n    gen = Generator(z_dim, im_dim, hidden_dim).get_gen()\n    \n    # Check there are six modules in the sequential part\n    assert len(gen) == 6\n    test_input = torch.randn(num_test, z_dim)\n    test_output = gen(test_input)\n\n    # Check that the output shape is correct\n    assert tuple(test_output.shape) == (num_test, im_dim)\n    assert test_output.max() < 1, \"Make sure to use a sigmoid\"\n    assert test_output.min() > 0, \"Make sure to use a sigmoid\"\n    assert test_output.min() < 0.5, \"Don't use a block in your solution\"\n    assert test_output.std() > 0.05, \"Don't use batchnorm here\"\n    assert test_output.std() < 0.15, \"Don't use batchnorm here\"\n\ntest_generator(5, 10, 20)\ntest_generator(20, 8, 24)\nprint(\"Success!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# UNQ_C3 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n# GRADED FUNCTION: get_noise\ndef get_noise(n_samples, z_dim, device='cpu'):\n    '''\n    Function for creating noise vectors: Given the dimensions (n_samples, z_dim),\n    creates a tensor of that shape filled with random numbers from the normal distribution.\n    Parameters:\n        n_samples: the number of samples to generate, a scalar\n        z_dim: the dimension of the noise vector, a scalar\n        device: the device type\n    '''\n    # NOTE: To use this on GPU with device='cuda', make sure to pass the device \n    # argument to the function you use to generate the noise.\n    #### START CODE HERE ####\n    return torch.randn(n_samples, z_dim, device=device)\n    #### END CODE HERE ####","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verify the noise vector function\ndef test_get_noise(n_samples, z_dim, device='cpu'):\n    noise = get_noise(n_samples, z_dim, device)\n    \n    # Make sure a normal distribution was used\n    assert tuple(noise.shape) == (n_samples, z_dim)\n    assert torch.abs(noise.std() - torch.tensor(1.0)) < 0.01\n    assert str(noise.device).startswith(device)\n\ntest_get_noise(1000, 100, 'cpu')\nif torch.cuda.is_available():\n    test_get_noise(1000, 32, 'cuda')\nprint(\"Success!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# UNQ_C4 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n# GRADED FUNCTION: get_discriminator_block\ndef get_discriminator_block(input_dim, output_dim):\n    '''\n    Discriminator Block\n    Function for returning a neural network of the discriminator given input and output dimensions.\n    Parameters:\n        input_dim: the dimension of the input vector, a scalar\n        output_dim: the dimension of the output vector, a scalar\n    Returns:\n        a discriminator neural network layer, with a linear transformation \n          followed by an nn.LeakyReLU activation with negative slope of 0.2 \n          (https://pytorch.org/docs/master/generated/torch.nn.LeakyReLU.html)\n    '''\n    return nn.Sequential(\n        #### START CODE HERE ####\n        nn.Linear(input_dim, output_dim),\n        nn.LeakyReLU(0.2, inplace=True)\n        #### END CODE HERE ####\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verify the discriminator block function\ndef test_disc_block(in_features, out_features, num_test=10000):\n    block = get_discriminator_block(in_features, out_features)\n\n    # Check there are two parts\n    assert len(block) == 2\n    test_input = torch.randn(num_test, in_features)\n    test_output = block(test_input)\n\n    # Check that the shape is right\n    assert tuple(test_output.shape) == (num_test, out_features)\n    \n    # Check that the LeakyReLU slope is about 0.2\n    assert -test_output.min() / test_output.max() > 0.1\n    assert -test_output.min() / test_output.max() < 0.3\n    assert test_output.std() > 0.3\n    assert test_output.std() < 0.5\n\ntest_disc_block(25, 12)\ntest_disc_block(15, 28)\nprint(\"Success!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# UNQ_C5 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n# GRADED FUNCTION: Discriminator\nclass Discriminator(nn.Module):\n    '''\n    Discriminator Class\n    Values:\n        im_dim: the dimension of the images, fitted for the dataset used, a scalar\n            (MNIST images are 28x28 = 784 so that is your default)\n        hidden_dim: the inner dimension, a scalar\n    '''\n    def __init__(self, im_dim=784, hidden_dim=128):\n        super(Discriminator, self).__init__()\n        self.disc = nn.Sequential(\n            get_discriminator_block(im_dim, hidden_dim * 4),\n            get_discriminator_block(hidden_dim * 4, hidden_dim * 2),\n            get_discriminator_block(hidden_dim * 2, hidden_dim),\n            # Hint: You want to transform the final output into a single value,\n            #       so add one more linear map.\n            #### START CODE HERE ####\n            nn.Linear(hidden_dim, 1)\n            \n            #### END CODE HERE ####\n        )\n\n    def forward(self, image):\n        '''\n        Function for completing a forward pass of the discriminator: Given an image tensor, \n        returns a 1-dimension tensor representing fake/real.\n        Parameters:\n            image: a flattened image tensor with dimension (im_dim)\n        '''\n        return self.disc(image)\n    \n    # Needed for grading\n    def get_disc(self):\n        '''\n        Returns:\n            the sequential model\n        '''\n        return self.disc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verify the discriminator class\ndef test_discriminator(z_dim, hidden_dim, num_test=100):\n    \n    disc = Discriminator(z_dim, hidden_dim).get_disc()\n\n    # Check there are three parts\n    assert len(disc) == 4\n\n    # Check the linear layer is correct\n    test_input = torch.randn(num_test, z_dim)\n    test_output = disc(test_input)\n    assert tuple(test_output.shape) == (num_test, 1)\n    \n    # Don't use a block\n    assert not isinstance(disc[-1], nn.Sequential)\n\ntest_discriminator(5, 10)\ntest_discriminator(20, 8)\nprint(\"Success!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set your parameters\ncriterion = nn.BCEWithLogitsLoss()\nn_epochs = 200\nz_dim = 64\ndisplay_step = 500\nbatch_size = 128\nlr = 0.00001\n\n# Load MNIST dataset as tensors\ndataloader = DataLoader(\n    FashionMNIST('.',download=True,transform=transforms.ToTensor()),\n    batch_size=batch_size,\n    shuffle=True)\n\n### DO NOT EDIT ###\ndevice = 'cuda'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gen = Generator(z_dim).to(device)\ngen_opt = torch.optim.Adam(gen.parameters(), lr=lr)\ndisc = Discriminator().to(device)\ndisc_opt = torch.optim.Adam(disc.parameters(), lr=lr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# UNQ_C6 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n# GRADED FUNCTION: get_disc_loss\ndef get_disc_loss(gen, disc, criterion, real, num_images, z_dim, device):\n    '''\n    Return the loss of the discriminator given inputs.\n    Parameters:\n        gen: the generator model, which returns an image given z-dimensional noise\n        disc: the discriminator model, which returns a single-dimensional prediction of real/fake\n        criterion: the loss function, which should be used to compare \n               the discriminator's predictions to the ground truth reality of the images \n               (e.g. fake = 0, real = 1)\n        real: a batch of real images\n        num_images: the number of images the generator should produce, \n                which is also the length of the real images\n        z_dim: the dimension of the noise vector, a scalar\n        device: the device type\n    Returns:\n        disc_loss: a torch scalar loss value for the current batch\n    '''\n    #     These are the steps you will need to complete:\n    #       1) Create noise vectors and generate a batch (num_images) of fake images. \n    #            Make sure to pass the device argument to the noise.\n    #       2) Get the discriminator's prediction of the fake image \n    #            and calculate the loss. Don't forget to detach the generator!\n    #            (Remember the loss function you set earlier -- criterion. You need a \n    #            'ground truth' tensor in order to calculate the loss. \n    #            For example, a ground truth tensor for a fake image is all zeros.)\n    #       3) Get the discriminator's prediction of the real image and calculate the loss.\n    #       4) Calculate the discriminator's loss by averaging the real and fake loss\n    #            and set it to disc_loss.\n    #     Note: Please do not use concatenation in your solution. The tests are being updated to \n    #           support this, but for now, average the two losses as described in step (4).\n    #     *Important*: You should NOT write your own loss function here - use criterion(pred, true)!\n    #### START CODE HERE ####\n    fake_noise=get_noise(num_images, z_dim, device=device)\n    fake=gen(fake_noise)\n    disc_fake_pred = disc(fake.detach())\n    disc_fake_loss = criterion(disc_fake_pred, torch.zeros_like(disc_fake_pred))\n    disc_real_pred = disc(real.detach())\n    disc_real_loss = criterion(disc_real_pred, torch.ones_like(disc_real_pred))\n    disc_loss = (disc_fake_loss + disc_real_loss)/2\n    #### END CODE HERE ####\n    return disc_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_disc_reasonable(num_images=10):\n    # Don't use explicit casts to cuda - use the device argument\n    import inspect, re\n    lines = inspect.getsource(get_disc_loss)\n    assert (re.search(r\"to\\(.cuda.\\)\", lines)) is None\n    assert (re.search(r\"\\.cuda\\(\\)\", lines)) is None\n    \n    z_dim = 64\n    gen = torch.zeros_like\n    disc = lambda x: x.mean(1)[:, None]\n    criterion = torch.mul # Multiply\n    real = torch.ones(num_images, z_dim)\n    disc_loss = get_disc_loss(gen, disc, criterion, real, num_images, z_dim, 'cpu')\n    assert torch.all(torch.abs(disc_loss.mean() - 0.5) < 1e-5)\n    \n    gen = torch.ones_like\n    criterion = torch.mul # Multiply\n    real = torch.zeros(num_images, z_dim)\n    assert torch.all(torch.abs(get_disc_loss(gen, disc, criterion, real, num_images, z_dim, 'cpu')) < 1e-5)\n    \n    gen = lambda x: torch.ones(num_images, 10)\n    disc = lambda x: x.mean(1)[:, None] + 10\n    criterion = torch.mul # Multiply\n    real = torch.zeros(num_images, 10)\n    assert torch.all(torch.abs(get_disc_loss(gen, disc, criterion, real, num_images, z_dim, 'cpu').mean() - 5) < 1e-5)\n\n    gen = torch.ones_like\n    disc = nn.Linear(64, 1, bias=False)\n    real = torch.ones(num_images, 64) * 0.5\n    disc.weight.data = torch.ones_like(disc.weight.data) * 0.5\n    disc_opt = torch.optim.Adam(disc.parameters(), lr=lr)\n    criterion = lambda x, y: torch.sum(x) + torch.sum(y)\n    disc_loss = get_disc_loss(gen, disc, criterion, real, num_images, z_dim, 'cpu').mean()\n    disc_loss.backward()\n    assert torch.isclose(torch.abs(disc.weight.grad.mean() - 11.25), torch.tensor(3.75))\n    \ndef test_disc_loss(max_tests = 10):\n    z_dim = 64\n    gen = Generator(z_dim).to(device)\n    gen_opt = torch.optim.Adam(gen.parameters(), lr=lr)\n    disc = Discriminator().to(device) \n    disc_opt = torch.optim.Adam(disc.parameters(), lr=lr)\n    num_steps = 0\n    for real, _ in dataloader:\n        cur_batch_size = len(real)\n        real = real.view(cur_batch_size, -1).to(device)\n\n        ### Update discriminator ###\n        # Zero out the gradient before backpropagation\n        disc_opt.zero_grad()\n\n        # Calculate discriminator loss\n        disc_loss = get_disc_loss(gen, disc, criterion, real, cur_batch_size, z_dim, device)\n        assert (disc_loss - 0.68).abs() < 0.05\n\n        # Update gradients\n        disc_loss.backward(retain_graph=True)\n\n        # Check that they detached correctly\n        assert gen.gen[0][0].weight.grad is None\n\n        # Update optimizer\n        old_weight = disc.disc[0][0].weight.data.clone()\n        disc_opt.step()\n        new_weight = disc.disc[0][0].weight.data\n        \n        # Check that some discriminator weights changed\n        assert not torch.all(torch.eq(old_weight, new_weight))\n        num_steps += 1\n        if num_steps >= max_tests:\n            break\n\ntest_disc_reasonable()\ntest_disc_loss()\nprint(\"Success!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# UNQ_C7 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n# GRADED FUNCTION: get_gen_loss\ndef get_gen_loss(gen, disc, criterion, num_images, z_dim, device):\n    '''\n    Return the loss of the generator given inputs.\n    Parameters:\n        gen: the generator model, which returns an image given z-dimensional noise\n        disc: the discriminator model, which returns a single-dimensional prediction of real/fake\n        criterion: the loss function, which should be used to compare \n               the discriminator's predictions to the ground truth reality of the images \n               (e.g. fake = 0, real = 1)\n        num_images: the number of images the generator should produce, \n                which is also the length of the real images\n        z_dim: the dimension of the noise vector, a scalar\n        device: the device type\n    Returns:\n        gen_loss: a torch scalar loss value for the current batch\n    '''\n    #     These are the steps you will need to complete:\n    #       1) Create noise vectors and generate a batch of fake images. \n    #           Remember to pass the device argument to the get_noise function.\n    #       2) Get the discriminator's prediction of the fake image.\n    #       3) Calculate the generator's loss. Remember the generator wants\n    #          the discriminator to think that its fake images are real\n    #     *Important*: You should NOT write your own loss function here - use criterion(pred, true)!\n\n    #### START CODE HERE ####\n    fake_noise = get_noise(num_images, z_dim, device=device)\n    fake = gen(fake_noise)\n    disc_fake_pred = disc(fake)\n    gen_loss = criterion(disc_fake_pred, torch.ones_like(disc_fake_pred)) #to have positive insight. (1-loss)\n     \n    #### END CODE HERE ####\n    return gen_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_gen_reasonable(num_images=10):\n    # Don't use explicit casts to cuda - use the device argument\n    import inspect, re\n    lines = inspect.getsource(get_gen_loss)\n    assert (re.search(r\"to\\(.cuda.\\)\", lines)) is None\n    assert (re.search(r\"\\.cuda\\(\\)\", lines)) is None\n    \n    z_dim = 64\n    gen = torch.zeros_like\n    disc = nn.Identity()\n    criterion = torch.mul # Multiply\n    gen_loss_tensor = get_gen_loss(gen, disc, criterion, num_images, z_dim, 'cpu')\n    assert torch.all(torch.abs(gen_loss_tensor) < 1e-5)\n    #Verify shape. Related to gen_noise parametrization\n    assert tuple(gen_loss_tensor.shape) == (num_images, z_dim)\n\n    gen = torch.ones_like\n    disc = nn.Identity()\n    criterion = torch.mul # Multiply\n    real = torch.zeros(num_images, 1)\n    gen_loss_tensor = get_gen_loss(gen, disc, criterion, num_images, z_dim, 'cpu')\n    assert torch.all(torch.abs(gen_loss_tensor - 1) < 1e-5)\n    #Verify shape. Related to gen_noise parametrization\n    assert tuple(gen_loss_tensor.shape) == (num_images, z_dim)\n    \n\ndef test_gen_loss(num_images):\n    z_dim = 64\n    gen = Generator(z_dim).to(device)\n    gen_opt = torch.optim.Adam(gen.parameters(), lr=lr)\n    disc = Discriminator().to(device) \n    disc_opt = torch.optim.Adam(disc.parameters(), lr=lr)\n    \n    gen_loss = get_gen_loss(gen, disc, criterion, num_images, z_dim, device)\n    \n    # Check that the loss is reasonable\n    assert (gen_loss - 0.7).abs() < 0.1\n    gen_loss.backward()\n    old_weight = gen.gen[0][0].weight.clone()\n    gen_opt.step()\n    new_weight = gen.gen[0][0].weight\n    assert not torch.all(torch.eq(old_weight, new_weight))\n\n\ntest_gen_reasonable(10)\ntest_gen_loss(18)\nprint(\"Success!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# UNQ_C8 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n# GRADED FUNCTION: \n\ncur_step = 0\nmean_generator_loss = 0\nmean_discriminator_loss = 0\ntest_generator = True # Whether the generator should be tested\ngen_loss = False\nerror = False\nfor epoch in range(n_epochs):\n  \n    # Dataloader returns the batches\n    for real, _ in tqdm(dataloader):\n        cur_batch_size = len(real)\n\n        # Flatten the batch of real images from the dataset\n        real = real.view(cur_batch_size, -1).to(device)\n\n        ### Update discriminator ###\n        # Zero out the gradients before backpropagation\n        disc_opt.zero_grad()\n\n        # Calculate discriminator loss\n        disc_loss = get_disc_loss(gen, disc, criterion, real, cur_batch_size, z_dim, device)\n\n        # Update gradients\n        disc_loss.backward(retain_graph=True)\n\n        # Update optimizer\n        disc_opt.step()\n\n        # For testing purposes, to keep track of the generator weights\n        if test_generator:\n            old_generator_weights = gen.gen[0][0].weight.detach().clone()\n\n        ### Update generator ###\n        #     Hint: This code will look a lot like the discriminator updates!\n        #     These are the steps you will need to complete:\n        #       1) Zero out the gradients.\n        #       2) Calculate the generator loss, assigning it to gen_loss.\n        #       3) Backprop through the generator: update the gradients and optimizer.\n        #### START CODE HERE ####\n        gen_opt.zero_grad()\n        gen_loss=get_gen_loss(gen, disc, criterion, cur_batch_size, z_dim, device)\n        gen_loss.backward()\n        gen_opt.step()\n        \n        #### END CODE HERE ####\n\n        # For testing purposes, to check that your code changes the generator weights\n        if test_generator:\n            try:\n                assert lr > 0.0000002 or (gen.gen[0][0].weight.grad.abs().max() < 0.0005 and epoch == 0)\n                assert torch.any(gen.gen[0][0].weight.detach().clone() != old_generator_weights)\n            except:\n                error = True\n                print(\"Runtime tests have failed\")\n\n        # Keep track of the average discriminator loss\n        mean_discriminator_loss += disc_loss.item() / display_step\n\n        # Keep track of the average generator loss\n        mean_generator_loss += gen_loss.item() / display_step\n\n        ### Visualization code ###\n        if cur_step % display_step == 0 and cur_step > 0:\n            print(f\"Epoch {epoch}, step {cur_step}: Generator loss: {mean_generator_loss}, discriminator loss: {mean_discriminator_loss}\")\n            fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n            fake = gen(fake_noise)\n            show_tensor_images(fake)\n            show_tensor_images(real)\n            mean_generator_loss = 0\n            mean_discriminator_loss = 0\n        cur_step += 1\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}