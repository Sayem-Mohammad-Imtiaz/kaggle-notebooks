{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Importing Data"},{"metadata":{},"cell_type":"markdown","source":"First, we import the packages that we will be using. Then, we import our dataset."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler,PolynomialFeatures\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/housesalesprediction/kc_house_data.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We look at the first 5 columns of the dataframe to know how it looks like. Then, we display the data types of each column."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Wrangling"},{"metadata":{},"cell_type":"markdown","source":"We drop the columns \"id\" and \"date\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop([\"id\",\"date\"], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, we check whether there are missing values in our data."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since there are no missing values in all columns, then we proceed to obtain the statistical summary of our data to examine their averages and other relevant values."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis"},{"metadata":{},"cell_type":"markdown","source":"In the boxplots below, we could infer that bedrooms, bathrooms, waterfront, and grade have effect on price. View has also an effect on price but only less, while floors has no effect at all."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"f, axes = plt.subplots(1, 2,figsize=(15,5))\nsns.boxplot(x=\"bedrooms\", y=\"price\", data=data, ax=axes[0])\nsns.boxplot(x=\"bathrooms\", y=\"price\", data=data, ax=axes[1])\nf, axes = plt.subplots(1, 2,figsize=(15,5))\nsns.boxplot(x=\"floors\", y=\"price\", data=data, ax=axes[0])\nsns.boxplot(x=\"waterfront\", y=\"price\", data=data, ax=axes[1])\nf, axes = plt.subplots(1, 2,figsize=(15,5))\nsns.boxplot(x=\"view\", y=\"price\", data=data, ax=axes[0])\nsns.boxplot(x=\"grade\", y=\"price\", data=data, ax=axes[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using the function regplot, we can see that the feature \"sqft_living\" has a positive correlation with \"price\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.regplot(x=\"sqft_living\", y=\"price\", data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the graph below, we could see that the most commonly sold houses are those having 3 bedrooms."},{"metadata":{"trusted":true},"cell_type":"code","source":"data['bedrooms'].value_counts().plot(kind='bar')\nplt.title('Number of Bedrooms')\nplt.xlabel('Bedrooms')\nplt.ylabel('Count')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we explore the correlation between different features."},{"metadata":{"trusted":true},"cell_type":"code","source":"corrmat = data.corr()\nf, ax1 = plt.subplots(figsize=(12,9))\n\nax1=sns.heatmap(corrmat,vmax = 0.8);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's take a closer look by examining their correlation coefficients."},{"metadata":{"trusted":true},"cell_type":"code","source":"corrmat = data.corr()\nf, ax1 = plt.subplots(figsize=(12,9))\n\nax1=sns.heatmap(corrmat,vmax = 0.8,annot = True);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Development"},{"metadata":{},"cell_type":"markdown","source":"### Multiple Linear Regression"},{"metadata":{},"cell_type":"markdown","source":"We use multiple linear regression to predict the price. We set price as our criterion variable (y_data) and all the other features except price as our predictors (x_data)."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlm = LinearRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_data = data.drop('price',axis=1)\ny_data = data['price']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"70% of the data will be used as our training data, while 30% will be our test data. We randomize the splitting of the data using random_state."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=1)\n\nprint(\"Number of test samples :\", x_test.shape[0])\nprint(\"Number of training samples:\",x_train.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lm.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lm.score(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The accuracy of the model is only at **69%**."},{"metadata":{"trusted":true},"cell_type":"code","source":"lm.intercept_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lm.coef_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Gradient Boosting Regression"},{"metadata":{},"cell_type":"markdown","source":"Since we want higher accuracy, we try to use a different method. We will now use gradient boosting regression."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import ensemble\nclf = ensemble.GradientBoostingRegressor(n_estimators=400, max_depth=5, min_samples_split=2, \n                                         learning_rate=0.1, loss='ls')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.score(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The accuracy of the new model is now at **89%**â€”a lot better than the first one!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}