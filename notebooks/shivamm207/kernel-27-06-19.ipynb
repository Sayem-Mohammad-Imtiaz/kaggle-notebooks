{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import linear_model\nfrom sklearn import preprocessing\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load the data_frame from the source file.\n\ndata_frame = pd.read_csv('../input/insurance.csv')\nx = [i for i in range(1338)]\ny = data_frame['expenses'].values\nplt.scatter(x, y)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scattered plot wasn't much helpful for data visualisation. To better visualise the data, data is sorted based on \n# its expense values. \n\ny = np.sort(y)\nplt.scatter(x, y)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# On sorting the data, it is noticed that the expense in this data-set is a combination of two linear curves.\n# One linear curve with slope_1 to the expense value of around 15,000. And the other linear curve with a greater \n# slope than the previous one.\n# So, while predicting, we first predict the expense values with the help of linear_model_1, which is based on the\n# training data for expenses less than 15,000. If the prediction from this model surpasses 15,000 we update our \n# prediction with linear_model_2, which is trained on the data-set having expense values greater than 15000.\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"value_1 = 15000\n\n# Segregating data_frames on the basis of expenses.\ndata_frame_1 = data_frame[data_frame['expenses'] < value_1]\ndata_frame_2 = data_frame[data_frame['expenses'] > value_1]\n\nx1 = data_frame_1[['age', 'sex', 'bmi', 'children', 'smoker', 'region']].values\ny1 = data_frame_1['expenses'].values\n\nx2 = data_frame_2[['age', 'sex', 'bmi', 'children', 'smoker', 'region']].values\ny2 = data_frame_2['expenses'].values\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# changing classification variables, to dummy variables.\nle_sex = preprocessing.LabelEncoder()\nle_sex.fit(['female', 'male'])\nx1[:, 1] = le_sex.transform(x1[:, 1])\nx2[:, 1] = le_sex.transform(x2[:, 1])\n\nle_smoker = preprocessing.LabelEncoder()\nle_smoker.fit(['no', 'yes'])\nx1[:, 4] = le_smoker.transform(x1[:, 4])\nx2[:, 4] = le_smoker.transform(x2[:, 4])\n\nle_region = preprocessing.LabelEncoder()\nle_region.fit(['southwest', 'southeast', 'northwest', 'northeast'])\nx1[:, 5] = le_region.transform(x1[:, 5])\nx2[:, 5] = le_region.transform(x2[:, 5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating training and testing data sets for expenses < 15000 and expenses > 15000.\ntrain_x1, test_x1, train_y1, test_y1 = train_test_split(x1, y1, test_size=0.2, random_state=4)\ntrain_x2, test_x2, train_y2, test_y2 = train_test_split(x2, y2, test_size=0.2, random_state=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# adding the two test data-sets, so as to use our model to predict any random value in the test-dataset.\n# similiar thing is done with the training data-set.\ntest_data_set = np.vstack((test_x1, test_x2))\nactual_test_results = np.hstack((test_y1, test_y2))\nactual_test_results = actual_test_results.transpose()\n\ntrain_data_set = np.vstack((train_x1, train_x2))\nactual_train_results = np.hstack((train_y1, train_y2))\nactual_train_results = actual_train_results.transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model_1 based on data-set having expenses < 15000\nmodel_1 = linear_model.LinearRegression()\nmodel_1.fit(train_x1, train_y1)\n\n# model_2 based on data-set having expenses > 15000\nmodel_2 = linear_model.LinearRegression()\nmodel_2.fit(train_x2, train_y2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prediction of test data-set.\nprediction_array = np.empty([len(test_data_set), 1])\nfor i1 in range(len(test_data_set)):\n    predict = model_1.predict([test_data_set[i1]])\n    if predict > 15000:\n        predict = model_2.predict([test_data_set[i1]])\n\n    prediction_array[i1, 0] = predict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prediction of train data-set.\nprediction_array_train = np.empty([len(train_data_set), 1])\nfor i2 in range(len(train_data_set)):\n    predict_train = model_1.predict(([train_data_set[i2]]))\n    if predict_train > 15000:\n        predict_train = model_2.predict([train_data_set[i2]])\n\n    prediction_array_train[i2, 0] = predict_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mean absolute and mean square error for predicted and actual values for test data-set.\ntest_MSE = mean_squared_error(actual_test_results, prediction_array)\ntest_MAE = mean_absolute_error(actual_test_results, prediction_array)\n\nprint('test_MSE', test_MSE,'     ' ,'test_MAE', test_MAE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mean absolute and mean square error for predicted and actual values for train data-set.\ntrain_MSE = mean_squared_error(actual_train_results, prediction_array_train)\ntrain_MAE = mean_absolute_error(actual_train_results, prediction_array_train)\nprint('train_MSE', train_MSE,'     ','train_MAE', train_MAE)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot for predicted and actual values of test set, so as to visualise the error in the predicted values.\nprint(\"Visualization\")\n\nx_plot = [j for j in range(len(actual_test_results))]\nplt.plot(x_plot, actual_test_results, 'r', x_plot, prediction_array, 'g')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# From the graph, it can be noted that the prediction works extremely well for the cases having expenses less than \n# 15000.\n# The errors for the prediction are mostly significant for the samples having expense values > 60000.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This is to find out about the reliability of the prediction model. Percentage of predictions in the test data-set \n# having an absolute error greater than the acceptable error limit (taken to be 1000 here) is calculated.\n\nacceptable_error = 1000\ncount = 0\nfor i in range(len(actual_test_results)):\n    error = actual_test_results[i] - prediction_array[i]\n    if abs(error) > acceptable_error:\n        count = count+1\npercentage = (count*100)/1338\npercentage = format(percentage, '.2f')\n\nprint(\"Percentage error\",\"   \",percentage, \"%\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}