{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 1. Introduction: Business Goal & Problem Definition\n\nIF YOU LIKE IT OR IF IT HELPS YOU SOMEHOW, COULD YOU PLEASE UPVOTE? THANK YOU VERY MUCH!!!\n\nThis project´s goal is doing passengers quantity prediction by month and year to help air companies control the resources they need to allocate in order to offer the most adequate services to their clients, at the same time they don´t waste funds in unnecessary actions, bringing more profitability to the business. The available dataset brings data from 1949 to 1960. Please look at the conclusion’s comments in the last section."},{"metadata":{},"cell_type":"markdown","source":"# 2. Importing Basic Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install openpyxl\nimport io\nimport openpyxl\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Data Collection"},{"metadata":{"trusted":true},"cell_type":"code","source":"air_passenger_ds = pd.read_csv(\"../input/air-passengers/AirPassengers.csv\", sep=\",\")\n\nair_passenger_ds","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Data Preliminary Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking a dataset sample\n\npd.set_option(\"display.max_rows\", 100)\npd.set_option(\"display.max_columns\", 100)\npd.options.display.float_format=\"{:,.2f}\".format\nair_passenger_ds.sample(n=10, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking dataset info by feature\n\nair_passenger_ds.info(verbose=True, null_counts=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking the existence of zeros in rows\n\n(air_passenger_ds==0).sum(axis=0).to_excel(\"zeros_per_feature.xlsx\")\n(air_passenger_ds==0).sum(axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking the existence of duplicated rows\n\nair_passenger_ds.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking basic statistical data by feature\n\nair_passenger_ds.describe(include=\"all\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Data Cleaning\n\n    We´ll perform the following:\n    \n    \n    1. Change \"Month\" name to \"Date\" in order to have a more intuitive name for the column\n    \n        \n    2. Convert \"Date\" to datetime datatype\n    \n    \n    3. Set \"Date\" column as Index \n    \n    \n    4. Order dataset by \"Date\""},{"metadata":{"trusted":true},"cell_type":"code","source":"1#\n\nair_passenger_ds.rename({\"Month\": \"Date\"}, axis=1, inplace=True)\n\n#2\n\nair_passenger_ds[\"Date\"] = pd.to_datetime(air_passenger_ds[\"Date\"])\n\n\n#3\n\nair_passenger_ds.set_index(\"Date\", inplace=True)\n\n#4\n\nair_passenger_ds.sort_values(by=[\"Date\"])\n\n\nair_passenger_ds.to_excel(\"air_passenger_ds_clean.xlsx\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. Data Exploration"},{"metadata":{},"cell_type":"markdown","source":"# 6.1 Visualizing Data Along the Time"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.line(air_passenger_ds, y=[\"#Passengers\"], height=500, width=1500)\nfig.layout.showlegend = False\nfig.update_layout(title=\"Air Passengers across the years (1949-1960)\", xaxis_title=\"Date\", yaxis_title=\"Passengers\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6.2 Checking Data Stationarity\n\nIn order to determine stationarity, the three statisticals below can not change over the time:\n* mean\n* variance\n* autocorrelation\n\n\nIn order to check it, we´ll use two methods:\n1. Moving Average\n2. ADF (Augmented Dickey–Fuller) Test\n\n\n* We´ll conclude in 6.1 and 6.2 sections the original dataset is nonstationary, but in section 7 we´ll change it to stationary using several methods"},{"metadata":{},"cell_type":"markdown","source":"# 6.2.1 Moving Average"},{"metadata":{"trusted":true},"cell_type":"code","source":"mean = air_passenger_ds[\"#Passengers\"].rolling(window=12).mean() #moving Mean along the 12 prior days\nstd = air_passenger_ds[\"#Passengers\"].rolling(window=12).std() #moving Standard Deviation along the 12 prior days\n\nimport plotly.graph_objects as go\n\nfig1 = px.line(air_passenger_ds, y=[\"#Passengers\"])\nfig1.update_traces(line=dict(color = \"blue\"), name=\"Original Data\")\n\nfig2 = px.line(mean)\nfig2.update_traces(line=dict(color = \"yellow\"), name=\"Rolling Mean\")\n\nfig3 = px.line(std)\nfig3.update_traces(line=dict(color = \"red\"), name=\"Rolling Standard Deviation\")\n\nfig4 = go.Figure(data=fig1.data + fig2.data + fig3.data)\nfig4.update_layout(title=\"Data vs Mean vs Std\", xaxis_title=\"Date\", yaxis_title=\"Passengers\", height=500, width=1500)\n\nfig4.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6.2.2 ADF (Augmented Dickey–Fuller) Test"},{"metadata":{"trusted":true},"cell_type":"code","source":"# For Data to be stationary p value should be < 0.05 and critical values should be close to Test Statistics\n\nfrom statsmodels.tsa.stattools import adfuller\n\nprint(\"Results of Dickey-Fuller Test:\")\ndftest = adfuller(air_passenger_ds[\"#Passengers\"], autolag=\"AIC\")\ndfoutput = pd.Series(dftest[0:4], index=[\"Test Statistic\", \"p-value\", \"#Lags Used\", \"Number of Observations Used\"])\nfor key, value in dftest[4].items():\n    dfoutput[\"Critical Value (%s)\"%key] = value\n\ndfoutput","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Alternatively using Profile Report to see variables statistics and correlations\n\nfrom pandas_profiling import ProfileReport\nprofile = ProfileReport(air_passenger_ds, title=\"Air Passenger\")\nprofile.to_file(output_file=\"Air_Passenger.html\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7. Data Stationarity Transformation"},{"metadata":{},"cell_type":"markdown","source":"# 7.1 Applying Log"},{"metadata":{"trusted":true},"cell_type":"code","source":"air_passenger_ds_log = np.log(air_passenger_ds)\nmean_log = air_passenger_ds_log.rolling(window=12).mean()\nstd_log = air_passenger_ds_log.rolling(window=12).std()\n\nfig1 = px.line(air_passenger_ds_log, y=[\"#Passengers\"])\nfig1.update_traces(line=dict(color = \"blue\"), name=\"Original Data (Log)\")\n\nfig2 = px.line(mean_log)\nfig2.update_traces(line=dict(color = \"yellow\"), name=\"Rolling Mean (Log)\")\n\nfig3 = px.line(std_log)\nfig3.update_traces(line=dict(color = \"red\"), name=\"Rolling Standard Deviation (Log)\")\n\nfig4 = go.Figure(data=fig1.data + fig2.data + fig3.data)\nfig4.update_layout(title=\"Logarithmic Data vs Mean vs Std\", xaxis_title=\"Date\", yaxis_title=\"Passengers (Log)\", height=500, width=1500)\n\nfig4.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ADF (Augmented Dickey–Fuller) Test\n\nprint(\"Results of Dickey-Fuller Test:\")\ndftest = adfuller(air_passenger_ds_log[\"#Passengers\"], autolag=\"AIC\")\ndfoutput = pd.Series(dftest[0:4], index=[\"Test Statistic\", \"p-value\", \"#Lags Used\", \"Number of Observations Used\"])\nfor key, value in dftest[4].items():\n    dfoutput[\"Critical Value (%s)\"%key] = value\n\ndfoutput","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7.2 Applying Log Differencing Simple Moving Average"},{"metadata":{"trusted":true},"cell_type":"code","source":"air_passenger_ds_log_dsma = air_passenger_ds_log - mean_log\nair_passenger_ds_log_dsma.dropna(inplace=True)\nmean_log_dsma = air_passenger_ds_log_dsma.rolling(window=12).mean()\nstd_log_dsma = air_passenger_ds_log_dsma.rolling(window=12).std()\n\nfig1 = px.line(air_passenger_ds_log_dsma, y=[\"#Passengers\"])\nfig1.update_traces(line=dict(color = \"blue\"), name=\"Original Data (Log Differencing Simple Moving Average)\")\n\nfig2 = px.line(mean_log_dsma)\nfig2.update_traces(line=dict(color = \"yellow\"), name=\"Rolling Mean (Log Differencing Simple Moving Average)\")\n\nfig3 = px.line(std_log_dsma)\nfig3.update_traces(line=dict(color = \"red\"), name=\"Rolling Standard Deviation (Log Differencing Simple Moving Average)\")\n\nfig4 = go.Figure(data=fig1.data + fig2.data + fig3.data)\nfig4.update_layout(title=\"Log Differencing Simple Moving Average Data vs Mean vs Std\", xaxis_title=\"Date\", yaxis_title=\"Passengers (Log Differencing Simple Moving Average)\", height=500, width=1500)\n\nfig4.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ADF (Augmented Dickey–Fuller) Test\n\nprint(\"Results of Dickey-Fuller Test:\")\ndftest = adfuller(air_passenger_ds_log_dsma[\"#Passengers\"], autolag=\"AIC\")\ndfoutput = pd.Series(dftest[0:4], index=[\"Test Statistic\", \"p-value\", \"#Lags Used\", \"Number of Observations Used\"])\nfor key, value in dftest[4].items():\n    dfoutput[\"Critical Value (%s)\"%key] = value\n\ndfoutput","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7.3 Applying Log Exponential Moving Average"},{"metadata":{"trusted":true},"cell_type":"code","source":"exponentialDecayWeightedAverage = air_passenger_ds_log.ewm(halflife=12, min_periods=0, adjust=True).mean()\nair_passenger_ds_log_ema = air_passenger_ds_log - exponentialDecayWeightedAverage\nair_passenger_ds_log_ema.dropna(inplace=True)\nmean_log_ema = air_passenger_ds_log_ema.rolling(window=12).mean()\nstd_log_ema = air_passenger_ds_log_ema.rolling(window=12).std()\n\nfig1 = px.line(air_passenger_ds_log_ema, y=[\"#Passengers\"])\nfig1.update_traces(line=dict(color = \"blue\"), name=\"Original Data (Log Exponential Moving Average)\")\n\nfig2 = px.line(mean_log_ema)\nfig2.update_traces(line=dict(color = \"yellow\"), name=\"Rolling Mean (Log Exponential Moving Average)\")\n\nfig3 = px.line(std_log_ema)\nfig3.update_traces(line=dict(color = \"red\"), name=\"Rolling Standard Deviation (Log Exponential Moving Average)\")\n\nfig4 = go.Figure(data=fig1.data + fig2.data + fig3.data)\nfig4.update_layout(title=\"Log Exponential Moving Average Data vs Mean vs Std\", xaxis_title=\"Date\", yaxis_title=\"Passengers (Exponential Moving Average)\", height=500, width=1500)\n\nfig4.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ADF (Augmented Dickey–Fuller) Test\n\nprint(\"Results of Dickey-Fuller Test:\")\ndftest = adfuller(air_passenger_ds_log_ema[\"#Passengers\"], autolag=\"AIC\")\ndfoutput = pd.Series(dftest[0:4], index=[\"Test Statistic\", \"p-value\", \"#Lags Used\", \"Number of Observations Used\"])\nfor key, value in dftest[4].items():\n    dfoutput[\"Critical Value (%s)\"%key] = value\n\ndfoutput","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7.4 Applying Log Differencing Previous Value"},{"metadata":{"trusted":true},"cell_type":"code","source":"air_passenger_ds_log_dpv = air_passenger_ds_log - air_passenger_ds_log.shift()\nair_passenger_ds_log_dpv.dropna(inplace=True)\nmean_log_dpv = air_passenger_ds_log_dpv.rolling(window=12).mean()\nstd_log_dpv = air_passenger_ds_log_dpv.rolling(window=12).std()\n\nfig1 = px.line(air_passenger_ds_log_dpv, y=[\"#Passengers\"])\nfig1.update_traces(line=dict(color = \"blue\"), name=\"Original Data (Log Differencing Previous Value)\")\n\nfig2 = px.line(mean_log_dpv)\nfig2.update_traces(line=dict(color = \"yellow\"), name=\"Rolling Mean (Log Differencing Previous Value)\")\n\nfig3 = px.line(std_log_dpv)\nfig3.update_traces(line=dict(color = \"red\"), name=\"Rolling Standard Deviation (Log Differencing Previous Value)\")\n\nfig4 = go.Figure(data=fig1.data + fig2.data + fig3.data)\nfig4.update_layout(title=\"Log Differencing Previous Value Data vs Mean vs Std\", xaxis_title=\"Date\", yaxis_title=\"Passengers (Log Differencing Previous Value)\", height=500, width=1500)\n\nfig4.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ADF (Augmented Dickey–Fuller) Test\n\nprint(\"Results of Dickey-Fuller Test:\")\ndftest = adfuller(air_passenger_ds_log_dpv[\"#Passengers\"], autolag=\"AIC\")\ndfoutput = pd.Series(dftest[0:4], index=[\"Test Statistic\", \"p-value\", \"#Lags Used\", \"Number of Observations Used\"])\nfor key, value in dftest[4].items():\n    dfoutput[\"Critical Value (%s)\"%key] = value\n\ndfoutput","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7.5 Applying Log Seasonal Decomposition"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.seasonal import seasonal_decompose\n\ndecomposition = seasonal_decompose(air_passenger_ds_log)\n\ntrend = decomposition.trend\nseasonal = decomposition.seasonal\nresidual = decomposition.resid\n\nplt.figure(figsize=(20, 7))\nplt.subplot(411)\nplt.plot(air_passenger_ds_log, label=\"Original\")\nplt.legend(loc=\"best\")\nplt.subplot(412)\nplt.plot(trend, label=\"Trend\")\nplt.legend(loc=\"best\")\nplt.subplot(413)\nplt.plot(seasonal, label=\"Seasonability\")\nplt.legend(loc=\"best\")\nplt.subplot(414)\nplt.plot(residual, label=\"Residuals\")\nplt.legend(loc=\"best\")\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"air_passenger_ds_log_sd = residual\nair_passenger_ds_log_sd.dropna(inplace=True)\nmean_log_sd = air_passenger_ds_log_sd.rolling(window=12).mean()\nstd_log_sd = air_passenger_ds_log_sd.rolling(window=12).std()\n\nfig1 = px.line(air_passenger_ds_log_sd)\nfig1.update_traces(line=dict(color = \"blue\"), name=\"Original Data (Log Seasonal Decomposition)\")\n\nfig2 = px.line(mean_log_sd)\nfig2.update_traces(line=dict(color = \"yellow\"), name=\"Rolling Mean (Log Seasonal Decomposition)\")\n\nfig3 = px.line(std_log_sd)\nfig3.update_traces(line=dict(color = \"red\"), name=\"Rolling Standard Deviation (Log Seasonal Decomposition)\")\n\nfig4 = go.Figure(data=fig1.data + fig2.data + fig3.data)\nfig4.update_layout(title=\"Log Seasonal Decomposition Data vs Mean vs Std\", xaxis_title=\"Date\", yaxis_title=\"Passengers (Log Seasonal Decomposition)\", height=500, width=1500)\n\nfig4.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ADF (Augmented Dickey–Fuller) Test\n\nprint(\"Results of Dickey-Fuller Test:\")\ndftest = adfuller(air_passenger_ds_log_sd, autolag=\"AIC\")\ndfoutput = pd.Series(dftest[0:4], index=[\"Test Statistic\", \"p-value\", \"#Lags Used\", \"Number of Observations Used\"])\nfor key, value in dftest[4].items():\n    dfoutput[\"Critical Value (%s)\"%key] = value\n\ndfoutput","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 8. AR and MA Models Lags Finding\n\nA nonseasonal ARIMA model is classified as an \"ARIMA(p,d,q)\" model, where:\n* p is the number of autoregressive terms\n* d is the number of nonseasonal differences needed for stationarity\n* q is the number of lagged forecast errors in the prediction equation"},{"metadata":{"trusted":true},"cell_type":"code","source":"#For ex: a lag k autocorrelation is the correlation between values that are k time periods apart\n\nimport warnings\nwarnings.filterwarnings('ignore', 'statsmodels.tsa.arima_model.ARMA',\n                        FutureWarning)\nwarnings.filterwarnings('ignore', 'statsmodels.tsa.arima_model.ARIMA',\n                        FutureWarning)\n\nfrom statsmodels.tsa.stattools import arma_order_select_ic\n\n#Select here the Data Stationarity Transformation Method (dstm) to use:\n#For this exercise we´re choosing Log Differencing Previous Value\ndstm = air_passenger_ds_log_dpv\n\n#Lags output\nprint(arma_order_select_ic(dstm))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 9. Algorithm Implementation & Assessment"},{"metadata":{},"cell_type":"markdown","source":"# 9.1 AR Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating an AR model and checking its Metrics\n\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n\nmodel_ar = ARIMA(air_passenger_ds_log, order = (2,1,0)).fit(disp=-1)\ny_preds = model_ar.fittedvalues\nrss = sum((y_preds-dstm[\"#Passengers\"])**2)\nscore = r2_score(dstm, y_preds)\nmse = mean_squared_error(dstm, y_preds)\nprint(\"Metrics: RSS:{0:,.3f}, R2:{1:,.3f}, MSE:{2:,.2f}, RMSE:{3:,.2f}\".format(rss, score, mse, np.sqrt(mse)))\n\n#Plotting\nx_ax = range(len(dstm))\nplt.scatter(x_ax, dstm, s=5, color=\"blue\", label=\"Original\")\nplt.plot(x_ax, y_preds, lw=0.8, color=\"red\", label=\"Predicted\")\nplt.title(\"RSS: %.4f\"% sum((y_preds-dstm[\"#Passengers\"])**2))\nplt.legend()\nplt.show()\n\n\n#Converting predictions to original scale\npredictions_ARIMA_diff = pd.Series(model_ar.fittedvalues, copy=True)\npredictions_ARIMA_diff_cumsum = predictions_ARIMA_diff.cumsum()\npredictions_ARIMA_log = pd.Series(air_passenger_ds_log[\"#Passengers\"].iloc[0], index=air_passenger_ds_log.index)\npredictions_ARIMA_log = predictions_ARIMA_log.add(predictions_ARIMA_diff_cumsum, fill_value=0)\npredictions_ARIMA = np.exp(predictions_ARIMA_log)\n\n#Plotting Original vs Predicted Data\nfig1 = px.line(air_passenger_ds)\nfig1.update_traces(line=dict(color = \"blue\"), name=\"Original Data\")\n\nfig2 = px.line(predictions_ARIMA)\nfig2.update_traces(line=dict(color = \"purple\"), name=\"Predicted Data\")\n\nfig3 = go.Figure(data=fig1.data + fig2.data)\nfig3.update_layout(title=\"Original vs Predicted Data\", xaxis_title=\"Date\", yaxis_title=\"Passengers\", height=500, width=1500).show()\n\n#Plotting Future Predicted Data for five years\nplt.rc(\"figure\", figsize=(20,7))\npred_plot = model_ar.plot_predict(1,204)\nplt.title(\"Future Predicted Data\")\nplt.show()\n\n#Visualizing y_pred in the dataset\ny_pred_all = predictions_ARIMA\nair_passenger_ds[\"passengers_predicted\"] = y_pred_all\nair_passenger_ds.to_excel(\"model_ar.xlsx\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 9.2 MA Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating a MA model and checking its Metrics\n\nmodel_ma = ARIMA(air_passenger_ds_log, order = (0,1,2)).fit(disp=-1)\ny_preds = model_ma.fittedvalues\nrss = sum((y_preds-dstm[\"#Passengers\"])**2)\nscore = r2_score(dstm, y_preds)\nmse = mean_squared_error(dstm, y_preds)\nprint(\"Metrics: RSS:{0:,.3f}, R2:{1:,.3f}, MSE:{2:,.2f}, RMSE:{3:,.2f}\".format(rss, score, mse, np.sqrt(mse)))\n\n#Plotting\nx_ax = range(len(dstm))\nplt.scatter(x_ax, dstm, s=5, color=\"blue\", label=\"Original\")\nplt.plot(x_ax, y_preds, lw=0.8, color=\"red\", label=\"Predicted\")\nplt.title(\"RSS: %.4f\"% sum((y_preds-dstm[\"#Passengers\"])**2))\nplt.legend()\nplt.show()\n\n\n#Converting predictions to original scale\npredictions_ARIMA_diff = pd.Series(model_ma.fittedvalues, copy=True)\npredictions_ARIMA_diff_cumsum = predictions_ARIMA_diff.cumsum()\npredictions_ARIMA_log = pd.Series(air_passenger_ds_log[\"#Passengers\"].iloc[0], index=air_passenger_ds_log.index)\npredictions_ARIMA_log = predictions_ARIMA_log.add(predictions_ARIMA_diff_cumsum, fill_value=0)\npredictions_ARIMA = np.exp(predictions_ARIMA_log)\n\n#Plotting Original vs Predicted Data\nfig1 = px.line(air_passenger_ds)\nfig1.update_traces(line=dict(color = \"blue\"), name=\"Original Data\")\n\nfig2 = px.line(predictions_ARIMA)\nfig2.update_traces(line=dict(color = \"purple\"), name=\"Predicted Data\")\n\nfig3 = go.Figure(data=fig1.data + fig2.data)\nfig3.update_layout(title=\"Original vs Predicted Data\", xaxis_title=\"Date\", yaxis_title=\"Passengers\", height=500, width=1500).show()\n\n#Plotting Future Predicted Data for five years\nplt.rc(\"figure\", figsize=(20,7))\npred_plot = model_ma.plot_predict(1,204)\nplt.title(\"Future Predicted Data\")\nplt.show()\n\n#Visualizing y_pred in the dataset\ny_pred_all = predictions_ARIMA\nair_passenger_ds[\"passengers_predicted\"] = y_pred_all\nair_passenger_ds.to_excel(\"model_ma.xlsx\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 9.3 ARIMA Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating an ARIMA model and checking its Metrics\n\nmodel_arima = ARIMA(air_passenger_ds_log, order = (2,1,2)).fit(disp=-1)\ny_preds = model_arima.fittedvalues\nrss = sum((y_preds-dstm[\"#Passengers\"])**2)\nscore = r2_score(dstm, y_preds)\nmse = mean_squared_error(dstm, y_preds)\nprint(\"Metrics: RSS:{0:,.3f}, R2:{1:,.3f}, MSE:{2:,.2f}, RMSE:{3:,.2f}\".format(rss, score, mse, np.sqrt(mse)))\n\n#Plotting\nx_ax = range(len(dstm))\nplt.scatter(x_ax, dstm, s=5, color=\"blue\", label=\"Original\")\nplt.plot(x_ax, y_preds, lw=0.8, color=\"red\", label=\"Predicted\")\nplt.title(\"RSS: %.4f\"% sum((y_preds-dstm[\"#Passengers\"])**2))\nplt.legend()\nplt.show()\n\n\n#Converting predictions to original scale\npredictions_ARIMA_diff = pd.Series(model_arima.fittedvalues, copy=True)\npredictions_ARIMA_diff_cumsum = predictions_ARIMA_diff.cumsum()\npredictions_ARIMA_log = pd.Series(air_passenger_ds_log[\"#Passengers\"].iloc[0], index=air_passenger_ds_log.index)\npredictions_ARIMA_log = predictions_ARIMA_log.add(predictions_ARIMA_diff_cumsum, fill_value=0)\npredictions_ARIMA = np.exp(predictions_ARIMA_log)\n\n#Plotting Original vs Predicted Data\nfig1 = px.line(air_passenger_ds)\nfig1.update_traces(line=dict(color = \"blue\"), name=\"Original Data\")\n\nfig2 = px.line(predictions_ARIMA)\nfig2.update_traces(line=dict(color = \"purple\"), name=\"Predicted Data\")\n\nfig3 = go.Figure(data=fig1.data + fig2.data)\nfig3.update_layout(title=\"Original vs Predicted Data\", xaxis_title=\"Date\", yaxis_title=\"Passengers\", height=500, width=1500).show()\n\n#Plotting Future Predicted Data for five years\nplt.rc(\"figure\", figsize=(20,7))\npred_plot = model_arima.plot_predict(1,204)\nplt.title(\"Future Predicted Data\")\nplt.show()\n\n#Visualizing y_pred in the dataset\ny_pred_all = predictions_ARIMA\nair_passenger_ds[\"passengers_predicted\"] = y_pred_all\nair_passenger_ds.to_excel(\"model_arima.xlsx\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 10. Model Deployment"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.display.float_format=\"{:,.4f}\".format\n\ndeploy_ds = pd.date_range(start=\"1/1/1961\", end=\"12/1/1965\", freq=\"MS\")\ndeploy_ds = pd.DataFrame({\"Date\":deploy_ds})\ndeploy_ds[\"Passengers\"] = np.exp(pd.DataFrame(model_arima.forecast(steps=60)[0]))\ndate_input = input(\"Enter the date you would like to estimate the passengers number - valid for next five years after dataset range, meaning from 1961 to 1965 (MM/YYYY): \")\nprint(\"{}\".format(deploy_ds.loc[deploy_ds[\"Date\"] == date_input]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 11. Conclusions\n\nIF YOU LIKE IT OR IF IT HELPS YOU SOMEHOW, COULD YOU PLEASE UPVOTE? THANK YOU VERY MUCH!!!\n\nWe were able to develop a model to predict passengers’ quantity to help the air company allocate the required resources in future months/years and maximize its profitability. We used ARIMA model, bringing a RSS = 1.0292, but the project can be further improved, first by choosing a better Data Stationarity Transformation Method (with a better p-value), and second by exploring SARIMA model, since it´s a seasonal dataset."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}