{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Importing the required libraries\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression, ElasticNet, Lasso, Ridge\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.pipeline import Pipeline\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/videogamesales/vgsales.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's take a look at our columns\ndf.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.isnull().sum()) \n# drop them if there are any \ndf = df.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# if we wanted the counts instead, we could just use Count. Count returns the number of instances,\n# not the sums of the values like above\nx = df.groupby(['Year']).count()\nx = x['Global_Sales']\ny = x.index.astype(int)\n\nplt.figure(figsize=(12,8))\ncolors = sns.color_palette(\"muted\")\nax = sns.barplot(y = y, x = x, orient='h', palette=colors)\nax.set_xlabel(xlabel='Number of releases', fontsize=16)\nax.set_ylabel(ylabel='Year', fontsize=16)\nax.set_title(label='Game Releases Per Year', fontsize=20)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vg_data = pd.read_csv('/kaggle/input/videogamesales/vgsales.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(vg_data.info())\nprint(vg_data.describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's choose a cutoff and drop any publishers that have published less than X games\n\nfor i in vg_data['Publisher'].unique():\n    if vg_data['Publisher'][vg_data['Publisher'] == i].count() < 60:\n        vg_data['Publisher'][vg_data['Publisher'] == i] = 'Other'\n\nfor i in vg_data['Platform'].unique():\n    if vg_data['Platform'][vg_data['Platform'] == i].count() < 100:\n        vg_data['Platform'][vg_data['Platform'] == i] = 'Other'\n\n# try plotting the new publisher and platform data\nsns.countplot(x='Publisher', data=vg_data)\nplt.title(\"# Games Published By Publisher\")\nplt.xticks(rotation=-90)\nplt.show()\n\nplat_data = vg_data['Platform'].value_counts(sort=False)\nsns.countplot(y='Platform', data=vg_data)\nplt.title(\"# Games Published Per Console\")\nplt.xticks(rotation=-90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='Genre', y='Global_Sales', data=vg_data)\nplt.title(\"Total Sales Per Genre\")\nplt.xticks(rotation=-45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# try visualizing the number of games in a specific genre\nfor i in vg_data['Platform'].unique():\n    vg_data['Genre'][vg_data['Platform'] == i].value_counts().plot(kind='line', label=i, figsize=(20, 10), grid=True)\n\n# set the legend and ticks\nplt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3, ncol=20, borderaxespad=0.)\nplt.xticks(np.arange(12), tuple(vg_data['Genre'].unique()))\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# going to attempt to carry out linear regression and predict the global sales of games\n# based off of the sales in North America Sales\n\nX = vg_data.iloc[:, 6].values\ny = vg_data.iloc[:, 10].values\n\n# train test split and split the dataframe\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reshape the data into long 2D arrays with 1 column and as many rows as necessary\nX_train = X_train.reshape(-1, 1)\nX_test = X_test.reshape(-1, 1)\ny_train = y_train.reshape(-1, 1)\ny_test = y_test.reshape(-1, 1)\n\nlin_reg = LinearRegression()\nlin_reg.fit(X_train, y_train)\nLinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's create a function for plotting\ndef plot_regression(classifier):\n\n    plt.scatter(X_train, y_train,color='blue')\n    plt.plot(X_train, classifier.predict(X_train), color='red')\n    plt.title('(Training set)')\n    plt.xlabel('North America Sales')\n    plt.ylabel('Global Sales')\n    plt.show()\n\n    plt.scatter(X_test, y_test,color='blue')\n    plt.plot(X_train, classifier.predict(X_train), color='red')\n    plt.title('(Testing set)')\n    plt.xlabel('North America Sales')\n    plt.ylabel('Global Sales')\n    plt.show()\n    \nplot_regression(lin_reg)\nprint(\"Training set score: {:.2f}\".format(lin_reg.score(X_train, y_train)))\nprint(\"Test set score: {:.2f}\".format(lin_reg.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decision tree regressor\nDTree_regressor = DecisionTreeRegressor(random_state=5)\nDTree_regressor.fit(X_train, y_train)\nplot_regression(DTree_regressor)\n\nprint(\"Training set score: {:.2f}\".format(DTree_regressor.score(X_train, y_train)))\nprint(\"Test set score: {:.2f}\".format(DTree_regressor.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now let’s try a Random Forest regressor algorithm.\nRF_regressor = RandomForestRegressor(n_estimators=300, random_state=5)\nRF_regressor.fit(X_train, y_train)\nplot_regression(RF_regressor)\n\nprint(\"Training set score: {:.2f}\".format(RF_regressor.score(X_train, y_train)))\nprint(\"Test set score: {:.2f}\".format(RF_regressor.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"components = [\n    ('scaling', StandardScaler()),\n    ('PCA', PCA()),\n    ('regression', LinearRegression())\n]\n\npca = Pipeline(components)\npca.fit(X_train, y_train)\nplot_regression(pca)\nprint(\"Training set score: {:.2f}\".format(pca.score(X_train, y_train)))\nprint(\"Test set score: {:.2f}\".format(pca.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We are now going to try different regression algorithms to see what results we get. \n# Let's try Elastic Net regressor\nelastic = ElasticNet()\nelastic.fit(X_train, y_train)\nplot_regression(elastic)\nprint(\"Training set score: {:.2f}\".format(elastic.score(X_train, y_train)))\nprint(\"Test set score: {:.2f}\".format(elastic.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now let’s try Ridge regression\nridge_reg = Ridge()\nridge_reg.fit(X_train, y_train)\nplot_regression(ridge_reg)\nprint(\"Training set score: {:.2f}\".format(ridge_reg.score(X_train, y_train)))\nprint(\"Test set score: {:.2f}\".format(ridge_reg.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Here’s a Lasso regression implementation\nlasso_reg = Lasso()\nlasso_reg.fit(X_train, y_train)\nplot_regression(lasso_reg)\nprint(\"Training set score: {:.2f}\".format(lasso_reg.score(X_train, y_train)))\nprint(\"Test set score: {:.2f}\".format(lasso_reg.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ADA Boost regressor\nada_reg = AdaBoostRegressor()\nada_reg.fit(X_train, y_train)\nplot_regression(ada_reg)\n\nprint(\"Training set score: {:.2f}\".format(ada_reg.score(X_train, y_train)))\nprint(\"Test set score: {:.2f}\".format(ada_reg.score(X_test, y_test)))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}