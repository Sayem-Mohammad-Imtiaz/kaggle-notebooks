{"cells":[{"metadata":{"_cell_guid":"b91a74ba-85f4-486e-b5f9-d0898f0626bf","_uuid":"6ac53f18b4f4ec0fc44348cedb5d1c319fa127c0"},"cell_type":"markdown","source":"Welcome to day 1 of the 5-Day Data Challenge! Today, we're going to be looking at how to deal with missing values. To get started, click the blue \"Fork Notebook\" button in the upper, right hand corner. This will create a private copy of this notebook that you can edit and play with. Once you're finished with the exercises, you can choose to make your notebook public to share with others. :)\n\n> **Your turn!** As we work through this notebook, you'll see some notebook cells (a block of either code or text) that has \"Your Turn!\" written in it. These are exercises for you to do to help cement your understanding of the concepts we're talking about. Once you've written the code to answer a specific question, you can run the code by clicking inside the cell (box with code in it) with the code you want to run and then hit CTRL + ENTER (CMD + ENTER on a Mac). You can also click in a cell and then click on the right \"play\" arrow to the left of the code. If you want to run all the code in your notebook, you can use the double, \"fast forward\" arrows at the bottom of the notebook editor.\n\nHere's what we're going to do today:\n\n* [Take a first look at the data](#Take-a-first-look-at-the-data)\n* [See how many missing data points we have](#See-how-many-missing-data-points-we-have)\n* [Figure out why the data is missing](#Figure-out-why-the-data-is-missing)\n* [Drop missing values](#Drop-missing-values)\n* [Filling in missing values](#Filling-in-missing-values)\n\nLet's get started!"},{"metadata":{"_cell_guid":"5cd5061f-ae30-4837-a53b-690ffd5c5830","_uuid":"9d82bf13584b8e682962fbb96131f2447d741679"},"cell_type":"markdown","source":"# Take a first look at the data\n________\n\nThe first thing we'll need to do is load in the libraries and datasets we'll be using. For today, I'll be using a dataset of events that occured in American Football games for demonstration, and you'll be using a dataset of building permits issued in San Francisco.\n\n> **Important!** Make sure you run this cell yourself or the rest of your code won't work!\n\n**NOTE FOR MY KERNEL**  I have removed the nfl_dataset that Rachael uses for her demonstration for clarity as we are supposed to run a similar analysis on the aforementioned San Francisco building permits dataset.  I did however keep all of her code and  commentary and some references to the American Football dataset with my comments on the San Francisco building permits dataset in **bold**.   Be sure to check out Rachaels original kernel if you want to see the NFL dataset examples."},{"metadata":{"_cell_guid":"135a7804-b5f5-40aa-8657-4a15774e3666","_uuid":"835cbe0834b935fb0fd40c75b9c39454836f4d5f","trusted":true,"collapsed":true},"cell_type":"code","source":"# modules we'll use\nimport pandas as pd\nimport numpy as np\n\n# read in all our data\nsf_permits = pd.read_csv(\"../input/building-permit-applications-data/Building_Permits.csv\", low_memory=False)\n\n# set seed for reproducibility\nnp.random.seed(0) ","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"09b58d03-d34d-497a-b298-12a0ae962e3d","_uuid":"53c84bf86149ac41b237633a1a79d6130d6a2cd4"},"cell_type":"markdown","source":"The first thing I do when I get a new dataset is take a look at some of it. This lets me see that it all read in correctly and get an idea of what's going on with the data. In this case, I'm looking to see if I see any missing values, which will be reprsented with `NaN` or `None`."},{"metadata":{"scrolled":false,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# look at a few rows of the sf_permits file. There is a handful of missing data already!\nsf_permits.sample(5)","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"9fd95bce-28b6-45f3-866e-8a419b07fe57","_uuid":"eb4511ef8cd115fd19e2d25f6bba5a68ebc43882"},"cell_type":"markdown","source":"**Personnally I like to use the methods 'info()' and 'describe()' when perusing a newly imported dataset.  The info() method gives you an idea of how many non-null (and conversely how many null) entries exist and also (if the dataset isn't too large) gives you a look at the feature names to see what kind of information makes up the dataset.  The describe() method gives a more statistical breakdown of the dataset which is useful for such numerical features such as 'Estimated Cost'.**"},{"metadata":{"scrolled":true,"_cell_guid":"8dca377c-95be-40ec-87dc-61a8fca750e2","_uuid":"e389495bb2e5d27ab632d5f3648ca1f912c94706","trusted":true},"cell_type":"code","source":"sf_permits.info()\n#Using describe gives you more statistical information\nsf_permits.describe()","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"33656c2b-a74e-4b76-9af2-d7ecd518577b","_uuid":"400b025f618cc76a39fec2537193f28ba1e49168"},"cell_type":"markdown","source":"# See how many missing data points we have\n___\n\nOk, now we know that we do have some missing values. Let's see how many we have in each column. \n>**Since there are a total of 198900 rows in the sf_permits dataset counting the null entries you should see the inverse of what you found with the info() method; i.e. permits have 198900 non-null entries so the missing values count is equal to 0.  Counting the null entries does save you from having to do subtraction in your head though!**"},{"metadata":{"scrolled":false,"_cell_guid":"a69ac02d-197b-487b-a38f-2f853d208eed","_uuid":"6dc0e32180c4a3bba003e7886faf126d93affadf","trusted":true},"cell_type":"code","source":"# get the number of missing data points per column\nmissing_values_count = sf_permits.isnull().sum()\n\n# look at the # of missing points\nmissing_values_count","execution_count":5,"outputs":[]},{"metadata":{"_cell_guid":"84455c7e-6c63-4e08-a7b4-7520a61072f9","_uuid":"054ba8782a7b0555336eddb90c985fb638beac4d"},"cell_type":"markdown","source":"That seems like a lot! It might be helpful to see what percentage of the values in our dataset were missing to give us a better sense of the scale of this problem:\n>**This is true for the NFL dataset and for some features of the sf_permits dataset and there is enough missing to warrant a look at how much it adds up to.**"},{"metadata":{"_cell_guid":"fb77dd56-192e-48be-8181-2082985dd5a2","_uuid":"d6e65ba197893f29d9dce0b0cd1c75017b60db09","trusted":true},"cell_type":"code","source":"# how many total missing values do we have?\ntotal_cells = np.product(sf_permits.shape)\ntotal_missing = missing_values_count.sum()\n\n# percent of data that is missing\n(total_missing/total_cells) * 100","execution_count":6,"outputs":[]},{"metadata":{"_cell_guid":"31daa324-9215-4930-985c-01dee717b6b8","_uuid":"3331fa42efa16f3db2e8e196411f351c5f8309f5"},"cell_type":"markdown","source":"Wow, almost a quarter of the cells in this dataset are empty! In the next step, we're going to take a closer look at some of the columns with missing values and try to figure out what might be going on with them.\n>**You can see this is slightly over a quarter for the sf_permits dataset.  This is also the point in the process where one needs to examine the features to determine if trying to figure out why data is missing is worth the effort; the question to be asked is, \"Can I do without this feature and what impact would not including it have on my analysis?\"  This is what Rachel discusses below as 'data intuition'.**"},{"metadata":{"_cell_guid":"62b9f021-5b80-43e2-bf60-8e0d5e22d572","_uuid":"032a618abb98a28e60ab84376cf21402178f995d"},"cell_type":"markdown","source":"# Figure out why the data is missing\n____\n \nThis is the point at which we get into the part of data science that I like to call \"data intution\", by which I mean \"really looking at your data and trying to figure out why it is the way it is and how that will affect your analysis\". It can be a frustrating part of data science, especially if you're newer to the field and don't have a lot of experience. For dealing with missing values, you'll need to use your intution to figure out why the value is missing. One of the most important question you can ask yourself to help figure this out is this:\n\n> Is this value missing becuase it wasn't recorded or becuase it dosen't exist?\n\nIf a value is missing becuase it doens't exist (like the height of the oldest child of someone who doesn't have any children) then it doesn't make sense to try and guess what it might be. These values you probalby do want to keep as NaN. On the other hand, if a value is missing becuase it wasn't recorded, then you can try to guess what it might have been based on the other values in that column and row. (This is called \"imputation\" and we'll learn how to do it next! :)\n\nLet's work through an example. Looking at the number of missing values in the nfl_data dataframe, I notice that the column `TimesSec` has a lot of missing values in it: \n\n>**The same is true for the sf_permits dataset - which features matter and which don't?  Read through Rachael's discussion and tips below and then we will continue with the sf_permits analysis. **"},{"metadata":{"_cell_guid":"1b17f4c9-dcab-4857-82f9-a2534e804c91","_uuid":"5cff158285ab37a89b80dcc35d5c690cdb42d3a4"},"cell_type":"markdown","source":"By looking at [the documentation](https://www.kaggle.com/maxhorowitz/nflplaybyplay2009to2016), I can see that this column has information on the number of seconds left in the game when the play was made. This means that these values are probably missing because they were not recorded, rather than because they don't exist. So, it would make sense for us to try and guess what they should be rather than just leaving them as NA's.\n\nOn the other hand, there are other fields, like `PenalizedTeam` that also have lot of missing fields. In this case, though, the field is missing because if there was no penalty then it doesn't make sense to say *which* team was penalized. For this column, it would make more sense to either leave it empty or to add a third value like \"neither\" and use that to replace the NA's.\n\n> **Tip:** This is a great place to read over the dataset documentation if you haven't already! If you're working with a dataset that you've gotten from another person, you can also try reaching out to them to get more information.\n\nIf you're doing very careful data analysis, this is the point at which you'd look at each column individually to figure out the best strategy for filling those missing values. For the rest of this notebook, we'll cover some \"quick and dirty\" techniques that can help you with missing values but will probably also end up removing some useful information or adding some noise to your data.\n\n## Your turn!\n\n* Look at the columns `Street Number Suffix` and `Zipcode` from the `sf_permits` datasets. Both of these contain missing values. Which, if either, of these are missing because they don't exist? Which, if either, are missing because they weren't recorded?"},{"metadata":{"_cell_guid":"5f023c72-41eb-402f-aa9e-c0785b280387","_uuid":"00509f307cc2481e19d0a94f6845b03018c7c2b4","trusted":true},"cell_type":"code","source":"sf_permits[['Street Number Suffix', 'Zipcode']].sample(10)","execution_count":7,"outputs":[]},{"metadata":{"_cell_guid":"cd346552-7c5c-42c7-a168-5f9732b99107","_uuid":"6771f8cf6bd18ee29f7b9941140cfe8bc71a614a"},"cell_type":"markdown","source":"**Now I'm no street address expert guy but Wikipedia is (https://en.wikipedia.org/wiki/Street_suffix).  Apparently there are 148 street number suffix's recognized by the U.S. Postal Service that provide additional information about the address (i.e. the suffix Ave. stands for avenue) but it doesn't seem very standardized so I think that the missing information was simply not recorded...especially when you consider that only a small fraction is actually filled in and it seems to be repeated in the column 'Street Suffix'.  However, I think the zipcode is definitely pertinent information for a permit so something needs to be done about the missing values in this feature.**"},{"metadata":{"_cell_guid":"ea022b62-6419-47e7-973e-c3e707e2795f","_uuid":"3f72f46f2464c7cd12f5eb2a752746ce1cd0b5a7"},"cell_type":"markdown","source":"# Drop missing values\n___\n\nIf you're in a hurry or don't have a reason to figure out why your values are missing, one option you have is to just remove any rows or columns that contain missing values. (Note: I don't generally recommend this approch for important projects! It's usually worth it to take the time to go through your data and really look at all the columns with missing values one-by-one to really get to know your dataset.)  \n\nIf you're sure you want to drop rows with missing values, pandas does have a handy function, `dropna()` to help you do this. Let's try it out on our NFL dataset!\n>**...or let's try it on the sf_permits dataset!**"},{"metadata":{"_cell_guid":"ad0ac9a2-2854-4bb7-8886-8eee7fad8756","_uuid":"ad8ef7825ba9bce3472a47d7c5242a4522f14065","trusted":true},"cell_type":"code","source":"# remove all the rows that contain a missing value\nsf_permits.dropna()","execution_count":8,"outputs":[]},{"metadata":{"_cell_guid":"e0545655-3d37-448b-ae56-2c7707cd805d","_uuid":"33eb849e076d2a4d0c409f58d78b5f303879b1b3"},"cell_type":"markdown","source":"Oh dear, it looks like that's removed all our data! 😱 This is because every row in our dataset had at least one missing value. We might have better luck removing all the *columns* that have at least one missing value instead.\n>**Same thing happens with the sf_permits dataset as you can see above.  Let's work on the columns instead of rows of the sf_permits dataset.  Remember, setting axis=1 defines columns instead of the default rows (which axis=0 but you don't have to type it in since it is the default).**"},{"metadata":{"_cell_guid":"97709ad4-f7b8-4cd0-8911-56e14db904ae","_uuid":"87c569672854fe23e1ee9376ef3115ba4712cbf5","trusted":true},"cell_type":"code","source":"# remove all columns with at least one missing value\ncolumns_with_na_dropped = sf_permits.dropna(axis=1)\ncolumns_with_na_dropped.head()","execution_count":9,"outputs":[]},{"metadata":{"_cell_guid":"0e51b19b-c44d-4487-8417-725d2b911739","_uuid":"e60a092d2799851aa725eadf28b197022a6b127f","trusted":true},"cell_type":"code","source":"# just how much data did we lose?\nprint(\"Columns in original dataset: %d \\n\" % sf_permits.shape[1])\nprint(\"Columns with na's dropped: %d\" % columns_with_na_dropped.shape[1])","execution_count":10,"outputs":[]},{"metadata":{"_cell_guid":"f417c614-f77f-45eb-b16b-fdc0be936502","_uuid":"bac84fee4ca849e54839c716c43dddfbb559954b"},"cell_type":"markdown","source":"We've lost quite a bit of data, but at this point we have successfully removed all the `NaN`'s from our data. "},{"metadata":{"_cell_guid":"1dbe153d-7b30-4ad8-80ad-a4c7fb53928e","_uuid":"eb1ef8d47d9ebed77c3d21eca24708708ed4d45f"},"cell_type":"markdown","source":"# Filling in missing values automatically\n_____\n\nAnother option is to try and fill in the missing values. For this next bit, I'm getting a small sub-section of the NFL data so that it will print well.\n>**We will do the same thing with the sf_permits data instead and start with the column of 'Supervisor District' to the column 'Location' with four columns in total.  The tail of the dataset is where you will find NaN's for these columns.**"},{"metadata":{"_cell_guid":"76fd83fb-a6d9-4c03-8c94-a111ee529881","_uuid":"e0944282c73a63513d5345689ddd6a9da0fc8547","trusted":true},"cell_type":"code","source":"# get a small subset of the sf_permits dataset\nsubset_sf_permits = sf_permits.loc[:, 'Supervisor District':'Location'].tail(20)\nsubset_sf_permits","execution_count":39,"outputs":[]},{"metadata":{"_cell_guid":"527c8703-4b29-459d-af7d-5505da36016b","_uuid":"f8cfe916904af3265d8ecc4f791f9f62e34ff458"},"cell_type":"markdown","source":"We can use the Panda's fillna() function to fill in missing values in a dataframe for us. One option we have is to specify what we want the `NaN` values to be replaced with. Here, I'm saying that I would like to replace all the `NaN` values with 0."},{"metadata":{"scrolled":true,"_cell_guid":"c01ed989-8901-43c8-afa3-6ca36605dfb5","_uuid":"77eac530ce398b8c13eb7886f86bce48fd997f34","trusted":true},"cell_type":"code","source":"# replace all NA's with 0\nsubset_sf_permits.fillna(\"0\")","execution_count":40,"outputs":[]},{"metadata":{"_cell_guid":"1103b725-c823-4f40-9bda-e97997856339","_uuid":"bec603202c6bfaae7a49b4a4042f37019ad1d801"},"cell_type":"markdown","source":"I could also be a bit more savvy and replace missing values with whatever value comes directly after it in the same column. (This makes a lot of sense for datasets where the observations have some sort of logical order to them.)\n>**For this particular subset forward fill ('ffill') works better than backfill ('bfill').**"},{"metadata":{"_cell_guid":"90ddac9b-ee20-492e-b437-0519c97ca317","_uuid":"afba99aa7897539e9a0af77dce03daab94d0ca68","trusted":true},"cell_type":"code","source":"# replace all NA's the value that comes directly after it in the same column, \n# then replace all the reamining na's with 0\nsubset_sf_permits.fillna(method = 'ffill', axis=0).fillna(\"0\")","execution_count":45,"outputs":[]},{"metadata":{"_cell_guid":"980e5d67-7e9c-41a3-b17e-51d87e9da9cf","_uuid":"1f8ac8b52f2933612e315f06a53185e164e6c5bc"},"cell_type":"markdown","source":"Filling in missing values is also known as \"imputation\", and you can find more exercises on it [in this lesson, also linked under the \"More practice!\" section](https://www.kaggle.com/dansbecker/handling-missing-values). "},{"metadata":{"_cell_guid":"b4f37fce-4d08-409e-bbbd-6a26c3bbc6ee","_uuid":"52b0af56e3c77db96056e9acd785f8f435f7caf5"},"cell_type":"markdown","source":"And that's it for today! If you have any questions, be sure to post them in the comments below or [on the forums](https://www.kaggle.com/questions-and-answers). \n\nRemember that your notebook is private by default, and in order to share it with other people or ask for help with it, you'll need to make it public. First, you'll need to save a version of your notebook that shows your current work by hitting the \"Commit & Run\" button. (Your work is saved automatically, but versioning your work lets you go back and look at what it was like at the point you saved it. It also let's you share a nice compiled notebook instead of just the raw code.) Then, once your notebook is finished running, you can go to the Settings tab in the panel to the left (you may have to expand it by hitting the [<] button next to the \"Commit & Run\" button) and setting the \"Visibility\" dropdown to \"Public\".\n\n# More practice!\n___\n\nIf you're looking for more practice handling missing values, check out these extra-credit\\* exercises:\n\n* [Handling Missing Values](https://www.kaggle.com/dansbecker/handling-missing-values): In this notebook Dan shows you several approaches to imputing missing data using scikit-learn's imputer. \n* Look back at the `Zipcode` column in the `sf_permits` dataset, which has some missing values. How would you go about figuring out what the actual zipcode of each address should be? (You might try using another dataset, like the [OpenAddresses dataset](https://www.kaggle.com/openaddresses/openaddresses-us-west).) \n\n\\* no actual credit is given for completing the challenge, you just learn how to clean data real good :P"}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}