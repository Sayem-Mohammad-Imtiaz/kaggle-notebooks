{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# XGBoost on Otto dataset, Tune n_estimators\nfrom pandas import read_csv\nimport os\nimport pandas as pd\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib\n#matplotlib.use('Agg')\nfrom matplotlib import pyplot\nimport time\nimport numpy as np\n# load data\n\n#df_basedata_train_0 = pd.read_csv(r'C:\\Vibhaas\\Artist of Analytics\\Algorithms\\XGBoost\\Otto_train.csv')\ndf_basedata_train_0 = pd.read_csv('/kaggle/input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv')\ndf_basedata_train_0.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_basedata_train_0.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Considerable size to tryout Classication problem."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_basedata_train_0.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting Total Charges to a numerical data type.\ndf_basedata_train_0.TotalCharges = pd.to_numeric(df_basedata_train_0.TotalCharges, errors='coerce')\ndf_basedata_train_0.info()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find Categorical Variables\ns = (df_basedata_train_0.dtypes == 'object')\nobject_cols = list(s[s].index)\nprint(\"Categorical variables:\")\nprint(object_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_1 = pd.get_dummies(df_basedata_train_0, columns=[\"gender\",\"Partner\",\"Dependents\", \"PhoneService\", \"MultipleLines\", \"InternetService\",\"OnlineSecurity\",\"OnlineBackup\",\"DeviceProtection\", \"TechSupport\",\"StreamingTV\",\"StreamingMovies\",\"Contract\",\"PaperlessBilling\",\"PaymentMethod\", \"Churn\"   ],drop_first=True)\ndf_1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_1.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Removing missing values \ndf_1.dropna(inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_1.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_1 = df_1.rename(columns={'Churn_Yes': 'target'})\n\n## Drop ID Features\ndf_2=df_1.drop(['customerID'],axis=1)\ndf_2.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**EDA**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ncorr = df_2.corr().tail(1)\ncorr.sort_values(by='target',axis=1)\n\n#import for visualization\nimport seaborn as sns\nimport matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfig, ax = plt.subplots(figsize=(20,5))\n\nplt.title(\"Correlation Plot\")\nplt.xlabel(\"Independent Vairables\")\nplt.ylabel(\"Correlation with Dependent Variable\")\nplt.xticks(rotation=90)\n\nax = sns.barplot(data=corr.sort_values(by='target',axis=1))\n\n\n#import for visualization\nimport seaborn as sns\nf,ax = plt.subplots(figsize=(35, 1))\nsns.heatmap(df_2.corr().tail(1).sort_values(by='target',axis=1), annot=True, linewidths=0.5, fmt='.2f',ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Machine Learning \n\nX = df_2.drop(\"target\", axis=1)\ny = df_2[\"target\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nclf = RandomForestClassifier(n_estimators=50, max_features='sqrt')\nclf = clf.fit(X, y)\n\n#have a look at the importance of each feature.\nfeatures = pd.DataFrame()\nfeatures['feature'] = X.columns\nfeatures['importance'] = clf.feature_importances_\nfeatures.sort_values(by=['importance'], ascending=True, inplace=True)\nfeatures.set_index('feature', inplace=True)\n\nfeatures.plot(kind='barh', figsize=(10, 10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Standardize\nfrom sklearn.preprocessing import StandardScaler\nscale = StandardScaler()\nscale.fit(X)\npredictor_standard = scale.transform(X)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# Split data to 80% training data and 20% of test to check the accuracy of our model\nX_train, X_test, y_train, y_test = train_test_split(predictor_standard, y, test_size=0.20, random_state=0)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model\n\nfrom sklearn.svm import SVC\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nimport xgboost as xgb\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nimport time\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create an array of models\nmodels = []\nmodels.append((\"LR\",LogisticRegression()))\nmodels.append((\"NB\",GaussianNB()))\nmodels.append((\"RF\",RandomForestClassifier()))\nmodels.append((\"SVC\",SVC()))\nmodels.append((\"Dtree\",DecisionTreeClassifier()))\nmodels.append((\"XGB\",xgb.XGBClassifier()))\nmodels.append((\"KNN\",KNeighborsClassifier()))\n\nresult = []\n#measure the accuracy \nfor name,model in models:\n    start_time = time.time()\n    kfold = KFold(n_splits=5, random_state=22)\n    cv_result = cross_val_score(model,X_train,y_train, cv = kfold,scoring = \"accuracy\")\n    print(name, cv_result)\n    print(\"-\"*5,name, \" Mean accuracy of cross-validation: \", format(round(cv_result.mean(),4)))\n    execution_time = (time.time() - start_time)\n    result.append((name,cv_result.mean(), execution_time ))\n    print(name,\"--- %s seconds ---\" % (time.time() - start_time))\n\npd.DataFrame(result)\n    \ndf = pd.DataFrame(result, columns =['Algo', 'Accuracy', 'execution_time']) \ndf \n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sort df by Count column\npd_df = df.sort_values(['Accuracy']).reset_index(drop=True)\nprint (pd_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplt.figure(figsize=(8,8))\n# plot bar chart with index as x values\nax = sns.barplot(pd_df.index, pd_df.Accuracy)\nax.get_yaxis().set_major_formatter(plt.FuncFormatter(lambda x, loc: \"{:,}\".format(int(x))))\nax.set(xlabel=\"Algo\", ylabel=\"Acurracy\")\n# add proper Dim values as x labels\n\nax.set_xticklabels(pd_df.Algo)\nfor item in ax.get_xticklabels(): item.set_rotation(90)\nfor i, v in enumerate(pd_df[\"Accuracy\"].iteritems()):        \n    ax.text(i ,v[1], \"{:,}\".format(v[1]), color='m', va ='bottom', rotation=45)\nplt.tight_layout()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# Split data to 80% training data and 20% of test to check the accuracy of our model\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n\n\n#Model\n\nfrom sklearn.svm import SVC\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nimport xgboost as xgb\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nimport time\n\n\n#create an array of models\nmodels = []\nmodels.append((\"LR\",LogisticRegression()))\nmodels.append((\"NB\",GaussianNB()))\nmodels.append((\"RF\",RandomForestClassifier()))\nmodels.append((\"SVC\",SVC()))\nmodels.append((\"Dtree\",DecisionTreeClassifier()))\nmodels.append((\"XGB\",xgb.XGBClassifier()))\nmodels.append((\"KNN\",KNeighborsClassifier()))\n\nresult = []\n#measure the accuracy \nfor name,model in models:\n    start_time = time.time()\n    kfold = KFold(n_splits=5, random_state=22)\n    cv_result = cross_val_score(model,X_train,y_train, cv = kfold,scoring = \"accuracy\")\n    print(name, cv_result)\n    print(\"-\"*5,name, \" Mean accuracy of cross-validation: \", format(round(cv_result.mean(),4)))\n    execution_time = (time.time() - start_time)\n    result.append((name,cv_result.mean(), execution_time ))\n    print(name,\"--- %s seconds ---\" % (time.time() - start_time))\n\npd.DataFrame(result)\n    \ndf = pd.DataFrame(result, columns =['Algo', 'Accuracy', 'execution_time']) \ndf \n\n\n# sort df by Count column\npd_df = df.sort_values(['Accuracy']).reset_index(drop=True)\npd_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\n# plot bar chart with index as x values\nax = sns.barplot(pd_df.index, pd_df.Accuracy)\nax.get_yaxis().set_major_formatter(plt.FuncFormatter(lambda x, loc: \"{:,}\".format(int(x))))\nax.set(xlabel=\"Algo\", ylabel=\"Acurracy\")\n# add proper Dim values as x labels\n\nax.set_xticklabels(pd_df.Algo)\nfor item in ax.get_xticklabels(): item.set_rotation(90)\nfor i, v in enumerate(pd_df[\"Accuracy\"].iteritems()):        \n    ax.text(i ,v[1], \"{:,}\".format(v[1]), color='m', va ='bottom', rotation=45)\nplt.tight_layout()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Attempt 3 XGBoost**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# Split data to 80% training data and 20% of test to check the accuracy of our model\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dmatrix = xgb.DMatrix(data=X,label=y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nxg_clas = xgb.XGBClassifier(objective ='reg:logistic', colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xg_clas.fit(X_train,y_train)\n\ny_pred = xg_clas.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nscore = accuracy_score(y_test, y_pred)\nprint(\"Accuracy is \" + str(round((score*100), 2))+\"%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nxgb.plot_tree(xg_clas,num_trees=0)\nplt.rcParams['figure.figsize'] = [10, 10]\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\"objective\":\"reg:logistic\",'colsample_bytree': 0.3,'learning_rate': 0.1,  'max_depth': 5, 'alpha': 10}\n\ncv_results = xgb.cv(dtrain=data_dmatrix, params=params, nfold=3, num_boost_round=50,early_stopping_rounds=10, as_pandas=True, seed=123)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_results.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nxgb.plot_tree(xg_reg,num_trees=0)\nplt.rcParams['figure.figsize'] = [50, 50]\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import plot_tree\nimport matplotlib.pyplot as plt\n\n# plot single tree\nplot_tree(xg_reg)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb.plot_importance(xg_clas)\nplt.rcParams['figure.figsize'] = [10, 10]\n\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for x in range(9):\n    xgb.plot_tree(xg_clas,num_trees=x)\n    #plt.rcParams['figure.figsize'] = [10, 10]\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}