{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# -*- coding: utf-8 -*-\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Supervisionado"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/heart-disease-uci/heart.csv\")\n# Dataset com features que indicam condições de saúde e tem classe booliana de quadro de doença cardíaca\n# será feito um algorítmo para prever se uma pessoa tem/terá doença cardíaca (1) ou não (0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# separando em dois dataframes: features e classe\nprevisores = df.iloc[:, 0:13].values \nclasse = df.iloc[:, 13].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Escalonamento: \nfrom sklearn.preprocessing import StandardScaler \nscaler = StandardScaler() \nprevisores = scaler.fit_transform(previsores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dividindo a base em treinamento e teste:\nfrom sklearn.model_selection import train_test_split \nprevisores_treinamento, previsores_teste, classe_treinamento,classe_teste = train_test_split(previsores,\n                                                                                             classe,\n                                                                                             test_size=0.3,\n                                                                                             random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Escolhemos o Support Vector Machine como classificador.\nPor um rápido tunning de parâmetros, selecionamos o kernel 'rbf' e custo 2.0 por ter dado a maior precisão nos dados. RBF (Radial basis function) é um kernel exponencial baseado na distância euclidiana dos pontos para determinar o hiperplano que separa as classes.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# classificador:\nfrom sklearn.svm import SVC\nclassificador = SVC(kernel='rbf',random_state=2, C=2.0)\n# kernel = 'rbf'\nclassificador.fit(previsores_treinamento,classe_treinamento)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# classificação: \nprevisoes = classificador.predict(previsores_teste)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# comparação com base de teste\nfrom sklearn.metrics import confusion_matrix, accuracy_score \nprecisao = accuracy_score(classe_teste, previsoes) # precisão do algoritmo\nmatriz = confusion_matrix(classe_teste, previsoes) # matriz de confusão ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"precisao","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matriz","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ## Não Supervisionado"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"import pandas as pd\ndf2 = pd.read_csv(\"../input/customer-segmentation-tutorial-in-python/Mall_Customers.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"dataset de registros são clientes de um shopping. Seus features são identidade, gênero, idade, renda e o quanto gasta no shopping.\nUma boa aplicação do aprendizado não supervisionado é a segmentação de clientes, então encontrei uma base simples, talvez simples demais, para fazer grupos de perfis de compra.\n\nUsei o clustering de Kmeans para clasificar. Os inputs necessários são basicamente o número de grupos que se quer classificar.\n\nÉ necessário transformar as variáveis categóricas em variáveis encoder. Além disso, faz-se a padronização (levar todos os valores para a mesma escala) para que não haja priorização de alguma variável pela distância euclidiana."},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df2.iloc[:,1:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# transformando variável categórica em numérica em numerica:\nfrom sklearn.preprocessing import LabelEncoder\nlabelencoder=LabelEncoder()\nX['Gender']=labelencoder.fit_transform(X['Gender'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = X.iloc[:,0:5].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# padronização das variáveis\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX = scaler.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cluster\nfrom sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters = 5)\nkmeans.fit(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"centroides = kmeans.cluster_centers_  # posição dos centroides\nrotulos = kmeans.labels_ # grupo de cada registro","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = scaler.inverse_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\ncores = [\"g.\", \"r.\", \"b.\",\"k.\",\"c.\"]  # lista de cores verde, vermelho e azul\nfor i in range(len(X)): # pra cada registro\n    plt.plot(X[i][2], X[i][3], cores[rotulos[i]], markersize = 15) \nplt.scatter(centroides[:,0], centroides[:,1])  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cores = [\"g.\", \"r.\", \"b.\",\"k.\",\"c.\"]  # lista de cores verde, vermelho e azul\nfor i in range(len(X)): # pra cada registro\n    plt.plot(X[i][1], X[i][3], cores[rotulos[i]], markersize = 15) \nplt.scatter(centroides[:,0], centroides[:,1])  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos visualizar bem os grupos, que surpreendentemente é bem dividido e o algoritmo detectou bem essa tendência.\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}