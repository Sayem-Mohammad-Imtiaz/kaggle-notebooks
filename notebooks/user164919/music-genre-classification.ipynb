{"cells":[{"metadata":{},"cell_type":"markdown","source":"# MUSIC GENRE CLASSIFICATION","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataset\n    The Dataset consist of two folders\n    1. Music files\n    2. Images of Music Files","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import librosa \nimport matplotlib.pyplot as plt\nimport librosa.display\n\n\nN_FFT = 2048\nN_MELS = 128\nHOP_LEN = 512\ny, sfr = librosa.load('/kaggle/input/gtzan-dataset-music-genre-classification/Data/genres_original/hiphop/hiphop.00016.wav')\n\nmelSpec = librosa.feature.melspectrogram(y=y, sr=sfr, n_mels=N_MELS,hop_length=HOP_LEN, n_fft=N_FFT)\nmelSpec_dB = librosa.power_to_db(melSpec, ref=np.max)\n\nlibrosa.display.specshow(melSpec_dB)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Задача\nСоздать модель для классификации музыки","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"path='../input/gtzan-dataset-music-genre-classification/Data/images_original'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_gen=tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255., validation_split=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(img_height, img_width)=(299,299)\nbatch_size=32\ntrain_generator = data_gen.flow_from_directory(\n    path,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training') # set as training data\n\nvalidation_generator = data_gen.flow_from_directory(\n    path, # same directory as training data\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation') # set as validation data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Подготовка модели\n### Transfer Learning\nДля примера будем использовать модель Xception.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications import Xception","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model=Xception(include_top=False,input_shape=(299,299,3))\n\n# Freeze the base_model\nbase_model.trainable = False\n\n# Create new model on top\ninputs = tf.keras.Input(shape=(299,299,3))\n\nx = base_model(inputs, training=False)\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\nx = tf.keras.layers.Dropout(0.2)(x)  # 1st improove Regularize with dropout\nx = tf.keras.layers.Dense(512,activation='relu')(x)\nx = tf.keras.layers.Dropout(0.2)(x) # 2st improove Regularize with dropout\nx = tf.keras.layers.Dense(64,activation='relu')(x)\noutputs = tf.keras.layers.Dense(10,activation='softmax')(x)\n\nmodel = tf.keras.Model(inputs, outputs)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Обучение модели","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## \"Прогрев\" новых слоев","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['acc'])\nhistory_warmup = model.fit(train_generator, validation_data=validation_generator,epochs=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Финальная настройка","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model.trainable = True\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = tf.keras.optimizers.Adam(1e-5)\nmodel.compile(loss='categorical_crossentropy',optimizer=optimizer,metrics=['acc'])\nhistory_final = model.fit(train_generator, validation_data=validation_generator,epochs=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(range(0,20), history_warmup.history['acc'], label='Warmup Accuracy (training data)')\nplt.plot(range(0,20), history_warmup.history['val_acc'], label='Warmup Accuracy (validation data)')\n\nplt.plot(range(20,40), history_final.history['acc'], label='Final Accuracy (training data)')\nplt.plot(range(20,40), history_final.history['val_acc'], label='Final Accuracy (validation data)')\n\nplt.ylabel('Accuracy')\nplt.xlabel('No. epoch')\n#plt.legend(loc=\"upper left\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import itertools\n\n#http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        #print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Предобработка","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Исходные изображения содержат рамки, попробуем их убрать.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport cv2 \n\nIMG = '../input/gtzan-dataset-music-genre-classification/Data/images_original'\n#IMG = './dataset/'\nimg_dataset = []\ngenre_target = []\ngenres = {}\nclasses = []\ni = 0\nfor root, dirs, files in os.walk(IMG):\n    for name in files:\n        filename = os.path.join(root, name)\n        img_dataset.append(filename)\n        genre = filename.split('/')[-2]\n        genre_target.append(genre)\n        \n        if(genre not in genres):\n            classes.append(genre)\n            genres[genre] = i\n            i+=1\n\nimg = cv2.imread(img_dataset[0],1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def crop_borders(img,x1=35,x2=252,y1=54,y2=389):\n    cropped = img[x1:x2,y1:y2]\n    return cropped\n\ndef get_y():\n    '''Convierte los generos en un array de targets y'''\n    y = []\n    for genre in genre_target:\n        n = genres[genre]\n        y.append(n)\n    return np.array(y)\n\ndef get_x(shape=[999,217,335], flag=1):\n    x = np.empty(shape, np.uint8)\n    for i in range(len(img_dataset)):\n        img = cv2.imread(img_dataset[i],flag)\n        img = crop_borders(img)\n        x[i] = img\n    return np.array(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = cv2.imread(img_dataset[0])\nimg = crop_borders(img)\n\nimg.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = get_x(shape=[999,img.shape[0], img.shape[1], img.shape[2]]) #Imagenes en color, RGB -> 3 canales\ny = get_y()\n\nm = len(y)\nnum_labels = 10 #estilos de musica diferente\n\nprint(X.shape, y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2)\n\ny = to_categorical(y)\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\n\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model=Xception(include_top=False,input_shape=(217, 335, 3))\n\n# Freeze the base_model\nbase_model.trainable = False\n\n# Create new model on top\ninputs = tf.keras.Input(shape=(217, 335, 3))\n\nx = base_model(inputs, training=False)\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\nx = tf.keras.layers.Dropout(0.2)(x)  # 1st improove Regularize with dropout\nx = tf.keras.layers.Dense(512,activation='relu')(x)\nx = tf.keras.layers.Dropout(0.2)(x) # 2st improove Regularize with dropout\nx = tf.keras.layers.Dense(64,activation='relu')(x)\noutputs = tf.keras.layers.Dense(10,activation='softmax')(x)\n\nmodel = tf.keras.Model(inputs, outputs)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['acc'])\nhistory_warmup = model.fit(X_train,y_train,\n                           validation_data=(X_test, y_test),\n                           epochs=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model.trainable = True\nmodel.summary()\noptimizer = tf.keras.optimizers.Adam(1e-5)\nmodel.compile(loss='categorical_crossentropy',optimizer=optimizer,metrics=['acc'])\nhistory_final = model.fit(X_train,y_train,\n                           validation_data=(X_test, y_test),\n                           epochs=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(range(0,20), history_warmup.history['acc'], label='Warmup Accuracy (training data)')\nplt.plot(range(0,20), history_warmup.history['val_acc'], label='Warmup Accuracy (validation data)')\n\nplt.plot(range(20,40), history_final.history['acc'], label='Final Accuracy (training data)')\nplt.plot(range(20,40), history_final.history['val_acc'], label='Final Accuracy (validation data)')\n\nplt.ylabel('Accuracy')\nplt.xlabel('No. epoch')\n#plt.legend(loc=\"upper left\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\npreds = np.argmax(model.predict(X_test), axis = 1)\ny_orig = np.argmax(y_test, axis = 1)\ncm = confusion_matrix(preds, y_orig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#keys = OrderedDict(sorted(genres.items(), key=lambda t: t[1])).keys()\nplt.figure(figsize=(10,10))\nplot_confusion_matrix(cm, classes, normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('my_h5_model.h5')\nmodel = tf.keras.models.load_model('my_h5_model.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Полностью своя сеть","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(input_shape):\n    \"\"\"Generates CNN model\n    :param input_shape (tuple): Shape of input set\n    :return model: CNN model\n    \"\"\"\n\n    # build network topology\n    model = tf.keras.Sequential()\n\n    # 1st conv layer\n    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n    model.add(tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n    model.add(tf.keras.layers.BatchNormalization())\n\n    # 2nd conv layer\n    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu'))\n    model.add(tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n    model.add(tf.keras.layers.BatchNormalization())\n\n    # 3rd conv layer\n    model.add(tf.keras.layers.Conv2D(32, (2, 2), activation='relu'))\n    model.add(tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n    model.add(tf.keras.layers.BatchNormalization())\n\n    # flatten output and feed it into dense layer\n    model.add(tf.keras.layers.Flatten())\n    model.add(tf.keras.layers.Dense(64, activation='relu'))\n    model.add(tf.keras.layers.Dropout(0.4))\n\n    # output layer\n    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create network\ninput_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3])\nmodel = build_model(input_shape)\n\n# compile model\noptimiser = tf.keras.optimizers.Adam(learning_rate=0.0001)\nmodel.compile(optimizer=optimiser,\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\nmodel.summary()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train model\nhistory = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=32, epochs=30)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['accuracy'], label='Accuracy (training data)')\nplt.plot(history.history['val_accuracy'], label='Accuracy (validation data)')\nplt.plot(history.history[\"loss\"], label=\"training loss\")\nplt.plot(history.history[\"val_loss\"], label=\"validation loss\")\n\nplt.ylabel('Accuracy')\nplt.xlabel('No. epoch')\nplt.legend(loc=\"upper left\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\npreds = np.argmax(model.predict(X_test), axis = 1)\ny_orig = np.argmax(y_test, axis = 1)\ncm = confusion_matrix(preds, y_orig)\nplt.figure(figsize=(10,10))\nplot_confusion_matrix(cm, classes, normalize=True)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}