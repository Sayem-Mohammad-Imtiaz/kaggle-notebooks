{"cells":[{"metadata":{},"cell_type":"markdown","source":"PREDICTING THE PRICE OF THE HOUSE USING NEURAL NETWORK\n\nPS: Please like or upvote my kernel if you liked my work or learnt something new from it. Thank you."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importing the required libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Upload the dataset and name it as 'df'"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/housesalesprediction/kc_house_data.csv')\n# importing the dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df # a look at the dataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Describing and understanding the dataset. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()\n# checking for any missing data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe().transpose()\n# understanding the data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.distplot(df['price'])\n# checking the price column distribution\n# most of the house price fall between 0 - 1.5 million dollars","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df['bedrooms'])\n# most of the houses have between 2 - 5 bedrooms on average","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()\n# correlations of all the columns with respect to each other","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()['price'].sort_values()\n# correlation of the price column alone with respect to other columns and sorted in ascending order","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.scatterplot(x='price',y='sqft_living',data=df)\n# a very linear relationship observed as they are highly correlated as seen from the above table","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.scatterplot(x='price',y='bathrooms',data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='bedrooms',y='price',data=df)\n# bedrooms and price correlation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.scatterplot(x = 'price', y = 'long', data = df)\n# there is a lot of price variations based on the longitude of the location of the house","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.scatterplot(x = 'price', y = 'lat', data = df)\n# expensive housing areas in some particular latitudes\n# at a certain combination of lat and long there seems to be an expensive neighbourhood","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15,12))\nsns.scatterplot(x = 'long', y = 'lat', data = df, hue = 'price')\n# the shape of the distribution matches the King county in Seattle\n# darker points are the expensive neighborhoods","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.sort_values('price', ascending = False).head(20)\n# only about 20 houses are in the range of 3 - 7 million dollars\n# these can be considered as outliers in the dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df)\n# 21613 houses in the dataset\n# 1% of 21613 = 216 houses","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dealing with the outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"bottom_99_percent = df.sort_values('price', ascending = False).iloc[216:]\n# this drops all the really expensive houses which were the outliers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bottom_99_percent","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15,12))\nsns.scatterplot(x = 'long', y = 'lat', data = bottom_99_percent, hue = 'price', palette = 'RdYlGn')\n# a lot clearer color distribution of the expensive houses","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='waterfront',y='price',data=df)\n# waterfront houses are more expensive","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dropping columns that are not necessary"},{"metadata":{"trusted":true},"cell_type":"code","source":"df\n# can drop ID","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop('id', axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['date'] = pd.to_datetime(df['date'])\n# convert the date column items into a date-time object. The formatting also changes.\n# now its easier to extract info like the month and year automatically","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['date']\n# feature engineering or feature extraction can be done on this object now","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['year'] = df['date'].apply(lambda date: date.year)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['year']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['month'] = df['date'].apply(lambda date: date.month)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['month']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df\n# the year and month columns are now added to this. Exploratory data analysis can be done on to see if they are useful.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('month').mean()['price'].plot()\n# to check if any significant relationship between month sold and price of the house\n# about $60k price difference during the sprint and summer months.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('year').mean()['price'].plot()\n# sales increasing in price as the time goes by","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop('date', axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['zipcode'].value_counts()\n# zipcodes cannot be left as numerical values. They have to be treated as a categorical variable.\n# 70 categories of zipcodes have to be created to make dummy variables here\n# ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop('zipcode', axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop('price', axis =1).values\ny = df['price']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Splitting the dataset into Training set and Test set (test set = 30% of the dataset)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=101)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Sacling only our training values. Using MinMaxScaler"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train= scaler.fit_transform(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importing libraries needed to create a neural network"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation\nfrom tensorflow.keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating the layers of the neural network along with the activation function and optimizer."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Dense(19,activation='relu'))\nmodel.add(Dense(19,activation='relu'))\nmodel.add(Dense(19,activation='relu'))\nmodel.add(Dense(19,activation='relu'))\nmodel.add(Dense(1)) # output layer neuron\n\nmodel.compile(optimizer='adam',loss='mse')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fitting the model to the training set and also providing the test set values to validate the model performance"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x=X_train,y=y_train.values,\n          validation_data=(X_test,y_test.values),\n          batch_size=128,epochs=400)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plotting the cost/loss function for the training and test set."},{"metadata":{"trusted":true},"cell_type":"code","source":"losses = pd.DataFrame(model.history.history)\n# Loss: loss on training set\n# val_loss: loss on test set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"losses.plot()\n# both lines are close so no overfitting of the model\n# decrease in both the training and validation loss","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importing libraries to evaluate the performance of the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error,mean_absolute_error,explained_variance_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_absolute_error(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.sqrt(mean_squared_error(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"explained_variance_score(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['price'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['price'].median()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The scatterplot indicates the predicted values and the red line indicates the actual values. Our predicted model is linear and falls very close to the actual value. The model's performance was reduced due to the presence of the outliers (houses worth more than $4 million). This model explains 80 percent of the variance."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Our predictions\nplt.scatter(y_test,y_pred)\n\n# Perfect predictions\nplt.plot(y_test,y_test,'r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}