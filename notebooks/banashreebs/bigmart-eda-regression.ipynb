{"cells":[{"metadata":{},"cell_type":"markdown","source":"# EDA\n\nExploratory data analysis is a crucial step of Data Analysis that helps in understanding the data. \nEDA gives insight and knowledge to the data which later helps us to build a suitable model. \n\nFor this notebook, I chose BigMart Sales data and the task is to build a regression model to prdict the sales of the items.\n\nThe data has both numerical and categorical features with missing values.\nLooks like I can apply all basic EDA techniques here!"},{"metadata":{"_uuid":"f9ed8a82-b2f6-4951-8555-342778b1d57b","_cell_guid":"8886b2da-9688-4439-9ccd-4a81bca69bd1","trusted":true},"cell_type":"code","source":"# BigMart Sales Prediction\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nfrom scipy.stats import norm\nfrom scipy import stats\n\n# Load the data \na = pd.read_csv(r'../input/big-mart-sales-prediction/Train.csv')\nb = pd.read_csv(r'../input/big-mart-sales-prediction/Test.csv')\n# I store the ID for later use and delete it from the data.\nc = b.iloc[:, 0]\nd = b.iloc[:, 6]\n\na.drop(['Item_Identifier', 'Outlet_Identifier'], axis = 1, inplace = True)\nb.drop(['Item_Identifier', 'Outlet_Identifier'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I stored the numerical and categorical feature names in a variable for future use."},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical = ['Item_Fat_Content', 'Outlet_Size','Outlet_Location_Type','Outlet_Type', 'Item_Type']\ncontinuous = ['Item_Weight','Item_Visibility', 'Item_MRP','Item_Outlet_Sales']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's have a look at the structure of our training data..."},{"metadata":{"_uuid":"9abeaaa5-3338-4ff3-ad9e-7c3e3fd1dc0e","_cell_guid":"8cc52c11-66f6-46ed-b3ca-c774564a8159","trusted":true},"cell_type":"code","source":"a.info()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"... and the testing data."},{"metadata":{"_uuid":"bc9acbbd-643d-444f-b1f1-5e1272210e82","_cell_guid":"4d3ef0e0-6b84-44cb-bfeb-369f3e547728","trusted":true},"cell_type":"code","source":"b.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* There are 9 features among which 5 are categorical and 4 are continuous.\n* Target variable is Item_Outlet_Sales and it is a continuous variable.\n* Both training and testing data have the same continuous and categorical features with the exception of target variable.\n* Eventhogh number of features are same, the testing data has less number of observations. Having too many observations will affect the working of the model since the model tends to fit nicely with the increase of the observations. Hence this difference in the number might help us anyway.\n\nBy looking at the features we can guess existence of relationship between MRP, FatContent, Visibility and the target variable but we won't arrive at a conclusion without looking at the correlations."},{"metadata":{},"cell_type":"markdown","source":"Let's have a closer look at our VIP, the target variable."},{"metadata":{"_uuid":"07566f91-4640-4410-b088-bf5e70e6e975","_cell_guid":"5ac41470-5cfd-49e4-ada0-8a4428f8e669","trusted":true},"cell_type":"code","source":"sns.distplot(a['Item_Outlet_Sales'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Turns out that the VIP is skewed positively.\n"},{"metadata":{},"cell_type":"markdown","source":"Let's have a peek into the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"a.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Has nan values, "},{"metadata":{},"cell_type":"markdown","source":"Checking for missing data. \n\n\nSometimes missing data can be written as nan or just replaced as 0. \nIn some features 0 does not make sense, so that time it is safe to assume that this might be a missing data."},{"metadata":{"_uuid":"07011ec5-1d2d-40f1-8ba2-8d3baa2e2e72","_cell_guid":"f6efe9f3-1eeb-4cac-865a-fa6d7e61843c","trusted":true},"cell_type":"code","source":"a.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4cfc04e2-2711-412e-9e0d-ca59ce71a14a","_cell_guid":"6e5df5b2-ef63-40c2-8b39-d8f049a25e31","trusted":true},"cell_type":"code","source":"b.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The training data has missing values in Item_Weight and Outlet_Size which is continuous and categorical feature respectively. Hence, the treatment will be different.\n* The testing data also have null values in the same features."},{"metadata":{},"cell_type":"markdown","source":"Checking for 0 valus."},{"metadata":{"_uuid":"66c8a7c6-2a76-4605-a497-94dba6ffa837","_cell_guid":"a8a6dea2-d42e-47a3-9470-69ee59474e00","trusted":true},"cell_type":"code","source":"a.eq(0).sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3811877b-a3b6-4e12-b88a-2707733baddb","_cell_guid":"b4f27f7c-47b1-47d6-b459-86a119c6184e","trusted":true},"cell_type":"code","source":"b.eq(0).sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is 0 value only in Item_Visibilty feature. We can approch this in 2 ways:\n* From the data description, we know that Item_Visibility is calculated in %. So, 0% can mean that the item was not on display. We can then,treat it as a normal data and move ahead with the analysis.\n* Or we can see it as missing value. Then, it belongs to the continuous feature and can be treated in the same way as Item Weight.\n\nHere, I see it as a missing data."},{"metadata":{},"cell_type":"markdown","source":"Missing data Treatment\n\nThere are 3 types of missing data:\n* Missing completely at random - The data is missing be error and does not depend on any other feature or itself.\n* Missing at Random - Here, the data is missing because of other feature and not itself. For eg., women not disclosing age. Women here is another feature.\n* Not missing at random - The data is missing because of it's nature. For eg., salary, sex etc. \n\nTreatment for missing values varies on the category."},{"metadata":{},"cell_type":"markdown","source":"In our data, values of Item Visibility, Outlet size and Item weight. \nWe can safely say that these are missing completely at random.\n\nI will impute them."},{"metadata":{"_uuid":"c63098b3-98a9-49e6-a969-78d11efb1f36","_cell_guid":"ee8d1196-89dd-48fe-b419-e576e7c28b2f","trusted":true},"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nimp = SimpleImputer(missing_values  = np.nan, strategy = 'mean')\na.iloc[:, [0]] = imp.fit_transform(a.iloc[:,[0]])\nb.iloc[:, [0]] = imp.transform(b.iloc[:,[0]])\nimp1 = SimpleImputer(missing_values  = 0, strategy = 'mean')\na.iloc[:, [2]] = imp1.fit_transform(a.iloc[:,[2]])\nb.iloc[:, [2]] = imp1.transform(b.iloc[:,[2]])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For categorical missing values, I will replace them with mode."},{"metadata":{"_uuid":"79b06964-845e-4615-b82e-243afc2c52df","_cell_guid":"ae83be0a-c20d-419b-b7ef-54979439cbeb","trusted":true},"cell_type":"code","source":"a['Outlet_Size'].fillna(a['Outlet_Size'].mode()[0], inplace = True)\nb['Outlet_Size'].fillna(b['Outlet_Size'].mode()[0], inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Correlation\n\nNow to check the relationship between our VIP and it's followers, I will use heatmap."},{"metadata":{"_uuid":"13261ee6-03e6-40be-941f-c3010158d307","_cell_guid":"70b54a8b-87cc-4afc-adef-84d56228697d","trusted":true},"cell_type":"code","source":"sns.heatmap(a.corr(), annot = True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks like our VIP is not liked that much. Sad!\nOnly Item_MRP and the target variable has correltion coefficient above 0.5.\nBut Multicollinearity won't be a problem. ;)\n"},{"metadata":{"_uuid":"a68d82df-5837-4ec0-9030-a7ecf1b483c8","_cell_guid":"fe949b08-6a2f-4bd3-972a-a4f374644630","trusted":true},"cell_type":"code","source":"sns.scatterplot(x = a['Item_MRP'], y = a['Item_Outlet_Sales'], data = a)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Eventhough, it looks like Sales increase with MRP, there are less number of sales for high MRP value. This trend seems natural, with less price, items tends to be sold out quickly."},{"metadata":{},"cell_type":"markdown","source":"Let's peek into the big picture."},{"metadata":{},"cell_type":"markdown","source":"Relationship with Continuous Features."},{"metadata":{"_uuid":"74c8d64b-781f-4c1a-ab3d-fba0edc9e62a","_cell_guid":"f2f5e300-5460-4299-9ed0-f16358687847","trusted":true},"cell_type":"code","source":"sns.pairplot(a)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Wow, not much of a linear data. \n\n\nOutlet_Establishment year graph looks odd, lets look at the values. "},{"metadata":{"_uuid":"b5a99cd2-9c07-4cb1-82c9-bd7686fa6f37","_cell_guid":"bfa420ae-1cc0-4e80-b21b-ed7754623299","trusted":true},"cell_type":"code","source":"a['Outlet_Establishment_Year'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since, there are only 9 values here, we can treat this feature as categorical data and encode or bin it."},{"metadata":{},"cell_type":"markdown","source":"Relationship of  target variable with Categorical Features."},{"metadata":{"_uuid":"7f8404d8-f529-42c2-9a97-d6b675a3caef","_cell_guid":"4c04f660-719f-410a-b15a-dc25c832dd42","trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=3, figsize = (15,8))\nfig.subplots_adjust(right=1)\nfig.suptitle('Relationshp with Categorical Features')\nfor ax, feature in zip(axes.flatten(),  categorical[0:3]):\n    sns.stripplot(x = feature,  y = 'Item_Outlet_Sales', data = a, ax = ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Oh oh, look at the first graph. Item Fat Content has error. Low Fat, LF and low fat all belongs to one category. We will need to correct this error."},{"metadata":{"_uuid":"5f2648b0-f2d8-4372-8afc-8cce4224e6ed","_cell_guid":"a2b12645-8492-4657-9943-b5e07d70780d","trusted":true},"cell_type":"code","source":"a.Item_Fat_Content = a.Item_Fat_Content.replace({'low fat' : 'Low Fat', 'LF' : 'Low Fat', 'reg' : 'Regular'})\nb.Item_Fat_Content = b.Item_Fat_Content.replace({'low fat' : 'Low Fat', 'LF' : 'Low Fat', 'reg' : 'Regular'})\nfig, axes = plt.subplots(nrows=1, ncols=3, figsize = (15,8))\nfig.subplots_adjust(right=1)\nfig.suptitle('Relationshp with Categorical Data')\nfor ax, feature in zip(axes.flatten(),  categorical[0:3]):\n    sns.stripplot(x = feature,  y = 'Item_Outlet_Sales', data = a, ax = ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Perfect. \n* Low fat Items were sold little more than regular. Who can stay away from the good stuff right?\n* Small outlet size means congesting, maybe that's why sales went down. \n"},{"metadata":{"_uuid":"56d6197b-2df8-4d8b-a98f-65ce126729ff","_cell_guid":"8721509f-0c3a-46a9-923b-8262d2628d96","trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows = 2, ncols=1, figsize = (20,25))\nfig.subplots_adjust(hspace=0.5)\nfig.suptitle('Relationshp with Categorical Data')\nfor ax, feature in zip(axes.flatten(),  categorical[3:]):\n    sns.stripplot(x = 'Item_Outlet_Sales', y = feature, data = a, ax = ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Naturally, supermarkets are large establishments with increased number of choice, quality and quantity which increases salse. Afterall, they are SUPERmarkets ;)"},{"metadata":{},"cell_type":"markdown","source":"Some more insights"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,axes = plt.subplots(figsize = (10,10))\nsns.boxplot(x = a['Outlet_Establishment_Year'], y = a['Item_Outlet_Sales'], hue = a['Outlet_Type'], ax = axes )\nplt.plot","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We can see that sales in grocery stores are rare even in previous years. \n* Many outliers are present. These are establishments having very huge sales for that year."},{"metadata":{},"cell_type":"markdown","source":"Treating our Categorical friends."},{"metadata":{"_uuid":"5127f3c0-62cb-4d8e-ac27-831180f47d92","_cell_guid":"8cc2835f-40b8-408d-a679-145db5dfb915","trusted":true},"cell_type":"code","source":"# Encoding Categorical\na = pd.get_dummies(a, drop_first = True)\nb = pd.get_dummies(b, drop_first = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"834e2198-30c0-4542-9801-ad5e4ebb7c12","_cell_guid":"209b5c88-163d-48f2-854e-3c04ee4fc119","trusted":true},"cell_type":"code","source":"a.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Dropfirst is used to avoid dummy variale trap.\n* Since Item_Type has many categories, we can use hashing technique on it.\n"},{"metadata":{},"cell_type":"markdown","source":"Checking for assumptions:\n"},{"metadata":{},"cell_type":"markdown","source":"Normality of Errors\n\nFor checking normality of errors, we will need a model and fit the data to it."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting\nY = a['Item_Outlet_Sales']\nX = a.drop('Item_Outlet_Sales', axis = 1)\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state = 0, test_size = 0.25)\n# Model\n# Linear Regression\nfrom sklearn.linear_model import LinearRegression\nlg = LinearRegression()\nlg.fit(X_train, Y_train)\nY_pred = lg.predict(X_test)\nresidue = Y_test - Y_pred\nsns.regplot(residue, Y_pred, lowess = True, line_kws={'color': 'red'})\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The graph is funnel shaped. Hence, it is heteroscedasticity.\n\nTo correct this, I will log transform Y variable and try."},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_train = np.log(Y_train)\nY_test = np.log(Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlg = LinearRegression()\nlg.fit(X_train, Y_train)\nY_pred = lg.predict(X_test)\nresidue = Y_test - Y_pred\nsns.regplot(residue, Y_pred, lowess = True, line_kws={'color': 'red'})\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Regression\n\nI will use SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"# SVM\nfrom sklearn.svm import SVR\nregressor = SVR(kernel = 'rbf')\nregressor.fit(X_train, Y_train)\nY_pred2 = regressor.predict(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Calculating RMSE"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nfrom math import sqrt\nrms = sqrt(mean_squared_error(Y_test, Y_pred2))\nfrom sklearn.metrics import r2_score\nr2 = r2_score(Y_test, Y_pred2)\nprint('RMSE = ',rms, ' R2 score = ',r2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Feature Selection Using Lasso"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LassoCV\nmodel_lasso = LassoCV(alphas = [1, 0.1, 0.001, 0.0005])\nmodel_lasso.fit(X_train, Y_train)\ncoef = pd.Series(model_lasso.coef_, index = X_train.columns)\nimp_features = coef.index[coef!=0].tolist()\n\nimp_features\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train[imp_features]\nX_test = X_test[imp_features]\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Feature Engineering\n\nI will bin the Outlet_Establishment_Year feature. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import KBinsDiscretizer\ndisc = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='uniform')\nX_train['Outlet_Establishment_Year'] = disc.fit_transform(X_train[['Outlet_Establishment_Year']])\nX_test['Outlet_Establishment_Year'] = disc.fit_transform(X_test[['Outlet_Establishment_Year']])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVR\nregressor = SVR(kernel = 'rbf')\nregressor.fit(X_train, Y_train)\nY_pred3 = regressor.predict(X_test)\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\nrms = sqrt(mean_squared_error(Y_test, Y_pred3))\nfrom sklearn.metrics import r2_score\nr2 = r2_score(Y_test, Y_pred3)\nprint('RMSE = ',rms, ' R2 score = ',r2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nX_train.iloc[:,0:2] = sc_X.fit_transform(X_train.iloc[:,0:2])\nX_test.iloc[:,0:2] = sc_X.transform(X_test.iloc[:,0:2])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model after feature scaling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVR\nregressor = SVR(kernel = 'rbf')\nregressor.fit(X_train, Y_train)\nY_pred3 = regressor.predict(X_test)\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\nrms = sqrt(mean_squared_error(Y_test, Y_pred3))\nfrom sklearn.metrics import r2_score\nr2 = r2_score(Y_test, Y_pred3)\nprint('RMSE = ',rms, ' R2 score = ',r2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After feature scaling, RMSE decreased but R square increased."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}