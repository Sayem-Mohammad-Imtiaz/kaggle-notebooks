{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"4324c511-2ee9-8382-a4e4-6c88a7eb5e5c"},"source":"# PET Signal for Labelling\nA script to show how to use the PET Signal for labeling tumors.\nBased on https://www.kaggle.com/kmader/d/4quant/soft-tissue-sarcoma/superpixels-on-petct-for-labeling"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cd1d06de-3331-4fb7-fef2-1250ca6ab4ee"},"outputs":[],"source":"import os\nimport h5py\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom skimage.segmentation import slic\nfrom skimage.segmentation import mark_boundaries\n\n# utility functions\nmake_proj = lambda x: np.sum(x,1)[::-1]\nmake_mip = lambda x: np.max(x,1)[::-1]"},{"cell_type":"markdown","metadata":{"_cell_guid":"b508aa73-eb83-77d0-6d1b-15e98e5ea52f"},"source":"# Loading and Displaying PET and CT\nHere we load the PET, CT and Label data from a _single_ patient and show the projection image for CT, the Maximum Intensity Projection (MIP) view for the PET data and the label data."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"18e97f9d-a93a-125c-809e-e762b5c230ba"},"outputs":[],"source":"patient_index = 2\nwith h5py.File(os.path.join('..', 'input', 'lab_petct_vox_5.00mm.h5'), 'r') as p_data:\n    print('Available keys', list(p_data.keys()))\n    id_list = list(p_data['ct_data'].keys())\n    ct_image = p_data['ct_data'][id_list[patient_index]].value\n    pet_image = p_data['pet_data'][id_list[patient_index]].value\n    label_image = p_data['label_data'][id_list[patient_index]].value\n    # ask kevin why label_image as below\n    #label_image = (p_data['label_data'][id_list[0]].value>0).astype(np.uint8)"},{"cell_type":"markdown","metadata":{"_cell_guid":"ffc85098-3fa0-7577-aca0-57cf23e91a9e"},"source":"### Projection\nShow the projection of the images. This means show a 2D view of the 3D image data."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f75abea4-fcd8-12d0-339a-98a5fbea8306"},"outputs":[],"source":"fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize = (12, 4))\nct_proj = make_proj(ct_image)\nsuv_max = make_mip(pet_image)\nlab_proj = make_proj(label_image)\n\nax1.set_title('CT Image projection')\nax1.imshow(ct_proj, cmap = 'bone')\n\nax2.set_title('SUV Image projection')\nax2.imshow(np.sqrt(suv_max), cmap = 'magma')\n\nax3.set_title('Tumor Labels projection')\nax3.imshow(lab_proj, cmap = 'magma')"},{"cell_type":"markdown","metadata":{"_cell_guid":"530bff45-04f1-d4d7-9f59-da11767ee48f"},"source":"## Full 3D Superpixels\nHere we make full 3D superpixels for PETCT and show a simple rendering of them"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fef8216f-d1d3-040a-3bad-4811dab5a419"},"outputs":[],"source":"pet_weight = 1.0 # how strongly to weight the pet_signal (1.0 is the same as CT)\n# based on experience how a radiologist is using the PET window\npet_window = 5\npetct_vol = np.stack([np.stack([(ct_slice+1024).clip(0,2048)/2048, \n                                 pet_weight*(suv_slice).clip(0, pet_window)/pet_window], -1) \n                      for ct_slice, suv_slice in zip(ct_image, pet_image)], 0)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6ca7a2ea-6dcf-8722-5ee6-4ff6c2ed49ec"},"outputs":[],"source":"%%time\npetct_segs = slic(petct_vol, \n                  n_segments = 5050,\n                  compactness = 1,\n                  multichannel = True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d722d804-2218-335c-86cf-62e8de438f35"},"outputs":[],"source":"petct_max_segs = make_mip(petct_segs)\nct_proj = make_proj(petct_vol[:,:,:,0])\nsuv_mip = make_mip(petct_vol[:,:,:,1])\n\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(14, 6))\nax1.imshow(suv_mip, cmap='magma')\nax1.set_title('SUV Image')\nax2.imshow(petct_max_segs, cmap='gray')\nax2.set_title('Segmented Image')\nax3.imshow(mark_boundaries(suv_mip, petct_max_segs))"},{"cell_type":"markdown","metadata":{"_cell_guid":"788bb6ee-07a3-2ab8-e13c-b5cc1e574ef5"},"source":"## Compare Segments to Labels\n\nWe look at each superpixel and see how many different labels are inside it. We want each superpixel to be an 'atomic' unit of the image."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8fbdb700-8760-2e73-3915-f71b1e7585c4"},"outputs":[],"source":"# Count label pixels\nunique_labels = np.unique(label_image)\nfor i in unique_labels:\n    u,c = np.unique(label_image[label_image == i], return_counts=True)\n    print('label', i, 'pixel count:\\t', c[0])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5b0c4da2-3710-cc29-a9f8-f1115f0cbe1d"},"outputs":[],"source":"print('Distinct values in CT:\\t', '{:,}'.format(len(np.unique(ct_image))))\nprint('Distinct values in PET:\\t','{:,}'.format(len(np.unique(pet_image))))\nprint('Distinct values in Label:\\t', len(np.unique(label_image)))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"14a348ba-1e8d-20fe-3f92-300f2ca6068d"},"outputs":[],"source":"for idx in np.unique(petct_segs):\n    cur_region_mask = (petct_segs == idx)\n    labels_in_region = label_image[cur_region_mask]\n    labeled_region_inside = np.unique(labels_in_region)\n    if len(labeled_region_inside) > 1:\n        print(labeled_region_inside)\n        print('\\nSuperpixel id', idx, 'regions', len(labeled_region_inside))\n        print(pd.value_counts(labels_in_region))\n        print('Missclassified Pixels:', np.sum(pd.value_counts(labels_in_region)[1:].values))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"592e61d9-a830-a7ef-e1fa-85f005d6b987"},"outputs":[],"source":"nz_labels = [i for i in np.unique(label_image) if i>=0]\nfig, m_axs = plt.subplots(len(nz_labels), 2, figsize = (5, 15))\nfor (ax1, ax2), i_label in zip(m_axs, nz_labels):\n    out_sp = np.zeros_like(petct_segs)\n    cur_label_mask = label_image == i_label\n    labels_in_region = petct_segs[cur_label_mask]\n    \n    superpixels_in_region = np.unique(labels_in_region)\n    for i, sp_idx in enumerate(superpixels_in_region):\n        out_sp[petct_segs == sp_idx] = i+1\n    \n    ax1.imshow(make_proj(cur_label_mask), cmap = 'bone')\n    ax1.set_title('Label Map {}'.format(i_label) if i_label>0 else 'Background Label')\n    ax1.axis('off')\n    \n    ax2.imshow(make_proj(out_sp), cmap = 'gist_earth')\n    ax2.set_title('Superpixels ({})'.format(len(superpixels_in_region)))\n    ax2.axis('off')"},{"cell_type":"markdown","metadata":{"_cell_guid":"3215327d-ad91-e365-9c02-ee735fd0d083"},"source":"## Show the superpixels for each label\nHere we can show which superpixels are inside each label."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"68bd9eaf-6a55-c4a7-5ace-d67c3b4056b5"},"outputs":[],"source":"for idx in np.unique(label_image):\n    cur_region_mask = label_image == idx\n    labels_in_region = petct_segs[cur_region_mask]\n    labeled_regions_inside = np.unique(labels_in_region)\n    print('Label id:', idx, 'superpixels inside', len(labeled_regions_inside))"},{"cell_type":"markdown","metadata":{"_cell_guid":"7c3c6145-b642-981c-78e2-052bd39c1b11"},"source":"# Optimize Superpixel Size"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"26b3915a-53bd-4a44-77f9-bf092683bf4c"},"outputs":[],"source":"def label_score(gt_labels, sp_segs):\n    # type: (np.ndarray, np.ndarray) -> float\n    \"\"\"\n    Score how well the superpixels match to the ground truth labels. \n    Here we use a simple penalty of number of pixels misclassified\n    :param gt_labels: the ground truth labels (from an annotation tool)\n    :param sp_segs: the superpixel segmentation\n    :return: the score (lower is better)\n    \"\"\"\n    out_score = 0\n    for idx in np.unique(sp_segs):\n        cur_region_mask = sp_segs == idx\n        labels_in_region = gt_labels[cur_region_mask]\n        if np.sum(labels_in_region) > 0:\n            out_score += np.sum(pd.value_counts(labels_in_region)[1:].values)\n    return out_score"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d4a39a44-8d01-e835-8843-f6de60f97e03"},"outputs":[],"source":"# Make new superpixels\ndef make_superpixel(pet_weight = 1.0, # how strongly to weight the pet_signal (1.0 is the same as CT)\n                    n_segments = 1000, # number of segments\n                    compactness = 1): # how compact the segments are\n    \n    t_petct_vol = np.stack([np.stack([(ct_slice+1024).clip(0,2048)/2048, \n                            pet_weight*(suv_slice).clip(0,5)/5.0\n                           ],-1) for ct_slice, suv_slice in zip(ct_image, pet_image)],0)\n    petct_segs = slic(t_petct_vol, \n                      n_segments=n_segments, \n                      compactness=compactness,\n                      multichannel=True)\n    return petct_segs\n\ndef make_and_score(*args, **kwargs):\n    n_segs = make_superpixel(*args, **kwargs)\n    return label_score(label_image, n_segs)\n\ndef f_make(n):\n    print('calling f_make with:', n)\n    return make_and_score(n_segments=int(n*1000))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"33a2fe44-f9ee-4381-852b-db33e8235a65"},"outputs":[],"source":"# test different values for n_segments to see how the performance changes\nn_segments = range(500, 2000, 100)\nn_score = [make_and_score(n_segments = c_seg) for c_seg in n_segments]\nplt.plot(n_segments, n_score, 'r*')\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6b6ad94e-25f7-03ac-e6be-194196fe20ac"},"outputs":[],"source":"# Optimize the values\nfrom scipy.optimize import fmin\n\nfmin(f_make, x0=[1], full_output=True, disp=True)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}