{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy             as np \nimport pandas            as pd \nimport matplotlib.pyplot as plt\nimport seaborn           as sns\nimport statsmodels.api   as sm\n%matplotlib inline\n\nfrom   sklearn.model_selection   import train_test_split\nfrom   sklearn.linear_model      import LinearRegression\nfrom   sklearn.preprocessing     import MinMaxScaler\nfrom   sklearn.metrics           import confusion_matrix\nfrom   sklearn.metrics           import r2_score,accuracy_score\nfrom   sklearn.feature_selection import RFE\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. **Importing Data & Analyzing the Data ****","metadata":{}},{"cell_type":"code","source":"heart_attack = pd.read_csv(r'../input/heart-attack-analysis-prediction-dataset/heart.csv')\nheart_attack.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Analyzing the dataset \nheart_attack.info()\n#There are no null values in the dataset & all the datatypes are correctly assigned","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Description of columns in the DATASET**\n* Age : Age of the patient\n* Sex : Sex of the patient\n* exang: exercise induced angina (1 = yes; 0 = no)\n* ca: number of major vessels (0-3)\n* cp : Chest Pain type chest pain type\n*     Value 1: typical angina\n*     Value 2: atypical angina\n*     Value 3: non-anginal pain\n*     Value 4: asymptomatic\n* trtbps : resting blood pressure (in mm Hg)\n* chol : cholestoral in mg/dl fetched via BMI sensor\n* fbs : (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n* rest_ecg : resting electrocardiographic results\n*     Value 0: normal\n*     Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n*     Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n* thalach : maximum heart rate achieved\n* target : 0= less chance of heart attack 1= more chance of heart attack","metadata":{}},{"cell_type":"markdown","source":"****2. Data cleaning ****","metadata":{}},{"cell_type":"code","source":"#Checking for outliers if any \nfig, axes = plt.subplots(1, 4, figsize=(14,5))\naxes[0].boxplot(heart_attack['age']);\naxes[1].boxplot(heart_attack['trtbps']);\naxes[2].boxplot(heart_attack['chol']);\naxes[3].boxplot(heart_attack['fbs']);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Function to analyse the columns with outliers \ndef outliers(df,x):\n    return df[x].quantile([0.25,0.50,0.75,0.90,0.95,0.96,0.97,0.98,0.99,1.00])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Analysing the suspected columns\nprint(outliers(heart_attack,'trtbps'))\nprint(outliers(heart_attack,'chol'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dropping the outliers from chol column\nprint(heart_attack[heart_attack['chol']>400].count())\nheart_attack.drop(heart_attack[(heart_attack['chol']>400)].index,axis=0,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dropping the outliers from \nprint(heart_attack[heart_attack['trtbps']>175].count())\nheart_attack.drop(heart_attack[(heart_attack['trtbps']>175)].index,axis=0,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" #Analysing the suspected columns\nprint(outliers(heart_attack,'fbs'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dropping the outliers from fbs column\nprint(heart_attack[heart_attack['fbs']==1].count())\nheart_attack.drop(heart_attack[(heart_attack['fbs']==1)].index,axis=0,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking for outliers if any \nfig, axes = plt.subplots(1, 4, figsize=(14,5))\naxes[0].boxplot(heart_attack['age']);\naxes[1].boxplot(heart_attack['trtbps']);\naxes[2].boxplot(heart_attack['chol']);\naxes[3].boxplot(heart_attack['fbs']);\n\n#We can observe from the figure that all the outliers have been treated","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking for outliers if any \nfig, axes = plt.subplots(1, 4, figsize=(14,5))\naxes[1].boxplot(heart_attack['thalachh']);\naxes[2].boxplot(heart_attack['oldpeak']);\naxes[3].boxplot(heart_attack['slp']);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dropping the outliers from oldpeak column\nprint(heart_attack[heart_attack['oldpeak']>6].count())\nheart_attack.drop(heart_attack[(heart_attack['oldpeak']>6)].index,axis=0,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(heart_attack['oldpeak']);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We can observe that all the outliers have been eliminated & all our data is clean & ready to use**","metadata":{}},{"cell_type":"markdown","source":"3. Exploratory Data analysis","metadata":{}},{"cell_type":"code","source":"#Analysing the correlation between the features \nplt.figure(figsize=(20,10))\nsns.heatmap(heart_attack.corr(),annot=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#The most correlated values to the Target values are \n1. slp\n2. thalachh\n3. restecg\n4. sex\n5. cp\n6. exng","metadata":{}},{"cell_type":"code","source":"#Checking if the data is balanced or imbalanced \nprint(heart_attack.shape)\nprint(heart_attack['output'].value_counts(normalize=True)*100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**4. Model Building **","metadata":{}},{"cell_type":"code","source":"#Splitting the data into train test split \nY = heart_attack['output']\nX = heart_attack.drop('output',axis=1).copy()\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#converting Y into dataframe \ny_train = y_train.values.reshape(-1,1)\ny_test = y_test.values.reshape(-1,1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Preprocessing the data \nscaler = MinMaxScaler()\nscaling_list = ['age','trtbps','chol','thalachh','oldpeak']\nX_train[scaling_list] = scaler.fit_transform(X_train[scaling_list])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test[scaling_list] = scaler.transform(X_test[scaling_list])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Training a model using top-down approach \nlr_model1 = sm.GLM(y_train,sm.add_constant(X_train),families=sm.families.Binomial())\nlr_model  = lr_model1.fit()\nprint(lr_model.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Running RFE with the output number of the variable equal to 10\nlm = LinearRegression()\nlm.fit(X_train, y_train)\nrfe = RFE(lm, 8)             # running RFE\nrfe = rfe.fit(X_train, y_train)\nlist(zip(X_train.columns,rfe.support_,rfe.ranking_))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fetching the list of best 8 columns \ncol = X_train.columns[rfe.support_]\ncol","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Building a model using the above features \nX_train_rfe = X_train[col].copy()\nlr_model2   = sm.GLM(y_train,sm.add_constant(X_train_rfe),family=sm.families.Binomial())\nlr_model    = lr_model2.fit()\nprint(lr_model.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Function to predict using latest model & printing the confusion matrix \ndef testing(model_name,test_set,thres_value,test_op):\n    y_pred_test = model_name.predict(test_set).values.reshape(-1,1)\n    y_train_pred_final = pd.DataFrame({'output':test_op, 'op_Prob':y_pred_test})\n    y_train_pred_final['index'] = test_set.index\n    return y_train_pred_final.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creating new_testing df\nX_train_rfe = sm.add_constant(X_train_rfe)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Function to create a table with pred values for logistic regression \ndef prediction(model_name,x_test,y_test):\n    y_pred                        = model_name.predict(x_test)\n    y_pred_final                  = pd.DataFrame({'op_train_Prob':y_pred})\n    y_pred_final['train_op']      = y_test\n    y_pred_final['op_train_pred'] = y_pred_final['op_train_Prob'].apply(lambda x:1 if x>0.5 else 0)\n    return y_pred_final","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction(lr_model,X_train_rfe,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#function to test the logistic Regression model \ndef validating_lr(y_real,y_pred):\n    from sklearn.metrics import confusion_matrix, accuracy_score\n    print('Confusion Matrix')\n    confusion = confusion_matrix(y_pred,y_real)\n    print(confusion)\n    print('Accuracy Score')\n    print(accuracy_score(y_pred,y_real)*100)\n    TP = confusion[1,1] # true positive \n    TN = confusion[0,0] # true negatives\n    FP = confusion[0,1] # false positives\n    FN = confusion[1,0] # false negatives\n    print('Sensitivity')\n    print((TP / float(TP+FN))*100)\n    print('specificity')\n    print((TN / float(TN+FP))*100)\n    print('false postive rate - predicting 1 when its 0')\n    print((FP/ float(TN+FP))*100)\n    print('Positive predictive value')\n    print((TP / float(TP+FP))*100)\n    print('Negative predictive value')\n    print((TN / float(TN+ FN))*100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validating_lr(y_pred_final['train_op'],y_pred_final['op_train_pred'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's create columns with different probability cutoffs \nnumbers = [float(x)/10 for x in range(10)]\nfor i in numbers:\n    y_pred_final[i]= y_pred_final['op_train_pred'].map(lambda x: 1 if x > i else 0)\npd.set_option('display.max_rows',None)\ny_pred_final","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\ncutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\nfrom sklearn.metrics import confusion_matrix\n\n# TP = confusion[1,1] # true positive \n# TN = confusion[0,0] # true negatives\n# FP = confusion[0,1] # false positives\n# FN = confusion[1,0] # false negatives\n\nnum = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\nfor i in num:\n    cm1 = confusion_matrix(y_pred_final[i],y_pred_final['train_op'])\n    total1=sum(sum(cm1))\n    accuracy = (cm1[0,0]+cm1[1,1])/total1\n    \n    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\nprint(cutoff_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#As we can see there is no variation in the accuracy even if we change the threshold \n#that means our model is stable & gives 85% accuracy on train data now lets check with test data ","metadata":{}},{"cell_type":"code","source":"X_test_rfe = X_test[col]\nX_test_rfe = sm.add_constant(X_test_rfe)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction(lr_model,X_test_rfe,y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking the accuracy of the model\nvalidating_lr(y_pred_final['train_op'],y_pred_final['op_train_pred'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\ncutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\nfrom sklearn.metrics import confusion_matrix\n\n# TP = confusion[1,1] # true positive \n# TN = confusion[0,0] # true negatives\n# FP = confusion[0,1] # false positives\n# FN = confusion[1,0] # false negatives\n\nnum = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\nfor i in num:\n    cm1 = confusion_matrix(y_pred_final[i],y_pred_final['train_op'])\n    total1=sum(sum(cm1))\n    accuracy = (cm1[0,0]+cm1[1,1])/total1\n    \n    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\nprint(cutoff_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#This is my final model as it is giving ","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}