{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\n\nimport sklearn.metrics as m\nimport sklearn.tree as tree\nimport sklearn.ensemble as ensemble\nimport sklearn.model_selection as ms\nimport sklearn.svm as svm\nimport sklearn.neural_network as nn\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/heart-failure-clinical-data/heart_failure_clinical_records_dataset.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Basic EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape[0] - data.count() # no blank values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data['DEATH_EVENT'].value_counts(normalize=True)) # About 32% of the data is positive class\nprint()\nprint(data['DEATH_EVENT'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_corr = data.corr()['DEATH_EVENT'] * 100\ndata_corr.sort_values()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Splitting Data\n* Data is splited such that BOTH the training and testing dataset contain the exact same proportion of death events"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.copy()\nX.drop('DEATH_EVENT', axis=1, inplace=True)\ny = data['DEATH_EVENT'].copy()\n\nX_train, X_test, y_train, y_test = ms.train_test_split(X, y, train_size=200, shuffle=True, stratify=y, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_train.value_counts(normalize=True))\nprint(y_test.value_counts(normalize=True))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Candidates Models & Ensemble (BASELINE)\n\n* My approach will be to train individual classifier models as well as an ensemble model (voting classifier)\n* I will assess the individual classifier models based on the default hyperparameter values\n* The voting classifier will be based on all the individual classifier models with their default hyperparameter values\n* ALL features will be used for this baseline models"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_clf = ensemble.RandomForestClassifier(random_state=42)\ndt_clf = tree.DecisionTreeClassifier(random_state=42)\next_clf = ensemble.ExtraTreesClassifier(random_state=42)\nmlp_clf = nn.MLPClassifier(random_state=42)\n\nvoting_classifier = ensemble.VotingClassifier([\n                                            ('rf_clf', ensemble.RandomForestClassifier(random_state=42)),\n                                            ('dt_clf', tree.DecisionTreeClassifier(random_state=42)),\n                                            ('ext_clf', ensemble.ExtraTreesClassifier(random_state=42)),\n                                            ('mlp_clf', nn.MLPClassifier(random_state=42))\n                                            ], voting='hard')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_clf.fit(X_train, y_train)\ndt_clf.fit(X_train, y_train)\next_clf.fit(X_train, y_train)\nmlp_clf.fit(X_train, y_train)\nvoting_classifier.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"estimators = [rf_clf, dt_clf, ext_clf, mlp_clf, voting_classifier]\n\ncv = ms.RepeatedKFold(n_splits=4, n_repeats=10, random_state=42)\n\nfor estimator in estimators:\n    cv_accuracy = ms.cross_val_score(estimator, X_train, y_train, cv=cv, n_jobs=-1, scoring='accuracy')\n    f1_score = ms.cross_val_score(estimator, X_train, y_train, cv=cv, n_jobs=-1, scoring='f1')\n    print(estimator.__class__.__name__)\n    print(f'Avg Accuracy: {np.mean(cv_accuracy) * 100}')\n    print(f'Std Accuracy: {np.std(cv_accuracy) * 100}')\n    print(f'Avg F1: {np.mean(f1_score) * 100}')\n    print(f'Std F1: {np.std(f1_score) * 100}')\n    print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MLPClassifier (with no tuning) perform the worse\n# Drop MLPClassifier from the ensemble model and retrain it\n\nnew_voting_classifier = ensemble.VotingClassifier([\n                                            ('rf_clf', ensemble.RandomForestClassifier(random_state=42)),\n                                            ('dt_clf', tree.DecisionTreeClassifier(random_state=42)),\n                                            ('ext_clf', ensemble.ExtraTreesClassifier(random_state=42)),\n                                            ], voting='hard')\n\n\nnew_voting_classifier.fit(X_train, y_train)\nnvc_accuracy_score = ms.cross_val_score(new_voting_classifier, X_train, y_train, cv=cv, n_jobs=-1, scoring='accuracy')\nnvc_f1_score = ms.cross_val_score(new_voting_classifier, X_train, y_train, cv=cv, n_jobs=-1, scoring='f1')\n\n\nprint(np.mean(nvc_accuracy_score) * 100)\nprint(np.std(nvc_accuracy_score) * 100)\nprint(np.mean(nvc_f1_score) * 100)\nprint(np.std(nvc_f1_score) * 100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Commentary\n\n* As it stands with no hyperparameter tuning, RandomForestClassifier perform the best\n    * F1 Score stands at 73.6% with Accuracy at 84.5%\n  \n \n* The new voting classifier perform 'much better' with lower bias and variance when it drop MLPClassifier from its ensemble\n    * Accuracy improves from 78.6% to 83.2%\n    * F1 Score improves from 56.2% to 71.0%\n    * Notably, new voting classifier has a slightly lower standard deviation as compare to the best model: RandomForestClassifier\n\n\n|                  \t| RandomForestClassifier (%) \t| New Voting Classifier (%) \t| Old Voting Classifier (%) \t|\n|------------------\t|----------------------------\t|---------------------------\t|---------------------------\t|\n| Average Accuracy \t| 84.5                       \t| 83.2                      \t| 78.6                      \t|\n| Std Accuracy     \t| 3.8                        \t| 3.7                       \t| 5.5                       \t|\n| Average F1       \t| 73.6                       \t| 71.0                      \t| 56.2                      \t|\n| Std F1           \t| 6.2                        \t| 6.0                       \t| 11.4                      \t|\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's change the voting method to soft to see if there is any gain in performance\n\nnew_soft_voting_classifier = ensemble.VotingClassifier([\n                                            ('rf_clf', ensemble.RandomForestClassifier(random_state=42)),\n                                            ('dt_clf', tree.DecisionTreeClassifier(random_state=42)),\n                                            ('ext_clf', ensemble.ExtraTreesClassifier(random_state=42)),\n                                            ], voting='soft')\n\nnew_soft_voting_classifier.fit(X_train, y_train)\nnsvc_accuracy_score = ms.cross_val_score(new_soft_voting_classifier, X_train, y_train, cv=cv, n_jobs=-1, scoring='accuracy')\nnsvc_f1_score = ms.cross_val_score(new_soft_voting_classifier, X_train, y_train, cv=cv, n_jobs=-1, scoring='f1')\n\nprint(np.mean(nsvc_accuracy_score) * 100)\nprint(np.std(nsvc_accuracy_score) * 100)\nprint(np.mean(nsvc_f1_score) * 100)\nprint(np.std(nsvc_f1_score) * 100)\n\n# Seems that hard voting is the way to go","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Performance on Testing Data (BASELINE MODELS)"},{"metadata":{"trusted":true},"cell_type":"code","source":"estimators = [rf_clf, dt_clf, ext_clf, mlp_clf, new_voting_classifier]\n\nfor estimator in estimators:\n    print(estimator.__class__.__name__)\n    print(estimator.score(X_test, y_test) * 100)\n    print()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Candidates Models & Ensemble (Feature Selection)\n\n* Let's select features that have at least 20% correlation with the target"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_corr = data.corr()['DEATH_EVENT'] * 100\ndata_corr.sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data[['time', 'ejection_fraction', 'age', 'serum_creatinine']].copy()\ny = data['DEATH_EVENT'].copy()\n\nX_train, X_test, y_train, y_test = ms.train_test_split(X, y, train_size=200, shuffle=True, stratify=y, random_state=42)\n\n\nrf_clf = ensemble.RandomForestClassifier(random_state=42)\ndt_clf = tree.DecisionTreeClassifier(random_state=42)\next_clf = ensemble.ExtraTreesClassifier(random_state=42)\n\nvoting_classifier = ensemble.VotingClassifier([\n                                            ('rf_clf', ensemble.RandomForestClassifier(random_state=42)),\n                                            ('dt_clf', tree.DecisionTreeClassifier(random_state=42)),\n                                            ('ext_clf', ensemble.ExtraTreesClassifier(random_state=42)),\n                                            ], voting='hard')\n\n\nrf_clf.fit(X_train, y_train)\ndt_clf.fit(X_train, y_train)\next_clf.fit(X_train, y_train)\nvoting_classifier.fit(X_train, y_train)\n\n\nestimators = [rf_clf, dt_clf, ext_clf, voting_classifier]\n\ncv = ms.RepeatedKFold(n_splits=4, n_repeats=10, random_state=42)\n\nfor estimator in estimators:\n    cv_accuracy = ms.cross_val_score(estimator, X_train, y_train, cv=cv, n_jobs=-1, scoring='accuracy')\n    f1_score = ms.cross_val_score(estimator, X_train, y_train, cv=cv, n_jobs=-1, scoring='f1')\n    print(estimator.__class__.__name__)\n    print(f'Avg Accuracy: {np.mean(cv_accuracy) * 100}')\n    print(f'Std Accuracy: {np.std(cv_accuracy) * 100}')\n    print(f'Avg F1: {np.mean(f1_score) * 100}')\n    print(f'Std F1: {np.std(f1_score) * 100}')\n    print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for estimator in estimators:\n    print(estimator.__class__.__name__)\n    print(estimator.score(X_test, y_test) * 100)\n    print()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion\n\n* Interestingly, the ExtraTreesClassifier perform the best on the training data (with feature selection) with the highest F1 score of 76.4% though the standard deviation on its F1 score is also the highest\n* On the testing data, the Voting Classifier and Random Forest model perform the same\n* All the models perform slightly better with feature selection\n* The reduced feature dataset also result in a slight increaser in the scores' standard deviation"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}