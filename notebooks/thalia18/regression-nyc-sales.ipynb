{"cells":[{"metadata":{"_uuid":"22609d32958715a21e430975eb5a4eeb3e3163c4"},"cell_type":"markdown","source":"This data is about properties sold in New York City over a 12-month period from September 2016 to September 2017.\n\n*1.  No (# in the data)\n2. BOROUGH (Code for the borough the property is located in; in order these are Manhattan (1), Bronx (2), Brooklyn (3), Queens (4), and State Island (5)), \n3. NEIGHBORHOOD \n4. BUILDING CLASS CATEGORY,\n5. TAX CLASS AT PRESENT (1,2,3,4,5)\n6. BLOCK,\n7. LOT,\n8. EASE-MENT\n9. BUILDING CLASS AT PRESENT\n10. ADDRESS (“A” signifies one-family homes, “O” signifies office buildings. “R” signifies condominiums)\n11. APARTMENT NUMBER\n12. ZIP CODE\n13. RESIDENTIAL UNITS\n14. COMMERCIAL UNITS,\n15. TOTAL UNITS\n16. LAND SQUARE FEET\n17. GROSS SQUARE FEET\n18. YEAR BUILT,\n19. TAX CLASS AT TIME OF SALE\n20. BUILDING CLASS AT TIME OF SALE\n21. SALE PRICE,\n22. SALE DATE*\n\nI cleaned the data: remove duplicate data, clean null data, converted the categorical data in numerical data that I can use in the regression, and normalize the use of strings."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\nsales_file_path = '../input/nyc-rolling-sales.csv'\nsales_data = pd.read_csv(sales_file_path)\nsales_data.columns =sales_data.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('-', '_')\nsales_data.building_class_category=sales_data.building_class_category.str.strip().str.lower().str.replace(' ', '').str.replace('-', '_')\nsales_data = sales_data.drop_duplicates(sales_data.columns, keep='last')\nsales_data.describe() \n#print(sales_data.columns)\n\nprice=[]\nland_square=[]\ngross_square=[]\ntaxclass1=[]\ntaxclass2=[]\ntaxclass4=[]\nManhattan=[] #(1), \nBronx=[] #(2), \nBrooklyn=[] #(3), \nQueens=[] #(4), \nState_Island=[]#5\nbuildingclass1=[]\nbuildingclass2=[]\nbuildingclass3=[]\nbuildingclass10=[]\nbuildingclass13=[]\n\n#######YPU CAN DO THIS WITH GET DUMMIES\n##########pd.get_dummies(data=data, columns=[''])\nfor i in range(len(sales_data.sale_price)):\n    price.append(0) if sales_data.sale_price[i]==' -  ' else price.append(float(sales_data.sale_price[i]))\n    land_square.append(0) if sales_data.land_square_feet[i]==' -  ' else land_square.append(float(sales_data.land_square_feet[i]))\n    gross_square.append(0) if sales_data.gross_square_feet[i]==' -  ' else gross_square.append(float(sales_data.gross_square_feet[i]))\n    taxclass1.append(1) if sales_data.tax_class_at_time_of_sale[i]==1 else taxclass1.append(0)\n    taxclass2.append(1) if sales_data.tax_class_at_time_of_sale[i]==2 else taxclass2.append(0)\n    taxclass4.append(1) if sales_data.tax_class_at_time_of_sale[i]==4 else taxclass4.append(0)    \n    Manhattan.append(1) if sales_data.borough[i]==1 else Manhattan.append(0)    \n    Bronx.append(1) if sales_data.borough[i]==2 else Bronx.append(0)    \n    Brooklyn.append(1) if sales_data.borough[i]==3 else Brooklyn.append(0)    \n    Queens.append(1) if sales_data.borough[i]==4 else Queens.append(0)    \n    State_Island.append(1) if sales_data.borough[i]==5 else State_Island.append(0)    \n    buildingclass1.append(1) if sales_data.building_class_category[i]=='01onefamilydwellings' else buildingclass1.append(0)\n    buildingclass2.append(1) if sales_data.building_class_category[i]=='02twofamilydwellings' else buildingclass2.append(0)\n    buildingclass3.append(1) if sales_data.building_class_category[i]=='03threefamilydwellings' else buildingclass3.append(0)\n    buildingclass10.append(1) if sales_data.building_class_category[i]=='10coops_elevatorapartments' else buildingclass10.append(0)\n    buildingclass13.append(1) if sales_data.building_class_category[i]=='13condos_elevatorapartments' else buildingclass13.append(0)\n\n    \nsales_data['sale_date'] = pd.to_datetime(sales_data['sale_date'])\nsales_data.sale_date = [item.to_julian_date() for item in sales_data.sale_date] \n\nsales_data['price'] =price\nsales_data['land_square'] =land_square\nsales_data['gross_square'] =gross_square\nsales_data['taxclass1']=taxclass1\nsales_data['taxclass2']=taxclass2\nsales_data['taxclass4']=taxclass4\nsales_data['Manhattan']=Manhattan\nsales_data['Bronx']=Bronx\nsales_data['Brooklyn']=Brooklyn\nsales_data['Queens']=Queens\nsales_data['State_Island']=State_Island\nsales_data['buildingclass1']=buildingclass1\nsales_data['buildingclass2']=buildingclass2\nsales_data['buildingclass3']=buildingclass3\nsales_data['buildingclass10']=buildingclass10\nsales_data['buildingclass13']=buildingclass13\n\n\n#features=['borough','land_square', 'gross_square', 'year_built',\n      # 'tax_class_at_time_of_sale','sale_date','price']\nsales_data.describe()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5fcebf83daffd71ceb66aa990d63650eebc4c05a"},"cell_type":"markdown","source":"I studied the building class categories, its relation with gross square and price."},{"metadata":{"trusted":true,"_uuid":"055f8cd4caa8fb0fd6684821135f6c86816823e9"},"cell_type":"code","source":"#print(sales_data.building_class_category.unique())\nplt.title(r'Building class category %')\n(sales_data['building_class_category'].value_counts().head() / len(sales_data)).plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a50053700b232c2fae9d4c647629b74542c13441","scrolled":true},"cell_type":"code","source":"ax1=sales_data[sales_data.building_class_category=='01onefamilydwellings'].plot.scatter(x='gross_square', y='price',c='red',title='Relation price vs gross square per building class',label='01onefamilydwellings')\nsales_data[sales_data.building_class_category=='02twofamilydwellings'].plot.scatter(x='gross_square', y='price',c='black',label='02twofamilydwellings',ax=ax1)\nsales_data[sales_data.building_class_category=='03threefamilydwellings'].plot.scatter(x='gross_square', y='price',c='blue',label='03threefamilydwellings',ax=ax1)\nsales_data[sales_data.building_class_category=='10coops_elevatorapartments'].plot.scatter(x='gross_square', y='price',c='green',label='10coops_elevatorapartments',ax=ax1)\nsales_data[sales_data.building_class_category=='13condos_elevatorapartments'].plot.scatter(x='gross_square', y='price',c='cyan',label='13condos_elevatorapartments',ax=ax1)\nax1.set_xlabel(\"Gross Square\")\nax1.set_ylabel(\"Price\")\nax1.set_ylim([.5,10**9])\nax1.set_xlim([-50,10**4.1])\nax1.set_yscale(\"log\", nonposy='clip')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5bedeace3201650c02188bf0326cf316ed60f45f"},"cell_type":"markdown","source":"I studied the borough categories, its relation with gross square and price."},{"metadata":{"trusted":true,"_uuid":"254263c030d58d9b1bf41b271b89d9d9314f149c"},"cell_type":"code","source":"plt.title(r'Borough %')\n(sales_data['borough'].value_counts().head() / len(sales_data)).plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d76a88f4ca8b02015e00fd38a7b1a37c211024ac"},"cell_type":"code","source":"#Manhattan #Bronx #Brooklyn\n#Queens #State_Island=[]#5  \n\nax1=sales_data[sales_data.Manhattan==1].plot.scatter(x='gross_square', y='price',c='red',title='Relation price vs gross square per borough',label='Manhattan')\nsales_data[sales_data.Bronx==1].plot.scatter(x='gross_square', y='price',c='black',label='Bronx',ax=ax1)\nsales_data[sales_data.Brooklyn==1].plot.scatter(x='gross_square', y='price',c='blue',label='Brooklyn',ax=ax1)\nsales_data[sales_data.Queens==1].plot.scatter(x='gross_square', y='price',c='green',label='State Island',ax=ax1)\nsales_data[sales_data.State_Island==1].plot.scatter(x='gross_square', y='price',c='cyan',label='Queens',ax=ax1)\nax1.set_xlabel(\"Gross Square\")\nax1.set_ylabel(\"Price\")\nax1.set_ylim([.5,10**9])\nax1.set_xlim([-50,10**4.1])\nax1.set_yscale(\"log\", nonposy='clip')\n#ax1.set_xscale(\"log\", nonposx='clip')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"523308d887da4980cf28d3133b8ab25c7d858d0a"},"cell_type":"markdown","source":"I studied the tax class time categories at time of sale categories, its relation with gross square and price.\nI am not interested in the tax class at present time, that could cause at leakage of my regression."},{"metadata":{"trusted":true,"_uuid":"6143453ca09e9db38e54b610944373c7374bc980"},"cell_type":"code","source":"plt.title(r'Tax Class at time of sale %')\n(sales_data['tax_class_at_time_of_sale'].value_counts().head() / len(sales_data)).plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ee6433dc8b8b42f6db4a32869f804ff47e66d85"},"cell_type":"code","source":"ax1=sales_data[sales_data.taxclass1==1].plot.scatter(x='gross_square', y='price',c='red',title='Relation price vs gross square per tax class',label='Tax class1')\nsales_data[sales_data.taxclass2==1].plot.scatter(x='gross_square', y='price',c='black',label='Tax class 2',ax=ax1)\nsales_data[sales_data.taxclass4==1].plot.scatter(x='gross_square', y='price',c='blue',label='Tax Class 4',ax=ax1)\nax1.set_xlabel(\"Gross Square\")\nax1.set_ylabel(\"Price\")\nax1.set_ylim([.5,10**9])\nax1.set_xlim([-50,10**4.1])\nax1.set_yscale(\"log\", nonposy='clip')\n#ax1.set_xscale(\"log\", nonposx='clip')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"11b3d053d9253394a869445269a348e1438211b8"},"cell_type":"markdown","source":"I studied the sale prices. A lot of houses where sold by unreal prices ($0-$10) , this means that the houses where not sold, they were transfer between owners.\nI used houses with prices over $100,000, because is a relistic price that wont mess my models."},{"metadata":{"trusted":true,"_uuid":"80b2cded95dafa1ad6cf0e663019c4431332c173"},"cell_type":"code","source":"plt.title(r'Price ')\nplt.xscale('log')\nplt.ylim((0,1050))\nsales_data['price'].value_counts().sort_index().plot.line()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"96913d21cacb5eb395844eebe5f440697c1b59d0"},"cell_type":"code","source":"plt.title(r'Price: houses under $10000 ')\nsales_data[sales_data['price'] < 10000]['price'].plot.hist()\nplt.text(1500,20000,'mostly between \\$0-\\$100'\n         'not really a sale and it will mess'\n         'with my predictions',wrap=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fede2f69127e0c1dd2a80d7b0ab7839f9e7ee020"},"cell_type":"code","source":"plt.title(r'Price ')\nplt.xscale('log')\nplt.ylim((0,550))\nsales_data[sales_data['price']>10000]['price'].value_counts().sort_index().plot.line()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7cfaf1506d91eb66525c24cfba0147ef50cabcd8"},"cell_type":"code","source":"plt.title(r' Year Built ')\nplt.xlim((-10,2020.10))\n#plt.ylim((0,1000.10))\nplt.text(250,400,'uppss First human settlement 1609')\nsales_data['year_built'].value_counts().sort_index().plot.line()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"99b415a0c07024cedca8508f9a7d0b3c58ed579b"},"cell_type":"code","source":"plt.title(r' Year Built ')\nplt.xlim((1880,2020.10))\n#plt.ylim((0,10.10))\nsales_data[sales_data['year_built']>1880]['year_built'].value_counts().sort_index().plot.line()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"abdf60c8464c5c7174aeda7b9e4619397ad134ab"},"cell_type":"code","source":"ax1=sales_data[sales_data.Manhattan==1].plot.scatter(x='year_built', y='price',c='red',title='Relation price vs year built per borough',label='Manhattan')\nsales_data[sales_data.Bronx==1].plot.scatter(x='year_built', y='price',c='black',label='Bronx',ax=ax1)\nsales_data[sales_data.Brooklyn==1].plot.scatter(x='year_built', y='price',c='blue',label='Brooklyn',ax=ax1)\nsales_data[sales_data.Queens==1].plot.scatter(x='year_built', y='price',c='green',label='State Island',ax=ax1)\nsales_data[sales_data.State_Island==1].plot.scatter(x='year_built', y='price',c='cyan',label='Queens',ax=ax1)\nax1.set_xlabel(\"Year_built\")\nax1.set_ylabel(\"Price\")\nax1.set_ylim([.05,10**9.5])\nax1.set_xlim([1880,2050])\nax1.set_yscale(\"log\", nonposy='clip')\n#ax1.set_xscale(\"log\", nonposx='clip')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"457177e3db703870d08cd2fe7bcd308b60ca7491"},"cell_type":"markdown","source":"I changed the sale date to julian time and explored the data, I didnt see any pater in the sale date."},{"metadata":{"trusted":true,"_uuid":"d2fd56b6605517c98adf51abb3f7fc8860c107ed"},"cell_type":"code","source":"plt.title(r' Sale_date ')\n#plt.xlim((-10,2020.10))\n#plt.ylim((0,1000.10))\n#plt.text(250,400,'uppss First human settlement 1609')\nsales_data['sale_date'].value_counts().sort_index().plot.line()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"09205847a20148091f38feecf3b5bdf9c80ae1e7"},"cell_type":"markdown","source":"So finally, the features that I decided to use in my models:\n'land_square'\n'gross_square',\n'year_built',\n 'taxclass1',\n 'taxclass2',\n 'taxclass4',\n  'Manhattan','Queens','Brooklyn','Bronx','State_Island',\n  'buildingclass1','buildingclass2','buildingclass3','buildingclass10',\n 'residential_units', 'commercial_units', 'total_units',\n "},{"metadata":{"trusted":true,"_uuid":"690da78174c591df62f99afadfb207a85441378e"},"cell_type":"code","source":"features=['land_square', 'gross_square', 'year_built',\n          'taxclass1','taxclass2','taxclass4',\n          'Manhattan','Queens','Brooklyn','Bronx','State_Island',\n         'buildingclass1','buildingclass2','buildingclass3','buildingclass10',\n          'residential_units', 'commercial_units', 'total_units',\n       'price']\nX=sales_data[features]\nX=X[X.gross_square != 0]\nX=X[X.land_square != 0]\nX=X[X.price >100000]\nX=X[X.year_built >1880]\nX.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f63ab2683a291ea1822367613db3300fc28c0885"},"cell_type":"markdown","source":"I transformed some data that was skewed to the right.\n\nI studied the correlations between the features and price:\n* gross_square         0.673120\n* Manhattan            0.457679\n* taxclass2            0.371986\n* taxclass4            0.325582\n* land_square          0.274129\n\n \n I will use four different methods for the regression:\n linear, lasso, ridge and random forest regression."},{"metadata":{"trusted":true,"_uuid":"470d5fcbd3b47e7db2ba7ac59f6e68937e6d158d"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nX['price']=np.log1p(X['price'])\nX['land_square']=np.log1p(X['land_square'])\nX['gross_square']=np.log1p(X['gross_square'])\nX['year_built']=np.log1p(X['year_built'])\n\ncolormap = plt.cm.magma\nplt.figure(figsize=(19,19))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\ncorr = X.corr()\nsns.heatmap(corr,linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)\ncorr['price'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import explained_variance_score\nfrom sklearn.metrics import mean_squared_error\n\n#X= np.log1p(X)\ny = X['price']\nX2 = X.drop(['price'], axis=1).values \ntrain_X, val_X, train_y, val_y = train_test_split(X2, y, random_state = 0)\n\nmodel = LinearRegression()\nmodel.fit(train_X, train_y)\ny_pred = model.predict(val_X) \n\nprint('r2',model.score(val_X, val_y))####r2 score\nprint('rmse',(mean_squared_error(val_y, y_pred))**0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"26740149037ba80d89056a49c08348db7e772ec4"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import explained_variance_score\nfrom sklearn.metrics import mean_squared_error\n\ny = X['price']\nX2 = X.drop(['price'], axis=1).values \ntrain_X, val_X, train_y, val_y = train_test_split(X2, y, random_state = 0)\n\nalpha_ridge = [0.000001,0.0001,.001,1]\nfor item in alpha_ridge:\n    modelt = Ridge(alpha=item,copy_X=True, fit_intercept=True, max_iter=None,\n          normalize=False, random_state=None, solver='auto', tol=0.001)\n    modelt.fit(train_X, train_y)\n    y_predt = modelt.predict(val_X) \n\n   # print(item,'r2',modelt.score(val_X, val_y))####r2 score\n    #print('rmse',(mean_squared_error(val_y, y_predt))**0.5)\n   # print('explained variance',explained_variance_score(val_y,y_predt))\n    \nmodel2 = Ridge(alpha=0.000001,copy_X=True, fit_intercept=True, max_iter=None,\n          normalize=False, random_state=None, solver='auto', tol=0.001)\nmodel2.fit(train_X, train_y)\ny_pred2 = model2.predict(val_X) \n\nprint('r2',model2.score(val_X, val_y))####r2 score\nprint('rmse',(mean_squared_error(val_y, y_pred2))**0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d234f1b716a56e188c53937fe8847f56936080db"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn import linear_model\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import explained_variance_score\nfrom sklearn.metrics import mean_squared_error\n\ny = X['price']\nX2 = X.drop(['price'], axis=1).values \ntrain_X, val_X, train_y, val_y = train_test_split(X2, y, random_state = 0)\n\nalpha_ridge = [0.000001,0.0001,.001,1]\nfor item in alpha_ridge:\n    modelt = linear_model.Lasso(alpha=item, copy_X=True, fit_intercept=True, max_iter=1000,\n   normalize=False, positive=False, precompute=False, random_state=None,\n   selection='cyclic', tol=0.0001, warm_start=False)\n    modelt.fit(train_X, train_y)\n    y_predt = modelt.predict(val_X) \n\n   # print(item,'r2',modelt.score(val_X, val_y))####r2 score\n   # print('rmse',(mean_squared_error(val_y, y_predt))**0.5)\n  #  print('explained variance',explained_variance_score(val_y,y_predt))\n    \nmodel3 = linear_model.Lasso(alpha=0.000005, copy_X=True, fit_intercept=True, max_iter=1000,\n   normalize=False, positive=False, precompute=False, random_state=None,\n   selection='cyclic', tol=0.0001, warm_start=False)\n                            \nmodel3.fit(train_X, train_y)\ny_pred3 = model3.predict(val_X) \n\nprint('r2',model3.score(val_X, val_y))####r2 score\nprint('rmse',(mean_squared_error(val_y, y_pred3))**0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"743c301cb262920e6022afb3fe1f214f640b0973"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import explained_variance_score\nfrom sklearn.metrics import mean_squared_error\n\ny = X['price']\nX2 = X.drop(['price'], axis=1).values \ntrain_X, val_X, train_y, val_y = train_test_split(X2, y, random_state = 0)\n\n\nmodel4 = RandomForestRegressor()\nmodel4.fit(train_X, train_y)\ny_pred4 = model4.predict(val_X) \n\nprint('r2',model4.score(val_X, val_y))####r2 score\nprint('rmse',(mean_squared_error(val_y, y_pred4))**0.5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c92a70480b7c10802404210e960307e88bb92228"},"cell_type":"markdown","source":"Results for the different regression:\n* linear:\n r2 0.6111805534821673\n rmse 0.5340183237978753\n* Ridge:\n r2 0.6111805532023231\n rmse 0.5340183239900492\n* lasso\n r2 0.6113140862445937\n rmse 0.5339266166236538\n* Random forest regression:\n r2 0.625753188947449\nrmse 0.5239154727330908\n\nThe best score is for the random forest."},{"metadata":{"trusted":true,"_uuid":"15121a603c96e717165f97de5e223fc546348c5a"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# plot a line, a perfit predict would all fall on this line\nind = np.linspace(10,21,1000)\nplt.xlabel('Test Data')\nplt.ylabel('Predicted DataPrice') \n#plt.xlim(-100,10000000)\n#plt.ylim(-100,10000000)\nplt.plot(ind, ind,'-')\nplt.plot(val_y, y_pred, '.',label='Linear Regression')\nplt.plot(val_y, y_pred2, 'o',label='Ridge Regression')\nplt.plot(val_y, y_pred3, '*',label='Lasso Regression')\nplt.plot(val_y, y_pred4, '.',label='Random Forest Regression')\nplt.legend(loc='lower right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca2ee2b6942e5e2faa44a1aa040c76e880ee949a"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport random\n#select random data to show\ni=random.randint(1,len(val_y)-101)\nind = np.linspace(0, 100,100)\n\nplt.xlabel('Data index')\nplt.ylabel('Price in thousands of $') \n\nplt.plot(ind, np.expm1(val_y[i:i+100])/1000,'-', linewidth=2.2,label='Test data' )\nplt.plot(ind, np.expm1(y_pred[i:i+100])/1000, '--',linewidth=1.4,label='Linear Regression')\nplt.plot(ind, np.expm1(y_pred2[i:i+100])/1000, '-.',linewidth=1.3,label='Ridge Regression')\nplt.plot(ind, np.expm1(y_pred3[i:i+100])/1000, '--',linewidth=1.2,label='Lasso Regression')\nplt.plot(ind, np.expm1(y_pred4[i:i+100])/1000, '-.',linewidth=1.2,label='Random Forest Regression')\nplt.legend(loc='upper right')\nplt.xlim(-2,112)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}