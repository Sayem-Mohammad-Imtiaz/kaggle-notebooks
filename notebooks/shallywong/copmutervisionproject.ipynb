{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install imutils\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers.experimental.preprocessing import CenterCrop\nfrom tensorflow.keras.layers.experimental.preprocessing import Rescaling\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom imutils import paths\nimport argparse\nimport imutils\nimport cv2\nimport os\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input/images/images'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n# ====== Begin ===============\n\n# Read images and create dataset as vectors of rgb values\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        os.path.join(dirname, filename)\n\n# Create a dataset\n\n#get list of artists and delete unimportant infos from artists.csv\nartists = pd.read_csv('/kaggle/input/best-artworks-of-all-time/artists.csv')\nartists.drop('id',inplace=True, axis=1)\nartists.drop('years',inplace=True, axis=1)\nartists.drop('bio',inplace=True, axis=1)\nartists.drop('wikipedia',inplace=True, axis=1)\nartists = artists.sort_values(by=['paintings'], ascending=False)\nartists.reset_index(inplace = True)\nmaxpaintings = artists['paintings'].sum()\nartists['weight'] = maxpaintings/artists.paintings\nprint(artists)\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Argument Parser\n#ap = argparse.ArgumentParser()\n#ap.add_argument(\"-d\", \"--dataset\", help=\"path to input dataset\",required=True, default=\"/kaggle/input/best-artworks-of-all-time/resized/resized/\")\n#ap.add_argument(\"-l\", \"--label\", help=\"artist or genre\", default=\"artist\")\n#ap.add_argument(\"-m\", \"--mode\", help=\"knn or cluster\",required=True)\n#ap.add_argument(\"-k\",\"--neighbors\", type=int, default=1, help=\"number of nearest neighbors for classification\")\n#ap.add_argument(\"-j\", \"--job\", type=int, default=-1, help=\"number of jobs for k-NN distance\")\n#args=vars(ap.parse_args())\n\n# presets\ndataset =\"/kaggle/input/best-artworks-of-all-time/resized/resized/\"\nneighbors = 5\njobs = -1\nlabelmode = \"genre\"\nlabelgenre = artists[\"genre\"]\n\nprint(\"[INFO] describing images...\")\n#imagePaths = list(paths.list_images(args[\"dataset\"]))\nimagePaths = list(paths.list_images(dataset))\nrawImages=[]\nfeatures = []\nlabels = []\n\n#========= Preprocessing and Feature Selection======================\n\n#========== Helperfunction ========================\n#Function getLabel. Modify file path to get artist name\ndef get_artistname(filepath):\n    whitespace=' '\n    artist=filepath[6].split(\".\")[0].split(\"_\")\n    del artist[len(artist)-1]\n    label=whitespace.join(artist)\n    return label\n\n\n#========= 1.1.1 Resize Image to (32,32) and flatten the image\ndef image_to_feature_vector(image, size=(32,32)):\n    return cv2.resize(image, size).flatten()\n\n#========= 1.1.2 extract 3d color histogram from HSV color space using bins per channel\ndef extract_color_histogram (image, bins=(8,8,8)):\n    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    hist = cv2.calcHist([hsv], [0,1,2], None, bins, [0,180,0,256,0,256])\n    if imutils.is_cv2():\n        hist = cv2.normalize(hist)\n    else:\n        cv2.normalize(hist, hist)\n    return hist.flatten()\n\n#loop over images\nfor (i, imagePath) in enumerate(imagePaths):\n    image = cv2.imread(imagePath)\n    label = imagePath.split(os.path.sep[-1].split(\".\")[0])\n    pixels = image_to_feature_vector(image)\n    hist = extract_color_histogram(image)\n    rawImages.append(pixels)\n    features.append(hist)\n    labels.append(get_artistname(label))\n    \n    if i>0 and i%1000 == 0:\n        print(\"[INFO] processed {}/{}\".format(i, len(imagePaths)))\n\nrawImages = np.array(rawImages)\nfeatures = np.array(features)\nlabels = np.array(labels)\n\nprint(\"[INFO] pixels matrix: {:.2f}MB\".format(rawImages.nbytes / (1024*1000.0)))\nprint(\"[INFO] pixels matrix: {:.2f}MB\".format(features.nbytes / (1024*1000.0)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#========== 1.1 KNN by artistname=================================\n\n# presets\ndataset =\"/kaggle/input/best-artworks-of-all-time/resized/resized/\"\nneighbors = 5\njobs = -1\n\n\n#partition training set (75%) und test (25%)\nif labelmode == 'genre': \n    (trainRI, testRI, trainRL, testRL) = train_test_split(rawImages, labelgenre, test_size=0.25, random_state=42)\n    (trainFeat, testFeat, trainLabels, testLabels) = train_test_split(features, labelsgenre, test_size=0.25, random_state=42)\nelse:\n    (trainRI, testRI, trainRL, testRL) = train_test_split(rawImages, labels, test_size=0.25, random_state=42)\n    (trainFeat, testFeat, trainLabels, testLabels) = train_test_split(features, labels, test_size=0.25, random_state=42)\n                            \n#train and evaluate a knn classifier on raw pixel intensities\nprint(\"[INFO] evaluating raw pixel accuracy...\")\nmodel = KNeighborsClassifier(n_neighbors=neighbors,n_jobs=jobs) # n_neighbors=args[\"neighbors\"],n_jobs=args[\"jobs\"]\nmodel.fit(trainRI, trainRL)\nacc= model.score(testRI, testRL)\nprint(\"[INFO] raw pixel accuracy: {:.2f}%\".format(acc*100))\n\n#train and evaluate a knn classifier on histogram\nprint(\"[INFO] evaluating histogram accuracy...\")\nmodel=KNeighborsClassifier(n_neighbors=neighbors,n_jobs=jobs) # n_neighbors=args[\"neighbors\"],n_jobs=args[\"jobs\"]\nmodel.fit(trainFeat,trainLabels)\nacc=model.score(testFeat, testLabels)\nprint(\"[INFO] histogram accuracy: {:.2f}%\".format(acc*100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#========== 1.2 KNN by genre=================================\n\n#========== Helperfunction ========================\n#Function getLabel. Modify file path to get artist name\ndef get_artistname(filepath):\n    whitespace=' '\n    artist=filepath[6].split(\".\")[0].split(\"_\")\n    del artist[len(artist)-1]\n    label=whitespace.join(artist)\n    return label\n\n#========= Preprocessing and Feature Selection======================\n\n#========= 1.2.1. Resize Image to (32,32) and flatten the image\ndef image_to_feature_vector(image, size=(32,32)):\n    return cv2.resize(image, size).flatten()\n\n#========= 1.2.2. extract 3d color histogram from HSV color space using bins per channel\ndef extract_color_histogram (image, bins=(8,8,8)):\n    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    hist = cv2.calcHist([hsv], [0,1,2], None, bins, [0,180,0,256,0,256])\n    if imutils.is_cv2():\n        hist = cv2.normalize(hist)\n    else:\n        cv2.normalize(hist, hist)\n    return hist.flatten()\n\n# presets\ndataset =\"/kaggle/input/best-artworks-of-all-time/resized/resized/\"\nneighbors = 5\njobs = -1\n\n\n\n#partition training set (75%) und test (25%)\n(trainRI, testRI, trainRL, testRL) = train_test_split(rawImages, labelsgenre, test_size=0.25, random_state=42)\n(trainFeat, testFeat, trainLabels, testLabels) = train_test_split(features, labelsgenre, test_size=0.25, random_state=42)\n                            \n#train and evaluate a knn classifier on raw pixel intensities\nprint(\"[INFO] evaluating raw pixel accuracy...\")\nmodel = KNeighborsClassifier(n_neighbors=neighbors,n_jobs=jobs) # n_neighbors=args[\"neighbors\"],n_jobs=args[\"jobs\"]\nmodel.fit(trainRI, trainRL)\nacc= model.score(testRI, testRL)\nprint(\"[INFO] raw pixel accuracy: {:.2f}%\".format(acc*100))\n\n#train and evaluate a knn classifier on histogram\nprint(\"[INFO] evaluating histogram accuracy...\")\nmodel=KNeighborsClassifier(n_neighbors=neighbors,n_jobs=jobs) # n_neighbors=args[\"neighbors\"],n_jobs=args[\"jobs\"]\nmodel.fit(trainFeat,trainLabels)\nacc=model.score(testFeat, testLabels)\nprint(\"[INFO] histogram accuracy: {:.2f}%\".format(acc*100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#============ 2. Clustering ==================\n\nfrom numpy import unique\nfrom numpy import where\nfrom sklearn.datasets import make_classification\nfrom sklearn.cluster import AgglomerativeClustering\nfrom matplotlib import pyplot\n\nnclusters=50\n\n#define dataset\nX = features\n_ = labels\n#X, _ = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=4)\n#define model\nmodel = AgglomerativeClustering(n_clusters=nclusters)\n#fit model and predict clusters\nyhat = model.fit_predict(X)\n#retrieve unique clusters\nclusters = unique(yhat)\n#create scatter plot from each cluster\nfor cluster in clusters:\n        # get row indexes\n        row_ix = where(yhat == cluster)\n        # create scatter \n        pyplot.scatter(X[row_ix,0],X[row_ix,1])\n#show plot\npyplot.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nclusters=50\n\n#define dataset\nX = rawImages\n_ = labels\n#X, _ = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=4)\n#define model\nmodel = AgglomerativeClustering(n_clusters=nclusters)\n#fit model and predict clusters\nyhat = model.fit_predict(X)\n#retrieve unique clusters\nclusters = unique(yhat)\n#create scatter plot from each cluster\nfor cluster in clusters:\n        # get row indexes\n        row_ix = where(yhat == cluster)\n        # create scatter \n        pyplot.scatter(X[row_ix,0],X[row_ix,1])\n#show plot\npyplot.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\n\n#get labels from filename\ndataset = keras.preprocessing.image_dataset_from_directory(\n  '/kaggle/input/best-artworks-of-all-time/images/images/', batch_size=64, image_size=(200, 200), label_mode='categorical', color_mode='rgb')\n\ndense = keras.layers.Dense(units=16)\n# Let's say we expect our inputs to be RGB images of size 200,200,3\ninputs = keras.Input(shape=(200, 200, 3))\n# Let's say we expect our inputs to be RGB images of arbitrary size\n#inputs = keras.Input(shape=(None, None, 3))\n\n# Example image data, with values in the [0, 255] range\ntraining_data = np.random.randint(0, 256, size=(64, 200, 200, 3)).astype(\"float32\")\n\ncropper = CenterCrop(height=150, width=150)\nscaler = Rescaling(scale=1.0 / 255)\n\noutput_data = scaler(cropper(training_data))\nprint(\"shape:\", output_data.shape)\nprint(\"min:\", np.min(output_data))\nprint(\"max:\", np.max(output_data))   \n\n# Center-crop images to 150x150\nx = CenterCrop(height=150, width=150)(inputs)\n# Rescale images to [0, 1]\nx = Rescaling(scale=1.0 / 255)(x)\n\n# Apply some convolution and pooling layers\nx = layers.Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\")(x)\nx = layers.MaxPooling2D(pool_size=(3, 3))(x)\nx = layers.Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\")(x)\nx = layers.MaxPooling2D(pool_size=(3, 3))(x)\nx = layers.Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\")(x)\n\n# Apply global average pooling to get flat feature vectors\nx = layers.GlobalAveragePooling2D()(x)\n\n# Add a dense classifier on top\nnum_classes = 51\noutputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n\nmodel2 = keras.Model(inputs=inputs, outputs=outputs)   \n\ndata = np.random.randint(0, 256, size=(64, 200, 200, 3)).astype(\"float32\")\nprocessed_data = model2(data)\nprint(processed_data.shape)\n\nmodel2.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n\nmodel2.fit(dataset, epochs=5)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!/usr/bin/env python\n# coding: utf-8\n\n\nfrom keras.models import load_model\nfrom keras.preprocessing import image\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\n\ndef load_image(img_path, show=False):\n\n    img = image.load_img(img_path, target_size=(200, 200))\n    img_tensor = image.img_to_array(img)                    # (height, width, channels)\n    img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n    img_tensor /= 255.                                      # imshow expects values in the range [0, 1]\n\n    if show:\n        plt.imshow(img_tensor[0])                           \n        plt.axis('off')\n        plt.show()\n\n    return img_tensor\n\n\nif __name__ == \"__main__\":\n\n    # load model\n    #model = load_model(\"model_aug.h5\")\n\n    # image path\n    # Reihenfolge der Label ist hierbei alphabetisch\n    img_path = \"/kaggle/input/best-artworks-of-all-time/resized/resized/Vincent_van_Gogh_10.jpg\"    #iconography  \n    #img_path = '0004.jpg'    #painting \n    #img_path = '4.jpg'    #sculpture \n    #img_path = '1.jpg'    #engraving \n    #img_path = 'download (21).jpeg' #drawing \n    \n\n    # load a single image\n    new_image = load_image(img_path)\n\n    # check prediction\n    pred = model2.predict(new_image)\n    \n    print(pred)\n    print(pred.argmax(axis=-1))\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}