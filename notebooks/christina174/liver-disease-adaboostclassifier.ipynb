{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/indian-liver-patient-records/indian_liver_patient.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data analysis ###","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.dropna()\ndata.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(7,7))\nsns.heatmap(abs(data.corr()), annot=True, square=True, cbar=False, ax=ax, linewidths=0.25);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(columns= ['Direct_Bilirubin', 'Alamine_Aminotransferase', 'Total_Protiens'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see there are correlation: 'Total_Bilirubin'-'Direct_Bilirubin', 'Alamine_Aminotransferase'-'Aspartate_Aminotransferase', 'Total_Protiens'-'Albumin'.\nI drop from data: 'Direct_Bilirubin', 'Alamine_Aminotransferase', 'Total_Protiens'.\n\nAnd data look like:\n\nCategorical:\n- Gender\n\nContinuous data:\n- Age\n- Total_Bilirubin\n- Alkaline_Phosphotase\n- Aspartate_Aminotransferase\n- Albumin\n- Albumin_and_Globulin_Ratio","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Dataset'] = data['Dataset'].replace(1,0)\ndata['Dataset'] = data['Dataset'].replace(2,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('How many people to have disease:', '\\n', data.groupby('Gender')[['Dataset']].sum(), '\\n')\nprint('How many people participated in the study:', '\\n', data.groupby('Gender')[['Dataset']].count())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Percentage of people with the disease depending on gender:')\ndata.groupby('Gender')[['Dataset']].sum()/ data.groupby('Gender')[['Dataset']].count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Women have a higher percentage of the disease, so we will conduct a separate study, depending on the gender of the person.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"age=pd.cut(data['Age'], [0,18,91])\nprint('Distribution of the disease by gender and age')\ndata.pivot_table('Dataset', ['Gender', age])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Among men with the disease at risk young people under 18 years of age.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data[['Age', 'Gender', 'Total_Bilirubin','Alkaline_Phosphotase','Aspartate_Aminotransferase','Albumin','Albumin_and_Globulin_Ratio']]\ny = pd.Series(data['Dataset'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabelencoder = LabelEncoder()\nX['Gender'] = labelencoder.fit_transform(X['Gender'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nscaler = StandardScaler()\nX_train = scaler.fit_transform(x_train)\nX_test = scaler.transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train model ###","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom numpy import mean","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this nootbook I use AdaBoostClassifier and the base estimator is DecisionTreeClassifier.\nLet`s look at some of the hyperparameters that we can consider tuning for the AdaBoost ensemble and their effect on model productivity:\n1. Number of Trees - 'n_estimators'\n2. Max depth of the trees\n3. Learning Rate\n\nFor it we to do:\n- create dictionary of models with differents hyperparameters\n- evaluate the model using repeated k-fold cross-validation\n- look at the mean of the accuracy of the each model across all repeats and folds.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ABC = AdaBoostClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_models():\n        models = dict()\n        models['10'] = AdaBoostClassifier(n_estimators=10)\n        models['30'] = AdaBoostClassifier(n_estimators=30)\n        models['50'] = AdaBoostClassifier(n_estimators=50)\n        models['75'] = AdaBoostClassifier(n_estimators=75)\n        models['100'] = AdaBoostClassifier(n_estimators=100)\n        models['125'] = AdaBoostClassifier(n_estimators=125)\n        models['150'] = AdaBoostClassifier(n_estimators=150)\n        return models\n \ndef evaluate_model(model):\n        cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n        scores = cross_val_score(model, X_test, y_test, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n        return scores\n\nmodels = get_models()\n\nresults, names = list(), list()\nfor name, model in models.items():\n        scores = evaluate_model(model)\n        results.append(scores)\n        names.append(name)\n        print('>%s %.3f' % (name, mean(scores)))\n\nplt.boxplot(results, labels=names, showmeans=True)\nplt.title('n_estimators')\nplt.show()    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_models():\n        models = dict()\n        for i in range(1,15):\n            models[str(i)] = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=i))\n        return models\n \ndef evaluate_model(model):\n        cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n        scores = cross_val_score(model, X_test, y_test, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n        return scores\n \nmodels = get_models()\n\nresults, names = list(), list()\nfor name, model in models.items():\n        scores = evaluate_model(model)\n        results.append(scores)\n        names.append(name)\n        print('>%s %.3f' % (name, mean(scores)))\n\nplt.boxplot(results, labels=names, showmeans=True)\nplt.title('max_depth')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_models():\n        models = dict()\n        for i in range(1, 21, 1):\n            per = i/10\n            key = '%.3f' % per\n            models[key] = AdaBoostClassifier(learning_rate=per)\n        return models\n \ndef evaluate_model(model):\n        cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n        scores = cross_val_score(model, X_test, y_test, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n        return scores\n \nmodels = get_models()\n\nresults, names = list(), list()\nfor name, model in models.items():\n        scores = evaluate_model(model)\n        results.append(scores)\n        names.append(name)\n        print('>%s %.3f' % (name, mean(scores)))\n\nplt.boxplot(results, labels=names, showmeans=True)\nplt.xticks(rotation=45)\nplt.title('Learning rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we choose the appropriate hyperparameters and train the model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ABC = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2),\n                         n_estimators=125,\n                        learning_rate = 0.6,\n                        random_state=42)\n\nABC.fit(X_train, y_train)\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\nn_scores = cross_val_score(ABC, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n('Accuracy: %.3f' % (mean(n_scores)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = ABC.predict(X_test)\nmatrix = confusion_matrix(y_test, labels)\nsns.heatmap(matrix.T, square=True, annot=True, fmt='d', cbar=False)\nplt.xlabel('true label')\nplt.ylabel('predicted label');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logit_roc_auc = roc_auc_score(y_test, labels)\nfpr, tpr, thresholds = roc_curve(y_test, ABC.predict_proba(X_test)[:,1])\nplt.figure()\nplt.plot(fpr, tpr, label='(area = %0.2f)' % logit_roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.legend(loc=\"lower right\")\nplt.savefig('Log_ROC')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, labels))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that with these hyperparameters model predict from people with disease 1:3.\nSo it is can miss many people with desease and for improvement model need more data.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Thanks to https://machinelearningmastery.com/\n\n### HAPPY Coding ###","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}