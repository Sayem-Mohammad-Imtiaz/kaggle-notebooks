{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport pickle\n\nfrom keras.utils.np_utils import to_categorical\nimport matplotlib.pyplot as plt\nfrom keras.layers import *\nfrom keras.activations import *\nfrom keras.models import *\nfrom keras.optimizers import *\nfrom keras.initializers import *\nfrom keras.callbacks import *\nfrom sklearn.model_selection import GridSearchCV\nfrom keras.wrappers.scikit_learn import KerasClassifier\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n        \n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# data class\nclass TRAFFIC:\n    def __init__(self, dataset=\"1\"):\n        \n        #load data\n        with open('../input/traffic-signs-preprocessed/data'+dataset+'.pickle', 'rb') as file:\n            self.data = pickle.load(file, encoding='latin1')\n         \n        # transpose for images 32 x 32 x 3\n        self.x_train = self.data['x_train'].transpose(0, 2, 3, 1)\n        self.x_validation = self.data['x_validation'].transpose(0, 2, 3, 1)\n        self.x_test = self.data['x_test'].transpose(0, 2, 3, 1)\n            \n        # shapes of pictures\n        self.height = self.x_train.shape[1]\n        self.width = self.x_train.shape[2]\n        self.depth = self.x_train.shape[3]\n        \n        #sizes\n        self.train_size = self.x_train.shape[0]\n        self.validation_size = self.x_validation.shape[0]\n        self.test_size = self.x_test.shape[0]\n        \n        self.labels = pd.read_csv('../input/traffic-signs-preprocessed/label_names.csv', delimiter=',')\n        self.num_classes = self.labels.shape[0]  \n        \n        # One hot encoding\n        self.y_train = to_categorical(self.data['y_train'], num_classes=self.num_classes)\n        self.y_validation = to_categorical(self.data['y_validation'], num_classes=self.num_classes)\n        self.y_test = to_categorical(self.data['y_test'], num_classes=self.num_classes)\n        \n    def info(self):\n        print(\"x_train: \", self.x_train.shape)\n        print(\"x_validation: \", self.x_validation.shape)\n        print(\"x_test: \", self.x_test.shape)\n        print(\"y_train: \", self.y_train.shape)\n        print(\"y_validation: \", self.y_validation.shape)\n        print(\"y_test: \", self.y_test.shape)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define the CNN\ndef create_model(optimizer, lr, width, height, depth, num_classes):\n    \n    input_img = Input(shape=(width, height, depth))\n\n    x = Conv2D(filters=32, kernel_size=3, strides=(1, 1), padding=\"same\")(input_img)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x) \n    x = MaxPool2D()(x)\n    \n    x = Conv2D(filters=64, kernel_size=9, strides=(1, 1), padding=\"same\")(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x) \n    x = MaxPool2D()(x)\n    \n    x = Conv2D(filters=128, kernel_size=18, strides=(1, 1), padding=\"same\")(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x) \n    x = MaxPool2D()(x)\n    \n    x = Flatten()(x)\n    x = Dense(128)(x)\n    x = Activation(\"relu\")(x)\n    x = Dense(64)(x)\n    x = Activation(\"relu\")(x)\n    x = Dense(num_classes)(x)\n    output_pred = Activation(\"softmax\")(x)\n   \n    optimizer = optimizer(lr=lr)\n    model = Model(inputs=input_img, outputs=output_pred)\n    model.compile(\n        loss=\"categorical_crossentropy\", \n        optimizer=optimizer, \n        metrics=[\"accuracy\"])\n    model.summary()\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load data\ndata = TRAFFIC(dataset=\"1\")\n\n#print info\ndata.info()\n\n#show example images\n\nrows = 5\ncols = 5\n\nfig, axs = plt.subplots(rows,cols, figsize = (25,25))\n\nfor i in range(rows):\n    for j in range(cols):\n        ClassId = np.argmax(data.y_train[rows*i+j])\n        label = data.labels[data.labels[\"ClassId\"] == ClassId][\"SignName\"].to_string()        \n        axs[i,j].imshow(data.x_train[rows*i+j])\n        axs[i,j].set_title(label)\n    \nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# hyperparameter\nlr = 1e-3\noptimizer = Adam\nbatch_size = 8\nepochs = 15\ndo_grid_search = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create model\nmodel = create_model(optimizer, lr, data.width, data.height, data.depth, data.num_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define learning rate sheduler\ndef schedule(epoch):\n    lr = 0.001/(epoch+1)\n\n    return lr\n\nlrs = LearningRateScheduler(\n    schedule=schedule,\n    verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For grid search\nif do_grid_search == True:\n    model = KerasClassifier(\n        build_fn=create_model,\n        epochs=epochs,\n        batch_size=batch_size,\n        verbose=1,\n        width = data.width,\n        height = data.height,\n        depth = data.depth,\n        num_classes = data.num_classes,\n        lr = 0.001)\n\n    #candidates\n    optimizer_candidates = [Adam, RMSprop]\n    batch_size_candidates = [8, 16, 32, 64]\n\n    param_grid = {\n        \"optimizer\": optimizer_candidates,\n        \"batch_size\": batch_size_candidates}\n\n    grid = GridSearchCV(\n        estimator=model,\n        param_grid=param_grid,\n        n_jobs=1,\n        verbose=1,\n        cv=3)\n\n    # fit\n    grid_result = grid.fit(data.x_train, data.y_train)\n\n    # Summary\n    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n    means = grid_result.cv_results_[\"mean_test_score\"]\n    stds = grid_result.cv_results_[\"std_test_score\"]\n    params = grid_result.cv_results_[\"params\"]\n\n    for mean, stdev, param in zip(means, stds, params):\n        print(\"%f (%f) with: %r\" % (mean, stdev, param))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# training\nhistory = model.fit(\n    x=data.x_train, \n    y=data.y_train, \n    verbose=1, \n    #batch_size=batch_size, \n    epochs=epochs, \n    validation_data=(data.x_validation, data.y_validation),\n    callbacks=[lrs])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# score on test data\nscore = model.evaluate(data.x_test, data.y_test, batch_size=batch_size)\nprint(\"Test performance: \", score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# store wrong predictions\n\npred = model.predict(data.x_test)\n\n# init\nwrong = np.array([])\n\nfor k in range(pred.shape[0]):\n    ClassId_pred = np.argmax(pred[k])\n    ClassId_true= np.argmax(data.y_test[k])\n    if ClassId_pred != ClassId_true: \n        wrong = np.append(wrong, k)\n        \nprint(\"Number of wrong predictions: \", wrong.size)\nprint(\"Percentage if wrong predictions: {0:.3f}\".format((wrong.size/pred.shape[0])*100), \"%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# show example images\nrows = 5\ncols = 5\n\nfig, axs = plt.subplots(rows,cols, figsize = (25,25))\n\nfor i in range(rows):\n    for j in range(cols):\n            ClassId_pred = np.argmax(pred[int(wrong[rows*i+j])])\n            label_pred = data.labels[data.labels[\"ClassId\"] == ClassId_pred][\"SignName\"].to_string()\n            ClassId_true= np.argmax(data.y_test[int(wrong[rows*i+j])])\n            label_true = data.labels[data.labels[\"ClassId\"] == ClassId_true][\"SignName\"].to_string()\n            axs[i,j].imshow(data.x_test[int(wrong[rows*i+j])])\n            axs[i,j].set_title(\"pred: \"+label_pred+\"\\n true: \"+label_true)\n    \nfig.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}