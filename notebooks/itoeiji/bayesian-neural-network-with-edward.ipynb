{"cells":[{"metadata":{"_cell_guid":"07f111ae-06bf-46cb-8701-72da33a1fb14","_uuid":"042c1f7fc6ae22b7f08625dc20752590a24788ae"},"cell_type":"markdown","source":"* Practice of using Edward\n* Comparing neural network (TensorFlow) with bayesian neural network (Edward)"},{"execution_count":null,"metadata":{"_cell_guid":"6499d4ec-cbc5-4ac3-a062-0f114971a87a","_uuid":"fcfd56975aa7b140fd596c8d6eaf7940e9f50e20","collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","outputs":[]},{"execution_count":null,"metadata":{"_cell_guid":"487f5c40-5eb5-4e38-b9ba-58a9680d1829","_uuid":"6140c95081da5ed8cb29add99bbea3c8bfe585bd","collapsed":true},"cell_type":"code","source":"data = pd.read_csv('../input/mushrooms.csv')\ndata.head()","outputs":[]},{"execution_count":null,"metadata":{"_cell_guid":"77d2bea6-537e-4df1-990e-d2a08423a5cb","_uuid":"915e07933c10b0f67617c350f09807af3a8003fe","collapsed":true},"cell_type":"code","source":"data.shape","outputs":[]},{"execution_count":null,"metadata":{"_cell_guid":"83a8d302-139c-403d-b566-84360900babb","_uuid":"e096a290c243aece8da0be1184186e54bc8b3aaf","collapsed":true},"cell_type":"code","source":"data.isnull().sum()","outputs":[]},{"execution_count":null,"metadata":{"_cell_guid":"fbc5b024-1f2b-416e-9d2a-e6c9d4042491","_uuid":"295402602bb560af0114f183320d0d4019dd101f","collapsed":true},"cell_type":"code","source":"data.dtypes","outputs":[]},{"execution_count":null,"metadata":{"_cell_guid":"ef5a4119-894c-4a96-b807-171ac5b8b7fd","_uuid":"6b65e761eca44bca87d090783d5a86d4859215ac","collapsed":true},"cell_type":"code","source":"data2 = pd.get_dummies(data)\ndata2.shape","outputs":[]},{"execution_count":null,"metadata":{"_cell_guid":"b2f3732e-6865-4e39-9995-e3c2d8cba6f9","_uuid":"1aa374a165d3951a8a138f35b4d9029d4f8545ea","collapsed":true},"cell_type":"code","source":"data2['class_e'].sum() / data.shape[0] # class rate","outputs":[]},{"execution_count":null,"metadata":{"_cell_guid":"0a5e67a1-a7bc-4886-bfa6-dd3836a0a918","_uuid":"101e5d7573af21d117b8e956f45658ad7a77b57e","collapsed":true},"cell_type":"code","source":"data_x = data2.loc[:, 'cap-shape_b':].as_matrix().astype(np.float32)\ndata_y = data2.loc[:, :'class_p'].as_matrix().astype(np.float32)\n\nN = 7000\ntrain_x, test_x = data_x[:N], data_x[N:]\ntrain_y, test_y = data_y[:N], data_y[N:]\n\nin_size = train_x.shape[1]\nout_size = train_y.shape[1]\n\nEPOCH_NUM = 5\nBATCH_SIZE = 1000\n\n# for bayesian neural network\ntrain_y2 = np.argmax(train_y, axis=1)\ntest_y2 = np.argmax(test_y, axis=1)","outputs":[]},{"execution_count":null,"metadata":{"_cell_guid":"75f733b1-adb5-4dfc-a701-3f15edb094e5","_uuid":"43c8d1bc2e1f4b6d4ff46c5adea2c6c61257aedc","collapsed":true},"cell_type":"code","source":"import sys\nfrom tqdm import tqdm\nimport tensorflow as tf\n\nx_ = tf.placeholder(tf.float32, shape=[None, in_size])\ny_ = tf.placeholder(tf.float32, shape=[None, out_size])\n\nw = tf.Variable(tf.truncated_normal([in_size, out_size], stddev=0.1), dtype=tf.float32)\nb = tf.Variable(tf.constant(0.1, shape=[out_size]), dtype=tf.float32)\ny_pre = tf.matmul(x_, w) + b\n\ncross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_pre))\ntrain_step = tf.train.AdamOptimizer().minimize(cross_entropy)\ncorrect_prediction = tf.equal(tf.argmax(y_pre, 1), tf.argmax(y_, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())\nfor epoch in tqdm(range(EPOCH_NUM), file=sys.stdout):\n    perm = np.random.permutation(N)\n    for i in range(0, N, BATCH_SIZE):\n        batch_x = train_x[perm[i:i+BATCH_SIZE]]\n        batch_y = train_y[perm[i:i+BATCH_SIZE]]\n        train_step.run(session=sess, feed_dict={x_: batch_x, y_: batch_y})\n    acc = accuracy.eval(session=sess, feed_dict={x_: train_x, y_: train_y})\n    test_acc = accuracy.eval(session=sess, feed_dict={x_: test_x, y_: test_y})\n    if (epoch+1) % 1 == 0:\n        tqdm.write('epoch:\\t{}\\taccuracy:\\t{}\\tvaridation accuracy:\\t{}'.format(epoch+1, acc, test_acc))","outputs":[]},{"execution_count":null,"metadata":{"_cell_guid":"49f21da9-61d7-422e-92c5-02a14b463f7b","_uuid":"d7cfcbaad88909f2d2466f7466e1bcda6dbcce63","collapsed":true},"cell_type":"code","source":"import edward as ed\nfrom edward.models import Normal, Categorical\n\nx_ = tf.placeholder(tf.float32, shape=(None, in_size))\ny_ = tf.placeholder(tf.int32, shape=(BATCH_SIZE))\n\nw = Normal(loc=tf.zeros([in_size, out_size]), scale=tf.ones([in_size, out_size]))\nb = Normal(loc=tf.zeros([out_size]), scale=tf.ones([out_size]))\ny_pre = Categorical(tf.matmul(x_, w) + b)\n\nqw = Normal(loc=tf.Variable(tf.random_normal([in_size, out_size])), scale=tf.Variable(tf.random_normal([in_size, out_size])))\nqb = Normal(loc=tf.Variable(tf.random_normal([out_size])), scale=tf.Variable(tf.random_normal([out_size])))\n\ny = Categorical(tf.matmul(x_, qw) + qb)\n\ninference = ed.KLqp({w: qw, b: qb}, data={y_pre: y_})\ninference.initialize()\n\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())\n\nwith sess:\n    samples_num = 100\n    for epoch in tqdm(range(EPOCH_NUM), file=sys.stdout):\n        perm = np.random.permutation(N)\n        for i in range(0, N, BATCH_SIZE):\n            batch_x = train_x[perm[i:i+BATCH_SIZE]]\n            batch_y = train_y2[perm[i:i+BATCH_SIZE]]\n            inference.update(feed_dict={x_: batch_x, y_: batch_y})\n        y_samples = y.sample(samples_num).eval(feed_dict={x_: train_x})\n        acc = (np.round(y_samples.sum(axis=0) / samples_num) == train_y2).mean()\n        y_samples = y.sample(samples_num).eval(feed_dict={x_: test_x})\n        test_acc = (np.round(y_samples.sum(axis=0) / samples_num) == test_y2).mean()\n        if (epoch+1) % 1 == 0:\n            tqdm.write('epoch:\\t{}\\taccuracy:\\t{}\\tvaridation accuracy:\\t{}'.format(epoch+1, acc, test_acc))","outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python","file_extension":".py","mimetype":"text/x-python","version":"3.6.3","pygments_lexer":"ipython3"}},"nbformat_minor":1,"nbformat":4}