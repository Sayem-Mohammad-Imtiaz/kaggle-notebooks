{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Importing Libraries"},{"metadata":{"trusted":false},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.set_palette('Set1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reading Dataset"},{"metadata":{"trusted":false},"cell_type":"code","source":"data = pd.read_csv('../input/heart.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Just a sanity check for null values. "},{"metadata":{"trusted":false},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on the data types attached to the columns, it seems like the data got read into the environment accurately. "},{"metadata":{"trusted":false},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Univariate Data Analysis\nIn this subsection, let us explore every attribute, within the data set, one by one. \n<br>\nIf the attribute into consideration possesses **continuous values**, then **distribution plots** provide a good summary of that attribute. If we have a **categorical quality**, then a **count plot** offers an excellent overview of that attribute. \n<br>\nLater in bivariate data analysis, we will compare the attributes with the target attribute. \n"},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.distplot(data['age']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# 1 = male; 0 = female\nsns.countplot(data['sex']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.countplot(data['cp']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.distplot(data['trestbps'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.distplot(data['chol'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.countplot(data['fbs']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.countplot(data['restecg']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.distplot(data['thalach'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.countplot(data['exang']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.distplot(data['oldpeak']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.countplot(data['slope']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.countplot(data['ca']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.countplot(data['thal']);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Bivariate Data Analysis\nIn this subsection, let's go through the relationship shared by the target variable and the attributes. "},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(14, 5))\nsns.distplot(data[data['target'] == 1]['age'], label= \"Disease - Yes\")\nsns.distplot(data[data['target'] == 0]['age'], label= \"Disease - No\")\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# 1 = male; 0 = female\nsns.countplot(data['target'], hue = data['sex']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.countplot(data['target'], hue = data['cp']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(14, 5))\nsns.distplot(data[data['target'] == 1]['trestbps'], label= \"Disease - Yes\")\nsns.distplot(data[data['target'] == 0]['trestbps'], label= \"Disease - No\")\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(14, 5))\nsns.distplot(data[data['target'] == 1]['chol'], label= \"Disease - Yes\")\nsns.distplot(data[data['target'] == 0]['chol'], label= \"Disease - No\")\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.countplot(data['target'], hue = data['fbs']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.countplot(data['target'] ,hue = data['restecg']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(14, 5))\nsns.distplot(data[data['target'] == 1]['thalach'], label= \"Disease - Yes\")\nsns.distplot(data[data['target'] == 0]['thalach'], label= \"Disease - No\")\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.countplot(data['target'], hue = data['exang']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(14, 5))\nsns.distplot(data[data['target'] == 1]['oldpeak'], label= \"Disease - Yes\")\nsns.distplot(data[data['target'] == 0]['oldpeak'], label= \"Disease - No\")\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.countplot(data['target'], hue = data['slope']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.countplot(data['target'], hue = data['ca']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.countplot(data['target'], hue = data['thal']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.jointplot(x= 'oldpeak' , y= 'chol' ,data= data, kind= 'kde');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Trivariate Data Analysis\nThe focus of this subsection would be to gather information between two categorical and one continuous attributes."},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nsns.violinplot(x = 'fbs',y= 'trestbps', data = data, hue = 'sex', split=True);","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nsns.boxplot(x = 'exang',y= 'trestbps', data = data, hue = 'sex');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Correlation Matrix"},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(12,10))\nsns.heatmap(data.corr(), annot= True, fmt='.2f')\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Pairplot"},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.pairplot(data, hue = 'target');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing\nIn this subsection, we need to preprocess categorical attributes with the help of ```get_dummies``` from **Pandas**. <br> \nIf we skip this step, then the machine learning model will assume the numbers assigned to the attributes as a ranked variable, which it is not. \n"},{"metadata":{"trusted":false},"cell_type":"code","source":"sex = pd.get_dummies(data['sex'])\ncp = pd.get_dummies(data['cp'])\nfbs = pd.get_dummies(data['fbs'])\nrestecg = pd.get_dummies(data['restecg'])\nexang = pd.get_dummies(data['exang'])\nslope = pd.get_dummies(data['slope'])\nca = pd.get_dummies(data['ca'])\nthal = pd.get_dummies(data['thal'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data = pd.concat([data, sex, cp, fbs, restecg, exang, slope, ca, thal], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data.drop(['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal'], axis = 1, inplace= True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Support Vector Machine (Without Scaler)"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.svm import SVC","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model = SVC(probability=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X = data.drop('target', axis = 1)\ny = data['target']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.metrics import classification_report, accuracy_score, roc_curve, auc","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Support Vector Machine (With Scaler)\nSignificant performance improvements with ```MinMaxScaler```. \nThe evaluation metric for this kernel will be **F1**, as it is the harmonic mean of precision and recall. <br>\nBut the evaluation metric will switch from precision to recall and vice-versa, depending on the problem statement of the project. \n"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"scaler = MinMaxScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train = scaler.fit_transform(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_test = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model.fit(X_train, y_train)\ny_pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Receiver Operating Characteristic (ROC) 1"},{"metadata":{"trusted":false},"cell_type":"code","source":"y_prob = model.predict_proba(X_test)\nfpr, tpr, thresholds = roc_curve(y_test, y_prob[:,1])\nroc_auc = auc(fpr, tpr)\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Learning Curves\nWe have achieved a commendable model above, but let us take this project one step further.<br> \nLearning curves helps to detect if the model is affected by **bias or variance**.<br> \nLet us plot learning curves based on a different set of hyperparameters. <br>\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import learning_curve","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_sizes, train_scores, test_scores = learning_curve(SVC(), X_train, y_train, scoring='f1', train_sizes=np.linspace(0.1, 1.0, 20), cv = 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_scores = np.mean(train_scores, axis = 1)\ntest_scores = np.mean(test_scores, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.plot(train_sizes, train_scores, 'o-', label=\"Training score\")\nplt.plot(train_sizes, test_scores, 'o-', label=\"Cross-validation score\")\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_sizes, train_scores, test_scores = learning_curve(SVC(C=2), X_train, y_train, scoring='f1', train_sizes=np.linspace(0.1, 1.0, 20), cv = 3)\ntrain_scores = np.mean(train_scores, axis = 1)\ntest_scores = np.mean(test_scores, axis = 1)\nplt.plot(train_sizes, train_scores, 'o-', label=\"Training score\")\nplt.plot(train_sizes, test_scores, 'o-', label=\"Cross-validation score\")\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_sizes, train_scores, test_scores = learning_curve(SVC(C=3), X_train, y_train, scoring='f1', train_sizes=np.linspace(0.1, 1.0, 20), cv = 3)\ntrain_scores = np.mean(train_scores, axis = 1)\ntest_scores = np.mean(test_scores, axis = 1)\nplt.plot(train_sizes, train_scores, 'o-', label=\"Training score\")\nplt.plot(train_sizes, test_scores, 'o-', label=\"Cross-validation score\")\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_sizes, train_scores, test_scores = learning_curve(SVC(C=3, gamma=0.1), X_train, y_train, scoring='f1', train_sizes=np.linspace(0.1, 1.0, 20), cv = 3)\ntrain_scores = np.mean(train_scores, axis = 1)\ntest_scores = np.mean(test_scores, axis = 1)\nplt.plot(train_sizes, train_scores, 'o-', label=\"Training score\")\nplt.plot(train_sizes, test_scores, 'o-', label=\"Cross-validation score\")\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_sizes, train_scores, test_scores = learning_curve(SVC(C=3, gamma=0.01), X_train, y_train, scoring='f1', train_sizes=np.linspace(0.1, 1.0, 20), cv = 3)\ntrain_scores = np.mean(train_scores, axis = 1)\ntest_scores = np.mean(test_scores, axis = 1)\nplt.plot(train_sizes, train_scores, 'o-', label=\"Training score\")\nplt.plot(train_sizes, test_scores, 'o-', label=\"Cross-validation score\")\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can try every combination of hyperparameters and pick the best one. <br>\nFortunately, ```scikit-learn``` comes with a ```GridSearchCV``` function to help us quickly come up with the best possible set of hyperparameters for the desired evaluation metric. \n"},{"metadata":{},"cell_type":"markdown","source":"# GridSearchCV"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"param_grid = {'C':[1,2,3,4,5,6,7,8,14], 'gamma':[0.1, 0.01, 0.001, 0.0001], 'kernel':['linear', 'poly', 'rbf'], 'degree': [1,2,3,4,5]}\ngrid = GridSearchCV(param_grid= param_grid, estimator= SVC(), scoring='f1', refit= True, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"grid.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"grid.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Narrowing down further"},{"metadata":{"trusted":false},"cell_type":"code","source":"param_grid = {'C':[6,7,8], 'gamma':np.linspace(0.01, 0.02, 10), 'kernel':['rbf'], 'degree': [1,2,3,4,5]}\ngrid = GridSearchCV(param_grid= param_grid, estimator= SVC(probability= True), scoring='f1', refit= True, verbose=1)\ngrid.fit(X_train, y_train)\ngrid.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_pred = grid.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_prob = grid.predict_proba(X_test)\n\nfpr, tpr, thresholds = roc_curve(y_test, y_prob[:,1])\nroc_auc = auc(fpr, tpr)\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"result = pd.DataFrame({'Test':y_test, 'Prediction':y_pred, 'Probability': y_prob[:,1]})","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"result.to_csv('Result.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}