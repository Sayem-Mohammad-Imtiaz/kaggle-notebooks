{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this kernel, I decided to evaluate two differeenet dataset with using different Machine Learning Techniques."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_2C = pd.read_csv('../input/biomechanical-features-of-orthopedic-patients/column_2C_weka.csv')\ndf_3C = pd.read_csv('../input/biomechanical-features-of-orthopedic-patients/column_3C_weka.csv')\ncompareScore3 =[]\ncompareScore2 =[]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"column_2C_weka\")\ncolor_list = ['red' if i == 'Abnormal' else 'green' for i in df_2C.loc[:,'class']]\npd.plotting.scatter_matrix(df_2C.loc[:,df_2C.columns!='class'],\n                                        c = color_list,\n                                        figsize=[15,15],\n                                        diagonal = 'hist',\n                                        alpha = 0.5,\n                                        s = 200,\n                                        marker = '*',\n                                        edgecolor = 'black')\n\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"column_3c\")\ncolor_list2 = ['red' if i != 'Normal' else 'green' for i in df_3C.loc[:,'class']]\npd.plotting.scatter_matrix(df_3C.loc[:,df_3C.columns!='class'],\n                                      c = color_list,\n                                      figsize = [15,15],\n                                      diagonal = 'hist',\n                                      alpha = 0.5,\n                                      s = 200,\n                                      marker = '*',\n                                      edgecolor = 'black')\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = \"class\",data = df_2C)\ndf_2C.loc[:,'class'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = \"class\",data = df_3C)\ndf_3C.loc[:,'class'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Applying KNN to first dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 3)\nx_2C,y_2C = df_2C.loc[:,df_2C.columns != 'class'], df_2C.loc[:,df_2C.columns == 'class']\nknn.fit(x_2C,y_2C)\nprediction = knn.predict(x_2C)\nprint(\"KNN score for 1. Dataset: \",knn.score(x_2C,y_2C))\n\n# confusion matrix\ny_pred = knn.predict(x_2C)\ny_true = y_2C\n\nfrom sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_true,y_pred)\nprint(\"Confusion matrix for 1. dataset\")\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nf,ax = plt.subplots(figsize=(5,5))\nsns.heatmap(cm,annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Applying KNN to second dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn2 = KNeighborsClassifier(n_neighbors = 3)\nx_3C, y_3C = df_3C.loc[:,df_3C.columns != 'class'], df_3C.loc[:,df_3C.columns == 'class']\nknn2.fit(x_3C,y_3C)\nprediction = knn2.predict(x_3C)\nprint(\"KNN score for 2. dataset: \",knn2.score(x_3C,y_3C))\n\n\n\ny_true = y_3C\ny_pred = knn2.predict(x_3C)\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_true,y_pred)\n\nprint(\"Confusion matrix for 2. dataset\")\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nf,ax=plt.subplots(figsize=(5,5))\nsns.heatmap(cm,annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\nplt.xlabel(\"y_true\")\nplt.ylabel(\"y_predict\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using two different confusion matrix, we can say that knn for second dataset is better fitted than first dataset eventhough it has low accuracy than first one."},{"metadata":{},"cell_type":"markdown","source":"Testing KNN with using logistic regression for our first dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nx2_train, x2_test, y2_train, y2_test = train_test_split(x_2C,y_2C,test_size=0.3,random_state=42)\n\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(x2_train,y2_train)\nprint(\"{} nn score {}: \".format(3,knn.score(x2_test,y2_test)))\nknnScore2 = knn.score(x2_test, y2_test) * 100\ncompareScore2.append(knnScore2)\n\n# confusion-matrix\ny_true = y2_test\ny_pred = knn.predict(x2_test)\n\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_true,y_pred)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\nf,ax = plt.subplots(figsize=(5,5))\nsns.heatmap(cm,annot=True,linewidths=0.5,linecolor=\"red\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"y_true\")\nplt.ylabel(\"y_pred\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using two different confusion matrix, we can say that knn for second dataset is better fitted than first dataset eventhough it has low accuracy than first one."},{"metadata":{},"cell_type":"markdown","source":"Testing KNN for our second dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nx3_train, x3_test, y3_train, y3_test = train_test_split(x_3C,y_3C,test_size = 0.3, random_state = 42)\nknn2 = KNeighborsClassifier(n_neighbors = 3)\nknn2.fit(x3_train,y3_train)\nprint(\"{} nn score: {}\".format(3,knn2.score(x3_test,y3_test)))\nknnScore3 = knn2.score(x3_test, y3_test) * 100\ncompareScore3.append(knnScore3)\n# confusion-matrix\n\ny_true = y3_test\ny_pred = knn2.predict(x3_test)\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_true,y_pred)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nf,ax = plt.subplots(figsize=(5,5))\nsns.heatmap(cm,annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\nplt.xlabel('y_true')\nplt.ylabel('y_pred')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evelation regresion model performance with R-square\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndf = pd.read_csv('../input/biomechanical-features-of-orthopedic-patients/column_2C_weka.csv')\n\ndata = df[df['class'] == 'Normal']\nx = np.array(data.loc[:,'pelvic_incidence']).reshape(-1,1)\ny = np.array(data.loc[:,'sacral_slope']).reshape(-1,1)\n\n# Scatter\nplt.figure(figsize=[10,10])\nplt.scatter(x=x,y=y)\nplt.xlabel('pelvic_incidence')\nplt.ylabel('sacral_slope')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlr = LinearRegression()\n\npredict_space = np.linspace(min(x),max(x)).reshape(-1,1)\nlr.fit(x,y)\npredicted = lr.predict(predict_space)\n\nprint('R^2 score: ',lr.score(x, y))\n\n# Plot regression line and scatter\nplt.plot(predict_space, predicted, color='black', linewidth=3)\nplt.scatter(x=x,y=y)\nplt.xlabel('pelvic_incidence')\nplt.ylabel('sacral_slope')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SVM(Support Vector Machine) for 1. dataset\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndf = pd.read_csv('../input/biomechanical-features-of-orthopedic-patients/column_2C_weka.csv')\n\ndf_abnormal = df[df['class'] == 'Abnormal']\ndf_normal = df[df['class'] == 'Normal']\n\nsns.countplot(x = 'class', data = df)\ndf.loc[:,'class'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(df_abnormal.sacral_slope,df_abnormal.pelvic_radius,label = 'abnormal',color=\"red\")\nplt.scatter(df_normal.sacral_slope,df_normal.pelvic_radius,label = 'normal',color=\"green\")\nplt.xlabel('sacral_slope')\nplt.ylabel('pelvic_radius')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y2 = df['class'].values.reshape(-1,1)\nx2_data = df.drop('class',axis = 1)\nx2 = ((x2_data - np.min(x2_data)) / (np.max(x2_data) - np.min(x2_data))).values\nfrom sklearn.model_selection import train_test_split\nx2_train, x2_test, y2_train, y2_test = train_test_split(x2,y2,test_size=0.3,random_state=42)\n\nfrom sklearn.svm import SVC\n\nsvm = SVC(random_state=1)\nsvm.fit(x2_train,y2_train)\n\nprint(\"print accuracy of svm algo for 1. dataset: \",svm.score(x2_test,y2_test))\nsvmScore2 = svm.score(x2_test, y2_test) * 100\ncompareScore2.append(svmScore2)\n#confusion_matrix\n\ny_true = y2_test\ny_pred = svm.predict(x2_test)\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_true,y_pred)\n\nprint(\"Confusion matrix for 1. dataset\")\n      \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nf,ax = plt.subplots(figsize=(5,5))\nsns.heatmap(cm,annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\nplt.xlabel('y_true')\nplt.ylabel('y_pred')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SVM(Support Vector Machine) for 2. dataset\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndf = pd.read_csv('../input/biomechanical-features-of-orthopedic-patients/column_3C_weka.csv')\n\ndf_abnormal = df[df['class'] == 'Abnormal']\ndf_normal = df[df['class'] == 'Normal']\n\nsns.countplot(x = 'class', data = df)\ndf.loc[:,'class'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(df_abnormal.sacral_slope,df_abnormal.pelvic_radius,label = 'abnormal',color=\"red\")\nplt.scatter(df_normal.sacral_slope,df_normal.pelvic_radius,label = 'normal',color=\"green\")\nplt.xlabel('sacral_slope')\nplt.ylabel('pelvic_radius')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y3 = df['class'].values.reshape(-1,1)\nx3_data = df.drop('class',axis = 1)\nx3 = ((x3_data - np.min(x3_data)) / (np.max(x3_data) - np.min(x3_data))).values\nfrom sklearn.model_selection import train_test_split\nx3_train, x3_test, y3_train, y3_test = train_test_split(x3,y3,test_size=0.3,random_state=42)\n\nfrom sklearn.svm import SVC\n\nsvm2 = SVC(random_state=1)\nsvm2.fit(x3_train,y3_train)\n\nprint(\"print accuracy of svm algo for 2. dataset: \",svm2.score(x3_test,y3_test))\nsvmScore3 = svm2.score(x3_test, y3_test) * 100\ncompareScore3.append(svmScore3)\n#confusion_matrix\n\ny_true = y3_test\ny_pred = svm2.predict(x3_test)\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_true,y_pred)\n\nprint(\"Confusion matrix for 2. dataset\")\n      \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nf,ax = plt.subplots(figsize=(5,5))\nsns.heatmap(cm,annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\nplt.xlabel('y_true')\nplt.ylabel('y_pred')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Naive Bayes for 1. dataset\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndf = pd.read_csv('../input/biomechanical-features-of-orthopedic-patients/column_2C_weka.csv')\n\ndf_Abnormal = df[df['class'] == 'Abnormal']\ndf_Normal = df[df['class'] == 'Normal']\n\nplt.scatter(df_Abnormal.sacral_slope,df_Abnormal.pelvic_radius,label=\"Abnormal\",color = \"red\")\nplt.scatter(df_Normal.sacral_slope,df_Normal.pelvic_radius,label=\"Normal\",color = \"green\")\nplt.xlabel('sacral_slope')\nplt.ylabel('pelvic_radius')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y2 = df['class'].values\nx2_data = df.drop('class',axis = 1)\n\nx2 = ((x2_data - np.min(x2_data)) / (np.max(x2_data) - np.min(x2_data))).values\n\nfrom sklearn.model_selection import train_test_split\n\nx2_train, x2_test, y2_train, y2_test = train_test_split(x2,y2,test_size=0.3,random_state=42)\n\nfrom sklearn.naive_bayes import GaussianNB\n\nnb = GaussianNB()\nnb.fit(x2_train,y2_train)\n\nprint(\"accuracy on naive bayes: \",nb.score(x2_test, y2_test))\nnbScore2 = nb.score(x2_test, y2_test) * 100\ncompareScore2.append(nbScore2)\n#confusion_matrix\n\ny_true = y2_test\ny_pred = nb.predict(x2_test)\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_true,y_pred)\n\nprint(\"Confusion matrix for 1. dataset\")\n      \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nf,ax = plt.subplots(figsize=(5,5))\nsns.heatmap(cm,annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\nplt.xlabel('y_true')\nplt.ylabel('y_pred')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Naive Bayes for 2. dataset\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndf = pd.read_csv('../input/biomechanical-features-of-orthopedic-patients/column_3C_weka.csv')\n\ndf_Abnormal = df[df['class'] == 'Abnormal']\ndf_Normal = df[df['class'] == 'Normal']\n\nplt.scatter(df_Abnormal.sacral_slope,df_Abnormal.pelvic_radius,label=\"Abnormal\",color = \"red\")\nplt.scatter(df_Normal.sacral_slope,df_Normal.pelvic_radius,label=\"Normal\",color = \"green\")\nplt.xlabel('sacral_slope')\nplt.ylabel('pelvic_radius')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y3 = df['class'].values\nx3_data = df.drop('class',axis = 1)\n\nx3 = ((x3_data - np.min(x3_data)) / (np.max(x3_data) - np.min(x3_data))).values\n\nfrom sklearn.model_selection import train_test_split\n\nx3_train, x3_test, y3_train, y3_test = train_test_split(x3,y3,test_size=0.3,random_state=42)\n\nfrom sklearn.naive_bayes import GaussianNB\n\nnb2 = GaussianNB()\nnb2.fit(x3_train,y3_train)\n\nprint(\"accuracy on naive bayes: \",nb2.score(x3_test, y3_test))\nnbScore3 = nb2.score(x3_test, y3_test) * 100\ncompareScore3.append(nbScore3)\n#confusion_matrix\n\ny_true = y3_test\ny_pred = nb2.predict(x3_test)\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_true,y_pred)\n\nprint(\"Confusion matrix for 2. dataset\")\n      \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nf,ax = plt.subplots(figsize=(5,5))\nsns.heatmap(cm,annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\nplt.xlabel('y_true')\nplt.ylabel('y_pred')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\nalgoList = [\"KNN\", \"SVM\", \"NaiveBayes\"]\ncomparison2 = {\"Models\" : algoList, \"Accuracy\" : compareScore2}\ndfComparison = pd.DataFrame(comparison2)\n\nnewIndex = (dfComparison.Accuracy.sort_values(ascending = False)).index.values\nsorted_dfComparison = dfComparison.reindex(newIndex)\n\n\ndata = [go.Bar(\n               x = sorted_dfComparison.Models,\n               y = sorted_dfComparison.Accuracy,\n               name = \"Scores of Models\",\n               marker = dict(color = \"rgba(116,173,209,0.8)\",\n                             line=dict(color='rgb(0,0,0)',width=1.0)))]\n\nlayout = go.Layout(xaxis= dict(title= 'Models',ticklen= 5,zeroline= False))\n\nfig = go.Figure(data = data, layout = layout)\nprint(\"Results for 1. dataset\")\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\nalgoList = [\"KNN\", \"SVM\", \"NaiveBayes\"]\ncomparison3 = {\"Models\" : algoList, \"Accuracy\" : compareScore3}\ndfComparison = pd.DataFrame(comparison3)\n\nnewIndex = (dfComparison.Accuracy.sort_values(ascending = False)).index.values\nsorted_dfComparison = dfComparison.reindex(newIndex)\n\n\ndata = [go.Bar(\n               x = sorted_dfComparison.Models,\n               y = sorted_dfComparison.Accuracy,\n               name = \"Scores of Models\",\n               marker = dict(color = \"rgba(116,173,209,0.8)\",\n                             line=dict(color='rgb(0,0,0)',width=1.0)))]\n\nlayout = go.Layout(xaxis= dict(title= 'Models',ticklen= 5,zeroline= False))\n\nfig = go.Figure(data = data, layout = layout)\nprint(\"Results for 2. dataset\")\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Conclusion:\n\nLooking the graph and confusion matrix, we can evaluate the algorithms both of the datasets."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}