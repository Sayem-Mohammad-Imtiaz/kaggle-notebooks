{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Problem Description\n## Affinity analysis\nAffinity analysis is a data analysis and data mining technique that discovers co-occurrence relationships among activities performed by (or recorded about) specific individuals or groups. In general, this can be applied to any process where agents can be uniquely identified and information about their activities can be recorded. In retail, affinity analysis is used to perform market basket analysis, in which retailers seek to understand the purchase behavior of customers.\n## Association Rule Mining\nMarket Basket Analysis is one of the key techniques used by large retailers to uncover associations between items. It works by looking for combinations of items that occur together frequently in transactions. To put it another way, it allows retailers to identify relationships between the items that people buy.\n## Apriori Algorithm\nApriori is an algorithm for frequent itemset mining and association rule learning over relational databases. It proceeds by identifying the frequent individual items in the database and extending them to larger and larger item sets as long as those item sets appear sufficiently often in the database. The frequent itemsets determined by Apriori can be used to determine association rules which highlight general trends in the database: this has applications in domains such as market basket analysis.\n\n1. Support: This says how popular an itemset is, as measured by the proportion of transactions in which an itemset appears.\n\n1. Confidence: This says how likely item Y is purchased when item X is purchased, expressed as {X -> Y}. This is measured by the proportion of transactions with item X, in which item Y also appears.\n\n1. Lift: This says how likely item Y is purchased when item X is purchased while controlling for how popular item Y is."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# for market basket analysis\n! pip install --index-url https://test.pypi.org/simple/ PyARMViz\nfrom mlxtend.frequent_patterns import apriori\nfrom mlxtend.frequent_patterns import association_rules\nfrom mlxtend.preprocessing import TransactionEncoder\nimport squarify\nimport matplotlib\nfrom matplotlib import style\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom PyARMViz import PyARMViz\nfrom PyARMViz.Rule import generate_rule_from_dict\n\nsns.set()\n%matplotlib inline\nmatplotlib.rcParams['figure.figsize'] = (18, 18)\nstyle.use('ggplot')\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionn","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Loading data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"basket = pd.read_csv('../input/groceries-dataset/Groceries_dataset.csv')\nprint(basket.head())\nprint(basket.tail())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Modelling and Visualization\nWe can observe that the loaded dataset consists of 38765 single item descriptions. Goal is to arrange as a set of items purchased by a customer on a particular day."},{"metadata":{"trusted":true},"cell_type":"code","source":"transactions = [a[1]['itemDescription'].tolist() for a in list(basket.groupby(['Member_number','Date']))]\nte = TransactionEncoder()\nte_ary = te.fit(transactions).transform(transactions)\ntransactions = pd.DataFrame(te_ary, columns=te.columns_)\npf = transactions.describe()\nf = pf.iloc[0]-pf.iloc[3]\na = f.tolist()\nb = list(f.index)\nitem = pd.DataFrame([[a[r],b[r]]for r in range(len(a))], columns=['Count','Item'])\nitem = item.sort_values(['Count'], ascending=False).head(20)\ntransactions","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Top 20 basket items"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\ncmap = matplotlib.cm.coolwarm\n\nmini = min(item[\"Count\"])\nmaxi = max(item[\"Count\"])\n\nnorm = matplotlib.colors.Normalize(vmin=mini, vmax=maxi)\ncolors = [cmap(norm(value)) for value in item[\"Count\"]]\n\nsquarify.plot(sizes=item[\"Count\"], label=item[\"Item\"], alpha=0.8, color=colors)\nplt.axis('off')\nplt.title(\"Top 20 Frequent Basket Items\", fontsize=32)\nttl = ax.title\nttl.set_position([.5, 1.05])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Associations"},{"metadata":{"trusted":true},"cell_type":"code","source":"frequent_itemsets = apriori(transactions, min_support=0.001, use_colnames=True, max_len=5)\nfrequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\nfrequent_itemsets","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Above table gives all association rules for basket analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"b = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=0.01)\nb['uni'] = np.nan\nb['ant'] = np.nan\nb['con'] = np.nan\nb['tot'] = 14963","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transactions = [a[1]['itemDescription'].tolist() for a in list(basket.groupby(['Member_number','Date']))]\n\ndef trans():\n    for t in transactions:\n        yield t\n    \ndef ant(x):\n    cnt = 0\n    for t in trans():\n        t = set(t)\n        if x.intersection(t) == x:\n            cnt = cnt + 1 \n    return cnt\n\nbb = b.values.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rules_dict = []\nfor bbb in bb:\n    bbb[10] = ant(bbb[0])\n    bbb[11] = ant(bbb[1])\n    bbb[9] = ant(bbb[0].union(bbb[1]))\n    diction = {\n        'lhs': tuple(bbb[0]), \n        'rhs': tuple(bbb[1]),\n        'count_full': bbb[9],\n        'count_lhs': bbb[10],\n        'count_rhs': bbb[11],\n        'num_transactions': bbb[12]\n    }\n    rules_dict.append(diction)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualizations\nWe will try to visualize the same association rules in different plots"},{"metadata":{"trusted":true},"cell_type":"code","source":"rules = []\nfor rd in rules_dict: \n    rules.append(generate_rule_from_dict(rd))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Network plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"PyARMViz.generate_rule_graph_plotly(rules)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Association rules strength plot\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"PyARMViz.generate_rule_strength_plot(rules)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}