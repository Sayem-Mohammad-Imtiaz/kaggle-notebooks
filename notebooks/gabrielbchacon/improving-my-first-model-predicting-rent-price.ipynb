{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\nDescrição / Description\nThis dataset contains 10962 houses to rent with 13 different features.\n\n### Columns:\n\n**city**: City where the property is located\n\n**area**: Property area\n\n**rooms**: Quantity of rooms\n\n**bathroom**: Quantity of bathroom\n\n**parking** spaces: Quantity of parking spaces\n\n**floor**: Floor\n\n**animal**: Accept animals?\n\n**furniture**: Furniture?\n\n**hoa**: Homeowners association tax\n\n**rent amount**: Rent amount\n\n**property tax**: Property tax\n\n**fire insurance**: Fire Insurance\n\n**total**: Total\n\nNote the column called total represents the sum of rent amount, property tax, hoa, and fire Insurance. \n\n# My Goal\n\n\nI will try to build a model that **can predict the rent amount** using this dataset features. This model can be useful to real estate broker that has to set a rent price using just these features according to the market. In this case, of course, this real estate broker does not have the total price or rent amount. Just hoa (because is defined by Homeowners association), property tax (because is defined by City Hall) and fire insurance (because is defined by the market)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Importing the libraries","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nfrom sklearn.ensemble import ExtraTreesClassifier\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Importing the dataset","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dataset = pd.read_csv('../input/brasilian-houses-to-rent/houses_to_rent_v2.csv')\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature explore","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Having a look what city we have in this dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['city'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['floor'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I made a decision to don't use this feature because, even I could clean this '-' values and drop outliers, to predict a rent may should important know if a floor is the last one (because that can (not necessary) configure another structure in a building. So I gonna try to build this model without this feature. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"del dataset['floor']\ndel dataset['area']\ndel dataset['fire insurance (R$)']\ndel dataset['total (R$)']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Another features that I decided to drop is area, fire insurance and total. Let me explain why:\n\n**Total (R$)**: Because we are tyring to predict the Rent amount. So, in this situation, if we dont have the Rent amount we also dont have the Total Price. \n\n**Area**: You probably are wonder why I did this. One thing that I'm afraid can affect my model is the relation of Area and property tax. Here in Brazil, this tax is calculated based on the current sale price of this apartment. Facts like how old this building is, the construction area, what kind of build we are talking about and the neighborhood make part of this calculation tax. Then, to avoid to use features that have a relation between each other, I chose to drop area and continue with property tax because I think can be a good resume of attributes of these apartments. \n\n**Fire Insurance**: Same Reason of area. Some Insurance companies use some attributes that we already considered, so I decided to drop this feature. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['animal'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['furniture'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dt_trasformed = pd.get_dummies(dataset)\ndt_trasformed = dt_trasformed[['hoa (R$)', 'property tax (R$)', 'rooms', 'bathroom', 'parking spaces', 'city_Belo Horizonte', 'city_Campinas', 'city_Porto Alegre', 'city_Rio de Janeiro', 'city_São Paulo', 'animal_acept', 'animal_not acept', 'furniture_furnished', 'furniture_not furnished',  'rent amount (R$)']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt_trasformed.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = dt_trasformed.iloc[:, :-1]\ny = dt_trasformed.iloc[:, -1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Feature Selection**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Univariate Selection","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#apply SelectKBest class to extract top 10 best features\nbestfeatures = SelectKBest(score_func=chi2, k=10)\nfit = bestfeatures.fit(X,y)\ndfscores = pd.DataFrame(fit.scores_)\ndfcolumns = pd.DataFrame(X.columns)\n#concat two dataframes for better visualization \nfeatureScores = pd.concat([dfcolumns,dfscores],axis=1)\nfeatureScores.columns = ['Specs','Score']  #naming the dataframe columns\nprint(featureScores.nlargest(10,'Score'))  #print 10 best features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Importance","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#model = ExtraTreesClassifier()\n#model.fit(X,y)\n#print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n#plot graph of feature importances for better visualization\n#feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n#feat_importances.nlargest(10).plot(kind='barh')\n#plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I left this code commented out because it exceeded the memory limit","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Correlation Matrix with Heatmap","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#get correlations of each features in dataset\ncorrmat = dt_trasformed.corr()\ntop_corr_features = corrmat.index\nplt.figure(figsize=(20,20))\n#plot heat map\ng=sns.heatmap(dt_trasformed[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Splitting the dataset into the Training set and Test set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = dt_trasformed.iloc[:, 0:5].values\ny = dt_trasformed.iloc[:, -1].values\ny = y.reshape(len(y),1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For the same reasons I drop area, taking a look at what I found making Feature Selection, I decided to don't use the location dummies features because they already are contained at property tax and for this dataset, this category looks like so generical. I mean, even we aren't considering the whole estate of São Paulo and Rio, just the metropolitical area, we are talking about huge cities that have a lot of arrays of rent prices.  ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Scaling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nsc_y = StandardScaler()\nX_train = sc_X.fit_transform(X_train)\ny_train = sc_y.fit_transform(y_train)\nX_test = sc_X.transform(X_test)\ny_test = sc_y.transform(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train[144])\nprint(y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training models on the Training set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"##Linear Model\nfrom sklearn.linear_model import LinearRegression\nlin_regressor = LinearRegression()\nlin_regressor.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Polynomial Model\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\npoly_reg = PolynomialFeatures(degree = 2)\nX_poly = poly_reg.fit_transform(X_train)\npoly_regressor = LinearRegression()\npoly_regressor.fit(X_poly, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Random Florest\nfrom sklearn.ensemble import RandomForestRegressor\nrf_regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\nrf_regressor.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Decision Tree\nfrom sklearn.tree import DecisionTreeRegressor\ndt_regressor = DecisionTreeRegressor(random_state = 0)\ndt_regressor.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#SVR Model\nfrom sklearn.svm import SVR\nsvr_regressor = SVR(kernel = 'rbf')\nsvr_regressor.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predicting the Test set results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Linear Prediction\ny_pred_lin = lin_regressor.predict(X_test)\nnp.set_printoptions(precision=2)\nprint(np.concatenate((y_pred_lin.reshape(len(y_pred_lin),1), y_test.reshape(len(y_test),1)),1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Polynomian Prediction\ny_pred_poly = poly_regressor.predict(poly_reg.transform(X_test))\nnp.set_printoptions(precision=2)\nprint(np.concatenate((y_pred_poly.reshape(len(y_pred_poly),1), y_test.reshape(len(y_test),1)),1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Random Florest\ny_pred_rf = rf_regressor.predict(X_test)\nnp.set_printoptions(precision=2)\nprint(np.concatenate((y_pred_rf.reshape(len(y_pred_rf),1), y_test.reshape(len(y_test),1)),1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Decison Tree\ny_pred_dt = dt_regressor.predict(X_test)\nnp.set_printoptions(precision=2)\nprint(np.concatenate((y_pred_dt.reshape(len(y_pred_dt),1), y_test.reshape(len(y_test),1)),1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#SVR Prediction\n#y_pred_svr = sc_y.inverse_transform(svr_regressor.predict(sc_X.transform(X_test)))\n#np.set_printoptions(precision=2)\n#print(np.concatenate((y_pred_svr.reshape(len(y_pred_svr),1), y_test.reshape(len(y_test),1)),1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluating the Models Performance","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Multiple Linear Regression R2: ' + str(r2_score(y_test, y_pred_lin)))\nprint('Polynomian Regression R2: ' + str(r2_score(y_test, y_pred_poly)))\nprint('Random Florest Regression R2: ' + str(r2_score(y_test, y_pred_rf)))\nprint('Decison Tree Regression R2: ' + str(r2_score(y_test, y_pred_dt)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"According to R2 score, my results are bad! I know! It is my first model and I have to get more tools to improve this model. I ask you guys to help me and guide my studies to improve my participation in the next competitions. ","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}