{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Práctica 1: Análisis exploratorio de datos, preprocesamiento y validación de modelos de clasificación\n\n### Minería de Datos: Curso académico 2020-2021\n\n### Realizado por:\n\n* Antonio Beltrán Navarro\n* Ramón Jesús Martínez Sánchez"},{"metadata":{},"cell_type":"markdown","source":"# Pima Diabetes"},{"metadata":{},"cell_type":"markdown","source":"Lo primero que haremos es cargar los datos y dividirlos en conjunto de entrenamiento y de test estratificando."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.dummy import DummyClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import KBinsDiscretizer\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nimport pandas as pd\nimport numpy as np\nimport plotly.graph_objects as go\nimport plotly.express as px\n\n\nimport miner_a_de_datos_an_lisis_exploratorio_utilidad as utils\n\nseed = 27912","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filepath = \"../input/pima-indians-diabetes-database/diabetes.csv\" \n\nindex = None\ntarget = \"Outcome\"\n\ndata = utils.load_data(filepath, index, target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(X, y) = utils.divide_dataset(data, target=\"Outcome\")\n\ntrain_size = 0.7\n\n(X_train, X_test, y_train, y_test) = train_test_split(X, y,\n                                                      stratify=y,\n                                                      random_state=seed,\n                                                      train_size=train_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = X_train.copy()\ntrain[target] = y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Análisis exploratorio de datos\n\nPrimero veamos cómo se distribuyen las diferentes variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe(include='category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_barplot(train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos ver que no está balanceada."},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_histogram(train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lo primero que podemos observar es que existen muchos valores perdidos que vienen representados con 0 en variables en las que este valor no está entre los valores razonables para la variable. Es el caso de Glucose, BloodPressure, SkinThickness, Insulin y BMI. Veamos qué fracción del total de valores están perdidos por variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"vs = [\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"]\nntrain = train.replace({v: {0: np.NaN} for v in vs})\nutils.not_valid_values_plot(ntrain, vs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos ver que casi un 50% de los valores de la variable Insulin y un 30% de la variable SkinThickness no son válidos, por lo que hemos decidido eliminarlas. Para el resto de variables imputaremos los valores perdidos, por la mediana en el caso de Glucose y BloodPressure al ser variables enteras, y por la media en el caso de BMI."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_clean = utils.imputar_valores(train)\nutils.plot_histogram(train_clean)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para ver claramente las distribuciones, las visualizaremos mediante un diagrama de cajas."},{"metadata":{"trusted":true},"cell_type":"code","source":"f = go.Figure(data=[{'type': 'box', 'y': train_clean[v], 'name': v} for v in set(train_clean.columns) - {\"Outcome\"}])\nf.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ahora realizaremos un análisis multivariado para intentar encontrar correlaciones entre las variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = utils.plot_pairplot(train_clean, 'Outcome')\nfig.update_layout(width=1200, height=1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"px.imshow(train_clean.corr())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos ver que Age y Pregnancies presentan cierta correlación por lo que eliminaremos esta última. También observamos que las variables predictoras son en general bastante independientes de la variable clase ya que no se puede observar una diferencia clara en la distribución de los puntos etiquetados como 0 y como 1.\n\nAl no poder observar puntos de corte claros, tomaremos arbitrariamente la decisión de realizar la discretización en tres intervalos de igual anchura.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"disc = KBinsDiscretizer(n_bins=3, strategy='uniform')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Preprocesamiento de datos"},{"metadata":{},"cell_type":"markdown","source":"Primero recopilaremos el preprocesamiento en un pipeline.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"med_imp = SimpleImputer(missing_values=0, strategy='median')\nmea_imp = SimpleImputer(missing_values=0, strategy='mean')\npreproc = ColumnTransformer([('', 'drop', ['Insulin', 'SkinThickness', 'Pregnancies']), \n                             ('med_inp', med_imp, [\"Glucose\", \"BloodPressure\"]),\n                             ('mea_inp', mea_imp, [\"BMI\"])], remainder='passthrough')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Aprendizaje y Evaluación *Zero-R*"},{"metadata":{},"cell_type":"markdown","source":"Empezaremos entrenando un Zero-R."},{"metadata":{"trusted":true},"cell_type":"code","source":"zeror = DummyClassifier(strategy='most_frequent', random_state=seed)\n\nclean_zeror = make_pipeline(preproc, zeror)\nutils.evaluate(clean_zeror, X_train, X_test, y_train, y_test)\n\ncfs = [confusion_matrix(y_test, clean_zeror.predict(X_test))]\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Aprendizaje y Evaluación *Árbol de Decisión*"},{"metadata":{},"cell_type":"markdown","source":"Ahora usaremos un árbol de clasificación sin discretización previa y con los hiperparámetros por defecto:\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"ndt = DecisionTreeClassifier(random_state=seed)\n\ncln_ndt = make_pipeline(preproc, ndt)\n\nutils.evaluate(cln_ndt, X_train, X_test, y_train, y_test)\n\ncfs.append(confusion_matrix(y_test, cln_ndt.predict(X_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Por último, discretizaremos antes de entrenar el árbol"},{"metadata":{"trusted":true},"cell_type":"code","source":"cln_disc_ndt = make_pipeline(preproc, disc, ndt)\n\nutils.evaluate(cln_disc_ndt, X_train, X_test, y_train, y_test)\n\ncfs.append(confusion_matrix(y_test, cln_disc_ndt.predict(X_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"go.Figure([go.Scatter(x=[0, 1], y=[0, 1], line={'dash': 'dash'}, name='Clasificador aleatorio'), go.Scatter(x=[cfs[i][0, 1] / (cfs[i][0, 0] + cfs[i][0, 1]) for i in range(len(cfs))], y=[cfs[i][1, 1] / (cfs[i][1, 1] + cfs[i][1, 0]) for i in range(len(cfs))], mode='markers', hovertext=['ZeroR', 'Árbol sin discretizar', 'Árbol discretizando'], name='Clasificadores propuestos')], layout={'title': 'Espacio ROC', 'xaxis': {'title': '1-specificity'}, 'yaxis': {'title': 'sensitivity'}})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observando los resultados de los tres clasificadores, podemos decir que los árboles de decisión son superiores al ZeroR en *accuracy*, además de alcanzar un mejor compromiso entre *sensitivity* y *specificity*.\n\nEntre los dos árboles, la discretización previa parece que mejora ligeramente las medidas consideradas con respecto a no realizarla."},{"metadata":{},"cell_type":"markdown","source":"----"},{"metadata":{},"cell_type":"markdown","source":"# Wisconsin"},{"metadata":{},"cell_type":"markdown","source":"Comenzamos cargando el conjunto de datos `wisconsin`:"},{"metadata":{"trusted":true},"cell_type":"code","source":"filepath = \"../input/breast-cancer-wisconsin-data/data.csv\"\n\nindex = \"id\"\ntarget = \"diagnosis\"\n\ndata = utils.load_data(filepath, index, target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Una vez hemos cargado el conjunto de datos, mostraremos 5 registros aleatorios mediante la función `sample` para comprobar que el proceso ha sido realizado correctamente"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como podemos observar, tenemos una columna, la última, cuyo nombre es `Unnamed` y todo el contenido de sus filas `NaN`. Esto significa que antes de continuar trabajando con nuestra base de datos, debemos borrarla."},{"metadata":{"trusted":true},"cell_type":"code","source":"del data['Unnamed: 32']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Comprobamos que se ha borrado correctamente haciendo uso del método `sample` de nuevo:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.diagnosis.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Es muy útil disponer del conjunto de datos separado dos subconjuntos, uno con las variables predictoras (`X`) y otro con la variable objetivo (`y`). Se puede utilizar el siguiente fragmento de código para dividirlo: "},{"metadata":{},"cell_type":"markdown","source":"A continuación, separaremos en dos subconjuntos nuestro conjunto de datos inicial, uno con las variables predictoras (`X`) y otro con la variable objetivo (`y`). "},{"metadata":{"trusted":true},"cell_type":"code","source":"(X, y) = utils.divide_dataset(data, target=\"diagnosis\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Comprobaremos que se hayan separado correctamente:"},{"metadata":{},"cell_type":"markdown","source":"Empezamos mostrando las variables predictoras:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Y a continuación la variable objetivo:"},{"metadata":{"trusted":true},"cell_type":"code","source":"y.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Antes de comenzar el análisis exploratorio de los datos, dividiremos nuestro conjunto de datos en otros dos subconjuntos, uno de entrenamiento y otro de prueba, con los siguientes porcentajes:\n\n* Conjunto de entrenamiento: **70%**\n* Conjunto de prueba: **30%**\n\nMediante este proceso, nos aseguraremos de que los resultados posteriores del proceso de validación han sido obtenidos de una manera correcta."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size = 0.7\n(X_train, X_test, y_train, y_test) = train_test_split(X, y,\n                                                      stratify=y,\n                                                      random_state=seed,\n                                                      train_size=train_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seguidamente, lo que haremos será unir los conjuntos `X_train` e `y_train` para obtener el conjunto de datos de entrenamiento.\nHaremos los mismo para `X_test` e `y_test`, juntando así el conjunto de datos de test."},{"metadata":{"trusted":true},"cell_type":"code","source":"train = utils.join_dataset(X_train, y_train)\ntest = utils.join_dataset(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nuevamente, vamos a asegurarnos de que el conjunto de datos se ha dividido correctamente. Comenzamos con las variables del conjunto de datos de entrenamiento, observando que la variable clase también aparece al final del conjunto:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Comprobamos lo mismo para nuestro nuevo conjunto de prueba:"},{"metadata":{"trusted":true},"cell_type":"code","source":"test.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Una vez tenemos bien definidos nuestros conjuntos de entrenamiento y prueba, podemos pasar con el análisis exploratorio de datos."},{"metadata":{},"cell_type":"markdown","source":"## 1. Análisis exploratorio de datos"},{"metadata":{},"cell_type":"markdown","source":"El análisis exploratorio de datos es un paso fundamental a la hora de comprender los datos con los que vamos a trabajar.\n\nEl objetivo de este análisis es explorar, describir y visualizar la naturaleza de los datos recogidos mediante la aplicación de técnicas simples de resumen de datos y métodos gráficos, para observar las posibles relaciones entre las variables de nuestro conjunto de datos.\n\nPara comenzar, veremos una descripción del conjunto de datos que vamos a emplear."},{"metadata":{},"cell_type":"markdown","source":"### Descripción del conjunto de datos\nEl número de casos y variables (respectivamente) del conjunto de datos se puede obtener consultando el atributo `shape`:\nObservamos como de los 569 registros iniciales, tenemos **398** de ellos para el entrenamiento (un 70%), y **171** (un 30%) para el conjunto de prueba, ambos con 31 variables, las 30 predictoras y la variable objetivo."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para conocer cuál es el tipo de las variables, recurrimos al método `info`:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info(memory_usage=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"De acuerdo con esto, todas las variables predictoras del conjunto de datos son numéricas (`float64`). Sin embargo, la variable clase (`diagnosis`) es categórica y contiene dos estados, cuyos valores serán `M`y`B` como ya hemos comentado anteriormente:"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.cat.categories","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Otra cosa que observamos gracias a aplicar el método `info` sobre nuestro conjunto de datos de entrenamiento es que en realidad solo contamos con **10 variables** reales, pero que se convierten en 30 puesto que están divididas en 3 categorías `mean`, `se` y `worst`. Es importante considerar esto cuando pasemos a visualizar las variables posteriormente, puesto que al haber tal cantidad de variables será mejor una representación dividida por estas 3 categorías."},{"metadata":{"_uuid":"f17f376d1ed7405027aebcd226bb6f54d61834ed"},"cell_type":"markdown","source":"### Visualización de las variables"},{"metadata":{},"cell_type":"markdown","source":"A la hora de visualizar las variables, comenzaremos comprobando la distribución de la variable clase de nuestro conjunto de entrenamiento. Como vemos, hay 250 instancias de la clase mayoritaria `B`, y 148 de la clase `M`."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe(include=\"category\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Se puede observar mejor de la siguiente manera, comprobando gráficamente qué clase es la que predomina:"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_barplot(train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lo que podemos observar es que las clases de la variable objetivo del problema no tienen el mismo número de casos, es decir, el problema está desbalanceado (las frecuencias de las combinaciones de estados no aparecen en la misma proporción).\n\nAhora que sabemos que el problema es **desbalanceado**, es el turno de visualizar las variables predictoras del conjunto de datos."},{"metadata":{},"cell_type":"markdown","source":"Comenzaremos mostrando un **histograma** con todas las variables, para mostrar la densidad de ejemplos para los distintos valores de las variables numéricas y analizar las tendencias que estas toman:"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_histogram(train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mediante el estudio de este histograma en el que se han representado todas las variables, podremos extraer diversas conclusiones que nos serán útiles a la hora de preprocesar los datos de nuestro conjunto:\n* Mirando las variables independientemente, encontramos outliers en las variables `radius, area, y perimeter` en sus tres variantes, lo que será algo a tener en cuenta a la hora de preprocesar los datos si queremos eliminarlos.\n* Estimación de las distribuciones:\n    * Si analizamos las variables `mean`, veremos que `radius, perimeter y area` siguen una distribución normal al igual que la mayoría de variables, excepto las relacionadas con la concavidad, que pueden llegar a tomar una distribución exponencial.\n    * Si analizamos las variables `se`, veremos que `radius, perimeter y area` siguen ahora una distribución exponencial, al igual que las relacionadas con la concavidad.\n    * Si analizamos las variables `worst`, veremos que `radius, perimeter y area` vuelven a seguir una distribución normal, y las relacionadas con la concavidad pasan a ser distintas, ahora solo `concavity` sigue una tendencia exponencial, mientras que `concave_points` pasa a tomar una clara distribución normal.\n* Tras este paso, vemos también que todas las distribuciones tienden a ir hacia la **derecha**."},{"metadata":{},"cell_type":"markdown","source":"Ahora realizaremos un análisis multivariado para intentar encontrar correlaciones entre las variables.\n\nPara ello, obtenemos del conjunto de entrenamiento solo las variables de tipo `mean`, puesto que son las más representativas. Con ellas, realizaremos una matriz de dispersión por parejas para comprobar las relaciones entre ellas.\n\nComo podemos ver, la variable clase se diferencia también en nuestra gráfica, siendo el color naranja el diagnóstico `M`, y su homólogo azul el diagnóstico `B`:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_mean = train.loc[:,'radius_mean':'fractal_dimension_mean']\ntrain_mean[\"diagnosis\"] = train[\"diagnosis\"]\n\nfig = utils.plot_pairplot(train_mean, 'diagnosis')\nfig.update_layout(width=1600, height=1400)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Estudiando la matriz de dispersión de las variables predictoras ordenadas por parejas, podemos sacar como conclusión que las variables `perimeter y area` dependen fuertemente de `radius`.\n\nIgualmente, podemos apreciar cómo las variables `concavity y compactness` dependen también en gran medida de `concave points`.\n\nA continuación, realizaremos diversas observaciones de estos datos para ver si realmente las dependencias ya mencionadas se ven reflejadas en el conjunto de datos."},{"metadata":{},"cell_type":"markdown","source":"Ahora realizaremos 3 distintos **Mapas de Correlación**. La respuesta a esto es que separaremos los 3 tipos de variables `mean, se y worst` en mapas distintos, para poder visualizar de una manera más clara las correlaciones entre las variables de nuestro conjunto.\n\nComenzamos con el Mapa de Correlación de las variables de tipo `mean`:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_mean = X_train.loc[:,'radius_mean':'fractal_dimension_mean']\n\nfig = px.imshow(X_train_mean.corr(),title=\"Mapa de Correlación variables 'mean'\")\nfig.show()\n\nX_train_mean.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seguimos con el Mapa de Correlación de las variables de tipo `se`:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_se = X_train.loc[:,'radius_se':'fractal_dimension_se']\n\nfig = px.imshow(X_train_se.corr(),title=\"Mapa de Correlación variables 'se'\")\nfig.show()\n\nX_train_se.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_worst = X_train.loc[:,'radius_worst':'fractal_dimension_worst']\n\nfig = px.imshow(X_train_worst.corr(),title=\"Mapa de Correlación variables 'worst'\")\nfig.show()\n\nX_train_worst.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Estudiando los tres mapas de correlación podemos sacar una clara conclusión: **Las variables `perimeter y area` dependen directamente de `radius`.** Esto significa que más adelante en el preprocesamiento de datos podremos eliminar las variables `perimeter y area` sin problema.\n\nDe la misma manera, vemos cómo las variables `concavity y compactness` dependen también en gran medida de `concave points`, por lo que ambas variables podrán tambier ser eliminadas posteriormente, debido a su dependencia con esta última."},{"metadata":{},"cell_type":"markdown","source":"Mediante un **Boxplot** veremos de mejor forma como están distribuidos los datos de cada una, y así ademas identificar de mejor forma aquellas que tengan valores atípicos (*outliers*), no solo fijándonos en el histograma. Ahora, podremos fijarnos en cada variable de forma individual para comprobar si cuentan con algún outlier."},{"metadata":{"trusted":true},"cell_type":"code","source":"f = go.Figure(data=[{'type': 'box', 'y': train[v], 'name': v} for v in set(train.columns)- {\"diagnosis\"}])\nf.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Las conclusiones que podemos obtener de este diagrama es que encontramos **outliers** en las variables `radius, area, y perimeter` en sus tres variantes (como ya habíamos comentado en el histograma), y además las variables `smoothness y concavity` cuentan con valores atípicos.\n\nEsto será algo que será algo a tener en cuenta a la hora de preprocesar los datos si queremos eliminarlos."},{"metadata":{},"cell_type":"markdown","source":"## 2. Preprocesamiento de datos"},{"metadata":{},"cell_type":"markdown","source":"En esta etapa limpiaremos y organizaremos los datos de manera adecuada para entrenar a nuestro modelo basándonos en las observación que hemos realizado en el análisis exploratorio de datos previo. Por ello, en este conjunto de datos nos centraremos en la selección de variables adecuadas para conseguir reducir el número de estas.\n\n\nPara realizar este proceso, haremos uso de un **Pipeline**. Este Pipeline será el encargado de aplicar las transformaciones que hemos decidido a nuestro conjunto de datos.\n\nComo hemos decidido anteriormente graciás al análisis exploratorio de los datos, debemos eliminar las columnas (variables) seleccionadas previamente:\n* Aquellas relacionadas con los `concave points`: `concavity_mean, compactness_mean, concavity_se, compactness_se, concavity_worst y compactness_worst`.\n* Aquellas relacionadas con `radius`, es decir: `area_mean, perimeter_mean, area_se, perimeter_se, area_worst y perimeter_worst`.\n\nLa respuesta a por qué estas columnas son las mencionadas previamente, porque son variables que dependen directamente de las 2 que vamos a dejar en nuestro conjunto de datos: `radius y concave points`."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import make_pipeline\nfrom sklearn.compose import ColumnTransformer\n\npreproc = ColumnTransformer([(\"\", \"drop\", [\"concavity_mean\", \"compactness_mean\", \"concavity_se\", \"compactness_se\", \"concavity_worst\", \"compactness_worst\", \"area_mean\", \"perimeter_mean\", \"area_se\", \"perimeter_se\", \"area_worst\", \"perimeter_worst\"])], remainder=\"passthrough\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Discretización"},{"metadata":{},"cell_type":"markdown","source":"Con el objeto de obtener unos datos más simples y convertir las variables numéricas en intervalos vamos a discretizar esas variables, siendo en este caso, todas las variables predictoras.\n\nPara simplificar los datos realizaremos un proceso de discretización de los datos. Esto quiere decir que convertiremos las variables que son numéricas (todas las variables predictoras que tengamos **después de la selección de variables** que hemos hecho previamente) en variables agrupadas por intervalos, lo que restará complejidad al modelo.\n\nAl no poder observar puntos de corte claros, tomaremos arbitrariamente la decisión de realizar la discretización en tres intervalos de igual anchura."},{"metadata":{"trusted":true},"cell_type":"code","source":"discretizer = KBinsDiscretizer(n_bins=3, strategy=\"uniform\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Aprendizaje y Evaluación *Zero-R*"},{"metadata":{},"cell_type":"markdown","source":"## Aprendizaje *Zero-R*"},{"metadata":{},"cell_type":"markdown","source":"Lo que este algoritmo hará será aprender un clasificador que asigne a los casos del conjunto de test la clase predominante en el conjunto de entrenamiento (ya vimos que el problema era desbalanceado). Como veremos, en nuestro conjunto de datos concreto no destaca por su efectividad."},{"metadata":{"trusted":true},"cell_type":"code","source":"zero_r_model = DummyClassifier(strategy=\"most_frequent\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluación *Zero-R*"},{"metadata":{},"cell_type":"markdown","source":"Ahora es el momento de entrenar y validar nuestros clasificadores. Para ello, vamos a usar una matriz de confusión y tasa de acierto."},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline = make_pipeline(preproc, zero_r_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Aplicamos nuestro preprocesamiento al conjunto de entrenamiento y al conjunto de test:"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(pipeline,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"56eac04a7c1e86758c1a208ba0d568d216132393"},"cell_type":"markdown","source":"Como era de esperar, el modelo *Zero-R* obtiene malos resultados, pues solo predice la clase mayoritaria en el conjunto de entrenamiento, en este caso 0 (B)."},{"metadata":{},"cell_type":"markdown","source":"## 4. Aprendizaje y Evaluación *Arbol de Decisión*"},{"metadata":{},"cell_type":"markdown","source":"## Aprendizaje *Arbol de Decisión*"},{"metadata":{},"cell_type":"markdown","source":"Una vez estudiado el algoritmo `Zero-R` probaremos un nuevo método, la creación de un árbol de decisión.\n\nPara obtener este arbol de decisión, usaremos el estimador `DecisionTreeClassifier` de `scikit-learn`, sin olvidar fijar la semilla que definimos al principio de la libreta para asegurar que los experimentos sean reproducibles:"},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_model = DecisionTreeClassifier(random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Aplicamos el pipeline al árbol de decisión creado. Diferenciaremos en dos:\n* Solo preprocesamiento (eliminación de variables que no son necesarias)\n* Preprocesamiento y discretización"},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocessed_tree_model = make_pipeline(preproc, tree_model)\npreprocessed_discretized_tree_model = make_pipeline(preproc, discretizer, tree_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluación *Arbol de Decisión*"},{"metadata":{},"cell_type":"markdown","source":"Vamos a ver los resultados del árbol de decisión sin el conjunto de datos discretizado:"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(preprocessed_tree_model,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Y con el conjunto de datos discretizado:"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(preprocessed_discretized_tree_model,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusión"},{"metadata":{},"cell_type":"markdown","source":"Como puede resultar evidente, los árboles de decisión que hemos implementado obtienen mejores resultados que el algoritmo `Zero-R` puesto que no solo se quedan con la clase mayoritaria.\n\nA su vez, es importante comentar que el árbol de decisión entrenado con el conjunto de datos discretizado (tras realizar las modificaciones necesarias que aprendimos en el análisis exploratorio) obtiene una tasa de acierto similar al árbol de decisión con el conjunto de datos sin discretizar para este problema concreto.\n\nLa conclusión que podemos obtener es que con un sencillo preprocesamiento y empleando un modelo predictivo no muy complejo obtendremos unas predicciones con una precisión de un 92%, lo que nos demuestra la importancia de preprocesar nuestro conjunto de datos."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}