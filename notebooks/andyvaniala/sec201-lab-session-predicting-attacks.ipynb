{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\ndf = pd.read_csv('../input/unsw-nb15/UNSW_NB15_training-set.csv')\n\nnumberColumn = len(df.columns)\nprint('Column number: '+ str(numberColumn) )\ncolumnNames = df.columns\nprint('Column names: ')\nprint(columnNames)\ncolumnType = df.dtypes\nprint('Column types ')\nprint(columnType)\nsizeDataSet = len(df)\nprint('Data set size: '+str(sizeDataSet))\n\n\n#####file header\nprint('\\nfile head\\n')\nprint(df.head())\n\n#####Column categories\nprint('\\nIndex\\n')\nprint(columnType[columnType == 'object'].index)\n\nfor category in columnType[columnType=='object'].index:\n    print(' '+category)\n    print(list(set(df[category])))\n    \n#####Column numeric\nprint('Column numeric')\nnumericDf=df._get_numeric_data()\nprint(numericDf.columns)\n\n####List numeric columns\nprint('\\n numeric column:\\n')\n\n\nfor category in numericDf.columns:\n    print('list categories: '+category)\n    minimum=min(df[category])\n    maximum=max(df[category])\n    mean=np.mean(df[category])\n    median=np.median(df[category])\n    standard=np.std(df[category])\n    print('min: '+str(minimum))\n    print('max: '+str(maximum))\n    print('mean: '+str(mean))\n    print('median: '+str(median))\n    print('Standard: '+str(standard))\n    print('\\n')\n    \n######Check whether the positive label (1) match attack categories and whether attack categories match labelled data\n#label_normal = df.loc[df.attack_cat == \"Normal\"].label.unique()\n#print(\"There is \" + str(len(label_normal)) + \" label where attack_cat == normal, label = \" + str(label_normal))\n\n#label_attack = df.loc[df.attack_cat != \"Normal\"].label.unique()\n#print(\"There is \" + str(len(label_attack)) + \" label where attack_cat != normal, label = \" + str(label_attack))\n#print(\"Nombre de label absent\", df.label.isna().sum())","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-02T06:30:47.201765Z","iopub.execute_input":"2021-06-02T06:30:47.202713Z","iopub.status.idle":"2021-06-02T06:30:49.108703Z","shell.execute_reply.started":"2021-06-02T06:30:47.202458Z","shell.execute_reply":"2021-06-02T06:30:49.107479Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##4.1 Column number\nnumberColumn = len(df.columns)\nprint('Column number: '+ str(numberColumn)  )\n\n##4.2 Column name\ncolumnNames = df.columns\nprint('\\nColumn names: ')\nprint(columnNames)\n\n##4.3 Column type\ncolumnType = df.dtypes\nprint('\\nColumn types ')\nprint(columnType)\n\n##4.4 Size of the data set\nsizeDataSet = len(df)\nprint('\\nData set size: '+str(sizeDataSet))","metadata":{"execution":{"iopub.status.busy":"2021-06-02T07:57:17.226676Z","iopub.execute_input":"2021-06-02T07:57:17.227373Z","iopub.status.idle":"2021-06-02T07:57:17.274468Z","shell.execute_reply.started":"2021-06-02T07:57:17.227259Z","shell.execute_reply":"2021-06-02T07:57:17.273355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##5 File head \nprint(df.head())","metadata":{"execution":{"iopub.status.busy":"2021-06-01T12:25:39.484992Z","iopub.execute_input":"2021-06-01T12:25:39.4854Z","iopub.status.idle":"2021-06-01T12:25:39.50074Z","shell.execute_reply.started":"2021-06-01T12:25:39.485357Z","shell.execute_reply":"2021-06-01T12:25:39.499718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##6 Which columns are categories? List them; extract existing values.\nprint(columnType[columnType == 'object'].index)\nfor category in columnType[columnType=='object'].index:\n    print('\\n'+category)\n    print(list(set(df[category])))\n    ","metadata":{"execution":{"iopub.status.busy":"2021-06-01T12:23:26.439756Z","iopub.execute_input":"2021-06-01T12:23:26.440181Z","iopub.status.idle":"2021-06-01T12:23:26.493395Z","shell.execute_reply.started":"2021-06-01T12:23:26.440142Z","shell.execute_reply":"2021-06-01T12:23:26.49242Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##7 Which columns are numeric? \nnumericDf=df._get_numeric_data()\nprint(numericDf.columns)\n\n##List them; extract min, max, mean, median and standard deviation values for ‘rate’.\nfor category in numericDf.columns:\n    \n    print('\\nCategories: '+category)\n    minimum=min(df[category])\n    maximum=max(df[category])\n    mean=np.mean(df[category])\n    median=np.median(df[category])\n    standard=np.std(df[category])\n    print('min: '+str(minimum))\n    print('max: '+str(maximum))\n    print('mean: '+str(mean))\n    print('median: '+str(median))\n    print('Standard: '+str(standard))","metadata":{"execution":{"iopub.status.busy":"2021-06-01T09:00:50.165364Z","iopub.execute_input":"2021-06-01T09:00:50.165714Z","iopub.status.idle":"2021-06-01T09:00:51.221375Z","shell.execute_reply.started":"2021-06-01T09:00:50.165684Z","shell.execute_reply":"2021-06-01T09:00:51.220143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**ANALYSIS GOAL**\n8. Based on this information\n8. 1. Goal of the analysis\nLe but de cette analyse est d'identifier les attaques et anomalies du réseau. En analysant les valeurs des colonnes numériques, une anomalie peut être détectée par la diversité des valeurs.\n8. 2. The target properties to analyse \nLes propriétés cibles à analyser sont le \"label\" du dataset et \"attack_cat\". Le label permet de savoir si il y a une attaque réseau ou non par la présence de la valeur 0 ou 1. L'analyse de \"attack_cat\" permet de connaître la catégorie de l'attaque. Le rapport entre ces deux propriétés permet alors de determiner si il y a une anomalie sur le réseau. Il se peut que le label portera la valeur 1 alors que attack_cat est normal. Il y donc une incohérence entre les deux propriétés.\n\n","metadata":{}},{"cell_type":"code","source":"##Evaluation of the training dataset\n##9 Check whether the positive label (1) match attack categories and whether attack categories match labelled data.\n#(df.loc[df.label==1].proto).drop_duplicates()\nnumber=((df.loc[df.attack_cat==\"Normal\"]).drop_duplicates()).count().unique()\n#if numberNormal==number\nprint(number)\nprint('attack!=normal')\n#(df.loc[df.attack_cat!=\"Normal\"]).drop_duplicates()\nnumberAttack=((df.loc[df.attack_cat!=\"Normal\"]).drop_duplicates()).count().unique()\nnumberLabel1=((df.loc[df.label==1]).drop_duplicates()).count().unique()\nprint(numberAttack)\nif numberAttack==numberLabel1: print('categories and positive label (1) match') \nelse: print ('NO')\n","metadata":{"execution":{"iopub.status.busy":"2021-06-02T06:33:19.219937Z","iopub.execute_input":"2021-06-02T06:33:19.220377Z","iopub.status.idle":"2021-06-02T06:33:19.573719Z","shell.execute_reply.started":"2021-06-02T06:33:19.220333Z","shell.execute_reply":"2021-06-02T06:33:19.572537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##10 Which is the number of occurrences for each attack category?\n#somme = sum(df.groupby(\"attack_cat\").count()['id'])\n#print('Total number of attacks '+ str(somme))\ndf.groupby(\"attack_cat\").count()['id']\n","metadata":{"execution":{"iopub.status.busy":"2021-06-01T13:49:23.592354Z","iopub.execute_input":"2021-06-01T13:49:23.592687Z","iopub.status.idle":"2021-06-01T13:49:23.644677Z","shell.execute_reply.started":"2021-06-01T13:49:23.592659Z","shell.execute_reply":"2021-06-01T13:49:23.643884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##11 Which protocols and services appear in the positively labelled entries? In the negatively labelled ones?\n#Positive label (1)\nprint('Protocols and services in the positively labelled entries')\nprint(sorted((df.loc[df.label==1].proto).drop_duplicates()),sorted((df.loc[df.label==1].service).drop_duplicates()))\n\n#Negative label (0)\nprint('\\nProtocols and services in the negatively labelled entries')\nprint(sorted((df.loc[df.label==0].proto).drop_duplicates()),sorted((df.loc[df.label==0].service).drop_duplicates()))","metadata":{"execution":{"iopub.status.busy":"2021-06-01T13:26:19.585329Z","iopub.execute_input":"2021-06-01T13:26:19.585688Z","iopub.status.idle":"2021-06-01T13:26:19.629498Z","shell.execute_reply.started":"2021-06-01T13:26:19.585651Z","shell.execute_reply":"2021-06-01T13:26:19.628459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"12. What do you conclude about the traffic being analysed?\nD'après l'analyse effectuée, nous pouvons constater que le nombre d'attaque dans le réseau est beaucoup élevé que la normale avec 45332 attaques et 37000 trafics normaux","metadata":{}},{"cell_type":"code","source":"##Data Visualisation\n##13 Visualise the repartition of services, protocols, attack types, as histograms\n####Use pyplot and seaborn libraries.\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfig = plt.gcf()\nfig.set_size_inches(8, 5)\ncplot = sns.countplot(y=\"service\", data=df)\ncplot.set_title(\"Repartition of services\")\nplt.show()\n\n#plt.figure(figsize=(40, 40))\nfig1 = plt.gcf()\nfig1.set_size_inches(10, 20)\ncplot1 = sns.countplot(y=\"proto\", data=df)\ncplot1.set_title(\"Repartition of protocols\")\nplt.show()\n\n\ncplot2 = sns.countplot(y=\"attack_cat\", data=df)\ncplot2.set_title(\"Repartition of attack types\")\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-02T09:33:54.468608Z","iopub.execute_input":"2021-06-02T09:33:54.469241Z","iopub.status.idle":"2021-06-02T09:33:56.818505Z","shell.execute_reply.started":"2021-06-02T09:33:54.469196Z","shell.execute_reply":"2021-06-02T09:33:56.817652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##14 Build the correlation matrix between parameters for labelled and unlabelled entries.\nfig = plt.gcf()\nfig.set_size_inches(40,10)\ncorrelation= df.corr()\ncmap = sns.color_palette(\"Spectral\", as_cmap=True)\nheatmap = sns.heatmap(correlation, annot=True, cmap=cmap)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T09:30:50.483077Z","iopub.execute_input":"2021-06-02T09:30:50.483538Z","iopub.status.idle":"2021-06-02T09:30:58.626328Z","shell.execute_reply.started":"2021-06-02T09:30:50.483499Z","shell.execute_reply":"2021-06-02T09:30:58.62504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Evaluation**\n15. Based on the Exploratory Data Analysis\n15.1. Describe what you learnt from the dataset\nD'après la répartition des services et protocoles, les données sont en manque surtout dans l'histogramme de la répartition des protocoles. Dans celle des services, nous n'avons de données sur le snmp, ssl, dhcp, irc, radius, ssh et dans celle des protocoles, seuls les protocoles tcp, udp, ospf, arp, sctp et unas ont des données. Nous pouvons en déduire, d'après l'histogramme de répartition des protocoles que les plus utilisés sont le protocole tcp et udp.\nD'après la repartition des attaques, nous pouvons constater que plusieurs attaques sont generic, ne sont pas categorisées.\n\n15.2. Draw the first conclusions\n\n\n15.3. Emit recommendations for enforcing the cybersecurity of the target system","metadata":{}}]}