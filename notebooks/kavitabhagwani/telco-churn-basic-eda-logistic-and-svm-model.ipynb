{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using the pandas library for data analysis and the scikit-learn library for machine learning\n\n#Build a model to predict wheather a new cust will churn or not","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predicting Customer Churn\n\n#Churn is when a customer stops doing business or ends a relationship with a company.\n\n#Itâ€™s a common problem across a variety of industries, from telecommunications to cable TV etc\n#company that can predict churn can take proactive action to retain valuable customers and get ahead of the competition","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns # used for plot interactive graph. \nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head() # checking first 5 rows of dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#How many churners does the dataset have, and how many non-churners\ndf['Churn'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info() # totalcharges is object so change in to float","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ChangeTotalcharges in to numeric variable \n\ndf.TotalCharges = pd.to_numeric(df.TotalCharges, errors='coerce')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.groupby(['Churn']).mean())\n\n# churning cust having are having less tunure and high monthly charges \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking missing value \ndf.isnull().sum() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove missing values\ndf.dropna(inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check dimensions of dataset\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# EDA\n# Important to understand how your variables are distributed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualize distribution of classes # after droping missing values \n\nplt.figure(figsize=(8, 4))\nsns.countplot(df['Churn'], palette='RdBu')\n\n# count number of obvs in each class\nNo,Yes = df['Churn'].value_counts()\nprint('Number of cells labeled yes: ', Yes)\nprint('Number of cells labeled no : ', No)\nprint('')\nprint('% of cells labeled churn', round(Yes / len(df) * 100, 2), '%')\nprint('% of cells labeled no churn', round(No / len(df) * 100, 2), '%')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt  # distribution is skewed & not normally distibuted of feature totalcharges \nimport seaborn as sns\nsns.distplot(df['TotalCharges'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['tenure']) # not normally distributed # not a proper bell shaped curve\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['MonthlyCharges'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Differences in Monthlycharges of churn and non churn customer using boxplot\nsns.boxplot(x ='Churn',y ='MonthlyCharges',data = df)\nplt.show()\n# there is much of a difference in monthly charges between churners and non-churners.\n# mean monthly charges of cust those are churn are higher ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Differences in tenure of churn and non churn customer using boxplot \n#There is a very noticeable difference here between churners and non-churners\n\nsns.boxplot(x ='Churn',y ='tenure',data = df)\nplt.show() \n\n#  there is much of a difference in tenure lengths between churners and non-churners.\n# mean length of tenure of cust those are churn cust is less as compared to No churn cust ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# there is noticeable diff in length of tenure ,those who streaming movies have long tenure\nsns.boxplot(x ='StreamingMovies',y ='tenure',data = df)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cust those have Fibre optic are more consist of churn cust as compare to services like DSL and No services\nsns.catplot(y=\"InternetService\", hue=\"Churn\", kind=\"count\",\n            palette=\"pastel\", edgecolor=\".6\",\n            data=df);\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# In month to Month contract the percentage of churn cust is more as comapre to one year and Two year , very less no cust churn in 2 yr contract\nsns.catplot(y=\"Contract\", hue=\"Churn\", kind=\"count\",\n            palette=\"pastel\", edgecolor=\".6\",\n            data=df);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add \"internet services\" as a third variable # for removing outlier can specify the additional parameter sym=\"\"\nsns.boxplot(x = 'Churn',\n            y = 'tenure',\n            data = df,\n            sym = \"\",\n            hue = \"InternetService\")\n\n# Display the plot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#obtaining correlation matrix\n\n#Tenure and Monthlycharges had highest correlation with TotalCharges \n\ncorr = df.corr().round(2)\n\n# Mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set figure size\nf, ax = plt.subplots(figsize=(20, 20))\n\n# Define custom colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap\nsns.heatmap(corr, mask=mask, cmap=cmap, vmin=-1, vmax=1, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True)\n\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data pre_processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Remove customer IDs from the data set # unneccessary variable \n\n# Drop the unnecessary features \n\ndf2 = df.drop(df[['SeniorCitizen','customerID']], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verify if features dropped\nprint(df2.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert Churn yes and no with 1,0 value \n# Replace 'no' with 0 and 'yes' with 1 in 'Churn'\ndf2['Churn'] = df2['Churn'].replace({'No':0 , 'Yes':1})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's convert all the categorical variables into dummy variables  \n# feature can be encoded numerically using the technique of one hot encoding:\n\ndf_new = pd.get_dummies(df2)\ndf_new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Feature scaling # different scales of the of tenure and charges and plots shown above not normally distributed \n#Centers the distribution around the mean\n#the number of standard deviations away from the mean each point is\n\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\ndf_new[['tenure','MonthlyCharges','TotalCharges']] = scaler.fit_transform(df_new[['tenure','MonthlyCharges','TotalCharges']].to_numpy())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# verifying first 5 rows \ndf_new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fit logistic regression model\n\n#Tunning parameter of c (Inverse of regularization strength;) and use of regularization technique l2 as penalty","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# target varaiable is y \ny = df_new['Churn'].values\n\n# predictor matrix is x\nx = df_new.drop(columns = ['Churn']) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using Skicit-learn to split data into training and testing sets\nfrom sklearn.model_selection import train_test_split\n# Split the data into training and testing sets\ntrain_x, test_x, train_y, test_y= train_test_split(x, y, test_size = 0.30, random_state = 200)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking the dimension of train and test dataset\ntrain_x.shape[0] \ntrain_y.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import required library for modelling \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import precision_score, recall_score\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Different value of paramter c in list and looping tuning parameter # getting different metrics \nC = [1, .5, .25, .1, .05, .025, .01, .005, .0025]\nl1_metrics = np.zeros((len(C), 5))\nl1_metrics[:,0] = C\nfor index in range(0, len(C)):  \n    logreg = LogisticRegression(penalty='l1', C=C[index], solver='liblinear')\n    logreg.fit(train_x, train_y)\n    pred_test_y = logreg.predict(test_x)\n    l1_metrics[index,1] = np.count_nonzero(logreg.coef_)\n    l1_metrics[index,2] = accuracy_score(test_y, pred_test_y)\n    l1_metrics[index,3] = precision_score(test_y, pred_test_y)\n    l1_metrics[index,4] = recall_score(test_y, pred_test_y) \ncol_names = ['C','Non-Zero Coeffs','Accuracy','Precision','Recall']\nprint(pd.DataFrame(l1_metrics, columns=col_names)) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Paramter C value 0.25 can be choose based on the business perfernces of precision and recall metrices\nMaximum accuracy attained with 26 non zero cofficients after that it decline"},{"metadata":{},"cell_type":"markdown","source":"# Use of SVM in modeling and tunning prameter"},{"metadata":{},"cell_type":"markdown","source":"#Large value of c : hard margin , forcing input data to explain potentially overfit\n\n#Gamma paramter : how far the training dataset reaches\n\n#large gamma : close training data pts have higher weight\n\n#small gamma : far reach more generalized"},{"metadata":{"trusted":true},"cell_type":"code","source":"# using support vector machine for modeling \nfrom sklearn.svm import SVC\nclassifier = SVC()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tuning paramter and kernel 'rbf'\nparam_grid = {'C':[0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001], 'kernel':['rbf']}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV # using gridsearch to find best parameter \n\ngrid = GridSearchCV(SVC(), param_grid, verbose= 4, refit=True)\ngrid.fit(train_x, train_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Best paramter \ngrid.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting prediction \noptimized_preds = grid.predict(test_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Evaluate the gridsearch SVM # Import accuracy_score\nfrom sklearn.metrics import accuracy_score\n\n# Compute test set accuracy  \nacc = accuracy_score(test_y,optimized_preds)\nprint(\"Test set accuracy: {:.2f}\".format(acc)) # test data accuracy is 80% ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# obtained different model metrices\nfrom sklearn.metrics import  classification_report\nprint(classification_report(test_y, optimized_preds))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}