{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install pyamg\n# import pyamg\nimport sys\nimport cv2\nimport time\nimport glob\nimport scipy.sparse\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom PIL import Image \nfrom torch import optim\nfrom torch.utils.data import TensorDataset, DataLoader, Dataset\nfrom torch.autograd.variable import Variable\nfrom torchvision import datasets, transforms","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-01T10:56:52.751402Z","iopub.execute_input":"2021-06-01T10:56:52.751878Z","iopub.status.idle":"2021-06-01T10:56:54.886244Z","shell.execute_reply.started":"2021-06-01T10:56:52.751816Z","shell.execute_reply":"2021-06-01T10:56:54.885265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device='cpu'\nBATCH_SIZE =1","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-06-01T10:56:54.890589Z","iopub.execute_input":"2021-06-01T10:56:54.890957Z","iopub.status.idle":"2021-06-01T10:56:54.895609Z","shell.execute_reply.started":"2021-06-01T10:56:54.890921Z","shell.execute_reply":"2021-06-01T10:56:54.894567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\npd.set_option('display.max_columns', 500)\n\ndef gen_mask(sample_batch, img_size):\n    np.random.seed(seed=int(time.time())) \n    masks = np.ones((sample_batch, img_size, img_size), dtype=np.float32)\n    scale = 0.25\n    low, upper = int(img_size * scale), int(img_size * (1.0 - scale))\n    masks[:, int(low*2.7):int(upper*1.2), low:upper] = 0.\n    return masks\n\n\nmask = gen_mask(1,23)\nprint(str(mask))","metadata":{"execution":{"iopub.status.busy":"2021-06-01T10:56:54.897008Z","iopub.execute_input":"2021-06-01T10:56:54.897287Z","iopub.status.idle":"2021-06-01T10:56:54.916654Z","shell.execute_reply.started":"2021-06-01T10:56:54.89726Z","shell.execute_reply":"2021-06-01T10:56:54.915567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rescale(image,image_size):\n    rescaled = np.resize(image,(image_size,image_size))\n    return torch.from_numpy(rescaled)","metadata":{"execution":{"iopub.status.busy":"2021-06-01T10:56:54.917917Z","iopub.execute_input":"2021-06-01T10:56:54.918196Z","iopub.status.idle":"2021-06-01T10:56:54.927415Z","shell.execute_reply.started":"2021-06-01T10:56:54.918169Z","shell.execute_reply":"2021-06-01T10:56:54.92637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folder_data = glob.glob(\"../input/beck-inpainting/WhatsApp Image 2021-06-01 at 12.48.32.jpeg\")\nlen_data = len(folder_data)\nprint(len_data)\n# i=4\n# test_image_paths = folder_data[i:BATCH_SIZE+i]\ntest_image_paths = folder_data[0:BATCH_SIZE]\n\n\n# folder_data = glob.glob(\"../input/ffhq-face-data-set/thumbnails128x128/*.png\")\n# folder_data = glob.glob(\"../input/matlam-imgs/*.jpg\")\n\nsize_of_train =len(folder_data)\ntest_image_paths = folder_data[size_of_train-16:size_of_train]\n\nprint(len(test_image_paths))\n\nclass TestDataset(Dataset):\n    def __init__(self, image_paths):\n        self.image_paths = image_paths\n        self.transforms = transforms.Compose([\n                                   transforms.Resize(150),\n                                   transforms.CenterCrop(128),\n                                   transforms.ToTensor(),\n#             0.485, 0.456, 0.406), (0.229, 0.224, 0.225)\n            \n                                  transforms.Normalize((0.2, 0.2, 0.2), (0.5, 0.5, 0.5)),\n            \n                               ])\n\n    def __getitem__(self, index):\n        image = Image.open(self.image_paths[index])\n        mask = gen_mask(1,128)\n        t_image = self.transforms(image)\n#         t_mask = self.scale(mask,64)\n        return t_image\n\n    def __len__(self):\n        return len(self.image_paths)","metadata":{"execution":{"iopub.status.busy":"2021-06-01T10:56:54.929525Z","iopub.execute_input":"2021-06-01T10:56:54.92983Z","iopub.status.idle":"2021-06-01T10:56:54.947821Z","shell.execute_reply.started":"2021-06-01T10:56:54.9298Z","shell.execute_reply":"2021-06-01T10:56:54.946962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = TestDataset(test_image_paths)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\nprint(len(test_loader))\nimport matplotlib.pyplot as plt\nprint(BATCH_SIZE)\nfor j, inputs in enumerate(test_loader):\n    for i in range(BATCH_SIZE):\n        plt.subplot(np.sqrt(BATCH_SIZE), np.sqrt(BATCH_SIZE), 1 + i)\n        plt.axis('off')\n        plt.imshow(np.transpose(inputs[i],(1,2,0)))","metadata":{"execution":{"iopub.status.busy":"2021-06-01T10:56:55.086468Z","iopub.execute_input":"2021-06-01T10:56:55.086796Z","iopub.status.idle":"2021-06-01T10:56:55.322866Z","shell.execute_reply.started":"2021-06-01T10:56:55.086768Z","shell.execute_reply":"2021-06-01T10:56:55.321747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_weights(masks,window_size):\n    assert (window_size+1)%2 == 0\n    pad_value = (window_size-1)/2\n    padded_masks = F.pad(1-masks, (int(pad_value),int(pad_value),int(pad_value),int(pad_value)), \"constant\", 0)\n    padded_masks.unsqueeze_(1)\n    kernel = torch.ones((window_size,window_size))\n    kernel = kernel.view(1, 1, window_size, window_size)\n    kernel = kernel.to(device)\n    temp = F.conv2d(padded_masks,kernel)\n    temp.squeeze_(1)\n    weights = (1/window_size)*torch.mul(temp,masks)\n    return weights\n\ndef context_loss(outputs,images):\n    batch_size = images.size()[0]\n#     W = get_weights(masks,window_size)\n    W = gen_mask(1,128)\n    W = np.tile(W,(3,1,1))\n    W = torch.from_numpy(W)\n    W.unsqueeze_(1)\n\n    print(W.shape)\n    plt.imshow(torch.mul(outputs-images,W).cpu().detach().numpy())\n\n#     W.unsqueeze_(1)\n#     W = torch.tensor(W)\n#     W = W.to(device)\n\n#     W = torch.cat((W,W,W),dim=1)\n#     torch.mul(outputs-images,W)\n#     plt.imshow(torch.mul(outputs-images,W).cpu().detach().numpy())\n#     closs = (1/batch_size)*(torch.sum(torch.abs(torch.mul(outputs-images,W))))\n    closs = (1/batch_size)*(torch.sum(torch.abs((outputs-images))))\n\n    return closs\n\ndef prior_loss(discriminator_outputs,Lambda):\n    batch_size = discriminator_outputs.size()[0]\n#     check accordign to the article\n    ones  = torch.ones_like(discriminator_outputs)\n    ploss = (1/batch_size)*(Lambda*torch.sum(torch.log(ones - discriminator_outputs)))\n    return ploss\n\ndef random_z(batch_size):\n#     Z = torch.randn((batch_size,100,1,1), requires_grad=True,device=\"cuda\")\n    Z = torch.randn((batch_size,100,1,1), requires_grad=True)\n    return Z","metadata":{"execution":{"iopub.status.busy":"2021-06-01T11:02:54.282003Z","iopub.execute_input":"2021-06-01T11:02:54.282469Z","iopub.status.idle":"2021-06-01T11:02:54.300277Z","shell.execute_reply.started":"2021-06-01T11:02:54.282427Z","shell.execute_reply":"2021-06-01T11:02:54.298873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Generator(torch.nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n        self.main = nn.Sequential(\n            nn.ConvTranspose2d(100, 1024, kernel_size = 4, stride = 1, padding = 0, bias = False),\n            nn.BatchNorm2d(1024),\n            nn.ReLU(inplace = True),\n\n            nn.ConvTranspose2d(1024, 512, kernel_size = 4, stride = 2, padding = 1, bias =False),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace = True),\n\n            nn.ConvTranspose2d(512, 256, kernel_size = 4, stride = 2, padding = 1, bias=False),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace = True),\n\n            nn.ConvTranspose2d(256, 128, kernel_size = 4, stride = 2, padding = 1, bias=False),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace = True),\n            \n            nn.ConvTranspose2d(128, 128, kernel_size = 4, stride = 2, padding = 1, bias=False),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace = True),\n\n            nn.ConvTranspose2d(128, 3, kernel_size = 4, stride = 2, padding = 1, bias=False),\n            nn.Tanh()\n        )\n        \n    def forward(self, x):\n            x = self.main(x)\n            return x\n\ngenerator = Generator()\ngenerator.float()\n# generator = generator.to(device)\nprint(generator)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-01T11:02:54.723612Z","iopub.execute_input":"2021-06-01T11:02:54.724048Z","iopub.status.idle":"2021-06-01T11:02:54.847709Z","shell.execute_reply.started":"2021-06-01T11:02:54.724013Z","shell.execute_reply":"2021-06-01T11:02:54.846331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Discriminator(torch.nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.main = nn.Sequential(\n          nn.Conv2d(3, 128, kernel_size = 5, stride = 2, padding = 2, bias = False),\n          nn.LeakyReLU(0.2, inplace=True),\n\n          nn.Conv2d(128, 128, kernel_size = 5, stride = 2, padding = 2, bias = False),\n          nn.BatchNorm2d(128),\n          nn.LeakyReLU(0.2, inplace=True),\n\n          nn.Conv2d(128, 256, kernel_size = 5, stride = 2, padding = 2, bias = False),\n          nn.BatchNorm2d(256),\n          nn.LeakyReLU(0.2, inplace=True),\n\n          nn.Conv2d(256, 512, kernel_size = 5, stride = 2, padding =2, bias = False),\n          nn.BatchNorm2d(512),\n          nn.LeakyReLU(0.2, inplace=True),\n\n          nn.Conv2d(512, 1024, kernel_size = 5, stride = 2, padding = 2, bias = False),\n          nn.BatchNorm2d(1024),\n          nn.LeakyReLU(0.2, inplace=True),\n\n          nn.Conv2d(1024, 1, kernel_size = 4, stride = 1, padding = 0, bias = False)\n        )\n    \n    def forward(self, x):\n        x = self.main(x)\n        return x\n\ndiscriminator = Discriminator()\ndiscriminator.float()\n# discriminator = discriminator.to(device)\nprint(discriminator)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-01T11:02:20.874837Z","iopub.execute_input":"2021-06-01T11:02:20.875234Z","iopub.status.idle":"2021-06-01T11:02:21.026748Z","shell.execute_reply.started":"2021-06-01T11:02:20.875201Z","shell.execute_reply":"2021-06-01T11:02:21.025778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator = Generator()\ngenerator.load_state_dict(torch.load(\"../input/gan128/g2_epoch-25.pth\", map_location=torch.device('cpu') ))\n# generator.load_state_dict(torch.load(\"../input/gan-64/g_celeb_epoch-40.pth\"))\n\ngenerator = generator.to(device)\ngenerator.eval()\nfor param in generator.parameters():\n    param.requires_grad = False\n\ndiscriminator = Discriminator()\ndiscriminator.load_state_dict(torch.load(\"../input/gan128/d2_epoch-25.pth\", map_location=torch.device('cpu') ))\n# discriminator.load_state_dict(torch.load(\"../input/gan-64/d_celeb_epoch-40.pth\"))\n\ndiscriminator = discriminator.to(device)\n\ndiscriminator.eval()\nfor param in discriminator.parameters():\n    param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2021-06-01T11:02:21.079735Z","iopub.execute_input":"2021-06-01T11:02:21.080107Z","iopub.status.idle":"2021-06-01T11:02:21.652161Z","shell.execute_reply.started":"2021-06-01T11:02:21.080075Z","shell.execute_reply":"2021-06-01T11:02:21.651224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import notebook,tqdm\n","metadata":{"execution":{"iopub.status.busy":"2021-06-01T11:02:21.653577Z","iopub.execute_input":"2021-06-01T11:02:21.65402Z","iopub.status.idle":"2021-06-01T11:02:21.657681Z","shell.execute_reply.started":"2021-06-01T11:02:21.653987Z","shell.execute_reply":"2021-06-01T11:02:21.656973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfor j, inputs in enumerate(test_loader):\n    for i in range(BATCH_SIZE):\n        plt.subplot(4, 4, 1 + i)\n        plt.axis('off')\n        plt.imshow(np.transpose(inputs[i],(1,2,0)))\n","metadata":{"execution":{"iopub.status.busy":"2021-06-01T11:02:21.658756Z","iopub.execute_input":"2021-06-01T11:02:21.659175Z","iopub.status.idle":"2021-06-01T11:02:21.75048Z","shell.execute_reply.started":"2021-06-01T11:02:21.65914Z","shell.execute_reply":"2021-06-01T11:02:21.749745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, images in tqdm(enumerate(test_loader), total=len(test_loader)):\n    losses = []\n    images = images.to(device)\n    Z = random_z(batch_size=BATCH_SIZE)\n    optimizer = optim.Adam([Z])\n    if (i+1)%10==0 or i==0:\n        print(\"Starting Training for Batch \"+str(i+1)+\"...\")\n    for iter in notebook.tqdm(range(8000)):\n        outputs = generator(Z)\n#         todo connect the outputs and the images\n        discriminator_outputs = discriminator(outputs)\n#         todo give more weight to the place without the mask\n        closs = context_loss(outputs,images)\n#         ploss = prior_loss(discriminator_outputs,Lambda=0.003)\n        ploss = prior_loss(discriminator_outputs,Lambda=20.003)\n        inpainting_loss = closs + ploss\n        optimizer.zero_grad()\n        inpainting_loss.backward()\n        optimizer.step()\n        losses.append(inpainting_loss)\n        if (i+1)%10==0 or i==0:\n            if (iter+1)%500==0:\n                print(\"Iteration No. = \"+str(iter+1))\n                print(\"Loss = \"+str(inpainting_loss))\n    if (i+1)%10==0 or i==0:\n        plt.figure(figsize=(10,5))\n        plt.title(\"Inpainting Loss During Training\")\n        plt.plot(losses)\n        plt.xlabel(\"iterations\")\n        plt.ylabel(\"Loss\")\n        plt.show()\n    Z_optimal = Z.detach()\n#     generated_images = generator(Z_optimal)\n#     generated_images = generated_images.detach().cpu().numpy()\n#     generated_images = np.transpose(generated_images,(0,2,3,1))\n#     generated_images = ((generated_images+1.)/2.)*255.\n#     generated_images = generated_images.astype(np.uint8)\n    \n    with torch.no_grad():\n        generated_images = generator(Z_optimal.detach())\n\n    for i in range(BATCH_SIZE):\n        plt.subplot(4, 4, 1 + i)\n#         plt.subplot(1, 1, 1 + i)\n        plt.axis('off')\n        plt.imshow(np.transpose(generated_images.cpu().numpy()[i],(1,2,0)))\n    plt.show()  \n\n\n#     for j in range(generated_images.shape[0]):\n#         inpainted_image = Image.fromarray(np.uint8(generated_images))\n#         inpainted_image.save(\"{}Inpainted_Image.png\".format(1+(i*generated_images.shape[0])+j),\"PNG\")","metadata":{"execution":{"iopub.status.busy":"2021-06-01T11:02:57.951587Z","iopub.execute_input":"2021-06-01T11:02:57.952037Z","iopub.status.idle":"2021-06-01T11:02:58.193974Z","shell.execute_reply.started":"2021-06-01T11:02:57.951997Z","shell.execute_reply":"2021-06-01T11:02:58.191788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    generated_images = generator(Z_optimal.detach())\n\ni=0\nfor j, inputs in enumerate(test_loader):\n    plt.imshow(np.transpose(generated_images.cpu().numpy()[j+i],(1,2,0)))\n    plt.show()  \n    plt.imshow(np.transpose(inputs[j+i],(1,2,0)))\n    plt.show()  \n\n# for i in range(BATCH_SIZE):\n#     plt.subplot(4, 1, 1 + i)\n#     plt.axis('off')\n#     plt.imshow(np.transpose(generated_images.cpu().numpy()[i],(1,2,0)))\n# plt.show()  \n","metadata":{"execution":{"iopub.status.busy":"2021-06-01T10:57:43.719265Z","iopub.status.idle":"2021-06-01T10:57:43.72034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfor j, inputs in enumerate(test_loader):\n    for i in range(BATCH_SIZE):\n        plt.subplot(1, 1, 1 + i)\n        plt.axis('off')\n        plt.imshow(np.transpose(inputs[i],(1,2,0)))\n\n#      plt.figure()\n#      plt.imshow(inputs[i].numpy())\n#      plt.show()\n# images, labels = dataiter.next()\n# plt.imshow(np.transpose(images[0].numpy(), (1, 2, 0)))\n\n# for i in range(16):\n#     plt.subplot(4, 4, 1 + i)\n#     plt.axis('off')\n#     plt.imshow(np.transpose(train_np[i],(1,2,0)))\n# plt.show()  \n","metadata":{"execution":{"iopub.status.busy":"2021-06-01T10:57:43.722042Z","iopub.status.idle":"2021-06-01T10:57:43.723064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}