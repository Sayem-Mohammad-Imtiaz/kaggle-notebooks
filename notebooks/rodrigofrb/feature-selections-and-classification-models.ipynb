{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#################################################################\n# MSc in Data Analytics - Dublin Institute of Technology\n# Machine Learning\n# Assignment - Task 1\n# Students: \n#     Rodrigo Bastos\n#     Murali Rajendran\n##################################################################\n\nimport pandas as pd\nimport numpy as np\nimport time\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nfrom sklearn.feature_selection import RFE\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#######################################\n# DATA PREPARATION\n#######################################\n\n# Import data into a dataframe\ndf = pd.read_csv('../input/weatherAUS.csv')\ndf.shape\n# Drop columns not applicable to the models to be created.\n# Resulting dataframe to be saved into a new variable (df2) to preserve the original data.\ndf2 = df.drop(['Date', 'Location', 'RISK_MM'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop rows with NA/Blanks/Nulls\ndf2 = df2.dropna()\ndf2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Re-code boolean variables into integers (0, 1 for No, Yes)\ndf2['RainToday'].replace('No', 0, inplace=True)\ndf2['RainToday'].replace('Yes', 1, inplace=True)\ndf2['RainTomorrow'].replace('No', 0, inplace=True)\ndf2['RainTomorrow'].replace('Yes', 1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create dummy variables from the categorical attributes.\n# Saving the resulting dataframe into a new variable (df3).\ndf3 = pd.get_dummies(df2)\ndf3.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the features from the target\nfeatures = df3.loc[:, df3.columns != 'RainTomorrow']\nscaler = MinMaxScaler(feature_range=[0, 1]) # Scale features between 0 and 1\nx = scaler.fit_transform(features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the target variable\ntarget = df3.loc[:,['RainTomorrow']].values\ny = np.ravel(target) # Converts vector into array to use in models.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Selection using Feature Importance from Random Forest Classifier\nmodel = RandomForestClassifier()\nmodel.fit(x, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save the feature scores into a dataframe and add the columns labels to it.\nrfc_fi = pd.DataFrame(model.feature_importances_).transpose()\nrfc_fi.columns = list(features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Re-Transpose the headed data and sort it by score (descending)\nrfc_scores = rfc_fi.transpose()\nrfc_scores.sort_values(0, ascending=False, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The list below shows that 17 out of 65 features have a score above 0.01\n# As a rule of thumb, we will use 20 as the number of features to use in subsequent feature selection techniques.\nrfc_scores.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Selection using Univariate Selection (Chi-squared)\nmodel = SelectKBest(score_func=chi2, k=20) # Using k = 20 due to results from Feature Importance from Random Forest Classifier.\nmodel.fit(x, y)\nnp.set_printoptions(precision=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Process feature scores into a sorted dataframe with the top 20 attributes.\nus_scores_df = pd.DataFrame(model.scores_).transpose()\nus_scores_df.columns = list(features)\nus_scores_df = us_scores_df.transpose()\nus_scores_df.sort_values(0, ascending=False, inplace = True)\nus_scores_df.head(20) # returns the top 20 attributes by score.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Selection using Recursive Feature Extraction\nmodel = LogisticRegression()\nrfe = RFE(model, 20)\nfit = rfe.fit(x, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Process resulting scores into a dataframe with the selected 20 features.\nrfe_scores_df = pd.DataFrame(fit.support_).transpose()\nrfe_scores_df.columns = list(features)\nrfe_scores_df = rfe_scores_df.transpose()\nrfe_scores_df.sort_values(0, ascending=False, inplace = True)\nrfe_scores_df.head(20) # returns the top 20 attributes by score.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract the top 20 headers from the results of the 3 techniques\nrfe_features = list(rfe_scores_df.head(20).transpose())\nrfc_features = list(rfc_scores.head(20).transpose())\nus_features = list(us_scores_df.head(20).transpose())\n# Combine the results from the 3 techniques, and get the unique values.\ncombo_features = np.unique(np.array(rfe_features + rfc_features + us_features))\n# The above analysis resulted in a list of 34 headers to be extracted from\n# the pool of 65 features of the original dataset.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Convert scaled features (array) into dataframe\nfeatures_df = pd.DataFrame(x)\nfeatures_df.columns = list(features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the original dataset between Training and Test sets at a ratio of 70/30\nmaster_x_train, master_x_test, master_y_train, master_y_test = train_test_split(features_df, target, test_size =0.3, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get train/test subsets based on results of 3 feature selection techniques.\ny_train = np.ravel(master_y_train)\ny_test = np.ravel(master_y_test)\nrfe_x_train = master_x_train[rfe_features]\nrfe_x_test = master_x_test[rfe_features]\nrfc_x_train= master_x_train[rfc_features]\nrfc_x_test= master_x_test[rfc_features]\nus_x_train= master_x_train[us_features]\nus_x_test= master_x_test[us_features]\ncombo_x_train= master_x_train[combo_features]\ncombo_x_test= master_x_test[combo_features]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"############################################\n# MODEL CREATION, TRAINING AND EVALUATION\n############################################\n\n# Function to output model metrics for comparison.\ndef EvaluateModel(model, x_test, y_test):\n    print(\"Accuracy:  {}\".format(model.score(x_test, y_test)))\n    print(\"Precision: {}\".format(precision_score(y_test, model.predict(x_test))))\n    print(\"Recall:    {}\".format(recall_score(y_test, model.predict(x_test), average='macro')))\n    print(\"ROC AUC:   {}\".format(roc_auc_score(y_test, model.predict_proba(x_test)[:,1])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to Train and Evaluate a given model and a set of data.\ndef BuildAndEvaluateModel(model, x_train, y_train, x_test, y_test):\n    print('')\n    start_time = time.time()\n    print('Training Model...')\n    model.fit(x_train, y_train)\n    print('Model Trained... Evaluating... Duration so far: ' + str(time.time() - start_time))\n    EvaluateModel(model, x_test, y_test)\n    end_time = time.time()\n    print('Done! Total Duration: ' + str(end_time - start_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic Regression Model\nlr = LogisticRegression(solver = 'liblinear')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BuildAndEvaluateModel(lr, master_x_train, y_train, master_x_test, y_test)\nBuildAndEvaluateModel(lr, rfe_x_train, y_train, rfe_x_test, y_test)\nBuildAndEvaluateModel(lr, rfc_x_train, y_train, rfc_x_test, y_test)\nBuildAndEvaluateModel(lr, us_x_train, y_train, us_x_test, y_test)\nBuildAndEvaluateModel(lr, combo_x_train, y_train, combo_x_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decision Tree Model\ndt = DecisionTreeClassifier(criterion = \"gini\", random_state = 100, max_depth=6, min_samples_leaf=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BuildAndEvaluateModel(dt, master_x_train, y_train, master_x_test, y_test)\nBuildAndEvaluateModel(dt, rfe_x_train, y_train, rfe_x_test, y_test)\nBuildAndEvaluateModel(dt, rfc_x_train, y_train, rfc_x_test, y_test)\nBuildAndEvaluateModel(dt, us_x_train, y_train, us_x_test, y_test)\nBuildAndEvaluateModel(dt, combo_x_train, y_train, combo_x_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Support Vector Machine Model\nsvm = SVC(gamma = 'auto', probability = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Warning: Long training times\n# Over 30 minutes on an i5 processor and 8gb ram\nBuildAndEvaluateModel(svm, master_x_train, y_train, master_x_test, y_test)\nBuildAndEvaluateModel(svm, rfe_x_train, y_train, rfe_x_test, y_test)\nBuildAndEvaluateModel(svm, rfc_x_train, y_train, rfc_x_test, y_test)\nBuildAndEvaluateModel(svm, us_x_train, y_train, us_x_test, y_test)\nBuildAndEvaluateModel(svm, combo_x_train, y_train, combo_x_test, y_test)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":1}