{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"['abcnews-date-text.csv']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\n\ndata = pd.read_csv('../input/abcnews-date-text.csv', error_bad_lines=False);\ndata_text = data[['headline_text']]\ndata_text['index'] = data_text.index\ndocuments = data_text","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(documents)","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"1103663"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"documents[:5]","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"                                       headline_text  index\n0  aba decides against community broadcasting lic...      0\n1     act fire witnesses must be aware of defamation      1\n2     a g calls for infrastructure protection summit      2\n3           air nz staff in aust strike for pay rise      3\n4      air nz strike to affect australian travellers      4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>headline_text</th>\n      <th>index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>aba decides against community broadcasting lic...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>act fire witnesses must be aware of defamation</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a g calls for infrastructure protection summit</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>air nz staff in aust strike for pay rise</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>air nz strike to affect australian travellers</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gensim\nfrom gensim.utils import simple_preprocess\nfrom gensim.parsing.preprocessing import STOPWORDS\nfrom nltk.stem import WordNetLemmatizer, SnowballStemmer\nfrom nltk.stem.porter import *\nimport numpy as np\nnp.random.seed(0)","execution_count":5,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/smart_open/ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(WordNetLemmatizer().lemmatize('went', pos='v'))","execution_count":7,"outputs":[{"output_type":"stream","text":"go\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"stemmer = SnowballStemmer('english')\noriginal_words = ['caresses', 'flies', 'dies', 'mules', 'denied','died', 'agreed', 'owned', \n           'humbled', 'sized','meeting', 'stating', 'siezing', 'itemization','sensational', \n           'traditional', 'reference', 'colonizer','plotted']\nsingles = [stemmer.stem(plural) for plural in original_words]\npd.DataFrame(data = {'original word': original_words, 'stemmed': singles})","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"   original word stemmed\n0       caresses  caress\n1          flies     fli\n2           dies     die\n3          mules    mule\n4         denied    deni\n5           died     die\n6         agreed    agre\n7          owned     own\n8        humbled   humbl\n9          sized    size\n10       meeting    meet\n11       stating   state\n12       siezing    siez\n13   itemization    item\n14   sensational  sensat\n15   traditional  tradit\n16     reference   refer\n17     colonizer   colon\n18       plotted    plot","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>original word</th>\n      <th>stemmed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>caresses</td>\n      <td>caress</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>flies</td>\n      <td>fli</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>dies</td>\n      <td>die</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>mules</td>\n      <td>mule</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>denied</td>\n      <td>deni</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>died</td>\n      <td>die</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>agreed</td>\n      <td>agre</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>owned</td>\n      <td>own</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>humbled</td>\n      <td>humbl</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>sized</td>\n      <td>size</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>meeting</td>\n      <td>meet</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>stating</td>\n      <td>state</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>siezing</td>\n      <td>siez</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>itemization</td>\n      <td>item</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>sensational</td>\n      <td>sensat</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>traditional</td>\n      <td>tradit</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>reference</td>\n      <td>refer</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>colonizer</td>\n      <td>colon</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>plotted</td>\n      <td>plot</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def lemmatize_stemming(text):\n    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n\ndef preprocess(text):\n    result = []\n    for token in gensim.utils.simple_preprocess(text):\n        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n            result.append(lemmatize_stemming(token))\n    return result","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"doc_sample = documents[documents['index'] == 4310].values[0][0]\n\nprint('original document: ')\nwords = []\nfor word in doc_sample.split(' '):\n    words.append(word)\nprint(words)\nprint('\\n\\n tokenized and lemmatized document: ')\nprint(preprocess(doc_sample))","execution_count":10,"outputs":[{"output_type":"stream","text":"original document: \n['rain', 'helps', 'dampen', 'bushfires']\n\n\n tokenized and lemmatized document: \n['rain', 'help', 'dampen', 'bushfir']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"processed_docs = documents['headline_text'].map(preprocess)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"processed_docs[:10]","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"0            [decid, communiti, broadcast, licenc]\n1                               [wit, awar, defam]\n2           [call, infrastructur, protect, summit]\n3                      [staff, aust, strike, rise]\n4             [strike, affect, australian, travel]\n5               [ambiti, olsson, win, tripl, jump]\n6           [antic, delight, record, break, barca]\n7    [aussi, qualifi, stosur, wast, memphi, match]\n8            [aust, address, secur, council, iraq]\n9                         [australia, lock, timet]\nName: headline_text, dtype: object"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"dictionary = gensim.corpora.Dictionary(processed_docs)","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count = 0\nfor k, v in dictionary.iteritems():\n    print(k, v)\n    count += 1\n    if count > 10:\n        break","execution_count":14,"outputs":[{"output_type":"stream","text":"0 broadcast\n1 communiti\n2 decid\n3 licenc\n4 awar\n5 defam\n6 wit\n7 call\n8 infrastructur\n9 protect\n10 summit\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\nbow_corpus[4310]","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"[(76, 1), (112, 1), (483, 1), (4014, 1)]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"bow_doc_4310 = bow_corpus[4310]\n\nfor i in range(len(bow_doc_4310)):\n    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_4310[i][0], \n                                                     dictionary[bow_doc_4310[i][0]], \n                                                     bow_doc_4310[i][1]))","execution_count":17,"outputs":[{"output_type":"stream","text":"Word 76 (\"bushfir\") appears 1 time.\nWord 112 (\"help\") appears 1 time.\nWord 483 (\"rain\") appears 1 time.\nWord 4014 (\"dampen\") appears 1 time.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from gensim import corpora, models\n\ntfidf = models.TfidfModel(bow_corpus)","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corpus_tfidf = tfidf[bow_corpus]","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pprint import pprint\n\nfor doc in corpus_tfidf:\n    pprint(doc)\n    break","execution_count":20,"outputs":[{"output_type":"stream","text":"[(0, 0.5892908867507543),\n (1, 0.38929654337861147),\n (2, 0.4964985175717023),\n (3, 0.5046520327464028)]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for idx, topic in lda_model.print_topics(-1):\n    print('Topic: {} \\nWords: {}'.format(idx, topic))","execution_count":22,"outputs":[{"output_type":"stream","text":"Topic: 0 \nWords: 0.035*\"say\" + 0.031*\"govern\" + 0.020*\"chang\" + 0.016*\"rural\" + 0.013*\"minist\" + 0.012*\"farmer\" + 0.011*\"support\" + 0.011*\"need\" + 0.011*\"labor\" + 0.010*\"feder\"\nTopic: 1 \nWords: 0.034*\"trump\" + 0.026*\"melbourn\" + 0.019*\"world\" + 0.018*\"countri\" + 0.011*\"abus\" + 0.010*\"game\" + 0.010*\"victorian\" + 0.009*\"liber\" + 0.009*\"race\" + 0.008*\"presid\"\nTopic: 2 \nWords: 0.030*\"charg\" + 0.028*\"court\" + 0.025*\"elect\" + 0.024*\"polic\" + 0.023*\"death\" + 0.022*\"murder\" + 0.018*\"face\" + 0.016*\"alleg\" + 0.016*\"interview\" + 0.015*\"woman\"\nTopic: 3 \nWords: 0.018*\"coast\" + 0.014*\"donald\" + 0.013*\"rise\" + 0.012*\"price\" + 0.012*\"gold\" + 0.011*\"victoria\" + 0.010*\"health\" + 0.010*\"budget\" + 0.010*\"centr\" + 0.010*\"farm\"\nTopic: 4 \nWords: 0.067*\"australia\" + 0.035*\"australian\" + 0.028*\"south\" + 0.027*\"kill\" + 0.020*\"attack\" + 0.018*\"hour\" + 0.017*\"west\" + 0.011*\"record\" + 0.011*\"drum\" + 0.009*\"weather\"\nTopic: 5 \nWords: 0.024*\"nation\" + 0.021*\"call\" + 0.019*\"plan\" + 0.015*\"water\" + 0.014*\"state\" + 0.012*\"park\" + 0.011*\"releas\" + 0.011*\"prison\" + 0.010*\"children\" + 0.010*\"review\"\nTopic: 6 \nWords: 0.033*\"sydney\" + 0.029*\"queensland\" + 0.021*\"crash\" + 0.021*\"canberra\" + 0.019*\"die\" + 0.018*\"brisban\" + 0.018*\"final\" + 0.018*\"live\" + 0.014*\"turnbul\" + 0.013*\"concern\"\nTopic: 7 \nWords: 0.040*\"year\" + 0.027*\"adelaid\" + 0.015*\"hous\" + 0.015*\"life\" + 0.014*\"fall\" + 0.013*\"near\" + 0.013*\"sentenc\" + 0.011*\"young\" + 0.010*\"refuge\" + 0.010*\"island\"\nTopic: 8 \nWords: 0.034*\"polic\" + 0.024*\"home\" + 0.023*\"warn\" + 0.020*\"china\" + 0.017*\"north\" + 0.015*\"leagu\" + 0.013*\"shoot\" + 0.013*\"talk\" + 0.012*\"hold\" + 0.012*\"test\"\nTopic: 9 \nWords: 0.021*\"open\" + 0.020*\"market\" + 0.018*\"women\" + 0.017*\"miss\" + 0.016*\"australian\" + 0.016*\"tasmania\" + 0.014*\"time\" + 0.014*\"share\" + 0.013*\"break\" + 0.012*\"busi\"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for idx, topic in lda_model_tfidf.print_topics(-1):\n    print('Topic: {} Word: {}'.format(idx, topic))","execution_count":24,"outputs":[{"output_type":"stream","text":"Topic: 0 Word: 0.009*\"ash\" + 0.008*\"david\" + 0.007*\"thursday\" + 0.007*\"festiv\" + 0.006*\"toni\" + 0.006*\"andrew\" + 0.006*\"scott\" + 0.005*\"interview\" + 0.005*\"wallabi\" + 0.005*\"william\"\nTopic: 1 Word: 0.012*\"drum\" + 0.011*\"elect\" + 0.011*\"christma\" + 0.008*\"refuge\" + 0.007*\"asylum\" + 0.007*\"stori\" + 0.007*\"tuesday\" + 0.006*\"labor\" + 0.006*\"seeker\" + 0.006*\"island\"\nTopic: 2 Word: 0.018*\"charg\" + 0.018*\"polic\" + 0.015*\"murder\" + 0.011*\"court\" + 0.011*\"woman\" + 0.010*\"death\" + 0.010*\"alleg\" + 0.010*\"jail\" + 0.009*\"assault\" + 0.009*\"shoot\"\nTopic: 3 Word: 0.012*\"interview\" + 0.009*\"leagu\" + 0.008*\"australia\" + 0.008*\"hobart\" + 0.008*\"world\" + 0.008*\"final\" + 0.007*\"miss\" + 0.007*\"search\" + 0.006*\"beat\" + 0.006*\"rugbi\"\nTopic: 4 Word: 0.024*\"trump\" + 0.014*\"queensland\" + 0.012*\"weather\" + 0.011*\"donald\" + 0.010*\"south\" + 0.009*\"north\" + 0.008*\"korea\" + 0.007*\"friday\" + 0.006*\"cyclon\" + 0.006*\"smith\"\nTopic: 5 Word: 0.012*\"child\" + 0.010*\"royal\" + 0.009*\"abus\" + 0.009*\"sport\" + 0.007*\"commiss\" + 0.007*\"marriag\" + 0.007*\"juli\" + 0.006*\"student\" + 0.006*\"peter\" + 0.006*\"mark\"\nTopic: 6 Word: 0.013*\"kill\" + 0.013*\"crash\" + 0.010*\"dead\" + 0.008*\"die\" + 0.008*\"climat\" + 0.007*\"august\" + 0.007*\"care\" + 0.006*\"syria\" + 0.005*\"suicid\" + 0.005*\"social\"\nTopic: 7 Word: 0.026*\"countri\" + 0.024*\"hour\" + 0.012*\"podcast\" + 0.011*\"turnbul\" + 0.008*\"violenc\" + 0.007*\"octob\" + 0.007*\"domest\" + 0.007*\"malcolm\" + 0.006*\"mount\" + 0.006*\"grand\"\nTopic: 8 Word: 0.009*\"govern\" + 0.008*\"fund\" + 0.007*\"health\" + 0.007*\"budget\" + 0.006*\"servic\" + 0.006*\"plan\" + 0.005*\"council\" + 0.005*\"indigen\" + 0.005*\"say\" + 0.005*\"septemb\"\nTopic: 9 Word: 0.016*\"rural\" + 0.014*\"market\" + 0.012*\"news\" + 0.010*\"price\" + 0.008*\"share\" + 0.007*\"farmer\" + 0.007*\"farm\" + 0.007*\"rise\" + 0.006*\"dollar\" + 0.006*\"busi\"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"processed_docs[4310]","execution_count":25,"outputs":[{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"['rain', 'help', 'dampen', 'bushfir']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for index, score in sorted(lda_model[bow_corpus[4310]], key=lambda tup: -1*tup[1]):\n    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))","execution_count":26,"outputs":[{"output_type":"stream","text":"\nScore: 0.8199616074562073\t \nTopic: 0.040*\"year\" + 0.027*\"adelaid\" + 0.015*\"hous\" + 0.015*\"life\" + 0.014*\"fall\" + 0.013*\"near\" + 0.013*\"sentenc\" + 0.011*\"young\" + 0.010*\"refuge\" + 0.010*\"island\"\n\nScore: 0.02000613324344158\t \nTopic: 0.024*\"nation\" + 0.021*\"call\" + 0.019*\"plan\" + 0.015*\"water\" + 0.014*\"state\" + 0.012*\"park\" + 0.011*\"releas\" + 0.011*\"prison\" + 0.010*\"children\" + 0.010*\"review\"\n\nScore: 0.02000543288886547\t \nTopic: 0.035*\"say\" + 0.031*\"govern\" + 0.020*\"chang\" + 0.016*\"rural\" + 0.013*\"minist\" + 0.012*\"farmer\" + 0.011*\"support\" + 0.011*\"need\" + 0.011*\"labor\" + 0.010*\"feder\"\n\nScore: 0.02000490389764309\t \nTopic: 0.018*\"coast\" + 0.014*\"donald\" + 0.013*\"rise\" + 0.012*\"price\" + 0.012*\"gold\" + 0.011*\"victoria\" + 0.010*\"health\" + 0.010*\"budget\" + 0.010*\"centr\" + 0.010*\"farm\"\n\nScore: 0.02000461146235466\t \nTopic: 0.033*\"sydney\" + 0.029*\"queensland\" + 0.021*\"crash\" + 0.021*\"canberra\" + 0.019*\"die\" + 0.018*\"brisban\" + 0.018*\"final\" + 0.018*\"live\" + 0.014*\"turnbul\" + 0.013*\"concern\"\n\nScore: 0.02000376582145691\t \nTopic: 0.021*\"open\" + 0.020*\"market\" + 0.018*\"women\" + 0.017*\"miss\" + 0.016*\"australian\" + 0.016*\"tasmania\" + 0.014*\"time\" + 0.014*\"share\" + 0.013*\"break\" + 0.012*\"busi\"\n\nScore: 0.020003680139780045\t \nTopic: 0.030*\"charg\" + 0.028*\"court\" + 0.025*\"elect\" + 0.024*\"polic\" + 0.023*\"death\" + 0.022*\"murder\" + 0.018*\"face\" + 0.016*\"alleg\" + 0.016*\"interview\" + 0.015*\"woman\"\n\nScore: 0.020003486424684525\t \nTopic: 0.034*\"trump\" + 0.026*\"melbourn\" + 0.019*\"world\" + 0.018*\"countri\" + 0.011*\"abus\" + 0.010*\"game\" + 0.010*\"victorian\" + 0.009*\"liber\" + 0.009*\"race\" + 0.008*\"presid\"\n\nScore: 0.020003193989396095\t \nTopic: 0.067*\"australia\" + 0.035*\"australian\" + 0.028*\"south\" + 0.027*\"kill\" + 0.020*\"attack\" + 0.018*\"hour\" + 0.017*\"west\" + 0.011*\"record\" + 0.011*\"drum\" + 0.009*\"weather\"\n\nScore: 0.020003193989396095\t \nTopic: 0.034*\"polic\" + 0.024*\"home\" + 0.023*\"warn\" + 0.020*\"china\" + 0.017*\"north\" + 0.015*\"leagu\" + 0.013*\"shoot\" + 0.013*\"talk\" + 0.012*\"hold\" + 0.012*\"test\"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for index, score in sorted(lda_model_tfidf[bow_corpus[4310]], key=lambda tup: -1*tup[1]):\n    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))","execution_count":27,"outputs":[{"output_type":"stream","text":"\nScore: 0.5796586275100708\t \nTopic: 0.026*\"countri\" + 0.024*\"hour\" + 0.012*\"podcast\" + 0.011*\"turnbul\" + 0.008*\"violenc\" + 0.007*\"octob\" + 0.007*\"domest\" + 0.007*\"malcolm\" + 0.006*\"mount\" + 0.006*\"grand\"\n\nScore: 0.2602965235710144\t \nTopic: 0.016*\"rural\" + 0.014*\"market\" + 0.012*\"news\" + 0.010*\"price\" + 0.008*\"share\" + 0.007*\"farmer\" + 0.007*\"farm\" + 0.007*\"rise\" + 0.006*\"dollar\" + 0.006*\"busi\"\n\nScore: 0.020007964223623276\t \nTopic: 0.009*\"govern\" + 0.008*\"fund\" + 0.007*\"health\" + 0.007*\"budget\" + 0.006*\"servic\" + 0.006*\"plan\" + 0.005*\"council\" + 0.005*\"indigen\" + 0.005*\"say\" + 0.005*\"septemb\"\n\nScore: 0.02000744268298149\t \nTopic: 0.024*\"trump\" + 0.014*\"queensland\" + 0.012*\"weather\" + 0.011*\"donald\" + 0.010*\"south\" + 0.009*\"north\" + 0.008*\"korea\" + 0.007*\"friday\" + 0.006*\"cyclon\" + 0.006*\"smith\"\n\nScore: 0.020005596801638603\t \nTopic: 0.018*\"charg\" + 0.018*\"polic\" + 0.015*\"murder\" + 0.011*\"court\" + 0.011*\"woman\" + 0.010*\"death\" + 0.010*\"alleg\" + 0.010*\"jail\" + 0.009*\"assault\" + 0.009*\"shoot\"\n\nScore: 0.02000546082854271\t \nTopic: 0.013*\"kill\" + 0.013*\"crash\" + 0.010*\"dead\" + 0.008*\"die\" + 0.008*\"climat\" + 0.007*\"august\" + 0.007*\"care\" + 0.006*\"syria\" + 0.005*\"suicid\" + 0.005*\"social\"\n\nScore: 0.020005183294415474\t \nTopic: 0.012*\"drum\" + 0.011*\"elect\" + 0.011*\"christma\" + 0.008*\"refuge\" + 0.007*\"asylum\" + 0.007*\"stori\" + 0.007*\"tuesday\" + 0.006*\"labor\" + 0.006*\"seeker\" + 0.006*\"island\"\n\nScore: 0.02000465616583824\t \nTopic: 0.012*\"child\" + 0.010*\"royal\" + 0.009*\"abus\" + 0.009*\"sport\" + 0.007*\"commiss\" + 0.007*\"marriag\" + 0.007*\"juli\" + 0.006*\"student\" + 0.006*\"peter\" + 0.006*\"mark\"\n\nScore: 0.020004598423838615\t \nTopic: 0.012*\"interview\" + 0.009*\"leagu\" + 0.008*\"australia\" + 0.008*\"hobart\" + 0.008*\"world\" + 0.008*\"final\" + 0.007*\"miss\" + 0.007*\"search\" + 0.006*\"beat\" + 0.006*\"rugbi\"\n\nScore: 0.020003939047455788\t \nTopic: 0.009*\"ash\" + 0.008*\"david\" + 0.007*\"thursday\" + 0.007*\"festiv\" + 0.006*\"toni\" + 0.006*\"andrew\" + 0.006*\"scott\" + 0.005*\"interview\" + 0.005*\"wallabi\" + 0.005*\"william\"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"unseen_document = 'How a Pentagon deal became an identity crisis for Google'\nbow_vector = dictionary.doc2bow(preprocess(unseen_document))\n\nfor index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))","execution_count":28,"outputs":[{"output_type":"stream","text":"Score: 0.3502257168292999\t Topic: 0.021*\"open\" + 0.020*\"market\" + 0.018*\"women\" + 0.017*\"miss\" + 0.016*\"australian\"\nScore: 0.18345728516578674\t Topic: 0.034*\"polic\" + 0.024*\"home\" + 0.023*\"warn\" + 0.020*\"china\" + 0.017*\"north\"\nScore: 0.18333959579467773\t Topic: 0.033*\"sydney\" + 0.029*\"queensland\" + 0.021*\"crash\" + 0.021*\"canberra\" + 0.019*\"die\"\nScore: 0.18289288878440857\t Topic: 0.024*\"nation\" + 0.021*\"call\" + 0.019*\"plan\" + 0.015*\"water\" + 0.014*\"state\"\nScore: 0.016682447865605354\t Topic: 0.035*\"say\" + 0.031*\"govern\" + 0.020*\"chang\" + 0.016*\"rural\" + 0.013*\"minist\"\nScore: 0.016680413857102394\t Topic: 0.034*\"trump\" + 0.026*\"melbourn\" + 0.019*\"world\" + 0.018*\"countri\" + 0.011*\"abus\"\nScore: 0.016680413857102394\t Topic: 0.030*\"charg\" + 0.028*\"court\" + 0.025*\"elect\" + 0.024*\"polic\" + 0.023*\"death\"\nScore: 0.016680413857102394\t Topic: 0.018*\"coast\" + 0.014*\"donald\" + 0.013*\"rise\" + 0.012*\"price\" + 0.012*\"gold\"\nScore: 0.016680413857102394\t Topic: 0.067*\"australia\" + 0.035*\"australian\" + 0.028*\"south\" + 0.027*\"kill\" + 0.020*\"attack\"\nScore: 0.016680413857102394\t Topic: 0.040*\"year\" + 0.027*\"adelaid\" + 0.015*\"hous\" + 0.015*\"life\" + 0.014*\"fall\"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}