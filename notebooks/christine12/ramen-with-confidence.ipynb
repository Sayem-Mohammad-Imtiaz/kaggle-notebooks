{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Tasty Statistics\n\nRecently I started with a Statistics in Python course on coursera. Instead of only learning from the examples provided in the course, I wanted to explore and apply the methods on my own.\nMost of statistics examples I cover serious topics that require complete accuracy when applying statiscal methods, like medical tests, systematic racism and politics. As a newbee, I am too afraid to jump to conclusions too quickly and spread an opinion without having my tools sharpened properly.\nSo I wanted to find data, that doesn't hurt and that is so highly subjective, that everybody can have an opinion about. Ramen became one of my favorite dishes lately, so I thought, why not look at that.\nSo here it comes, the Ramen with confidence statistics.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Prep","metadata":{}},{"cell_type":"code","source":"# Importing the data\nramen_df = pd.read_csv('/kaggle/input/ramen-ratings/ramen-ratings.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Looking at the data\nramen_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ramen_df.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ramen_df['Stars'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ramen_df[ramen_df['Stars'] == 'Unrated'].count()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I got an error, when I tried to convert Stars to float. In the dataset are 3 occurences of \"Unrated\" as Stars. So I feel comfortable to remove those. ","metadata":{}},{"cell_type":"code","source":"ramen_df = ramen_df[ramen_df['Stars'] != 'Unrated']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ramen_df[\"Stars\"] = ramen_df.Stars.astype(float)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ramen_df['Country'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_df = ramen_df.groupby('Country').count()[\"Brand\"]\ncount_df.sort_values(ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's have a look at the \"Top Ten\" column. We see that the rank values are not complete for all the years. That can mean that our data set is not complete and we need to be careful when drawing conclusions from this column. ","metadata":{}},{"cell_type":"code","source":"ramen_df[ramen_df['Top Ten'].notna()][['Country', 'Top Ten']].sort_values('Top Ten')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"___________________________________________________________","metadata":{}},{"cell_type":"markdown","source":"So now we know our data set a bit better. \n**What can we actually explore here? **\n\nI want to see if there a significant difference in ramen ratings of the two big ramen producers Japan (352) and USA (323). \n\nFor that I want to check that the mean value of ratings are similar in for both countries.\n\nHypothesis: mean(japan_ratings) == mean(usa_ratings)\n","metadata":{}},{"cell_type":"markdown","source":"For that I firstly extract the data for Japan and USA Ramen. Since there are different styles of ramen and I want to compare apples with apples, I select the most represented style from each data set.","metadata":{}},{"cell_type":"code","source":"japan_ramen_df = ramen_df[ramen_df['Country'] == 'Japan']\nusa_ramen_df = ramen_df[ramen_df['Country'] == 'USA']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are different styles of ramen and I want to compare apples with apples and see how many reviews there are for each style for the 2 countries. In this case this is style \"Pack\" ","metadata":{}},{"cell_type":"code","source":"japan_ramen_df.groupby('Style')['Review #'].nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"usa_ramen_df.groupby('Style')['Review #'].nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Bowl, Cup and Pack look like the ones we can look at, since they have a high number of reviews. ","metadata":{}},{"cell_type":"code","source":"japan_bowl_df = japan_ramen_df[japan_ramen_df['Style'] == 'Bowl']\njapan_pack_df = japan_ramen_df[japan_ramen_df['Style'] == 'Pack']\njapan_cup_df = japan_ramen_df[japan_ramen_df['Style']  == 'Cup']\njapan_cup_df.head(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"usa_bowl_df = usa_ramen_df[usa_ramen_df['Style'] == 'Bowl']\nusa_pack_df = usa_ramen_df[usa_ramen_df['Style'] == 'Pack']\nusa_cup_df = usa_ramen_df[usa_ramen_df['Style']  == 'Cup']\nusa_cup_df.head(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The Analysis","metadata":{}},{"cell_type":"markdown","source":"Null hypothesis: \n\nThere is no difference between mean ratings\nmean(Japan) - mean(USA) = 0\n\n\nAlternative hypthesis: \n\nThere is a significant difference between mean ratings \n\n\nWe assume that the two samples (ratings in Japan and ratings in the USA) are random and independent from each other.\n\nWe set the confidence intervall to **95%** which means that our significance level is at **0.05** \n\n","metadata":{}},{"cell_type":"markdown","source":"## Boxplot of ratings Japan vs USA ","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfig1, ax1 = plt.subplots()\nax1.set_title('Ratings Ramen Pack')\nlabels = ['Japan', 'USA']\nax1.boxplot([japan_pack_df['Stars'],usa_pack_df['Stars']], labels=labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Distribution of ratings ","metadata":{}},{"cell_type":"code","source":"fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n\n# We can set the number of bins with the `bins` kwarg\naxs[0].hist(japan_pack_df['Stars'], bins=5)\naxs[0].set_title('Ratings Ramen Pack Japan')\naxs[1].hist(usa_pack_df['Stars'], bins=5)\naxs[1].set_title('Ratings Ramen Pack USA')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"japan_pack_df['Stars'].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"usa_pack_df['Stars'].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"japan_mean_ratings = japan_pack_df['Stars'].mean()\nusa_mean_ratings = usa_pack_df['Stars'].mean()\nprint(japan_mean_ratings, usa_mean_ratings)\n\nbest_estimate = japan_mean_ratings - usa_mean_ratings\nprint(best_estimate)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Is that mean significantly different than zero?\n\nThe standard deviations are similar enough, so that we can use the pooled approach\n\ntest_statistic = $\\frac{best estimate - null value}{estimated standard error}$\n\n\n**Unpooled test statistics**\n\n$stderror_{estimated} = \\sqrt{\\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2 }{n_1 + n_2 - 2}} \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}$\n\n","metadata":{}},{"cell_type":"markdown","source":"test_statistic = $\\frac{x1_{mean} - x2_{mean} - 0}{stderror_{estimated}}$","metadata":{}},{"cell_type":"code","source":"n1 = japan_pack_df['Stars'].count()\nn2 = usa_pack_df['Stars'].count()\nprint(n1, n2)\n\ns1 = japan_pack_df['Stars'].std()\ns2 = usa_pack_df['Stars'].std()\nprint(s1, s2)\n\ntest_statistic = (japan_mean_ratings - usa_mean_ratings)\ntest_statistic /= np.sqrt( ((n1 - 1)* s1**2 + (n2 -1)*s2**2) / (n1 + n2 -2) )\ntest_statistic /= np.sqrt(1/n1 + 1/n2)\ntest_statistic","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If the null hypothesis were true, would a test statistic value of 2.05 be unusual enough to reject the null?\n\np-value: assuming the null hypothesis is true, it is the probability of observing a test statistic of 2.05 or more extreme\n\nSince we want to see the difference of the means unequal to zero, we have to do a two sided test. ","metadata":{}},{"cell_type":"code","source":"df = n1 + n2 - 2  # degrees of freedom, reducting 2 because of mean\n\nfrom scipy import stats\n\np = 1 - stats.t.cdf(test_statistic,df=df)\np","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The p-value of 0.02 is smaller than our significance level of 0.05. \nTherefore we can reject the null hypothesis and assume that our alternative hypothesis is true, that \nthe mean ratings are different for Ramen Packs from Japan and USA.  ","metadata":{}},{"cell_type":"markdown","source":"# **Future work**\nIs there a difference between ramen styles? ","metadata":{}},{"cell_type":"code","source":"usa_pack_df['Stars'].count()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}