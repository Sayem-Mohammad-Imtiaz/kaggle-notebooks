{"cells":[{"metadata":{},"cell_type":"markdown","source":"\n---\n\n<img src=\"https://petlja.org/images/img/python.png\"\n     alt=\"Opis\"\n     width=\"250\"\n     style=\"float: right; margin-right: 10px;\" />\n\nChurn Modeling\n==============\n\n***Predicting service cancelation using bank customers data, Customer Churn***\n\n**Author:** *Žarko Milošev*\n\n---\n\n# Table of Contents:\n\n1. [Data Preparation](#1.-Data-preparation)\n    - [Imports](#Imports)\n    - [Loading data indo pandas DF object](#Loading)\n    - [Data Cleaning](#Cleaning)\n<br>\n2. [EDA - Exploratory Data Analasys](#2.-EDA)\n    - [General overview of data Distribution](#Distribution)\n    - [Data Visualisation](#Visualisation)\n    - [Explore Categorical Collumns](#Categorical-Features)\n    - [Explore Numerical Features - Discrete values](#Discrete-Features)\n    - [Outlier Detection](#Outliers)\n    - [Histograms](#Histograms)\n    - [Correlation Matrix](#Correlations)\n<br>\n3. [Data Preprocessing](#3.-Preprocessing)\n    - [Removal of data with low information value](#Removal-of-data-with-low-information-value)\n    - [Outlier handeling](#Outlier-removal)\n    - [Handling Imbalanced Data - Oversampling](#Oversampling)\n    - [Handling Imbalanced Data - Undersampling](#Undersampling)\n    - [Encoding Categorical Features](#Encoding)\n    - [Feature Scaling - data normalisation](#Scaling)\n    - [Spliting to train and test](#Train-test-split)\n<br>\n4. [Data Modeling](4.-Modeling)\n    - [Optimal model parameters - Cross Validation](#Optimal-model-parameters)\n    - [Model evaluation OOB](#OOB)\n    - [Feature optimisation](#Feature-optimisation)\n    - [Training the Model](#Training)\n    - [Results](#Results)\n5. [Conclusion](#Conclusion)\n\n\n\n---\n\n[<< Project topic](#Churn-Modeling) | [Content Table](#Table-of-Contents:) | [Next Chapter >>](#1.-Data-Preparation)\n\n---","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **1. Data Preparation**  \n*Since the data set is available directly from the site there is no need to do any ETL work, and can proceed to importing the needed modules to operate data, and import the data itself*","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"---\n\n[<< Previous Chapter](#Table-of-Contents:) | [Content Table](#Table-of-Contents:) | [Next Chapter >>](#2.-EDA)\n\n---","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## **Imports** \n*The first thing to do is to import all of the modules needed for this kernel.*","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#NumPy and Pandas DataFrame object type\nimport numpy as np\nimport pandas as pd\n#Options for Pandas DF\npd.options.display.max_rows = None\npd.options.display.max_columns = None\n#Ploting libs for visualisation\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n#Preprocessing libs\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import resample\n#Chosen models from scikitlearn library\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n#All of the metrics used in this example\nfrom sklearn.metrics import (accuracy_score, precision_score, average_precision_score, \n                             recall_score, roc_auc_score, roc_curve, \n                             classification_report, f1_score, confusion_matrix)\n#Libs for testing optimal model parameters \nfrom sklearn.feature_selection import RFECV\nfrom sklearn.model_selection import GridSearchCV\nfrom collections import OrderedDict\nfrom sklearn.datasets import make_classification","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Loading**  \n*In this step the data is loaded and a small portion is displayed in the table*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/churn-modelling/Churn_Modelling.csv')\ndf.shape\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Cleaning**  \n*Checking for missing values with further examination of the data set*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **2. EDA**  \n*It is important to examine every feature (collumn) in order to get a full picture of data distribution across the set. Looking at previous output - using *`.info()`* command, there are several columns flaged as Object type - meaning they contain categorical data (in this case strings). Other collumns have discreet, numerical values such as float or integer*","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"---\n\n[<< Previous Chapter](#1.-Data-Preparation) | [Content Table](#Table-of-Contents:) | [Next Chapter >>](#3.-Preprocessing)\n\n---","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## **Distribution**  \n*Examining the distribution of the data across all of the columns*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#statistical overview of numerical features (collumns)\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Listing unique value distribution acress collumns\ndf.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Distribution of .mean value of the feature we are trying to predict - IsActiveMember 0 and 1 across Discrete features\ndf.groupby(df['IsActiveMember']).mean().head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Visualisation**  \n*Visualising the data gives a beter insight into the distribution*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#The distribution of Exited column\nlabels = 'Churn', 'Active'\nsizes = [df.Exited[df['Exited']==1].count(), df.Exited[df['Exited']==0].count()]\nexplode = (0, 0.05)\nfig1, ax1 = plt.subplots(figsize=(4, 4))\nax1.pie(sizes, explode=explode, labels=labels, autopct='%1.2f%%',textprops={'fontsize': 24})\nax1.axis('equal')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Categorical Features**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Distribution of active membership (IsActiveMember) over categorical features\nfig, axarr = plt.subplots(2, 2, figsize=(16, 16))\nsns.countplot(x='Geography', hue = 'Exited',data = df, ax=axarr[0][0])\nsns.countplot(x='Gender', hue = 'Exited',data = df, ax=axarr[0][1])\nsns.countplot(x='HasCrCard', hue = 'Exited',data = df, ax=axarr[1][0])\nsns.countplot(x='IsActiveMember', hue = 'Exited',data = df, ax=axarr[1][1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Discrete Features**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distribution of active membership (IsActiveMember) over discreet features\nfig, axarr = plt.subplots(3, 2, figsize=(16, 24))\nsns.boxplot(y='CreditScore',x = 'Exited', hue = 'Exited',data = df, ax=axarr[0][0])\nsns.boxplot(y='Age',x = 'Exited', hue = 'Exited',data = df , ax=axarr[0][1])\nsns.boxplot(y='Tenure',x = 'Exited', hue = 'Exited',data = df, ax=axarr[1][0])\nsns.boxplot(y='Balance',x = 'Exited', hue = 'Exited',data = df, ax=axarr[1][1])\nsns.boxplot(y='NumOfProducts',x = 'Exited', hue = 'Exited',data = df, ax=axarr[2][0])\nsns.boxplot(y='EstimatedSalary',x = 'Exited', hue = 'Exited',data = df, ax=axarr[2][1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Outliers**  \n*Discovering outliers is an important part of EDA, these must be flaged for preprocessing tasks, or eliminated using other methods*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#The distribution of Churn across Tenure and NumberOfProducts\nfig, axarr = plt.subplots(1,2, figsize=(16, 8))\nsns.countplot(x='Tenure', hue = 'Exited',data = df, ax=axarr[0])\nsns.countplot(x='NumOfProducts', hue = 'Exited',data = df, ax=axarr[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Possible outliers on customers that have 3 or 4 products, displaying the discreet distribution of Churn\ndf.NumOfProducts.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Examining Customer age Distribution since the visualisation on the discreet values showed indications of outliers\ndf.Age.value_counts().plot(kind='bar',figsize=(16,4))\ndf.Age.value_counts().tail(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Distribution of age across Churn\nchurn_age = df[['Exited']].groupby(df['Age']).mean()\nchurn_age.plot(kind='bar',figsize=(20,8))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Histograms**  ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using histograms to examine the selected distributions for Age, Credit Score, Balance and EstimatedSalary\nfig, axa = plt.subplots(2, 2, figsize=(16, 16))\ndf.CreditScore.hist(bins=500, ax = axa[0][0])\ndf.Age.hist(bins=75, ax = axa[0][1])\ndf[(df.Balance!=0)].Balance.hist(bins=225,figsize=(24,16), ax = axa[1][0])\ndf.EstimatedSalary.hist(bins=300,figsize=(24,16), ax = axa[1][1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Correlations**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation matrix\nplt.subplots(figsize=(14,12))\nsns.heatmap(df.corr(), annot=True, cmap=\"tab20c\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Examining feature importances\ndf.drop([\"Exited\"], axis = 1).corrwith(df['Exited']).plot.bar(figsize = (16, 8), title = \"Corelation with Exited bool\", fontsize = 20, rot = 45, grid = True)\ndf.corrwith(df['Exited'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **3. Preprocessing** \n*During the preprocessing the data is modified in such a way that in the end it is digestable by the chosen models algorithm. That being said, and considering the methods chosen, all of the data needs to be Discreet - meaning that all of the categorical values must be translated into numerical, also eliminate any outliers that we caught in previous [EDA chapter](#2.-EDA)*","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"---\n\n[<< Previous Chapter](#2.-EDA) | [Content Table](#Table-of-Contents:) | [Next Chapter >>](#4.-Modeling)\n\n---","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Taking a fresh copy to work with\ndata = df.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Removal of data with low information value**  \n*Some of the collumns are redundant. For example the ID's, and row numbers, as well as customer names*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# removal of non related data\ndata = data.drop([\"RowNumber\", \"CustomerId\", \"Surname\"], axis = 1)\n#result\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Outlier removal**\n*Removing previousley detected outliers*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#outlier removal\ndata = data[(data.CreditScore>400)]\ndata = data[(data.Age < 78)]\ndata = data[(data.NumOfProducts<3)]\n#result\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Encoding**  \n*Gender and Geography must be transformed to numerical values so that RFR algo can digest the data in an expected way*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#transforming text values to numerical \ndataLebelEncoded = data.copy()\n# Lebel enkoder, used to encode male/female to 0/1\nle= LabelEncoder()\ndataLebelEncoded['Gender']= le.fit_transform(dataLebelEncoded['Gender'])\ndataLebelEncoded.head()\n#dataLebelEncoded.info()\n#dataLebelEncoded.hist(bins = 100, figsize=(24,24))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#encoding the Geography values...\ndataEncoded = dataLebelEncoded.copy()\ndataEncoded = pd.get_dummies(dataEncoded, columns=['Geography'])\ndataEncoded.rename(columns={\"Geography_France\":\"France\",\n                   \"Geography_Germany\":\"Germany\",\n                   \"Geography_Spain\":\"Spain\"}, inplace=True)\ndataEncoded.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Scaling**  \n*Note that only some Discreet values are undergoing normalisation, compare results to *[Histograms](#Histograms)*, notice that values range from 0 to 1 now. *","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Value normalisation\nscaler = MinMaxScaler() \nnormalizacija = [\"CreditScore\", \"Age\", \"Balance\",'EstimatedSalary']\ndataScaled = pd.DataFrame(data = dataEncoded)\ndataScaled[normalizacija] = scaler.fit_transform(dataEncoded[normalizacija])\ndataScaled.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualizing the distribution after normalization\nfig, axa = plt.subplots(2, 2, figsize=(16, 16))\ndataScaled.CreditScore.hist(bins=400, ax = axa[0][0])\ndataScaled.Age.hist(bins=60, ax = axa[0][1])\ndataScaled[(dataScaled.Balance!=0)].Balance.hist(bins=225,figsize=(24,16), ax = axa[1][0])\ndataScaled.EstimatedSalary.hist(bins=300,figsize=(24,16), ax = axa[1][1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets see what we got so far\ndataScaled.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Train test split**  \n*The main object is to prepare a test and training set.*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Separating the y *(Churns, Exited customers)\nX = dataScaled.drop(\"Exited\", axis=1)\ny = dataScaled[\"Exited\"]\nX.shape, y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Podela seta na testni deo, i deo za obuku\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **4. Modeling**  \n*In modeling phase warious classifiers are tested in order to find the best and most persistant model* ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"---\n\n[<< Previous Chapter](#3.-Preprocessing) | [Content Table](#Table-of-Contents:) | [Conclusion >>](#5.-Conclusion)\n\n---","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## **Optimal model parameters**  \n*It is important to run heavy load tasks such as cross search validation on as much processor cores as possible since the folds can be done in paralell.Notice the *`n_jobs=-1`* parameter in the *` gsCV = GridSearchCV(gsCV_model, tuned_parameters,n_jobs=-1, verbose=1)`* command, this way we can use all of the CPU cores available.*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Taking a smaller sample\nsampleData = dataScaled.sample(frac=0.1, replace=True)\n\n#delimo podatke na y i X\nX_sample=sampleData.drop(['Exited'], axis=1)\ny_sample=sampleData['Exited']\n\nX_sample.shape, y_sample.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ngsCV_model = RandomForestClassifier(oob_score=True)\ntuned_parameters = {'max_depth': [10, 20, 30, 50],\n                    'min_samples_leaf': [1, 2, 3, 5],\n                    'min_samples_split': [2, 3, 4, 5, 6, 8],\n                    'n_estimators': [100]},\ngsCV = GridSearchCV(gsCV_model, tuned_parameters,n_jobs=-1, verbose=1)  \ngsCV.fit(X_sample,y_sample)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The results:\nprint('Best Score: {:.3f} \\n'.format(gsCV.best_score_ ))\nprint('Parameters used:')\nprint(gsCV.best_params_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Note that you can shufle the input data and use different ranges for GSCV, the best result was: *`{'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}`*   \nso these are going to be used for further testing. *","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ensemble_clfs = [(\"RandomForestClassifier, max_depth='30', min_samples_leaf='1', min_samples_split='2'\", \n                   RandomForestClassifier (max_depth=30,   min_samples_leaf=1,   min_samples_split=2, oob_score=True))]\nerror_rate = OrderedDict((label, []) for label, _ in ensemble_clfs)\n#The range in which we are wearching for the optimal number estimators\nmin_estimators = 20\nmax_estimators = 800\n#Change the step if needed, here its 10, the smaller the number the more steps there is to calculate, so the operation takes more time\nfor label, clf in ensemble_clfs:\n    for i in range(min_estimators, max_estimators + 1,10):\n        clf.set_params(n_estimators=i)\n        clf.fit(X_sample, y_sample)\n        #Recording the OOB error rate for every `n_estimators=i`\n        oob_error = 1 - clf.oob_score_\n        error_rate[label].append((i, oob_error))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **OOB**  \n*Calculating the optimal number of estimators*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualising the plot for \"OOB error rate\" vs. \"n_estimators\" \nfor label, clf_err in error_rate.items():\n    xs, ys = zip(*clf_err)\n    plt.plot(xs, ys, label=label)\nplt.xlim(min_estimators, max_estimators)\nplt.xlabel(\"n_estimators\")\nplt.ylabel(\"OOB error rate\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Feature optimisation**  \n*Cross validation of features*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#The number of correct classifications\nclf_rf_4 = RandomForestClassifier(n_estimators = 290) \nrfecv = RFECV(estimator=clf_rf_4, step=1, cv=5,scoring='accuracy')   #5-fold cross-validation\n#fitting the classifier\nrfecv = rfecv.fit(X_train, y_train.values.ravel())\n\nprint('Optimal number of features: ', rfecv.n_features_)\nprint('Best features', X_train.columns[rfecv.support_])\n\n#Plot features VS cross-validation scores\nplt.figure()\nplt.xlabel(\"Number of features\")\nplt.ylabel(\"Cross validation score\")\nplt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\nplt.show()\n\nclf_rf = RandomForestClassifier(n_estimators = 100)      \nclr_rf = clf_rf.fit(X_train,y_train.values.ravel())\n#printing the score \ny_pred=clf_rf.predict(X_test)\nac = accuracy_score(y_test,y_pred)\nprint('Accuracy: ',ac)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Training**  \n*Some of the fits (the ones with higher parameter value) *","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fittingg the parameters\nRFC = RandomForestClassifier(bootstrap=True, \n                             class_weight=None,\n                             criterion='gini', \n                             max_depth=30,\n                             max_features=10,\n                             min_samples_leaf=1,\n                             min_samples_split=3,\n                             n_estimators=200,\n                             oob_score=True, \n                             random_state=743,\n                             verbose=0, \n                             warm_start=False,\n                             n_jobs=-1)\n\n#Training the model\nRFC.fit(X_train, y_train)\ny_pred = RFC.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Results**  \n*Precision report and confusion matrix are presented to have a better insight to what exactly is predicted*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Report\nprint('Precision for Random Forest Classificator: \\n')\nprint(classification_report(y_test, y_pred))\n\n#Visual representation\nfig = plt.figure()\nax = fig.add_subplot(111)\ncax = ax.matshow(confusion_matrix(y_test, y_pred))\nplt.title('Confusion Matrix')\nfig.colorbar(cax)\nplt.xlabel('Predicted')\nplt.ylabel('Real')\nplt.show()\nprint(confusion_matrix(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Literal translation disclaimer: These figures can differ slightly depending on the random seeds*** \n\n---\n  \nDuring the testing there had been 1602 total class 0, and 325 total class 1.  \n\nTotal found Class 0: 1724 out of which 1526 are correct and 198 are incorrect, the accuracy for class 0 is 89% whithin the classified cluster, if we compare 1526 correctly classified samples with a total number tested 1602 the accuracy is stagering 95%. However the best score that is readable on the scoreboard is not neceseraly what is the bussiness question in the first place:  **Which customers are about to cancel subscription?**  \n<br>\nTotal found Class 1: 203 out of which 127 are correct and 76 are incorrect, the accuracy for class 1 is 63% whithin the classified cluster, if we compare 127 correctly classified samples with a total number tested 325 the accuracy is 39%. So the answer to the question would be: **At this time the model can detect 39% of total amount of the customers that are about to cancel their subscription, the accuracy within the selected cluster is 63%, meaning that 37% of customers were not about to cancel anyway**  \n\n*Retest with other ansemble methods is recommended*","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"*Looking at the overall results, there is a noticable overfiting to majoriti class, in our case the *`Exited[0]`*, the class imbalance is an issue that can be addressed using either undersampling or oversampling *","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **5. Conclusion**  \n*In conclusion:  \n\n*The chalange here was to predict which customers will cancell their subscription *`Exited[1]`*, RFC caught 127 out of total 325 the accuracy here is quite low, how ever the rate of false positives is not so high (76). This means that 37% of the customers that have \"Exiting\" are incorrectley clasified, considering that the recall on *`class [0]`* is 95% class balancing should improve our 39% hit chance atleest to some extent. *\n\n\n\n---\n\n[<< Previous Chapter](#4.-Modeling) | [Content Table](#Table-of-Contents:) | [Conclusion >>](#5.-Conclusion)\n\n---","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}