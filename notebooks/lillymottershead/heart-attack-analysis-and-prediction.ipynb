{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"033b386b-001e-4251-a404-4af29313553e","_cell_guid":"8495f1b1-f620-4d15-abbe-687625e0998e","collapsed":false,"jupyter":{"outputs_hidden":false},"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-21T16:02:00.091291Z","iopub.execute_input":"2021-05-21T16:02:00.09166Z","iopub.status.idle":"2021-05-21T16:02:00.104891Z","shell.execute_reply.started":"2021-05-21T16:02:00.09163Z","shell.execute_reply":"2021-05-21T16:02:00.103177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Exploration\n\n## 1.1 Imports","metadata":{"_uuid":"4a1160d0-f487-44e0-88ad-175e636bafec","_cell_guid":"82d430d5-cefc-47b4-acb4-0f097af5c42e","trusted":true}},{"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport seaborn as sns\nimport math","metadata":{"_uuid":"31de3ccf-d369-4de4-906f-e1313b18d3bc","_cell_guid":"e5d56798-f008-4524-845c-4f8b0c21b3fb","collapsed":false,"jupyter":{"outputs_hidden":false},"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-21T16:02:00.11034Z","iopub.execute_input":"2021-05-21T16:02:00.110722Z","iopub.status.idle":"2021-05-21T16:02:00.119585Z","shell.execute_reply.started":"2021-05-21T16:02:00.110688Z","shell.execute_reply":"2021-05-21T16:02:00.118706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.2 Read CSV","metadata":{"_uuid":"f2c536d8-510c-47da-a964-f682e3462d20","_cell_guid":"fb5769b1-812d-4d3e-9c43-042ad4401666","trusted":true}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/heart-attack-analysis-prediction-dataset/heart.csv\")","metadata":{"_uuid":"6c5b0ba8-be4a-494e-8097-baea1c5fc30f","_cell_guid":"8cef278b-1002-4ec4-adc1-47d1852f7291","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-05-21T16:02:00.121245Z","iopub.execute_input":"2021-05-21T16:02:00.121655Z","iopub.status.idle":"2021-05-21T16:02:00.141573Z","shell.execute_reply.started":"2021-05-21T16:02:00.121624Z","shell.execute_reply":"2021-05-21T16:02:00.140288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.3 Basic data structure exploration","metadata":{"_uuid":"554a3b4c-29f8-4e9e-a456-791f919ee410","_cell_guid":"f6a550fc-167c-450f-85bd-0eefb83f95b4","trusted":true}},{"cell_type":"code","source":"print(f'Shape of heart.csv: {df.shape}')","metadata":{"_uuid":"985c8f2d-5bea-4bea-98cf-a1e8422a9834","_cell_guid":"36906de1-ce1d-44f2-b455-459e1d63a17c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-05-21T16:02:00.145604Z","iopub.execute_input":"2021-05-21T16:02:00.145931Z","iopub.status.idle":"2021-05-21T16:02:00.154635Z","shell.execute_reply.started":"2021-05-21T16:02:00.145902Z","shell.execute_reply":"2021-05-21T16:02:00.153124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 303 records in the dataset, and 14 features to describe them.","metadata":{}},{"cell_type":"code","source":"print(f'\\nFirst 5 rows of heart.csv:')\ndf.head()","metadata":{"_uuid":"05c48659-f1f8-4ffb-9387-c574c238a5b2","_cell_guid":"d7ac35ea-ce31-4827-b1d9-6db8e06f0597","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-05-21T16:02:00.161614Z","iopub.execute_input":"2021-05-21T16:02:00.162013Z","iopub.status.idle":"2021-05-21T16:02:00.181837Z","shell.execute_reply.started":"2021-05-21T16:02:00.161967Z","shell.execute_reply":"2021-05-21T16:02:00.18097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Feature information:')\ndf.info()","metadata":{"_uuid":"5d129b3b-4b53-45c5-b1b1-7bfbacf0775b","_cell_guid":"21b585ce-bc07-44fc-a433-50819c6b09d2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-05-21T16:02:00.183221Z","iopub.execute_input":"2021-05-21T16:02:00.183675Z","iopub.status.idle":"2021-05-21T16:02:00.212853Z","shell.execute_reply.started":"2021-05-21T16:02:00.183637Z","shell.execute_reply":"2021-05-21T16:02:00.210901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Number of null values in each column:')\ndf.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-05-21T16:04:30.505824Z","iopub.execute_input":"2021-05-21T16:04:30.506278Z","iopub.status.idle":"2021-05-21T16:04:30.518755Z","shell.execute_reply.started":"2021-05-21T16:04:30.506242Z","shell.execute_reply":"2021-05-21T16:04:30.517819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As there are no null values in the data, null-filling will not be necessary in the data preparation.","metadata":{}},{"cell_type":"code","source":"print('Number of unique values in each column:')\ndf.nunique(axis=0)","metadata":{"_uuid":"8f19ffdd-8934-492b-b994-3b22896bbaf9","_cell_guid":"6aa4da47-4e28-425f-b080-02105c340056","execution":{"iopub.status.busy":"2021-05-21T16:02:00.215187Z","iopub.execute_input":"2021-05-21T16:02:00.215537Z","iopub.status.idle":"2021-05-21T16:02:00.248645Z","shell.execute_reply.started":"2021-05-21T16:02:00.215506Z","shell.execute_reply":"2021-05-21T16:02:00.247408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Variance in each column:')\ndf.var(axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T16:05:46.383922Z","iopub.execute_input":"2021-05-21T16:05:46.384338Z","iopub.status.idle":"2021-05-21T16:05:46.395344Z","shell.execute_reply.started":"2021-05-21T16:05:46.384302Z","shell.execute_reply":"2021-05-21T16:05:46.394431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With such a wide range of variance across the columns, some features, particularly the continuous features, will require scaling.","metadata":{}},{"cell_type":"markdown","source":"## 1.4 Categorical feature exploration\n\n### List of categorical features","metadata":{"_uuid":"e91bd374-6c68-4006-b067-37b08164a810","_cell_guid":"10eeee81-837f-4f7a-81f8-00d199aa6fd1","trusted":true}},{"cell_type":"code","source":"CATEGORICAL_FEATURES = ['sex', 'cp', 'fbs', 'restecg', 'exng', 'slp', 'thall', 'caa']","metadata":{"_uuid":"517aa2fe-89b4-412b-83d5-1753ab05da90","_cell_guid":"a26cda3d-055e-45e6-8d0c-d5b74c4a4417","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-05-21T16:02:00.251177Z","iopub.execute_input":"2021-05-21T16:02:00.252071Z","iopub.status.idle":"2021-05-21T16:02:00.25716Z","shell.execute_reply.started":"2021-05-21T16:02:00.252027Z","shell.execute_reply":"2021-05-21T16:02:00.255994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_ = pd.DataFrame()\nfor column in CATEGORICAL_FEATURES:\n    df_[column] = df[column].astype(\"category\")\n\nprint(f'Basic categorical feature statistical information:')\ndf_[CATEGORICAL_FEATURES].describe()","metadata":{"execution":{"iopub.status.busy":"2021-05-21T16:02:00.259406Z","iopub.execute_input":"2021-05-21T16:02:00.259913Z","iopub.status.idle":"2021-05-21T16:02:00.333545Z","shell.execute_reply.started":"2021-05-21T16:02:00.259876Z","shell.execute_reply":"2021-05-21T16:02:00.331692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rows = 4\ncolumns = math.ceil(len(CATEGORICAL_FEATURES)/rows)\nfig, ax = plt.subplots(\n    rows,\n    columns,\n    figsize=(3*columns, 3*rows),\n    sharey=False,\n)\nfor i, column in enumerate(CATEGORICAL_FEATURES):\n    plot = sns.countplot(\n        data=df, \n        x=column, \n        ax=ax[i%rows, i//rows], \n        color=sns.color_palette('deep')[0],\n    )\n    plot.set_xlabel(column, fontsize=14)\n    if i//rows > 0:\n        plot.set(ylabel=None)\nfig.suptitle('Count Plot for categorical features', fontsize=16)\nfig.tight_layout()","metadata":{"_uuid":"8ecb45fe-2061-47ee-92ff-6a1f384449cb","_cell_guid":"477068bc-5b0b-4d92-a60c-70eddda1e216","collapsed":false,"jupyter":{"outputs_hidden":false},"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-21T16:02:00.335927Z","iopub.execute_input":"2021-05-21T16:02:00.33632Z","iopub.status.idle":"2021-05-21T16:02:01.33957Z","shell.execute_reply.started":"2021-05-21T16:02:00.336286Z","shell.execute_reply":"2021-05-21T16:02:01.337647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Notes:\n* There are nearly twice as many of sex category 1 (male) as there are of category 0 (female).","metadata":{}},{"cell_type":"code","source":"rows = 4\ncolumns = math.ceil(len(CATEGORICAL_FEATURES)/rows)\nfig, ax = plt.subplots(\n    rows,\n    columns,\n    figsize=(4*columns, 4*rows),\n    sharey=False,\n)\nfor i, column in enumerate(CATEGORICAL_FEATURES):\n    plot = sns.countplot(\n        data=df, \n        x=column, \n        hue='output', \n        ax=ax[i%rows, i//rows], \n        palette=sns.color_palette('deep'),\n    )\n    plot.set_xlabel(column, fontsize=14)\n    if i//rows > 0:\n        plot.set(ylabel=None)\nfig.suptitle('Count plot for categorical features split by target', fontsize=16)\nfig.tight_layout()","metadata":{"_uuid":"3871105e-acfd-446d-bcca-858224409ba7","_cell_guid":"cf6e6563-1bdc-4bea-8004-f5530b33a4c4","collapsed":false,"jupyter":{"outputs_hidden":false},"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-21T16:02:01.341848Z","iopub.execute_input":"2021-05-21T16:02:01.342198Z","iopub.status.idle":"2021-05-21T16:02:02.62465Z","shell.execute_reply.started":"2021-05-21T16:02:01.34216Z","shell.execute_reply":"2021-05-21T16:02:02.623209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Notes:\n* Samples of sex category 0 (female) are much more likely to have a target output of 1 (heart attack), especially as compared to sex category 1 (male).\n* exng 0, cp 1 & 2, slp 2, thall 2, and caa 0 have high rates of heart attack.\n\n## 1.5 Continuous feature exploration\n\n### List of continuous features","metadata":{"_uuid":"4561fe98-57be-4208-b3c1-04fd567507ec","_cell_guid":"cae4b855-89ed-4f91-bfce-42e9f0b25529","trusted":true}},{"cell_type":"code","source":"CONTINUOUS_FEATURES = ['age', 'trtbps', 'chol', 'thalachh', 'oldpeak']","metadata":{"_uuid":"e50a79bd-5d90-4b58-beba-850efdd9a6cd","_cell_guid":"3bc9f367-720f-4f7f-8b05-bf644559128a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-05-21T16:02:02.626508Z","iopub.execute_input":"2021-05-21T16:02:02.626852Z","iopub.status.idle":"2021-05-21T16:02:02.631237Z","shell.execute_reply.started":"2021-05-21T16:02:02.626819Z","shell.execute_reply":"2021-05-21T16:02:02.630399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Basic continuous feature statistical information:')\ndf[CONTINUOUS_FEATURES].describe()","metadata":{"_uuid":"a1a83664-c6aa-41b6-8298-1d0b839634b5","_cell_guid":"b6b7f296-db59-4daa-9712-44e2c30a3ca6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-05-21T16:02:02.632463Z","iopub.execute_input":"2021-05-21T16:02:02.633267Z","iopub.status.idle":"2021-05-21T16:02:02.680818Z","shell.execute_reply.started":"2021-05-21T16:02:02.633213Z","shell.execute_reply":"2021-05-21T16:02:02.679174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rows = 3\ncolumns = math.ceil(len(CONTINUOUS_FEATURES)/rows)\nfig, ax = plt.subplots(\n    rows,\n    columns,\n    figsize=(4*columns, 4*rows),\n    sharey=False,\n)\nax[-1, -1].axis('off')\nfor i, column in enumerate(CONTINUOUS_FEATURES):\n    plot = sns.histplot(\n        data=df, \n        x=column, \n        ax=ax[i%rows, i//rows], \n        linewidth=0,\n        color=sns.color_palette('deep')[0],\n    )\n    plot.set_xlabel(column, fontsize=14)\n    if i//rows > 0:\n        plot.set(ylabel=None)\nfig.suptitle('Histogram for each continuous feature', fontsize=16)\nfig.tight_layout()","metadata":{"_uuid":"63f705c2-67d9-422a-a780-f01c1c945a05","_cell_guid":"537d8c66-3abf-4a15-bc04-9d643f8ccb73","collapsed":false,"jupyter":{"outputs_hidden":false},"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-21T16:02:02.684123Z","iopub.execute_input":"2021-05-21T16:02:02.684462Z","iopub.status.idle":"2021-05-21T16:02:04.009071Z","shell.execute_reply.started":"2021-05-21T16:02:02.684431Z","shell.execute_reply":"2021-05-21T16:02:04.007382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rows = 2\ncolumns = math.ceil(len(CONTINUOUS_FEATURES)/rows)\nfig, ax = plt.subplots(\n    rows, \n    columns,\n    figsize=(2*columns, 5*rows),\n    sharey=False,\n)\nax[-1, -1].axis('off')\nfor i, column in enumerate(CONTINUOUS_FEATURES):\n    plot = sns.boxenplot(\n        data=df, \n        y=column, \n        x='output', \n        ax=ax[i%rows, i//rows], \n        linewidth=1,\n        palette=sns.color_palette('deep'), \n    )\n    plot.set_ylabel(column, fontsize=14)\n    plot.set(xlabel=None)\nfig.suptitle('Boxen plot for each continuous feature split by target', fontsize=16)\nfig.tight_layout()\nplt.show()","metadata":{"_uuid":"4648f91d-699d-4879-a1d9-e98f65a3a74e","_cell_guid":"d2d3adf4-bbfb-4f7f-8016-fb7e42610cd0","collapsed":false,"jupyter":{"outputs_hidden":false},"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-21T16:02:04.0108Z","iopub.execute_input":"2021-05-21T16:02:04.011314Z","iopub.status.idle":"2021-05-21T16:02:04.789884Z","shell.execute_reply.started":"2021-05-21T16:02:04.011269Z","shell.execute_reply":"2021-05-21T16:02:04.787915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Notes:\n* While it may seem intuitive that greater age would correspond with a high likeliness of heart attack, heart attacks skew younger for this data.","metadata":{}},{"cell_type":"code","source":"rows = 3\ncolumns = math.ceil(len(CONTINUOUS_FEATURES)/rows)\nfig, ax = plt.subplots(\n    rows,\n    columns,\n    figsize=(5*columns, 4*rows),\n    sharey=False,\n)\nax[-1, -1].axis('off')\nfor i, column in enumerate(CONTINUOUS_FEATURES):\n    sns.kdeplot(\n        data=df, \n        x=column, \n        hue='output', \n        ax=ax[i%rows, i//rows],  \n        fill=True, \n        linewidth=0,\n        palette=sns.color_palette('dark')[:2],\n        alpha=.3,\n    )\n    plot.set_xlabel(column, fontsize=14)\n    if i//rows > 0:\n        plot.set(ylabel=None)\nfig.suptitle('KDE Density plot for each continuous feature split by target', fontsize=16)\nfig.tight_layout()","metadata":{"_uuid":"2cb7b172-8d1f-41fd-b78a-ed632c7e0992","_cell_guid":"ebbf157d-84eb-4e13-a8b7-691d41e02c96","collapsed":false,"jupyter":{"outputs_hidden":false},"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-21T16:02:04.794019Z","iopub.execute_input":"2021-05-21T16:02:04.794511Z","iopub.status.idle":"2021-05-21T16:02:06.052611Z","shell.execute_reply.started":"2021-05-21T16:02:04.794475Z","shell.execute_reply":"2021-05-21T16:02:06.051372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Notes:\n* The high frequency of category 0 in oldpeak is predominantly from output 1 samples.","metadata":{}},{"cell_type":"markdown","source":"# 2. Data Preparation\n\n## 2.1 Imports","metadata":{"_uuid":"d7cef5ba-5bfd-4c34-8215-d0c180b062c7","_cell_guid":"00b8b083-1482-4ff2-8678-5fe8328f28b2","trusted":true}},{"cell_type":"code","source":"from sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"f8dcafb5-2034-4d99-8755-548aec1c61bd","_cell_guid":"04c26918-3241-46f8-aba7-29854666292a","collapsed":false,"jupyter":{"outputs_hidden":false},"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-21T16:02:06.054536Z","iopub.execute_input":"2021-05-21T16:02:06.054875Z","iopub.status.idle":"2021-05-21T16:02:06.058719Z","shell.execute_reply.started":"2021-05-21T16:02:06.054846Z","shell.execute_reply":"2021-05-21T16:02:06.057915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.2 Creating training set and test set","metadata":{"_uuid":"c39a57e9-d1ca-473b-a4a2-11667e61cd5a","_cell_guid":"612ad7de-1064-42d8-afcc-da8193f20fff","trusted":true}},{"cell_type":"code","source":"# Copy df before creating dummies for categorical features\ndf_copy = df.copy(deep=True)\n\n# Converting categorical features into binary categories\ndf_copy = pd.get_dummies(df_copy, columns=CATEGORICAL_FEATURES, drop_first=True)\n\n# Scaling continuous features using RobustScaler\nscaler = RobustScaler()\ndf_copy[CONTINUOUS_FEATURES] = scaler.fit_transform(df_copy[CONTINUOUS_FEATURES])\n\n# Splitting the data\nX = df_copy.drop(['output'], axis=1)\ny = df_copy[['output']]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=75)\nfor name, split in {\n    'X_train': X_train, \n    'y_train': y_train, \n    'X_test': X_test, \n    'y_test': y_test,\n}.items():\n    descripter = f'The shape of {name} is:'\n    print(f'{descripter:<24} {split.shape}')","metadata":{"_uuid":"0f20bf34-60d2-495a-8f95-25265b107d01","_cell_guid":"ccea984a-f250-4a2d-9000-2b55d1f170ad","collapsed":false,"jupyter":{"outputs_hidden":false},"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-21T16:02:18.781015Z","iopub.execute_input":"2021-05-21T16:02:18.781404Z","iopub.status.idle":"2021-05-21T16:02:18.828004Z","shell.execute_reply.started":"2021-05-21T16:02:18.781372Z","shell.execute_reply":"2021-05-21T16:02:18.826134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Models\n\n## 3.1 Imports","metadata":{"_uuid":"eeecffca-8755-4957-9e51-3b142bc190ed","_cell_guid":"0821f782-b01d-4b5b-a2cf-9198928e900a","trusted":true}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\nfrom time import time","metadata":{"_uuid":"203c860a-d020-4da9-984c-2c915c5dac2d","_cell_guid":"674c2cea-6f6f-4c2a-857f-bc24f142b124","collapsed":false,"jupyter":{"outputs_hidden":false},"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-21T16:02:06.124353Z","iopub.execute_input":"2021-05-21T16:02:06.124807Z","iopub.status.idle":"2021-05-21T16:02:06.131144Z","shell.execute_reply.started":"2021-05-21T16:02:06.124761Z","shell.execute_reply":"2021-05-21T16:02:06.12974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.2 Defining a function to train, predict, and score a classifier","metadata":{"_uuid":"a0c95ffe-2c02-4d7c-8c32-31e1e76cb31b","_cell_guid":"06923314-8b7a-4c5f-a9aa-152b96d32d53","trusted":true}},{"cell_type":"code","source":"def train_and_print_results(classifier, header):\n    start_time = time()\n    model = classifier.fit(X_train, np.ravel(y_train))\n    total_time = time() - start_time\n\n    y_pred = model.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    print(header)\n    print(f\"  accuracy: {accuracy:.3f}\")\n    print(f'  time: {total_time*100:.3f}ms')","metadata":{"_uuid":"c3fd45a4-cd71-4cec-a325-8c7028efc55a","_cell_guid":"5d3c8459-f8ec-46f9-a504-9ba866884ae2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-05-21T16:02:06.133109Z","iopub.execute_input":"2021-05-21T16:02:06.133556Z","iopub.status.idle":"2021-05-21T16:02:06.149789Z","shell.execute_reply.started":"2021-05-21T16:02:06.13351Z","shell.execute_reply":"2021-05-21T16:02:06.14824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.3 K-Nearest Neighbor Classifier","metadata":{"_uuid":"22d01177-6081-4419-8a4b-25c0139a2959","_cell_guid":"a83771e4-f281-4b86-84ac-209fe05bb911","trusted":true}},{"cell_type":"code","source":"# No hyperparameter tuning\nclassifier = KNeighborsClassifier()\ntrain_and_print_results(classifier, 'KNeighborsClassifier no tuning')\n\n# Parameter tuning\nparameters = {\n    'n_neighbors': [1, 2, 4, 8, 16, 32, 64],\n    'weights': ['uniform', 'distance'],\n}\nclassifier = GridSearchCV(\n    KNeighborsClassifier(), \n    parameters,\n    cv=3,\n)\ntrain_and_print_results(classifier, 'KNeighborsClassifier with tuning')","metadata":{"_uuid":"1271bf1e-bdf1-4eec-a8ec-ec18b0fa2109","_cell_guid":"caf886e5-d978-4ec1-a9cd-47735f90d010","collapsed":false,"jupyter":{"outputs_hidden":false},"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-21T16:02:06.151745Z","iopub.execute_input":"2021-05-21T16:02:06.152448Z","iopub.status.idle":"2021-05-21T16:02:06.858864Z","shell.execute_reply.started":"2021-05-21T16:02:06.152395Z","shell.execute_reply":"2021-05-21T16:02:06.857696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.4 Support Vector Classifier","metadata":{"_uuid":"cca40b31-d7bb-40bb-aca0-0af2e6e7b9fa","_cell_guid":"9cc8d6f2-5069-4572-a0a8-32cd39ab8b1c","trusted":true}},{"cell_type":"code","source":"# No tuning\nclassifier = SVC()\ntrain_and_print_results(classifier, 'SVC no tuning')\n\n# Linear\nparameters = {\n    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n    'kernel': ['linear'],\n}\nclassifier = GridSearchCV(\n    SVC(),\n    parameters,\n    cv=3,\n)\ntrain_and_print_results(classifier, 'Linear SVC with tuning')\n\n# Poly\nparameters = {\n    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n    'kernel': ['poly'],\n    'degree': [.5, 2, 3, 4, 5, 10],\n    'gamma': ['scale', 'auto'],\n}\nclassifier = GridSearchCV(\n    SVC(),\n    parameters,\n    cv=3,\n)\ntrain_and_print_results(classifier, 'Poly SVC with tuning')\n\n# RBF\nparameters = {\n    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n    'kernel': ['rbf'],\n    'gamma': ['scale', 'auto'],\n}\nclassifier = GridSearchCV(\n    SVC(),\n    parameters,\n    cv=3,\n)\ntrain_and_print_results(classifier, 'RBF SVC with tuning')","metadata":{"_uuid":"31cb3eee-7940-4f89-9999-bae369784a6f","_cell_guid":"e3051293-3437-4c27-a927-6d69815e841f","collapsed":false,"jupyter":{"outputs_hidden":false},"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-21T16:02:06.860612Z","iopub.execute_input":"2021-05-21T16:02:06.861307Z","iopub.status.idle":"2021-05-21T16:02:09.204351Z","shell.execute_reply.started":"2021-05-21T16:02:06.861258Z","shell.execute_reply":"2021-05-21T16:02:09.202104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.5 Stochastic Gradient Descent Classifier","metadata":{"_uuid":"db2e49fd-9eac-41c6-96e7-09567017cbbe","_cell_guid":"4100436f-1a41-4491-8017-4359ab328a96","trusted":true}},{"cell_type":"code","source":"# No tuning\nclassifier = SGDClassifier(random_state=75)\ntrain_and_print_results(classifier, 'SGDClassifier no tuning')\n\n# Tuning\nparameters = {\n    'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron', 'squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n    'penalty': ['l1', 'l2', 'elasticnet'],\n    'random_state': [75],\n}\nclassifier = GridSearchCV(\n    SGDClassifier(),\n    parameters,\n    cv=3,\n)\ntrain_and_print_results(classifier, 'SGDClassifier with tuning')","metadata":{"_uuid":"3343d163-f4a9-4839-86a1-3ac82c57b419","_cell_guid":"09025e07-8e92-4e9b-a0e0-1aece4e27d62","collapsed":false,"jupyter":{"outputs_hidden":false},"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-21T16:02:09.205918Z","iopub.execute_input":"2021-05-21T16:02:09.206309Z","iopub.status.idle":"2021-05-21T16:02:09.966378Z","shell.execute_reply.started":"2021-05-21T16:02:09.206274Z","shell.execute_reply":"2021-05-21T16:02:09.964945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Results\nThe best performing model was the poly kernal Support Vector Classifier, with an accuracy of 85%. It should be noted that the accuracy is fairly dependent on the random state used to split the training and testing data. This is likely due to the relatively small data set provided, with only 303 samples.","metadata":{"_uuid":"fca14602-331d-4e60-878d-7c7eb32ee8d0","_cell_guid":"0898b23b-4c9c-4ddf-ae4d-4e7dc89ed2c8","trusted":true}}]}