{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Libraries used in this project\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\n# Display all columns\npd.set_option('display.max_columns', None)\n\nprint(\"Pandas version: \", pd.__version__)\nprint(\"Matplotlib version: \", matplotlib.__version__)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the dataframe\nraw_data = pd.read_csv('../input/wine-quality/winequalityN.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 1. DATA INVESTIGATION","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DATA INVESTIGATION: Descriptive statistics\nraw_data.head(10) # Display it in tabular form of data\n# raw_data.shape # Gives total rows and columns\n# raw_data.columns # Gives lists of columns\n# raw_data.info() # Gives datatype of each column","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DATA INVESTIGATION: Overall descriptive statistics of the raw data\npd.DataFrame([raw_data.mean(),\n              raw_data.median(), \n              raw_data.std(), \n              raw_data.var()], \n             index=['Mean', 'Median','Std. dev', 'Variance'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# - Highest variance was observed in residual sugar ARE'\n# 'residual sugar', 'free sulfur dioxide', and 'total sulfur dioxide'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DATA INVESTIGATION: is there unbalanced dataset in categorical variables\nraw_data[\"type\"].value_counts()\n# The result is yes.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  DATA INVESTIGATION: Descriptive statistics for each categorical label\nraw_data.groupby(\"type\").describe()\n\n# White wine:Red wine is about 3:1. Hence there is concern of unbalanced dataset\n# The max standard deviation for red wine includes 'free sulfur dioxide', 'total sulfur dioxide', 'pH', 'alcohol',\n# The max standard deviation for white wine includes 'residual sugar', 'free sulfur dioxide', 'total sulfur dioxide', 'pH', 'alcohol'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DATA INVESTIGATION: Visualise the class imbalance in this dataset\npd.value_counts(raw_data['type']).plot.bar()\nplt.title('Wine class histogram')\nplt.xlabel('Wine')\nplt.ylabel('Frequency')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DATA INVESTIGATION: Check if any row is duplicated\n# Find out the total number of duplicated rows\nraw_data.duplicated(subset=None, keep='first').sum() # Considers all columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DATA INVESTIGATION: Descriptive statistics of duplicated rows for both red and white wine\nduplicate_rows = raw_data[raw_data.duplicated()].copy()\nduplicate_rows.groupby(\"type\").describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DATA INVESTIGATION: Check if there is any NAs in the dataset\n# Count the na values of all columns  \nraw_data.isnull().sum().sort_values(ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Count the na values of all columns in terms of percentage\n(raw_data.isnull().sum()* 100 / len(raw_data)).round(2).sort_values(ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 2. DATA PREPROCESSING\n\n# DATA PREPROCESSING: Handling duplicated rows\n# - Duplicates are an extreme case of nonrandom sampling.\n# - they bias your fitted model. \n# - Including them will essentially lead to the model overfitting.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DATA PREPROCESSING: Remove the duplicated rows\nwithout_duplicate = raw_data.drop_duplicates(keep='first').copy()\nwithout_duplicate.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DATA PREPROCESSING: Descriptive statistics after duplicates are removed\nwithout_duplicate.groupby(\"type\").describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DATA PREPROCESSING: check NA in precentage after duplicates are removed\n(without_duplicate.isnull().sum()* 100 / len(without_duplicate)).round(2).sort_values(ascending = False)\n\n# Since the Na values are less than 1% hence they can safely be removed (rule of thumb is 5%)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DATA PREPROCESSING: Visualise NAs after removing duplicated rows in the form of pattern to see their location\nsns.heatmap(without_duplicate.isnull(), cbar=True)\n\n# Nas are located very sparse.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DATA PREPROCESSING: Remove all NAs\n# Drop the whole row that contains the empty cell\n# Always assign the new dataframe\nwithout_dup_na = without_duplicate.dropna(how= \"any\").copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DATA PREPROCESSING: Check if there is any NAs\nwithout_dup_na.isnull().values.any()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DATA PREPROCESSING: Again visualise the categorical variable after removing duplicates and NAs\n\n\npd.value_counts(without_dup_na['type']).plot.bar()\nplt.title('Wine class histogram')\nplt.xlabel('Wine')\nplt.ylabel('Frequency')\n\n# Still we got the unbalanced dataset\n# Next task is to balance the dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 3. DATA PREPARATION","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DATA PREPARATION: Prepare target variable and independent variable\nX = np.array(without_dup_na.iloc[:,without_dup_na.columns != 'type'])\ny = np.array(without_dup_na.iloc[:,without_dup_na.columns == 'type'])\n\nprint(\"Shape of X(PREDICTORS): {}\".format(X.shape))\nprint(\"Shape of y(TARGET): {}\".format(y.shape))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DATA PREPARATION: Create training/testing sets\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=10, shuffle=True)\n\nprint(\"Number of X_train dataset: \", X_train.shape)\nprint(\"Number of y_train dataset: \", y_train.shape)\nprint(\"\\nNumber of X_test dataset: \", X_test.shape)\nprint(\"Number of y_test dataset: \", y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DATA PREPARATION: Handling Unbalanced dataset\n# Perform SMOTE algorithm to handle the unbalanced dataset\n# https://www.kaggle.com/qianchao/smote-with-imbalance-data\n\nprint(\"Before OverSampling of training dataset, counts of label 'white': {}\".format(sum(y_train==\"white\")))\nprint(\"Before OverSampling of training dataset, counts of label 'red': {} \\n\".format(sum(y_train==\"red\")))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DATA PREPARATION: Handling Unbalanced dataset by oversampling label red wine\n\nfrom imblearn.over_sampling import SMOTE\nsm = SMOTE(random_state=10)\n\nX_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())\n\nprint('After OverSampling, the shape of train_X_res: {}'.format(X_train_res.shape))\nprint('After OverSampling, the shape of train_y_res: {} \\n'.format(y_train_res.shape))\n\nprint(\"After OverSampling, counts of label 'white': {}\".format(sum(y_train_res==\"white\")))\nprint(\"After OverSampling, counts of label 'red': {} \\n\".format(sum(y_train_res==\"red\")))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 4. MODEL - PIPELINE CREATION","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# MODEL - PIPELINE: Libraries needed\nfrom sklearn.pipeline import Pipeline\nimport joblib\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 4. MODEL - PIPELINE CREATION- Create pipelines with or without PCA\n\n##  First create three different pipelines without PCA\n# Logistic Regression\npipeline_lr = Pipeline([('scalar1', StandardScaler()),\n                       ('lr_classifier', LogisticRegression(random_state=0))])\n\n# Pipeline for decision tree\npipeline_dt = Pipeline([('dt_classifier', DecisionTreeClassifier())])\n\n# Pipeline for random forest classification\npipeline_rf = Pipeline([('rf_classifier', RandomForestClassifier())])\n\n## Now create pipelines with PCA\n\n# Pipeline for logistic regression\npipeline_pca_lr = Pipeline([('scalar1', StandardScaler()),\n                       ('pca1', PCA(n_components=2)),\n                       ('lr_classifier', LogisticRegression(random_state=0))])\n\n# Pipeline for decision tree\npipeline_pca_dt = Pipeline([('scalar2', StandardScaler()),\n                       ('pca2', PCA(n_components=2)),\n                       ('dt_classifier', DecisionTreeClassifier())])\n# Pipeline for random forest classification\npipeline_pca_rf = Pipeline([('scalar3', StandardScaler()),\n                       ('pca3', PCA(n_components=2)),\n                       ('rf_classifier', RandomForestClassifier())])\n\n# Create the list of pipelines for classifier\npipelines = [pipeline_lr, pipeline_dt, pipeline_rf, pipeline_pca_lr, pipeline_pca_dt, pipeline_pca_rf]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 4. MODEL - PIPELINE CREATION: Fit the pipelines in training dataset\nfor pipe in pipelines:\n    pipe.fit(X_train_res, y_train_res)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 5. MODEL EVALUATION: Dictionary of pipelines and classifier type for ease of reference\npipe_dict = {0: 'Logistic Regression only', 1: 'Decision Tree classifier only', 2: 'Random Forest Classifier only',3: 'First PCA and Logistic Regression', 4: 'First PCA and Decision Tree classifier', 5: 'First PCA and Random Forest Classifier'}\n\n# Model evaluation in training dataset\nfor i, model in enumerate(pipelines):\n    print(\"{} Training Accuracy: {}\".format(pipe_dict[i], model.score(X_train_res, y_train_res).round(4))) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 5. MODEL EVALUATION : Model evaluation in testing dataset\nfor i, model in enumerate(pipelines):\n    print(\"{} Test Accuracy: {}\".format(pipe_dict[i], model.score(X_test, y_test).round(4)))  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 5. MODEL EVALUATION :Best Accuracy in testing dataset\n\n# Initializer\nbest_accuracy = 0.0\nbest_classifier = 0\nbest_pipeline = \"\"\n\nfor i, model in enumerate(pipelines):\n    if model.score(X_test, y_test) > best_accuracy:\n        best_accuracy = model.score(X_test, y_test)\n        best_pipeline = model\n        best_classifier = i\nprint(\"Classifier with best accuracy in test dataset: {}\".format(pipe_dict[best_classifier]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 6. PERFORMANCE METRICS OF BEST ALGORITHM\n\n# Since Logistic Regression as well as Random forest works really well. Hence we will do detailed performance metrics analysis of these algorithms.\n# Similarly, performing PCA before applying LR or Random forests algorithms did not enhance the performance of the model.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 6. PERFORMANCE METRICS OF BEST ALGORITHM: Pipeline for logistic regression as well as random forest classification\n\n# Preprocessing of training data, fit model for Logistic Regression only (Note:NO PCA)\npipeline_lr.fit(X_train_res, y_train_res)\n\ny_pred_LR = pipeline_lr.predict(X_test)\n\n# Preprocessing of training data, fit model for Random forest classification only (Note:NO PCA)\npipeline_rf.fit(X_train_res, y_train_res)\n\ny_pred_RF = pipeline_rf.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 6. DETAILED PERFORMANCE METRICS OF BEST ALGORITHM: LOGISTIC REGRESSION WITHOUT PCA\n\nfrom sklearn.metrics import confusion_matrix\nconfusion = confusion_matrix(y_test, y_pred_LR)\nprint('Confusion Matrix\\n')\nprint(confusion)\n\n#importing accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nprint('\\nAccuracy score: {:.2f}\\n'.format(accuracy_score(y_test, y_pred_LR).round(4)))\n\nprint('Micro Precision: {:.2f}'.format(precision_score(y_test, y_pred_LR, average='micro')))\nprint('Micro Recall: {:.2f}'.format(recall_score(y_test, y_pred_LR, average='micro')))\nprint('Micro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred_LR, average='micro')))\n\nprint('Macro Precision: {:.2f}'.format(precision_score(y_test, y_pred_LR, average='macro')))\nprint('Macro Recall: {:.2f}'.format(recall_score(y_test, y_pred_LR, average='macro')))\nprint('Macro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred_LR, average='macro')))\n\nprint('Weighted Precision: {:.2f}'.format(precision_score(y_test, y_pred_LR, average='weighted')))\nprint('Weighted Recall: {:.2f}'.format(recall_score(y_test, y_pred_LR, average='weighted')))\nprint('Weighted F1-score: {:.2f}'.format(f1_score(y_test, y_pred_LR, average='weighted')))\n\nfrom sklearn.metrics import classification_report\nprint('\\nClassification Report\\n')\nprint(classification_report(y_test, y_pred_LR, target_names=['Red wine', 'White wine']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 6. DETAILED PERFORMANCE METRICS OF BEST ALGORITHM: RANDOM FOREST CLASSIFICATION WITHOUT PCA\nconfusion = confusion_matrix(y_test, y_pred_RF)\nprint('Confusion Matrix\\n')\nprint(confusion)\n\n#importing accuracy_score, precision_score, recall_score, f1_score\nprint('\\nAccuracy score: {:.2f}\\n'.format(accuracy_score(y_test, y_pred_RF).round(4)))\n\nprint('Micro Precision: {:.2f}'.format(precision_score(y_test, y_pred_RF, average='micro')))\nprint('Micro Recall: {:.2f}'.format(recall_score(y_test, y_pred_RF, average='micro')))\nprint('Micro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred_RF, average='micro')))\n\nprint('Macro Precision: {:.2f}'.format(precision_score(y_test, y_pred_RF, average='macro')))\nprint('Macro Recall: {:.2f}'.format(recall_score(y_test, y_pred_RF, average='macro')))\nprint('Macro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred_RF, average='macro')))\n\nprint('Weighted Precision: {:.2f}'.format(precision_score(y_test, y_pred_RF, average='weighted')))\nprint('Weighted Recall: {:.2f}'.format(recall_score(y_test, y_pred_RF, average='weighted')))\nprint('Weighted F1-score: {:.2f}'.format(f1_score(y_test, y_pred_RF, average='weighted')))\n\nfrom sklearn.metrics import classification_report\nprint('\\nClassification Report\\n')\nprint(classification_report(y_test, y_pred_RF, target_names=['Red wine', 'White wine']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 7. FINAL EVALUATION","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 7. FINAL EVALUATION: Both Logistic regression and Random forest works equally well. I decided to use the logistic regression as it is simple compared to random forest.\n\n#  Plot the confusion matrix\n\n# Creates a confusion matrix\ncm = confusion_matrix(y_test, y_pred_LR) \n\n# Transform to df for easier plotting\ncm_df = pd.DataFrame(cm,\n                     index = ['Red wine','White wine'], \n                     columns = ['Red wine','White wine'])\n\nplt.figure(figsize=(5.5,4))\nsns.heatmap(cm_df, annot=True, fmt='d',annot_kws={\"size\": 20})\nplt.title('Logistic Regression \\nAccuracy:{0:.3f}'.format(accuracy_score(y_test, y_pred_LR)))\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Final conclusion:\n# Since the data looks very ideal hence, the Logistic Regression as well as Random Forest gave best result.\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}