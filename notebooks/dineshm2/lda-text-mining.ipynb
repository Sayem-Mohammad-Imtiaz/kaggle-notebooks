{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":2,"outputs":[{"output_type":"stream","text":"['abcnews-date-text.csv']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/abcnews-date-text.csv\", error_bad_lines=False)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_text = data[:300000][['headline_text']]\ndata_text['index']=data_text.index\ndocuments = data_text","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"documents[:5]","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"                                       headline_text  index\n0  aba decides against community broadcasting lic...      0\n1     act fire witnesses must be aware of defamation      1\n2     a g calls for infrastructure protection summit      2\n3           air nz staff in aust strike for pay rise      3\n4      air nz strike to affect australian travellers      4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>headline_text</th>\n      <th>index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>aba decides against community broadcasting lic...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>act fire witnesses must be aware of defamation</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a g calls for infrastructure protection summit</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>air nz staff in aust strike for pay rise</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>air nz strike to affect australian travellers</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gensim\nfrom gensim.utils import simple_preprocess\nfrom gensim.parsing.preprocessing import STOPWORDS\nfrom nltk.stem import WordNetLemmatizer , SnowballStemmer\nfrom nltk.stem.porter import *\nnp.random.seed(400)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nnltk.download('wordnet')","execution_count":7,"outputs":[{"output_type":"stream","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","name":"stdout"},{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"True"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"stemmer = SnowballStemmer(\"english\")\ndef lemmatize_stemming(text):\n    return stemmer.stem(WordNetLemmatizer().lemmatize(text,pos='v'))\n\ndef preprocess(text):\n    result=[]\n    for token in gensim.utils.simple_preprocess(text):\n        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) >3:\n            result.append(lemmatize_stemming(token))\n    return result","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"doc_num = 4310\ndoc_sample = documents[documents['index']==doc_num].values[0][0]\n\nprint(\"original document\")\nwords=[]\nfor word in doc_sample.split(' '):\n    words.append(word)\nprint(words)\nprint(\"\\n\\nTokenized and lemmatized document: \")\nprint(preprocess(doc_sample))\n    ","execution_count":28,"outputs":[{"output_type":"stream","text":"original document\n['rain', 'helps', 'dampen', 'bushfires']\n\n\nTokenized and lemmatized document: \n['rain', 'help', 'dampen', 'bushfir']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"doc_sample","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"'rain helps dampen bushfires'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"stemmer = SnowballStemmer(\"english\")\noriginal_words = ['caresses', 'flies', 'dies', 'mules', 'denied','died', 'agreed', 'owned', \n           'humbled', 'sized','meeting', 'stating', 'siezing', 'itemization','sensational', \n           'traditional', 'reference', 'colonizer','plotted']\nsingles = [stemmer.stem(plural) for plural in original_words]\n\npd.DataFrame(data={'original word':original_words, 'stemmed':singles })","execution_count":23,"outputs":[{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"   original word stemmed\n0       caresses  caress\n1          flies     fli\n2           dies     die\n3          mules    mule\n4         denied    deni\n5           died     die\n6         agreed    agre\n7          owned     own\n8        humbled   humbl\n9          sized    size\n10       meeting    meet\n11       stating   state\n12       siezing    siez\n13   itemization    item\n14   sensational  sensat\n15   traditional  tradit\n16     reference   refer\n17     colonizer   colon\n18       plotted    plot","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>original word</th>\n      <th>stemmed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>caresses</td>\n      <td>caress</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>flies</td>\n      <td>fli</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>dies</td>\n      <td>die</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>mules</td>\n      <td>mule</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>denied</td>\n      <td>deni</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>died</td>\n      <td>die</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>agreed</td>\n      <td>agre</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>owned</td>\n      <td>own</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>humbled</td>\n      <td>humbl</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>sized</td>\n      <td>size</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>meeting</td>\n      <td>meet</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>stating</td>\n      <td>state</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>siezing</td>\n      <td>siez</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>itemization</td>\n      <td>item</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>sensational</td>\n      <td>sensat</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>traditional</td>\n      <td>tradit</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>reference</td>\n      <td>refer</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>colonizer</td>\n      <td>colon</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>plotted</td>\n      <td>plot</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"processed_docs = documents['headline_text'].map(preprocess)","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"processed_docs[:10]","execution_count":30,"outputs":[{"output_type":"execute_result","execution_count":30,"data":{"text/plain":"0            [decid, communiti, broadcast, licenc]\n1                               [wit, awar, defam]\n2           [call, infrastructur, protect, summit]\n3                      [staff, aust, strike, rise]\n4             [strike, affect, australian, travel]\n5               [ambiti, olsson, win, tripl, jump]\n6           [antic, delight, record, break, barca]\n7    [aussi, qualifi, stosur, wast, memphi, match]\n8            [aust, address, secur, council, iraq]\n9                         [australia, lock, timet]\nName: headline_text, dtype: object"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"dictionary= gensim.corpora.Dictionary(processed_docs)","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count=0\nfor k,v in dictionary.iteritems():\n    print(k,v)\n    count +=1\n    if count > 10:\n        break","execution_count":37,"outputs":[{"output_type":"stream","text":"0 broadcast\n1 communiti\n2 decid\n3 licenc\n4 awar\n5 defam\n6 wit\n7 call\n8 infrastructur\n9 protect\n10 summit\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"dictionary.filter_extremes(no_below=15,no_above=0.1,keep_n=100000)","execution_count":38,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bow_corpus= [dictionary.doc2bow(doc) for doc in processed_docs]","execution_count":39,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bow_corpus[doc_num]","execution_count":40,"outputs":[{"output_type":"execute_result","execution_count":40,"data":{"text/plain":"[(71, 1), (107, 1), (462, 1), (3530, 1)]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"bow_doc_4310 = bow_corpus[doc_num]\nfor i in range(len(bow_doc_4310)):\n    print (\"Word{} (\\\"{}\\\")) appears {} time.\".format(bow_doc_4310[i][0], \n                                                     dictionary[bow_doc_4310[i][0]], \n                                                     bow_doc_4310[i][1]))","execution_count":41,"outputs":[{"output_type":"stream","text":"Word71 (\"bushfir\")) appears 1 time.\nWord107 (\"help\")) appears 1 time.\nWord462 (\"rain\")) appears 1 time.\nWord3530 (\"dampen\")) appears 1 time.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from gensim import corpora,models\ntfidf = models.TfidfModel(bow_corpus)","execution_count":42,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corpus_tfidf = tfidf[bow_corpus]\n","execution_count":43,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pprint import pprint\nfor doc in corpus_tfidf:\n    pprint(doc)\n    break","execution_count":44,"outputs":[{"output_type":"stream","text":"[(0, 0.5959813347777092),\n (1, 0.39204529549491984),\n (2, 0.48531419274988147),\n (3, 0.5055461098578569)]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lda_model = gensim.models.LdaMulticore(bow_corpus, \n                                       num_topics=10, \n                                       id2word = dictionary, \n                                       passes = 2, \n                                       workers=2)","execution_count":45,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for idx, topic in lda_model.print_topics(-1):\n    print(\"Topic: {} \\nWords: {}\".format(idx, topic))\n    print(\"\\n\")","execution_count":46,"outputs":[{"output_type":"stream","text":"Topic: 0 \nWords: 0.024*\"open\" + 0.021*\"test\" + 0.018*\"world\" + 0.017*\"win\" + 0.014*\"lead\" + 0.014*\"south\" + 0.012*\"take\" + 0.012*\"timor\" + 0.011*\"strike\" + 0.010*\"east\"\n\n\nTopic: 1 \nWords: 0.034*\"report\" + 0.030*\"help\" + 0.017*\"urg\" + 0.017*\"deal\" + 0.015*\"blaze\" + 0.015*\"inquiri\" + 0.012*\"firefight\" + 0.012*\"close\" + 0.011*\"bushfir\" + 0.011*\"resid\"\n\n\nTopic: 2 \nWords: 0.038*\"crash\" + 0.022*\"closer\" + 0.017*\"die\" + 0.016*\"road\" + 0.016*\"coast\" + 0.016*\"sydney\" + 0.014*\"train\" + 0.013*\"dead\" + 0.012*\"kill\" + 0.012*\"gold\"\n\n\nTopic: 3 \nWords: 0.041*\"plan\" + 0.035*\"council\" + 0.031*\"govt\" + 0.030*\"water\" + 0.017*\"urg\" + 0.016*\"group\" + 0.012*\"fund\" + 0.012*\"chang\" + 0.012*\"concern\" + 0.012*\"consid\"\n\n\nTopic: 4 \nWords: 0.023*\"hospit\" + 0.022*\"labor\" + 0.019*\"defend\" + 0.019*\"elect\" + 0.016*\"protest\" + 0.016*\"minist\" + 0.015*\"power\" + 0.014*\"govt\" + 0.014*\"work\" + 0.013*\"begin\"\n\n\nTopic: 5 \nWords: 0.045*\"warn\" + 0.020*\"fight\" + 0.017*\"england\" + 0.017*\"nuclear\" + 0.016*\"year\" + 0.014*\"action\" + 0.014*\"threat\" + 0.011*\"iran\" + 0.010*\"say\" + 0.009*\"program\"\n\n\nTopic: 6 \nWords: 0.019*\"school\" + 0.018*\"drought\" + 0.018*\"farmer\" + 0.015*\"fund\" + 0.014*\"price\" + 0.014*\"market\" + 0.013*\"rise\" + 0.013*\"boost\" + 0.012*\"rain\" + 0.012*\"feder\"\n\n\nTopic: 7 \nWords: 0.028*\"iraq\" + 0.018*\"talk\" + 0.016*\"australia\" + 0.015*\"troop\" + 0.012*\"storm\" + 0.012*\"leader\" + 0.010*\"bush\" + 0.010*\"victori\" + 0.010*\"hold\" + 0.010*\"tiger\"\n\n\nTopic: 8 \nWords: 0.074*\"polic\" + 0.031*\"charg\" + 0.027*\"court\" + 0.023*\"face\" + 0.020*\"kill\" + 0.020*\"investig\" + 0.019*\"attack\" + 0.019*\"miss\" + 0.018*\"jail\" + 0.018*\"death\"\n\n\nTopic: 9 \nWords: 0.034*\"claim\" + 0.025*\"opposit\" + 0.021*\"deni\" + 0.019*\"govt\" + 0.018*\"say\" + 0.018*\"break\" + 0.013*\"reject\" + 0.013*\"rule\" + 0.013*\"wont\" + 0.011*\"rudd\"\n\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, \n                                             num_topics=10, \n                                             id2word = dictionary, \n                                             passes = 2, \n                                             workers=4)","execution_count":47,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for idx, topic in lda_model_tfidf.print_topics(-1):\n    print(\"Topic: {} Word: {}\".format(idx, topic))\n    print(\"\\n\")","execution_count":48,"outputs":[{"output_type":"stream","text":"Topic: 0 Word: 0.011*\"market\" + 0.009*\"price\" + 0.007*\"black\" + 0.006*\"profit\" + 0.006*\"record\" + 0.005*\"resign\" + 0.005*\"time\" + 0.005*\"eagl\" + 0.005*\"share\" + 0.005*\"wait\"\n\n\nTopic: 1 Word: 0.009*\"plan\" + 0.008*\"govt\" + 0.008*\"council\" + 0.007*\"farm\" + 0.007*\"drought\" + 0.007*\"farmer\" + 0.006*\"telstra\" + 0.006*\"urg\" + 0.006*\"wind\" + 0.006*\"group\"\n\n\nTopic: 2 Word: 0.008*\"liber\" + 0.006*\"beazley\" + 0.006*\"quit\" + 0.005*\"interview\" + 0.005*\"surgeri\" + 0.005*\"polic\" + 0.005*\"coach\" + 0.005*\"maintain\" + 0.005*\"militari\" + 0.004*\"warrior\"\n\n\nTopic: 3 Word: 0.012*\"nuclear\" + 0.006*\"bushfir\" + 0.006*\"iran\" + 0.006*\"celebr\" + 0.005*\"korea\" + 0.005*\"flag\" + 0.004*\"lake\" + 0.004*\"evid\" + 0.004*\"dump\" + 0.004*\"villag\"\n\n\nTopic: 4 Word: 0.011*\"govt\" + 0.010*\"water\" + 0.009*\"health\" + 0.009*\"fund\" + 0.008*\"urg\" + 0.008*\"plan\" + 0.007*\"indigen\" + 0.007*\"council\" + 0.006*\"boost\" + 0.006*\"hous\"\n\n\nTopic: 5 Word: 0.023*\"polic\" + 0.018*\"charg\" + 0.016*\"crash\" + 0.013*\"court\" + 0.013*\"murder\" + 0.012*\"investig\" + 0.012*\"miss\" + 0.011*\"search\" + 0.010*\"woman\" + 0.009*\"face\"\n\n\nTopic: 6 Word: 0.028*\"closer\" + 0.020*\"kill\" + 0.014*\"iraq\" + 0.010*\"bomb\" + 0.010*\"troop\" + 0.008*\"attack\" + 0.008*\"rudd\" + 0.007*\"iraqi\" + 0.007*\"soldier\" + 0.007*\"blast\"\n\n\nTopic: 7 Word: 0.009*\"water\" + 0.007*\"restrict\" + 0.006*\"titl\" + 0.006*\"uranium\" + 0.006*\"eas\" + 0.006*\"break\" + 0.006*\"hill\" + 0.006*\"kangaroo\" + 0.005*\"rate\" + 0.005*\"open\"\n\n\nTopic: 8 Word: 0.008*\"hick\" + 0.008*\"firefight\" + 0.008*\"east\" + 0.008*\"blaze\" + 0.007*\"export\" + 0.007*\"south\" + 0.007*\"bird\" + 0.006*\"solomon\" + 0.006*\"cyclon\" + 0.006*\"crew\"\n\n\nTopic: 9 Word: 0.007*\"toll\" + 0.007*\"strike\" + 0.007*\"govt\" + 0.006*\"union\" + 0.006*\"chang\" + 0.006*\"climat\" + 0.006*\"rais\" + 0.006*\"legal\" + 0.006*\"action\" + 0.006*\"teacher\"\n\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"processed_docs[4310]","execution_count":49,"outputs":[{"output_type":"execute_result","execution_count":49,"data":{"text/plain":"['rain', 'help', 'dampen', 'bushfir']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for index, score in sorted(lda_model[bow_corpus[doc_num]], key=lambda tup: -1*tup[1]):\n    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))","execution_count":51,"outputs":[{"output_type":"stream","text":"\nScore: 0.6199342608451843\t \nTopic: 0.034*\"report\" + 0.030*\"help\" + 0.017*\"urg\" + 0.017*\"deal\" + 0.015*\"blaze\" + 0.015*\"inquiri\" + 0.012*\"firefight\" + 0.012*\"close\" + 0.011*\"bushfir\" + 0.011*\"resid\"\n\nScore: 0.22005116939544678\t \nTopic: 0.019*\"school\" + 0.018*\"drought\" + 0.018*\"farmer\" + 0.015*\"fund\" + 0.014*\"price\" + 0.014*\"market\" + 0.013*\"rise\" + 0.013*\"boost\" + 0.012*\"rain\" + 0.012*\"feder\"\n\nScore: 0.020001819357275963\t \nTopic: 0.024*\"open\" + 0.021*\"test\" + 0.018*\"world\" + 0.017*\"win\" + 0.014*\"lead\" + 0.014*\"south\" + 0.012*\"take\" + 0.012*\"timor\" + 0.011*\"strike\" + 0.010*\"east\"\n\nScore: 0.020001819357275963\t \nTopic: 0.038*\"crash\" + 0.022*\"closer\" + 0.017*\"die\" + 0.016*\"road\" + 0.016*\"coast\" + 0.016*\"sydney\" + 0.014*\"train\" + 0.013*\"dead\" + 0.012*\"kill\" + 0.012*\"gold\"\n\nScore: 0.020001819357275963\t \nTopic: 0.041*\"plan\" + 0.035*\"council\" + 0.031*\"govt\" + 0.030*\"water\" + 0.017*\"urg\" + 0.016*\"group\" + 0.012*\"fund\" + 0.012*\"chang\" + 0.012*\"concern\" + 0.012*\"consid\"\n\nScore: 0.020001819357275963\t \nTopic: 0.023*\"hospit\" + 0.022*\"labor\" + 0.019*\"defend\" + 0.019*\"elect\" + 0.016*\"protest\" + 0.016*\"minist\" + 0.015*\"power\" + 0.014*\"govt\" + 0.014*\"work\" + 0.013*\"begin\"\n\nScore: 0.020001819357275963\t \nTopic: 0.045*\"warn\" + 0.020*\"fight\" + 0.017*\"england\" + 0.017*\"nuclear\" + 0.016*\"year\" + 0.014*\"action\" + 0.014*\"threat\" + 0.011*\"iran\" + 0.010*\"say\" + 0.009*\"program\"\n\nScore: 0.020001819357275963\t \nTopic: 0.028*\"iraq\" + 0.018*\"talk\" + 0.016*\"australia\" + 0.015*\"troop\" + 0.012*\"storm\" + 0.012*\"leader\" + 0.010*\"bush\" + 0.010*\"victori\" + 0.010*\"hold\" + 0.010*\"tiger\"\n\nScore: 0.020001819357275963\t \nTopic: 0.074*\"polic\" + 0.031*\"charg\" + 0.027*\"court\" + 0.023*\"face\" + 0.020*\"kill\" + 0.020*\"investig\" + 0.019*\"attack\" + 0.019*\"miss\" + 0.018*\"jail\" + 0.018*\"death\"\n\nScore: 0.020001819357275963\t \nTopic: 0.034*\"claim\" + 0.025*\"opposit\" + 0.021*\"deni\" + 0.019*\"govt\" + 0.018*\"say\" + 0.018*\"break\" + 0.013*\"reject\" + 0.013*\"rule\" + 0.013*\"wont\" + 0.011*\"rudd\"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for index, score in sorted(lda_model_tfidf[bow_corpus[doc_num]], key=lambda tup: -1*tup[1]):\n    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))","execution_count":52,"outputs":[{"output_type":"stream","text":"\nScore: 0.5791903734207153\t \nTopic: 0.009*\"water\" + 0.007*\"restrict\" + 0.006*\"titl\" + 0.006*\"uranium\" + 0.006*\"eas\" + 0.006*\"break\" + 0.006*\"hill\" + 0.006*\"kangaroo\" + 0.005*\"rate\" + 0.005*\"open\"\n\nScore: 0.26076966524124146\t \nTopic: 0.012*\"nuclear\" + 0.006*\"bushfir\" + 0.006*\"iran\" + 0.006*\"celebr\" + 0.005*\"korea\" + 0.005*\"flag\" + 0.004*\"lake\" + 0.004*\"evid\" + 0.004*\"dump\" + 0.004*\"villag\"\n\nScore: 0.02000747248530388\t \nTopic: 0.008*\"hick\" + 0.008*\"firefight\" + 0.008*\"east\" + 0.008*\"blaze\" + 0.007*\"export\" + 0.007*\"south\" + 0.007*\"bird\" + 0.006*\"solomon\" + 0.006*\"cyclon\" + 0.006*\"crew\"\n\nScore: 0.020006336271762848\t \nTopic: 0.009*\"plan\" + 0.008*\"govt\" + 0.008*\"council\" + 0.007*\"farm\" + 0.007*\"drought\" + 0.007*\"farmer\" + 0.006*\"telstra\" + 0.006*\"urg\" + 0.006*\"wind\" + 0.006*\"group\"\n\nScore: 0.02000594697892666\t \nTopic: 0.011*\"govt\" + 0.010*\"water\" + 0.009*\"health\" + 0.009*\"fund\" + 0.008*\"urg\" + 0.008*\"plan\" + 0.007*\"indigen\" + 0.007*\"council\" + 0.006*\"boost\" + 0.006*\"hous\"\n\nScore: 0.0200053621083498\t \nTopic: 0.023*\"polic\" + 0.018*\"charg\" + 0.016*\"crash\" + 0.013*\"court\" + 0.013*\"murder\" + 0.012*\"investig\" + 0.012*\"miss\" + 0.011*\"search\" + 0.010*\"woman\" + 0.009*\"face\"\n\nScore: 0.02000424452126026\t \nTopic: 0.007*\"toll\" + 0.007*\"strike\" + 0.007*\"govt\" + 0.006*\"union\" + 0.006*\"chang\" + 0.006*\"climat\" + 0.006*\"rais\" + 0.006*\"legal\" + 0.006*\"action\" + 0.006*\"teacher\"\n\nScore: 0.020003972575068474\t \nTopic: 0.011*\"market\" + 0.009*\"price\" + 0.007*\"black\" + 0.006*\"profit\" + 0.006*\"record\" + 0.005*\"resign\" + 0.005*\"time\" + 0.005*\"eagl\" + 0.005*\"share\" + 0.005*\"wait\"\n\nScore: 0.02000364102423191\t \nTopic: 0.008*\"liber\" + 0.006*\"beazley\" + 0.006*\"quit\" + 0.005*\"interview\" + 0.005*\"surgeri\" + 0.005*\"polic\" + 0.005*\"coach\" + 0.005*\"maintain\" + 0.005*\"militari\" + 0.004*\"warrior\"\n\nScore: 0.0200030580163002\t \nTopic: 0.028*\"closer\" + 0.020*\"kill\" + 0.014*\"iraq\" + 0.010*\"bomb\" + 0.010*\"troop\" + 0.008*\"attack\" + 0.008*\"rudd\" + 0.007*\"iraqi\" + 0.007*\"soldier\" + 0.007*\"blast\"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"unseen_document = \"My favorite sports activities are running and swimming.\"","execution_count":53,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n\nfor index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))","execution_count":54,"outputs":[{"output_type":"stream","text":"Score: 0.4200017750263214\t Topic: 0.024*\"open\" + 0.021*\"test\" + 0.018*\"world\" + 0.017*\"win\" + 0.014*\"lead\"\nScore: 0.2225508838891983\t Topic: 0.023*\"hospit\" + 0.022*\"labor\" + 0.019*\"defend\" + 0.019*\"elect\" + 0.016*\"protest\"\nScore: 0.21739985048770905\t Topic: 0.028*\"iraq\" + 0.018*\"talk\" + 0.016*\"australia\" + 0.015*\"troop\" + 0.012*\"storm\"\nScore: 0.020009607076644897\t Topic: 0.045*\"warn\" + 0.020*\"fight\" + 0.017*\"england\" + 0.017*\"nuclear\" + 0.016*\"year\"\nScore: 0.020008262246847153\t Topic: 0.041*\"plan\" + 0.035*\"council\" + 0.031*\"govt\" + 0.030*\"water\" + 0.017*\"urg\"\nScore: 0.020007528364658356\t Topic: 0.019*\"school\" + 0.018*\"drought\" + 0.018*\"farmer\" + 0.015*\"fund\" + 0.014*\"price\"\nScore: 0.02000551111996174\t Topic: 0.034*\"report\" + 0.030*\"help\" + 0.017*\"urg\" + 0.017*\"deal\" + 0.015*\"blaze\"\nScore: 0.02000551111996174\t Topic: 0.038*\"crash\" + 0.022*\"closer\" + 0.017*\"die\" + 0.016*\"road\" + 0.016*\"coast\"\nScore: 0.02000551111996174\t Topic: 0.074*\"polic\" + 0.031*\"charg\" + 0.027*\"court\" + 0.023*\"face\" + 0.020*\"kill\"\nScore: 0.02000551111996174\t Topic: 0.034*\"claim\" + 0.025*\"opposit\" + 0.021*\"deni\" + 0.019*\"govt\" + 0.018*\"say\"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}