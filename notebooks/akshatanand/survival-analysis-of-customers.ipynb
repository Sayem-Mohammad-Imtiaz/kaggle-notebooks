{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Survival Analysis : Implementation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install lifelines","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install ppscore","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom lifelines.plotting import plot_lifetimes      # Lifeline package for the Survival Analysis\n%pylab inline\nfigsize(12,6)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Example with a fictitious data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":" in case of user 4 and user 5, we don’t know at what time the event will occur, but still we are using that data to estimate the probability of survival. If we choose not to include the censored data, then it is highly likely that our estimates would be highly biased and under-estimated. The inclusion of censored data to calculate the estimates, makes the Survival Analysis very powerful","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"ni is deﬁned as the population at risk at time just prior to time ti; and di is defined as number of events occurred at time ti.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from lifelines import KaplanMeierFitter\n\n## Example Data \ndurations = [5,6,6,2.5,4,4]\nevent_observed = [1, 0, 0, 1, 1, 1]\n\n## create an kmf object\nkmf = KaplanMeierFitter() \n\n\n## Fit the data into the model\nkmf.fit(durations, event_observed,label='Kaplan Meier Estimate')\n\n## Create an estimate\nkmf.plot(ci_show=False) ## ci_show is meant for Confidence interval, since our data set is too tiny, thus i am not showing it.\nprint(kmf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Right censoring</b> – a data point is above a certain value but it is unknown by how much. ... The observed value is the minimum of the censoring and failure times; subjects whose <b>failure time is greater than their censoring time</b> are right-censored.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Real World Example ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### We will be using Telco Customer Churn data from Kaggle\nhttps://www.kaggle.com/blastchar/telco-customer-churn/","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"##  create a dataframe\ndf = pd.read_csv(\"../input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv\") ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Explanation of Dataset","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<b>customerID:</b> Customer ID\n<br>\n<b>gender:</b> Whether the customer is a male or a female\n<br>\n<b>SeniorCitizen:</b> Whether the customer is a senior citizen or not (1, 0)\n<br>\n<b>Partner:</b> Whether the customer has a partner or not (Yes, No)\n<br>\n<b>Dependents:</b> Whether the customer has dependents or not (Yes, No)\n<br>\n<b>tenure:</b> Number of months the customer has stayed with the company\n<br>\n<b>PhoneService:</b> Whether the customer has a phone service or not (Yes, No)\n<br>\n<b>MultipleLines:</b> Whether the customer has multiple lines or not (Yes, No, No phone service)\n<br>\n<b>InternetService:</b> Customer’s internet service provider (DSL, Fiber optic, No)\n<br>\n<b>OnlineSecurity:</b> Whether the customer has online security or not (Yes, No, No internet service)\n<br>\n<b>OnlineBackup:</b> Whether the customer has online backup or not (Yes, No, No internet service)\n<br>\n<b>DeviceProtection:</b> Whether the customer has device protection or not (Yes, No, No internet service)\n<br>\n<b>TechSupport:</b> Whether the customer has tech support or not (Yes, No, No internet service)\n<br>\n<b>StreamingTV:</b> Whether the customer has streaming TV or not (Yes, No, No internet service)\n<br>\n<b>StreamingMovies:</b> Whether the customer has streaming movies or not (Yes, No, No internet service)\n<br>\n<b>Contract:</b> The contract term of the customer (Month-to-month, One year, Two year)\n<br>\n<b>PaperlessBilling:</b> Whether the customer has paperless billing or not (Yes, No)\n<br>\n<b>PaymentMethod:</b> The customer’s payment method (Electronic check, Mailed check, Bank transfer (automatic), Credit card (automatic))\n<br>\n<b>MonthlyCharges:</b> The amount charged to the customer monthly\n<br>\n<b>TotalCharges:</b> The total amount charged to the customer\n<br>\n<b>Churn:</b> Whether the customer churned or not (Yes or No)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Have a first look at the data\ndf.head() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Data Types and Missing Values in Columns\ndf.info()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Convert TotalCharges to numeric\ndf['TotalCharges']=pd.to_numeric(df['TotalCharges'],errors='coerce')\n\n## Replace yes and No in the Churn column to 1 and 0. 1 for the event and 0 for the censured data.\ndf['Churn']=df['Churn'].apply(lambda x: 1 if x == 'Yes' else 0 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## after converting the column TotalCharges to numeric\ndf.info()  ## Column TotalCharges is having missing values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Impute the null value with the median value\n\ndf.TotalCharges.fillna(value=df['TotalCharges'].median(),inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ways of filling missing values - https://towardsdatascience.com/6-different-ways-to-compensate-for-missing-values-data-imputation-with-examples-6022d9ca0779","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Create a list of Categorical Columns\ncat_cols= [i  for i in df.columns if df[i].dtype==object]\ncat_cols.remove('customerID')  ## customerID has been removed because it is unique for all the rows.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## lets have a look at the categories and their distribution in all the categorical columns.\n\nfor i in cat_cols:\n    print('Column Name: ',i)\n    print(df[i].value_counts())\n    print('-----------------------------')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predictive Power Score","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import ppscore as pps\nplt.figure(figsize=(16,12))\nsns.heatmap(pps.matrix(df),annot=True,fmt=\".2f\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Corelation Matrix","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,12))\nsns.heatmap(df.corr(),annot=True,fmt=\".2f\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"More details about the Kaplan-Meier graphs given below- https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3059453/","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Lets create an overall KaplanMeier curve, without breaking it into groups of covariates.\n\n## Import the library\nfrom lifelines import KaplanMeierFitter\n\n\ndurations = df['tenure'] ## Time to event data of censored and event data\nevent_observed = df['Churn']  ## It has the churned (1) and censored is (0)\n\n## create a kmf object as km\nkm = KaplanMeierFitter() ## instantiate the class to create an object\n\n## Fit the data into the model\nkm.fit(durations, event_observed,label='Kaplan Meier Estimate')\n\n## Create an estimate\nkm.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Lets create Kaplan Meier Curves for Cohorts","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Lets create three cohorts of customers based on whether a customer has subscribed for Streaming TV or not. We want to know that which cohort has the better customer retention.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"kmf = KaplanMeierFitter() \n\n\nT = df['tenure']     ## time to event\nE = df['Churn']      ## event occurred or censored\n\n\ngroups = df['Contract']             ## Create the cohorts from the 'Contract' column\nix1 = (groups == 'Month-to-month')   ## Cohort 1\nix2 = (groups == 'Two year')         ## Cohort 2\nix3 = (groups == 'One year')         ## Cohort 3\n\n\nkmf.fit(T[ix1], E[ix1], label='Month-to-month')    ## fit the cohort 1 data\nax = kmf.plot()\n\n\nkmf.fit(T[ix2], E[ix2], label='Two year')         ## fit the cohort 2 data\nax1 = kmf.plot(ax=ax)\n\n\nkmf.fit(T[ix3], E[ix3], label='One year')        ## fit the cohort 3 data\nkmf.plot(ax=ax1)                                 ## Plot the KM curve for three cohort on same x and y axis","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that month-to-month subscribers has highest probability to churn ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"kmf1 = KaplanMeierFitter() ## instantiate the class to create an object\n\n## Two Cohorts are compared. 1. Streaming TV Not Subsribed by Users, 2. Streaming TV subscribed by the users.\ngroups = df['StreamingTV']   \ni1 = (groups == 'No')      ## group i1 , having the pandas series for the 1st cohort\ni2 = (groups == 'Yes')     ## group i2 , having the pandas series for the 2nd cohort\n\n\n## fit the model for 1st cohort\nkmf1.fit(T[i1], E[i1], label='Not Subscribed StreamingTV')\na1 = kmf1.plot()\n\n## fit the model for 2nd cohort\nkmf1.fit(T[i2], E[i2], label='Subscribed StreamingTV')\nkmf1.plot(ax=a1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the curves, it is evident that the customers, who have subscribed for the Streaming TV, have better customer retention as compared to the customers, who have not subscribed for the Streaming TV. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":" we can see that the survival probability of the cohort in blue is less than the cohort in red. For the cohort in blue, the survival probability is decreasing with high rate in first 10 months and it gets relatively better after that; however, for the red cohort, the rate of decrease in survival rate is fairly constant. Therefore, for the cohort , which has not subscribed for the Streaming TV, efforts should be made to retain the customers in first 10 volatile months.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"kmf2 = KaplanMeierFitter() ## instantiate the class to create an object\n\n\ngroups = df['gender']   \nj1 = (groups == 'Male')      ## group i1 , having the pandas series for the 1st cohort\nj2 = (groups == 'Female')     ## group i2 , having the pandas series for the 2nd cohort\n\n\n## fit the model for 1st cohort\nkmf2.fit(T[j1], E[j1], label='Male')\na1 = kmf2.plot()\n\n## fit the model for 2nd cohort\nkmf2.fit(T[j2], E[j2], label='Female')\nkmf2.plot(ax=a1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmf3 = KaplanMeierFitter() ## instantiate the class to create an object\n\n\ngroups = df['Partner']   \nk1 = (groups == 'No')      ## group i1 , having the pandas series for the 1st cohort\nk2 = (groups == 'Yes')     ## group i2 , having the pandas series for the 2nd cohort\n\n\n## fit the model for 1st cohort\nkmf3.fit(T[k1], E[k1], label='Do not have a partner')\na1 = kmf3.plot()\n\n## fit the model for 2nd cohort\nkmf3.fit(T[k2], E[k2], label='Have a partner')\nkmf3.plot(ax=a1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Additionally, Kaplan-Meier curves  are useful only when the predictor variable is categorical (e.g.: treatment A vs treatment B; males vs females). They don’t work easily for quantitative predictors such as gene expression, weight, or age.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"An alternative method is the Cox proportional hazards regression analysis, which works for both quantitative predictor variables and for categorical variables. Furthermore, the Cox regression model extends survival analysis methods to assess simultaneously the effect of several risk factors on survival time.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Cox Proportional Hazard Model (Survival Regression)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from lifelines import CoxPHFitter     ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## My objective here is to introduce you to the implementation of the model.Thus taking subset of the columns to train the model.\n## Only using the subset of the columns present in the original data\ndf_r= df.loc[:,['tenure','Churn','gender','Partner','Dependents','PhoneService','MonthlyCharges','SeniorCitizen','StreamingTV']]\ndf_r.head() ## have a look at the data ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Create dummy variables by using one-hot encoding\ndf_dummy = pd.get_dummies(df_r, drop_first=True)\ndf_dummy.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this seminal paper, Cox (1972) presented the proportional hazards model, which specifies that the conditional hazard function of failure time given a set of covariates is the product of an unknown baseline hazard function and an exponential regression function of covariates","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Description of the above model -https://lifelines.readthedocs.io/en/latest/Survival%20Regression.html#cox-s-proportional-hazard-model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using Cox Proportional Hazards model\ncph = CoxPHFitter()   ## Instantiate the class to create a cph object\ncph.fit(df_dummy, 'tenure', event_col='Churn')   ## Fit the data to train the model\ncph.print_summary()    ## HAve a look at the significance of the features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cph.plot() #With a fitted model, an alternative way to view the coefficients and their ranges is to use the plot method.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This plot is an another way to show the coefficient for example- PhoneService_Yes(having a phone service)-has a coefficient of about 0.69 Thus, a one unit increase in PhoneService_Yes means the the baseline hazard will increase by a factor of exp(0.69)= 2.00, about a 20% increase in the Cox proportional hazard model, a higher hazard means more at risk of the event occurring. The value exp(0.69) is called the hazard ratio","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Interesting point to note here is that , the β (coef ) values in case of covariates MonthlyCharges and gender_Male is approximately zero (~-0.01), but still the MonthlyCharges plays a significant role in predicting churn , while the latter is insignificant. The reason is that the MonthlyCharges is continuous value and it can vary from the order of tens, hundreds to thousands, when multiplied by the small coef (β=-0.01), it becomes significant. On the other hand, the covariate gender can only take the value 0 or 1, and in both the cases [exp(-0.01 * 0), exp(-0.01*1)] it will be insignificant.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## We want to see the Survival curve at the customer level. Therefore, we have selected 6 customers (rows 5 till 9).\n\ntr_rows = df_dummy.iloc[1:5, 2:]\ntr_rows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Lets predict the survival curve for the selected customers. \n## Customers can be identified with the help of the number mentioned against each curve.\ncph.predict_survival_function(tr_rows).plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So from the above graph from the given graph we can see that customer 2 has the highest probability to churn.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Creating the survival curves at each customer level helps us in proactively creating a tailor made strategy for high-valued customers for different survival risk segments along the timeline.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Additional Resources","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Lifelines Python Doumentation-https://lifelines.readthedocs.io/en/latest/Quickstart.html","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"SciPy 2015 lecture by Allen Downey- https://www.youtube.com/watch?v=XHYFNraQEEo","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Princeton University Lectures notes-https://data.princeton.edu/wws509/notes/c7.pdf","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Thanks for checking out the analysis<br>\n-Akshat Anand","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}