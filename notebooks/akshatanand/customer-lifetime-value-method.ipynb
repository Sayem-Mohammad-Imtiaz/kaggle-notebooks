{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importing Necessary Modules\nWe import all the modules that we are going to use in this code.\n\n1) Pandas for handling our .csv file & converting it to a usable DataFrame\n\n2) Warnings to filter out all the unnecessary warning messages\n\n3) Matplotlib  for showing our visualizations using different available plots\n\n4) Lifetimes packages for our model development."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib as plt\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importing all the neccessary packages in the given notebook"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\n#Import Data\ndata=pd.read_csv(r\"../input/onlineretail/OnlineRetail.csv\", encoding=\"cp1252\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the read_csv() we use the particular datafile in .csv format ,additionally we are using encoding parameter which ensures the conversion of unknown encoding of the data into a functional data."},{"metadata":{},"cell_type":"markdown","source":"About the encoding follow this article - https://docs.python.org/3/library/codecs.html#standard-encodings<br>\nThe dataset is downloaded from - https://www.kaggle.com/vijayuv/onlineretail/download"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"data.head() gives the output of the top 5 rows of the dataframe."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check the shape (number of columns ,rows) in the dataset\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"data.shape defines the numbers of rows and the numbers of columns\nfrom the above output we can see that there are 541909 rows of data whereas 8 columns of particular data."},{"metadata":{},"cell_type":"markdown","source":"The following details of the code is given here - https://www.geeksforgeeks.org/python-pandas-df-size-df-shape-and-df-ndim/"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"data.describe() describes the different statistical quantities such as <br>\ncount = which describes the no. of data of rows in the data for a particular column .<br>\nmean = Mean of the values for a particular column.<br>\nmax = Maximum of the values in the object.<br>\nmin = Minimum of the values in the object in the particular<br> \nstd = Standard deviation of the observations.<br>\nand also the 25%, 50% and 75% returns the 25th, 50th, and 75th percentiles of the data.\n\n"},{"metadata":{},"cell_type":"markdown","source":"The comphrensive details of the following code given here - https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is similar as the above code being difference is that the parameter which has a include value which indicates it takes all the column as categorical values and the numeric values. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Find out missing values\ndata.isnull().sum(axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we define find the number of values of data which is nullcharacter,these can occur due to mistyping or wrong data entry of the data.<br>\naxis = (0 or ‘index’, 1 or ‘columns’), the value is default 0<br>\n   If 0 or ‘index’ counts are generated for each column. If 1 or ‘columns’ counts are generated for each row."},{"metadata":{},"cell_type":"markdown","source":"The details of the following code is given here - https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.count.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Remove time from date\ndata['InvoiceDate'] = pd.to_datetime(data['InvoiceDate'], format=\"%m/%d/%Y %H:%M\").dt.date","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the Invoicedata column the data in each row has time and date. We are not sure of the use of time in our analysis so will be removing time from the given customer's purchaae date. <br>\nThe to_datatime() takes values from InvoiceDate column and formats takes value in the given particular format and returns numpy array of python datetime.date objects . "},{"metadata":{},"cell_type":"markdown","source":"Details about the to_datatime and other related topics is given here -https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html<br>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#There are 135,080 missing values in the CustomerID column, and since our analysis is based on customers, \n#we will remove these missing values from the CustomerID column.\ndata = data[pd.notnull(data['CustomerID'])]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Detect non-missing values for an array-like object for the column 'CustomerID'\n\nThis function takes a scalar or array-like object and indictates whether values are valid"},{"metadata":{},"cell_type":"markdown","source":"The details of the above code is given here - https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.notnull.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Keeping records with non negative quantity\ndata = data[(data['Quantity']>0)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"keeping the values of the column 'Quantity' positive as we don't want any absurd value is out of scope. Here data['Quantity']>0 filters out the negative or absurd value ."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Add a new column depicting total sales\ndata['Total_Sales'] = data['Quantity'] * data['UnitPrice']     #Total sales = (Quantity of particular prod.) * (Unitprice of prod.) \nnecessary_cols = ['CustomerID', 'InvoiceDate', 'Total_Sales']  #taking only three given columns for our analysis\ndata = data[necessary_cols]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1st l.o.c. describes the column 'total sales' which is found by multiplying each value of Quantity and UnitPrice"},{"metadata":{},"cell_type":"markdown","source":"For our analysis we require three important features i.e. customerid, invoicedata and total_sales and we feed into a single column new column for our easy convenience."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head() #shows the first 5 rows of the dataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we define the order of our new dataframe by head()"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Printing numbers of unique Customer IDs\nprint(data['CustomerID'].nunique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we check the number of unique values in the column customerID in order to replace the duplicate values from the data with the function nunique()."},{"metadata":{},"cell_type":"markdown","source":"The details about the above function is given here - https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.nunique.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"last_order_date = data['InvoiceDate'].max() #its checks the Last order date\nprint(last_order_date)\nprint(\"--------------------------------------\")\nprint(data[(data['CustomerID']==12346)]) #it gives the details of the particular customerID with index no. ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1st l.o.c defines last date of the transaction from the column 'InvoiceDate\" by the function max() which returns the highest value from the column"},{"metadata":{},"cell_type":"markdown","source":"2nd line of code \"(data[(data['CustomerID']==12346)\" defines the particular row and the column \"CustomerID\" which has the value \"12346\" and retuens the whole row."},{"metadata":{},"cell_type":"markdown","source":"For this analysis we will be using BG/NBD model which stands for Beta Geometric/Negative Binomial Model.<br>\nWe will be importing lifetimes package here is the documentation-https://lifetimes.readthedocs.io/en/latest/lifetimes.fitters.html#module-lifetimes.fitters.pareto_nbd_fitter"},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install Lifetimes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In order to download all the packages of lifetmes we use the following command. Using pip install lifetimes which download all the packages"},{"metadata":{"trusted":true},"cell_type":"code","source":"from lifetimes.plotting import *\nfrom lifetimes.utils import *\n#importing the necessary packages","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the lifetimes.plotting ww will be importing all the packages which is used for plotting or visualization of the given data file and also the utility libraries which includes are the given models for the prediction of the model<br>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndata = summary_data_from_transaction_data(data, 'CustomerID', 'InvoiceDate', monetary_value_col='Total_Sales', observation_period_end='2011-12-9')\ndata.reset_index().head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Built-in utility functions from lifetimes package to transform the transactional data (one row per purchase) into summary data (a frequency, recency, age and monetary).<br>\nFor all models, the following nomenclature is used:<br>\n• **frequency** represents the number of repeat purchases the customer has made. This means that it’s one less\nthan the total number of purchases. This is actually slightly wrong. It’s the count of time periods the customer\nhad a purchase in. So if using days as units, then it’s the count of days the customer had a purchase on.<br>\n• **T** represents the age of the customer in whatever time units chosen (weekly, in the above dataset). This is equal\nto the duration between a customer’s first purchase and the end of the period under study.<br>\n• **recency** represents the age of the customer when they made their most recent purchases. This is equal to the\nduration between a customer’s first purchase and their latest purchase. (Thus if they have made only 1 purchase,\nthe recency is 0.)<br>\n• **monetary_value** represents the average value of a given customer’s purchases. This is equal to the sum of\nall a customer’s purchases divided by the total number of purchases. Note that the denominator here is different\nthan the frequency described above.<br>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data['frequency'].describe())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The code describes the statistical analysis of the particular column 'frequency' with all the mean, std(standard deviation), min, max, etc which gives the overall overview of the column."},{"metadata":{"trusted":true},"cell_type":"code","source":"one_time_buyers = round(sum(data['frequency'] == 0)/float(len(data))*(100),2)\nprint(\"Percentage of customers purchase the item only once:\", one_time_buyers ,\"%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This percentage gives us the percentage of one time buyers which is almost 1/3 rd of the total buyers."},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#Create histogram to find out how many customers purchased item only once.\ndata['frequency'].plot(kind='hist', bins=50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"About the BG/NBD Model read from here-https://lifetimes.readthedocs.io/en/latest/Quickstart.html#estimating-customer-lifetime-value-using-the-gamma-gamma-model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Frequency/Recency Analysis Using the BG/NBD Model\nfrom lifetimes import BetaGeoFitter\nbgf = BetaGeoFitter(penalizer_coef=0.0)\nbgf.fit(data['frequency'], data['recency'], data['T'])\nprint(bgf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We’ll use the BG/NBD model first. There are other models which we will explore in these docs, but this is the simplest\nto start with.<br>\nAfter fitting, we have lots of nice methods and properties attached to the fitter object, like param_ and summary.\nFor small samples sizes, the parameters can get implausibly large, so by adding an l2 penalty the likelihood, we can\ncontrol how large these parameters can be. This is implemented as setting as positive penalizer_coef in the\ninitialization of the model. In typical applications, penalizers on the order of 0.001 to 0.1 are effective."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualizing our frequency/recency matrix\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom lifetimes.plotting import plot_frequency_recency_matrix\nfig = plt.figure(figsize=(12,8))\nplot_frequency_recency_matrix(bgf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Consider: a customer bought from you every day for three weeks straight, and we haven’t heard from them in months.\nWhat are the chances they are still “alive”? Pretty small. On the other hand, a customer who historically buys\nfrom you once a quarter, and bought last quarter, is likely still alive. We can visualize this relationship using the\nFrequency/Recency matrix, which computes the expected number of transactions a artificial customer is to make in\nthe next time period, given his or her recency (age at last purchase) and frequency (the number of repeat transactions\nhe or she has made).\n"},{"metadata":{},"cell_type":"markdown","source":"We can see that if a customer has bought 120 times from you, and their latest purchase was when they were 330 weeks\nold (given the individual is 330 weeks old), then they are your best customer (bottom-right). Your coldest customers\nare those that are in the top-right corner: they bought a lot quickly, and we haven’t seen them in weeks.<br>\nThere’s also that beautiful “tail” around (20,250). That represents the customer who buys infrequently, but we’ve seen\nhim or her recently, so they might buy again - we’re not sure if they are dead or just between purchases.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#predict if the customers are surely alive:\nfrom lifetimes.plotting import plot_probability_alive_matrix\nfig = plt.figure(figsize=(12,8))\nplot_probability_alive_matrix(bgf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Another interesting matrix to look at is the probability of still being alive:"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predict future transaction in next 10 days i.e.top 10 customers that the model expects them to make purchases \n#in the next 10 days, based on historical data\n\nt = 10\ndata['pred_num_txn'] = round(bgf.conditional_expected_number_of_purchases_up_to_time(t, data['frequency'], data['recency'], data['T']),2)\ndata.sort_values(by='pred_num_txn', ascending=False).head(10).reset_index()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let’s return to our customers and rank them from “highest expected purchases in the next period” to lowest. Models\nexpose a method that will predict a customer’s expected purchases in the next period using their history<br>\nGreat, we can see that the customer who has made 131 purchases, and bought very recently from us, is probably going\nto buy again in the next period."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Assessing model fit\nfrom lifetimes.plotting import plot_period_transactions\nplot_period_transactions(bgf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok, we can predict and we can visualize our customers’ behaviour, but is our model correct? There are a few ways\nto assess the model’s correctness. The first is to compare your data versus artificial data simulated with your fitted\nmodel’s parameters.<br>\nWe can see that our actual data and our simulated data line up well. This proves that our model doesn’t create problem."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Customer's future transaction prediction for next 10 days\n\nt = 10\nindividual = data.loc[14911]\nbgf.predict(t, individual['frequency'], individual['recency'], individual['T'])\n\n#OBSERVATION: Our model predicts that customer 14911’s future transaction is appx 3 in 10 days.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we predict the future transcation of the customer i'd = \"14911\" and we found out that it will be close to 3 transactions in next 10 days"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check if there is correlation between monetary value and frequency in order to use gamma gamma model for CLV calculation by pearson coeff.\ndata[['monetary_value', 'frequency']].corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The model we are going to use to estimate the CLV for our userbase is called the Gamma-Gamma submodel, which\nrelies upon an important assumption. The Gamma-Gamma submodel, in fact, assumes that there is no relationship\nbetween the monetary value and the purchase frequency. In practice we need to check whether the Pearson correlation\nbetween the two vectors is close to 0 in order to use this model.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Shortlist customers who had at least one repeat purchase with the company. \nshortlisted_customers = data[data['frequency']>0]\nprint(shortlisted_customers.head().reset_index())\nprint(\"-----------------------------------------\")\nprint(\"The Number of Returning Customers are: \",len(shortlisted_customers))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For this whole time we didn’t take into account the economic value of each transaction and we focused mainly on\ntransactions’ occurrences. To estimate this we can use the Gamma-Gamma submodel. But first we need to create\nsummary data from transactional data also containing economic values for each transaction (i.e. profits or revenues).\n"},{"metadata":{},"cell_type":"markdown","source":"About the gamma gamma model read here-https://lifetimes.readthedocs.io/en/latest/Quickstart.html#estimating-customer-lifetime-value-using-the-gamma-gamma-model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Train gamma-gamma model by taking into account the monetary_value.\nfrom lifetimes import GammaGammaFitter\nggf = GammaGammaFitter(penalizer_coef = 0)\nggf.fit(shortlisted_customers['frequency'],\n        shortlisted_customers['monetary_value'])\nprint(ggf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"At this point we can train our Gamma-Gamma submodel and predict the conditional, expected average lifetime value\nof our customers."},{"metadata":{"trusted":true},"cell_type":"code","source":"#After applying Gamma-Gamma model, now we can estimate average transaction value for each customer. \nprint(ggf.conditional_expected_average_profit(\n        data['frequency'],\n        data['monetary_value']\n    ).head(10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can now estimate the average profit of each of these customers"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['pred_txn_value'] = round(ggf.conditional_expected_average_profit(\n        data['frequency'],\n        data['monetary_value']), 2)\ndata.reset_index().head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we calculate the CLV score for the top customers"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['CLV'] = round(ggf.customer_lifetime_value(\n    bgf, #the model to use to predict the number of future transactions\n    data['frequency'],\n    data['recency'],\n    data['T'],\n    data['monetary_value'],\n    time=12, # months\n    discount_rate=0.01 # monthly discount rate ~ 12.7% annually\n), 2)\n\n\ndata.sort_values(by='CLV', ascending=False).head(10).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calculate Customer Lifetime Value\ndata['CLV'] = round(ggf.customer_lifetime_value(\n    bgf, #the model to use to predict the number of future transactions\n    data['frequency'],\n    data['recency'],\n    data['T'],\n    data['monetary_value'],\n    time=12, # months\n    discount_rate=0.01 # monthly discount rate ~ 12.7% annually\n), 2)\n\ndata.drop(data.iloc[:, 0:6], inplace=True, axis=1)\n\ndata.sort_values(by='CLV', ascending=False).head(10).reset_index()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}