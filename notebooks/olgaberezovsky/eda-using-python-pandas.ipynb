{"cells":[{"metadata":{},"cell_type":"markdown","source":"<p>&nbsp;</p>\n<img src=\"https://1000logos.net/wp-content/uploads/2017/05/Reddit-logo.png\" width=400>\n<p>&nbsp;</p>"},{"metadata":{},"cell_type":"markdown","source":"## Introduction\n\nThis is a brief exploratory data analysis using Pandas for a given public sample of random Reddit posts.\nWe will get a feel of a dataset and try to answer the following questions: \n* What are the most popular reddits? Which topics are viral?\n* Which posts have been removed and why? \n* What % removed reddits are deleted by moderatos? \n* Who are the most popular authors? \n* Who are the biggest spammers at Reddit platform?\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Getting all the packages we need: \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\n\nimport seaborn as sns #statist graph package\nimport matplotlib.pyplot as plt #plot package\n\nimport wordcloud #will use for the word cloud plot\nfrom wordcloud import WordCloud, STOPWORDS # optional to filter out the stopwords\n\n#Optional helpful plot stypes:\nplt.style.use('bmh') #setting up 'bmh' as \"Bayesian Methods for Hackers\" style sheet\n#plt.style.use('ggplot') #R ggplot stype","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a name=\"read\"></a>Reading the dataset\nAccessing Reddit dataset:"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/dataisbeautiful/r_dataisbeautiful_posts.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a name=\"feel\"></a>Getting a feel of the dataset\nLet's run basic dataframe exploratory commands"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Data shape :\",df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Empty values:\n\ndf.isnull().sum().sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We note from the table above:\n- There are `173,611` entries in the dataset. Caveat, not all columns in the dataset are complete. \n- The average reddit score `193`. The median value for the score is `1`, which means that a half of reddits in our dataset have the score `0` or `1` and only less than 75% reddits have the score more than `5`\n- The most popular reddit has `18,801` comments, while the average is `25` and the median is `1`. "},{"metadata":{},"cell_type":"markdown","source":"## <a name=\"corr\"></a>Removed reddits deep dive"},{"metadata":{},"cell_type":"markdown","source":"Let's see who and why removes posts:"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = 'removed_by', hue = 'removed_by', data = df)\n#df.removed_by","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">As we can see, the most deleted posts (68%) were removed by moderator. Less than 1% are deleted by authors.\n"},{"metadata":{},"cell_type":"markdown","source":"## <a name=\"corr\"></a>The most popular reddits"},{"metadata":{},"cell_type":"markdown","source":"## <a name=\"corr\"></a>The most common words in reddits:\n\nLet's see the word map of the most commonly used words from reddit titles:"},{"metadata":{"trusted":true},"cell_type":"code","source":"#To build a wordcloud, we have to remove NULL values first:\ndf[\"title\"] = df[\"title\"].fillna(value=\"\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now let's add a string value instead to make our Series clean:\nword_string=\" \".join(df['title'].str.lower())\n\n#word_string","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#And - plotting:\n\nplt.figure(figsize=(15,15))\nwc = WordCloud(background_color=\"purple\", stopwords = STOPWORDS, max_words=2000, max_font_size= 300,  width=1600, height=800)\nwc.generate(word_string)\n\nplt.imshow(wc.recolor( colormap= 'viridis' , random_state=17), interpolation=\"bilinear\")\nplt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a name=\"corr\"></a>Comments distribution\n"},{"metadata":{},"cell_type":"markdown","source":">The average reddit has less than 25 comments. Let's see the comment distribution for those reddits who have <25 comments:"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Comments distribution plot:\n\nfig, ax = plt.subplots()\n_ = sns.distplot(df[df[\"num_comments\"] < 25][\"num_comments\"], kde=False, rug=False, hist_kws={'alpha': 1}, ax=ax)\n_ = ax.set(xlabel=\"num_comments\", ylabel=\"id\")\n\nplt.ylabel(\"Number of reddits\")\nplt.xlabel(\"Comments\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">As we can see, the most reddits have less than 5 comments. "},{"metadata":{},"cell_type":"markdown","source":"## <a name=\"corr\"></a>Correlation between dataset variables\n\nNow let's see how the dataset variables are correlated with each other:\n* How score and comments are correlated? \n* Do they increase and decrease together (positive correlation)? \n* Does one of them increase when the other decrease and vice versa (negative correlation)? Or are they not correlated?\n\nCorrelation is represented as a value between -1 and +1 where +1 denotes the highest positive correlation, -1 denotes the highest negative correlation, and 0 denotes that there is no correlation.\n\n* Let's see the correlation table between our dataset variables (numerical and boolean variables only)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that score and number of comments are highly positively correlated with a correlation value of 0.6. \n\nThere is some positive correlation of 0.2 between total awards received and score (0.2) and num_comments (0.1).\n\nNow let's visualize the correlation table above using a heatmap\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"h_labels = [x.replace('_', ' ').title() for x in \n            list(df.select_dtypes(include=['number', 'bool']).columns.values)]\n\nfig, ax = plt.subplots(figsize=(10,6))\n_ = sns.heatmap(df.corr(), annot=True, xticklabels=h_labels, yticklabels=h_labels, cmap=sns.cubehelix_palette(as_cmap=True), ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a name=\"corr\"></a>Score distribution\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.score.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.score.median()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Score distribution: \n\nfig, ax = plt.subplots()\n_ = sns.distplot(df[df[\"score\"] < 22][\"score\"], kde=False, hist_kws={'alpha': 1}, ax=ax)\n_ = ax.set(xlabel=\"score\", ylabel=\"No. of reddits\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}