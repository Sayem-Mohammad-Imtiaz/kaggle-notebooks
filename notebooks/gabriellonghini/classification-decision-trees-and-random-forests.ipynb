{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import confusion_matrix, plot_confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n# Declaring a random state so the execution doesn't change\nrandom_state = 0","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-17T16:44:53.440603Z","iopub.execute_input":"2021-08-17T16:44:53.441005Z","iopub.status.idle":"2021-08-17T16:44:53.45345Z","shell.execute_reply.started":"2021-08-17T16:44:53.440973Z","shell.execute_reply":"2021-08-17T16:44:53.452258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading the data\nraw_data = pd.read_csv('/kaggle/input/health-care-data-set-on-heart-attack-possibility/heart.csv')\nraw_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-17T16:44:53.456352Z","iopub.execute_input":"2021-08-17T16:44:53.456686Z","iopub.status.idle":"2021-08-17T16:44:53.482845Z","shell.execute_reply.started":"2021-08-17T16:44:53.456651Z","shell.execute_reply":"2021-08-17T16:44:53.481999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The columns are:\n\n* age\n* sex: 1 = male, 0 = female\n* cp: chest pain type\n    * 1: typical angina\n    * 2: atypical angina\n    * 3: non-anginal pain\n    * 4: asymptomatic\n* trestbps: resting blood pressure\n* chol: serum cholestoral in mg/dl\n* fbs: fasting blood sugar 0 = >=120 mg/dl, 1 = <120 mg/dl\n* restecg: resting electrocardiographic results \n    * 0: normal\n    * 1: having ST-T wave abnormality\n    * 2: showing probable or definite left ventricular hypertrophy\n* thalach: maximum heart rate achieved\n* exang: exercise induced angina 0 = no, 1 = yes\n* oldpeak: oldpeak = ST depression induced by exercise relative to rest\n* slope: the slope of the peak exercise ST segment\n    * 1: upsloping\n    * 2: flat\n    * 3: downsloping\n* ca: number of major vessels (0-3) colored by flourosopy\n* thal: 0 = normal; 1 = fixed defect; 2 = reversable defect\n* target: 0 = less chance of heart attack 1 = more chance of heart attack","metadata":{}},{"cell_type":"code","source":"# Statistics about the dataset\nraw_data.describe()","metadata":{"execution":{"iopub.status.busy":"2021-08-17T16:44:53.484145Z","iopub.execute_input":"2021-08-17T16:44:53.484556Z","iopub.status.idle":"2021-08-17T16:44:53.539482Z","shell.execute_reply.started":"2021-08-17T16:44:53.484524Z","shell.execute_reply":"2021-08-17T16:44:53.538681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's check how much data is null\nraw_data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-08-17T16:44:53.540668Z","iopub.execute_input":"2021-08-17T16:44:53.541099Z","iopub.status.idle":"2021-08-17T16:44:53.549709Z","shell.execute_reply.started":"2021-08-17T16:44:53.541058Z","shell.execute_reply":"2021-08-17T16:44:53.548684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the unique values of the columns\nfor column in raw_data.columns:\n    print(column)\n    print(raw_data[column].unique())\n    print('\\n')","metadata":{"execution":{"iopub.status.busy":"2021-08-17T16:44:53.551271Z","iopub.execute_input":"2021-08-17T16:44:53.551724Z","iopub.status.idle":"2021-08-17T16:44:53.570884Z","shell.execute_reply.started":"2021-08-17T16:44:53.551688Z","shell.execute_reply":"2021-08-17T16:44:53.569937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data preprocessing\n\nAs some of the columns are categorical data, we need to create dummies for them. We'll apply the get dummies method to the cp, restecg, slope and thal columns.","metadata":{}},{"cell_type":"code","source":"# Get dummies\ndf = pd.get_dummies(raw_data, columns=['cp', 'restecg', 'slope', 'thal'])\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-17T16:44:53.572789Z","iopub.execute_input":"2021-08-17T16:44:53.573207Z","iopub.status.idle":"2021-08-17T16:44:53.603203Z","shell.execute_reply.started":"2021-08-17T16:44:53.573176Z","shell.execute_reply":"2021-08-17T16:44:53.602193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model building\n\nLet's try to fit a Decision Tree and a Random Forest to compare each method. We can apply some techniques to improve the models as well.","metadata":{}},{"cell_type":"code","source":"# Splitting inputs and targets\nX_encoded = df.drop(['target'], axis=1)\ny = df['target']","metadata":{"execution":{"iopub.status.busy":"2021-08-17T16:44:53.604368Z","iopub.execute_input":"2021-08-17T16:44:53.604642Z","iopub.status.idle":"2021-08-17T16:44:53.610881Z","shell.execute_reply.started":"2021-08-17T16:44:53.604616Z","shell.execute_reply":"2021-08-17T16:44:53.609759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting the training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X_encoded, y, random_state=random_state)","metadata":{"execution":{"iopub.status.busy":"2021-08-17T16:44:53.61212Z","iopub.execute_input":"2021-08-17T16:44:53.61241Z","iopub.status.idle":"2021-08-17T16:44:53.624438Z","shell.execute_reply.started":"2021-08-17T16:44:53.612382Z","shell.execute_reply":"2021-08-17T16:44:53.623633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Decision Tree\ndt = DecisionTreeClassifier()\ndt.fit(X_train, y_train)\n\n# Cross validation\ndt_accuracy = np.mean(cross_val_score(dt, X_train, y_train, cv=5, scoring='accuracy'))\nprint(\"Mean accuracy: \", dt_accuracy)\n\n# Plotting the tree\nplt.figure(figsize=(28, 18))\nplot_tree(dt, filled=True, rounded=True, class_names=['No HD', 'HD'], feature_names=X_encoded.columns);","metadata":{"execution":{"iopub.status.busy":"2021-08-17T16:44:53.62536Z","iopub.execute_input":"2021-08-17T16:44:53.625611Z","iopub.status.idle":"2021-08-17T16:44:59.137114Z","shell.execute_reply.started":"2021-08-17T16:44:53.625587Z","shell.execute_reply":"2021-08-17T16:44:59.136085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Let's check the accuracy of it's predictions","metadata":{}},{"cell_type":"code","source":"# Confusion matrix\nplot_confusion_matrix(dt, X_test, y_test, display_labels=['Does not have HD', 'Has HD'])\nplt.grid(False)","metadata":{"execution":{"iopub.status.busy":"2021-08-17T16:44:59.139199Z","iopub.execute_input":"2021-08-17T16:44:59.139764Z","iopub.status.idle":"2021-08-17T16:44:59.330754Z","shell.execute_reply.started":"2021-08-17T16:44:59.139701Z","shell.execute_reply":"2021-08-17T16:44:59.329979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Overall accuracy of the pruned tree\ndt.score(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-17T16:44:59.332127Z","iopub.execute_input":"2021-08-17T16:44:59.332574Z","iopub.status.idle":"2021-08-17T16:44:59.340325Z","shell.execute_reply.started":"2021-08-17T16:44:59.332522Z","shell.execute_reply":"2021-08-17T16:44:59.339593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can try to improve the model by pruning. Let's visualize the optimal alpha for our tree.\n\n# Cost complexity pruning: visualizing alpha\n\n## **This part was taken from this [webinar](https://https://www.youtube.com/watch?v=q90UDEgYqeI)**","metadata":{}},{"cell_type":"code","source":"# Determine the values for alpha\npath = dt.cost_complexity_pruning_path(X_train, y_train)\n# Extract the different values for alpha\nccp_alphas = path.ccp_alphas\n# Exclude the maximum value for alpha, as this value would produce a tree with only one leaf\nccp_alphas = ccp_alphas[:-1]\n\n# Let's create an array to hold our decision trees\ndts = []\n\nfor ccp_alpha in ccp_alphas:\n    dt = DecisionTreeClassifier(ccp_alpha=ccp_alpha)\n    dt.fit(X_train, y_train)\n    dts.append(dt)","metadata":{"execution":{"iopub.status.busy":"2021-08-17T16:44:59.341536Z","iopub.execute_input":"2021-08-17T16:44:59.341971Z","iopub.status.idle":"2021-08-17T16:44:59.432353Z","shell.execute_reply.started":"2021-08-17T16:44:59.341931Z","shell.execute_reply":"2021-08-17T16:44:59.431407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's plot the accuracy of the trees using the Training Dataset and the Testing Dataset as a function of alpha","metadata":{}},{"cell_type":"code","source":"train_scores = [dt.score(X_train, y_train) for dt in dts]\ntest_scores = [dt.score(X_test, y_test) for dt in dts]\n\nfig, ax = plt.subplots(figsize=(12,8))\nax.set_xlabel(\"alpha\")\nax.set_ylabel(\"accuracy\")\nax.set_title(\"Accuracy vs alpha for training and testing sets\")\nax.plot(ccp_alphas, train_scores, marker='o', label=\"train\", drawstyle='steps-post')\nax.plot(ccp_alphas, test_scores, marker='o', label=\"test\", drawstyle='steps-post')\nax.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-17T16:44:59.433412Z","iopub.execute_input":"2021-08-17T16:44:59.433854Z","iopub.status.idle":"2021-08-17T16:44:59.94993Z","shell.execute_reply.started":"2021-08-17T16:44:59.433823Z","shell.execute_reply":"2021-08-17T16:44:59.948996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cost complexity pruning: Cross validation for finding the best alpha\n\nA second method that we can apply is cross validation for finding the best alpha. We will run a 5-fold cross validation for each candidate alpha and plot the results.","metadata":{}},{"cell_type":"code","source":"# Creating an array to store the results of cross validation\nalpha_loop_values = []\n\n# Cross validation\nfor ccp_alpha in ccp_alphas:\n    dt = DecisionTreeClassifier(ccp_alpha=ccp_alpha)\n    scores = cross_val_score(dt, X_train, y_train, cv=5, scoring='accuracy')\n    alpha_loop_values.append([ccp_alpha, np.mean(scores), np.std(scores)])\n    \n# Let's visualize the candidate alphas\nalpha_results = pd.DataFrame(alpha_loop_values, columns=['alpha', 'mean_accuracy', 'std'])\n\nalpha_results.plot(x='alpha', y='mean_accuracy', yerr='std', marker='o', linestyle='--')","metadata":{"execution":{"iopub.status.busy":"2021-08-17T16:44:59.951047Z","iopub.execute_input":"2021-08-17T16:44:59.951483Z","iopub.status.idle":"2021-08-17T16:45:01.062984Z","shell.execute_reply.started":"2021-08-17T16:44:59.951452Z","shell.execute_reply":"2021-08-17T16:45:01.062095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's get the best value\nideal_ccp_alpha = alpha_results['alpha'][alpha_results['mean_accuracy'].idxmax]\nideal_ccp_alpha","metadata":{"execution":{"iopub.status.busy":"2021-08-17T16:45:01.064027Z","iopub.execute_input":"2021-08-17T16:45:01.064422Z","iopub.status.idle":"2021-08-17T16:45:01.070315Z","shell.execute_reply.started":"2021-08-17T16:45:01.064391Z","shell.execute_reply":"2021-08-17T16:45:01.069546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Pruned Decision Tree\ndt_pruned = DecisionTreeClassifier(ccp_alpha=ideal_ccp_alpha)\ndt_pruned.fit(X_train, y_train)\n\n# Plotting the tree\nplt.figure(figsize=(24, 18))\nplot_tree(dt_pruned, filled=True, rounded=True, class_names=['No HD', 'HD'], feature_names=X_encoded.columns);","metadata":{"execution":{"iopub.status.busy":"2021-08-17T16:45:01.072318Z","iopub.execute_input":"2021-08-17T16:45:01.072775Z","iopub.status.idle":"2021-08-17T16:45:02.129821Z","shell.execute_reply.started":"2021-08-17T16:45:01.072715Z","shell.execute_reply":"2021-08-17T16:45:02.128704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion matrix\nplot_confusion_matrix(dt_pruned, X_test, y_test, display_labels=['Does not have HD', 'Has HD'])\nplt.grid(False)","metadata":{"execution":{"iopub.status.busy":"2021-08-17T16:45:02.131697Z","iopub.execute_input":"2021-08-17T16:45:02.132187Z","iopub.status.idle":"2021-08-17T16:45:02.331605Z","shell.execute_reply.started":"2021-08-17T16:45:02.132137Z","shell.execute_reply":"2021-08-17T16:45:02.330659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Overall accuracy of the pruned tree\ndt_pruned.score(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-17T16:45:02.332782Z","iopub.execute_input":"2021-08-17T16:45:02.333107Z","iopub.status.idle":"2021-08-17T16:45:02.341216Z","shell.execute_reply.started":"2021-08-17T16:45:02.333078Z","shell.execute_reply":"2021-08-17T16:45:02.340291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **There's a tiny improvement over the original tree, and in this case (for this random state) it seems like we lost time, but after all, we got a higher accuracy with a much smaller tree, and that's good.**\n\n# Random Forest\n\nLet's try now a much better approach for classifying: Random Forest.","metadata":{}},{"cell_type":"code","source":"# Random Forest\nrf = RandomForestClassifier(n_estimators=50)\nrf.fit(X_train, y_train)\n\n# Cross validation\nrf_accuracy = np.mean(cross_val_score(rf, X_train, y_train, cv=5, scoring='accuracy'))\nprint('Mean accuracy: ', rf_accuracy)","metadata":{"execution":{"iopub.status.busy":"2021-08-17T16:51:48.457208Z","iopub.execute_input":"2021-08-17T16:51:48.45771Z","iopub.status.idle":"2021-08-17T16:51:49.092018Z","shell.execute_reply.started":"2021-08-17T16:51:48.457678Z","shell.execute_reply":"2021-08-17T16:51:49.091239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Accuracy\nrf.score(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-17T16:51:51.104597Z","iopub.execute_input":"2021-08-17T16:51:51.105092Z","iopub.status.idle":"2021-08-17T16:51:51.123006Z","shell.execute_reply.started":"2021-08-17T16:51:51.105061Z","shell.execute_reply":"2021-08-17T16:51:51.121746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Let's tune the model\n\n* n_estimators: Cross-validation to find the best value for n_estimators","metadata":{}},{"cell_type":"code","source":"error_rate = []\nn_est = []\n\nfor n in range(20, 200):\n    rf.set_params(n_estimators=n, oob_score=True, random_state=random_state)\n    rf.fit(X_train, y_train)\n    \n    # Record the OOB error for each `n_estimators=i` setting.\n    oob_error = 1 - rf.oob_score_\n    n_est.append(n)\n    error_rate.append(oob_error)\n    \nplt.plot(n_est, error_rate)\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-17T16:50:53.478395Z","iopub.execute_input":"2021-08-17T16:50:53.478777Z","iopub.status.idle":"2021-08-17T16:51:41.768325Z","shell.execute_reply.started":"2021-08-17T16:50:53.478744Z","shell.execute_reply":"2021-08-17T16:51:41.767468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The value for n_estimators seems to be stable after n=50 (using a random_state)","metadata":{}}]}