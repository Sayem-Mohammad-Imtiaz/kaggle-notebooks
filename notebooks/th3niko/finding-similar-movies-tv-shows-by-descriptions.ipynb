{"cells":[{"metadata":{"id":"Fl8XYQhQe6Ys"},"cell_type":"markdown","source":"# Finding similar movies/tv shows using their descriptions"},{"metadata":{"id":"qolzpZULe6Yw"},"cell_type":"markdown","source":"Created for learning purposes."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"id":"dVBsWk9Ue6Yx","outputId":"54be5b9e-21a1-43a7-fb5b-7821680888fb"},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing\nimport nltk # Language processing tools\nnltk.download('punkt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"8eC0yaQSe6Yx"},"cell_type":"code","source":"#Load our data\nnetflix_data = pd.read_csv(\"../input/netflix-shows/netflix_titles.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"OvBAjO7Ve6Yx","outputId":"bab25348-a8f3-4b10-9d4e-bf4709133178"},"cell_type":"code","source":"#Check how data looks\nnetflix_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"th30f5Gpe6Yy"},"cell_type":"code","source":"#Replace index with netflix database convention\nnetflix_data.set_index('show_id',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"kR6GMeV0e6Yz"},"cell_type":"code","source":"#Lets first tokenize each description using nltk and list comprehesion\ndescriptions_tokenized = [nltk.word_tokenize(description) for description in netflix_data['description']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"EIe9k_yHe6Yz","outputId":"6bf5ea91-c8db-440f-a2e3-3e3ba07ca1bc"},"cell_type":"code","source":"#Check first description\ndescriptions_tokenized[0]\n\n# Explanation\n# desriptions_tokenized[i][j]\n# i - index of description\n# j - index of word in chosen description\n# Example: desriptions_tokenized[14][5] - six word of fifteenth description (cause we numerate from 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"Lck1x7P2e6Yz","outputId":"bcf5422e-13fe-47af-eda8-48fecba50ab8"},"cell_type":"code","source":"#Lets give each word unique ID, so it will be easier later to use it\n#Easiest method is to create gensim dictionary which will contain all words without repetition\nfrom gensim import corpora\ndictionary = corpora.Dictionary(descriptions_tokenized)\nprint(dictionary)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"df0Im0t0e6Yz","outputId":"656dbaf3-9e4b-457c-db53-ad05606c6389"},"cell_type":"code","source":"#We have 21381 uniqe words in out dictionary, lets check how many words we have in total. To do it we can multiplay rows length * columns length.\n#We need to do it for each row and then sum it up, becuase every row has diffrent number of words\nsum(len(row) for row in descriptions_tokenized)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"eg2W24rne6Y0","outputId":"479b5d4b-06e3-4740-a377-0535b7310e98"},"cell_type":"code","source":"#If the dictionary would be huge, we could decrease number of words by deleting these with low frequency (lets say these which appear only once)\n#Now we have ids for each word\ndictionary.token2id['island']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"JyE9RXuFe6Y0"},"cell_type":"code","source":"#Now we can exchange all descriptions to numbers (their identifiers). It's called bag of words (bow).\ndescriptions_bow = [dictionary.doc2bow(description) for description in descriptions_tokenized]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"WHH3Db_ae6Y0","outputId":"b266f926-ab34-4336-9ccf-91cbd352ac38"},"cell_type":"code","source":"#First number in tuple is ID of word. Second number in tuple is frequency in document number 88\ndescriptions_bow[89]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"Xq6gq40Ge6Y1","outputId":"672a43f7-705f-4c86-f0b9-cddf5999fbd0"},"cell_type":"code","source":"#Now we can create model which will allow us to represent documents as vectors. We need that to search for similarities using math. \n#Lets try TFidf which uses frequency for transforming\nfrom gensim import models\n\n# Train the tfidf model \ntfidf = models.TfidfModel(descriptions_bow)\n\n# Transform the \"shoot enemies\" string to test how it works. First value is word ID and second one is tf-idf weight\nwords = \"shoot enemies\".lower().split()\nprint(tfidf[dictionary.doc2bow(words)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"6WsokFkwe6Y1"},"cell_type":"code","source":"#Lets create spare matrix similarity\nfrom gensim import similarities\n\nindex = similarities.SparseMatrixSimilarity(tfidf[descriptions_bow], num_features=dictionary.num_pos)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"HBRjcZTpe6Y1","outputId":"d748ee10-033f-4d66-9032-90dc6beb2713"},"cell_type":"code","source":"#Now we can use model to find similar descriptions! Lets test one of the descriptions from base. I will use La casa de papel tv series, lets find it by title to get show_id.\nnetflix_data[netflix_data.title.str.find(\"La casa\") > -1]","execution_count":null,"outputs":[]},{"metadata":{"id":"1HhD8wKhgA0-","outputId":"68f78469-ef45-4436-b516-86dee5f8a2c6","trusted":true},"cell_type":"code","source":"descriptions_tokenized[3488]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"UWVGnVV-e6Y1","outputId":"14a64b17-c51f-4df5-f947-a8ee8f1ce6c0"},"cell_type":"code","source":"descriptions_bow[3488]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"H2q00QqVe6Y2"},"cell_type":"code","source":"#Get query bag of words and tfidf model representation\nquery_bow = descriptions_bow[3488]\nquery_tfidf = tfidf[query_bow]","execution_count":null,"outputs":[]},{"metadata":{"id":"Q2fal0qig3FO","trusted":true},"cell_type":"code","source":"#Get similarity list\nsims = index[query_tfidf]","execution_count":null,"outputs":[]},{"metadata":{"id":"iPxi6-8FiD6f","outputId":"d42b3435-46a3-45d9-d875-14724edcedb6","trusted":true},"cell_type":"code","source":"#Lets sort them and check first 15 titles similar to La casa de papel\nsorted_similar = sorted(enumerate(sims), key=lambda x: x[1], reverse=True)\nfor document_number, score in sorted_similar[:15]:\n    print(document_number, netflix_data.iloc[document_number].title, score)","execution_count":null,"outputs":[]},{"metadata":{"id":"G_5lpdGIjX-i","outputId":"bd104ec4-f116-43f7-a1e5-3b7df1652162","trusted":true},"cell_type":"code","source":"#Lets check 3 highest scored films descriptions to check if its somehow similar to La casa de papel description. As you can see La casa de papel similarity is 1.0 because its equal to query.\nfor document_number, score in sorted_similar[0:4]:\n   print(netflix_data.iloc[document_number].title)\n   print(netflix_data.iloc[document_number].description + \"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"id":"CwEJy8B5735U","trusted":true},"cell_type":"code","source":"# Doc2Vec model (propably too small dataset for this one to work good)\nfrom gensim.models.doc2vec import Doc2Vec, TaggedDocument\ndoc_model = models.Doc2Vec(vector_size=50, min_count=2, epochs=500)","execution_count":null,"outputs":[]},{"metadata":{"id":"p5xSnJQv8n1Y","trusted":true},"cell_type":"code","source":"documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(descriptions_tokenized)]\ndoc_model.build_vocab(documents)","execution_count":null,"outputs":[]},{"metadata":{"id":"S5C848m_FVFG","trusted":true},"cell_type":"code","source":"doc_model.train(documents, total_examples=doc_model.corpus_count, epochs=50)","execution_count":null,"outputs":[]},{"metadata":{"id":"Yq1NmTUu9qrA","trusted":true},"cell_type":"code","source":"la_papel_vector = doc_model.infer_vector(descriptions_tokenized[3488])\ndoc_sims = doc_model.docvecs.most_similar([la_papel_vector])","execution_count":null,"outputs":[]},{"metadata":{"id":"TQPCaK3bAKjb","outputId":"eec133bf-b0ea-4b56-d273-d955a942d14d","trusted":true},"cell_type":"code","source":"for document_number, score in doc_sims:\n    print(document_number, netflix_data.iloc[document_number].title, score)","execution_count":null,"outputs":[]},{"metadata":{"id":"6fEZcWJrDiED","outputId":"09ce1d7c-19e2-4820-ae9f-4e07c414b0c8","trusted":true},"cell_type":"code","source":"for document_number, score in doc_sims[0:4]:\n   print(netflix_data.iloc[document_number].title)\n   print(netflix_data.iloc[document_number].description + \"\\n\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}