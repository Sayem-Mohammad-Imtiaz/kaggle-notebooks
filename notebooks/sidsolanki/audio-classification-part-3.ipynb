{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"# important packages\n\t\nimport pandas as pd\t\t\t\t\t# data manipulation using dataframes\nimport numpy as np\t\t\t\t\t# data statistical analysis\n\nimport seaborn as sns\t\t\t\t# Statistical data visualization\nimport matplotlib.pyplot as plt\t\t# data visualisation\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing modified dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"../input/modified-urbansound8kcsv/modified_URBANSOUND8K.csv\", index_col = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"### Define Features(X) & Target(y)\n\nX = df.iloc[:, :-1].values\ny = df.iloc[:, -1].values.reshape(-1,1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X.shape)\nprint(y.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelEncoder\nlabelencoder=LabelEncoder()\ny=to_categorical(labelencoder.fit_transform(y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(y.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Splitting Dataset ###\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split( X, y , test_size = 0.2, random_state = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape, y_train.shape)\nprint(X_test.shape, y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Building","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Input, Dense, Dropout","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_label = y.shape[1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Input(shape = (40, ))) \nmodel.add(Dense(512, activation = 'relu'))\nmodel.add(Dense(256, activation = 'relu'))\nmodel.add(Dense(128, activation = 'relu'))\nmodel.add(Dense(num_label, activation = 'softmax'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import RMSprop, SGD, Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## callbacks\n\nes = EarlyStopping(monitor='val_loss',\n                   mode='min',\n                   verbose=1,\n                   patience=10,\n                   min_delta=0.001)\n\ncp = ModelCheckpoint('./best_model.h5', \n                     monitor='val_loss', \n                     mode='min',\n                     save_best_only=True,\n                     verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics = ['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 100\nnum_batch_size = 32\n\nhistory = model.fit(X_train,\n                    y_train,\n                    epochs = num_epochs,\n                    batch_size = num_batch_size,\n                    verbose = 2,\n                    validation_split = 0.2,\n                    callbacks = [es])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history.history.keys()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'], label='train_loss')\nplt.plot(history.history['val_loss'], label='val_loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.grid(True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['accuracy'], label='train_acc')\nplt.plot(history.history['val_accuracy'], label='val_acc')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.grid(True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Prediction","metadata":{}},{"cell_type":"code","source":"y_pred = model.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = y_pred > 0.5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(y_pred[0], y_test[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Metrices","metadata":{}},{"cell_type":"markdown","source":"## Accuracy","metadata":{}},{"cell_type":"code","source":"# Accuracy\n\nscore = model.evaluate(X_train, y_train, verbose=0)\nprint(\"Training Accuracy: \", score[1])\n\nscore = model.evaluate(X_test, y_test, verbose=0)\nprint(\"Testing Accuracy: \", score[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Confusion Matrix","metadata":{}},{"cell_type":"code","source":"### Confusion Matrix ###\n\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n\nplt.figure(figsize=(10,6))\nsns.heatmap(cm, annot=True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Classification Report","metadata":{}},{"cell_type":"code","source":"### Classification report ###\n\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Testing","metadata":{}},{"cell_type":"code","source":"# load original dataframe\n\nraw_df = pd.read_csv(\"../input/urbansound8k/UrbanSound8K.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# choose random audio file\n\nimport random\nimport os\n\ndir = \"../input/urbansound8k/\"\n\nrow = raw_df.sample()\n\nrow = row.reset_index(drop=True)\n\naudio_file = row['slice_file_name'][0]\naudio_path = dir + 'fold' + str(row['fold'][0]) + '/' + row['slice_file_name'][0]\nclass_label = row['class'][0]\nprint(audio_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import librosa library\n\nimport librosa\t\t\t\t\t\t\t# package for music and audio analysis\nimport librosa.display\nimport IPython.display as ipd\t\t\t# public api for display tool in ipython","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# feature engineering\n\ndef feature_extractor(audio_file):\n    data,sample_rate = librosa.load(audio_file, res_type='kaiser_fast')\n    mfccs_file = librosa.feature.mfcc(y=data, sr=sample_rate, n_mfcc=40)\n    return mfccs_file\n\nmfccs_audio = feature_extractor(audio_path)\nmfccs_audio = np.mean(mfccs_audio.T,axis=0)\nmfccs_audio = mfccs_audio.reshape(-1,1).T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(mfccs_audio.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class prediction\n\npredict_label = model.predict(mfccs_audio)\npredict_label = (predict_label > 0.5).T\npredict_class = labelencoder.inverse_transform(predict_label) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check real and prediction class\n\nprint(predict_class, class_label)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"!!yayyyy","metadata":{}},{"cell_type":"code","source":"# Now listen music od predicted class\n\nipd.Audio(audio_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion","metadata":{}},{"cell_type":"markdown","source":"Our trained model obtained a Training accuracy of average 98%, Validatioon accuracy of 90% and a Testing accuracy of 88%.\nThe performance is very good and the model has generalised well, seeming to predict well when tested against new audio data.","metadata":{}}]}