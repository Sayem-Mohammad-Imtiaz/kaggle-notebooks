{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"## Importing necessary modules"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np #For linear algebra maths\nimport pandas as pd #For data manipulation\nfrom keras.models import Sequential #For DL\nfrom keras.layers import LSTM, Dense, Dropout #For DL\nimport matplotlib.pyplot as plt #For plotting","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"797323f75953473994cc599100d87e4c3d4ac50e"},"cell_type":"markdown","source":"## Settings"},{"metadata":{"trusted":true,"_uuid":"9dbf81f07650073d2e892ab23d82013300d0d932"},"cell_type":"code","source":"hist_len = 10","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f81de6e96b8479361f1380239d894feab4861c6b"},"cell_type":"markdown","source":"## Preprocessing"},{"metadata":{"_uuid":"a05cccf2629bdeee4e8f59d5636010e8cce9febe"},"cell_type":"markdown","source":" Load data from file, then show the beginning to get a feel for the layout of the data."},{"metadata":{"trusted":true,"_uuid":"dd615d515d56ff5a24ed906c74c6eacb0532e118"},"cell_type":"code","source":"data = pd.read_csv(\"../input/avocado.csv\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4b983694411a4819c65782e5cb1b6aff689720f3"},"cell_type":"markdown","source":" Drop all of the unneeded columns, we will only use Average Price"},{"metadata":{"trusted":true,"_uuid":"37984db9f5eec2d9f1be220fe2128a0d898a76d9"},"cell_type":"code","source":"data = data.drop(['Unnamed: 0','Date','Total Volume','4046','4225','4770','Total Bags','Small Bags','Large Bags','XLarge Bags','type','year','region'],1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"be78d547779475c6a15138e5eda5abba3820ca6a"},"cell_type":"markdown","source":"Turn single column to single row with .T\nSo:\n    1        \n    2             =====>         1    2    3   4\n    3           becomes\n    4\n    \n Then turn pandas dataFrame into array."},{"metadata":{"trusted":true,"_uuid":"0791b111332455a4af08e6ced4ae7a2701fb5faa"},"cell_type":"code","source":"data = data.T\ndata = data.values","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9967fb729b593e0876433b89ff5941f7f3fa5d2b"},"cell_type":"markdown","source":"Change the matrix structure slightly, Ex.: [[1,2,3,4....]] to [1,2,3,4....].\n\nNormalise data."},{"metadata":{"trusted":true,"_uuid":"63d1e6895c2509ebc67332d7b7cde654e245d6dd"},"cell_type":"code","source":"data = data[0]\nscale_min = min(data)\nscale_range = max(data) - scale_min\ndata = (data-scale_min)/(scale_range)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6dc730c06445f1c37f63d4d19e5c898302194bfe"},"cell_type":"markdown","source":"Function that constructs each x vector. Then creates lists of each x input and the corresponding y output.\nEx.:      a_list = [1,2,3,4,5,6,7,8,9,10,11,12,13] with a hist_len of 3, the lists created are as:\n\n   xs = [[1,2,3],   and ys = [4,\n           [2,3,4],                    5,\n           [3,4,5],                    6,\n               .....]                     ...]\n               \n so for [1,2,3] the network needs to predict 4. \n \n Then split both lists into training and validation sets. With the last ~10% being used as validation data."},{"metadata":{"trusted":true,"_uuid":"5ec521b0a16bdbf2b85fbd7ee36f51ea005c64ee"},"cell_type":"code","source":"def make_feed_dicts(data,hist_len):\n    xs,ys = [],[]\n    for i in range(len(data)-hist_len-1):\n        ys.append(data[i+hist_len])\n        xs.append(data[i:i+hist_len])\n    j = int(len(data)*0.9)\n    return np.array(xs[:j]),np.array(xs[j:]),np.array(ys[:j]),np.array(ys[j:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b8d9d05b9998eada89061f73182dfb020692129"},"cell_type":"code","source":"x_train, x_test, y_train, y_test = make_feed_dicts(data,hist_len)\nx_test.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"492465912d2b43c70a2264293e7fbdc5213281e5"},"cell_type":"markdown","source":"Reshape data for the last time."},{"metadata":{"trusted":true,"_uuid":"101f14906f4b9eb70309a835fb266ca4851e8faa"},"cell_type":"code","source":"x_train = x_train.reshape((x_train.shape[0],x_train.shape[1],1))\nx_test = x_test.reshape((x_test.shape[0],x_test.shape[1],1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c7033af65e59f76573e670d0f39cb0e1ba775586"},"cell_type":"code","source":"x_test.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"be7d5c9ff0965a45bdfa1db1ab8f000bd98fbc44"},"cell_type":"markdown","source":"## Building Model"},{"metadata":{"trusted":true,"_uuid":"2fad55ed9da63dd79ed985b914e451ce19ef3598"},"cell_type":"code","source":"model = Sequential()\nmodel.add(LSTM(256,input_shape=(hist_len,1)))\nmodel.add(Dense(5))\n#model.add(Dropout(0.1))\nmodel.add(Dense(1))\nmodel.compile(optimizer='adam', loss='mse')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4fab34c65500b89377ba4f995bc2c5fe0df61900"},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3d4cd9766630e828fce1b556158361b95e69ce4e"},"cell_type":"markdown","source":"## Training"},{"metadata":{"trusted":true,"_uuid":"41510bbb978fa7664845484752d462d5f586c9ea"},"cell_type":"code","source":"history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test,y_test),shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0b7a711f086dce3c039b1350d3dd677a57cb8da4"},"cell_type":"markdown","source":"## Loss and Validation Loss Graphs"},{"metadata":{"trusted":true,"_uuid":"0699abc5992e7f35f586aba85a8610f0a2865d78"},"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e95c53cd580af2cee23b285cb456049f9700b7ab"},"cell_type":"markdown","source":"Lets see how well the trained model agrees with the actual validation data."},{"metadata":{"trusted":true,"_uuid":"ee9fd3df423f00c350d82db888683d022d50b5d2"},"cell_type":"code","source":"predicted_x = model.predict(x_test[:250])\nplt.plot(predicted_x*scale_range+scale_min)\nplt.plot(y_test[:250].reshape(-1,1)*scale_range+scale_min)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"28bc0add9fe8e5aef8922f081f77a12749b76a0a"},"cell_type":"markdown","source":"Now lets predict forward:"},{"metadata":{"trusted":true,"_uuid":"170d3f8476dd2e655c890ee27ec96b51eed8f913"},"cell_type":"code","source":"step = np.array([x_test[0]])\n\n\n\ndef take_step(step):\n    next_step = model.predict(step)\n    next_step = next_step.reshape(1,1,1)\n    next_step = np.concatenate(([step[0][1:]],next_step),axis=1)\n    return next_step, next_step[0][0][0]\n    \n    \ntrendline = []\nfor _ in range(100):\n    step, value = take_step(step)\n    trendline.append(value)\n    \nplt.plot(trendline)\nplt.plot(y_test[7:100])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}