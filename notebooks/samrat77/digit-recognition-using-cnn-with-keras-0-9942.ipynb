{"cells":[{"metadata":{},"cell_type":"markdown","source":"**MNIST digit recognition using CNN with Keras**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Handle table-like data and matrices\nimport numpy as np\nimport pandas as pd\nimport math \n# Modelling Algorithms\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier , GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score\n\n# Modelling Helpers\nfrom sklearn.preprocessing import Imputer , Normalizer , scale\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import RFECV\nimport datetime as dt\n\n# Visualisation\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns\nimport keras\nfrom keras import backend as K\n\n# Configure visualisations\n%matplotlib inline\nmpl.style.use( 'ggplot' )\nsns.set_style( 'white' )\npylab.rcParams[ 'figure.figsize' ] = 8 , 6\nfrom random import randint","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/digit-recognizer/train.csv')\ntest = pd.read_csv('../input/digit-recognizer/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = train.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.shape , test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df.label.values.astype('int32')\ndf = df[df.columns[1:]].values.astype('float32')\n\nX_train , X_test , y_train , y_test = train_test_split(df , y , test_size = 0.2 , random_state = 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print ( X_train.shape , y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = test.values.astype('float32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train.reshape( -1 , 28 , 28 , 1)\nX_test = X_test.reshape( -1 , 28 , 28 , 1)\ntest = test.reshape( -1 , 28 , 28 , 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new = pd.read_csv('../input/digit-recognizer/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"new.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_counter = new.label.value_counts()\nprint (label_counter)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize = (8,5))\nplt.title('Count of different digits as labeled in the datset')\nsns.countplot(x=new.label , data=new)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**# Normalizing**"},{"metadata":{},"cell_type":"markdown","source":"Now we have 33,600 images with dimensions of 28 x 28 x 1 in X_train ."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train / 255\nX_test = X_test / 255\ntest = test / 255","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nConverting y_train and y_test into one hot encoder , eg. 3--> [0,0,0,1,0,0,0,0,0,0]"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = keras.utils.to_categorical(y_train, 10)\ny_test = keras.utils.to_categorical(y_test, 10)  #  10 is used because we have to classify images in 10 groups","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential, load_model\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Making the model with convolutional layers , maxpool layers and dropout layers to enhance regularization and generalization with further avoidance to overfitting ."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32, (3, 3), activation='relu', padding='same',input_shape=(28 , 28 , 1)))\nmodel.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\nmodel.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(100, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\nmodel.add(Dense(10, activation='softmax'))      #  10 is used because we have to classify images in 10 groups","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer = RMSprop(lr=0.001),loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.0, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\ndatagen.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 64\nepochs = 10\nlr_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.1, epsilon=0.0001, patience=1, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),\n                    steps_per_epoch=X_train.shape[0] // batch_size,\n                    callbacks=[lr_reduce],\n                    validation_data=(X_test, y_test),\n                    epochs = epochs, verbose = 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = model.evaluate(X_test, y_test, verbose=0)\nprint('valid loss:', score[0])\nprint('valid accuracy:', score[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_digits = np.argmax(pred , axis = 1)\nImageId = range( 1 , len(pred_digits)+1 )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"pred_digits contains the predicted labels of the digits .\nargmax(axis = 1) is converting the one hot encoder back to the labels along the row axis ."},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_digits","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(ImageId)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"context = {\"ImageId\" : ImageId , \"Label\" : pred_digits }\nans = pd.DataFrame(context)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ans is the predicted dataframe by CNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"ans.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Converting the dataframe to csv file"},{"metadata":{"trusted":true},"cell_type":"code","source":"ans.to_csv(\"Predictions by CNN.csv\", index=None)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}