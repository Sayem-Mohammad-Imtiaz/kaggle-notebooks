{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **Algorythms for MNIST dataset**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The MNIST dataset is a contain a 70000 photos of handwriten digits. 60000 for training set and 10000 for test set.\nEach photo is of size 28x28.\nMore about the dataset is here: [http://yann.lecun.com/exdb/mnist/](http://)\n\nWe will load the dataset and try some algorythms of both machine learning and deep learning algorythms. We will achieve 99% accuracy.\n\nWe will check:\n* logistic regression\n* random forest\n* kneighbours\n* neural network\n* convolutional neural network\n\nNeural network is a plain network with 2 hidden layers.\nEarch hidden layer has 784 neurons.\n\nConvolutional neural network is very similar to the Lenet-5.\nAbout LeNet-5:\n[https://towardsdatascience.com/understanding-and-implementing-lenet-5-cnn-architecture-deep-learning-a2d531ebc342](http://)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Results**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* Logistic regression: 92.256% accuracy\n* Random Forest: 96.85% accuracy\n* KNeighbours: 96.88% accuracy\n* Neural Network: 98.07% accuracy\n* Convolutional Neural Network: 99.11% accuracy ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n#loading the data\ntrain = pd.read_csv('../input/mnist-in-csv/mnist_train.csv')\ntest = pd.read_csv('../input/mnist-in-csv/mnist_test.csv')\nprint(train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_train = train.iloc[:,0]\nY_train = pd.DataFrame(Y_train).to_numpy()\nY_train = Y_train.reshape(60000)\nX_train = train.iloc[:,1:785]\nX_train = pd.DataFrame(X_train).to_numpy()\nY_test = test.iloc[:,0]\nY_test = pd.DataFrame(Y_test).to_numpy()\nY_test = Y_test.reshape(10000)\nX_test = test.iloc[:,1:785]\nX_test = pd.DataFrame(X_test).to_numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train.reshape(60000,28,28)\nX_test = X_test.reshape(10000,28,28)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#we want pixels to be between 0 and 1\nX_train = X_train/255\nX_test = X_test/255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\ndef show_number(indeks):\n    \"\"\"Show number using matplotlib, indeks should be in range 0 - 59999\"\"\"\n    plt.imshow(X_train[indeks])\n    plt.title(\"Digit: \" + str(Y_train[indeks]))\n    plt.show()\n    \nshow_number(5)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train.reshape(60000,784)\nX_test = X_test.reshape(10000,784)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def examine_model(model, X_train, Y_train, X_test, Y_test):\n    model.fit(X_train,Y_train)\n    accuracy = model.score(X_test, Y_test)\n    return accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = examine_model(LogisticRegression(max_iter=1000), X_train, Y_train, X_test, Y_test)\nprint(\"Logistic regression:\")\nprint(accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = examine_model(RandomForestClassifier(), X_train, Y_train, X_test, Y_test)\nprint(\"Random Forest Classifier:\")\nprint(accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = examine_model(KNeighborsClassifier(),X_train, Y_train, X_test, Y_test)\nprint(\"K-Neighbors Classifier:\")\nprint(accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\nfrom keras.layers import AveragePooling2D, MaxPooling2D\nfrom keras.models import Model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def two_layers(input_shape):\n    \"\"\"The model of the neural network with two hidden fully connected layers and softmax output\"\"\"\n    X_input = Input(input_shape)\n    X = Dense(748, activation=\"relu\", name=\"first\")(X_input)\n    X = Dense(748, activation=\"relu\", name=\"second\")(X)\n    X = X = Dense(10, activation=\"softmax\", name=\"last\")(X)\n    \n    model = Model(inputs = X_input, outputs = X, name='Two_hidden_layers')\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are few differences between this network and LeNet-5:\n* we use relu activations\n* we use batch normalization\n* max-pooling instead of average-pooling\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def CNN_model(input_shape):\n    \"\"\"The model of simple convolutional neural network, the model is similar to NeLet5 but with a few adjustments\"\"\"\n    X_input = Input(input_shape)\n    X = ZeroPadding2D((3, 3))(X_input)\n    \n    X = Conv2D(6, (5, 5), strides = (1, 1), name = 'conv1')(X)\n    X = BatchNormalization(axis = 3, name = 'bn1')(X)\n    X = Activation('relu')(X)\n    \n    X = MaxPooling2D((2, 2), name='max_pool1')(X)\n    \n    X = Conv2D(16, (5, 5), strides = (1, 1), name = 'conv2')(X)\n    X = BatchNormalization(axis = 3, name = 'bn2')(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D((2, 2), name='max_pool2')(X)\n\n    X = Flatten()(X)\n    X = Dense(84, activation=\"relu\")(X)\n    X = Dense(10, activation=\"softmax\")(X)\n    \n    model = Model(inputs = X_input, outputs = X, name='CNN')\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape[1:])\nNN_model = two_layers(X_train.shape[1:])\nNN_model.compile(optimizer = \"adam\", loss = \"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NN_model.fit(x = X_train, y = Y_train, epochs = 30, batch_size = 32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nn_predictions = NN_model.evaluate(x = X_test, y = Y_test)\n\nprint(nn_predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train.reshape((60000,28,28,1))\nX_test = X_test.reshape((10000,28,28,1))\nprint(X_train.shape)\ncnn_model = CNN_model(X_train.shape[1:])\ncnn_model.compile(optimizer = \"adam\", loss = \"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cnn_model.fit(x = X_train, y = Y_train, epochs = 30, batch_size = 32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cnn_predictions = cnn_model.evaluate(x = X_test, y = Y_test)\n\nprint(cnn_predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}