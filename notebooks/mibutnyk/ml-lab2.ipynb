{"cells":[{"metadata":{},"cell_type":"markdown","source":"## 1 Методы ближайших соседей"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import GridSearchCV, KFold, cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\nfrom sklearn.metrics import accuracy_score, mean_squared_error\nfrom scipy.stats import normaltest\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv', sep=',')\ndf.head(10).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Наша задача заключается в определении качества красного вина на основе признаков, которые на это влияют. Наш целевой признак (target) - это 'quality', качество красного вина по неизвестной шкале (у нас присутствуют значения от 3 до 8). Соответственно, можем сделать вывод, что наш целевой признак является ранговым (порядковым). Исходя из этого можем рассматривать задачу и как классификацию, и как регрессию."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['quality'].hist(bins=11);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"normaltest(df['quality'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"По графику и специальной функции normaltest видим, что у значений таргет-переменной распределение не нормальное."},{"metadata":{},"cell_type":"markdown","source":"Так как значения наших признаков покрывают разные диапазоны, необходимо масштабировать данные:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\ny = df['quality']\nX = df.drop('quality', axis=1)\nX_new = scaler.fit_transform(X)\nprint(X_new[:5, :5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(X_new,\n                                                      y, \n                                                      test_size=0.2, \n                                                      random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Разбиваем наш набор данных на обучающую и валидационную (тестовую) выборки, по 80% и 20% соответственно."},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors=1)\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_valid)\nknn.score(X_valid, y_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(y_valid, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knr = KNeighborsRegressor(n_neighbors=1)\nknr.fit(X_train, y_train)\ny1_pred = knr.predict(X_valid)\nmean_squared_error(y_valid, y1_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Как видим, качество метода ближайших соседей для регрессии немного хуже, чем качество этого же метода для классификации (касательно нашего датасета), поэтому в дальнейшем будем использовать KNeighborsClassifier."},{"metadata":{},"cell_type":"markdown","source":"## 2 Настройка оптимального числа ближайших соседей в методе kNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"kf = KFold(n_splits=5, shuffle=True, random_state=42)\nscores = cross_val_score(knn, X_new, y,\n                         cv=kf, scoring='accuracy')\nprint(scores)\nmean_score = scores.mean()\nprint(mean_score)    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"В целом, использование данной меры (метрики) качества более менее приемлемо для нашей задачи, ведь оценка качества вина не требует хирургической точности, хотя, конечно, хотелось бы иметь точность повыше."},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = cross_val_score(knn, X_new, y,\n                         cv=kf, scoring='balanced_accuracy')\nprint(scores)\nmean_score = scores.mean()\nprint(mean_score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Так как у нас крайне небольшой выбор возможных метрик качества, попробуем сходную метрику balanced_accuracy. По результатам видим, что наша метрика качества действительно приемлема."},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_params = {'n_neighbors': np.arange(1, 51)}\nknn_grid = GridSearchCV(knn, \n                        knn_params, \n                        scoring='accuracy',\n                        cv=kf)\nknn_grid.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_grid.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_grid.best_score_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Как видим, наилучшее качество мы получили при количестве соседей = 1, и это качество ≈ 0.613. "},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_results = pd.DataFrame(knn_grid.cv_results_)\nplt.plot(grid_results['param_n_neighbors'], grid_results['mean_test_score'])\nplt.xlabel('n_neighbors')\nplt.ylabel('knn_score')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"График значений метрики в зависимости от количества соседей."},{"metadata":{},"cell_type":"markdown","source":"## 3 Выбор метрики в методе kNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"knn2 = KNeighborsClassifier(n_neighbors=1, weights='distance')\nknn2_params = {'p': np.linspace(1, 10, num=200, endpoint=True)}\nknn2_grid = GridSearchCV(knn2, \n                        knn2_params, \n                        scoring='accuracy',\n                        cv=kf)\nknn2_grid.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn2_grid.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn2_grid.best_score_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Как видим, наилучшее качество мы получили при р ≈ 8.779, и это качество ≈ 0.6215."},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_results2 = pd.DataFrame(knn2_grid.cv_results_)\nplt.plot(grid_results2['param_p'], grid_results2['mean_test_score'])\nplt.xlabel('р')\nplt.ylabel('knn_score')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4 Другие метрические методы"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import RadiusNeighborsClassifier\nrnn = RadiusNeighborsClassifier(radius=5.0)\nrnn.fit(X_train, y_train)\ny2_pred = rnn.predict(X_valid)\nrnn.score(X_valid, y_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(y_valid, y2_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import NearestCentroid\nnc = NearestCentroid()\nnc.fit(X_train, y_train)\ny3_pred = nc.predict(X_valid)\nnc.score(X_valid, y_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(y_valid, y3_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Поэкспериментировав с другими метрическими методами, видим, что метод ближайших соседей для нашей задачи является наиболее приемлемым."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}