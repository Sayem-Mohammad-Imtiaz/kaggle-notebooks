{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot  as plt \n%matplotlib inline\nimport cv2 as cv\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfrom keras.layers import Dense, Convolution2D, UpSampling2D, MaxPooling2D, ZeroPadding2D, Flatten, Dropout, Reshape\nfrom keras.models import Sequential\nfrom keras.utils import np_utils","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dataset = pd.read_csv('../input/facial-expression-recognitionferchallenge/fer2013/fer2013/fer2013.csv')\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = dataset[[\"emotion\", \"pixels\"]][dataset[\"Usage\"] == \"Training\"]\ntest_data = dataset[[\"emotion\", \"pixels\"]][dataset[\"Usage\"] == \"PrivateTest\"]       \n# val_data = dataset[[\"emotion\", \"pixels\"]][dataset[\"Usage\"] == \"PublicTest\"]      ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = train_data['pixels'].apply(lambda x:np.fromstring(x, sep = ' ').reshape(48,48))\nx_test = test_data['pixels'].apply(lambda x:np.fromstring(x, sep = ' ').reshape(48,48))\n# x_val = val_data['pixels'].apply(lambda x:np.fromstring(x, sep = ' ').reshape(48,48))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from math import ceil\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.zeros((x_train.shape[0],48,48,3))\nfor a,x in enumerate(x_train):\n    X_train[a] = np.expand_dims(x,axis=2)\nX_train = np.array(X_train)\nprint(X_train.shape)\n\nX_test = np.zeros((x_test.shape[0],48,48,3))\nfor a,x in enumerate(x_test):\n    X_test[a] = np.expand_dims(x,axis=2)\nX_test = np.array(X_test)\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = train_data['emotion']\ny_test = test_data['emotion']\n# y_val = val_data['emotion']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_dict = {0:'Angry', 1:'Disgust', 2:'Fear', 3:'Happy', 4:'Sad', 5:'Surprise', 6:'Neutral'}\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(X_valdata[10][0],cmap='bone')\nplt.title(label_dict[Y_valdata[10].argmax()])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\n# y_val = to_categorical(y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_split = 0.8\nsplit = ceil(x_train.shape[0]*val_split)\nX_traindata = X_train[0:split]\nX_valdata = X_train[split:]\nY_traindata = y_train[0:split]\nY_valdata = y_train[split:]\nprint(X_traindata.shape,X_valdata.shape)\nprint(Y_traindata.shape,Y_valdata.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  \n        samplewise_center=False,  \n        featurewise_std_normalization=False,  \n        samplewise_std_normalization=False,  \n        zca_whitening=False,  \n        rotation_range=10,  \n        zoom_range = 0.0,  \n        width_shift_range=0.1,  \n        height_shift_range=0.1,  \n        horizontal_flip=False, \n        vertical_flip=False)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import ReduceLROnPlateau\nlr_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.1, epsilon=0.0001, patience=1, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install keras","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Dense , Activation\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.constraints import maxnorm\nfrom keras.optimizers import SGD , Adam\nfrom keras.layers import Input, Conv2D , BatchNormalization\nfrom keras.layers import MaxPooling2D\nfrom keras.utils import np_utils\nfrom keras import backend as K\nK.common.set_image_dim_ordering('th')\nfrom keras.applications.mobilenet_v2 import MobileNetV2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mnetv2 = MobileNetV2(include_top=False,input_shape=(48,48,3), weights='imagenet')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mnetv2.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"topLayerModel = Sequential()\n\ntopLayerModel.add(mnetv2)\ntopLayerModel.add(Flatten())\ntopLayerModel.add(Dense(256, activation='relu'))\ntopLayerModel.add(Dense(256, activation='relu'))\ntopLayerModel.add(Dropout(0.5))\ntopLayerModel.add(Dense(128, activation='relu'))\ntopLayerModel.add(Dense(7, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(topLayerModel.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"topLayerModel.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = topLayerModel.fit_generator(datagen.flow(X_traindata, Y_traindata, batch_size=128),\n                    steps_per_epoch=ceil(X_train.shape[0] / 128) ,\n                    callbacks=[lr_reduce,],\n                    validation_data=(X_valdata, Y_valdata),\n                    epochs = 10, verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nprint(tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = np.zeros((x_test.shape[0],48,48,3))\nfor a,x in enumerate(x_test):\n    X_test[a] = np.expand_dims(x,axis=2)\nX_test = np.array(X_test)\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Select id for manual checking\nidx = 511\nprint(\"Output: \",label_dict[topLayerModel.predict(np.array([X_test[idx]])).argmax()])\nplt.imshow(x_test.iloc[idx],cmap='bone')\nplt.title(label_dict[y_test[idx].argmax()])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}