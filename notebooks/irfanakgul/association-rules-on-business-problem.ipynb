{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Business Problem\n\n### What is the **Association Rules**?\n\nIt is a rule-based machine learning technique used to find patterns (relationships, structures) in the data.\n\nAssociation analysis applications are among the most common applications in data science. It will also coincide as Recommendation Systems.\n\nThese applications may have come up in the following ways, such as \"bought this product that bought that product\" or \"those who viewed that ad also looked at these ads\" or \"we created a playlist for you\" or \"recommended video for the next video\".\n\nThese scenarios are the most frequently encountered scenarios within the scope of e-commerce data science data mining studies.\n\nIn Turkey and the world's largest e-commerce companies spotify, amazon, it uses many platforms like netflix recommendation systems can know a little more closely.\n\n### So what does this association analysis summarize?\n\n#### Apriori Algorithm\n\nIt is the most used method in this field.\n\nAssociation rule analysis is carried out by examining some metrics:\n\n* Support\n    Support(X, Y) = Freq(X,Y)/N\n        X: Product\n        Y: Product\n        N: Total Shopping\n\n* Confidence\n\n        Confidence (X, Y) = Freq (X, Y) / Freq (X)\n\n* Lift (The purchase of one product increases the level of purchase of the other.)\n\n        Lift = Support (X, Y) / (Support (X) * Support (Y))\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom mlxtend.frequent_patterns import apriori, association_rules\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Understanding"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/online-retail-data-set-from-ml-repository/retail_dataset.csv', sep=',')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we have to convert this DF, which is made up of categorical variables to DF, which consists of 0's and 1's."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"items = (df['0'].unique())\nitems","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" The main purpose now is to ensure that the variables in the column are on the line. One-Hot Encoding method will help us to do this."},{"metadata":{"trusted":true},"cell_type":"code","source":"encoded_vals = []\nfor index, row in df.iterrows(): \n    labels = {}\n    uncommons = list(set(items) - set(row))\n    commons = list(set(items).intersection(row))\n    for uc in uncommons:\n        labels[uc] = 0\n    for com in commons:\n        labels[com] = 1\n    encoded_vals.append(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ohe_df = pd.DataFrame(encoded_vals)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see what happenned after One-Hot Encoding method:"},{"metadata":{"trusted":true},"cell_type":"code","source":"ohe_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Association Rules\n\nFor apriori, you need to do one by giving DF with hot encoding."},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_items = apriori(ohe_df, min_support = 0.2, use_colnames = True, verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thus, support values are calculated. Let's check it:"},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_items.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally, we will see the function association_rules (togetherness analysis), we need to use support (frequency items) DF."},{"metadata":{"trusted":true},"cell_type":"code","source":"association_rules(freq_items, metric = \"confidence\", min_threshold = 0.6)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## We can easily see how often there is a connection between which products."},{"metadata":{},"cell_type":"markdown","source":"\n# Conclusion\n\nAfter this notebook, my aim is to prepare 'kernel' which is 'not clear' data set.\n\nIf you have any suggestions, please could you write for me? I wil be happy for comment and critics!\n\nThank you for your suggestion and votes ;)\n\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}