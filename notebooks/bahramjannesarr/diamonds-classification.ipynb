{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split , GridSearchCV , cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler , MinMaxScaler\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report , confusion_matrix , roc_curve , roc_auc_score \nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"diamonds = pd.read_csv('../input/diamonds/diamonds.csv' , index_col = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diamonds.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diamonds.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clarity = pd.get_dummies(diamonds['clarity'])\ncolor = pd.get_dummies(diamonds['color'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diamonds = pd.concat([diamonds , clarity , color] , axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diamonds.drop(['color' , 'clarity'] , axis = 1 , inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diamonds.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diamonds.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 20))\ndf_corr = diamonds.corr()\nsns.heatmap(df_corr, cmap=sns.diverging_palette(220, 20, n=12), annot=True)\nplt.title(\"Diamonds\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diamonds['cut'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_kg_hide-input":false,"_kg_hide-output":true},"cell_type":"code","source":"for i in range(len(diamonds)):\n    if diamonds['cut'].iloc[i] == 'Ideal':\n        diamonds['cut'].iloc[i] = 1\n    if diamonds['cut'].iloc[i] == 'Premium':\n        diamonds['cut'].iloc[i] = 2\n    if diamonds['cut'].iloc[i] == 'Very Good':\n        diamonds['cut'].iloc[i] = 3\n    if diamonds['cut'].iloc[i] == 'Good':\n        diamonds['cut'].iloc[i] = 4\n    if diamonds['cut'].iloc[i] == 'Fair':\n        diamonds['cut'].iloc[i] = 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = diamonds.drop(['cut'], axis = 1 ).values\ny = diamonds['cut'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scalar = StandardScaler()\nX = scalar.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X , y  , test_size = 0.2 , random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = y_train.astype('int')\ny_test = y_test.astype('int')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Functions\nI run 3 algorithm on this dataset \n1. kNN ( k-nearest neighbors )\n2. SVM ( Sub vector machine )\n3. Logistic Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_and_plot_k_neighbors(X_train, X_test, y_train, y_test):\n    \n    neighbors = np.arange(1, 10)\n    train_accuracy = np.empty(len(neighbors))\n    test_accuracy = np.empty(len(neighbors))\n    \n    for i, k in enumerate(neighbors):\n        knn = KNeighborsClassifier(n_neighbors= k)\n        knn.fit(X_train , y_train)\n        train_accuracy[i] = knn.score(X_train, y_train)    \n        test_accuracy[i] = knn.score(X_test, y_test)\n\n    plt.figure(figsize=(10, 8))   \n    plt.title('k in kNN analysis')\n    plt.plot( neighbors , test_accuracy , label = 'Testing Accuracy')\n    plt.plot(neighbors,train_accuracy ,label = 'Training Accuracy')\n    plt.legend()\n    plt.annotate('Best accuracy for this model with this k is {0:.2f} %'.format(max(test_accuracy) * 100), xy=(np.argmax(test_accuracy) + 1 , max(test_accuracy)), xytext=(5 , 0.80),\n            arrowprops=dict(arrowstyle=\"->\",\n                            connectionstyle=\"angle3,angleA=0,angleB=-90\"));\n    plt.xlabel('Number of Neighbors')\n    plt.ylabel('Accuracy')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_confusion_matrix(cf_matrix , y_test , model_type , cf_size):\n    if cf_size == '2x2':\n        group_names = ['True Negative','False Positive','False Negative','True Positive']\n        group_counts = ['{0:0.0f}'.format(value) for value in cf_matrix.flatten()]\n        labels = ['{}\\n{}'.format(v1 ,v2) for v1, v2 in zip(group_names,group_counts)]\n        labels = np.asarray(labels).reshape(2,2)\n        plt.figure(figsize=(10, 8))\n        sns.heatmap(\n            cf_matrix,\n            annot = labels,\n            cmap=sns.cubehelix_palette(100, as_cmap=True, hue=1, dark=0.30),\n            fmt='',\n            linewidths=1.5,\n            vmin=0,\n            vmax=len(y_test),\n        )\n        plt.title(model_type)\n        plt.show()\n    else:\n        plt.figure(figsize=(10, 8))\n        sns.heatmap(\n            cf_matrix / np.sum(cf_matrix) * 100,\n            annot = True,\n            cmap=sns.cubehelix_palette(100, as_cmap=True, hue=1, dark=0.30),\n            fmt='.2f',\n            linewidths=1.5,\n            vmin=0,\n            vmax=100,\n        )\n        plt.title(model_type)\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def kNN_algorithm(X_train , y_train , X_test , y_test , k):\n    \n    global y_pred_kNN\n    global kNN_pipeline\n    \n    steps = [('impute' , SimpleImputer(missing_values = 0, strategy='mean')),\n             ('sclaer', StandardScaler()),\n             ('kNN', KNeighborsClassifier(n_neighbors = k))]\n    \n    kNN_pipeline = Pipeline(steps)\n    \n    kNN_pipeline.fit(X_train , y_train)\n    \n    y_pred_kNN = kNN_pipeline.predict(X_test)\n    \n    print(classification_report(y_test , y_pred_kNN))\n    print('kNN algorithm acuracy is : {0:.2f} %'.format(kNN_pipeline.score(X_test , y_test) * 100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def SVM_algorithm(X_train, X_test, y_train, y_test):\n    \n    global y_pred_SVM\n    global SVM_pipeline\n    global y_prob_SVM\n    \n    steps = [('scaler', StandardScaler()),\n             ('SVM', SVC(probability=True))]\n    \n    SVM_pipeline = Pipeline(steps)\n    \n    parameters = {'SVM__C':[1, 10, 100 ],\n                  'SVM__gamma':[0.1, 0.01]}\n    \n    cv = GridSearchCV(SVM_pipeline , cv = 5 , param_grid = parameters)\n    \n    cv.fit(X_train , y_train)\n    \n    y_pred_SVM = cv.predict(X_test)\n    \n    y_prob_SVM = cv.predict_proba(X_test)\n    \n    print(\"Accuracy: {0:.2f} %\".format(cv.score(X_test, y_test) * 100))\n    print(classification_report(y_test, y_pred_SVM))\n    print(\"Tuned Model Parameters: {}\".format(cv.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def LogisticRegression_algorithm(X_train, X_test, y_train, y_test):\n    \n    global y_pred_LG\n    global LG_pipeline\n    global y_prob_LG\n    \n    steps = [('scaler', StandardScaler()),\n             ('LogisticRegression', LogisticRegression(random_state = 0))]\n    \n    LG_pipeline = Pipeline(steps)\n\n    \n    LG_pipeline.fit(X_train , y_train)\n    \n    y_pred_LG = LG_pipeline.predict(X_test)\n    \n    y_prob_LG = LG_pipeline.predict_proba(X_test)\n    \n    print(\"Accuracy: {0:.2f} %\".format(LG_pipeline.score(X_test, y_test) * 100))\n    print(classification_report(y_test, y_pred_LG))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# kNN (k-nearest neighbors)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"calculate_and_plot_k_neighbors(X_train, X_test, y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kNN_algorithm(X_train , y_train , X_test , y_test , 8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cf_matrix_knn = confusion_matrix(y_test, y_pred_kNN)\ncf_matrix_knn = pd.DataFrame(cf_matrix_knn  , index = ['Ideal' ,'Premium','Very Good','Good','Fair'] , columns =['Ideal','Premium','Very Good','Good','Fair'])\nplot_confusion_matrix(cf_matrix_knn , y_test , 'kNN Confusion Matrix in percent %' , '5x5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SVM (Sub vector machine)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"SVM_algorithm(X_train, X_test, y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cf_matrix_SVM = confusion_matrix(y_test, y_pred_SVM)\ncf_matrix_SVM = pd.DataFrame(cf_matrix_SVM  , index = ['Ideal' ,'Premium','Very Good','Good','Fair'] , columns =['Ideal','Premium','Very Good','Good','Fair'])\nplot_confusion_matrix(cf_matrix_SVM , y_test , 'SVM Confusion Matrix in percent' , '5x5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"LogisticRegression_algorithm(X_train, X_test, y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cf_matrix_LG = confusion_matrix(y_test, y_pred_LG)\ncf_matrix_LG = pd.DataFrame(cf_matrix_LG  , index = ['Ideal' ,'Premium','Very Good','Good','Fair'] , columns =['Ideal','Premium','Very Good','Good','Fair'])\nplot_confusion_matrix(cf_matrix_LG , y_test , 'LogisticRegression Confusion Matrix in percent' , '5x5')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}