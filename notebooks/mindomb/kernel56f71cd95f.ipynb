{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n    %tensorflow_version 2.x\nexcept:\n    pass","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"SETUP = True\nif SETUP:\n    !pip install -q -U toai\n    # !pip install -q -U nb_black\n    # !pip install -q -U tensorflow-datasets\n    !pip install -q  --no-deps tensorflow-addons~=0.6\n    print(__import__(\"toai\").__version__)\n    print(__import__(\"tensorflow\").__version__)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from toai.imports import *\nfrom toai.data import DataBundle, DataParams, DataContainer\n# from toai.image import ImageParser, ImageScaler\nimport tensorflow as tf\nfrom tensorflow import keras","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from typing import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_DIR = Path(\"/kaggle/input/pokemon-images-and-types/images/images\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 32\nSHUFFLE_SIZE = 1024\nIMG_DIMS = (64, 64, 3)\nN_IMAGES = len(os.listdir(DATA_DIR))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import attr\n\n@attr.s(auto_attribs=True)\nclass ImageParser:\n    n_channels: int = 3\n\n    def __call__(self, filename: tf.Tensor, label: tf.Tensor) -> tf.Tensor:\n        image = tf.image.decode_jpeg(\n            tf.io.read_file(filename), channels=self.n_channels\n        )\n        image = tf.image.convert_image_dtype(image, tf.float32)\n\n        return image, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@attr.s(auto_attribs=True)\nclass ImageResizer:\n    img_dims: Tuple[int, int, int]\n    resize: Optional[str] = None\n    crop_adjustment: float = 1\n\n    def __call__(self, image: tf.Tensor, label: tf.Tensor) -> tf.Tensor:\n        height, width, _ = self.img_dims\n        if self.resize == \"stretch\":\n            image = tf.image.resize(image, (height, width))\n        elif self.resize == \"crop\":\n            crop_height, crop_width = [\n                int(x * self.crop_adjustment) for x in (height, width)\n            ]\n            image = tf.image.resize(\n                images=image, size=(crop_height, crop_width), preserve_aspect_ratio=True\n            )\n            image = tf.image.resize_with_crop_or_pad(image, height, width)\n        elif self.resize == \"random_crop\":\n            crop_height, crop_width = [\n                int(x * self.crop_adjustment) for x in (height, width)\n            ]\n            image = tf.image.resize(image, (crop_height, crop_width))\n            image = tf.image.random_crop(image, self.img_dims)\n\n        return image, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@attr.s(auto_attribs=True)\nclass ImageScaler:\n    scale_fn: Callable\n\n    def __call__(self, image: tf.Tensor, label: tf.Tensor) -> tf.Tensor:\n        return self.scale_fn(image), label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@tf.function\ndef preprocess_input(x):\n    return x / 255.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = (\n    tf.data.Dataset.from_tensor_slices(([str(x) for x in DATA_DIR.glob('**/*')], os.listdir(DATA_DIR)))\n    .map(map_func=ImageParser())\n    .map(map_func=ImageResizer(IMG_DIMS, \"stretch\"))\n    .repeat()\n    .shuffle(SHUFFLE_SIZE)\n    .batch(BATCH_SIZE)\n    .prefetch(tf.data.experimental.AUTOTUNE)\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for x, y in train_data.take(1):\n    print(y[0])\n    print(x[0].numpy().min(), x[0].numpy().max())\n    plt.imshow(x.numpy()[0])\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"codings_size = 32","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generator = keras.models.Sequential(\n    [\n        keras.layers.Dense(8 * 8 * 128, input_shape=[codings_size]),\n        keras.layers.Reshape([8, 8, 128]),\n        keras.layers.BatchNormalization(),\n        keras.layers.Conv2DTranspose(\n            64,\n            kernel_size=5,\n            strides=2,\n            padding=\"SAME\",\n            activation=keras.activations.selu,\n            kernel_initializer=keras.initializers.lecun_uniform(),\n        ),\n        keras.layers.BatchNormalization(),\n        keras.layers.Conv2DTranspose(\n            32,\n            kernel_size=5,\n            strides=2,\n            padding=\"SAME\",\n            activation=keras.activations.selu,\n            kernel_initializer=keras.initializers.lecun_uniform(),\n        ),\n        keras.layers.BatchNormalization(),\n        keras.layers.Conv2DTranspose(\n            IMG_DIMS[2], kernel_size=5, strides=2, padding=\"SAME\", activation=keras.activations.sigmoid\n        ),\n    ]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generator.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discriminator = keras.models.Sequential(\n    [\n#         keras.layers.Conv2D(\n#             64,\n#             kernel_size=5,\n#             strides=2,\n#             padding=\"SAME\",\n#             activation=keras.layers.LeakyReLU(0.2),\n#             kernel_initializer=keras.initializers.he_uniform(),\n#             input_shape=IMG_DIMS,\n#         ),\n#         keras.layers.Dropout(0.5),\n        keras.layers.Conv2D(\n            128,\n            kernel_size=5,\n            strides=2,\n            padding=\"SAME\",\n            activation=keras.layers.LeakyReLU(0.2),\n            kernel_initializer=keras.initializers.he_uniform(),\n            input_shape=IMG_DIMS,\n        ),\n        keras.layers.Dropout(0.4),\n        keras.layers.Conv2D(\n            256,\n            kernel_size=5,\n            strides=2,\n            padding=\"SAME\",\n            activation=keras.layers.LeakyReLU(0.2),\n            kernel_initializer=keras.initializers.he_uniform(),\n        ),\n        keras.layers.Dropout(0.4),\n        keras.layers.Conv2D(\n            512,\n            kernel_size=5,\n            strides=2,\n            padding=\"SAME\",\n            activation=keras.layers.LeakyReLU(0.2),\n            kernel_initializer=keras.initializers.he_uniform(),\n        ),\n        keras.layers.Dropout(0.4),\n#         keras.layers.Conv2D(\n#             1028,\n#             kernel_size=5,\n#             strides=2,\n#             padding=\"SAME\",\n#             activation=keras.layers.LeakyReLU(0.2),\n#             kernel_initializer=keras.initializers.he_uniform(),\n#         ),\n#         keras.layers.Dropout(0.5),\n        keras.layers.Flatten(),\n        keras.layers.Dense(1, activation=keras.activations.sigmoid),\n    ]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# discriminator1 = discriminator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# discriminator = keras.models.Sequential([\n#     keras.applications.VGG16(include_top=False, weights=None),\n#     keras.layers.GlobalMaxPool2D(),\n#     keras.layers.Dropout(0.5),\n#     keras.layers.Dense(1, activation=keras.activations.sigmoid),\n# ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discriminator.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_multiple_images(images, n_cols=None):\n    n_cols = n_cols or len(images)\n    n_rows = (len(images) - 1) // n_cols + 1\n    if images.shape[-1] == 1:\n        images = np.squeeze(images, axis=-1)\n    plt.figure(figsize=(n_cols * 2, n_rows * 2))\n    for index, image in enumerate(images):\n        plt.subplot(n_rows, n_cols, index + 1)\n        plt.imshow(image, cmap=\"binary\")\n        plt.axis(\"off\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_gan(gan, dataset, n_images, batch_size, codings_size, n_epochs=1):\n    generator, discriminator = gan.layers\n    for epoch in range(n_epochs):\n        print(\"Epoch {}/{}\".format(epoch + 1, n_epochs))\n        for train_batch, _ in dataset.take(n_images // batch_size):\n            # phase 1 - training the discriminator\n            noise = tf.random.normal(shape=[batch_size, codings_size])\n            generated_images = generator(noise)\n            fake_and_real_data = tf.concat([generated_images, train_batch], axis=0)\n            fake_and_real_labels = tf.constant([[0.0]] * batch_size + [[1.0]] * batch_size)\n            discriminator.trainable = True\n            discriminator.train_on_batch(fake_and_real_data, fake_and_real_labels)\n            # phase 2 - training the generator\n            noise = tf.random.normal(shape=[batch_size, codings_size])\n            noise_labels = tf.constant([[1.0]] * batch_size)\n            discriminator.trainable = False\n            gan.train_on_batch(noise, noise_labels)\n        plot_multiple_images(generated_images, 8)\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gan = keras.models.Sequential([generator, discriminator])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# discriminator.compile(\n#     loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adam(3e-4)\n# )\n# discriminator.trainable = False\n# gan.compile(\n#     loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adam(1e-4)\n# )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discriminator.compile(\n    loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.RMSprop(3e-4)\n)\ndiscriminator.trainable = False\ngan.compile(\n    loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.RMSprop(3e-3)\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gan(gan, train_data, N_IMAGES, BATCH_SIZE, codings_size, 20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gan(gan, train_data, N_IMAGES, BATCH_SIZE, codings_size, 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gan(gan, train_data, N_IMAGES, BATCH_SIZE, codings_size,100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gan(gan, train_data, N_IMAGES, BATCH_SIZE, codings_size, 200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gan(gan, train_data, N_IMAGES, BATCH_SIZE, codings_size, 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gan(gan, train_data, N_IMAGES, BATCH_SIZE, codings_size, 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gan(gan, train_data, N_IMAGES, BATCH_SIZE, codings_size, 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gan(gan, train_data, N_IMAGES, BATCH_SIZE, codings_size, 20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gan(gan, train_data, N_IMAGES, BATCH_SIZE, codings_size, 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 32\nSHUFFLE_SIZE = 1024\nIMG_DIMS = (64, 64, 3)\nN_IMAGES = len(os.listdir(DATA_DIR))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"codings_size = 128","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generator = keras.models.Sequential(\n    [\n        keras.layers.Dense(8 * 8 * 128, input_shape=[codings_size]),\n        keras.layers.Reshape([8, 8, 128]),\n        keras.layers.BatchNormalization(),\n        keras.layers.Conv2DTranspose(\n            128,\n            kernel_size=5,\n            strides=2,\n            padding=\"SAME\",\n            activation=keras.activations.selu,\n            kernel_initializer=keras.initializers.lecun_uniform(),\n        ),\n        keras.layers.BatchNormalization(),\n        keras.layers.Conv2DTranspose(\n            64,\n            kernel_size=5,\n            strides=2,\n            padding=\"SAME\",\n            activation=keras.activations.selu,\n            kernel_initializer=keras.initializers.lecun_uniform(),\n        ),\n        keras.layers.BatchNormalization(),\n        keras.layers.Conv2DTranspose(\n            IMG_DIMS[2], kernel_size=5, strides=2, padding=\"SAME\", activation=keras.activations.sigmoid\n        ),\n    ]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generator.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discriminator = keras.models.Sequential(\n    [\n        keras.layers.Conv2D(\n            128,\n            kernel_size=5,\n            strides=2,\n            padding=\"SAME\",\n            activation=keras.layers.LeakyReLU(0.2),\n            kernel_initializer=keras.initializers.he_uniform(),\n            input_shape=IMG_DIMS,\n        ),\n        keras.layers.Dropout(0.5),\n        keras.layers.Conv2D(\n            256,\n            kernel_size=5,\n            strides=2,\n            padding=\"SAME\",\n            activation=keras.layers.LeakyReLU(0.2),\n            kernel_initializer=keras.initializers.he_uniform(),\n        ),\n        keras.layers.Dropout(0.5),\n        keras.layers.Conv2D(\n            512,\n            kernel_size=5,\n            strides=2,\n            padding=\"SAME\",\n            activation=keras.layers.LeakyReLU(0.2),\n            kernel_initializer=keras.initializers.he_uniform(),\n        ),\n        keras.layers.Dropout(0.5),\n#         keras.layers.Conv2D(\n#             1024,\n#             kernel_size=5,\n#             strides=2,\n#             padding=\"SAME\",\n#             activation=keras.layers.LeakyReLU(0.2),\n#             kernel_initializer=keras.initializers.he_uniform(),\n#         ),\n#         keras.layers.Dropout(0.4),\n        keras.layers.Flatten(),\n        keras.layers.Dense(1, activation=keras.activations.sigmoid),\n    ]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# discriminator1 = discriminator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# discriminator = keras.models.Sequential([\n#     keras.applications.VGG16(include_top=False, weights=None),\n#     keras.layers.GlobalMaxPool2D(),\n#     keras.layers.Dropout(0.4),\n#     keras.layers.Dense(1, activation=keras.activations.sigmoid),\n# ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discriminator.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_gan(gan, dataset, n_images, batch_size, codings_size, n_epochs=1):\n    generator, discriminator = gan.layers\n    for epoch in range(n_epochs):\n        print(\"Epoch {}/{}\".format(epoch + 1, n_epochs))\n        for train_batch, _ in dataset.take(n_images // batch_size):\n            # phase 1 - training the discriminator\n            noise = tf.random.normal(shape=[batch_size, codings_size])\n            generated_images = generator(noise)\n            fake_and_real_data = tf.concat([generated_images, train_batch], axis=0)\n            fake_and_real_labels = tf.constant([[0.0]] * batch_size + [[1.0]] * batch_size)\n            discriminator.trainable = True\n            discriminator.train_on_batch(fake_and_real_data, fake_and_real_labels)\n            # phase 2 - training the generator\n            noise = tf.random.normal(shape=[batch_size, codings_size])\n            noise_labels = tf.constant([[1.0]] * batch_size)\n            discriminator.trainable = False\n            gan.train_on_batch(noise, noise_labels)\n        plot_multiple_images(generated_images, 10)\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gan = keras.models.Sequential([generator, discriminator])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discriminator.compile(\n    loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adam(2e-3)\n)\ndiscriminator.trainable = False\ngan.compile(\n    loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adam(1e-4)\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gan(gan, train_data, N_IMAGES, BATCH_SIZE, codings_size, 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}