{"cells":[{"metadata":{},"cell_type":"markdown","source":"# objective\n    The Project contains data of stack-overflow-developers.Data like developers experience,employment status,job     satisfaction,career satisfaction & Salary etc.\n    project's objective is to predict whether a person will opt to contribute for an open source projet or not.\n  "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" # Importing libraries\n     Numpy and panda libraries has a lot of predefined functions that will be essential \n     for us in project\n****"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. # Importing Dataframe\nHere we are importing datasets in to our notebook from Kaggle data sets repository  "},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset=pd.read_csv('/kaggle/input/stack-overflow-2018-developer-survey/survey_results_public.csv')\ndataset2=pd.read_csv('/kaggle/input/stack-overflow-2018-developer-survey/survey_results_schema.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Assigning first 17 columns of dataframe to a new data frame mydata"},{"metadata":{"trusted":true},"cell_type":"code","source":"mydata=dataset.iloc[:,:17]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mydata.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  As we can see our data has some null values\n# Below steps are to drop rows containing null values"},{"metadata":{"trusted":true},"cell_type":"code","source":"mydata = mydata.dropna(axis=0, subset=['JobSatisfaction'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mydata = mydata.dropna(axis=0, subset=['Country'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mydata = mydata.dropna(axis=0, subset=['Student'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mydata = mydata.dropna(axis=0, subset=['Employment'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mydata = mydata.dropna(axis=0, subset=['FormalEducation'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mydata = mydata.dropna(axis=0, subset=['UndergradMajor'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mydata = mydata.dropna(axis=0, subset=['CompanySize'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mydata = mydata.dropna(axis=0, subset=['DevType'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mydata = mydata.dropna(axis=0, subset=['YearsCoding'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mydata = mydata.dropna(axis=0, subset=['YearsCodingProf'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mydata = mydata.dropna(axis=0, subset=['CareerSatisfaction'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mydata = mydata.dropna(axis=0, subset=['HopeFiveYears'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mydata = mydata.dropna(axis=0, subset=['JobSearchStatus'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mydata = mydata.dropna(axis=0, subset=['LastNewJob'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mydata = mydata.dropna(axis=0, subset=['OpenSource'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"  # Let us chechk if there are more null values"},{"metadata":{"trusted":true},"cell_type":"code","source":"mydata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mydata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Now, we can see that thre are no more null values in dataframe"},{"metadata":{},"cell_type":"markdown","source":"# creating X with all independent variables and y with all dependent variables\n\nAs I mentioned before, Our objective is to predict 'Yes' or 'No' for open source.\nSo, y variable is Open_Source."},{"metadata":{"trusted":true},"cell_type":"code","source":"y=pd.DataFrame(mydata.iloc[:,2])\n\ndf=pd.DataFrame(mydata)\nX=df.drop(['OpenSource'],axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# dummification\n Machine cannot understand Strings(Categorical Variables).So, a number should be assigned to every Strings(Catgorical Variable),Whenever this number occurs in that column, machine understands that respective String categorical variable has occured.This process of converting  Strings(categorical variables) in to numerical factors is called dummification.\n \n Below given steps are of dummification of X and y dataframes. "},{"metadata":{"trusted":true},"cell_type":"code","source":"a=pd.get_dummies(X,drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"b=pd.get_dummies(y, drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# splitting data in to train and test sets\nWe split the data set in to test and train data sets.We perform our model on train data set and test our model on test data set."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,y_train,y_test=train_test_split(a,b,test_size=0.2,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* # Applying decision tree classifier on train dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nregression=DecisionTreeClassifier()\nregression.fit(X_train,y_train)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# performing prediction for test dataset\n  In next steps we perform prediction on Open_source for test data set and compare it with the actual Data."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=regression.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Calculating accuracy of our prediction\nIn next steps we calcuate accuracy,Here accuracy is (no of correct predictions)/total no of observations.More the accuracy,better our model is."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm=confusion_matrix(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total=sum(sum(cm))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy=(cm[0,0]+cm[1,1])/total","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We got an accuracy of 56.3 percent i.e of all the predicted outputs, 56.3 are correct\n\nSo, let us try random forest model and check the accuracy"},{"metadata":{},"cell_type":"markdown","source":"# Performing Randomforestclassificaton on train dataset\nBelow, we perform the same steps above but we are doing it for Random forest model."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrandomclassifier=RandomForestClassifier(n_estimators=10,criterion='entropy',random_state=0)\nrandomclassifier.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred2=randomclassifier.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Calculating accuracy of prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"cm2=confusion_matrix(y_test,y_pred2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total2=sum(sum(cm2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy2=(cm2[0,0]+cm2[1,1])/total2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random forest model is giving us more accuracy(58.6%) than decision tree model(56.2%), but still this is not good enough.\n\nWe can  make this model more accurate by removing the indpendent variables which does not gave much impact on depndent variable.\n"},{"metadata":{},"cell_type":"markdown","source":"In next steps, We are trying to remove those columns which doesnot have much impact on our \ndependent variable(Open_Source). This helps in increasing accuracy of our prediction\n\nWe are trying to check whether 'Country' and 'DevType' columns are significant or not because the no of distinct observtions in these two columns are far more when compared to other columns and if they are not affecting independent variables then we could get rid of thse two columns.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"m=[]\nz=0\nfor i in range(187,5977):\n    k=X_train.columns[i]\n    for j in range(0,42440):\n     if(X_train[k].values[j]==1):\n        \n       if(y_train.iloc[j][0]==1):\n            m.append(True)\n       else:\n            m.append(False)\n            \n            \n    if(all(m)==any(m)):\n        print(i)\n        z=z+1\n            \n    \n        \n    \n          \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m=[]\nz=0\nfor i in range(2,161):\n    k=X_train.columns[i]\n    for j in range(0,42440):\n     if(X_train[k].values[j]==1):\n        \n       if(y_train.iloc[j][0]==1):\n            m.append(True)\n       else:\n            m.append(False)\n            \n            \n    if(all(m)==any(m)):\n        print(i)\n        z=z+1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After checking whether obsevations in \"DevType' and 'Country' are showing any impact on our dependent variable.\nwe found out that both of these colums are not showing any impact on our dependent variable"},{"metadata":{},"cell_type":"markdown","source":"In next steps, we remove all the dummy columns of dependent variables 'DevType' \nand 'Country' from train data set and test dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.drop(X_train.iloc[:,2:160],inplace=True,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.drop(X_train.iloc[:,187:5976],inplace=True,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.drop(X_test.iloc[:,2:160],inplace=True,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.drop(X_test.iloc[:,187:5976],inplace=True,axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In next steps we reiteerate the steps that we performed while calculating accuracy for decision tree model and Random foreest model.Only difference is we are prforming it on updated datasets, i.e dataset after removing columns 'DevType' and 'Country'."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nclassification=DecisionTreeClassifier()\nclassification.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y3_pred=classification.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm3=confusion_matrix(y_test,y3_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy3=(cm3[0,0]+cm3[1,1])/sum(sum(cm3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy3","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Accuracy we got for updated dataset is 52.9 which is less when compared to  56.2 i.e accuracy we got with first dataset\n\nNow, let us check Random forest on updated dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrandomclassifier2=RandomForestClassifier(n_estimators=10,criterion='entropy',random_state=0)\nrandomclassifier2.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred4=randomclassifier2.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm4=confusion_matrix(y_test,y_pred4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy4=(cm4[0,0]+cm4[1,1])/sum(sum(cm4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy4","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Accuracy of Random forest model on updated data set is 53.9 which is less than 58.6,i.e accuracy of Random forest model on first data set.\n\nAs Accuracy of Random forest model on first data set is more.We Should predict our independent variable by performing Random forest model on first data set."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}