{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we need to identify our libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reading the data by pandas","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now we will know some information about our data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total = data1.isnull().sum().sort_values(ascending=False)\ntotal","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['quality'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style=\"darkgrid\")\n\nax = sns.countplot(x=\"quality\", hue=data['quality'], data=data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(data1['quality'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#correlation matrix\ncorrmat = data1.corr()\nf, ax = plt.subplots(figsize=(12, 9))\n#sns.heatmap(corrmat, vmax=.8, square=True);\nsns.heatmap(corrmat,fmt=\".2f\",cmap='coolwarm', annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we will show relations among all the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#scatterplot\nsns.set()\ncols = data1.columns\nsns.pairplot(data[cols], size = 2.5)\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"split our data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=data1.iloc[:,:-1]\ny=data1.quality\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Standard Scaler for Data\n\nscaler = StandardScaler(copy=True, with_mean=True, with_std=True)\nX = scaler.fit_transform(X)\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Splitting data\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=44, shuffle =True)\n\n ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we will use neural net work to classify"},{"metadata":{"trusted":true},"cell_type":"code","source":" \nfrom sklearn.neural_network import MLPClassifier\n \n\nMLPClassifierModel = MLPClassifier(activation='relu',  \n                                   solver='adam',  \n                                   learning_rate='constant',  \n                                   early_stopping= False,max_iter=500,\n                                   alpha=0.0001 ,hidden_layer_sizes=(100, 3),random_state=33)\nMLPClassifierModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('MLPClassifierModel Train Score is : ' , MLPClassifierModel.score(X_train, y_train))\nprint('MLPClassifierModel Test Score is : ' , MLPClassifierModel.score(X_test, y_test))\nprint('MLPClassifierModel loss is : ' , MLPClassifierModel.loss_)\nprint('MLPClassifierModel No. of iterations is : ' , MLPClassifierModel.n_iter_)\nprint('MLPClassifierModel No. of layers is : ' , MLPClassifierModel.n_layers_)\nprint('MLPClassifierModel last activation is : ' , MLPClassifierModel.out_activation_)\n#print('----------------------------------------------------')\n\n#Calculating Prediction\ny_pred = MLPClassifierModel.predict(X_test)\ny_pred_prob = MLPClassifierModel.predict_proba(X_test)\n ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"use random forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import Libraries\nfrom sklearn.ensemble import RandomForestClassifier\n \n'''\n\nRandomForestClassifierModel = RandomForestClassifier(criterion = 'entropy',n_estimators=200,max_depth=50,random_state=33) #criterion can be also : entropy \nRandomForestClassifierModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('RandomForestClassifierModel Train Score is : ' , RandomForestClassifierModel.score(X_train, y_train))\nprint('RandomForestClassifierModel Test Score is : ' , RandomForestClassifierModel.score(X_test, y_test))\nprint('RandomForestClassifierModel features importances are : ' , RandomForestClassifierModel.feature_importances_)\n#print('----------------------------------------------------')\n\n#Calculating Prediction\ny_pred = RandomForestClassifierModel.predict(X_test)\ny_pred_prob = RandomForestClassifierModel.predict_proba(X_test)\n#print('Predicted Value for RandomForestClassifierModel is : ' , y_pred[:10])\n#print('Prediction Probabilities Value for RandomForestClassifierModel is : ' , y_pred_prob[:10])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"use support vector classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import Libraries\nfrom sklearn.svm import SVC\n#----------------------------------------------------\n\n#----------------------------------------------------\n#Applying SVC Model \n\n'''\nsklearn.svm.SVC(C=1.0, kernel=’rbf’, degree=3, gamma=’auto_deprecated’, coef0=0.0, shrinking=True,\n                probability=False, tol=0.001, cache_size=200, class_weight=None,verbose=False,\n                max_iter=-1, decision_function_shape='ovr’, random_state=None)\n'''\n\nSVCModel = SVC(kernel= 'linear',# it can be also linear,poly,sigmoid,precomputed\n               max_iter=10000,C=1.0,gamma='auto',tol=0.0001)\nSVCModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('SVCModel Train Score is : ' , SVCModel.score(X_train, y_train))\nprint('SVCModel Test Score is : ' , SVCModel.score(X_test, y_test))\n#print('----------------------------------------------------')\n\n#Calculating Prediction\ny_pred = SVCModel.predict(X_test)\n#print('Predicted Value for SVCModel is : ' , y_pred[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import Libraries\nfrom sklearn.metrics import f1_score\n#----------------------------------------------------\n\n \nF1Score = f1_score(y_test, y_pred, average='micro') #it can be : binary,macro,weighted,samples\nprint('F1 Score is : ', F1Score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import Libraries\nfrom sklearn.metrics import confusion_matrix\n \nCM = confusion_matrix(y_test, y_pred)\nprint('Confusion Matrix is : \\n', CM)\n\n# drawing confusion matrix\nsns.heatmap(CM, center = True)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}