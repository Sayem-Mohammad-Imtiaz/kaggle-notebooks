{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"libraries we will use:"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt # visualizing data\nimport seaborn as sns \nfrom collections import Counter\n%matplotlib inline\n \nfrom plotly.offline import init_notebook_mode, iplot\n \nimport os\nprint(os.listdir(\"../input\"))\n \nimport plotly.graph_objs as go\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"reading the data\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv('../input/health-insurance-cross-sell-prediction/train.csv')\ntest=pd.read_csv('../input/health-insurance-cross-sell-prediction/test.csv')\n              ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"showing the format of the data will helpe us when dealing with it"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(10)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"here the some information about our data ........shape, info, columns name"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"here we will show the percentage of males and females who interactive more with Response "},{"metadata":{"trusted":true},"cell_type":"code","source":"fig1, ax1 = plt.subplots(figsize=(12,7))\nplt.pie(df.groupby('Gender')['Response'].sum(),labels=('Female','Male'), explode = [0.1,0.1],autopct ='%1.1f%%',shadow = True,startangle = 180)\nplt.legend()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig1, ax1 = plt.subplots(figsize=(12,7))\nax1=sns.barplot(df['Gender'],'Response',data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now we will display the number of females and males which have Driving_License"},{"metadata":{"trusted":true},"cell_type":"code","source":"ax=sns.countplot(df['Driving_License'],hue='Gender',data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now we will show that the number of males and females which have Driving_License and responsed in the the same time"},{"metadata":{"trusted":true},"cell_type":"code","source":"ax=sns.barplot(df['Driving_License'],'Response',hue='Gender',data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"here we will display how many regions we interact with "},{"metadata":{"trusted":true},"cell_type":"code","source":" df['Region_Code'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig1, ax1 = plt.subplots(figsize=(12,7))\ndf.groupby('Region_Code')['Response'].count().nlargest(10).sort_values().plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we find that the regions which have number (25 and 8) have more peoples which response more ,so the company will intersted in "},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Vehicle_Age'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(df['Vehicle_Age'],y='Response',data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(df['Vehicle_Damage'],'Response',hue='Gender',data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Policy_Sales_Channel'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig1, ax1 = plt.subplots(figsize=(12,7))\ndf.groupby('Policy_Sales_Channel')['Response'].count().nlargest(10).sort_values().plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"as we notice last diagram ,the company should concentrate on  'Policy_Sales_Channel' =125"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df['Previously_Insured'],hue=\"Gender\",data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig1, ax1 = plt.subplots(figsize=(12,7))\nax1=sns.barplot(df['Previously_Insured'],'Response',data=df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we notice that all only people who have no  previously_indured is responsed to new response"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#correlation matrix\ncorrmat = df.corr()\nf, ax = plt.subplots(figsize=(12, 12))\n#sns.heatmap(corrmat, vmax=.8, square=True);\nsns.heatmap(corrmat,fmt=\".2f\",cmap='coolwarm', annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we find two catogrical  features so we convert them to numerical feauters to deel with "},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Gender']=df['Gender'].replace({'Male':0,'Female':1})\n\ndf['Vehicle_Age']=df['Vehicle_Age'].replace({'> 2 Years':0,'1-2 Year':1,'< 1 Year':3})\ndf['Vehicle_Damage']=df['Vehicle_Damage'].replace({'Yes':5,'No':6})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"before we build our classification model we will drop some features which don't help us in our algorithm such as (vintage, id) which have zero correlation with response"},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df.drop(['id','Vintage'],axis=1)\ntest=test.drop(['id','Vintage'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"then we will define the X and y to build our classification model"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=df.drop(['Response'],axis=1)\ny=df['Response']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Standard Scaler for Data\n\nscaler = StandardScaler(copy=True, with_mean=True, with_std=True)\nX = scaler.fit_transform(X)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we will split our train data into trian and test to tunning hyperparamaters then launch our model to our test data to get best accuracy "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import Libraries\nfrom sklearn.model_selection import train_test_split\n#----------------------------------------------------\n\n#----------------------------------------------------\n#Splitting data\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=44, shuffle =True)\n\n#Splitted Data\nprint('X_train shape is ' , X_train.shape)\nprint('X_test shape is ' , X_test.shape)\nprint('y_train shape is ' , y_train.shape)\nprint('y_test shape is ' , y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"let's try SVM MODEL"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import Libraries\nfrom sklearn.svm import SVC\n#----------------------------------------------------\n\n#----------------------------------------------------\n#Applying SVC Model \n\n'''\nsklearn.svm.SVC(C=1.0, kernel=’rbf’, degree=3, gamma=’auto_deprecated’, coef0=0.0, shrinking=True,\n                probability=False, tol=0.001, cache_size=200, class_weight=None,verbose=False,\n                max_iter=-1, decision_function_shape='ovr’, random_state=None)\n'''\n\nSVCModel = SVC(kernel= 'linear',# it can be also linear,poly,sigmoid,precomputed\n               max_iter=2000,C=1.0,gamma='auto')\nSVCModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('SVCModel Train Score is : ' , SVCModel.score(X_train, y_train))\nprint('SVCModel Test Score is : ' , SVCModel.score(X_test, y_test))\n#print('----------------------------------------------------')\n\n#Calculating Prediction\ny_pred = SVCModel.predict(X_test)\n#print('Predicted Value for SVCModel is : ' , y_pred[:10])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"let's RandomForestClassifier "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import Libraries\nfrom sklearn.ensemble import RandomForestClassifier\n#----------------------------------------------------\n\n#----------------------------------------------------\n#Applying RandomForestClassifier Model \n\n'''\nensemble.RandomForestClassifier(n_estimators='warn’, criterion=’gini’, max_depth=None,\n                                min_samples_split=2, min_samples_leaf=1,min_weight_fraction_leaf=0.0,\n                                max_features='auto’,max_leaf_nodes=None,min_impurity_decrease=0.0,\n                                min_impurity_split=None, bootstrap=True,oob_score=False, n_jobs=None,\n                                random_state=None, verbose=0,warm_start=False, class_weight=None)\n'''\n\nRandomForestClassifierModel = RandomForestClassifier(criterion = 'entropy',n_estimators=500,max_depth=50,random_state=33) #criterion can be also : entropy \nRandomForestClassifierModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('RandomForestClassifierModel Train Score is : ' , RandomForestClassifierModel.score(X_train, y_train))\nprint('RandomForestClassifierModel Test Score is : ' , RandomForestClassifierModel.score(X_test, y_test))\n#print('RandomForestClassifierModel features importances are : ' , RandomForestClassifierModel.feature_importances_)\n#print('----------------------------------------------------')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calculating Prediction\ny_pred = RandomForestClassifierModel.predict(X_test)\ny_pred_prob = RandomForestClassifierModel.predict_proba(X_test)\n#print('Predicted Value for RandomForestClassifierModel is : ' , y_pred[:10])\n#print('Prediction Probabilities Value for RandomForestClassifierModel is : ' , y_pred_prob[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import Libraries\nfrom sklearn.metrics import roc_auc_score\n#----------------------------------------------------\n\n#----------------------------------------------------\n#Calculating ROC AUC Score:  \n#roc_auc_score(y_true, y_score, average=’macro’, sample_weight=None,max_fpr=None)\n\nROCAUCScore = roc_auc_score(y_test,y_pred, average='micro') #it can be : macro,weighted,samples\nprint('ROCAUC Score : ', ROCAUCScore)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Gender']=test['Gender'].replace({'Male':0,'Female':1})\n\ntest['Vehicle_Age']=test['Vehicle_Age'].replace({'> 2 Years':0,'1-2 Year':1,'< 1 Year':3})\ntest['Vehicle_Damage']=test['Vehicle_Damage'].replace({'Yes':5,'No':6})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calculating Prediction\ny_pred = RandomForestClassifierModel.predict(test)\ny_pred_prob = RandomForestClassifierModel.predict_proba(test)\nprint('Predicted Value for RandomForestClassifierModel is : ' , y_pred[:10])\nprint('Prediction Probabilities Value for RandomForestClassifierModel is : ' , y_pred_prob[:10])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}