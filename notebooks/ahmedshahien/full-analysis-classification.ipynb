{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sb\nfrom collections import Counter\nimport matplotlib as mpl\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import SGDClassifier \n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#load our data\ndf=pd.read_csv('../input/students-performance-in-exams/StudentsPerformance.csv')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#let's take alook about some information as type and non values\ndf.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we see we have no nulls in our data","metadata":{}},{"cell_type":"markdown","source":"# Adding new column which combine the final score of reading ,writing, and math ","metadata":{}},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#adding reading,writing,math to total_score\ndf['total_score']=df['math score']+df['reading score']+df['writing score']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#shape of df\ndf.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Number of males and femals","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=[15,5])\nplt.subplot(1,2,1)\nplt.pie(df['gender'].value_counts(),labels=df['gender'].value_counts().index,explode=[.1,.1],autopct='%1.1f%%',shadow=True);\nplt.title('percentage of males and females')\nplt.subplot(1,2,2)\n#base_color = sb.color_palette()[5]\nsb.countplot(data=df,x='gender' )\nplt.title('Number of males and females')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Distribution of our numerical features with each other","metadata":{}},{"cell_type":"code","source":"#Distribution of our numerical features with each other\nsb.pairplot(df, hue=\"gender\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Numbers of each gender in each race","metadata":{}},{"cell_type":"code","source":"#Numbers of each gender in each race\nsb.set(style='darkgrid')\nplt.figure(figsize=[10,5])\nax=sb.countplot(data=df,x='gender',hue='race/ethnicity')\nplt.title('Numbers of each gender in each race');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Distribution of total score for each gender in each group","metadata":{}},{"cell_type":"code","source":"#Distribution of total score for each gender in each group\nplt.figure(figsize=[10,10]);\nsb.set_theme(style=\"darkgrid\")\nsb.displot(df, x=\"total_score\", col=\"race/ethnicity\", row=\"gender\",\n             binwidth=3, height=3, facet_kws=dict(margin_titles=True),);\n ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Number of each gender in math score","metadata":{}},{"cell_type":"code","source":"f, ax = plt.subplots(figsize=(10, 5))\nsb.despine(f)\n\nsb.histplot(\n    df,\n    x=\"math score\", hue=\"gender\",\n    multiple=\"stack\",\n    palette=\"light:m_r\",\n    edgecolor=\".3\",\n    linewidth=.5,\n    log_scale=False,)\nplt.title('Number of each gender in math score')\nax.xaxis.set_major_formatter(mpl.ticker.ScalarFormatter());\nax.set_xticks([0,10,20,30,40,50,60,70,80,90,100,110]);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sb.set(style='darkgrid')\nplt.figure(figsize=[10,5])\nax=sb.countplot(data=df,x='parental level of education',hue='gender')\nplt.xticks(rotation=45)\nplt.title('Numbers of each gender in each level education');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Number in each race which has test preparation course","metadata":{}},{"cell_type":"code","source":"#Number in each race which has test preparation course\nplt.figure(figsize=[10,7])\ncounts = df.groupby(['race/ethnicity', 'test preparation course']).size()\ncounts = counts.reset_index(name='count')\n# Use DataFrame.pivot() to rearrange the data, to have race class on rows\ncounts =counts.pivot(index = 'race/ethnicity', columns = 'test preparation course' ,values = 'count')\n#drow hwat map \nsb.heatmap(counts,annot = True, fmt = 'd');\n#get the title\nplt.title('Number in each race which has test preparation course');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Math score statistics for each gender","metadata":{}},{"cell_type":"code","source":"#math score statistics for each gender\nbase_color = sb.color_palette()[4]\nsb.violinplot(data=df, x='gender', y='math score', color=base_color, innner=None)\nplt.xticks(rotation=15);\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"WE see that the main of males is higher than femals","metadata":{}},{"cell_type":"markdown","source":"# Writing score statistics for each gender","metadata":{}},{"cell_type":"code","source":"base_color = sb.color_palette()[4]\nsb.boxplot(data=df, x='gender', y='writing score', color=base_color )\nplt.xticks(rotation=15);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Draw a categorical scatterplot to show each observation\nplt.figure(figsize=[10,6])\nax = sb.swarmplot(data=df, x=\"reading score\", y=\"gender\",hue='lunch');\nax.set(ylabel=\"\");","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Total score with types of races","metadata":{}},{"cell_type":"code","source":"#plotting boxplot for Total score with types of races\nsb.set_theme(style=\"ticks\")\n\n# Initialize the figure with a logarithmic x axis\nf, ax = plt.subplots(figsize=(7, 6))\nax.set_xscale(\"log\")\n\nsb.boxplot(x=\"total_score\", y=\"race/ethnicity\", data=df,\n            whis=[0, 100], width=.6, palette=\"vlag\")\n\n# Add in points to show each observation\nsb.stripplot(x=\"total_score\", y=\"race/ethnicity\", data=df,\n              size=2, color=\".3\", linewidth=0)\n\n# Tweak the visual presentation\nplt.xticks( )\nax.xaxis.grid(False)\nax.set(ylabel=\"\")\nsb.despine(trim=False, left=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Anomaly Detection","metadata":{}},{"cell_type":"code","source":"\ndef detect_outliers(df,features):\n    outlier_indices = []\n    \n    for c in features:\n        # 1st quartile\n        Q1 = np.percentile(df[c],25)\n        # 3rd quartile\n        Q3 = np.percentile(df[c],75)\n        # IQR\n        IQR = Q3 - Q1\n        # Outlier step\n        outlier_step = IQR * 1.5\n        # detect outlier and their indeces\n        outlier_list_col = df[(df[c] < Q1 - outlier_step) | (df[c] > Q3 + outlier_step)].index\n        # store indeces\n        outlier_indices.extend(outlier_list_col)\n    \n    outlier_indices =Counter(outlier_indices)\n    multiple_outliers = list(i for i, v in outlier_indices.items() if v > 2)\n    \n    return multiple_outliers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.loc[detect_outliers(df,['math score', 'reading score', 'writing score'])]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# drop outliers\ndf =df.drop(detect_outliers(df,['math score', 'reading score', 'writing score']),axis = 0).reset_index(drop = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Relation between our features","metadata":{}},{"cell_type":"markdown","source":"first we will replace each catoegory with unique number to make it easy to deel with our feature","metadata":{}},{"cell_type":"code","source":"#encoding gender feature\ndf['gender']=df['gender'].replace({'female':0,'male':1})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#we want to know the uniques in race\ndf['race/ethnicity'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# encoding race\ndf['race/ethnicity']=df['race/ethnicity'].replace({'group B':1, 'group C':2, 'group A':3, 'group D':4, 'group E':5})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# uniques of parental level of education\ndf['parental level of education'].unique()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# encoding parental level of education\ndf['parental level of education']=df['parental level of education'].replace({\"bachelor's degree\":1, 'some college':2, \"master's degree\":3,\n       \"associate's degree\":4, 'high school':5, 'some high school':6})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# uniques of lunch\ndf['lunch'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# encoding lunch\ndf['lunch']=df['lunch'].replace({'standard':1, 'free/reduced':0})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# uniques of test preparation course\ndf['test preparation course'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# encoding test preparation course \ndf['test preparation course']=df['test preparation course'].replace({'none':0, 'completed':1})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Our new encoded data NOW","metadata":{}},{"cell_type":"markdown","source":"let's take alook after we encode our data","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# drawing heatmap\nplt.figure(figsize=[10,10])\nsb.heatmap(df.corr(),annot=True, cmap='Dark2_r', linewidths = .2)\nplt.title('Relation between variables');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we see above the three scores in writing ,reading and math have strong relation between each other","metadata":{}},{"cell_type":"markdown","source":"# Now we will make prediction of gender based on other features","metadata":{}},{"cell_type":"markdown","source":"Because od the strong relations between these three features we will drop two of them","metadata":{}},{"cell_type":"code","source":"df.drop(['writing score','reading score'],inplace=True,axis=1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=df.drop(['gender'],axis=1)\ny=df['gender']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Rescale total score and math score","metadata":{}},{"cell_type":"code","source":"X['total_score']=X['total_score']/X['total_score'].max()\nX['math score']=X['math score']/X['math score'].max()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Splitting data\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=44, shuffle =True)\n\n#Splitted Data\nprint('X_train shape is ' , X_train.shape)\nprint('X_test shape is ' , X_test.shape)\nprint('y_train shape is ' , y_train.shape)\nprint('y_test shape is ' , y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Applying VotingClassifier Model \n\n#loading models for Voting Classifier\nLRModel_ = LogisticRegression(solver='lbfgs', multi_class='multinomial',random_state=33)\nDTModel_ = DecisionTreeClassifier(criterion = 'entropy',max_depth=20,random_state = 33)\nKNNModel_ = KNeighborsClassifier(n_neighbors= 20 , weights ='uniform', algorithm='auto')\nSGDModel_ = SGDClassifier(loss='log', penalty='l2', max_iter=200, tol=1e-5)\n\n#loading Voting Classifier\nVotingClassifierModel = VotingClassifier(estimators=[('LRModel',LRModel_),('DTModel',DTModel_),('KNNModel',KNNModel_),('SGDModel',SGDModel_)],n_jobs=10 ,voting='hard')\nVotingClassifierModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('VotingClassifierModel Train Score is : ' , VotingClassifierModel.score(X_train, y_train))\nprint('VotingClassifierModel Test Score is : ' , VotingClassifierModel.score(X_test, y_test))\nprint('----------------------------------------------------')\n\n#Calculating Prediction\ny_pred = VotingClassifierModel.predict(X_test)\nprint('Predicted Value for VotingClassifierModel is : ' , y_pred[:10])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Import Libraries\nfrom sklearn.metrics import accuracy_score\n \n#Calculating Accuracy Score  : ((TP + TN) / float(TP + TN + FP + FN))\nAccScore = accuracy_score(y_test, y_pred, normalize=True)\nprint('Accuracy Score is : ', AccScore)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  Please if you benefit from this kernal UPVOTE it ","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}