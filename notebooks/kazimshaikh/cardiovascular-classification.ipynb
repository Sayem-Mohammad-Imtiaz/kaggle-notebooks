{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Importing Libraries and Dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing the required libraries.\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting the data into a DataFrame.\ndata=pd.read_csv(r\"/kaggle/input/cardiovascular-disease-dataset/cardio_train.csv\",sep=\";\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The age is given in days, we have to convert it into years.\ndata[\"age\"] = data[\"age\"]/365\ndata[\"age\"] = data[\"age\"].astype(\"int\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping id column, its of no use.\ndata = data.drop(columns = [\"id\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = 'cardio', data = data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"the dataset is well balanced."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the existence of outliers using boxplots\nfig, ax = plt.subplots(figsize = (15,10))\nsns.boxplot(data = data, width = 0.5, ax = ax, fliersize = 3)\nplt.title(\"Visualization of outliers\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we can see some outliers present in some features (app_hi, app_lo, height and weight)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ap_hi greater than 200 and lower than or equal to 80 will be removed.\n# ap_lo greater than 180 and lower than 50 will be removed.\n# height greater or equal to 100 and weight less than 28 will be removed.\noutlier = ((data[\"ap_hi\"]>200) | (data[\"ap_lo\"]>180) | (data[\"ap_lo\"]<50) | (data[\"ap_hi\"]<=80) | (data[\"height\"]<=100)\n             | (data[\"weight\"]<=28) )\nprint(\"There is {} outlier\".format(data[outlier][\"cardio\"].count()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We already have 70000 data and this 1434 is only a 2% of it.\nSo we have enough data to train the model even if we remove these outliers."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing  the outlier from the Dataset.\ndata = data[~outlier]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# BoxPlot after removing the outliers.\nfig, ax = plt.subplots(figsize = (15,10))\nsns.boxplot(data = data, width = 0.5, ax = ax, fliersize = 3)\nplt.title(\"Visualization of outliers\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.drop(columns = ['cardio'])\ny = data['cardio']\nplt.figure(figsize=(20,25), facecolor='white')\nplotnumber = 1\n\nfor column in X:\n    if plotnumber<=16 :\n        ax = plt.subplot(4,4,plotnumber)\n        sns.stripplot(y,X[column])\n    plotnumber+=1\n\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating a heatmap of correlation of the data.\ncorr = data.corr()\nf, ax = plt.subplots(figsize = (15,15))\nsns.heatmap(corr, annot=True, fmt=\".3f\", linewidths=0.5, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see in the above **heatmap**, there are **correlations** among **gender and height**, **app_lo and app_hi**, **gluc and cholestrol**, and a small correlation among **smoke and alco**."},{"metadata":{},"cell_type":"markdown","source":"**Body Mass Index (BMI)**\nHeight and weight seems uncorrelated with the cardio feature but **Body Mass Index (BMI)** could be helpful to train our model."},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"bmi\"] = data[\"weight\"]/ (data[\"height\"]/100)**2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Detecting Genders\na = data[data[\"gender\"]==1][\"height\"].mean()\nb = data[data[\"gender\"]==2][\"height\"].mean()\nif a > b:\n    gender = \"male\"\n    gender2 = \"female\"\nelse:\n    gender = \"female\"\n    gender2 = \"male\"\nprint(\"Gender:1 is \"+ gender +\" & Gender:2 is \" + gender2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Women have many of the same risk factors with men for heart disease as men, such as smoking, high blood pressure, and high cholesterol especially after 65. \n* Thus we shouldn't categorize them into 1 and 2 because of 2 is always numerically bigger than 1, the model would take into account that and give a bigger ratio to men for having a disease"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"gender\"] = data[\"gender\"] % 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.drop(columns = ['cardio'])\ny = data['cardio']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscalar=MinMaxScaler()\nx_scaled=scalar.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preparing the Training and Test set."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV,RandomizedSearchCV,train_test_split\nfrom sklearn.metrics import accuracy_score,confusion_matrix,f1_score,roc_curve, roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(x_scaled, y, test_size = 0.30, random_state = 9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtc = DecisionTreeClassifier()\nran = RandomForestClassifier(n_estimators=90)\nknn = KNeighborsClassifier(n_neighbors=79)\nsvm = SVC(random_state=6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = {\"Decision tree\" : dtc,\n          \"Random forest\" : ran,\n          \"KNN\" : knn,\n          \"SVM\" : svm}\nscores= { }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for key, value in models.items():    \n    model = value\n    model.fit(X_train, y_train)\n    scores[key] = model.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores_frame = pd.DataFrame(scores, index=[\"Accuracy Score\"]).T\nscores_frame.sort_values(by=[\"Accuracy Score\"], axis=0 ,ascending=False, inplace=True)\nscores_frame","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import plot_roc_curve","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"disp = plot_roc_curve(dtc, X_test, y_test)\n\nplot_roc_curve(ran,X_test, y_test, ax = disp.ax_)\n\nplot_roc_curve(knn,X_test, y_test, ax = disp.ax_)\n\nplot_roc_curve(svm,X_test, y_test, ax = disp.ax_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the table and graph we can see that the SVM and KNN are performing better than other models."},{"metadata":{},"cell_type":"markdown","source":"## Evaluation of SVC"},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_svc=svm.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = accuracy_score(y_test, predicted_svc)\nprint(\"The accuracy of svc model is : \", accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"conf_mat = confusion_matrix(y_test, predicted_svc)\nprint(\"The Confusion Matrix for SVC in this dataset is : \\n\", conf_mat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"true_positive = conf_mat[0][0]\nfalse_positive = conf_mat[0][1]\nfalse_negative = conf_mat[1][0]\ntrue_negative = conf_mat[1][1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Precison\nPrecision = true_positive/(true_positive+false_positive)\nprint(\"The precision of this svc model is : \",Precision)\n\n# Recall\nRecall= true_positive/(true_positive+false_negative)\nprint(\"The Recall score of svc model is : \",Recall)\n\n# F1 Score\nF1_Score = 2*(Recall * Precision) / (Recall + Precision)\nprint(\"The F1_Score for this dataset is : \",F1_Score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluation of KNN."},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_knn=knn.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy=accuracy_score(y_test,predicted_knn)\nprint(\"The accuracy of knn model is : \",accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"conf_mat = confusion_matrix(y_test,predicted_knn)\nprint(\"The Confusion Matrix for KNN in this dataset is : \\n\",conf_mat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"true_positive = conf_mat[0][0]\nfalse_positive = conf_mat[0][1]\nfalse_negative = conf_mat[1][0]\ntrue_negative = conf_mat[1][1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Precison\nPrecision = true_positive/(true_positive+false_positive)\nprint(\"The precision of this knn model is : \",Precision)\n\n# Recall\nRecall= true_positive/(true_positive+false_negative)\nprint(\"The Recall score of knn model is : \",Recall)\n\n# F1 Score\nF1_Score = 2*(Recall * Precision) / (Recall + Precision)\nprint(\"The F1_Score for this dataset is : \",F1_Score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion\n\n#### SVC gives a better result than other models,in terms of Accuracy score,Auc score and F1_score Svc gives good result. so we can take svc to predict whether a person has cardio or not with good accuracy of 73%."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}