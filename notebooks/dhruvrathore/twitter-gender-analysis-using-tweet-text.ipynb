{"cells":[{"metadata":{},"cell_type":"markdown","source":"## __Problem Statement:__\n\nFor the given dataset, perform EDA with visualization, I'll formulate 2 questions on the given data and answer the same. Then proceed to to build an ensemble classifier using 3 ML algorithms and find out which algorithm best suits the dataset with respect to the accuracy of the algorithm.\n#### __Procedure:__\n\n   1. The dataset is to be analysed and preliminary data cleaning is to be done.\n   2. Data exploration and feature engineering are to done for fine tuning of dataset.\n   3. ML modelling and accuracy checking to find the optimal algorithm for the dataset.\n\n\n#### __Questions to be answered at the end of EDA:__\n   1. Text analysis based on common words used by Males & Females ?\n   2. How significant are the color attributes used by the users ?\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing necessary packages \n\nimport numpy as np \nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## __Preliminary Data Assessment__","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"twitter = pd.read_csv('../input/twitter-user-gender-classification/gender-classifier-DFE-791531.csv',encoding='latin-1')\ntwitter.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"twitter.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"twitter.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"twitter.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"twitter.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"twitter.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"twitter['tweet_count'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"twitter['retweet_count'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot (x = 'gender', y = 'tweet_count',data = twitter)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot (x = 'gender', y = 'retweet_count',data = twitter)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizing null values to get a better idea of the dataset & it's trends\n\nplt.subplots(figsize=(15,15))\nsns.heatmap(twitter.isnull(), cbar=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## __Data Exploration & Feature Engineering__\nHere we are going to explore the relationships of the independent and dependent variables, modify the features and look for anomalies to present a better dataset for the ML models.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"As by observing the above representations\nWe will reduce down to only the following columns which are required for ML algorithm implimentation :\n\n   1. 'gender'\n   2. 'link_color'\n   3. 'sidebar_color'\n   4. 'text'\n   4. 'description'\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dropping irrelevant columns from dataset\n\ntwitter = twitter.drop(['_unit_id', '_golden', '_unit_state', '_last_judgment_at', 'gender:confidence', 'profile_yn', 'profile_yn:confidence', \n                        'created', 'fav_number', 'gender_gold', 'name', 'profile_yn_gold', 'profileimage', 'retweet_count', \n                        'tweet_coord', 'tweet_count', 'tweet_created', 'tweet_id', 'tweet_location', 'user_timezone', \n                        '_trusted_judgments'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"twitter.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"twitter['gender'].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"twitter['gender'].value_counts(dropna=False) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(twitter['gender'],label=\"Gender\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### __Text Analysis :__","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# dropping all the null values from 'gender'\n\ntwitter = twitter.dropna(subset=['gender'],how ='any')  \ntwitter.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merging the 'text' & 'description' to combine all sorts of text and then find out common words\n\ntwitter['text_description'] = twitter['text'].str.cat(twitter['description'], sep=' ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"twitter = twitter.drop(['description','text'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"twitter.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Text cleaning\nIn this phase, we will filtering out text and perform other functions like Normalizing, Lemmatizing etc","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Junk words & letters other than the English vocab words are filtered out\nimport re\ndef cleaning(s):\n    s = str(s)\n    s = s.lower()\n    s = s.replace(\",\",\"\")\n    s = re.sub('[!@#$_]', '', s)\n    s = re.sub('\\W,\\s',' ',s)\n    s = re.sub(r'[^\\w]', ' ', s)\n    s = re.sub('\\s\\W',' ',s)\n    s = re.sub(\"\\d+\", \"\", s)\n    s = re.sub('\\s+',' ',s)\n    s = s.replace(\"co\",\"\")\n    s = s.replace(\"https\",\"\")\n    s = s.replace(\"[\\w*\",\" \")\n    return s\n\ntwitter['text_description'] = [cleaning(s) for s in twitter['text_description']]\ntwitter.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Removing __Stop words__ from 'text_description'","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\nwords = Counter()\nfor twit in twitter['text_description']:\n    for x in twit.split(' '):\n        words[x] += 1\n\nwords.most_common(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These are the number of most common stopwords used in the whole dataset\nThese words are considered 'noise' which can be eliminated","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filtering out 'text_description' and printing most commonly used words by elimination stopwords\n\nfrom nltk.corpus import stopwords\nstopwords = stopwords.words('english')\nwords_filtered = Counter()\nfor x, y in words.items():\n    if not x in stopwords:\n        words_filtered[x]=y\n\nwords_filtered.most_common(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <u>__Answer 1__ : The most used words by the users are words like Love, Like, Life, Time etc </u>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"There is still some trash to clear out such as HTML tags, emojis & unfinished words","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# This will clear out the rest of the remaining junk\n\nimport re\ndef preprocessor(text_description):\n    text_description = re.sub(\"[^a-zA-z]\", \" \",text_description)\n    text_description = re.sub('<[^>]*>', '', text_description)\n    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text_description)\n    text_description = (re.sub('[\\W]+', ' ', text_description.lower()) + ' ' + ' '.join(emoticons).replace('-', ''))\n    return text_description","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### __Lemmatization__\nFor reducing our vocabulary and consolidate words to their roots, we'll use __stemming / Lemmatizing__ \nWe will be using __Porter algorithm__ for stemming\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.stem import PorterStemmer\n\nporter = PorterStemmer()\n\ndef tokenizer(text_description): #tokenizer to break down our twits in individual words\n    return text_description.split()\n\ndef tokenizer_porter(text_description):\n    return [porter.stem(word) for word in text_description.split()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"twitter.text_description\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### __Color attribute analysis :__","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Side bar color >>>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"male_sidebar_color = twitter[twitter['gender'] == 'male']['sidebar_color'].value_counts().head(7)\nmale_sidebar_color_idx = male_sidebar_color.index\nmale_top_color = male_sidebar_color_idx.values\n\nmale_top_color[2] = '000000'\nprint (male_top_color)\n\nl = lambda x: '#'+x\n\nsns.set_style(\"darkgrid\")\nsns.barplot (x = male_sidebar_color, y = male_top_color) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"female_sidebar_color = twitter[twitter['gender'] == 'female']['sidebar_color'].value_counts().head(7)\nfemale_sidebar_color_idx = female_sidebar_color.index\nfemale_top_color = female_sidebar_color_idx.values\n\nfemale_top_color[2] = '000000'\nprint (female_top_color)\n\nl = lambda x: '#'+x\n\nsns.set_style(\"darkgrid\")\nsns.barplot (x = female_sidebar_color, y = female_top_color)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Link color >>>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"male_link_color = twitter[twitter['gender'] == 'male']['link_color'].value_counts().head(7)\nmale_link_color_idx = male_link_color.index\nmale_top_color = male_link_color_idx.values\nmale_top_color[1] = '009999'\nmale_top_color[5] = '000000'\nprint(male_top_color)\n\nl = lambda x: '#'+x\n\nsns.set_style(\"whitegrid\", {\"axes.facecolor\": \"white\"})\nsns.barplot (x = male_link_color, y = male_link_color_idx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"female_link_color = twitter[twitter['gender'] == 'female']['link_color'].value_counts().head(7)\nfemale_link_color_idx = female_link_color.index\nfemale_top_color = female_link_color_idx.values\n\nl = lambda x: '#'+x\n\nsns.set_style(\"whitegrid\", {\"axes.facecolor\": \"white\"})\nsns.barplot (x = female_link_color, y = female_link_color_idx, palette=list(map(l, female_top_color)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### As seen from plots displayed above, most users have not changed the default color of their profile, but if these are discarded, then there is significant dataset to be used for classification.\n\n## <u>__Answer 2__ : The most primiarly used color for both 'sidebar' & 'link color' is Blue followed by Orange and the rest of them. </u>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## __Training & Testing of ML algorithms__\nThe following classifiers have been chosen for training on the dataset :-\n\n    1. Logistic Regression\n    2. Random forest\n    3. SVM Classifier\n\nThe ML algorithms are trained on each feature of the dataset and the algorithm with the maximum accuracy is the most optimal model for this dataset and the feature that gives maximum accuracy is the optimal feature for classification of this data.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Training for Text :","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# The frequency of the words will be helpful in classifying the gender of the users.\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\n# Setting up training and testing data \nencoder = LabelEncoder()\ny = encoder.fit_transform(twitter['gender'])\nX = twitter['text_description']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Modelling on Logistic Regression >>>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import accuracy_score\n\ntfidf = TfidfVectorizer(lowercase=False,\n                        tokenizer=tokenizer_porter)\nclf = Pipeline([('vect', tfidf),\n                ('clf', LogisticRegression(multi_class='ovr', random_state=0))])\n\nclf.fit(X_train, y_train)\n\npredictions = clf.predict(X_test)\nprint('Accuracy:',accuracy_score(y_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Modelling on Random Forest >>>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nn = range (1,100,10)\n\ntfidf = TfidfVectorizer(lowercase=False,\n                        tokenizer=tokenizer_porter)\nclf = Pipeline([('vect', tfidf),\n                ('clf', RandomForestClassifier(n_estimators = 40, random_state=0))])\n\nclf.fit(X_train, y_train)\n\npredictions = clf.predict(X_test)\nprint('Accuracy:',accuracy_score(y_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Modelling on SVM >>>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\ntfidf = TfidfVectorizer(lowercase=False,\n                        tokenizer=tokenizer_porter)\nclf = Pipeline([('vect', tfidf),\n                ('clf', SVC(kernel = 'linear'))])\n\nclf.fit(X_train, y_train)\n\npredictions = clf.predict(X_test)\nprint('Accuracy:',accuracy_score(y_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### __Experimental Results__\n\nAccuracy:\n\n    Logistic Regression: 57.90%\n    Random Forest: 53.92%\n    SVM: 57.85%\n\n## <u>Winner: __Logistic Regression__ model</u>\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Training for color attributes :","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\nencoder = LabelEncoder()\ny = encoder.fit_transform(twitter['gender'])\nX = twitter['sidebar_color']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Modelling on Logistic Regression(sidebar_color) >>>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\ntfidf = TfidfVectorizer(lowercase=False,\n                        tokenizer=tokenizer_porter)\nclf = Pipeline([('vect', tfidf),\n                ('clf', LogisticRegression(multi_class='ovr', random_state=0))])\n\nclf.fit(X_train, y_train)\n\npredictions = clf.predict(X_test)\nprint('Accuracy:',accuracy_score(y_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Modelling for Random Forest(sidebar_color) >>>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nn = range (1,100,10)\n\ntfidf = TfidfVectorizer(lowercase=False,\n                        tokenizer=tokenizer_porter)\nclf = Pipeline([('vect', tfidf),\n                ('clf', RandomForestClassifier(n_estimators = 40, random_state=0))])\n\nclf.fit(X_train, y_train)\n\npredictions = clf.predict(X_test)\nprint('Accuracy:',accuracy_score(y_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Modelling for SVM(sidebar_color) >>>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\ntfidf = TfidfVectorizer(lowercase=False,\n                        tokenizer=tokenizer_porter)\nclf = Pipeline([('vect', tfidf),\n                ('clf', SVC(kernel = 'linear'))])\nclf.fit(X_train, y_train)\n\npredictions = clf.predict(X_test)\nprint('Accuracy:',accuracy_score(y_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\nencoder = LabelEncoder()\ny = encoder.fit_transform(twitter['gender'])\nX = twitter['link_color']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Modelling on Logistic Regression(link_color) >>>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\ntfidf = TfidfVectorizer(lowercase=False,\n                        tokenizer=tokenizer_porter)\nclf = Pipeline([('vect', tfidf),\n                ('clf', LogisticRegression(multi_class='ovr', random_state=0))])\n\nclf.fit(X_train, y_train)\n\npredictions = clf.predict(X_test)\nprint('Accuracy:',accuracy_score(y_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Modelling for Random Forest(link_color) >>>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nn = range (1,100,10)\n\ntfidf = TfidfVectorizer(lowercase=False,\n                        tokenizer=tokenizer_porter)\nclf = Pipeline([('vect', tfidf),\n                ('clf', RandomForestClassifier(n_estimators = 40, random_state=0))])\n\nclf.fit(X_train, y_train)\n\npredictions = clf.predict(X_test)\nprint('Accuracy:',accuracy_score(y_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Modelling for SVM(link_color) >>>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\ntfidf = TfidfVectorizer(lowercase=False,\n                        tokenizer=tokenizer_porter)\nclf = Pipeline([('vect', tfidf),\n                ('clf', SVC(kernel = 'linear'))])\nclf.fit(X_train, y_train)\n\npredictions = clf.predict(X_test)\nprint('Accuracy:',accuracy_score(y_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### __Experimental Results__\n\nAccuracy for 'sidebar_color':\n\n    Logistic Regression: 37.71%\n    Random Forest: 37.62%\n    SVM: 37.77%\n\n## <u>Winner: __SVM__ model</u>\n\nAccuracy for 'link_color':\n\n    Logistic Regression: 40.34%\n    Random Forest: 40.47%\n    SVM: 40.36%\n\n## <u>Winner: __Random Forest__ model</u>\n\n\n","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}