{"cells":[{"metadata":{"trusted":true,"_uuid":"91af2917256c7df70056a5937c8300492e66f101"},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport pandas_profiling\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport re\n\nfrom scipy import stats\nfrom functools import reduce\n\n# Import statements required for Plotly \nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\n# Some matplotlib options\n%matplotlib inline\nmatplotlib.style.use(\"ggplot\")\n\n# General pandas options\npd.set_option('display.max_colwidth', -1)  # Show the entire column \npd.options.display.max_columns = 100 \npd.options.display.max_rows = 10000 \n\n# Seaborn options\nsns.set_style(\"whitegrid\")\n\n\n# model to implement\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, roc_curve, precision_recall_curve\nfrom imblearn.over_sampling import SMOTE\n\n\n# Import and suppress warnings\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"19a429e21eebf3ab80ed863490e24692841b8c35"},"cell_type":"code","source":"df = pd.read_csv(\"../input/WA_Fn-UseC_-HR-Employee-Attrition.csv\")\nprint(df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5a673b20f78275aa54fe2159e5a32455c86a5a6a"},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b0796042fc5bf65876871a8d9c285cfefa5242d"},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"75b23c14943bfe9f9095b359d75c04d91362113e"},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"21e36a94dd5ec8c9ea674b222a2f5a09a330fb0f"},"cell_type":"markdown","source":"# Looking at each column and generating hypothesis w.r.t to  Attrition\n1) Age = High Age, High Experience \n2) High Daily Rate , Less Attrition \n3) Less distance, less attrition\n4) High Education , High Income\n5) High Environment Satisfaction, Less attrition\n6) High Job Satisfaction, Less attrition\n7) High NumCompaniesWorked, High salary, High chance of leaving for more saary\n8) High Overtime High Attrition,who are working overtime and who in many cases have a relatively low salary \n9) High percent salary hike less attrition\n10) High performance rating less attrition \n11) stock option yes, less attrition\n12) work life balance high, less attrition\n13) high years at company, less attrition\n14) high years since last promotion ,  high attrition"},{"metadata":{"_uuid":"972fd972bad566f27fed2c5d0c1ddbd9df1eace4"},"cell_type":"markdown","source":"# encoding categorical variables into numerical"},{"metadata":{"trusted":true,"_uuid":"d7ed2b9ea4b481bb939689c3f6394daef7bae222"},"cell_type":"code","source":"df.Attrition = df.Attrition.astype(\"category\")\ndf.Attrition = df.Attrition.cat.reorder_categories(['No','Yes'])\ndf.Attrition = df.Attrition.cat.codes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc9baaadee9f2e448cb220f7f59f0228fd93874f"},"cell_type":"code","source":"df.Attrition.dtype","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"902a49983599b7110ec15ffa36c82b9642a23fe0"},"cell_type":"code","source":"df.BusinessTravel.value_counts() # I am considering them in order.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d4a9246254750afbb2d863199bf16e4f75eec61"},"cell_type":"code","source":"df.BusinessTravel = df.BusinessTravel.astype(\"category\")\ndf.BusinessTravel = df.BusinessTravel.cat.reorder_categories(['Non-Travel','Travel_Rarely','Travel_Frequently'])\ndf.BusinessTravel = df.BusinessTravel.cat.codes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"78832acc7de3b128d88e6750387fe6af8c4e5047"},"cell_type":"code","source":"df.Department.value_counts() # This is nominal data here label encoding and just assigning nos. won't work so I create dummy variables.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3aca625c9b2ab4c05e7b6e37117346edc16c781f"},"cell_type":"code","source":"df.EducationField.value_counts()  # This is nominal data here label encoding and just assigning nos. won't work so I create dummy variables.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d5efe24028f48e56b8db887289ae89d3183bbfb"},"cell_type":"code","source":"df.Gender.value_counts()  # This is nominal data here label encoding and just assigning nos. won't work so I create dummy variables.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9b820b258c92a6287e9669c853ae893fd61697e7"},"cell_type":"code","source":"df.JobRole.value_counts() # This is nominal data here label encoding and just assigning nos. won't work so I create dummy variables.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5f324fbe6a1cccb88f3e7e8c70e7d25cb0ad0bba"},"cell_type":"code","source":"df.MaritalStatus.value_counts() # This is nominal data here label encoding and just assigning nos. won't work so I create dummy variables.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9ccd723b9b178a5d3502a928e494871163bcef4"},"cell_type":"code","source":"df.Over18.value_counts() # constant so delete","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6406b61a7bdf05a04d58908116d8e71abd5b7a23"},"cell_type":"code","source":"df.OverTime.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d93200649e0fc170bc46e1dea1e973c220923eb1"},"cell_type":"code","source":"df.OverTime = df.OverTime.astype(\"category\")\ndf.OverTime = df.OverTime.cat.reorder_categories(['No','Yes'])\ndf.OverTime = df.OverTime.cat.codes","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"902f69222c0d3bba197542e46d7b9efa78c4f693"},"cell_type":"markdown","source":"# EDA Univariate analysis # to check distribution "},{"metadata":{"_uuid":"977b28bcf0ea97b10cc045fad7db819c9b1ba97d"},"cell_type":"markdown","source":"# Distribution plot for numerical variables\n# Frequency count plot for categorical variables"},{"metadata":{"trusted":true,"_uuid":"c7b37a47cd3e987f7561d25b9beac322ed06c505"},"cell_type":"code","source":"# Plot for all variables distribution + Count\n# Graph distribution\ndf.hist (bins=50, figsize=(20,15), color = 'deepskyblue')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"79d719397ae6d75d1d2aca9d1fb1fb3dbb93600a"},"cell_type":"code","source":"#seprating numerical columns from dataframe\nnumerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64','int8']\n\nnewdf = df.select_dtypes(include=numerics)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7c5f3c6fccb19835afd1d79dc13a7f8573d1cf02"},"cell_type":"markdown","source":"# Distribution plot for numerical variables\n# Frequency count plot for categorical variables"},{"metadata":{"trusted":true,"_uuid":"8ad683a3b749d9ccac5a79d32fc070e472403aaa"},"cell_type":"code","source":"newdf.columns # numerical variable","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"346743d7f330e82aa453533eeba7eed92803fe04"},"cell_type":"code","source":"# Create a figure space matrix consisting of 3 columns and 2 rows\nfig, ax = plt.subplots(figsize=(20,15), ncols=3, nrows=5)\n# The amount of space above titles\n\"\"\"y_title_margin = .2\nax[0][0].set_title(\"Age\",y = y_title_margin)\nax[0][1].set_title(\"BusinessTravel\",y = y_title_margin)\nax[0][2].set_title(\"DailyRate\",y = y_title_margin)\nax[1][0].set_title(\"DistanceFromHome\",y = y_title_margin)\nax[1][1].set_title(\"EnvironmentSatisfaction\",y = y_title_margin)\nax[1][2].set_title(\"JobSatisfaction\",y = y_title_margin)\nax[2][0].set_title(\"MonthlyRate\",y = y_title_margin)\nax[2][1].set_title(\"OverTime\",y = y_title_margin)\nax[2][2].set_title(\"PerformanceRating\",y = y_title_margin)\nax[3][0].set_title(\"RelationshipSatisfaction\",y = y_title_margin)\nax[3][1].set_title(\"TotalWorkingYears\",y = y_title_margin)\nax[3][2].set_title(\"WorkLifeBalance\",y = y_title_margin)\nax[4][0].set_title(\"YearsAtCompany\",y = y_title_margin)\nax[4][1].set_title(\"YearsSinceLastPromotion\",y = y_title_margin)\nax[4][2].set_title(\"YearsWithCurrManage\",y = y_title_margin)\"\"\"\n\nsns.distplot(df.Age,kde=False,color=\"b\", ax=ax[0][0])\nsns.distplot(df.BusinessTravel,kde=False,color=\"b\", ax=ax[0][1])\nsns.distplot(df.DailyRate,kde=False,color=\"b\", ax=ax[0][2])\nsns.distplot(df.DistanceFromHome,kde=False,color=\"b\", ax=ax[1][0])\nsns.distplot(df.EnvironmentSatisfaction,kde=False,color=\"b\", ax=ax[1][1])\nsns.distplot(df.JobSatisfaction,kde=False,color=\"b\", ax=ax[1][2])\nsns.distplot(df.MonthlyRate,kde=False,color=\"b\", ax=ax[2][0])\nsns.distplot(df.OverTime,kde=False,color=\"b\", ax=ax[2][1])\nsns.distplot(df.PerformanceRating,kde=False,color=\"b\", ax=ax[2][2])\nsns.distplot(df.RelationshipSatisfaction,kde=False,color=\"b\", ax=ax[3][0])\nsns.distplot(df.TotalWorkingYears,kde=False,color=\"b\", ax=ax[3][1])\nsns.distplot(df.WorkLifeBalance,kde=False,color=\"b\", ax=ax[3][2])\nsns.distplot(df.YearsAtCompany,kde=False,color=\"b\", ax=ax[4][0])\nsns.distplot(df.YearsSinceLastPromotion,kde=False,color=\"b\", ax=ax[4][1])\nsns.distplot(df.YearsWithCurrManager,kde=False,color=\"b\", ax=ax[4][2])\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1420d89fc9508145533a1c4a6d7332687996664b"},"cell_type":"markdown","source":"# insights from univariate analysis of numerical data\n1) Age = max employ has age in range of 27-29, 35-37, 39-40\n2) Business_travel = Travel_Rarely 1043, Travel_Frequently 277 ,Non-Travel  150\n3) Daily rate = mostly between range of 115- 130 for all employees\n4) Distance from home = Good no. of  people live near office range of distance = 0-3\n5) Environment satidfaction = most people are satisfied with environment of company as they have rated it 3 and 4 and same for job satisfaction and same for relationship satisfaction this means that less employee are not satisfied and thus less people have higher chance of attrition.\n6) overtime = less people do overtime and thus they might have higher chance of attrition\n7) worklife balance =  most people have balanced life b/w work and personal life but some have rated it 1 and 2 thus they have high chance of attrition.\n8) YearsSinceLastPromotion = most people got promoted recentely as there are more people who in range of 0-1 years and hypothesis is this that poeple who did not get fromotion from 2-5 years are likely to churn more."},{"metadata":{"trusted":true,"_uuid":"973299bcf64d477725e5809985a96d3952b67ed9"},"cell_type":"code","source":"#separting categorical columns ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df21895d5f05f3b4303f4733a10757e6c7f8e6f2"},"cell_type":"code","source":"cat = ['object']\n\nnewdf1 = df.select_dtypes(include=cat)\nnewdf1.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"037c9fddcc48ff8c4721cf26952f8cb60c68134c"},"cell_type":"code","source":"# Create a figure space matrix consisting of 3 columns and 2 rows\nfig, ax = plt.subplots(figsize=(20,15), ncols=3, nrows=2)\nsns.countplot(x=\"Department\",data=df,palette=\"Greens_d\",ax= ax[0][0])\nsns.countplot(x=\"EducationField\",data=df,palette=\"Greens_d\",ax= ax[0][1])\nsns.countplot(x=\"Gender\",data=df,palette=\"Greens_d\",ax= ax[0][2])\nsns.countplot(x=\"JobRole\",data=df,palette=\"Greens_d\",ax= ax[1][0])\nsns.countplot(x=\"MaritalStatus\",data=df,palette=\"Greens_d\",ax= ax[1][1])\nsns.countplot(x=\"Over18\",data=df,palette=\"Greens_d\",ax= ax[1][2]) # drop Over18","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2623ad3960f92dbf6634fc00553759f45cd24df8"},"cell_type":"markdown","source":"# Bivariate analysis with respect to target variable"},{"metadata":{"trusted":true,"_uuid":"10ed958f6fbcf481fe1d8f9b07ef8c14e032817d"},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c08295d7fc87fd4631cdb7e32d6fd21ee6ece785"},"cell_type":"code","source":"# Create a figure space matrix consisting of 3 columns and 2 rows ## box plot for categorical vs numerical\nsns.boxplot(x=\"BusinessTravel\",y=\"Age\",hue=\"Attrition\",data=df) \n# we can conclude that most employers who are in range of 27-38 leave company.this can be due to career switch or want salary hike.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e547985afe87aa797f67bfae0e7266ed8dc6acc1"},"cell_type":"code","source":"sns.countplot(x=\"Department\",data=df,hue='Attrition')  # no specific relation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1e62acb9813a23a0d930016f17f074d4a83b871f"},"cell_type":"code","source":"sns.boxplot(x=\"Attrition\",y='DistanceFromHome',hue=\"Attrition\",data=df) # no specific relation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"63f474e99d4e4f51cbfeccdf21b811a6d8e8b037"},"cell_type":"code","source":"sns.countplot(x=\"Education\",data=df,hue='Attrition') # no specific relation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2405d37d13acb40efcd63aff06f06d1c273c392a"},"cell_type":"code","source":"sns.countplot(x=\"EducationField\",data=df,hue='Attrition') # no specific relation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ac009da37c14209b4c5eee56cd14f905fb60c58a"},"cell_type":"code","source":"sns.countplot(x=\"EnvironmentSatisfaction\",data=df,hue='Attrition') # we can see that % of attrition for environment satisfaction = 1,2 will be more that of 3 and 4.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0dace4c82682c56ab36e069a906088d5602e69fe"},"cell_type":"code","source":"sns.countplot(x=\"Gender\",data=df,hue='Attrition') #no specific relation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6a05c733da86fb6475f0cd9a0e4c65dd12e3ac3a"},"cell_type":"code","source":"sns.countplot(x=\"JobSatisfaction\",data=df,hue='Attrition') # we can see that % of attrition for job satisfaction = 1,2 will be more that of 3 and 4.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3d13d37ddddc61dc3a7f682e963b963c8a6e80da"},"cell_type":"code","source":"sns.boxplot(x=\"Attrition\",y=\"YearsSinceLastPromotion\",hue=\"Attrition\",data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11dd2df2e139bc3c5892b79c2de6c0438ddc1c0b"},"cell_type":"code","source":"True_Class = print(sum(df['Attrition']==1))\nTotal_length = print(len(df['Attrition']))\nprint((237/1470)*100) # percentage of class 1, checking class imbalance # it is not highly imbalanced but still we will use SMOTE for 1 model and do it without SMOTE for other model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f29b5bc42d05abd8a4c7cf3feb4d722c3d786f8c"},"cell_type":"code","source":"#Checking class imbalance\nsns.countplot(x ='Attrition',data = df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2bea552a01b8485b96e9290096330591e6d013a6"},"cell_type":"code","source":"pandas_profiling.ProfileReport(df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"78a2217fe768132553ee91014c490491878bceee"},"cell_type":"markdown","source":"# Encoding nominal data and removing constant and highly correlated data\nGenerally when making a predictive model, it would be preferable to train a model with features that are not too correlated with one another so that we do not need to deal with redundant features. In the case that we have quite a lot of correlated features one could perhaps apply a technique such as Principal Component Analysis (PCA) to reduce the feature space."},{"metadata":{"trusted":true,"_uuid":"f3dc63948d484f23e37a41a467b5269d82b41ca1"},"cell_type":"code","source":"df = df.drop(['EmployeeCount','MonthlyIncome','Over18','StandardHours'],axis =1)\ndf = pd.get_dummies(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49e30ed8f40e0ba97c2edcafd2351386c44f1b12"},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0ba937af522a40428013fed710df866e799ebb48"},"cell_type":"markdown","source":"# ML Models\nSplitting Data into Train and Test sets\nBut before we even start training a model, we will have to partition our dataset into a training set and a test set (unlike Kaggle competitions where the train and test data are already segregated for you). To split our data we will utilise sklearn's"},{"metadata":{"_uuid":"f2765fffc020d59b5879b29ad089accd2afbc0da"},"cell_type":"markdown","source":"# Decision Tree"},{"metadata":{"trusted":true,"_uuid":"dc73a7de9741ae1c194c56ac877aec38ac471f7d"},"cell_type":"code","source":"# Choose the dependent variable column (churn) and set it as target\ntarget = df.Attrition\n# Drop column churn and set everything else as features\nfeatures = df.drop(\"Attrition\",axis=1)\n# Import the train_test_split method\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold, cross_val_score\n\n# Split data into train and test sets as well as for validation and testing\n# Use that function to create the splits both for target and for features\n# Set the test sample to be 25% of your observations\ntarget_train, target_test, features_train, features_test = train_test_split(target,features,test_size=0.25,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e84c6cbd5935b58e03473636668d6692ca3682b6"},"cell_type":"code","source":"kf = KFold(n_splits=10, shuffle=True, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ba401431e622d7c1720a0c39b6e69cf3bb4992c9"},"cell_type":"code","source":"# Import the classification algorithm\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Initialize it and call model by specifying the random_state parameter\nmodel = DecisionTreeClassifier(random_state=42,class_weight='balanced')\n\n# Apply a decision tree model to fit features to the target\nmodel.fit(features_train,target_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"86396e332b417c9d959ad76dfc1ff73c69a7fc37"},"cell_type":"code","source":"# Do k-fold cross-validation\ncv_results = cross_val_score(model, # Pipeline\n                             features_train, # Feature matrix\n                             target_train, # Target vector\n                             cv=kf, # Cross-validation technique\n                             scoring=\"accuracy\", # Loss function\n                             n_jobs=-1) # Use all CPU scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e399640bc0468aaeb97521e57416113155e551bc"},"cell_type":"code","source":"# Calculate mean # cross validated score\nCV_mean = cv_results.mean()\nprint(CV_mean*(100))","execution_count":null,"outputs":[]},{"metadata":{"code_folding":[],"trusted":true,"_uuid":"1ccf5008f4b94abed52ac054d1f04ce987498a0f"},"cell_type":"code","source":"# overfited model\n# Check the accuracy score of the prediction for the training set\nprint(model.score(features_train,target_train)*100)\n\n# Check the accuracy score of the prediction for the test set\nprint(model.score(features_test,target_test)*100)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e2821a22a4f8483acbb911369d253a09417739e9"},"cell_type":"markdown","source":"# Parameter tuning"},{"metadata":{"trusted":true,"_uuid":"95e1b9bba805ffa3cdc69bbcf24d083b2fe1641a"},"cell_type":"code","source":"# generate max depth range\ndepth = [i for i in range (5,21,1)]\nsamples = [i for i in range(50,450,1)]\nParameters = dict(max_depth = depth, min_samples_leaf = samples)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8848c83e6fcd651099a5c81b99961bb9f2949a76"},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"32eaa30b5d6295c77ebfd841b3a1d1ff98cb5cc8"},"cell_type":"code","source":"Param_search = GridSearchCV(model,Parameters)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c7551ff3a8235243e7ce57ab3b3f95fd62e95edb"},"cell_type":"code","source":"Param_search.fit(features_train,target_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c665901bb0c96a045da18ce42b88195f23e55ea"},"cell_type":"code","source":"print(Param_search.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea354690f07da3e98bf13e94c70997b0d4b27b7a"},"cell_type":"markdown","source":"# Tuned DT Model"},{"metadata":{"trusted":true,"_uuid":"c0f5c18e7b138d5ca304ec26d251c9a028973d84"},"cell_type":"code","source":"model1 = DecisionTreeClassifier(random_state=42,class_weight='balanced',max_depth = 5, min_samples_leaf = 368)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4bd3216245dd9b49f4a0b19e7948afa64a7faf2b"},"cell_type":"code","source":"model1.fit(features_train,target_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6df0753342fb085672ac34a67f5a6301393770b0"},"cell_type":"code","source":"# Do k-fold cross-validation\ncv_results1 = cross_val_score(model1, # Pipeline\n                             features_train, # Feature matrix\n                             target_train, # Target vector\n                             cv=kf, # Cross-validation technique\n                             scoring=\"accuracy\", # Loss function\n                             n_jobs=-1) # Use all CPU scores\n# Calculate mean # cross validated score\nCV_mean1 = cv_results1.mean()\nprint(CV_mean1*(100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2acfc7d2153cddfcc536d35e364986ee3fb90806"},"cell_type":"code","source":"# No overfiting\n# Check the accuracy score of the prediction for the training set\nprint(model1.score(features_train,target_train)*100)\n\n# Check the accuracy score of the prediction for the test set\nprint(model1.score(features_test,target_test)*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"54054985593b009e94e143277bddad2069ad37fb"},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix,classification_report\nprint (confusion_matrix(target_test, model1.predict(features_test)))\nprint (classification_report(target_test, model1.predict(features_test)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"74fac067181b323e126b1a9fca848fd27e05e2a1"},"cell_type":"markdown","source":"# Important features for DT model"},{"metadata":{"trusted":true,"_uuid":"b3e899300b04bc3b77a444c8ed84b569eacefc76"},"cell_type":"code","source":"important_features = model.feature_importances_\nfeature_list = list(features)\nrelative_importances = pd.DataFrame(index = feature_list, data = important_features, columns = ['Important'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9ffceca24e3257734fc8ddbb2ea541b181f58a45"},"cell_type":"code","source":"relative_importances.sort_values(by='Important', ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"606e94056707d28fef68cddea7a71541ec6c5e89"},"cell_type":"code","source":"selected_features = relative_importances[relative_importances.Important> 0.02]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"722117eea047870c0a7113137729b62108a935c1"},"cell_type":"code","source":"selected_list = selected_features.index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b974dd1b4d50afbc024adecf1cfee977e2721d9"},"cell_type":"code","source":"feature_train_selected = features_train[selected_list]\nfeature_test_selected = features_test[selected_list]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6a2c4ef4a0001001f9a659b96705d20e09ab9227"},"cell_type":"markdown","source":"# Random forest"},{"metadata":{"trusted":true,"_uuid":"afd54d77d7600cf2797b901376a94d608b31a790"},"cell_type":"code","source":"# Import RandomForestRegressor\nfrom sklearn.ensemble import RandomForestClassifier\n\nseed = 0   # We set our random seed to zero for reproducibility\n\n# Random Forest parameters\nrf_params = {\n    'n_jobs': -1,\n    'n_estimators': 800,\n    'warm_start': True, \n    'max_features': 0.3,\n    'max_depth': 9,\n    'min_samples_leaf': 2,\n    'max_features' : 'sqrt',\n    'random_state' : seed,\n    'verbose': 0\n}\n\n# Instantiate rf\nrf = RandomForestClassifier(**rf_params)\n            \n# Fit rf to the training set    \nrf.fit(features_train, target_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b1b1fbbbe57ac5a0546386f9e6845edd90a760b4"},"cell_type":"code","source":"# Do k-fold cross-validation\ncv_results2 = cross_val_score(rf, # Pipeline\n                             features_train, # Feature matrix\n                             target_train, # Target vector\n                             cv=kf, # Cross-validation technique\n                             scoring=\"accuracy\", # Loss function\n                             n_jobs=-1) # Use all CPU scores\n# Calculate mean # cross validated score\nCV_mean2 = cv_results2.mean()\nprint(CV_mean2*(100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"69c7a8092d242b9f3a64e2811e4505a0107a1402"},"cell_type":"code","source":"# Slight overfiting\n# Check the accuracy score of the prediction for the training set\nprint(rf.score(features_train,target_train)*100)\n\n# Check the accuracy score of the prediction for the test set\nprint(rf.score(features_test,target_test)*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8ea9d81c93136e6669fb3423365b0d1d0119fdf1"},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix,classification_report\nprint (confusion_matrix(target_test, rf.predict(features_test)))\nprint (classification_report(target_test, rf.predict(features_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c0c777787a56846413c501db28fc6977a117f6ac"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n#Create a pd.Series of features importances\nimportances = pd.Series(data=rf.feature_importances_,\n                        index= features_train.columns)\n\n# Sort importances\nimportances_sorted = importances.sort_values()\n\n# Draw a horizontal barplot of importances_sorted\nimportances_sorted.plot(kind='barh', color='lightgreen')\nplt.title('Features Importances')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dba38fe9ca6d18652e3d68ec5796d5c98e71c8f3"},"cell_type":"markdown","source":"\"\"\"Apparently, Overtime, Total Working Years, Age are the most important features according to rf. The importances of these two features add up to 14% roughly\"\"\"\n\n# Most RF important features : Overtime, Marital Status\n\nAs observed in the plot of feature importances, it seems that our Random Forest Classifier has decided to rank the features of OverTime highest, which is followed by marital status.\n\nI don't know about you, but working overtime to me does indeed affect my satisfaction derived from any job (and I have worked many an overtime). Maybe then it should come as no surprise that our classifier has caught on to this and thus ranked overtime the highest\n"},{"metadata":{"_uuid":"20ecb6fed03338303cc24cda11455ea629fe85b4"},"cell_type":"markdown","source":"# Logistic Regression"},{"metadata":{"trusted":true,"_uuid":"f3480174e9d321ed2e76ed227a7ff96aed39f92c"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nlr.fit(features_train,target_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bd429affdd05bbed8ed4ae12a5e78df34e6d1446"},"cell_type":"code","source":"# Do k-fold cross-validation\ncv_results2 = cross_val_score(lr, # Pipeline\n                             features_train, # Feature matrix\n                             target_train, # Target vector\n                             cv=kf, # Cross-validation technique\n                             scoring=\"accuracy\", # Loss function\n                             n_jobs=-1) # Use all CPU scores\n# Calculate mean # cross validated score\nCV_mean2 = cv_results2.mean()\nprint(CV_mean2*(100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d2f913944382b6a234cd042a644af72ea2edadd"},"cell_type":"code","source":"# No overfiting\n# Check the accuracy score of the prediction for the training set\nprint(lr.score(features_train,target_train)*100)\n\n# Check the accuracy score of the prediction for the test set\nprint(lr.score(features_test,target_test)*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5d2ae6f74e7d07a17386732ffad02ff05349b5a9"},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix,classification_report\nprint (confusion_matrix(target_test, lr.predict(features_test)))\nprint (classification_report(target_test, lr.predict(features_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5e3d6337ff3e79c6f470cd9dfecb7b92f6d04d0"},"cell_type":"code","source":"print(lr.coef_)\nprint(lr.intercept_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"000a18065a589acc72c33c963026c23edb76e348"},"cell_type":"code","source":"probability = lr.predict_proba(features_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2db926486ca43e17c0dfb6db2eab07e4c0ffb682"},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nroc_auc_score(target_test,probability[:,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d6e331aa0963c054acf431bbea8eee4090cf952b"},"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4dfdaaf6931f344fdfd722811afe85f4032f2fe7"},"cell_type":"code","source":"fpr, tpr, thresholds = roc_curve(target_test, lr.predict(features_test))\nroc_auc = auc(fpr, tpr)\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, label='AUC = %0.4f'% roc_auc)\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')\nplt.xlim([-0.001, 1])\nplt.ylim([0, 1.001])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show();","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}