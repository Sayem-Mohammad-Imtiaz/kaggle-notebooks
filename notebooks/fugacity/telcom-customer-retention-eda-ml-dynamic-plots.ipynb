{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport re\nimport time\nimport warnings\nimport numpy as np\nfrom nltk.corpus import stopwords\nfrom sklearn.preprocessing import normalize\nimport seaborn as sns\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics.classification import accuracy_score, log_loss\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import SGDClassifier\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.naive_bayes import GaussianNB\nimport math\nfrom sklearn.metrics import normalized_mutual_info_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom scipy import stats\nfrom sklearn.decomposition import PCA\n\nfrom scipy.stats import norm\nfrom mlxtend.classifier import StackingClassifier\nfrom IPython.display import Image\nimport pylab \n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,accuracy_score,classification_report\nfrom sklearn.metrics import roc_auc_score,roc_curve,scorer\nfrom sklearn.metrics import f1_score\nimport statsmodels.api as sm\nfrom sklearn.metrics import precision_score,recall_score\nfrom yellowbrick.classifier import DiscriminationThreshold\n\nimport plotly.offline as py#visualization\npy.init_notebook_mode(connected=True)#visualization\nimport plotly.graph_objs as go#visualization\nimport plotly.tools as tls#visualization\nimport plotly.figure_factory as ff#visualization\n\n\nfrom sklearn import model_selection\nfrom sklearn.linear_model import Lasso\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.linear_model import LogisticRegression\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\n\n\nfrom sklearn.metrics import recall_score\n\n\nimport plotly.offline as py#visualization\npy.init_notebook_mode(connected=True)#visualization\nimport plotly.graph_objs as go#visualization\nimport plotly.tools as tls#visualization\nimport plotly.figure_factory as ff#visualization\n\n%matplotlib inline\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data prepation"},{"metadata":{"trusted":true},"cell_type":"code","source":"telcom_df =pd.read_csv('../input/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n\n# Converting TotalChargees column to float\ntelcom_df['TotalCharges'] = pd.to_numeric(telcom_df['TotalCharges'],errors='coerce')\ntelcom_df['TotalCharges']= telcom_df['TotalCharges'].astype(float)\n\n# Imputing missing values with mean should not produce significant shift to the overall distribution\ntelcom_df['TotalCharges']=telcom_df['TotalCharges'].fillna(telcom_df['TotalCharges'].mode()[0])\n\n\n# Seperating Churn and No Churn\nNo_Churn = telcom_df[telcom_df['Churn']=='No']\nChurn = telcom_df[telcom_df['Churn']=='Yes']\n\n# Attributing No internet service to No\nno_internet_feats = [ 'TechSupport','OnlineBackup', 'DeviceProtection','StreamingTV',\n                 'OnlineSecurity','StreamingMovies']\n\nfor i in no_internet_feats:\n    telcom_df[i] = telcom_df[i].replace({'No internet service':'No'})\n\n# Attributing No phone service to No\ntelcom_df['MultipleLines']=telcom_df['MultipleLines'].replace({'No phone service':'No'})\n\n# Attributing No phone service to No\ntelcom_df['SeniorCitizen']=telcom_df['SeniorCitizen'].replace({0:'No',\n                                                              1:'Yes'})\n\n\n\n\n# Feature seperation\nId_features = ['customerID']\ntarget_feature = ['Churn']\n\nnum_features =  telcom_df.select_dtypes(include='number').columns.tolist()\ncat_features = telcom_df.select_dtypes(include='object').columns.tolist()\ncat_features   = [x for x in cat_features if x not in Id_features]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"categ_count=[]\nfor i in cat_features:\n    temp = telcom_df[i]\n    temp = temp.value_counts()\n    categ_count.append(temp)\n\nfor i in range(1,len(categ_count)+1):\n    pylab.subplot(5,5,i)\n    sns.barplot(categ_count[i-1].index, categ_count[i-1].values, alpha=0.8,label='big').set_title(categ_count[i-1].name)\n    plt.gcf().set_size_inches(20, 15)\n    plt.xticks(rotation=20)\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Categorical Data Analysis:\n    - The ratio of Churn and No Churn is approximately 1:3. This might result in using different sampling techniques to account for inbalance\n    - Month-to-month is the most common type of contract. This might heavily influce the prediction, since it can be considered as \"level of commitment\"\n    - Telcom Service options can be groupped together to generate new feature\n    - Customers can be grouped into Engaged and Not Engaged group, where in Engaged groups consist of customers with long-term contracts and all services. Two possible business objective might be retain Engaged Group and convert Non Engaged in Engaged"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport plotly.graph_objs as go\nimport plotly\n\nx1 = telcom_df[telcom_df['Churn']=='Yes']['TotalCharges']\nx2 = telcom_df[telcom_df['Churn']=='No']['TotalCharges']\nx3 = telcom_df[telcom_df['Churn']=='Yes']['tenure']\nx4 = telcom_df[telcom_df['Churn']=='No']['tenure']\nx5 = telcom_df[telcom_df['Churn']=='Yes']['MonthlyCharges']\nx6 = telcom_df[telcom_df['Churn']=='No']['MonthlyCharges']\n\nfig = plotly.tools.make_subplots(rows=1,cols=3)\n\nfig.append_trace(go.Histogram(x = x1, opacity = 0.75, name = 'Churn', histnorm= \"percent\" ,showlegend=False,marker=dict(color='#0000FF')),1,1)\nfig.append_trace(go.Histogram(x = x2, opacity = 0.75, name = 'No Churn', histnorm= \"percent\",showlegend=False,marker=dict(color='#FFA500')),1,1)\n\nfig.append_trace(go.Histogram(x = x3, opacity = 0.75, name = 'Churn', histnorm= \"percent\",showlegend=False,marker=dict(color='#0000FF')),1,2)\nfig.append_trace(go.Histogram(x = x4, opacity = 0.75, name = 'No Churn', histnorm= \"percent\",showlegend=False,marker=dict(color='#FFA500')),1,2)\n\nfig.append_trace(go.Histogram(x = x5, opacity = 0.75, name = 'Churn', histnorm= \"percent\",marker=dict(color='#0000FF')),1,3)\nfig.append_trace(go.Histogram(x = x6, opacity = 0.75, name = 'No Churn', histnorm= \"percent\",marker=dict(color='#FFA500')),1,3)\n\nfig['layout']['xaxis1'].update(title='TotalCharges($)')\nfig['layout']['xaxis2'].update(title='Tenure(month)')\nfig['layout']['xaxis3'].update(title='MonthlyCharges($)')\n\nfig['layout']['yaxis1'].update(title='percent')\n\nfig.layout.update(go.Layout(barmode = 'overlay',title='Numerical Features Distribution'))\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Numerical Data Analysis\n    - Total Charges for both target groups seems to follow Pareto distribtuion \n    - Interestengly that 30% of Churn customers have 0 total charges. This might suggest that 30% of Churned customers actually Not Churned. \n    \n    - Tenature for Churn group also follows Pareto distribution, however No Churn group behaves more like a U-Shape distribution\n    - "},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature seperation\nId_features = ['customerID']\ntarget_feature = ['Churn']\n\nnum_features =  telcom_df.select_dtypes(include='number').columns.tolist()\ncat_features = telcom_df.select_dtypes(include='object').columns.tolist()\ncat_features   = [x for x in cat_features if x not in Id_features]\n\n# Binary columns with 2 values\nbin_features   = telcom_df.nunique()[telcom_df.nunique() == 2].keys().tolist()\n#Columns more than 2 values\nmulti_features = [x for x in cat_features if x not in bin_features]\n    \n#Duplicating columns for multi value columns\ntelcom_df = pd.get_dummies(data = telcom_df,columns = multi_features )\n\n#Label encoding Binary columns\nle = LabelEncoder()\nfor i in bin_features :\n    telcom_df[i] = le.fit_transform(telcom_df[i])\n\n#Scaling Numerical columns\nstd = StandardScaler()\nscaled = std.fit_transform(telcom_df[num_features])\nscaled = pd.DataFrame(scaled,columns=num_features)\n\n#dropping original values merging scaled values for numerical columns\ntelcom_df_og = telcom_df.copy()\ntelcom_df = telcom_df.drop(columns = num_features+Id_features,axis = 1)\ntelcom_df = telcom_df.merge(scaled,left_index=True,right_index=True,how = \"left\")\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### HEAT MAP + PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"#correlation\ncorrelations = telcom_df.corr().sort_values(by=['Churn'],ascending=False)\ncorrelations = correlations.T.sort_values(by=['Churn'],ascending=False)\n#tick labels\nmatrix_cols = correlations.columns.tolist()\n#convert to array\ncorr_array  = np.array(correlations)\n\n#Plotting\ntrace = go.Heatmap(z = corr_array,\n                   x = matrix_cols,\n                   y = matrix_cols,\n                   colorscale = \"Portland\",\n                   colorbar   = dict(title = \"Pearson Correlation Coefficient\",\n                                     titleside = \"right\"\n                                    ) ,\n                  )\n\nlayout = go.Layout(dict(title = \"Correlation Matrix for variables\",\n                        autosize = False,\n                        height  = 720,\n                        width   = 800,\n                        margin  = dict(r = 0 ,l = 210,\n                                       t = 25,b = 210,\n                                      ),\n                        yaxis   = dict(tickfont = dict(size = 9)),\n                        xaxis   = dict(tickfont = dict(size = 9))\n                       )\n                  )\n\ndata = [trace]\nfig = go.Figure(data=data,layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### HeatMap Insights:\n* The bottom row shows the correlation of all given features to the target variable ( Left Side = Churn & Right Size = No Churn)\n* **Contract_Month-to-month, InternetService_Fiber optic,  PaymentMethod_Electronic check** shows the highest **positive correlation** (Churn)\n* **Tenature, Contract_Two_Years, InternetService_No** shows the highest **negative correlation** (No Churn)\n    "},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components = 2)\n\nX = telcom_df[[i for i in telcom_df.columns if i not in Id_features + target_feature]]\nY = telcom_df[target_feature]\n\nprincipal_components = pca.fit_transform(X)\npca_data = pd.DataFrame(principal_components,columns = [\"PC1\",\"PC2\"])\npca_data = pca_data.merge(Y,left_index=True,right_index=True,how=\"left\")\npca_data[\"Churn\"] = pca_data[\"Churn\"].replace({1:\"Churn\",0:\"Not Churn\"})\n\ncomponents_df = pd.DataFrame(pca.components_,columns=X.columns)\n\npc1 = components_df.loc[0].sort_values(ascending=True).to_dict()\npc2 = components_df.loc[1].sort_values(ascending=True).to_dict()\ncomp_1 = pd.DataFrame([pc1],columns=pc1.keys())\ncomp_2 = pd.DataFrame([pc2],columns=pc2.keys())\nx1 = comp_1.T.reset_index()\nx2 = comp_2.T.reset_index()\nx1= x1.rename(columns={'index':'Feature',0:'Value'})\nx2 = x2.rename(columns={'index':'Feature',0:'Value'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trace1 = go.Scatter(x = pca_data[pca_data[\"Churn\"] == 'Churn'][\"PC1\"],\n                    y = pca_data[pca_data[\"Churn\"] == 'Churn'][\"PC2\"], name = 'Churn',\n                    mode = \"markers\", \n                    marker = dict(color = 'red',symbol =  \"diamond-open\"))\n\ntrace2 = go.Scatter(x = pca_data[pca_data[\"Churn\"] == 'Not Churn'][\"PC1\"],\n                    y = pca_data[pca_data[\"Churn\"] == 'Not Churn'][\"PC2\"], name = 'Not Churn',\n                    mode = \"markers\",\n                    marker = dict(color = 'blue',symbol =  \"diamond-open\"))\n\ntrace4 = go.Bar(x = x1[\"Feature\"],y = x1[\"Value\"],name = \"PC1\")\ntrace3 = go.Bar(x = x2[\"Feature\"],y = x2[\"Value\"],name = \"PC2\")\n\nfig = plotly.tools.make_subplots(rows=2,cols=2,horizontal_spacing = 0.1,vertical_spacing = 0.5,)\n\nfig.append_trace(trace1,1,1)\nfig.append_trace(trace2,1,1)\nfig.append_trace(go.Bar(x = x1[\"Feature\"],y = x1[\"Value\"],name = \"PC1\",showlegend=False,marker=dict(color='#9400D3')),1,2)\nfig.append_trace(go.Bar(x = x2[\"Feature\"],y = x2[\"Value\"],name = \"PC2\",showlegend=False,marker=dict(color='#008000')),2,2)\n\nfig['layout'].update(showlegend=True, title=\"Model performance\" ,\n                     autosize = False,height = 800,width = 1200,\n                     plot_bgcolor = 'rgba(240,240,240, 0.95)',\n                     paper_bgcolor = 'rgba(240,240,240, 0.95)',\n                     margin = dict(b = 250))\n\nfig['layout']['xaxis1'].update(title='principal component 1',domain=[0.05, 0.5])\nfig['layout']['yaxis1'].update(title='principal component 2',domain=[1, 0.3])\nfig['layout']['xaxis2'].update(tickangle=60)\nfig['layout']['yaxis2'].update(title='PC 1')\nfig['layout']['xaxis4'].update(tickangle=60)\nfig['layout']['yaxis4'].update(title='PC 2')\n\nfig.layout.update(go.Layout(barmode = 'overlay',title='Principle Component Analysis and Feature Contribution' ))\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### PCA Insights:\n* Not Churn costomers mostly cluster in the 2nd quadrant of the cartesian coordinate\n* Features that drive Not Churn cluster aggregation are features with negative impact on PC 1 and features with positive impact on PC 2 \n* This suggest that we Tenature, Contract_Two year, InternetServices_No, Contract Month-to-Month, PaymentMethod_Mailed check have negative impact on customer retention \n    \nMore thoughts on \"Negative Impact\" on customer retention:\n* Hypothesis can be made that customers with short or too long of contract have tendency to terminate their contract.\n* Payment method of mailed check and no internet service can be a reasonable predictor for cusomer retention as well  "},{"metadata":{},"cell_type":"markdown","source":"# Machine Learning"},{"metadata":{},"cell_type":"markdown","source":"### Feature Generation\n\nTo avoid data leakage we are going to preprocess original data again"},{"metadata":{"trusted":true},"cell_type":"code","source":"telcom_df =pd.read_csv('../input/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n\n# Converting TotalChargees column to float\ntelcom_df['TotalCharges'] = pd.to_numeric(telcom_df['TotalCharges'],errors='coerce')\ntelcom_df['TotalCharges']= telcom_df['TotalCharges'].astype(float)\n\n# Imputing missing values with mean should not produce significant shift to the overall distribution\ntelcom_df['TotalCharges']=telcom_df['TotalCharges'].fillna(telcom_df['TotalCharges'].mode()[0])\n\n\n# Seperating Churn and No Churn\nNo_Churn = telcom_df[telcom_df['Churn']=='No']\nChurn = telcom_df[telcom_df['Churn']=='Yes']\n\n# Attributing No internet service to No\nno_internet_feats = [ 'TechSupport','OnlineBackup', 'DeviceProtection','StreamingTV',\n                 'OnlineSecurity','StreamingMovies']\n\nfor i in no_internet_feats:\n    telcom_df[i] = telcom_df[i].replace({'No internet service':'No'})\n\n# Attributing No phone service to No\ntelcom_df['MultipleLines']=telcom_df['MultipleLines'].replace({'No phone service':'No'})\n\n# Attributing No phone service to No\ntelcom_df['SeniorCitizen']=telcom_df['SeniorCitizen'].replace({0:'No',\n                                                              1:'Yes'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here is the list of features I decided to generate:\n- **TotalServices** - combine all services offered by the telecom company\n- **EngagedCustomers** - customers that are subscribed to multiple services and with countract term greaterthan month-to-month \n- **Young_NoDep** - Customers that are not senior and with no dependents \n- **Single_NoDep** - Singles with no dependents\n- **AveServicePrice** - MonthlyCharges / TotalServices"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature seperation\nId_features = ['customerID']\ntarget_feature = ['Churn']\n\n# All services \ntelcom_df['TotalServices'] = (telcom_df[['PhoneService', 'InternetService', 'OnlineSecurity','OnlineBackup', \n                                         'DeviceProtection', 'TechSupport','StreamingTV', 'StreamingMovies']]== 'Yes').sum(axis=1)\n\n# This feature tends to reflect the relationship between services and monthy charges. \n# This features assumes equal weight between services\n\n# Engaged customer that subscribes to all services with contract greater than month-to-month \ntelcom_df.loc[:,'EngagedCustomers'] = np.where((telcom_df['StreamingTV'] =='Yes') &\n                               (telcom_df['PhoneService']=='Yes') &\n                               (telcom_df['StreamingMovies']=='Yes') &\n                               (telcom_df['Contract'] != 'Month-to-month'), 1,0)\n\n# Not Senior, Single, No Dependents \ntelcom_df.loc[:,'Young_NoDep'] = np.where((telcom_df['Dependents'] =='No') &\n                                    (telcom_df['SeniorCitizen']=='No'), 1,0)\n\n# Not Senior, No Dependents \ntelcom_df.loc[:,'Single_NotSen'] = np.where((telcom_df['Partner'] =='No') &\n                                    (telcom_df['SeniorCitizen']=='No'), 1,0)\n\n#########################\n\nnum_features =  telcom_df.select_dtypes(include='number').columns.tolist()\ncat_features = telcom_df.select_dtypes(include='object').columns.tolist()\ncat_features   = [x for x in cat_features if x not in Id_features]\n\n# Binary columns with 2 values\nbin_features   = telcom_df.nunique()[telcom_df.nunique() == 2].keys().tolist()\n#Columns more than 2 values\nmulti_features = [x for x in cat_features if x not in bin_features]\n\ntelcom_df[num_features]=telcom_df[num_features].astype(float)\ntelcom_df['EngagedCustomers']=telcom_df['EngagedCustomers'].astype(float)\n######################\n\n    \n#Duplicating columns for multi value columns\ntelcom_df = pd.get_dummies(data = telcom_df,columns = multi_features )\n\n#Label encoding Binary columns\nle = LabelEncoder()\nfor i in bin_features :\n    telcom_df[i] = le.fit_transform(telcom_df[i])\n\n#Scaling Numerical columns\nstd = StandardScaler()\nscaled = std.fit_transform(telcom_df[num_features])\nscaled = pd.DataFrame(scaled,columns=num_features)\n\n#dropping original values merging scaled values for numerical columns\ntelcom_df_og = telcom_df.copy()\ntelcom_df = telcom_df.drop(columns = num_features+Id_features,axis = 1)\ntelcom_df = telcom_df.merge(scaled,left_index=True,right_index=True,how = \"left\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Try Feature\ntelcom_df['AveServicePrice[$/mo]'] = telcom_df['MonthlyCharges']/telcom_df['TotalServices'] \n# Comb Engin_feat\nengin_feat = telcom_df[['TotalServices','AveServicePrice[$/mo]','EngagedCustomers','Single_NotSen']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Splitting Data into Train / Test"},{"metadata":{"trusted":true},"cell_type":"code","source":"train,test = train_test_split(telcom_df,test_size = .25 ,random_state = 111)\n    \n##seperating dependent and independent variables\nfeatures    = [i for i in telcom_df.columns if i not in Id_features + target_feature]\nX_train = train[features]\nY_train = train[target_feature]\nX_test  = test[features]\nY_test  = test[target_feature]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_performance_80_20(name,\n                            clf,\n                            X_train,\n                            X_test,\n                            Y_train,\n                            Y_test):\n    '''\n    IN: Model name, Classifier, Best Alpha, and All 3 OneHotEncoded Sets \n    OUT: Log-Loss Report data frame\n    '''\n    # Model\n    clf = clf\n    clf.fit(X_train.values, Y_train.values)\n    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n    sig_clf.fit(X_train.values, Y_train.values)\n    \n    train_predict_y = sig_clf.predict_proba(X_train.values)\n    train_log_loss = np.round(log_loss(Y_train, train_predict_y, labels=clf.classes_, eps=1e-15),3)\n    \n    test_predict_y = sig_clf.predict_proba(X_test)\n    test_log_loss = np.round(log_loss(Y_test, test_predict_y, labels=clf.classes_, eps=1e-15),3)\n    \n    pred_y = sig_clf.predict(X_test.values)\n    miss_class = np.round(np.count_nonzero(100*(pred_y- Y_test['Churn']))/Y_test.shape[0],5)\n    miss_class=miss_class*100\n    \n    test_recall = np.round(recall_score(Y_test['Churn'], pred_y, average='macro'),5)\n    accuracy    = np.round(accuracy_score(Y_test['Churn'], pred_y,),5)\n    precision    = np.round(precision_score(Y_test['Churn'], pred_y,),5)\n    roc_auc      = np.round(roc_auc_score(Y_test['Churn'], pred_y,),5)\n    f1score      = np.round(f1_score(Y_test['Churn'], pred_y,) ,5)\n\n    \n    report=[name,\n            accuracy,\n            test_recall,\n            precision,\n            roc_auc,\n            f1score,\n            train_log_loss,\n            test_log_loss,\n            miss_class]\n    \n    temp_df = pd.DataFrame([report],columns=['Model',\n                                             'accuracy score',\n                                             'recall score',\n                                             'precision score',\n                                             'roc_auc',\n                                             'f1score',\n                                             'train_log_loss',\n                                             'test_log_loss',\n                                             'miss_classified(%)' ])   \n    return temp_df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic Regression\nclf  = LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False)\n\nLogisticReg= model_performance_80_20('LogisticReg',clf,X_train,X_test,Y_train,Y_test)\n\n# XGB\nclf = XGBClassifier(base_score=0.1, booster='gbtree', colsample_bylevel=1,\n                    colsample_bytree=1, gamma=0, learning_rate=0.9, max_delta_step=0,\n                    max_depth = 7, min_child_weight=1, missing=None, n_estimators=100,\n                    n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n                    reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n                    silent=True, subsample=1)\n\nXGB= model_performance_80_20('XGB',clf,X_train,X_test,Y_train,Y_test)\n\n# LightGBM\nclf = LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n                        learning_rate=0.5, max_depth=3, min_child_samples=20,\n                        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n                        n_jobs=-1, num_leaves=500, objective='binary', random_state=None,\n                        reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n                        subsample_for_bin=200000, subsample_freq=0)\nLightGBM= model_performance_80_20('LightGBM',clf,X_train,X_test,Y_train,Y_test)\n\n# Random Forest\nclf = RandomForestClassifier(n_estimators=100,  max_depth=10, criterion='gini',random_state=42, n_jobs=-1)\nRandomForest= model_performance_80_20('RandomForest',clf,X_train,X_test,Y_train,Y_test)\n\n\n# Decision Tree\nclf = DecisionTreeClassifier(max_depth = 5,\n                                   random_state = 123,\n                                   splitter  = \"best\",\n                                   criterion = \"gini\",\n                                  )\nDecisionTree= model_performance_80_20('DecisionTree',clf,X_train,X_test,Y_train,Y_test)\n\nclf = GaussianNB()\nNaiveBase= model_performance_80_20('NaiveBase',clf,X_train,X_test,Y_train,Y_test)\n\n# SVM\nclf  = SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n               decision_function_shape='ovr', degree=3, gamma=1.0, kernel='linear',\n               max_iter=-1, probability=True, random_state=None, shrinking=True,\n               tol=0.001, verbose=False)\n\nSVM= model_performance_80_20('SVM',clf,X_train,X_test,Y_train,Y_test)\n\nall_models_80_20 = pd.concat([DecisionTree,\n                        LogisticReg,\n                        XGB,\n                        LightGBM,\n                        RandomForest,\n                        DecisionTree,\n                             NaiveBase,\n                             SVM])\n\nall_models_80_20 = all_models_80_20.sort_values(by ='miss_classified(%)',ascending=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Testing oversampling via SMOTE method"},{"metadata":{},"cell_type":"markdown","source":"Lets plot target variable data count per training and testing:\n    - Looks like **No Churn** contains 2.5x more entries than **Churn**\n    - In this case, we might not be able to judge the performance of model by accuracy (% misclassified) alone\n    - We have an option of adding more performance metrix (Recall & Precision score)\n    - Or we can introduce different sampling techniques like SMOTE\n    \n    \n    - We are going to do both"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set = []\ntest_set = []\n\ntrain_class_distribution = Y_train['Churn'].value_counts()\ntest_class_distribution = Y_test['Churn'].value_counts()\n\nsorted_train = np.argsort(-train_class_distribution.values)\nsorted_test = np.argsort(-test_class_distribution.values)\n\nfor i in sorted_train:\n    train_set.append(np.round((train_class_distribution.values[i]/telcom_df.shape[0]*100), 3))\nfor i in sorted_test:\n    test_set.append(np.round((test_class_distribution.values[i]/telcom_df.shape[0]*100),3))\n\ndistribution_per_set = pd.DataFrame(\n    {'Train Set(%)': train_set,\n     'Test Set(%)':test_set\n    })\n# Plotting Distribution per class \ndistribution_per_set.index = distribution_per_set.index\ndistribution_per_set.plot.bar(figsize=(12,6))\nplt.xticks(rotation=0)\nplt.title('Distribution of data per set and Target Variable')\nplt.xlabel('Churn')\nplt.ylabel('% Of total data')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**SMOTE - Synthetic Minority Over-sampling Technique**\n* The method is going to over-sample the minority class (No Churn)\n* It is done by altering values of similar records \n* As a result both classes will have the same number of records  "},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\n##seperating dependent and independent variables\nfeatures    = [i for i in telcom_df.columns if i not in Id_features + target_feature]\n\n\nsmote_X = telcom_df[features]\nsmote_Y = telcom_df[target_feature]\n\n#Split train and test data\nsmote_train_X,smote_test_X,smote_train_Y,smote_test_Y = train_test_split(smote_X,smote_Y,\n                                                                         test_size = .25 ,\n                                                                         random_state = 111)\n\n#oversampling minority class using smote\nos = SMOTE(random_state = 0)\nos_smote_X,os_smote_Y = os.fit_sample(smote_train_X,smote_train_Y)\nos_smote_X = pd.DataFrame(data = os_smote_X,columns=features)\nos_smote_Y = pd.DataFrame(data = os_smote_Y,columns=target_feature)\n###","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic Regression\nlogit  = LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False)\n\nLogisticReg_SMOTE= model_performance_80_20('LogisticReg_SMOTE',logit,smote_train_X,smote_test_X,smote_train_Y,smote_test_Y)\n\n# XGB\nclf = XGBClassifier(base_score=0.1, booster='gbtree', colsample_bylevel=1,\n                    colsample_bytree=1, gamma=0, learning_rate=0.9, max_delta_step=0,\n                    max_depth = 7, min_child_weight=1, missing=None, n_estimators=100,\n                    n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n                    reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n                    silent=True, subsample=1)\n\nXGB_SMOTE= model_performance_80_20('XGB_SMOTE',clf,smote_train_X,smote_test_X,smote_train_Y,smote_test_Y)\n\n# LightGBM\nclf = LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n                        learning_rate=0.5, max_depth=3, min_child_samples=20,\n                        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n                        n_jobs=-1, num_leaves=500, objective='binary', random_state=None,\n                        reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n                        subsample_for_bin=200000, subsample_freq=0)\nLightGBM_SMOTE= model_performance_80_20('LightGBM_SMOTE',clf,smote_train_X,smote_test_X,smote_train_Y,smote_test_Y)\n\n# Random Forest\nclf = RandomForestClassifier(n_estimators=100,  max_depth=10, criterion='gini',random_state=42, n_jobs=-1)\nRandomForest_SMOTE= model_performance_80_20('RandomForest_SMOTE',clf,smote_train_X,smote_test_X,smote_train_Y,smote_test_Y)\n\n\n# Decision Tree\nclf = DecisionTreeClassifier(max_depth = 5,\n                                   random_state = 123,\n                                   splitter  = \"best\",\n                                   criterion = \"gini\",\n                                  )\nDecisionTree_SMOTE= model_performance_80_20('DecisionTree_SMOTE',clf,smote_train_X,smote_test_X,smote_train_Y,smote_test_Y)\n\n# Naive Base \nclf = GaussianNB()\nNaiveBase_SMOTE= model_performance_80_20('NaiveBase_SMOTE',clf,smote_train_X,smote_test_X,smote_train_Y,smote_test_Y)\n\n\n# SVM\nclf  = SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n               decision_function_shape='ovr', degree=3, gamma=1.0, kernel='linear',\n               max_iter=-1, probability=True, random_state=None, shrinking=True,\n               tol=0.001, verbose=False)\n\nSVM_SMOTE= model_performance_80_20('SVM_SMOTE',clf,smote_train_X,smote_test_X,smote_train_Y,smote_test_Y)\n\n\nall_models_SMOTE = pd.concat([DecisionTree_SMOTE,\n                        LogisticReg_SMOTE,\n                        XGB_SMOTE,\n                        LightGBM_SMOTE,\n                        RandomForest_SMOTE,\n                        DecisionTree_SMOTE,\n                             NaiveBase_SMOTE,\n                             SVM_SMOTE])\n\nall_models_SMOTE = all_models_SMOTE.sort_values(by ='miss_classified(%)',ascending=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Testing Both Methods"},{"metadata":{"trusted":true},"cell_type":"code","source":"comb_models = pd.concat([all_models_80_20,all_models_SMOTE ]) \n\ncomb_models = comb_models.sort_values(by ='accuracy score',ascending=True)\nx1 = comb_models['accuracy score']\ny1 = comb_models['Model']\ncomb_models = comb_models.sort_values(by ='recall score',ascending=True)\nx2 = comb_models['recall score']\ny2 = comb_models['Model']\ncomb_models = comb_models.sort_values(by ='precision score',ascending=True)\nx3 = comb_models['precision score']\ny3 = comb_models['Model']\n\nfig = plotly.tools.make_subplots(rows=1,cols=3,horizontal_spacing = 0.132)\n\nfig.append_trace(go.Bar(\n            x=x1,\n            y=y1,\n            orientation='h',\n            name = 'Accuracy Score'),1,1)\n\nfig.append_trace(go.Bar(\n            x=x2,\n            y=y2,\n            orientation='h',\n            name = 'Recall Score'),1,2)\n\nfig.append_trace(go.Bar(\n            x=x3,\n            y=y3,\n            orientation='h',\n            name = 'Precision'),1,3)\n\nfig['layout'].update(showlegend=True, title=\"Model performance\" ,\n                     autosize = False,height = 600,width = 1200,\n                     plot_bgcolor = 'rgba(240,240,240, 0.95)',\n                     paper_bgcolor = 'rgba(240,240,240, 0.95)',\n                     )\n\nfig['layout']['xaxis1'].update(title='Accuracy Score')\nfig['layout']['xaxis2'].update(title='Recall Score')\nfig['layout']['xaxis3'].update(title='Precision Score')\n\nfig.layout.update(go.Layout(barmode = 'overlay',title='All Models Performance'))\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Seems like accuracy of most models peaks at ~ 80% \n- Recall score shows some gradual trend across models\n- Surprisingly SMOTE shows no difference in values compared to regular sampling techniques. Is this due to relatively common target variable ratio ? \n\n- We choose Logistic Regression due to relatevily good performance parameters and simplicity of analysis "},{"metadata":{},"cell_type":"markdown","source":"# Performance summary of the best model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def single_model_performance(name,model,X_training,X_testing,Y_training,Y_testing,features):\n    \n    model.fit(X_training.values,Y_training.values)\n    Y_predicted = model.predict(X_testing.values)\n    Y_prob_predicted = model.predict_proba(X_testing.values)\n    \n    # Performace matrices \n    conf_matrix = confusion_matrix(Y_testing,Y_predicted)     \n    precision =(conf_matrix/conf_matrix.sum(axis=0))\n    recall =(((conf_matrix.T)/(conf_matrix.sum(axis=1))).T)\n    \n    model_roc_auc = roc_auc_score(Y_testing,Y_predicted) \n    print (\"Area under curve : \",model_roc_auc,\"\\n\")\n    fpr,tpr,thresholds = roc_curve(Y_testing,Y_prob_predicted[:,1])\n    \n    #coefficients  = pd.DataFrame(algorithm.feature_importances_)\n\n    coeffs  = pd.DataFrame(model.coef_.ravel())    \n    feature_df     = pd.DataFrame(features)\n    coef_sumry    = (pd.merge(coeffs,feature_df,left_index= True,\n                              right_index= True, how = \"left\"))\n    \n    coef_sumry.columns = [\"coefficients\",\"features\"]\n    coef_sumry    = coef_sumry.sort_values(by = \"coefficients\",ascending = False)\n    \n\n    print (\"\\n Classification report : \\n\",classification_report(Y_testing,Y_predicted))\n    \n    # Plotting \n    \n    #Precision Matrix\n    trace1 = go.Heatmap(z=precision,\n                           x=['Not Churn','Churn'],\n                           y=['Not Churn','Churn'], \n                           name = 'Precision',\n                           colorscale = \"Portland\",showscale  = False\n                           )\n\n    #Recall Matrix\n    trace2 = go.Heatmap(z=recall,\n                           x=['Not Churn','Churn'],\n                           y=['Not Churn','Churn'], \n                           name = 'Recall',\n                           colorscale = \"Portland\",showscale  = False)\n   # AUC  \n    trace3 = go.Scatter(x = fpr,\n                        y = tpr, \n                        name = 'ROC'+ str(model_roc_auc),\n                        mode = \"markers\",\n                        marker = dict(color = 'blue',symbol =  \"diamond-open\"))\n    \n    trace4 = go.Scatter(x = [0,1],\n                        y = [0,1],\n                        name=None,\n                        line = dict(color = ('red'),width = 2,\n                        dash = 'dot'))\n\n    \n    # Feature Importance\n    \n    trace5 = go.Bar(x = coef_sumry[\"features\"],\n                    y = coef_sumry[\"coefficients\"],name = \"Feature Importance\")\n\n    fig = plotly.tools.make_subplots(rows=5, cols=2,\n        specs=[[{}, {\"rowspan\": 2}],\n               [{}, None],\n               [{\"rowspan\": 2, \"colspan\": 2}, None],\n               [None, None],\n               [{}, {}]],\n        print_grid=True,subplot_titles=('Precision',\n                                            'Receiver operating characteristic',\n                                            'Recall','Feature Importances'))\n\n    fig.add_trace(trace1,row=1, col=1)\n    fig.add_trace(trace2, row=2, col=1)\n    fig.add_trace(trace3, row=1, col=2)\n    fig.add_trace(trace4, row=1, col=2)\n    fig.add_trace(trace5, row=3, col=1)\n    \n    fig['layout']['xaxis2'].update(title='False PR')\n    fig['layout']['yaxis2'].update(title='True PR')\n    \n    fig['layout'].update(go.Layout(height=800, width=1000, title_text=\"{} Model Performance\".format(name),showlegend=False))\n    py.iplot(fig)\n    \nfeatures = [i for i in telcom_df.columns if i not in Id_features + target_feature]\n\nlogit  = LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False)\n\nsingle_model_performance('Logistic Regression',logit,X_train,X_test,Y_train,Y_test,features)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Extract Important Features:"},{"metadata":{},"cell_type":"markdown","source":"### From Logistic Regression Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [i for i in telcom_df.columns if i not in Id_features + target_feature]\n\nlogit  = LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False)\n\ndef get_features(model,features,X_train,Y_train):\n    \n    model.fit(X_train.values,Y_train.values)\n    \n    coeffs  = pd.DataFrame(model.coef_.ravel())    \n    feature_df     = pd.DataFrame(features)\n    coef_sumry    = (pd.merge(coeffs,\n                              feature_df,\n                              left_index= True,\n                              right_index= True, how = \"left\"))\n    \n    coef_sumry.columns = [\"coefficients\",\"features\"]\n    coef_sumry    = coef_sumry.sort_values(by = \"coefficients\",ascending = False)\n    \n    return coef_sumry\n\nget_features(logit,features,X_train,Y_train).head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Drop Column Method:\n    - Each feature is dropped sequentially and the new model score is compared against benchmark score (difference is taken)\n    - Negative importance means that removing a given feature from the model actually improves the performance"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.base import clone \n\n# Negative importance means that removing a given feature from the model actually improves the performance\ndef drop_col_feat_imp(model, X_train, y_train, random_state = 42):\n    \n    # clone the model to have the exact same specification as the one initially trained\n    model_clone = clone(model)\n    # set random_state for comparability\n    model_clone.random_state = random_state\n    # training and scoring the benchmark model\n    model_clone.fit(X_train, y_train)\n    benchmark_score = model_clone.score(X_train, y_train)\n    # list for storing feature importances\n    importances = []\n    \n    # iterating over all columns and storing feature importance (difference between benchmark and new model)\n    for col in X_train.columns:\n        model_clone = clone(model)\n        model_clone.random_state = random_state\n        model_clone.fit(X_train.drop(col, axis = 1), y_train)\n        drop_col_score = model_clone.score(X_train.drop(col, axis = 1), y_train)\n        importances.append(benchmark_score - drop_col_score)\n    \n    importances_df = pd.DataFrame({'Column':X_train.columns,\n                                   'Importance':importances})\n    return importances_df.sort_values(by = \"Importance\",ascending = False)\n\ndrop_col_feat_imp(logit,X_train,Y_train).head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion:"},{"metadata":{},"cell_type":"markdown","source":"We were able to analyze customer rentention data for telecom company. From EDA we found that services such as **Contract_Month-to-month, InternetService_Fiber optic,  PaymentMethod_Electronic check** suggest a positive correlation to Churn, while **Tenature, Contract_Two_Years, InternetService_No** show negative correlation.\n\nML section helped us evaluate several models which performance was measured by Accuracy, Recall, and Precision scores. SMOTE data preporcessing technique technic showed no significant improvment to all evaluated models. Logistic regression was chosen as a primery model due to its usefullness to this particular domain problem. When optimizing for customer retention logistic regression allows us to access weight coefficients of the given features that can lead us to better decision making. Proposed decision is to increase advertisment budget for additional services since they show positive effect on customer retention."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}