{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"pandas version:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"../input/default-of-credit-card-clients-dataset/UCI_Credit_Card.csv\")\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Get CATEGORICAL data which is represented by int64:","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"sources: \n* https://pbpython.com/categorical-encoding.html=\n\n* https://www.shanelynn.ie/using-pandas-dataframe-creating-editing-viewing-data-in-python/\n\n* https://towardsdatascience.com/categorical-encoding-using-label-encoding-and-one-hot-encoder-911ef77fb5bd","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_df = df.select_dtypes(include=['int64']).copy()\ncat_df = cat_df.drop(columns=\"ID\")#delete ID from categorical data -> not useful\ncat_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. ONE-HOT-ENCODE certain categorical data\n\n\n* replaces i column with multiple columns that will be \"hot\" when rows with a certain status\n* will not one-hot-encode AGE","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"ONE-HOT-ENCODE: \"SEX\",\"MARRIAGE\",\"EDUCATION\",","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"TOO MANY COLUMNS FOR \"EDUCATION\"\n\n->replace certain education statuses due to too many cols ->put all other options into 4 ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_df['EDUCATION'].replace({0: 4, 5: 4, 6: 4}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encode_columns=['SEX','MARRIAGE','EDUCATION']\nfor i in encode_columns:\n    cat_df=pd.get_dummies(cat_df, columns=[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\ncat_df.columns\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ONE-HOT-ENCODE \"PAY_i\":","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_status = np.unique(cat_df[['PAY_0']])\nprint(\"total unique statuses:\", len(unique_status))\nprint(unique_status)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* will get 10-11 new columns per PAY_i with one-hot-encoding because some monthes might have 0 frequency of a payment status/es","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"monthes=['PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']\nfor i in monthes:\n    cat_df=pd.get_dummies(cat_df, columns=[i])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"BIN the AGE feature\n\n5 groups : 21-30 , 31-40 , 40-50 , 50-60 , 60-75\n\nsources:\n\nhttps://medium.com/vickdata/four-feature-types-and-how-to-transform-them-for-machine-learning-8693e1c24e80","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"bins = [21, 30, 40, 50, 60, 76]\ngroup_names = ['21-30', '31-40', '41-50', '51-60', '61-76']\nage_cats = pd.cut(cat_df['AGE'], bins, labels=group_names)\ncat_df['age_cats'] = pd.cut(cat_df['AGE'], bins, labels=group_names)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ONE-HOT-ENCODE the age categories :","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_df=pd.get_dummies(cat_df, columns=['age_cats'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(cat_df.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(cat_df.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Get NUMERICAL data which is represented by float64:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"num_df = df.select_dtypes(include=['float64']).copy()\nnum_df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. ADAPTIVE BINNING: the BILL_AMT cols\n\n\n* we use the data distribution itself to decide our bin ranges\n\n* bill_amts will be put into quantiles\n\nsource: https://towardsdatascience.com/understanding-feature-engineering-part-1-continuous-numeric-data-da4e47099a7b","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"bills=['BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4','BILL_AMT5','BILL_AMT6']\ncol_names=['Q_BILL_AMT1', 'Q_BILL_AMT2', 'Q_BILL_AMT3', 'Q_BILL_AMT4','Q_BILL_AMT5', 'Q_BILL_AMT6']\ni=0#counter \n\nfor col in bills:\n    quantile_list = [0, 0.25, 0.5, 0.75, 1.0]\n    quantile_labels = ['0-25Q', '25-50Q', '50-75Q', '75-100Q']\n    num_df[col_names[i]] = pd.qcut(num_df[col],q=quantile_list,labels=quantile_labels)\n    i+=1\n    \nnum_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. ADAPTIVE BINNING: the PAY_AMT cols AND LIMIT_BAL\nwe use the data distribution itself to decide our bin ranges\n\nPAY_AMT(s) and LIMIT_BAL will be put into quantiles\n\nsource: https://towardsdatascience.com/understanding-feature-engineering-part-1-continuous-numeric-data-da4e47099a7b","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pays=['PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5','PAY_AMT6','LIMIT_BAL']\ncol_names=['Q_PAY_AMT1', 'Q_PAY_AMT2', 'Q_PAY_AMT3','Q_PAY_AMT4','Q_PAY_AMT5','Q_PAY_AMT6','Q_LIMIT_BAL']\ni=0#counter \n\nfor col in pays:\n    quantile_list = [0, 0.25, 0.5, 0.75, 1.0]\n    quantile_labels = ['0-25Q', '25-50Q', '50-75Q', '75-100Q']\n    num_df[col_names[i]] = pd.qcut(num_df[col],q=quantile_list,labels=quantile_labels)\n    i+=1\n    \nnum_df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now the originally numerical columns are categorical columns ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"ONE-HOT-ENCODE the Q_PAY_AMTs , Q_BILL_AMTs, and Q_LIM_BAL","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"encode_columns=['Q_BILL_AMT1', 'Q_BILL_AMT2','Q_BILL_AMT3', 'Q_BILL_AMT4', 'Q_BILL_AMT5', 'Q_BILL_AMT6','Q_PAY_AMT1', 'Q_PAY_AMT2', 'Q_PAY_AMT3','Q_PAY_AMT4','Q_PAY_AMT5','Q_PAY_AMT6','Q_LIMIT_BAL']\nfor i in encode_columns:\n    num_df=pd.get_dummies(num_df, columns=[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(num_df.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"NEW COLUMN: create column that indicates if tuple has payment status >1 in first month and last month\n\n\n* make loop to go thru each PAY_0\n* make col with 0 or 1 that will indicate if condtion in true \n* add to num_df \n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"source:https://stackoverflow.com/questions/32984462/setting-1-or-0-to-new-pandas-column-conditionally","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"num_df['late_payer']=df['PAY_0'].apply(lambda x: 1 if x > 1 else 0)\n\nnum_df['late_payer'].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"NEW COLUMN: create column that indicates if tuple has payed more than BILL_AMT (meaning they have a negative balance)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"bill_mons=['BILL_AMT1','BILL_AMT2','BILL_AMT3','BILL_AMT4','BILL_AMT5','BILL_AMT6']\ncols=['OVER_BILL_AMT1','OVER_BILL_AMT2','OVER_BILL_AMT3','OVER_BILL_AMT4','OVER_BILL_AMT5','OVER_BILL_AMT6']\ni=0#counter\n\nfor mon in bill_mons:\n    num_df[cols[i]]=df[mon].apply(lambda x: 1 if x < 0 else 0)\n    i+=1\n    \nnum_df['OVER_BILL_AMT1'].head()    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"CONCAT ALL DATAFRAMES MADE:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.concat([cat_df, num_df], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.to_csv('mycsvfile.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(data.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"153 columns in all (with target col): next step is creating model with this df ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MAKE copies of dataframe w/o target column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_=data[data.columns[~data.columns.isin(['default.payment.next.month'])]]#already does not have ID","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target=data['default.payment.next.month']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LOGISTIC REGRESSION: \n\nsource: https://www.kaggle.com/mnassrib/titanic-logistic-regression-with-python#4.-Logistic-Regression-and-Results\n\n* this is exact code from the section called \"Logistic Regression and Results\" ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_selection import RFE\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score \nfrom sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve, auc, log_loss\nfrom sklearn import preprocessing\nimport matplotlib.pyplot as plt \n\n# create X (features) and y (response)\nX = data_\ny = target\n\n# use train/test split with different random_state values\n# we can change the random_state values that changes the accuracy scores\n# the scores change a lot, this is why testing scores is a high-variance estimate\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n\n# check classification scores of logistic regression\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\ny_pred = logreg.predict(X_test)\ny_pred_proba = logreg.predict_proba(X_test)[:, 1]\n[fpr, tpr, thr] = roc_curve(y_test, y_pred_proba)\nprint('Train/Test split results:')\nprint(logreg.__class__.__name__+\" accuracy is %2.3f\" % accuracy_score(y_test, y_pred))\nprint(logreg.__class__.__name__+\" log_loss is %2.3f\" % log_loss(y_test, y_pred_proba))\nprint(logreg.__class__.__name__+\" auc is %2.3f\" % auc(fpr, tpr))\n\nidx = np.min(np.where(tpr > 0.95)) # index of the first threshold for which the sensibility > 0.95\n\n#plot\nplt.figure()\nplt.plot(fpr, tpr, color='coral', label='ROC curve (area = %0.3f)' % auc(fpr, tpr))\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot([0,fpr[idx]], [tpr[idx],tpr[idx]], 'k--', color='blue')\nplt.plot([fpr[idx],fpr[idx]], [0,tpr[idx]], 'k--', color='blue')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (1 - specificity)', fontsize=14)\nplt.ylabel('True Positive Rate (recall)', fontsize=14)\nplt.title('Receiver operating characteristic (ROC) curve')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nprint(\"Using a threshold of %.3f \" % thr[idx] + \"guarantees a sensitivity of %.3f \" % tpr[idx] +  \n      \"and a specificity of %.3f\" % (1-fpr[idx]) + \n      \", i.e. a false positive rate of %.2f%%.\" % (np.array(fpr[idx])*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# precision-recall curve\n\nsource: https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# precision-recall curve and f1\nfrom sklearn.datasets import make_classification\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import auc\nfrom matplotlib import pyplot\n\n# split into train/test sets\n# create X (features) and y (response)\nX = data_\ny = target\n\n# use train/test split with different random_state values\n# we can change the random_state values that changes the accuracy scores\n# the scores change a lot, this is why testing scores is a high-variance estimate\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n\n# fit a model\nmodel = LogisticRegression(solver='lbfgs')\nmodel.fit(X_train, y_train)\n# predict probabilities\nlr_probs = model.predict_proba(X_test)\n# keep probabilities for the positive outcome only\nlr_probs = lr_probs[:, 1]\n# predict class values\nyhat = model.predict(X_test)\nlr_precision, lr_recall, _ = precision_recall_curve(y_test, lr_probs)\nlr_f1, lr_auc = f1_score(y_test, yhat), auc(lr_recall, lr_precision)\n# summarize scores\nprint('Logistic: f1=%.3f AUPR=%.3f' % (lr_f1, lr_auc))\n# plot the precision-recall curves\nno_skill = len(y_test[y_test==1]) / len(y_test)\npyplot.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\npyplot.plot(lr_recall, lr_precision, marker='.', label='Logistic')\n# axis labels\npyplot.xlabel('Recall')\npyplot.ylabel('Precision')\n# show the legend\npyplot.legend()\n# show the plot\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"false positive: lots of defaults are being reported when they don't exist actually ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"another source: \n\nhttps://towardsdatascience.com/logistic-regression-detailed-overview-46c4da4303bc#:~:text=Data%20is%20fit%20into%20linear,the%20target%20categorical%20dependent%20variable.&text=To%20predict%20which%20class%20a,probability%20is%20classified%20into%20classes.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# h2o work\nsource: https://h2oai.github.io/tutorials/introduction-to-machine-learning-with-h2o-part-1/#2","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# GLM: H2O Generalized Linear Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import h2o\nh2o.init()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import H2O and other libraries that will be used in this tutorial \nimport matplotlib as plt\n%matplotlib inline\n\n#Import the Estimators\nfrom h2o.estimators.glm import H2OGeneralizedLinearEstimator\nfrom h2o.estimators import H2ORandomForestEstimator\nfrom h2o.estimators.gbm import H2OGradientBoostingEstimator\n\n#Import h2o grid search \nimport h2o.grid \nfrom h2o.grid.grid_search import H2OGridSearch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clus=h2o.H2OFrame(data_)\nclus.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n\nstartup  = '/home/h2o/bin/aquarium_startup'\nshutdown = '/home/h2o/bin/aquarium_stop'\n\nif os.path.exists(startup):\n    os.system(startup)\n    local_url = 'http://localhost:54321/h2o'\n    aquarium = True\nelse:\n    local_url = 'http://localhost:54321'\n    aquarium = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"h2o.init(url=local_url)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"need target column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"orig_data=h2o.import_file(\"../input/default-of-credit-card-clients-dataset/UCI_Credit_Card.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target=orig_data['default.payment.next.month']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clus['default.payment.next.month']=orig_data['default.payment.next.month']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = clus.split_frame([0.8], seed=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"train:%d test:%d\" % (train.nrows,test.nrows))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = 'default.payment.next.month'\n\nignore = [\"default.payment.next.month\"] \n\nx = list(set(train.names) - set(ignore))\n\nprint(x)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"glm = H2OGeneralizedLinearEstimator(family = \"binomial\", seed=42, model_id = 'default_glm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%time glm.train(x = x, y = y, training_frame = train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"glm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"glm.plot(metric='negative_log_likelihood')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"glm.varimp_plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"glm.predict(test).head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"save default performance to compare later on: ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"default_glm_perf=glm.model_performance(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"AUC: \",default_glm_perf.auc())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"ACCURACY: \",default_glm_perf.accuracy())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[threshold, accuracy]","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"F1 score: \",default_glm_perf.F1())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[threshold, f1_score]","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# RANDOM FOREST WITH h2o","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from h2o.model.confusion_matrix import ConfusionMatrix\nrf = H2ORandomForestEstimator (seed=42, model_id='default_rf')\n%time rf.train(x=x, y=y, training_frame=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf.plot(metric='AUTO')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf.varimp_plot(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# GBM:H2OGradientBoostingEstimator","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clus['default.payment.next.month'] = clus['default.payment.next.month'].asfactor()    \n\ntrain,test = clus.split_frame([0.7], seed=42)\n\ny = 'default.payment.next.month'\n\nx = list(set(train.names))\n\ngbm= H2OGradientBoostingEstimator(seed=42, model_id='default_gbm')\n%time gbm.train(x=x, y=y, training_frame=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gbm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"default_gbm_perf=gbm.model_performance(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"default_gbm_perf.accuracy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gbm.varimp_plot(20)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}