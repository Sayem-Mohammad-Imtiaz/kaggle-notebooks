{"cells":[{"metadata":{"id":"opdZZyZ4oxFt","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport datetime\nimport time\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import davies_bouldin_score\n\nimport plotly.offline as py\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, LSTM, Dropout\nfrom tensorflow.keras.losses import MSE","execution_count":null,"outputs":[]},{"metadata":{"id":"gc0qZyC-pAXJ","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"Case = pd.read_csv(\"../input/coronavirusdataset/Case.csv\")\nPatientInfo = pd.read_csv(\"../input/coronavirusdataset/PatientInfo.csv\")\nPatientRoute = pd.read_csv(\"../input/coronavirusdataset/PatientRoute.csv\")\nRegion = pd.read_csv(\"../input/coronavirusdataset/Region.csv\")\nSearchTrend = pd.read_csv(\"../input/coronavirusdataset/SearchTrend.csv\")\nSeoulFloating = pd.read_csv(\"../input/coronavirusdataset/SeoulFloating.csv\")\nTime = pd.read_csv(\"../input/coronavirusdataset/Time.csv\")\nTimeAge = pd.read_csv(\"../input/coronavirusdataset/TimeAge.csv\")\nTimeGender = pd.read_csv(\"../input/coronavirusdataset/TimeGender.csv\")\nTimeProvince = pd.read_csv(\"../input/coronavirusdataset/TimeProvince.csv\")\nWeather = pd.read_csv(\"../input/coronavirusdataset/Weather.csv\")","execution_count":null,"outputs":[]},{"metadata":{"id":"o4HAoiQgqCkQ","colab_type":"text"},"cell_type":"markdown","source":"# First we take a look at patients data\nRemove some not-needed columns then perform our analysis"},{"metadata":{"id":"4fvNY6LapamO","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"p_info = PatientInfo[['patient_id', 'sex', 'age','country',\n                      'province', 'city', 'infection_case', 'infection_order',\n                      'confirmed_date', 'state']]\n\np_info = p_info.fillna(method = 'ffill')\n#Calculatiing exact year of patients\np_info['age'] = PatientInfo['birth_year'].apply(lambda x: 2020 - x)\n\n#Assigning numerical value to all string columns\nsexes = {}\ncountries = {}\nprovinces = {}\ncities = {}\ninfection_cases = {}\nstates = {}\n\n\nfor i in p_info['sex'].unique():\n  key = list(p_info['sex'].unique()).index(i)\n  sexes[key] = i\n\nfor i in p_info['country'].unique():\n  key = list(p_info['country'].unique()).index(i)\n  countries[key] = i\n\nfor i in p_info['province'].unique():\n  key = list(p_info['province'].unique()).index(i)\n  provinces[key] = i\n\nfor i in p_info['city'].unique():\n  key = list(p_info['city'].unique()).index(i)\n  cities[key] = i\n\nfor i in p_info['infection_case'].unique():\n  key = list(p_info['infection_case'].unique()).index(i)\n  infection_cases[key] = i\n\nfor i in p_info['state'].unique():\n  key = list(p_info['state'].unique()).index(i)\n  states[key] = i\n\nfor i in range(0, len(p_info)):\n  p_info.loc[i,'sex'] = (list(sexes.keys())[list(sexes.values()).index(p_info.iloc[i]['sex'])])\n  p_info.loc[i,'country'] = (list(countries.keys())[list(countries.values()).index(p_info.iloc[i]['country'])])\n  p_info.loc[i,'province'] = (list(provinces.keys())[list(provinces.values()).index(p_info.iloc[i]['province'])])\n  p_info.loc[i,'city'] = (list(cities.keys())[list(cities.values()).index(p_info.iloc[i]['city'])])\n  p_info.loc[i,'infection_case'] = (list(infection_cases.keys())[list(infection_cases.values()).index(p_info.iloc[i]['infection_case'])])\n  p_info.loc[i,'state'] = (list(states.keys())[list(states.values()).index(p_info.iloc[i]['state'])])\n\n\np_info['confirmed_date'] = p_info['confirmed_date'].apply(\n    lambda x: time.mktime(\n        datetime.datetime.strptime(str(x), \"%Y-%m-%d\").timetuple()))\n\np_info['age'] = p_info['age'].fillna(method = 'ffill')\n\np_info = p_info.set_index('patient_id')","execution_count":null,"outputs":[]},{"metadata":{"id":"i7Fu66x_wLJP","colab_type":"code","outputId":"7594e7ec-7ad2-4476-e369-73c0e165f05c","colab":{"base_uri":"https://localhost:8080/","height":235},"trusted":true},"cell_type":"code","source":"#Take a look to our new dataset\np_info.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"HzFQadui5H7Y","colab_type":"code","outputId":"97df6454-7cff-44c2-e7eb-85eda9955623","colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":true},"cell_type":"code","source":"#Perform a clustering on our new dataset\nscaler = MinMaxScaler()\nscaler.fit(p_info)\np_info_scaled = scaler.transform(p_info)\n\nkmeans = KMeans(n_clusters=3)\nkmeans.fit(p_info_scaled)\nlabels = kmeans.predict(p_info_scaled)\nprint(\"Davies-Bouldin score for clustering is :{}\".format(davies_bouldin_score(p_info, labels)))","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"code","outputId":"8b9c39be-4bc4-45df-f75c-3df62a25739c","id":"dhLWFpaT-pOj","colab":{"base_uri":"https://localhost:8080/","height":542},"trusted":true},"cell_type":"code","source":"p_info['cluster'] = labels\n# Make the plot\nfig1 = px.parallel_coordinates(p_info, color=\"cluster\")\npy.offline.iplot(fig1)","execution_count":null,"outputs":[]},{"metadata":{"id":"nj3azJnOB_yH","colab_type":"code","outputId":"0c442950-06e6-4551-9e11-fd483db3aab0","colab":{"base_uri":"https://localhost:8080/","height":1000},"trusted":true},"cell_type":"code","source":"from pandas.plotting import scatter_matrix\nscatter_matrix(p_info, alpha=0.2, figsize=(15, 15), diagonal='kde')","execution_count":null,"outputs":[]},{"metadata":{"id":"at7zp-KCFLBx","colab_type":"text"},"cell_type":"markdown","source":"Now we are going to plot some columns based on each cluster"},{"metadata":{"id":"rHcwjGOnFIAS","colab_type":"code","outputId":"20ab1d45-bc44-4c9c-e4da-e8802d0b247c","colab":{"base_uri":"https://localhost:8080/","height":153},"trusted":true},"cell_type":"code","source":"#Plotting based on cluster\np_new = PatientInfo[['patient_id', 'sex', 'age','country',\n                      'province', 'city', 'infection_case', 'infection_order',\n                      'confirmed_date', 'state']]\np_new['cluster'] = labels\n","execution_count":null,"outputs":[]},{"metadata":{"id":"oQoKCqT5Fkyb","colab_type":"code","outputId":"09f8a46d-b5f2-486d-9e63-7e90929220d0","colab":{"base_uri":"https://localhost:8080/","height":763},"trusted":true},"cell_type":"code","source":"temp = p_new[['sex', 'cluster']]\ntemp = temp.fillna('Unknown')\nfig1 = make_subplots(rows=1, cols=3,\n                     specs=[[{'type':'domain'}, {'type':'domain'},\n                             {'type':'domain'}]])\ncol = 1\nfor item in p_new['cluster'].unique():\n  grp = temp[temp['cluster'] == item].groupby(['sex'])\n  print(grp.size())\n  vals = dict(grp.size())\n  sum_val = 0\n  to_plot = {}\n  for key in vals:\n    sum_val += vals[key]\n  for key in vals:\n    to_plot[key] = (vals[key]/sum_val) * 100\n    \n  fig1.add_trace(go.Pie(labels=list(to_plot.keys()),\n                       values=list(to_plot.values()),\n                        name=\"Cluster \" + str(item)),\n                  row=1, col=col)\n  col += 1\n\nfig1.update_layout(title_text=\"Sexes Based on cluster\")\npy.offline.iplot(fig1)","execution_count":null,"outputs":[]},{"metadata":{"id":"F5eo-iqsRwRn","colab_type":"code","outputId":"ff4e77da-0675-4af7-af78-d95cf442877f","colab":{"base_uri":"https://localhost:8080/","height":1000},"trusted":true},"cell_type":"code","source":"temp = p_new[['age', 'cluster']]\ntemp = temp.fillna('Unknown')\nfig1 = make_subplots(rows=1, cols=3,\n                     specs=[[{'type':'domain'}, {'type':'domain'},\n                             {'type':'domain'}]])\ncol = 1\nfor item in p_new['cluster'].unique():\n  grp = temp[temp['cluster'] == item].groupby(['age'])\n  print(grp.size())\n  vals = dict(grp.size())\n  sum_val = 0\n  to_plot = {}\n  for key in vals:\n    sum_val += vals[key]\n  for key in vals:\n    to_plot[key] = (vals[key]/sum_val) * 100\n    \n  fig1.add_trace(go.Pie(labels=list(to_plot.keys()),\n                       values=list(to_plot.values()),\n                        name=\"Cluster \" + str(item)),\n                  row=1, col=col)\n  col += 1\n\nfig1.update_layout(title_text=\"Age Based on cluster\")\npy.offline.iplot(fig1)","execution_count":null,"outputs":[]},{"metadata":{"id":"pEYr2LJdUpXM","colab_type":"code","outputId":"9bc4ee28-0bbb-4c63-e92e-1d2fee3eba94","colab":{"base_uri":"https://localhost:8080/","height":780},"trusted":true},"cell_type":"code","source":"temp = p_new[['country', 'cluster']]\ntemp = temp.fillna('Unknown')\nfig1 = make_subplots(rows=1, cols=3,\n                     specs=[[{'type':'domain'}, {'type':'domain'},\n                             {'type':'domain'}]])\ncol = 1\nfor item in p_new['cluster'].unique():\n  grp = temp[temp['cluster'] == item].groupby(['country'])\n  print(grp.size())\n  vals = dict(grp.size())\n  sum_val = 0\n  to_plot = {}\n  for key in vals:\n    sum_val += vals[key]\n  for key in vals:\n    to_plot[key] = (vals[key]/sum_val) * 100\n    \n  fig1.add_trace(go.Pie(labels=list(to_plot.keys()),\n                       values=list(to_plot.values()),\n                        name=\"Cluster \" + str(item)),\n                  row=1, col=col)\n  col += 1\n\nfig1.update_layout(title_text=\"Countries Based on cluster\")\npy.offline.iplot(fig1)","execution_count":null,"outputs":[]},{"metadata":{"id":"21_rRpOTbsd7","colab_type":"code","outputId":"f99b67dc-4b33-4cda-b5cb-e967e06faf14","colab":{"base_uri":"https://localhost:8080/","height":1000},"trusted":true},"cell_type":"code","source":"temp = p_new[['province', 'cluster']]\ntemp = temp.fillna('Unknown')\nfig1 = make_subplots(rows=1, cols=3,\n                     specs=[[{'type':'domain'}, {'type':'domain'},\n                             {'type':'domain'}]])\ncol = 1\nfor item in p_new['cluster'].unique():\n  grp = temp[temp['cluster'] == item].groupby(['province'])\n  print(grp.size())\n  vals = dict(grp.size())\n  sum_val = 0\n  to_plot = {}\n  for key in vals:\n    sum_val += vals[key]\n  for key in vals:\n    to_plot[key] = (vals[key]/sum_val) * 100\n    \n  fig1.add_trace(go.Pie(labels=list(to_plot.keys()),\n                       values=list(to_plot.values()),\n                        name=\"Cluster \" + str(item)),\n                  row=1, col=col)\n  col += 1\n\nfig1.update_layout(title_text=\"Provinces Based on cluster\")\npy.offline.iplot(fig1)","execution_count":null,"outputs":[]},{"metadata":{"id":"wh2BwJosb42N","colab_type":"code","outputId":"8dff8acb-4f19-413c-980d-357224bc4ba4","colab":{"base_uri":"https://localhost:8080/","height":831},"trusted":true},"cell_type":"code","source":"temp = p_new[['state', 'cluster']]\ntemp = temp.fillna('Unknown')\nfig1 = make_subplots(rows=1, cols=3,\n                     specs=[[{'type':'domain'}, {'type':'domain'},\n                             {'type':'domain'}]])\ncol = 1\nfor item in p_new['cluster'].unique():\n  grp = temp[temp['cluster'] == item].groupby(['state'])\n  print(grp.size())\n  vals = dict(grp.size())\n  sum_val = 0\n  to_plot = {}\n  for key in vals:\n    sum_val += vals[key]\n  for key in vals:\n    to_plot[key] = (vals[key]/sum_val) * 100\n    \n  fig1.add_trace(go.Pie(labels=list(to_plot.keys()),\n                       values=list(to_plot.values()),\n                        name=\"Cluster \" + str(item)),\n                  row=1, col=col)\n  col += 1\n\nfig1.update_layout(title_text=\"States Based on cluster\")\npy.offline.iplot(fig1)","execution_count":null,"outputs":[]},{"metadata":{"id":"dNGV7byUcDZm","colab_type":"code","outputId":"f041bc69-f2ac-461f-9b32-aea2599221b0","colab":{"base_uri":"https://localhost:8080/","height":1000},"trusted":true},"cell_type":"code","source":"temp = p_new[['city', 'cluster']]\ntemp = temp.fillna('Unknown')\nfig1 = make_subplots(rows=1, cols=3,\n                     specs=[[{'type':'domain'}, {'type':'domain'},\n                             {'type':'domain'}]])\ncol = 1\nfor item in p_new['cluster'].unique():\n  grp = temp[temp['cluster'] == item].groupby(['city'])\n  print(grp.size())\n  vals = dict(grp.size())\n  sum_val = 0\n  to_plot = {}\n  for key in vals:\n    sum_val += vals[key]\n  for key in vals:\n    to_plot[key] = (vals[key]/sum_val) * 100\n    \n  fig1.add_trace(go.Pie(labels=list(to_plot.keys()),\n                       values=list(to_plot.values()),\n                        name=\"Cluster \" + str(item)),\n                  row=1, col=col)\n  col += 1\n\nfig1.update_layout(title_text=\"Cities Based on cluster\")\npy.offline.iplot(fig1)","execution_count":null,"outputs":[]},{"metadata":{"id":"HkXvvVXBHvWK","colab_type":"text"},"cell_type":"markdown","source":"**Now we want to visualize original Patient info dataset**\n\nThese visualizations are not based on clusters."},{"metadata":{"id":"Df9H9485cZDX","colab_type":"code","outputId":"34a2d3fb-2b7b-4186-d129-a735fb42bdd6","colab":{"base_uri":"https://localhost:8080/","height":763},"trusted":true},"cell_type":"code","source":"temp = PatientInfo\ntemp = temp.fillna('Unknown')\nfig1 = make_subplots(rows=1, cols=1,\n                     specs=[[{'type':'domain'}]])\ncol = 1\n\ngrp = temp.groupby(['city'])\nprint(grp.size())\nvals = dict(grp.size())\nsum_val = 0\nto_plot = {}\nfor key in vals:\n  sum_val += vals[key]\nfor key in vals:\n  to_plot[key] = (vals[key]/sum_val) * 100\n    \nfig1.add_trace(go.Pie(labels=list(to_plot.keys()),\n                      values=list(to_plot.values()),\n                      name=\"Cities\"),\n                row=1, col=col)\n\nfig1.update_layout(title_text=\"Cities\")\npy.offline.iplot(fig1)","execution_count":null,"outputs":[]},{"metadata":{"id":"EWl6WiunIozb","colab_type":"code","outputId":"2c3a22ff-6448-48ce-80f4-229828480059","colab":{"base_uri":"https://localhost:8080/","height":865},"trusted":true},"cell_type":"code","source":"temp = PatientInfo\ntemp = temp.fillna('Unknown')\nfig1 = make_subplots(rows=1, cols=1,\n                     specs=[[{'type':'domain'}]])\ncol = 1\n\ngrp = temp.groupby(['province'])\nprint(grp.size())\nvals = dict(grp.size())\nsum_val = 0\nto_plot = {}\nfor key in vals:\n  sum_val += vals[key]\nfor key in vals:\n  to_plot[key] = (vals[key]/sum_val) * 100\n    \nfig1.add_trace(go.Pie(labels=list(to_plot.keys()),\n                      values=list(to_plot.values()),\n                      name=\"Provinces\"),\n                row=1, col=col)\n\nfig1.update_layout(title_text=\"Provinces\")\npy.offline.iplot(fig1)","execution_count":null,"outputs":[]},{"metadata":{"id":"uV0yporqJXn_","colab_type":"code","outputId":"2d0b00e8-1a08-4846-c0fd-5a5dba4b0cf3","colab":{"base_uri":"https://localhost:8080/","height":644},"trusted":true},"cell_type":"code","source":"temp = PatientInfo\ntemp = temp.fillna('Unknown')\nfig1 = make_subplots(rows=1, cols=1,\n                     specs=[[{'type':'domain'}]])\ncol = 1\n\ngrp = temp.groupby(['state'])\nprint(grp.size())\nvals = dict(grp.size())\nsum_val = 0\nto_plot = {}\nfor key in vals:\n  sum_val += vals[key]\nfor key in vals:\n  to_plot[key] = (vals[key]/sum_val) * 100\n    \nfig1.add_trace(go.Pie(labels=list(to_plot.keys()),\n                      values=list(to_plot.values()),\n                      name=\"States\"),\n                row=1, col=col)\n\nfig1.update_layout(title_text=\"States\")\npy.offline.iplot(fig1)","execution_count":null,"outputs":[]},{"metadata":{"id":"h2RwCdFXJd3k","colab_type":"code","outputId":"4905cc3b-6afa-4c11-b86b-714c2b2d45d5","colab":{"base_uri":"https://localhost:8080/","height":627},"trusted":true},"cell_type":"code","source":"temp = PatientInfo\ntemp = temp.fillna('Unknown')\nfig1 = make_subplots(rows=1, cols=1,\n                     specs=[[{'type':'domain'}]])\ncol = 1\n\ngrp = temp.groupby(['sex'])\nprint(grp.size())\nvals = dict(grp.size())\nsum_val = 0\nto_plot = {}\nfor key in vals:\n  sum_val += vals[key]\nfor key in vals:\n  to_plot[key] = (vals[key]/sum_val) * 100\n    \nfig1.add_trace(go.Pie(labels=list(to_plot.keys()),\n                      values=list(to_plot.values()),\n                      name=\"Sexes\"),\n                row=1, col=col)\n\nfig1.update_layout(title_text=\"Sexes\")\npy.offline.iplot(fig1)","execution_count":null,"outputs":[]},{"metadata":{"id":"_ok0cpH-KFHa","colab_type":"text"},"cell_type":"markdown","source":"Now we performed some analysis on Patient Info dataset. \n\nThese graphs shows the statistics of patients.\n\nNow we are going to next dataset for analysis."},{"metadata":{"id":"NoVDhMDPJqc8","colab_type":"code","outputId":"58f915b5-19c4-4666-a375-cb0570a46a2d","colab":{"base_uri":"https://localhost:8080/","height":542},"trusted":true},"cell_type":"code","source":"sizes = list(\n    PatientRoute[['longitude', 'latitude']].groupby(\n        ['longitude', 'latitude']).size())\nfig = go.Figure(data=go.Scattergeo(\n        lon = PatientRoute['longitude'],\n        lat = PatientRoute['latitude'],\n        mode = 'markers'\n        ))\nfig.update_layout(\n        title = 'Infected cordinates',\n        geo_scope='asia'\n    )\npy.offline.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"id":"qAHjoU1fZVkC","colab_type":"text"},"cell_type":"markdown","source":"Now we want to perform some analysis on floating population"},{"metadata":{"id":"lrM_r-c8XZyz","colab_type":"code","outputId":"2cb5e77d-7a01-4c51-c9c3-ba55af618a10","colab":{"base_uri":"https://localhost:8080/","height":542},"trusted":true},"cell_type":"code","source":"fp = SeoulFloating[['city', 'fp_num']]\nfp = fp.fillna('Unknown')\nfig1 = make_subplots(rows=1, cols=1,\n                     specs=[[{'type':'domain'}]])\ncol = 1\n\ngrp = fp.groupby(['city'])\nvals = pd.DataFrame(grp.sum().reset_index())\nsum_val = 0\nto_plot = {}\nfor item in vals['fp_num']:\n  sum_val += item\nkey = vals['city']\nfor item in range(len(vals['fp_num'])):\n  key = vals['city'].iloc[item]\n  to_plot[key] = (int(vals['fp_num'].iloc[item])/sum_val) * 100\n    \nfig1.add_trace(go.Pie(labels=list(to_plot.keys()),\n                      values=list(to_plot.values()),\n                      name=\"Cities\"),\n                row=1, col=col)\n\nfig1.update_layout(title_text=\"Cities\")\npy.offline.iplot(fig1)","execution_count":null,"outputs":[]},{"metadata":{"id":"v2gFf-hre615","colab_type":"text"},"cell_type":"markdown","source":"Now we have floating population percentage of whole floating population."},{"metadata":{"id":"rofymcb_crrx","colab_type":"text"},"cell_type":"markdown","source":"Alright, now we want to perform some time series analysis.\n\nWe should define our look back, out lstm and then train it."},{"metadata":{"id":"xHIrFphCdgyc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"cab25058-1728-4513-b684-d9cd06ffd8c5","trusted":true},"cell_type":"code","source":"time_df = Time[['test', 'negative', 'released',\n       'deceased', 'confirmed']]\n\ndef create_dataset(dataset, look_back=1):\n    dataX, dataY = [], []\n    for i in range(len(dataset) - look_back - 1):\n        a = dataset[i:(i + look_back), :]\n        dataX.append(a)\n        dataY.append(dataset[i + look_back, 2])\n    return np.array(dataX), np.array(dataY)\n\ndataset = time_df.values\nscaler = MinMaxScaler(feature_range=(0, 1))\ndataset = scaler.fit_transform(dataset)\ntrain_size = int(len(dataset) * 0.7) \ntest_size = len(dataset) - train_size\ntrain, test = dataset[0:train_size, :], dataset[train_size:len(dataset), :]\n\n\nlook_back = 10\ntrainX, trainY = create_dataset(train, look_back)  \ntestX, testY = create_dataset(test, look_back)\n\ntrainX = np.reshape(trainX, (trainX.shape[0], look_back, 5))\ntestX = np.reshape(testX, (testX.shape[0],look_back, 5))\n\n\nmodel = Sequential()\nmodel.add(LSTM(5, return_sequences=True, input_shape=(look_back, 5)))\nmodel.add(LSTM(5, return_sequences=True, input_shape=(look_back, 5)))\nmodel.add(LSTM(5, return_sequences=True, input_shape=(look_back, 5)))\nmodel.add(LSTM(5, return_sequences=True, input_shape=(look_back, 5)))\nmodel.add(LSTM(5, input_shape=(look_back, 5)))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='sgd')\nhistory= model.fit(trainX, trainY, validation_split=0.33, nb_epoch=200,\n                   batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{"id":"8vLc1HWepLgZ","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#Make new prediction\nlook_back = 10\nx, y = create_dataset(dataset, look_back)\nx = np.reshape(x, (x.shape[0], look_back, 5))\n\npredicted = model.predict(x)","execution_count":null,"outputs":[]},{"metadata":{"id":"00lE3E2XuiIN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":542},"outputId":"e922b81c-44d9-46ef-e004-2e99d909204c","trusted":true},"cell_type":"code","source":"fig = go.Figure()\nfig.add_trace(go.Scatter(x=Time['date'], y=y,\n                    mode='lines',\n                    name='Original'))\nfig.add_trace(go.Scatter(x=Time['date'], y=predicted.reshape(y.shape),\n                    mode='lines',\n                    name='Predicted'))\npy.offline.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"id":"2a5XDTETvyh9","colab_type":"text"},"cell_type":"markdown","source":"We see that the predition is very unstable and wrong. It can be improved by changing lstm layers, adding activation and especially more samples. Here, we just wanted to make a simple prediction."},{"metadata":{"id":"rxOBcYfEtqB5","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"DS4C Visualiziation and prediction.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":4}