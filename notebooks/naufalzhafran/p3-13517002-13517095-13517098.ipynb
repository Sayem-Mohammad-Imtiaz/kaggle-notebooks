{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Informasi Data\n\nhttps://www.kaggle.com/paresh2047/uci-semcom"},{"metadata":{},"cell_type":"markdown","source":"**UCI SECOM Dataset**\n\n\nSemiconductor manufacturing process dataset\n\n\nData Structure: The data consists of 2 files the dataset file SECOM consisting of 1567 examples each with 591 features a 1567 x 591 matrix and a labels file containing the classifications and date time stamp for each example.\n\n\nAs with any real life data situations this data contains null values varying in intensity depending on the individuals features. This needs to be taken into consideration when investigating the data either through pre-processing or within the technique applied.\n\n\nThe data is represented in a raw text file each line representing an individual example and the features seperated by spaces. The null values are represented by the 'NaN' value as per MatLab."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport warnings\nwarnings.simplefilter(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataset Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset=pd.read_csv(\"../input/uci-semcom/uci-secom.csv\")\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d = dataset.isnull().sum()\nj = []\nfor i in d.keys():\n    if(d[i] >900):\n        print(i, d[i])\n        j.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.drop(j, axis = 1, inplace = True)\ndataset.replace(np.nan, 0, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dataset Separation"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=dataset.drop(['Pass/Fail','Time'],axis=1) #Predictors\ny=dataset['Pass/Fail'] #Response\nX.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training and Test Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Scoring Function"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_predict, cross_val_score\nfrom sklearn.metrics import confusion_matrix,classification_report,accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_score(classifier,X_train,y_train,X_test,y_test,train=True):\n    if train == True:\n        print(\"Training results:\\n\")\n        print('Accuracy Score: {0:.4f}\\n'.format(accuracy_score(y_train,classifier.predict(X_train))))\n        print('Classification Report:\\n{}\\n'.format(classification_report(y_train,classifier.predict(X_train))))\n        print('Confusion Matrix:\\n{}\\n'.format(confusion_matrix(y_train,classifier.predict(X_train))))\n        res = cross_val_score(classifier, X_train, y_train, cv=10, n_jobs=-1, scoring='accuracy')\n        print('Average Accuracy:\\t{0:.4f}\\n'.format(res.mean()))\n        print('Standard Deviation:\\t{0:.4f}'.format(res.std()))\n    elif train == False:\n        print(\"Test results:\\n\")\n        print('Accuracy Score: {0:.4f}\\n'.format(accuracy_score(y_test,classifier.predict(X_test))))\n        print('Classification Report:\\n{}\\n'.format(classification_report(y_test,classifier.predict(X_test))))\n        print('Confusion Matrix:\\n{}\\n'.format(confusion_matrix(y_test,classifier.predict(X_test))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier as DT\n\nclassifier = DT(criterion='entropy',random_state=42)\nclassifier.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_score(classifier,X_train,y_train,X_test,y_test,train=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Selection"},{"metadata":{},"cell_type":"markdown","source":"## Filter - ANOVA"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest, f_classif","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Memilih fitur terbaik\n\nselected = SelectKBest(score_func=f_classif, k=10)\nanova_fit = selected.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.set_printoptions(precision=3)\nprint(anova_fit.scores_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Elemen dari array di atas merupakan nilai evaluasi dari semua atribut atau fitur yang ada pada dataset. Nilai yang lebih tinggi menandakan bahwa fitur tersebut relatif lebih bermakna daripada fitur lainnya, sehingga akan lebih diprioritaskan untuk dipilih. Akan dipilih 10 fitur terbaik dalam implementasi feature selection berdasarkan perhitungan ANOVA."},{"metadata":{"trusted":true},"cell_type":"code","source":"features_columns = np.empty((0, 0))\n\nfor i in (np.argsort(anova_fit.scores_)[::-1]):\n    if (not np.isnan(anova_fit.scores_[i])):\n        features_columns = np.append(features_columns, i)\n        \nprint(features_columns[:10])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hasil di atas adalah kolom index dari 10 fitur yang paling penting dari dataset ini. Sementara berikut ini adalah sampel 5 data pertama yang sudah disaring memanfaatkan hanya 10 fitur tersebut."},{"metadata":{"trusted":true},"cell_type":"code","source":"features_by_anova = anova_fit.transform(X_train)\nprint(features_by_anova[0:5,:])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Embedded - Ridge"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Ridge","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ridge = Ridge(alpha=1.0)\nridge.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pretty_print_coefs(coefs, names = None, sort = False):\n    if names == None:\n        names = [\"X%s\" % x for x in range(len(coefs))]\n    lst = zip(coefs, names)\n    if sort:\n        lst = sorted(lst,  key = lambda x:-np.abs(x[0]))\n    return \" + \".join(\"%s * %s\" % (round(coef, 3), name) for coef, name in lst)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Ridge model:\", pretty_print_coefs(ridge.coef_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Diperoleh koefisien untuk setiap fitur dari algoritma seleksi Ridge. Regresi Ridge menghasilkan L2-Regularization. Apabila ditemukan beberapa fitur yang memiliki nilai koefisien cukup dekat, maka fitur-fitur memiliki hubungan yang berpengaruh pada dataset. Untuk fitur-fitur yang memperoleh koefisien negatif, berarti fitur tersebut tidak berpengaruh banyak dan bisa dieliminasi sesuai tujuan feature selection."},{"metadata":{},"cell_type":"markdown","source":"## Perbandingan Feature Selection\n\nPenggunaan ridge regression (embedded) memerlukan analisis lebih untuk seleksi fitur yang ada dan mengonsumsi waktu yang lebih lama dibandingkan ANOVA (filter). Membutuhkan percobaan algoritma lainnya untuk memperoleh metode feature selection yang lebih ideal."},{"metadata":{},"cell_type":"markdown","source":"# Feature Extraction"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## PCA"},{"metadata":{},"cell_type":"markdown","source":"Langkah awal perlu dilakukan standardisasi terlebih dahulu terhadap fitur pada data. Hal tersebut disebabkan data dengan range yang lebih besar dapat mendominasi data dengan range yang lebih kecil sehingga hasil menjadi bias"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_std = StandardScaler().fit_transform(X_train)\nX_test_std = StandardScaler().fit_transform(X_test)\nX_std = StandardScaler().fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initializing PCA and fitting\n# Choose minimum number of PCA features such that 85% variance is retained to avoid overfitting\npca = PCA(0.85)\npca.fit(X_std)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Variance of each component:', pca.explained_variance_ratio_)\nprint('\\nTotal features:', pca.n_components_)\nprint('Total Variance Explained:', round(sum(list(pca.explained_variance_ratio_))*100, 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transform train and test datasets\nX_train_pca = pca.transform(X_train_std)\nX_test_pca = pca.transform(X_test_std)\n\nprint('X_train_pca shape:', X_train_pca.shape)\nprint('X_test_pca shape:', X_test_pca.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Selanjutnya, dilakukan training menggunakan data train PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier as DT\n\nclassifier = DT(criterion='entropy',random_state=42)\nclassifier.fit(X_train_pca,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_score(classifier,X_train_pca,y_train,X_test_pca,y_test,train=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## LDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n\nlda = LinearDiscriminantAnalysis()\n\nlda.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transform train and test datasets\nX_train_lda = lda.transform(X_train)\nX_test_lda = lda.transform(X_test)\n\nprint('X_train_lda shape:', X_train_lda.shape)\nprint('X_test_lda shape:', X_test_lda.shape)\nprint('Variance of each component:', lda.explained_variance_ratio_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Selanjutnya, dilakukan training menggunakan data train PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier as DT\n\nclassifier = DT(criterion='entropy',random_state=42)\nclassifier.fit(X_train_lda,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_score(classifier,X_train_lda,y_train,X_test_lda,y_test,train=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Pembagian Kerja\n\n1. 13517002 - Isa : Feature Extraction\n2. 13517095 - Naufal : Data preprocessing, baseline model\n3. 13517098 - Anzaldi : Feature Selection"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}