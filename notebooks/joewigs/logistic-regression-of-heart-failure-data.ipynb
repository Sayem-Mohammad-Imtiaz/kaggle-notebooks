{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1><center>Logistic Regression to predict death in heart failure patients</center></h1>\n\nObjectives: The objective of this exercise is to use a Logistic Regression machine learning algorithm to define the likelhood of survival of a heart failure patient.  The dataset used for the analysis can be found here: https://www.kaggle.com/andrewmvd/heart-failure-clinical-data. This dataset provides a comprehensive snapshot of the factors that require consideration when trying to predict the outcome of heart failure.","metadata":{"id":"tnJgRltlz3bG"}},{"cell_type":"code","source":"import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom matplotlib import pyplot as plt\nimport statistics\nimport itertools\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","id":"zpMLmOOYz3bM","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Methods: The necessary datasets were imported for analysis. The death even data were separated from the rest of the data allowing the death event column to be used for predictions and testing of the proposed model. The time column was also removed, as it refers to the time from the last follow up until death and is therefore not a predictor. The first 5 rows of the whole dataset were printed out so that the different parameters avaiaible can be easily reviewed.","metadata":{"id":"0NgnCRodz3bP"}},{"cell_type":"code","source":"df = pd.read_csv('../input/heart-failure-clinical-data/heart_failure_clinical_records_dataset.csv')\ndied = df['DEATH_EVENT']\nall_features = df.drop(['DEATH_EVENT', 'time'], axis=1)\ndf.head()","metadata":{"id":"xhNQ0mSBz3bP","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next, the model was trained on on every column of the dataset.  The data was split 80/20 into training and testing sets respectively, with all data scaled so the model doesnt over emphasise one factor, for example the platelets column, which has very large numbers compared to the rest. The model was then trained and tested, with the desired outcome being a score as close to 1 as possible, where a score of 1 which indicates the model was entirely predictave.","metadata":{"id":"chjOPysez3bQ"}},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(all_features, died, test_size=0.2, random_state=10)\nscaler = StandardScaler()\nx_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test)\nmodel = LogisticRegression()\nmodel.fit(x_train, y_train)\nall_score = model.score(x_test, y_test)\n\nprint(all_score)","metadata":{"id":"pkiI3w-nz3bR","executionInfo":{"status":"ok","timestamp":1617864410315,"user_tz":-60,"elapsed":2021,"user":{"displayName":"Joe Wignell","photoUrl":"","userId":"08326053059241561256"}},"outputId":"9bcabfcf-119c-4667-c40b-b1efbf8b2858","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Results test 1: The model was found to be 66.67% accurate, which was not much of an improvement over guessing! Further optimisation is required. To facilitate this, a graph was prepared visualising the coefficients of each variable (see below).  This will demonstrate how much each variable is influencing the model allowing their importance to be determined.","metadata":{"id":"bg9YFAtRz3bT"}},{"cell_type":"code","source":"coefs = model.coef_\ncoefs = coefs[0]\ncoefsabs = abs(coefs)\nlabels = all_features.columns.values\nlabelsspace = [i.replace('_', ' ') for i in labels]\nplt.figure(figsize=(18, 13))\nax = plt.subplot()\nplt.barh(range(len(coefsabs)), coefsabs)\nax.set_yticks(range(len(coefs)))\nax.set_yticklabels(labelsspace, fontsize=20)\nplt.title('Coefficients for Variables in current model', fontsize=30)\nplt.show()","metadata":{"id":"j165Hlwtz3bU","executionInfo":{"status":"ok","timestamp":1617864410317,"user_tz":-60,"elapsed":2012,"user":{"displayName":"Joe Wignell","photoUrl":"","userId":"08326053059241561256"}},"outputId":"740211ad-70d2-4017-a8c0-1354babe5115","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Following review of the graph, variables which were demonstrated as having very little effect on outcome were removed to investigate whether this improved the accuaracy of the proposed model. Once removed, the model was re trained and tested, with print outs collected for this new model and the old one with every variable included. The new model gave a result of 71.66%, a slight improvement over the original score.","metadata":{"id":"qqxlYlduz3bV"}},{"cell_type":"code","source":"new_features = all_features.drop(['platelets', 'smoking', 'diabetes'], axis=1)\nx_train, x_test, y_train, y_test = train_test_split(new_features, died, test_size=0.2, random_state=10)\nx_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test)\nmodel.fit(x_train, y_train)\nprint('new model: ', model.score(x_test, y_test))\nprint('all features: ', all_score)","metadata":{"id":"wldxJwJ2z3bW","executionInfo":{"status":"ok","timestamp":1617864410318,"user_tz":-60,"elapsed":1999,"user":{"displayName":"Joe Wignell","photoUrl":"","userId":"08326053059241561256"}},"outputId":"75963b7f-fbc8-444a-c1ba-98ff9c2547ca","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Discussion: It is clear that removing some variables led to an improvement in the model performance, however how can the proposed model be otimised further?  Below is a block of code which will train and test the model on every single combination of the variables we have.  It runs the train and test over 4000 times so it may take a couple of minutes.  Afterwards it will print out the best score it could get along with the largest and smallest list of variables that will achieve that score.  Often the same score can result from different combinations of variables.","metadata":{"id":"DTrBhodbz3bX"}},{"cell_type":"code","source":"best_features = []\nbest_most_features = []\nbest_score = 0\nscores = {}\nscoreslist = []\nfor i in range(1, (len(labels))):\n  combos = list(itertools.combinations(labels, i))\n  for i in combos:\n    brand_new_features = all_features[list(i)]\n    x_train, x_test, y_train, y_test = train_test_split(brand_new_features, died, test_size=0.2, random_state=10)\n    x_train = scaler.fit_transform(x_train)\n    x_test = scaler.transform(x_test)\n    model.fit(x_train, y_train)\n    score = model.score(x_test, y_test)\n    scores[score] = list(i)\n    scoreslist.append(score)\n    if score > best_score:\n        best_score = score\n        best_features = list(i)\n    if score == best_score:\n        best_most_features = list(i)\n        \nprint('Best Score =', best_score)\nprint('Shortest List of Features =', best_features)\nprint('Longest List of Features =', best_most_features)","metadata":{"id":"oM_Rxwfgz3bZ","executionInfo":{"status":"ok","timestamp":1617864428580,"user_tz":-60,"elapsed":20251,"user":{"displayName":"Joe Wignell","photoUrl":"","userId":"08326053059241561256"}},"outputId":"46393db3-7ef3-4210-d61d-aa63fc1c2a42","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"According to my code you can get an 80% accurate prediction for the outcome of a heart failure patient with just their age and whether they have high blood pressure or not.  If we look at the last graph these have lower coefficients than some other variables.  Perhaps working with a larger dataset would gleen more information.  The 2 highest coefficients are serum creatinine and ejection franction.  Maybe I could put them one on one against age and high blood pressure in ranomised tests to see if either is better.  I will run my model on randomised splits of the data 100 times and then print the mean result of each set of variables.","metadata":{"id":"Stumj4uvz3ba"}},{"cell_type":"code","source":"scores_age = []\nscores_serum = []\ni = 0\n\nwhile i < 100:\n  age_and_pressure = all_features[['age', 'high_blood_pressure']]\n  x_train, x_test, y_train, y_test = train_test_split(age_and_pressure, died, test_size=0.2)\n  x_train = scaler.fit_transform(x_train)\n  x_test = scaler.transform(x_test)\n  model.fit(x_train, y_train)\n  scores_age.append(model.score(x_test, y_test))\n\n  serum_and_ejection = all_features[['serum_creatinine', 'ejection_fraction']]\n  x_train, x_test, y_train, y_test = train_test_split(serum_and_ejection, died, test_size=0.2)\n  x_train = scaler.fit_transform(x_train)\n  x_test = scaler.transform(x_test)\n  model.fit(x_train, y_train)\n  scores_serum.append(model.score(x_test, y_test))\n  i += 1\n\nprint('Mean score for age and blood pressure: ', statistics.mean(scores_age))\nprint('Mean score for serum creatinine and ejection fraction: ', statistics.mean(scores_serum))\n","metadata":{"id":"25a96JZvz3bc","executionInfo":{"status":"ok","timestamp":1617864430662,"user_tz":-60,"elapsed":22323,"user":{"displayName":"Joe Wignell","photoUrl":"","userId":"08326053059241561256"}},"outputId":"6e1f8832-9886-4298-9a66-cad9aceedfd7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As this is randomised you will be seeing different numbers from me now but after a few runs it appears that serum creatinine and ejection fraction is about 5% more accurate, with a score of 74.73% versus 70.03% for age and blood pressure alone. It seems the 80% we got before was a complete outlier, which is why data anaylsis shoud be repeated multiple times.  I have written code below which will train and test the model on each combination of variables 10 times and compare the mean scores to find out which features produce optimum results.  ","metadata":{"id":"-uDF5iZwz3be"}},{"cell_type":"code","source":"best_features = []\nbest_most_features = []\nbest_score = 0\nscores = {}\n\nfor i in range(1, (len(labels))):\n  combos = list(itertools.combinations(labels, i))\n  for i in combos:\n    brand_new_features = all_features[list(i)]\n    scoreslist = []\n    j=0\n    while j < 10:\n      x_train, x_test, y_train, y_test = train_test_split(brand_new_features, died, test_size=0.2)\n      x_train = scaler.fit_transform(x_train)\n      x_test = scaler.transform(x_test)\n      model.fit(x_train, y_train)\n      score = model.score(x_test, y_test)\n      scoreslist.append(score)\n      j += 1\n    mean_score = statistics.mean(scoreslist) \n    if mean_score > best_score:\n      best_score = mean_score\n      best_features = list(i)\n    if mean_score == best_score:\n      best_most_features = list(i)\n\nprint('Best Score =', best_score)\nprint('Shortest List of Features =', best_features)\nprint('Longest List of Features =', best_most_features)","metadata":{"id":"I_SyVryVer4G","executionInfo":{"status":"ok","timestamp":1617864579186,"user_tz":-60,"elapsed":170837,"user":{"displayName":"Joe Wignell","photoUrl":"","userId":"08326053059241561256"}},"outputId":"2d4b366c-abc8-4897-9dcc-5f7ebc0323a9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So after running that code on a gpu accelerated notebook I can confirm that using age, ejection fraction, high blood pressure and serum creatinine to train the model you can get an acuracy of 80%.  I believe a larger study with more data would be needed before you could implement anything like this and I would reccommend adjusting the classification threshold in a clinical seitting in order to create more false positives.  In this case the cost of a false negative, is in my opinion, worth skewing the model to be less accurate.","metadata":{"id":"ZjVq31x7Tymp"}}]}