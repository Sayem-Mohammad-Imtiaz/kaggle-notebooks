{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pyspark","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Turning on intellisense in the notebook\n%config Completer.use_jedi = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pyspark import SparkConf, SparkContext\nfrom pyspark.sql import SparkSession, SQLContext\n\nfrom pyspark.sql.types import *\nimport pyspark.sql.functions as F\nfrom pyspark.sql.functions import udf, col\n\nfrom pyspark.ml.regression import LinearRegression\nfrom pyspark.mllib.evaluation import RegressionMetrics\n\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator, CrossValidatorModel\nfrom pyspark.ml.feature import VectorAssembler, StandardScaler\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Visualization\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n\npd.set_option('display.max_columns', 200)\npd.set_option('display.max_colwidth', 400)\n\nfrom matplotlib import rcParams\nsns.set(context='notebook', style='whitegrid', rc={'figure.figsize': (18,4)})\nrcParams['figure.figsize'] = 18,4\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\n# setting random seed for notebook reproducability\nrnd_seed=23\nnp.random.seed=rnd_seed\nnp.random.set_state=rnd_seed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spark = SparkSession.builder.master(\"local[2]\").appName(\"Used-cars-data-wrangling\").getOrCreate()\nspark","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load The Data From a File Into a Dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"USED_CAR_DATA = '/kaggle/input/craigslist-carstrucks-data/vehicles.csv'\n# define the schema, corresponding to a line in the csv data file.\nschema = StructType([StructField(\"id\", LongType(), nullable=True),\n StructField(\"linkurl\", StringType(), nullable=True),\n StructField(\"text_formatregion\", StringType(), nullable=True),\n StructField(\"linkregion_url\", StringType(), nullable=True),\n StructField(\"grid_3x3price\", FloatType(), nullable=True),\n StructField(\"grid_3x3year\", IntegerType(), nullable=True),\n StructField(\"text_formatmanufacturer\", StringType(), nullable=True),\n StructField(\"text_formatmodel\", StringType(), nullable=True),\n StructField(\"text_formatcondition\", StringType(), nullable=True),\n StructField(\"text_formatcylinders\", StringType(), nullable=True),\n StructField(\"text_formatfuel\", StringType(), nullable=True),\n StructField(\"grid_3x3odometer\",IntegerType(), nullable=True),\n StructField(\"text_formattitle_status\", StringType(), nullable=True),\n StructField(\"text_formattransmission\", StringType(), nullable=True),\n StructField(\"text_formatVIN\", StringType(), nullable=True),\n StructField(\"text_formatdrive\", StringType(), nullable=True),\n StructField(\"text_formatsize\", StringType(), nullable=True),\n StructField(\"text_formattype\", StringType(), nullable=True),\n StructField(\"text_formatpaint_color\", StringType(), nullable=True),\n StructField(\"linkimage_url\", StringType(), nullable=True),\n StructField(\"text_formatdescription\", StringType(), nullable=True),\n StructField(\"text_formatstate\", StringType(), nullable=True),\n StructField(\"navigationlat\", StringType(), nullable=True),\n StructField(\"grid_3x3long\", IntegerType(), nullable=True),\n StructField(\"calendar_todayposting_date\", StringType(), nullable=True)\n    ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cars_df =spark.read.format('csv').options(header='true').options(delimiter=',').load(USED_CAR_DATA).cache()\n#cars_df.describe()\ncars_df.show(20)\ncars_df.printSchema()\ncars_df.select('region','price','year','manufacturer','model','condition','cylinders', 'fuel','odometer','title_status', 'transmission','drive','size', 'state', \n               'type', 'paint_color', 'posting_date','image_url').show(10)\ncars_df.count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# group by condition and see the distribution\nresult_df = cars_df.groupBy(\"condition\").count().sort(\"condition\", ascending=False)\nresult_df.show(101)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Filtering only the cars where the condition is in the list [\"good\", \"fair\", \"excellent\", \"new\", \"like new\", \"salvage\"] and add the Null rows as well"},{"metadata":{"trusted":true},"cell_type":"code","source":"conditions = [\"good\", \"fair\", \"excellent\", \"new\", \"like new\", \"salvage\"]\ncondition_result_not_null_df = cars_df.where(cars_df.condition.isin(conditions) )\ncondition_result_not_null_df.show(10)\ncondition_result_not_null_df.count()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# condition_result_null_df = cars_df.where(cars_df.condition is Nul)\ncondition_result_null_df = cars_df.filter(\"condition is NULL\")\ncondition_result_null_df.count()\n\ncondition_result_df = condition_result_null_df.union(condition_result_not_null_df)\ncondition_result_df.count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# manufacturer_df = cars_df.groupBy(\"manufacturer\").count().sort(\"manufacturer\", ascending=True)\n# manufacturer_df = condition_result_df.groupBy(\"manufacturer\").count().sort(\"manufacturer\", ascending=True)\nmanufacturer_list = ['alfa-romeo', 'aston-martin', 'audi', 'bmw', 'buick', 'cadillac', 'chevrolet', 'chrysler', 'datsun','dodge','ferrari','fiat','ford','gmc', 'harley-davidson','hennessey',\n'honda','hyundai','infiniti','jaguar','jeep', 'kia','land rover', 'lexus','lincoln','mazda', 'mercedes-benz','mercury','mini','mitsubishi','morgan',\n'nissan','pontiac','porsche','ram','rover','saturn','subaru','tesla','toyota','volkswagen','volvo'\n]\n\n# 'price', 'year' - Numeric \n# 'manufacturer', 'condition', 'cylinders','fuel', 'odometer', 'transmission','drive', 'type', 'paint_color' - Categorical\n\nmanufacturer_df = cars_df.where(cars_df.manufacturer.isin(manufacturer_list)  ).cache()\n#manufacturer_null_df = manufacturer_df.filter(\"manufacturer is NULL\")\n#manufacturer_not_null_df\n#manufacturer_not_null_df.count()\n\nmanufacturer_df.show(10)\n#manufacturer_df = manufacturer_not_null_df.union(manufacturer_null_df)\nmanufacturer_df.count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"manufacturer_df_list = manufacturer_df.groupBy(\"manufacturer\").count().sort(\"manufacturer\", ascending=True)\nmanufacturer_df_list.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What car is most popular?"},{"metadata":{"trusted":true},"cell_type":"code","source":"manufacturer_df_list.toPandas().plot.bar(x='manufacturer',figsize=(18, 6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate summary statistics\n# manufacturer_df.describe().show()\n#Statistics.colStats(manufacturer_df)\n\n(manufacturer_df.describe().select(\n                    \"summary\",\n                    F.round(\"price\", 2).alias(\"price\"),\n                    F.round(\"year\", 0).alias(\"year\"),\n                    F.round(\"odometer\", 0).alias(\"odometer\"),\n                    F.round(\"lat\", 2).alias(\"lat\"),\n                    F.round(\"long\", 2).alias(\"long\"))\n                    .show())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cylinders_df = manufacturer_df.groupBy(\"cylinders\").count().sort(\"cylinders\", ascending=False)\ncylinders_df = cylinders_df.na.fill(\"None\")\n#cylinders_df.show()\ncylinders_df.toPandas().plot.bar(x='cylinders',figsize=(14, 6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fuel_df = manufacturer_df.groupBy(\"fuel\").count().sort(\"fuel\", ascending=False)\nfuel_df = fuel_df.na.fill(\"None\")\nfuel_df.show()\nfuel_df.count()\nfuel_df.toPandas().plot.bar(x='fuel',figsize=(14, 6))\n\ntransmission_df = manufacturer_df.groupBy(\"transmission\").count().sort(\"transmission\", ascending=False)\ntransmission_df = transmission_df.na.fill(\"None\")\ntransmission_df.show()\ntransmission_df.count()\ntransmission_df.toPandas().plot.bar(x='transmission',figsize=(14, 6))\n\npaint_color_df = manufacturer_df.groupBy(\"paint_color\").count().sort(\"paint_color\", ascending=False)\npaint_color_df = paint_color_df.na.fill(\"None\")\npaint_color_df.show()\npaint_color_df.count()\npaint_color_df.toPandas().plot.bar(x='transmission',figsize=(14, 6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"title_df = manufacturer_df.groupBy(\"title_status\").count().sort(\"title_status\", ascending=False)\ntitle_df = title_df.na.fill(\"None\")\ntitle_df.show()\ntitle_df.toPandas().plot.bar(x='title_status',figsize=(14, 6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Only use the cars with clean titles\ntitle_df = manufacturer_df.where(manufacturer_df.title_status.isin('clean') ).cache()\ntitle_df.count()\n\nmanufacturer_df.unpersist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drive_df = title_df.groupBy(\"drive\").count().sort(\"drive\", ascending=False)\ndrive_df = drive_df.na.fill(\"None\")\ndrive_df.show()\ndrive_df.toPandas().plot.bar(x='drive',figsize=(14, 6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# size|  type and state\nsize_df = title_df.groupBy(\"size\").count().sort(\"size\", ascending=False)\nsize_df = size_df.na.fill(\"None\")\nsize_df.show()\nsize_df.toPandas().plot.bar(x='size',figsize=(14, 6))\n\ntype_df = title_df.groupBy(\"type\").count().sort(\"type\", ascending=False)\ntype_df = type_df.na.fill(\"None\")\ntype_df.show()\ntype_df.toPandas().plot.bar(x='type',figsize=(14, 6))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This is the state of the car like in the features built in the car.\n\nregion_df = title_df.groupBy(\"region\").count().sort(\"count\", ascending=False)\nregion_df = region_df.na.fill(\"None\")\nregion_df.show(405)\n# region_df.count() -- 405\nregion_df.limit(100).toPandas().plot.bar(x='region',figsize=(38, 6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"price_df = title_df.groupBy(\"price\").count().sort(\"price\", ascending=False)\nprice_df = price_df.na.replace(\"None\")\nprice_df[price_df==\"None\"]\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"manufacturer_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#. Modelling\n\n# Linear regression - hand code []\n# 'region' , 'price', 'year', 'manufacturer','model', 'condition', 'cylinders','fuel', 'odometer', |title_status|transmission|              VIN|drive|     size|  type|paint_color|           image_url|         description|state|      lat|       long|        posting_date|\n\n# Pick only these :\n# 'price', 'year', 'manufacturer', 'condition', 'cylinders','fuel', 'odometer', 'transmission','drive', 'type', 'paint_color'\n\nmanufacturer_list = ['alfa-romeo', 'aston-martin', 'audi', 'bmw', 'buick', 'cadillac', 'chevrolet', 'chrysler', 'datsun','dodge','ferrari','fiat','ford','gmc', 'harley-davidson','hennessey',\n                    'honda','hyundai','infiniti','jaguar','jeep', 'kia','land rover', 'lexus','lincoln','mazda', 'mercedes-benz','mercury','mini','mitsubishi','morgan',\n                    'nissan','pontiac','porsche','ram','rover','saturn','subaru','tesla','toyota','volkswagen','volvo']\nconditions        = [\"good\", \"fair\", \"excellent\", \"new\", \"like new\", \"salvage\", \"None\"]\nfuels             = [\"other\", \"hybrid\", \"gas\",\"electric\", \"diesel\", \"None\"]\ntransmissions     = [\"other\", \"manual\", \"automatic\", \"None\"]\ndrives            = [ \"rwd\", \"fwd\", \"4wd\", \"None\"]\nvehicle_types     = [\"wagon\", \"van\", \"truck\", \"sedan\",\"pickup\",\"other\", \"offroad\", \"mini-van\", \"hatchback\", \"coupe\", \"convertible\", \"bus\", \"SUV\", \"None\"]\npaint_colors      = [\"yellow\", \"white\",\"silver\",\"red\",\"purple\",\"orange\", \"grey\",\"green\",\"custom\",\"brown\",\"blue\",\"None\"]\n\n# 'price', 'year' - Numeric \n# 'manufacturer', 'condition', 'cylinders','fuel', 'odometer', 'transmission','drive', 'type', 'paint_color' - Categorical\nsize_df = manufacturer_df.na.fill(\"None\")\nfeatures_df = manufacturer_df.where(\n                    manufacturer_df.manufacturer.isin(manufacturer_list) & \n                    manufacturer_df.condition.isin(conditions) &  \n                    manufacturer_df.fuel.isin(fuels) &  \n                    manufacturer_df.transmission.isin(transmissions) &  \n                    manufacturer_df.drive.isin(drives) &  \n                    manufacturer_df.type.isin(vehicle_types) &  \n                    manufacturer_df.paint_color.isin(paint_colors)   \n\n                ).cache()\n\n#features_df.show(10)\nfeatures_df.count()\n\n#Picking only the relevant columns for Analysis\nselected_df = features_df.select('price', 'year', 'manufacturer', 'condition', 'cylinders','fuel', 'odometer', 'transmission','drive', 'type', 'paint_color')\nselected_df = selected_df.dropna()\nselected_df.show(10)\nselected_df.count()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nselected_df.printSchema\n\nfrom pyspark.sql.types import IntegerType\nselected_int_df = selected_df.withColumn(\"price\", selected_df[\"price\"].cast(IntegerType()))\nselected_int_df = selected_int_df.withColumn(\"year\", selected_df[\"year\"].cast(IntegerType()))\nselected_int_df.printSchema\nselected_int_df.describe()\n\nselected_int_df.count()\nselected_int_df = selected_int_df.filter(\"price is not null and price > 3000 and price < 60000 \")\nselected_int_df.count()\n\nselected_int_df.agg({'price': 'min', 'price': 'max'}).show()\n#selected_int_df.agg({'price': 'max'}).show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting the categorical features to Numerical\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml.feature import OneHotEncoder, StringIndexer\n\n# 2 step process. Convert the strings to an indexed value and then apply the one hot encoder\nindexer = StringIndexer(inputCols=['manufacturer', 'condition', 'cylinders','fuel', 'odometer', 'transmission','drive', 'type', 'paint_color'], \n                        outputCols=['manufacturer_index', 'condition_index', 'cylinders_index','fuel_index', 'odometer_index', 'transmission_index','drive_index', 'type_index', 'paint_color_index'])\nindexed = indexer.fit(selected_int_df).transform(selected_int_df)\nindexed.show(3)\n\nencoder = OneHotEncoder(inputCols=['manufacturer_index', 'condition_index', 'cylinders_index','fuel_index', 'odometer_index', 'transmission_index','drive_index', 'type_index', 'paint_color_index'],\n                        outputCols=[ 'manufacturer_vec', 'condition_vec', 'cylinders_vec','fuel_vec', 'odometer_vec', 'transmission_vec','drive_vec', 'type_vec', 'paint_color_vec'])\nmodel = encoder.fit(indexed)\nencoded_df = model.transform(indexed)\nencoded_df.show(3)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Standardizing and Normalizing the data.\n\nfrom pyspark.ml.feature import VectorAssembler\nvectorAssembler = VectorAssembler(inputCols = ['manufacturer_vec', 'condition_vec', 'cylinders_vec','fuel_vec', 'odometer_vec', 'transmission_vec','drive_vec', 'type_vec', 'paint_color_vec'], \n                                   outputCol = 'features')\nv_selected_df = vectorAssembler.transform(encoded_df)\nv_selected_df = v_selected_df.select(['features', 'price'])\nv_selected_df.show(3, False)\nv_selected_df.count()\n\nsplits = v_selected_df.randomSplit([0.7, 0.3])\ntrain_df = splits[0]\ntest_df = splits[1]\n\ntest_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n\n\nfrom pyspark.ml.regression import LinearRegression\nlr = LinearRegression(featuresCol = 'features', labelCol='price', maxIter=10, regParam=0.3, elasticNetParam=0.8)\nlr_model = lr.fit(train_df)\nprint(\"Coefficients: \" + str(lr_model.coefficients))\nprint(\"Intercept: \" + str(lr_model.intercept))\n\n# y= m*x + b\n# Price = slope1* manufacturer + slope2 * paint + slope3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainingSummary = lr_model.summary\nprint(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\nprint(\"r2: %f\" % trainingSummary.r2)\ntrain_df.describe().show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_predictions = lr_model.transform(test_df)\nlr_predictions.select(\"prediction\",\"price\",\"features\").show(15)\n\nfrom pyspark.ml.evaluation import RegressionEvaluator\nlr_evaluator = RegressionEvaluator(predictionCol=\"prediction\",  labelCol=\"price\", metricName=\"r2\")\nprint(\"R Squared (R2) on test data = %g\" % lr_evaluator.evaluate(lr_predictions))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pyspark.ml.regression import DecisionTreeRegressor\n\ndt = DecisionTreeRegressor(featuresCol ='features', labelCol = 'price')\ndt_model = dt.fit(train_df)\ndt_predictions = dt_model.transform(test_df)\ndt_predictions.select(\"prediction\",\"price\",\"features\").show(5)\n\ndt_evaluator = RegressionEvaluator(\n    labelCol=\"price\", predictionCol=\"prediction\", metricName=\"rmse\")\nrmse = dt_evaluator.evaluate(dt_predictions)\nprint(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\nprint(\"R Squared (R2) on test data = %g\" % dt_evaluator.evaluate(dt_predictions))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Future enhancements\nsplits = [-float(\"inf\"), -1, -0.5, 0.0, 0.5, float(\"inf\")]\n\ndata = [(-999.9,), (-0.5,), (-0.3,), (0.0,), (0.2,), (999.9,)]\ndataFrame = spark.createDataFrame(data, [\"features\"])\n\nbucketizer = Bucketizer(splits=splits, inputCol=\"features\", outputCol=\"bucketedFeatures\")\n\n# Transform original data into its bucket index.\nbucketedData = bucketizer.transform(dataFrame)\n\nprint(\"Bucketizer output with %d buckets\" % (len(bucketizer.getSplits())-1))\nbucketedData.show()\n\nfrom pyspark.ml.feature import Bucketizer\n\nsplits = [100000.0, 90000.0, 80000.0, 70000.0, \n          60000.0, 50000.0,40000.0, 30000.0, 20000.0,10000.0, 0.0]\nbucketizer = Bucketizer(splits=splits, inputCol=\"price\", outputCol=\"bucketedPrice\")\n\n# Transform original data into its bucket index.\nbucketedData = bucketizer.transform(encoded_df)\n\nprint(\"Bucketizer output with %d buckets\" % (len(bucketizer.getSplits())-1))\nbucketedData.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_df.show(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a model using pure python\n# Array for features, predict the price.\n\n# Calculate the mean value of a list of numbers\ndef mean(values): return sum(values) / float(len(values))\n \n# Calculate the variance of a list of numbers\ndef variance(values, mean): return sum([(x-mean)**2 for x in values])\n\nmean_x, mean_y = mean(selected_df[\"features), mean(selected_df.price)\n#var_x, var_y = variance(train_df.x, train_df.mean_x), variance(train_df.y, train_df.mean_y)\nprint('x stats: mean=%.3f variance=%.3f' % (mean_x, var_x))\n#print('y stats: mean=%.3f variance=%.3f' % (mean_y, var_y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}