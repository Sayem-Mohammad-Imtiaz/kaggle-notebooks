{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# !pip install --upgrade wandb -q\n# !wandb login <API KEY>","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import torch\nimport torchvision.transforms as transforms\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport wandb\n# %matplotlib inline\n# from PIL import Image","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## config"},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_dir = '/kaggle/input/sign-language-mnist/'\n\nepochs = 25\nlr = 0.001\n# momentum = 0.9\ntrain_batch_size = 12000 #27455\ntest_batch_size = 5000 #7172\nwb = False","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nclass dataset(Dataset):\n    def __init__(self, csv_file, root_dir, transform=None):\n        csv_dir = os.path.join(root_dir, csv_file)\n        csv = pd.read_csv(csv_dir)\n        self.labels = csv.iloc[:,0]\n        self.images = csv.iloc[:,1:]\n        self.images = (self.images.values).reshape(-1,28,28).astype('float32')\n        self.labels = torch.tensor(self.labels)\n#         self.labels = F.one_hot(self.labels)\n        if transform:\n            for i in range(self.images.shape[0]):\n                self.images[i] = transform(self.images[i])\n    \n    def __len__(self):\n        return len(self.labels)\n    \n    def __getitem__(self, index):\n#         if torch.is_tensor(index):\n#             index = index.tolist()\n        \n        img = self.images[index]\n        label = self.labels[index]\n    \n        sample = {'image': img, 'label': label}\n        \n        return sample\n\n# ds = dataset('sign_mnist_test/sign_mnist_test.csv', ds_dir, transform=None)\n# ds[0]['label']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# csv = pd.read_csv(os.path.join(ds_dir, 'sign_mnist_test/sign_mnist_test.csv'))\n# # print(csv.loc[csv['label'] == 9].head())\n# # img = csv.iloc[21, 1:]\n# # img = (img.values).reshape(28,28).astype('float32')\n# # plt.imshow(img, 'gray')\n# labels = F.one_hot(torch.tensor(csv.iloc[:,0]))\n# for i in range (50):\n#     print('eeky' if labels[i][9] != 0 else '', end='')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## dataloader"},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = transforms.Compose(\n    [transforms.ToPILImage(),\n     transforms.RandomRotation(degrees=5),\n     transforms.ToTensor(),\n     transforms.Normalize(0.5, 0.5)])\n\ntrainset = dataset('sign_mnist_train/sign_mnist_train.csv', ds_dir, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=train_batch_size,\n                                          shuffle=True, num_workers=1)\n\ntestset = dataset('sign_mnist_test/sign_mnist_test.csv', ds_dir, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=test_batch_size,\n                                          shuffle=True, num_workers=1)\n\nclasses = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y'] # no 'J' or 'Z'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import string\n# for i in string.ascii_uppercase:\n#     print(f'\\'{i}\\', ', end='')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## sneak peek"},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_imgs(image, label):\n    plt.imshow(torch.squeeze(torch.tensor(image)), 'gray')\n    plt.pause(0.001)\n\nfig = plt.figure()\n\nfor i in range(len(trainset)):\n    sample = trainset[i]\n    \n#     print(i, sample['image'].shape, sample['label'].shape)\n\n    ax = plt.subplot(1, 4, i + 1)\n    ax.set_title('= {} ='.format(classes[sample['label']]))\n    ax.axis('off')\n    plt.tight_layout()\n    show_imgs(**sample)\n    \n\n    if i == 3:\n        plt.show()\n        break","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## model"},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 16, 2)\n        self.pool = nn.MaxPool2d(2)\n        self.batch_norm1 = nn.BatchNorm2d(16)\n        self.conv2 = nn.Conv2d(16, 64, 3)\n        self.batch_norm2 = nn.BatchNorm2d(64)\n        self.conv3 = nn.Conv2d(64, 128, 3)\n        self.batch_norm3 = nn.BatchNorm2d(128)\n        self.fc1 = nn.Linear(2048, 1024)\n        self.dropout = nn.Dropout(0.2)\n        self.fc2 = nn.Linear(1024, 512)\n        self.batch_norm4 = nn.BatchNorm1d(512)\n        self.fc3 = nn.Linear(512, 256)\n        self.fc4 = nn.Linear(256, 25)\n\n    def forward(self, x):\n        # correct shape\n        x = x.reshape(-1, 1, 28, 28)\n        # conv blocks\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.batch_norm1(x)\n        x = self.swish(self.conv2(x))\n        x = self.dropout(x)\n        x = self.batch_norm2(x)\n        x = self.pool(self.swish(self.conv3(x)))\n        x = self.dropout(x)\n        x = self.batch_norm3(x)\n        # reshape for linear layers\n        x = x.view(-1, 128*4*4)\n        # linear block\n        x = self.swish(self.fc1(x))\n        x = self.dropout(x)\n        x = self.swish(self.fc2(x))\n        x = self.dropout(x)\n        x = self.batch_norm4(x)\n        x = F.relu(self.fc3(x))\n        x = self.fc4(x)\n        return x\n        \n    def swish(self, x):\n        return x * F.sigmoid(x)\n\n# net = Net()\n# net(torch.randn(2, 1, 28, 28)).shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## model summary"},{"metadata":{"trusted":true},"cell_type":"code","source":"from prettytable import PrettyTable\n\ndef count_parameters(model):\n    table = PrettyTable([\"Modules\", \"Parameters\"])\n    total_params = 0\n    for name, parameter in model.named_parameters():\n        if not parameter.requires_grad: continue\n        param = parameter.numel()\n        table.add_row([name, param])\n        total_params+=param\n    print(table)\n    print(f\"Total Trainable Params: {total_params}\")\n    return total_params\n    \ncount_parameters(Net())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## training"},{"metadata":{"trusted":true},"cell_type":"code","source":"if wb:\n    wandb.init(project=\"sign-lang\")\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nsteps = 0\nprint_every = 1\nrunning_loss = 0\ntrain_losses, test_losses = [], []\n\n\nnet = Net().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(net.parameters(), lr=lr)\n\nfor epoch in range(epochs):\n    for inputs in trainloader:\n        steps += 1\n        inputs, labels = (inputs['image']).to(device), (inputs['label']).to(device)\n        optimizer.zero_grad()\n        out = net(inputs)\n        loss = criterion(out, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n        \n        if steps % print_every == 0:\n            test_loss = 0\n            accuracy = 0\n            net.eval()\n            with torch.no_grad():\n                for inputs in testloader:\n                    inputs, labels = (inputs['image']).to(device), (inputs['label']).to(device)\n                    out = net(inputs)\n                    batch_loss = criterion(out, labels)\n                    test_loss += batch_loss.item()\n                    \n                    ps = torch.exp(out)\n                    top_p, top_class = ps.topk(1, dim=1)\n                    equals = top_class == labels.view(*top_class.shape)\n                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n            train_losses.append(running_loss/len(trainloader))\n            test_losses.append(test_loss/len(testloader))                    \n            print(f\"Epoch {epoch+1}/{epochs}.. \"\n                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n                  f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n                  f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n            if wb:\n                wandb.log({'Train Loss':running_loss/print_every, 'Test Loss': test_loss/len(testloader), 'Test Accuracy':accuracy/len(testloader)})\n\n            running_loss = 0\n            net.train()\ndest = f'sign_lang_lr_{lr}_epo_{epochs}_'\nv = 0\nwhile os.path.isfile(dest+str(v)):\n    v += 1\ntorch.save(net, dest+str(v)+'.pth')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## model 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import torch.nn as nn\n# import torch.nn.functional as F\n\n# class XNet(nn.Module):\n#     def __init__(self):\n#         super(XNet, self).__init__()\n#         self.conv1 = nn.Conv2d(1, 16, 2)\n#         self.pool = nn.MaxPool2d(2)\n#         self.batch_norm1 = nn.BatchNorm2d(16)\n#         self.conv2 = nn.Conv2d(16, 64, 3)\n#         self.batch_norm2 = nn.BatchNorm2d(64)\n#         self.conv3 = nn.Conv2d(64, 128, 3)\n#         self.batch_norm3 = nn.BatchNorm2d(128)\n#         self.fc1 = nn.Linear(2048, 1024)\n#         self.dropout = nn.Dropout(0.2)\n#         self.fc2 = nn.Linear(1024, 512)\n#         self.batch_norm4 = nn.BatchNorm1d(512)\n#         self.fc3 = nn.Linear(512, 256)\n#         self.fc4 = nn.Linear(256, 1)\n\n#     def forward(self, x):\n#         # correct shape\n#         x = x.reshape(-1, 1, 28, 28)\n#         # conv blocks\n#         x = self.pool(F.relu(self.conv1(x)))\n#         x = self.batch_norm1(x)\n#         x = self.swish(self.conv2(x))\n#         x = self.dropout(x)\n#         x = self.batch_norm2(x)\n#         x = self.pool(self.swish(self.conv3(x)))\n#         x = self.dropout(x)\n#         x = self.batch_norm3(x)\n#         # reshape for linear layers\n#         x = x.view(-1, 128*4*4)\n#         # linear block\n#         x = self.swish(self.fc1(x))\n#         x = self.dropout(x)\n#         x = self.swish(self.fc2(x))\n#         x = self.dropout(x)\n#         x = self.batch_norm4(x)\n#         x = F.relu(self.fc3(x))\n#         x = self.fc4(x)\n#         return x\n        \n#     def swish(self, x):\n#         return x * torch.sigmoid(x)\n\n# # net = XNet()\n# # net(torch.randn(2, 1, 28, 28))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## train 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"# if wb:\n#     wandb.init(project=\"sign-lang\")\n\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# steps = 0\n# print_every = 1\n# running_loss = 0\n# train_losses, test_losses = [], []\n\n\n# net = XNet().to(device)\n# criterion = nn.MSELoss()\n# optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n\n# for epoch in range(epochs):\n#     for inputs in trainloader:\n#         steps += 1\n#         inputs, labels = (inputs['image']).to(device), (inputs['label']).to(device)\n#         optimizer.zero_grad()\n#         out = net(inputs)\n#         loss = criterion(torch.squeeze(out), labels.float())\n#         loss.backward()\n#         optimizer.step()\n#         running_loss += loss.item()\n        \n#         if steps % print_every == 0:\n#             test_loss = 0\n#             accuracy = 0\n#             net.eval()\n#             with torch.no_grad():\n#                 for inputs in testloader:\n#                     inputs, labels = (inputs['image']).to(device), (inputs['label']).to(device)\n#                     out = net(inputs)\n#                     batch_loss = criterion(out, labels)\n#                     test_loss += batch_loss.item()\n                    \n#                     ps = torch.exp(out)\n#                     top_p, top_class = ps.topk(1, dim=1)\n#                     equals = top_class == labels.view(*top_class.shape)\n#                     accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n#             train_losses.append(running_loss/len(trainloader))\n#             test_losses.append(test_loss/len(testloader))                    \n#             print(f\"Epoch {epoch+1}/{epochs}.. \"\n#                   f\"Train loss: {running_loss/print_every:.3f}.. \"\n#                   f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n#                   f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n#             if wb:\n#                 wandb.log({'Train Loss':running_loss/print_every, 'Test Loss': test_loss/len(testloader), 'Test Accuracy':accuracy/len(testloader)})\n\n#             running_loss = 0\n#             net.train()\n# dest = f'Xsign_lang_lr_{lr}_epo_{epochs}'\n# v = 0\n# while os.path.isfile(dest+str(v)):\n#     v += 1\n# torch.save(net, dest+str(v)+'.pth')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}