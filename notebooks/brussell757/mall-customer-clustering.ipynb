{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"211185f91d71c91b863b08a949d77885079825ca"},"cell_type":"markdown","source":"## **Our goal is to cluster our customers into buying groups based off of their Annual Income and Spending Scores**"},{"metadata":{"_uuid":"0b48cc7a4fe6ee851e7840f4d7ffefc5bca7829c"},"cell_type":"markdown","source":"Examine our dataset"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/Mall_Customers.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2df68cc32dd16c5b3b04dfe02f2ebcbb044e9d3b"},"cell_type":"code","source":"X = np.array(df.iloc[:,[3,4]])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bafe232519193b1f65ff9d829194d64fa59f357d"},"cell_type":"markdown","source":"Visualize the raw data"},{"metadata":{"trusted":true,"_uuid":"f97fc14171e5872b55f8c1b09a16b9db778d6e3a"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.scatter(X[:,0], X[:,1], s = 25)\nplt.title('Raw Data')\nplt.xlabel('Annual Income (k$)')\nplt.ylabel('Spending Score (1-100)')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ab575644ed21bd3a5d4c1beaef817ba6d846a6f7"},"cell_type":"markdown","source":"### **K-Means Algorithm**"},{"metadata":{"_uuid":"13a2630b2296fe73d042eb1feeb9d0f98154f236"},"cell_type":"markdown","source":"Let's use the 'Elbow Method' to determine the appropriate number of clusters to use"},{"metadata":{"trusted":true,"_uuid":"48f1e6f2166de48b081ba0fa818f536a589da3c6"},"cell_type":"code","source":"from sklearn.cluster import KMeans\n\nwcss = []\niterations = 500\nnum_centroid_seeds = 10\nrand_state = 0\n\nfor i in range(1,11):\n    kmeans = KMeans(n_clusters = i, max_iter = iterations, n_init = num_centroid_seeds, random_state = rand_state)\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)\n    \nplt.plot(range(1,11), wcss)\nplt.title('Elbow Method')\nplt.xlabel('Number of Clusters')\nplt.ylabel('WCSS')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3d68fa019aa3cef55442c91a589be35fa5a7aafd"},"cell_type":"markdown","source":"From the above we can see that the optimal number of clusters is 5"},{"metadata":{"trusted":true,"_uuid":"7c2064e821b10a4b8f15311de60f63154f25dbcd"},"cell_type":"code","source":"kmeans = KMeans(n_clusters = 5, max_iter = iterations, n_init = num_centroid_seeds, random_state = rand_state)\nkmeans_preds = kmeans.fit_predict(X)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bd01e741653af5054aea0643708b8c08181ce3a8"},"cell_type":"markdown","source":"Plot our clusters"},{"metadata":{"trusted":true,"_uuid":"c49087fb04afe0c5dea182dbfd3553b0359e409b"},"cell_type":"code","source":"point_size = 25\ncolors = ['red', 'blue', 'green', 'cyan', 'magenta']\nlabels = ['Careful', 'Standard', 'Target', 'Careless', 'Sensible']\n\nplt.figure(figsize = (10,7))\nfor i in range(5):\n    plt.scatter(X[kmeans_preds == i,0], X[kmeans_preds == i,1], s = point_size, c = colors[i], label = labels[i])\n    \nplt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], s = 100, c = 'orange', label = 'Centroids')\nplt.title('Clusters of Clients')\nplt.xlabel('Annual Income (k$)')\nplt.ylabel('Spending Score (1-100)')\nplt.legend(loc = 'best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5e498887f25c2ea8bfa7eedf51ce6fa7b7efa24a"},"cell_type":"markdown","source":"### **Agglomerative Hierarchical Clustering Algorithm**"},{"metadata":{"_uuid":"2cdc92d2ea17ad5577cd14889e95aa880c5e6e0a"},"cell_type":"markdown","source":"Create our dendrogram"},{"metadata":{"trusted":true,"_uuid":"533a83459bd69549e6b2afe0add2745c57f32537"},"cell_type":"code","source":"import scipy.cluster.hierarchy as sch\n\nplt.figure(figsize = (25,10))\ndendrogram = sch.dendrogram(sch.linkage(X, method = 'ward'))\n\nplt.title('Dendrogram')\nplt.xlabel('Customers')\nplt.ylabel('Euclidean Distances')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"06279dc12e1a6668746a01ead32fa206adef995b"},"cell_type":"markdown","source":"Perfrom Agglomerative Clustering"},{"metadata":{"trusted":true,"_uuid":"2421f3e02e1adbf4e3681878ce345ef683c809fa"},"cell_type":"code","source":"from sklearn.cluster import AgglomerativeClustering\n\nagg_clustering = AgglomerativeClustering(n_clusters = 5, affinity = 'euclidean', linkage = 'ward')\nagg_preds = agg_clustering.fit_predict(X)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4589aac732cd39d4d00e7f8d8716618666e5f0e1"},"cell_type":"markdown","source":"Plot our clusters"},{"metadata":{"trusted":true,"_uuid":"577fa39c1400f987fc9c181e59bf383e7613ac13"},"cell_type":"code","source":"point_size = 25\ncolors = ['red', 'blue', 'green', 'cyan', 'magenta']\nlabels = ['Careful', 'Standard', 'Target', 'Careless', 'Sensible']\n\nplt.figure(figsize = (10,7))\nfor i in range(5):\n    plt.scatter(X[agg_preds == i,0], X[agg_preds == i,1], s = point_size, c = colors[i], label = labels[i])\n\nplt.title('Clusters of Clients')\nplt.xlabel('Annual Income (k$)')\nplt.ylabel('Spending Score (1-100)')\nplt.legend(loc = 'best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cbf883a979b32340b3b231daaf7c73bf2b159c88"},"cell_type":"markdown","source":"### **Compare KMeans to Agglomerative Clusters**"},{"metadata":{"trusted":true,"_uuid":"682a997dee69a63ec659759fbda81cd16651eb88"},"cell_type":"code","source":"point_size = 25\ncolors = ['red', 'blue', 'green', 'cyan', 'magenta']\nlabels = ['Careful', 'Standard', 'Target', 'Careless', 'Sensible']\n\nplt.figure(figsize = (25,7))\n\nplt.subplot(1,2,1)\nfor i in range(5):\n    plt.scatter(X[kmeans_preds == i,0], X[kmeans_preds == i,1], s = point_size, c = colors[i], label = labels[i])\n    \nplt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], s = 100, c = 'orange', label = 'Centroids')\nplt.title('Clusters of Clients (K-Means)')\nplt.xlabel('Annual Income (k$)')\nplt.ylabel('Spending Score (1-100)')\nplt.legend(loc = 'best')\n\nplt.subplot(1,2,2)\nfor i in range(5):\n    plt.scatter(X[agg_preds == i,0], X[agg_preds == i,1], s = point_size, c = colors[i], label = labels[i])\n    \nplt.title('Clusters of Clients (Agglomerative)')\nplt.xlabel('Annual Income (k$)')\nplt.ylabel('Spending Score (1-100)')\nplt.legend(loc = 'best')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fa30605facb73e610c46d3753e9904717919f400"},"cell_type":"markdown","source":"### **In conclusion we can see that Hierarchical Clustering seems to produce better results than K-Means Clustering**"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}