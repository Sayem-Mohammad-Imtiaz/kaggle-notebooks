{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"zoo_data = pd.read_csv('../input/zoo.csv')\nclass_data = pd.read_csv('../input/class.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3bb675822375ad841a1be8f56e4fcebf08ecad06"},"cell_type":"markdown","source":"**Inspect our zoo data**"},{"metadata":{"trusted":true,"_uuid":"28732afc844f13840ec4706d11c106482864040d"},"cell_type":"code","source":"zoo_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"94c40618dd2fac44fb67ea8f9bdbc290fcbb8396"},"cell_type":"code","source":"zoo_data.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4b6893bdfcc029e3ee81d0360be94ef75fb07197"},"cell_type":"markdown","source":"**Inspect our class data**"},{"metadata":{"trusted":true,"_uuid":"417f2a8321f48422bfe5362e43c9e2fa07594fd7"},"cell_type":"code","source":"class_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3095fe886d5fa8b51125747ec0e10c08a42fa5fb"},"cell_type":"code","source":"class_data.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"210eb5014d5348b3cb8c3716e68ac36a4be7da63"},"cell_type":"markdown","source":"**Create a dictionary mapping class number to class type**"},{"metadata":{"trusted":true,"_uuid":"e5e85cdee7055e7c0827a931662ace3a9b4183a8"},"cell_type":"code","source":"classes = dict(zip(class_data.Class_Number, class_data.Class_Type))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5fee2ee833b64b28f98d0c7e4a6f5fd21b415c77"},"cell_type":"markdown","source":"**Gather our features and labels**"},{"metadata":{"trusted":true,"_uuid":"62629c5f6b1573693c942a67c25755e85e2325ca"},"cell_type":"code","source":"features = np.array(zoo_data.iloc[:,1:-1])\nlabels = np.array(zoo_data.iloc[:, -1])\n\nlabels = tf.one_hot(labels, depth = len(classes))\nwith tf.Session() as sess:\n    labels = labels.eval(session = sess)\n    \nprint(features.shape)\nprint(labels.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a25017af8fe8e321c675cf41b7d20e608171ccd7"},"cell_type":"markdown","source":"**Split our train/dev sets**"},{"metadata":{"trusted":true,"_uuid":"9e3557d6b9eeeda3fa99e478681553c9db9837a0"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.2, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"29acff2749b9e1f06a6ebaf0c53cec2dd7c85a7d"},"cell_type":"markdown","source":"**Create our placeholders**"},{"metadata":{"trusted":true,"_uuid":"396d9e33ac6058241f279695e9b310a80031b8e8"},"cell_type":"code","source":"def create_placeholders(n_x, n_y):\n    X = tf.placeholder(tf.float32, (n_x, None), name = 'X')\n    Y = tf.placeholder(tf.float32, (n_y, None), name = 'Y')\n    \n    return X, Y","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ed1e557ad973f6a2e06154f36f8d268132e8f513"},"cell_type":"markdown","source":"**Initialize our weights**"},{"metadata":{"trusted":true,"_uuid":"d95427b39e18d5efa9662bce62c4f7bd0ee9f588"},"cell_type":"code","source":"def initialize_weights(layer_dims):\n    seed = 42\n    \n    L = len(layer_dims)\n    parameters = {}\n    for l in range(1, L):\n        parameters['W' + str(l)] = tf.get_variable('W' + str(l), shape = (layer_dims[l], layer_dims[l - 1]), dtype = tf.float32, initializer = tf.contrib.layers.xavier_initializer(seed))\n        parameters['b' + str(l)] = tf.get_variable('b' + str(l), shape = (layer_dims[l], 1), dtype = tf.float32, initializer = tf.zeros_initializer())\n    return parameters","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8db1933c7bce9d2cee22cca0328b2869f49a4a35"},"cell_type":"markdown","source":"**Define forward propagation**"},{"metadata":{"trusted":true,"_uuid":"75bcd9e6935dff72ecc06c598d6d14e19df10295"},"cell_type":"code","source":"def forward_propagation(X, parameters):\n    L = len(parameters) // 2\n    A = X    \n    for l in range(1, L):\n        Z = tf.matmul(parameters['W' + str(l)], A) + parameters['b' + str(l)]\n        A = tf.nn.relu(Z)\n    \n    Z = tf.matmul(parameters['W' + str(L)], A) + parameters['b' + str(L)]\n    return Z","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"84e7e2c8b0633c196337425d3fcdfbf4f716203a"},"cell_type":"markdown","source":"**Define cost function**"},{"metadata":{"trusted":true,"_uuid":"25e044d7b4a510b89b0ad659319e62133cd84950"},"cell_type":"code","source":"def compute_cost(Y_PRED, Y):\n    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = tf.transpose(Y_PRED), labels = tf.transpose(Y)))\n    return cost","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"24e784c9e0efc6e600811cfca9dddeeae73a1bc5"},"cell_type":"markdown","source":"**Define optimizer function**"},{"metadata":{"trusted":true,"_uuid":"2df22f9997cfdee9903d147a4b7bd39c59e81266"},"cell_type":"code","source":"def build_optimizer(learning_rate, cost):\n    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n    return optimizer","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eec451604bcd7a287a0167036b7123b16d564c1b"},"cell_type":"markdown","source":"**Build model**"},{"metadata":{"trusted":true,"_uuid":"4a8be8a981b12a0ea89ab53688d7da3845194ad0"},"cell_type":"code","source":"def build_model(train_data, test_data, layer_dims, learning_rate = 0.01, epoch = 50, batch_size = 32, print_cost = True):\n    tf.reset_default_graph()\n    \n    (n_x, m) = train_data['data'].T.shape\n    n_y = train_data['labels'].T.shape[0]\n      \n    costs = []\n    \n    X, Y = create_placeholders(n_x, n_y)\n    parameters = initialize_weights(layer_dims)\n    Y_PRED = forward_propagation(X, parameters)\n    cost = compute_cost(Y_PRED, Y)\n    optimizer = build_optimizer(learning_rate, cost)\n    \n    init = tf.global_variables_initializer()\n    \n    with tf.Session() as sess:\n        sess.run(init)\n        \n        for epoch in range(epochs):\n            epoch_cost = 0.\n            num_batches = m // batch_size\n            \n            for i in range(num_batches):\n                offset = (i * batch_size) % (train_data['labels'].shape[0] - batch_size)\n                batch_X = train_data['data'][offset:(offset + batch_size), :]\n                batch_Y = train_data['labels'][offset:(offset + batch_size), :]\n                _, batch_cost = sess.run([optimizer, cost], feed_dict = {X:batch_X.T, Y:batch_Y.T})\n                epoch_cost += batch_cost / num_batches\n            \n            if m % batch_size != 0:\n                batch_X = train_data['data'][num_batches * batch_size:m, :]\n                batch_Y = train_data['labels'][num_batches * batch_size:m, :]\n                _, batch_cost = sess.run([optimizer, cost], feed_dict = {X:batch_X.T, Y:batch_Y.T})\n                epoch_cost += batch_cost / num_batches\n                \n            if epoch % 50 == 0 and print_cost == True:\n                print('Cost after epoch {}: {}'.format(epoch, epoch_cost))\n            \n            if print_cost == True:\n                costs.append(epoch_cost)\n                \n        plt.figure(figsize = (16,5))\n        plt.plot(np.squeeze(costs), c = 'b')\n        plt.xlim(0, epochs - 1)\n        plt.ylabel('cost')\n        plt.xlabel('epochs')\n        plt.title('Learning Rate: {}'.format(learning_rate))\n        plt.show()\n        \n        parameters = sess.run(parameters)\n        print('Parameters have been trained')\n        \n        predictions = {'classes': tf.argmax(Y_PRED, axis = 0).eval(feed_dict = {X:test_data['data'].T, Y:test_data['labels'].T}),\n                       'probabilities': tf.nn.softmax(Y_PRED).eval(feed_dict = {X:test_data['data'].T, Y:test_data['labels'].T})}\n        \n        correct_preds = tf.equal(tf.argmax(Y_PRED), tf.argmax(Y))\n        accuracy = tf.reduce_mean(tf.cast(correct_preds, 'float'))\n        \n        print('Train Accuracy: ', accuracy.eval({X:train_data['data'].T, Y:train_data['labels'].T}))\n        print('Test Accuracy: ', accuracy.eval({X:test_data['data'].T, Y:test_data['labels'].T}))\n        \n    return parameters, predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"984975a6e7f86edf72f006e12b7d9aee4bbf225b"},"cell_type":"code","source":"train_data = {'data':train_features, 'labels':train_labels}\ntest_data = {'data':test_features, 'labels':test_labels}\nlayer_dims = [train_data['data'].shape[1], 8, len(classes)]\nlearning_rate = 0.001\nepochs = 500\nbatch_size = 8\n\nparameters, predictions = build_model(train_data, test_data, layer_dims, learning_rate, epochs, batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd8e58ddbc3fc366afaf0a504b612b4d065bacd2"},"cell_type":"code","source":"import itertools\n\ndef plot_confusion_matrix(cm, target_names, title = 'Confusion Matrix', cmap = None, normalize = True):\n    accuracy = np.trace(cm)/ float(np.sum(cm))\n    misclass = 1 - accuracy\n    \n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n        \n    plt.figure(figsize = (8,6))\n    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n    plt.title(title)\n    plt.colorbar()\n    \n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation = 45)\n        plt.yticks(tick_marks, target_names)\n        \n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis = 1)[:, np.newaxis]\n        \n    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]), horizontalalignment = 'center', color = 'white' if cm[i,j] > thresh else 'black')\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i,j]), horizontalalignment = 'center', color = 'white' if cm[i,j] > thresh else 'black')\n            \n    plt.tight_layout()\n    plt.ylabel('True Label')\n    plt.xlabel('Predicted Label\\naccuracy={:0.4f}; misclass = {:0.4f}'.format(accuracy, misclass))\n    \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a04cba1eae7fa786661439a6e560d0bfd44ffe1"},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(np.argmax(test_data['labels'], axis = 1), predictions['classes'])\nplot_confusion_matrix(cm, normalize = False, target_names = classes.values())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f109c7d21bb8437e4cb2c1721184853e34e31389"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}