{"cells":[{"metadata":{"_uuid":"a298a77021600d45aab6680a4938bc79c6991282"},"cell_type":"markdown","source":"# Data Examination and Cleaning"},{"metadata":{"_uuid":"0ade654ef45f5749363978a29f878ab4ca8ea825"},"cell_type":"markdown","source":"\nTutorial Level : ***Beginner***\n\nData Cleaning is detection, fillup or removal of incomplete, inaccurate or vague data.\nThe tutorial below discuss the examination of data and performing necessary steps to clean data including \n\n* Dealing with Missing Data \n    *     Removal and Filling of Missing Data for Numerical and Categorical Features\n* Dividing Numerical and Categorical Data and Converting Categorical Data to Numeric Form\n* Inspecting Feature Correlation to study important features\n* Removal of less Corrlated Features\n* Plotting histogram and kde plots to get a butter understanding of data\n"},{"metadata":{"_uuid":"92f2dcfd45cc861154e83872754623c1d139d0b6"},"cell_type":"markdown","source":"Importing required libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # for plots\nimport seaborn as sns\n%matplotlib inline\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"365f45ad720ec6f1f751d819e3ee4924eb83b0b4"},"cell_type":"markdown","source":"Data being used here for data examination is 'Horse Colic Dataset' which predicts whether a horse can survive or not based on past medical conditions.\nData is available via following links.\n1.  [Kaggle](http://www.kaggle.com/uciml/horse-colic)\n2. [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/datasets/Horse+Colic)"},{"metadata":{"_uuid":"d512168020d4e1ed095584158ce755fd83e23cd0"},"cell_type":"markdown","source":"Reading data from **CSV file** and saving as **Pandas' Dataframe**"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"print(os.listdir(\"../input\"))\ndata = pd.read_csv('../input/horse.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"815b5ed3547be9f2ecfdb0866d41c2efce64a83f"},"cell_type":"markdown","source":"## Shape and Nature of data"},{"metadata":{"trusted":true,"_uuid":"413c64aa7b33228912713b7f44d328707b2ee1fe"},"cell_type":"code","source":"print(\"Shape of data (samples, features): \",data.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d6cecdf86088b93854f118466eb2ccf82024f590"},"cell_type":"markdown","source":"**Inspecting nature of data**, it can be seen that data consists of **17** categorical features and rest numerical out of **28**."},{"metadata":{"trusted":true,"_uuid":"a53e0454ec3f6ff871376ec3b4e40db2cbc21e7c"},"cell_type":"code","source":"data.dtypes.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3630fa479e72f8c57a2c81b1f64640fb834a17ba"},"cell_type":"markdown","source":"## Checking missing values for each feature"},{"metadata":{"trusted":true,"_uuid":"3ab7efce1599b56f1430e092a3ff97486053d754"},"cell_type":"code","source":"nan_per=data.isna().sum()/len(data)*100\nplt.bar(range(len(nan_per)),nan_per)\nplt.xlabel('Features')\nplt.ylabel('% of NAN values')\nplt.plot([0, 25], [40,40], 'r--', lw=1)\nplt.xticks(list(range(len(data.columns))),list(data.columns.values),rotation='vertical')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"433aa24313afd067fcb856cb9f8f83981d5a7a62"},"cell_type":"markdown","source":"The graph shows the number of Missing values in each feature, most of the features have less than 40% missing values. "},{"metadata":{"_uuid":"aea5af0cd4df1d568d83dc72c03557f5a9f111ea"},"cell_type":"markdown","source":"## Dividing Categorical and Numerical Data"},{"metadata":{"trusted":true,"_uuid":"6884689d452bda523d017c3eff0ef053e1b8a10e"},"cell_type":"code","source":"obj_columns=[]\nnonobj_columns=[]\nfor col in data.columns.values:\n    if data[col].dtype=='object':\n        obj_columns.append(col)\n    else:\n        nonobj_columns.append(col)\nprint(len(obj_columns),\" Object Columns are \\n\",obj_columns,'\\n')\nprint(len(nonobj_columns),\"Non-object columns are \\n\",nonobj_columns)\n\ndata_obj=data[obj_columns]\ndata_nonobj=data[nonobj_columns]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a39c63d9e26ac3dae31f0bed6ad297c225e94297"},"cell_type":"markdown","source":"## Removing and Filling Missing Values in Numerical and Categorical Data \n1.     For columns with more than 40% NAN Value : Remove Columns\n2.     For columns with less than 40% NAN Value \n    *       ***For Numerical Data***: Replace NAN values with median value of that particular column\n    *      ** *For Categorical Data***: Replace NAN values with mode value of that particular column"},{"metadata":{"trusted":true,"_uuid":"cbd83eeaf4484a0414eb5b338e8c9fb23135f6a0"},"cell_type":"code","source":"print(\"Data Size Before Numerical NAN Column(>40%) Removal :\",data_nonobj.shape)\nfor col in data_nonobj.columns.values:\n    if (pd.isna(data_nonobj[col]).sum())>0:\n        if pd.isna(data_nonobj[col]).sum() > (40/100*len(data_nonobj)):\n            print(col,\"removed\")\n            data_nonobj=data_nonobj.drop([col], axis=1)\n        else:\n            data_nonobj[col]=data_nonobj[col].fillna(data_nonobj[col].median())\nprint(\"Data Size After Numerical NAN Column(>40%) Removal :\",data_nonobj.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd3bf8b3c9578cba1ebb74bae3bb262490b8abcd"},"cell_type":"code","source":"print(\"Data Size Before Categorical NAN Column(>40%) Removal :\",data_obj.shape)\nfor col in data_obj.columns.values:\n    if (pd.isna(data_obj[col]).sum())>0:\n        if pd.isna(data_obj[col]).sum() > (40/100*len(data_nonobj)):\n            print(col,\"removed\")\n            data_obj=data_obj.drop([col], axis=1)\n        else:\n            data_obj[col]=data_obj[col].fillna(data_obj[col].mode()[0])\nprint(\"Data Size After Categorical NAN Column(>40%) Removal :\",data_obj.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5b146dfe479ad0829217f6adc227a8b64163880d"},"cell_type":"markdown","source":"## Converting Categorical Data to Numerical and Merging Them"},{"metadata":{"trusted":true,"_uuid":"3a7779815256ddca5623509045ff9e8532ed4087"},"cell_type":"code","source":"for col in data_obj.columns.values:\n    data_obj[col]=data_obj[col].astype('category').cat.codes\ndata_merge=pd.concat([data_nonobj,data_obj],axis=1)\n\ntarget=data['outcome']\nprint(target.value_counts())\ntarget=data_merge['outcome']\nprint(target.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"079048b07ce959d6c7f5d8b2572eadec10af85e4"},"cell_type":"markdown","source":"It shall be noted that numeric **0,1,2** are equivalent to **died, euthanized, lived** for outcome."},{"metadata":{"_uuid":"75bedc68c7ba52676991a48ec43af5171c493a82"},"cell_type":"markdown","source":"## Inspecting Correlation between various Features and Outcome"},{"metadata":{"_uuid":"5526e6fa7f569d38a54c2f7e18bfcf977cf0fd4d"},"cell_type":"markdown","source":"Correlation shows how strongly features are related to each other. We will be checking correlation of each column with outcome. \n* If correlation value is positive, fetaure is positively correlated to outcome. \n1. If correlation value is negative, feature is negatively correlated to outcome. \n1. If correlation value is 0, two columns are not correlated. \n\n    *  |value| > 0.7 : Hight correlated    \n    *  0.7 < |value| > 0.3 : Moderately correlated    \n    *  0.3 < |value| > 0 : Weakly correlated    "},{"metadata":{"trusted":true,"_uuid":"667568c643ce2b0348b0ebbbd81dc48eabc38b47"},"cell_type":"code","source":"train_corr=data_merge.corr()\nsns.heatmap(train_corr, vmax=0.8)\ncorr_values=train_corr['outcome'].sort_values(ascending=False)\ncorr_values=abs(corr_values).sort_values(ascending=False)\nprint(\"Correlation of mentioned features wrt outcome in ascending order\")\nprint(abs(corr_values).sort_values(ascending=False))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b7409aea2caa378a2f46eff40dceb207cc124fa9"},"cell_type":"markdown","source":"Removing unwanted very less correlated features"},{"metadata":{"trusted":true,"_uuid":"21624dbf14afd9a1e6da9156d164a1bf7b862df9"},"cell_type":"code","source":"print(\"Data Size Before Correlated Column Removal :\",data_merge.shape)\n\nfor col in range(len(corr_values)):\n        if abs(corr_values[col]) < 0.1:\n            data_merge=data_merge.drop([corr_values.index[col]], axis=1)\n            print(corr_values.index[col],\"removed\")\nprint(\"Data Size After Correlated Column Removal :\",data_merge.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"76e534cb8920fc38d8175c20437e3836dbf25441"},"cell_type":"markdown","source":"To better understand, how two features are correlated. Let us plot two most correlated (to outcome) features as histogram and kde plot."},{"metadata":{"_uuid":"7725661bd855318717a47478eba413665611ce53"},"cell_type":"markdown","source":"## 1. Packed Cell Volume & Outcome"},{"metadata":{"trusted":true,"_uuid":"4c69839a963d9648a2aeaee46946dff0b9cf8607"},"cell_type":"code","source":"#packed_cell_volume \ncol='packed_cell_volume'\nfig,(ax1,ax2)=plt.subplots(1,2, figsize=[20,10])\n\ny=data_merge[col][target==2]\nx=data_merge['outcome'][target==2]\ny.plot.hist(ax=ax2)\nsns.kdeplot(y,ax=ax1)\n\ny=data_merge[col][target==0]\nx=data_merge['outcome'][target==0]\ny.plot.hist(ax=ax2)\nsns.kdeplot(y,ax=ax1)\n\ny=data_merge[col][target==1]\nx=data_merge['outcome'][target==1]\ny.plot.hist(ax=ax2)\nsns.kdeplot(y,ax=ax1)\n\nplt.title(col)\nax1.legend(['lived','died','euthanized'])\nax2.legend(['lived','died','euthanized'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a481f71e2372a462c698243355fb5cfab6d77180"},"cell_type":"markdown","source":"The plots show that after approx **50**, outcome is most likely to be **euthanized**, and after **60**, it is likely to be **died**. "},{"metadata":{"_uuid":"4f366f4eb2384f29f10befd2466cf41b920da660"},"cell_type":"markdown","source":"## 2. Pulse & Outcome"},{"metadata":{"trusted":true,"_uuid":"ee926192b3e1d00dc20a9dd0b02a7e35dabca66f"},"cell_type":"code","source":"#pulse \ncol='pulse'\nfig,(ax1,ax2)=plt.subplots(1,2, figsize=[20,10])\ny=data_merge[col][target==2]\nx=data_merge['outcome'][target==2]\ny.plot.hist(ax=ax2)\nsns.kdeplot(y,ax=ax1)\ny=data_merge[col][target==0]\nx=data_merge['outcome'][target==0]\ny.plot.hist(ax=ax2)\nsns.kdeplot(y,ax=ax1)\ny=data_merge[col][target==1]\nx=data_merge['outcome'][target==1]\ny.plot.hist(ax=ax2)\nsns.kdeplot(y,ax=ax1)\nplt.title(col)\nax1.legend(['lived','died','euthanized'])\nax2.legend(['lived','died','euthanized'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6d219396e03e4398e11eb87195d9ac212e2ffb13"},"cell_type":"markdown","source":"The plots show that after approx **60**, outcome is likely to be **died** which is then replaced by **euthanized** after **100**.  And after **150** , the probability of **died** being the outcome is highest."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}