{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"raw","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-20T01:54:03.481372Z","iopub.execute_input":"2021-08-20T01:54:03.481727Z","iopub.status.idle":"2021-08-20T01:54:03.493299Z","shell.execute_reply.started":"2021-08-20T01:54:03.481697Z","shell.execute_reply":"2021-08-20T01:54:03.492192Z"}}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"execution":{"iopub.status.busy":"2021-08-26T02:17:55.807667Z","iopub.execute_input":"2021-08-26T02:17:55.808104Z","iopub.status.idle":"2021-08-26T02:17:55.816334Z","shell.execute_reply.started":"2021-08-26T02:17:55.80807Z","shell.execute_reply":"2021-08-26T02:17:55.814863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we all know, Let's import the data!","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"../input/netflix-shows/netflix_titles.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-26T02:17:55.824033Z","iopub.execute_input":"2021-08-26T02:17:55.824567Z","iopub.status.idle":"2021-08-26T02:17:55.906218Z","shell.execute_reply.started":"2021-08-26T02:17:55.824515Z","shell.execute_reply":"2021-08-26T02:17:55.904854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's explore the data first","metadata":{}},{"cell_type":"code","source":"df.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-08-26T02:17:55.907881Z","iopub.execute_input":"2021-08-26T02:17:55.908202Z","iopub.status.idle":"2021-08-26T02:17:55.93153Z","shell.execute_reply.started":"2021-08-26T02:17:55.908173Z","shell.execute_reply":"2021-08-26T02:17:55.930159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's see how big the data is\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-26T02:17:55.934113Z","iopub.execute_input":"2021-08-26T02:17:55.934555Z","iopub.status.idle":"2021-08-26T02:17:55.94217Z","shell.execute_reply.started":"2021-08-26T02:17:55.934522Z","shell.execute_reply":"2021-08-26T02:17:55.940884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Okay, let's clean the data. In other words, let me just keep the columns that I will be using and delete all the unneccesary columns.\n# drop show_id column\ndf.drop(columns = [\"show_id\"], inplace = True)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-26T02:17:55.944024Z","iopub.execute_input":"2021-08-26T02:17:55.94435Z","iopub.status.idle":"2021-08-26T02:17:55.97241Z","shell.execute_reply.started":"2021-08-26T02:17:55.94432Z","shell.execute_reply":"2021-08-26T02:17:55.971156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Great! I have deleted all the columns (even though it is a column)! Let's divide date_added in more detail into years, month and day.\ndf[[\"month_added\", \"day_added\", \"year_added\", \"null1\"]] = df[\"date_added\"].str.split(\" \", expand = True)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-26T02:17:55.973973Z","iopub.execute_input":"2021-08-26T02:17:55.974262Z","iopub.status.idle":"2021-08-26T02:17:56.013808Z","shell.execute_reply.started":"2021-08-26T02:17:55.974235Z","shell.execute_reply":"2021-08-26T02:17:56.012154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# delete null1 columns and get rid of \",\" from day_added column\ndf.drop(columns = [\"null1\"], inplace = True)\ndf[\"day_added\"] = df[\"day_added\"].str.replace(',','')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-26T02:17:56.015589Z","iopub.execute_input":"2021-08-26T02:17:56.016054Z","iopub.status.idle":"2021-08-26T02:17:56.055368Z","shell.execute_reply.started":"2021-08-26T02:17:56.016011Z","shell.execute_reply":"2021-08-26T02:17:56.053955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's reorder the columns and delete date_added column\ndf.columns","metadata":{"execution":{"iopub.status.busy":"2021-08-26T02:17:56.057322Z","iopub.execute_input":"2021-08-26T02:17:56.057773Z","iopub.status.idle":"2021-08-26T02:17:56.065495Z","shell.execute_reply.started":"2021-08-26T02:17:56.057709Z","shell.execute_reply":"2021-08-26T02:17:56.064168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df[['type', 'title', 'country', 'month_added', 'day_added', 'year_added',\n       'release_year', 'rating', 'duration', 'listed_in', 'description',\n        'director', 'cast']]","metadata":{"execution":{"iopub.status.busy":"2021-08-26T02:17:56.069477Z","iopub.execute_input":"2021-08-26T02:17:56.070016Z","iopub.status.idle":"2021-08-26T02:17:56.081041Z","shell.execute_reply.started":"2021-08-26T02:17:56.069968Z","shell.execute_reply":"2021-08-26T02:17:56.079909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-08-26T02:17:56.082975Z","iopub.execute_input":"2021-08-26T02:17:56.083265Z","iopub.status.idle":"2021-08-26T02:17:56.106137Z","shell.execute_reply.started":"2021-08-26T02:17:56.083237Z","shell.execute_reply":"2021-08-26T02:17:56.104622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's perform basic EAD to understand the data first. we will be suing plotly\n\nimport plotly.graph_objects as go\nimport math\ndf_type = pd.DataFrame(df[\"type\"].value_counts())\ndf_type\n\nfig = go.Figure(data=go.Bar(x = df_type.index, y = df_type[\"type\"]))\nfig.show()\n\n\"{:.2f}\".format(13.949999999999999)\n\nprint(f' Netflix has more {float((df_type.loc[\"Movie\"] / df_type.loc[\"TV Show\"]))} times more movie than TV Shows.')\n# netflix has more 2.23 times more movies than TV Shows","metadata":{"execution":{"iopub.status.busy":"2021-08-26T02:17:56.1077Z","iopub.execute_input":"2021-08-26T02:17:56.108146Z","iopub.status.idle":"2021-08-26T02:17:56.132431Z","shell.execute_reply.started":"2021-08-26T02:17:56.108102Z","shell.execute_reply":"2021-08-26T02:17:56.131095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# EAD for country\ndf_country = pd.DataFrame(df[\"country\"].value_counts())\ndf_country.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-26T02:17:56.134365Z","iopub.execute_input":"2021-08-26T02:17:56.13467Z","iopub.status.idle":"2021-08-26T02:17:56.151269Z","shell.execute_reply.started":"2021-08-26T02:17:56.134642Z","shell.execute_reply":"2021-08-26T02:17:56.150034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's examine how many countries we have\ndf_country.shape\n# we will be only visualize for top 15 countries\ndf_country.sort_values(by = [\"country\"], ascending = False, inplace = True)\ndf_count15 = df_country.head(15)","metadata":{"execution":{"iopub.status.busy":"2021-08-26T02:17:56.152703Z","iopub.execute_input":"2021-08-26T02:17:56.153139Z","iopub.status.idle":"2021-08-26T02:17:56.166544Z","shell.execute_reply.started":"2021-08-26T02:17:56.153096Z","shell.execute_reply":"2021-08-26T02:17:56.165493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from plotly.subplots import make_subplots\n# Let's do ead for the df_country\nfig = go.Figure(data=go.Bar(x = df_count15.index, y = df_count15[\"country\"]))\n\nfig = make_subplots(rows=1, cols=2, column_widths=[0.7, 0.3])\n\nfig.add_trace(go.Bar(x=df_count15.index, y=df_count15[\"country\"]),\n              row=1, col=1)\n\nfig.add_trace(go.Scatter(x=df_count15.index, y=df_count15[\"country\"]),\n              row=1, col=2)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-26T02:17:56.167919Z","iopub.execute_input":"2021-08-26T02:17:56.168207Z","iopub.status.idle":"2021-08-26T02:17:56.217078Z","shell.execute_reply.started":"2021-08-26T02:17:56.168178Z","shell.execute_reply":"2021-08-26T02:17:56.216124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# How about the rating?\n# EAD for country\ndf_rating = pd.DataFrame(df[\"rating\"].value_counts())\ndf_rating.head()\n\nfig = go.Figure(data=[go.Pie(labels=df_rating.index, values=df_rating['rating'])])\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-26T02:17:56.218995Z","iopub.execute_input":"2021-08-26T02:17:56.219298Z","iopub.status.idle":"2021-08-26T02:17:56.236285Z","shell.execute_reply.started":"2021-08-26T02:17:56.219266Z","shell.execute_reply":"2021-08-26T02:17:56.235363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now we want to explore listed_in column\n# First of all let's figure out how many unique categories we have\nimport re\nmerged_cat = \"\"\n# merge all the column into a string\nfor i in df[\"listed_in\"]:\n    merged_cat += i\n    merged_cat += \"@\"\n# split the list with , & and @\nmerged = re.split(', |&|@',merged_cat)\n# get rid of space\nmerged = [i.strip() for i in merged]\nprint(f\"in total we have {df.shape[0]} tv series and movies and overall it is defined by {len(merged)} which accounts for {len(merged)/ df.shape[0]} per show\")","metadata":{"execution":{"iopub.status.busy":"2021-08-26T02:17:56.237264Z","iopub.execute_input":"2021-08-26T02:17:56.237664Z","iopub.status.idle":"2021-08-26T02:17:56.272372Z","shell.execute_reply.started":"2021-08-26T02:17:56.237632Z","shell.execute_reply":"2021-08-26T02:17:56.270917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's visualize what type of tv show or movie is listed in netflix the most?\nlist_value = pd.DataFrame(merged).value_counts()\nlist_value = pd.DataFrame(list_value)\nlist_value.columns = [\"list\"]\ntype(list(list_value.index)[0][0])\na = [i[0] for i in list(list_value.index)]\na\nfig = go.Figure(data=go.Bar(x = a, y = list_value[\"list\"]))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-26T02:17:56.274119Z","iopub.execute_input":"2021-08-26T02:17:56.27445Z","iopub.status.idle":"2021-08-26T02:17:56.303954Z","shell.execute_reply.started":"2021-08-26T02:17:56.27442Z","shell.execute_reply":"2021-08-26T02:17:56.302358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The below is the top 10 netflix show category\n#list_value = list_value[\"list\"] / df.shape[0]\nlist_value.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-08-26T02:17:56.305523Z","iopub.execute_input":"2021-08-26T02:17:56.305861Z","iopub.status.idle":"2021-08-26T02:17:56.317906Z","shell.execute_reply.started":"2021-08-26T02:17:56.30583Z","shell.execute_reply":"2021-08-26T02:17:56.316312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now we will check the release year\ndf_release = df[[\"year_added\",\"type\"]]\ndf_release[\"dummy\"] = 1\ndf_release\ntable = pd.pivot_table(df_release, values = \"dummy\",\n                      index = [\"year_added\"],columns = [\"type\"],aggfunc=np.sum)\ntable.fillna(0, inplace = True)\n\ndate = np.arange(2008, 2022, 1)\n\n#list(table[\"year_added\"]).index(2008)\n\n# list(table.index).index(\"2008\")\n# 12 - 25\n\n\ntable[\"Movie\"][12:26]\n\n\nfig = make_subplots(rows=1, cols=2, column_widths=[0.5, 0.5])\n\nfig.add_trace(go.Bar(x= date, y=table[\"Movie\"][12:26]),\n              row=1, col=1)\n\nfig.add_trace(go.Bar(x=date, y=table[\"TV Show\"][12:26]),\n              row=1, col=2)\n\nfig.show()\n\nprint(\"Trace 0 is Movie and Trace 1 is TV Show. We can see that number of TV show is increasing whereas Movie has decrease from 2020\")","metadata":{"execution":{"iopub.status.busy":"2021-08-26T02:17:56.319649Z","iopub.execute_input":"2021-08-26T02:17:56.320131Z","iopub.status.idle":"2021-08-26T02:17:56.38246Z","shell.execute_reply.started":"2021-08-26T02:17:56.32007Z","shell.execute_reply":"2021-08-26T02:17:56.381241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now I have a interesting hypothesis : If movie or tv show is {good}, then Netflix will {add to their website fast}\n\nLet's see my hyphothesis is true!\n\nHere we have two term that we have to define\n\nGood -> Good rating in Rotten Tomato (need to pull out from different data set)\nadd to their website fast -> added_year - release_year (we can make an additional column)\n\nTo Be Continue....","metadata":{}},{"cell_type":"code","source":"a = df.groupby(by = \"year_added\").count()[\"type\"]\na = pd.DataFrame(a)\ndate = list(map(str,np.arange(2016,2022,1)))\nadded_per = float(a.loc[date].sum() / a.sum()) * 100\nprint(f' {\"{:.2f}\".format(added_per)} % of movie and tv shows were added between 2016 - 2021 so we will only examine the movie and tv shows that were released after 2016')\n","metadata":{"execution":{"iopub.status.busy":"2021-08-26T02:17:56.384323Z","iopub.execute_input":"2021-08-26T02:17:56.384804Z","iopub.status.idle":"2021-08-26T02:17:56.414986Z","shell.execute_reply.started":"2021-08-26T02:17:56.384762Z","shell.execute_reply":"2021-08-26T02:17:56.413506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_newMovie = df[df['release_year'] > 2015]\n# make sure to convert all the columns into int\nprev_size = df_newMovie.shape[0]\nprint(df_newMovie.shape[0])\ndf_newMovie[\"year_added\"] = list(map(str, df_newMovie[\"year_added\"]))\ndf_newMovie[\"year_added\"].value_counts()\ndf_newMovie[\"year_added\"] = list(map(str.strip, df_newMovie[\"year_added\"]))\ndf_newMovie[\"year_added_len\"] = list(map(len, df_newMovie[\"year_added\"]))\ndf_newMovie = df_newMovie[df_newMovie[\"year_added_len\"]==4]\nnew_size = (df_newMovie.shape[0])\nprint(df_newMovie.shape)\nprint(f' {prev_size - new_size} row has been deleted')\ndf_newMovie[\"year_added\"] = list(map(int, df_newMovie[\"year_added\"]))\ndf_newMovie[\"fast\"] = df_newMovie[\"year_added\"] - df_newMovie[\"release_year\"]\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-26T02:17:56.41665Z","iopub.execute_input":"2021-08-26T02:17:56.417247Z","iopub.status.idle":"2021-08-26T02:17:56.451858Z","shell.execute_reply.started":"2021-08-26T02:17:56.417214Z","shell.execute_reply":"2021-08-26T02:17:56.451109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Okay we Finally got the \"Fast\" Columns. Let's see how it looks like","metadata":{}},{"cell_type":"code","source":"df_newMovie[\"fast\"].value_counts()\n","metadata":{"execution":{"iopub.status.busy":"2021-08-26T02:17:56.452807Z","iopub.execute_input":"2021-08-26T02:17:56.453277Z","iopub.status.idle":"2021-08-26T02:17:56.460351Z","shell.execute_reply.started":"2021-08-26T02:17:56.453249Z","shell.execute_reply":"2021-08-26T02:17:56.459389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_title = pd.read_csv(\"../input/titletsv/title.tsv\", sep = \"/t\")\n# ../input/netflix-shows\n# ../input/titletsv\n# ../input/netflix-shows","metadata":{"execution":{"iopub.status.busy":"2021-08-26T02:25:11.792761Z","iopub.execute_input":"2021-08-26T02:25:11.79319Z","iopub.status.idle":"2021-08-26T02:25:44.36296Z","shell.execute_reply.started":"2021-08-26T02:25:11.793154Z","shell.execute_reply":"2021-08-26T02:25:44.36081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}