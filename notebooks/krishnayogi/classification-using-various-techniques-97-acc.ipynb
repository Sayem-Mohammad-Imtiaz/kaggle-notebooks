{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"## Importing Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt              # Data Visualization\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split     # For Train/Test Split","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"Dataset = pd.read_csv(\"/kaggle/input/mobile-price-classification/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Dataset.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Dataset.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Analysing the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"Dataset.info()                             # Checking Data types","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Dataset.isnull().sum()                      # Checking Null-values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Dataset.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Displaying number of samples for each Disease\nfig, ax = plt.subplots(figsize = (10, 4))\nsns.countplot(x ='price_range', data=Dataset)\nplt.xlabel(\"Class Label\")\nplt.ylabel(\"Number of Samples\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, we have perfectly balanced Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculating Correlation between features\ncorrmat = Dataset.corr()                ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizing Correlation between every feature\nf, ax = plt.subplots(figsize =(9, 8)) \nsns.heatmap(corrmat, ax = ax, cmap =\"YlGnBu\", linewidths = 0.1) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corrmat['price_range']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corrmat['price_range'] = abs(corrmat['price_range'])          # Converting all values to positives","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corrmat['price_range']                                        # All positive values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new = corrmat.sort_values(by=['price_range'])                 # Sorting correlation values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new['price_range']                                            # Final list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Selecting features with correlation more than 0.022\nfeatures = ['ram', 'battery_power', 'px_width', 'px_height', 'int_memory', 'sc_w', 'pc', 'touch_screen',\n            'mobile_wt', 'three_g', 'sc_h', 'price_range']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Dataset = Dataset[features]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Dataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Splitting Data and Targets"},{"metadata":{"trusted":true},"cell_type":"code","source":"Target = np.array(Dataset.pop('price_range'))             # Target\nData   = np.array(Dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (Data)\nprint (Target)\nprint (\"Shape of input Data is: \", Data.shape)\nprint (\"Shape of input Data is: \", Target.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating Training and Testing Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(Data, Target, test_size=0.2, random_state=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"Shape of Train Data is:  \", X_train.shape)\nprint (\"Shape of Test  Data is:  \", X_test.shape)\nprint (\"Shape of Train Label is: \", Y_train.shape)\nprint (\"Shape of Test  Label is: \", Y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Implementing Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = []\nx_axis_DT = range(3,12)\nfor i in range(3,12):\n    DT = DecisionTreeClassifier(criterion = \"gini\",\n                                random_state = 100,\n                                max_depth=i, \n                                min_samples_leaf=5)\n    DT.fit(X_train, Y_train)\n    y_pred = DT.predict(X_test)\n    accuracy = accuracy_score(Y_test,y_pred)*100\n    acc.append(accuracy)\n    print (\"Accuracy for Decision for max depth \",i,\" is: \", accuracy) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize = (10, 4))\nplt.plot(x_axis_DT,acc)\nplt.xlabel('Maximum Depth')\nplt.ylabel('Accuracy')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Choosing maximum depth = 6"},{"metadata":{},"cell_type":"markdown","source":"## Implementing Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_RF = []\nx_axis_RF = range(5,31)\nfor i in range(5,31):\n    RF = RandomForestClassifier(n_estimators = i, random_state = 0)\n    RF.fit(X_train, Y_train)\n    y_pred = RF.predict(X_test)\n    accuracy = accuracy_score(Y_test,y_pred)*100\n    acc_RF.append(accuracy)\n    print (\"Accuracy for Random Forest for max depth \",i,\" is: \", accuracy) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize = (10, 4))\nplt.plot(x_axis_RF,acc_RF)\nplt.xlabel('Number of Estimators')\nplt.ylabel('Accuracy')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Choosing n_estimators = 26"},{"metadata":{},"cell_type":"markdown","source":"## Implementing KNN Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_KNN = []\nx_axis_KNN = range(5,16)\nfor i in range(5,16):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train, Y_train)\n    y_pred = knn.predict(X_test)\n    accuracy = accuracy_score(Y_test,y_pred)*100\n    acc_KNN.append(accuracy)\n    print (\"Accuracy for KNN for k = \",i,\" is: \", accuracy) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize = (10, 4))\nplt.plot(x_axis_KNN,acc_KNN)\nplt.xlabel('Number of Estimators')\nplt.ylabel('Accuracy')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Choosing k = 13"},{"metadata":{},"cell_type":"markdown","source":"## Implementing Naive bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NB = MultinomialNB()\nNB.fit(Data, Target)\ny_pred = NB.predict(X_test)\naccuracy = accuracy_score(Y_test,y_pred)*100\nprint (\"Accuracy of Naive Bayes Classifier is: \", accuracy) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Implementing Naive Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svc = SVC(kernel='linear')\nsvc.fit(X_train, Y_train)\ny_pred = svc.predict(X_test)\naccuracy = accuracy_score(Y_test,y_pred)*100\nprint (\"Accuracy of Naive Bayes Classifier is: \", accuracy) ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}