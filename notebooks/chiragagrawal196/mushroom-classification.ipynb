{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split as tts, RandomizedSearchCV,StratifiedShuffleSplit\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder, power_transform\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, classification_report, r2_score, precision_recall_curve, roc_auc_score, roc_curve, auc, f1_score, recall_score, precision_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.feature_selection import SelectKBest, RFE, RFECV, chi2   #chi2 aka. chi square is used when working with 2 categorical columns.\nfrom sklearn.decomposition import PCA\nfrom scipy import stats\nimport statsmodels.api as sm\nimport pprint\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Importing Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values = [\"n/a\", \"na\", \"--\", \"NONE\", \"None\", \"none\", \"NA\", \"N/A\",'inf','-inf']\ndata = pd.read_csv('../input/mushroom-classification/mushrooms.csv', na_values=missing_values)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Creating Train and Test sets using Stratified Shuffle Split**\n"},{"metadata":{},"cell_type":"markdown","source":"**Stratified Shuffle split will not create sampling bias as it will choose some samples from all the target classes.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"split = StratifiedShuffleSplit(n_splits = 1, random_state=42, test_size=0.2) #n_splits = 1, because I want to divide data into train and test sets\nfor train_index, test_index in split.split(data, data['class']):\n  stratified_train_data = data.loc[train_index]\n  stratified_test_data = data.loc[test_index]\n\nprint(stratified_train_data.shape , stratified_test_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stratified_test_data.drop(['class'],1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Using Stratified Train Data**"},{"metadata":{},"cell_type":"markdown","source":"**Label Encoding the data as ML model does not accept non-numerical values**"},{"metadata":{"trusted":true},"cell_type":"code","source":"le = LabelEncoder()\nstratified_train_data[[\"cap-shape\",'cap-surface','cap-color','bruises','odor','gill-attachment','gill-spacing','gill-size','gill-color','stalk-shape','stalk-root','stalk-surface-above-ring','stalk-surface-below-ring','stalk-color-above-ring','stalk-color-below-ring','veil-type','veil-color','ring-number','ring-type','spore-print-color','population','habitat']] = stratified_train_data[[\"cap-shape\",'cap-surface','cap-color','bruises','odor','gill-attachment','gill-spacing','gill-size','gill-color','stalk-shape','stalk-root','stalk-surface-above-ring','stalk-surface-below-ring','stalk-color-above-ring','stalk-color-below-ring','veil-type','veil-color','ring-number','ring-type','spore-print-color','population','habitat']].apply(le.fit_transform)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stratified_train_data['class'] = stratified_train_data['class'].replace('p',0)\nstratified_train_data['class'] = stratified_train_data['class'].replace('e',1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Creating a Pearson Correlation function for deleting column with above threshold value. In this case I have chosen 0.6 or 60%**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def correlation(dataset, threshold):\n    col_corr = set()  # Set of all the names of correlated columns\n    corr_matrix = dataset.corr()\n    for i in range(len(corr_matrix.columns)):\n        for j in range(i):\n            if (corr_matrix.iloc[i, j]) > threshold:\n                colname = corr_matrix.columns[i]  # getting the name of column\n                col_corr.add(colname)\n    return col_corr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_features = correlation(stratified_train_data.iloc[:,:22], 0.6)\nprint(\"Number of correlated features are :\",len(set(corr_features)))\nprint(\"Independent correlated features are to be deleted are :\",corr_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Deleting columns which have feature to target correlation between -0.1 to 0.1 as they are very less correlated to target**"},{"metadata":{"trusted":true},"cell_type":"code","source":"stratified_train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stratified_train_data = stratified_train_data[['cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor',\n       'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color',\n       'stalk-shape', 'stalk-root', 'stalk-surface-above-ring',\n       'stalk-surface-below-ring', 'stalk-color-above-ring',\n       'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number',\n       'ring-type', 'spore-print-color', 'population', 'habitat','class']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stratified_train_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('FEATURES CORRELATION TO TARGET VALUES :')\ntrain_data_corr = stratified_train_data[stratified_train_data.columns[1:]].corr()['class'][:]\nprint(train_data_corr)\nprint(\"=================================================\")\nprint('DELETING FETAURES THAT ARE LESS CORRELATED TO TARGET VARIABLES BETWEEN -0.1 & 0.1')\ntrain_data_corr.drop(train_data_corr[(train_data_corr.values > -0.1 ) & (train_data_corr.values < 0.1)].index, inplace=True)\nprint(train_data_corr)\nprint(\"=================================================\")\nprint(\"PRINTING THE DELETED COLUMN NAMES\")\nnew_train_data = stratified_train_data.columns[~stratified_train_data.columns.isin(train_data_corr.index)]\nprint(new_train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#DELETING ALL THE UNWANTED COLUMNS AND ALSO DELETING THE 'veil-type' COLUMN AS IT IS USELESS FOR US\nstratified_train_data.drop(['cap-shape','cap-color','veil-type','veil-color', 'spore-print-color', 'ring-type'],1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = stratified_train_data.drop('class',1)\ny = stratified_train_data['class']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Selection"},{"metadata":{},"cell_type":"markdown","source":"### Using SelectKBest library of sklearn to select features that are most important using chi-square hypothesis testing.\n\n\n> chi sqaure hypothesis testing uses two columns for working. Here Two columns will be feature and another is target.\n\n\n> This will be done iteratively with every feature until the k value of SelectKBest is reached.\n\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"select_K_Best = SelectKBest(k=9, score_func=chi2)\nselected_features = select_K_Best.fit(X, y)\nindices_selected = selected_features.get_support(indices=True)\ncolnames_selected = [X.columns[i] for i in indices_selected]\n\nX = X[colnames_selected]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The 9 most important features chosen by SelectKBest are : \\n {} \".format(X.columns))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Calculating Multicollinearity in data\n\n* Using Variance Inflation Factor to check the multicollinearity or dependency in independent columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"def calc_vif(X):\n    vif = pd.DataFrame()\n    vif[\"variables\"] = X.columns\n    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n\n    return(vif)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calc_vif(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X['stalk-surface'] = X['stalk-surface-above-ring'] + X['stalk-surface-below-ring']\nX['stalk-surface']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.drop(['stalk-surface-above-ring','stalk-surface-below-ring'],1,inplace= True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calc_vif(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Models like linear regression and logistic regression assume that data follows gaussian distribution so to use that we transform skewed data to normal distributed \ndata. But SVM, Neural Network, Tree based and boosting does not require to transform data.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"skewness_of_df = pd.DataFrame(X.skew())\nskewness_of_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def boxcox_transformation(df,column):\n  try:\n    for column in df:\n      if ((df[column].skew() > 1.0) or (df[column].skew() < -1.0).any()):\n        plt.figure(figsize=(15,6))\n        plt.subplot(1, 2, 1)\n        df[column].hist()\n\n        plt.subplot(1, 2, 2)\n        stats.probplot(df[column], dist=\"norm\", plot=plt)\n        print(df[column].skew())\n \n        df[column], params = stats.boxcox(df[column]+1)\n\n        plt.figure(figsize=(15,6))\n        plt.subplot(2, 2, 1)\n        df[column].hist()\n\n        plt.subplot(2, 2, 2)\n        stats.probplot(df[column], dist=\"norm\", plot=plt)\n        print(data[column].skew())\n\n        return boxcox_transformation\n  except TypeError:\n       print(\"\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"column = ['bruises','gill-spacing','gill-size','gill-color','stalk-root','population','habitat','stalk-surface']\nboxcox_transformation(X,column)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pricipal Component Analysis"},{"metadata":{},"cell_type":"markdown","source":"**Applying Principal Component Analysis (PCA), this helps to handle multicollinearity in data as column stalk-surface has high multicollinearity.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components = 7,random_state=42)\ntransformed_data = pca.fit_transform(X)\nX = pd.DataFrame(data = transformed_data, columns = ['PCA1','PCA2','PCA3','PCA4','PCA5','PCA6','PCA7'])\nX","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The explained_variance_ratio gives the variance of every column. In our case the remaining columns are 7 as passed in n_components = 7.**\n\n**The noise_variance gives the overall noise in the data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(pca.explained_variance_ratio_)\nprint(pca.noise_variance_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = tts(X, y, random_state=42,test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(model, X_test, y_test, X_train, y_train):\n    y_pred = model.predict(X_test)\n    errors = abs(y_pred - y_test)\n    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n    print(classification_report(y_test,y_pred))\n    print(confusion_matrix(y_test,y_pred))\n    print('Recall Score = ',recall_score(y_test, y_pred))\n    print('Precision Score = ',precision_score(y_test, y_pred))\n\n    return evaluate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_auc_roc_curve(model, X_test, y_test, X_train, y_train):\n  y_pred = model.predict(X_test)\n  print(\"roc curve :\",roc_curve(y_test,y_pred))\n  base_fpr,base_tpr,base_threshold = roc_curve(y_train, model.predict(X_train))\n  plt.plot([0,1])\n  plt.plot(base_fpr,base_tpr)\n  print(\"auc score :\",auc(base_fpr,base_tpr))\n\n  return train_auc_roc_curve","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_auc_ruc_curve(model, X_test, y_test):\n  test_fpr, test_tpr, test_threshold = roc_curve(y_test,model.predict(X_test))\n  test_auc = auc(test_fpr, test_tpr)\n  print(test_auc)\n  plt.plot([0,1])\n  plt.plot(test_fpr, test_tpr)\n\n  return test_auc_ruc_curve","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Applying Classification models"},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression"},{"metadata":{},"cell_type":"markdown","source":"## Default Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"default_logistic_model = LogisticRegression(random_state = 1)\ndefault_logistic_model.fit(X_train, y_train)\nbase_accuracy = evaluate(default_logistic_model, X_test, y_test, X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_auc_roc_curve(default_logistic_model, X_test, y_test, X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tuned Logistic Regression "},{"metadata":{"trusted":true},"cell_type":"code","source":"logistic = LogisticRegression(random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_parameters = ({'C' : [0.001, 0.01, 0.1, 1.0],\n                      'penalty' : ['l2'],\n                      'solver' : ['lbfgs', 'newton-cg', 'saga'],\n                      'max_iter' : [300,400,500,600,700,900,1000]})\n\nrandom_search_logistic = RandomizedSearchCV(logistic, param_distributions= random_parameters, n_iter=60, cv=5)\nrandom_search_logistic.fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(random_search_logistic.best_estimator_)\nprint(random_search_logistic.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logistic = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                   intercept_scaling=1, l1_ratio=None, max_iter=600,\n                   multi_class='auto', n_jobs=None, penalty='l2',\n                   random_state=42, solver='newton-cg', tol=0.0001, verbose=0,\n                   warm_start=False)\nlogistic.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluate(logistic, X_test, y_test, X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_auc_roc_curve(logistic, X_test, y_test, X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Decision Tree Classifier "},{"metadata":{},"cell_type":"markdown","source":"### Default Decision Tree Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"default_decision_tree_model = DecisionTreeClassifier(random_state=42)\ndefault_decision_tree_model.fit(X_train, y_train)\nbase_accuracy = evaluate(default_decision_tree_model, X_test, y_test, X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_auc_roc_curve(default_decision_tree_model, X_test, y_test, X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tuned Decision Tree Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"dtree_classifier = DecisionTreeClassifier(random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**cost_complexity_pruning_path helps to find different ccp values which will be later used in random search for choosing the best one**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"path = dtree_classifier.cost_complexity_pruning_path(X_train, y_train)\nalphas = path['ccp_alphas']\nalphas","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_dtree_parameters = ({'ccp_alpha' : alphas,\n                             'criterion' : ['gini','entropy'],\n                            'splitter' : ['best','random'],\n                            'max_depth' : [8,10,12,15,20,24,32],\n                            'min_samples_leaf' : [2,3,5],\n                            'max_features' : ['auto', 'sqrt', 'log2']})\n\nrandom_search_dtree = RandomizedSearchCV(dtree_classifier, param_distributions= random_dtree_parameters, n_iter=60, cv=5)\nrandom_search_dtree.fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(random_search_dtree.best_estimator_)\nprint(random_search_dtree.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtree_classifier = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n                       max_depth=20, max_features='auto', max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=3, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, presort='deprecated',\n                       random_state=42, splitter='best')\ndtree_classifier.fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluate(dtree_classifier, X_test, y_test, X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_auc_roc_curve(dtree_classifier, X_test, y_test, X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Using Stratified Test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"stratified_test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le = LabelEncoder()\nstratified_test_data[[\"cap-shape\",'cap-surface','cap-color','bruises','odor','gill-attachment','gill-spacing','gill-size','gill-color','stalk-shape','stalk-root','stalk-surface-above-ring','stalk-surface-below-ring','stalk-color-above-ring','stalk-color-below-ring','veil-type','veil-color','ring-number','ring-type','spore-print-color','population','habitat']] = stratified_test_data[[\"cap-shape\",'cap-surface','cap-color','bruises','odor','gill-attachment','gill-spacing','gill-size','gill-color','stalk-shape','stalk-root','stalk-surface-above-ring','stalk-surface-below-ring','stalk-color-above-ring','stalk-color-below-ring','veil-type','veil-color','ring-number','ring-type','spore-print-color','population','habitat']].apply(le.fit_transform)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**DELETING ALL THE UNWANTED COLUMNS AND ALSO DELETING THE 'veil-type' COLUMN AS IT IS USELESS FOR US**"},{"metadata":{"trusted":true},"cell_type":"code","source":"stratified_test_data.drop(['cap-shape','cap-color','veil-type','veil-color', 'spore-print-color', 'ring-type'],1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stratified_test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(stratified_test_data.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stratified_test_data['stalk-surface'] = stratified_test_data['stalk-surface-above-ring'] + stratified_test_data['stalk-surface-below-ring']\nstratified_test_data['stalk-surface']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stratified_test_data.drop(['stalk-color-above-ring', 'stalk-color-below-ring','stalk-surface-above-ring','stalk-surface-below-ring','cap-surface','odor', 'gill-attachment', 'stalk-shape', 'ring-number'],1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Remaining Columns are \\n: {}\". format(stratified_test_data.columns))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"column = ['bruises','gill-spacing','gill-size','gill-color','stalk-root','population','habitat','stalk-surface']\nboxcox_transformation(stratified_test_data,column)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pca = PCA(n_components = 7,random_state=42)\ntransformed_test_data = test_pca.fit_transform(stratified_test_data)\ntest_x = pd.DataFrame(data = transformed_test_data, columns = ['PCA1','PCA2','PCA3','PCA4','PCA5','PCA6','PCA7'])\ntest_x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sc = StandardScaler()\ntest_x = sc.fit_transform(test_x)\nprint(test_x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Testing Default Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_auc_ruc_curve(default_logistic_model, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Testing Tuned Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_auc_ruc_curve(logistic, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Default Decision tree classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_auc_ruc_curve(default_decision_tree_model, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Testing Tuned Decision Tree "},{"metadata":{"trusted":true},"cell_type":"code","source":"test_auc_ruc_curve(dtree_classifier, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**My Conclusion\n\n**Models applied :\n\n** 1.Logistic Regression (Default and Tuned)**\n\n   2.Decision Tree Classifier (Default and Tuned)**\n* Default models run better than tuned models"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}