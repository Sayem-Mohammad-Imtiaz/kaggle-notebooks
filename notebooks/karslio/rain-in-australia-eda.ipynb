{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-04T17:35:39.435474Z","iopub.execute_input":"2021-06-04T17:35:39.435815Z","iopub.status.idle":"2021-06-04T17:35:39.445899Z","shell.execute_reply.started":"2021-06-04T17:35:39.43578Z","shell.execute_reply":"2021-06-04T17:35:39.444707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d = pd.read_csv('/kaggle/input/weather-dataset-rattle-package/weatherAUS.csv')\nd","metadata":{"execution":{"iopub.status.busy":"2021-06-04T17:35:39.447434Z","iopub.execute_input":"2021-06-04T17:35:39.447705Z","iopub.status.idle":"2021-06-04T17:35:39.969442Z","shell.execute_reply.started":"2021-06-04T17:35:39.447678Z","shell.execute_reply":"2021-06-04T17:35:39.968725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1- Read the dataset as a dataframe. Create a copy of your dataframe. Solve the rest of the questions using this dataframe copy.","metadata":{}},{"cell_type":"code","source":"df=d.copy()\ndf","metadata":{"execution":{"iopub.status.busy":"2021-06-04T17:35:39.971252Z","iopub.execute_input":"2021-06-04T17:35:39.971838Z","iopub.status.idle":"2021-06-04T17:35:40.104643Z","shell.execute_reply.started":"2021-06-04T17:35:39.97179Z","shell.execute_reply":"2021-06-04T17:35:40.103524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2-Find out the describe and info attributes of the dataframe. Analyze these information and create a short write-up according to your findings.","metadata":{}},{"cell_type":"code","source":"# Info of data\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-04T17:35:40.106113Z","iopub.execute_input":"2021-06-04T17:35:40.1066Z","iopub.status.idle":"2021-06-04T17:35:40.165475Z","shell.execute_reply.started":"2021-06-04T17:35:40.10656Z","shell.execute_reply":"2021-06-04T17:35:40.164331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe().T","metadata":{"execution":{"iopub.status.busy":"2021-06-04T17:35:40.168348Z","iopub.execute_input":"2021-06-04T17:35:40.168628Z","iopub.status.idle":"2021-06-04T17:35:40.341101Z","shell.execute_reply.started":"2021-06-04T17:35:40.168601Z","shell.execute_reply":"2021-06-04T17:35:40.339967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# std degeri ne kadar yukskse veri yayilimi o kadar fazla \n# mean ve %50 degerleri birbirine yakinsa normal dagilim denebilir \n","metadata":{"execution":{"iopub.status.busy":"2021-06-04T17:35:40.34333Z","iopub.execute_input":"2021-06-04T17:35:40.343608Z","iopub.status.idle":"2021-06-04T17:35:40.347498Z","shell.execute_reply.started":"2021-06-04T17:35:40.343582Z","shell.execute_reply":"2021-06-04T17:35:40.34654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3- Find out the shape and size info of the dataset.","metadata":{"execution":{"iopub.status.busy":"2021-06-04T14:07:01.367831Z","iopub.execute_input":"2021-06-04T14:07:01.370025Z","iopub.status.idle":"2021-06-04T14:07:01.38371Z","shell.execute_reply.started":"2021-06-04T14:07:01.369879Z","shell.execute_reply":"2021-06-04T14:07:01.381595Z"}}},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-04T17:35:40.348498Z","iopub.execute_input":"2021-06-04T17:35:40.348735Z","iopub.status.idle":"2021-06-04T17:35:40.365014Z","shell.execute_reply.started":"2021-06-04T17:35:40.348711Z","shell.execute_reply":"2021-06-04T17:35:40.363991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.size","metadata":{"execution":{"iopub.status.busy":"2021-06-04T17:35:40.366193Z","iopub.execute_input":"2021-06-04T17:35:40.366611Z","iopub.status.idle":"2021-06-04T17:35:40.379326Z","shell.execute_reply.started":"2021-06-04T17:35:40.366577Z","shell.execute_reply":"2021-06-04T17:35:40.378448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4- Find out the types values of the columns and save the result as a dataframe.","metadata":{"execution":{"iopub.status.busy":"2021-06-04T14:09:48.814078Z","iopub.execute_input":"2021-06-04T14:09:48.81454Z","iopub.status.idle":"2021-06-04T14:09:48.818603Z","shell.execute_reply.started":"2021-06-04T14:09:48.814498Z","shell.execute_reply":"2021-06-04T14:09:48.817666Z"}}},{"cell_type":"code","source":"df1 = df.dtypes.to_frame('dtypes').reset_index()\ndf1","metadata":{"execution":{"iopub.status.busy":"2021-06-04T17:35:40.381529Z","iopub.execute_input":"2021-06-04T17:35:40.382011Z","iopub.status.idle":"2021-06-04T17:35:40.400733Z","shell.execute_reply.started":"2021-06-04T17:35:40.381967Z","shell.execute_reply":"2021-06-04T17:35:40.400036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5- Find out the non-null counts of the columns and save the result as a dataframe.","metadata":{}},{"cell_type":"code","source":"df2 = pd.DataFrame(df.shape[0]-df.isna().sum(), columns = ['notnull'])\ndf2.reset_index(level=0, inplace=True)\ndf2","metadata":{"execution":{"iopub.status.busy":"2021-06-04T17:35:40.402365Z","iopub.execute_input":"2021-06-04T17:35:40.402856Z","iopub.status.idle":"2021-06-04T17:35:40.461496Z","shell.execute_reply.started":"2021-06-04T17:35:40.402815Z","shell.execute_reply":"2021-06-04T17:35:40.460437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6- Find out the null counts of the columns and save the result as a dataframe.","metadata":{}},{"cell_type":"code","source":"df3 = pd.DataFrame(df.isnull().sum(), columns = ['isnull'])\ndf3.reset_index(level=0, inplace=True)\ndf3","metadata":{"execution":{"iopub.status.busy":"2021-06-04T17:35:40.4627Z","iopub.execute_input":"2021-06-04T17:35:40.463112Z","iopub.status.idle":"2021-06-04T17:35:40.515292Z","shell.execute_reply.started":"2021-06-04T17:35:40.463081Z","shell.execute_reply":"2021-06-04T17:35:40.514585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7- Find out the unique counts of the columns and save the result as a dataframe.","metadata":{}},{"cell_type":"code","source":"df4 = pd.DataFrame(df.nunique(), columns = ['nunique'])\ndf4.reset_index(level=0, inplace=True)\ndf4","metadata":{"execution":{"iopub.status.busy":"2021-06-04T17:35:40.516147Z","iopub.execute_input":"2021-06-04T17:35:40.516498Z","iopub.status.idle":"2021-06-04T17:35:40.664733Z","shell.execute_reply.started":"2021-06-04T17:35:40.516472Z","shell.execute_reply":"2021-06-04T17:35:40.663993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 8- Merge the dataframes you created in questions 4-5-6-7.","metadata":{}},{"cell_type":"code","source":"df_info = pd.merge(pd.merge(pd.merge(df1,df2),df3),df4)\ndf_info.rename(columns={\"index\": \"Columns\"}, inplace=True)\ndf_info[\"%null\"] = (df_info[\"isnull\"])/len(df)*100\ndf_info","metadata":{"execution":{"iopub.status.busy":"2021-06-04T17:35:40.665602Z","iopub.execute_input":"2021-06-04T17:35:40.665975Z","iopub.status.idle":"2021-06-04T17:35:40.692535Z","shell.execute_reply.started":"2021-06-04T17:35:40.665937Z","shell.execute_reply":"2021-06-04T17:35:40.691567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 9-Lowercase all column names.","metadata":{}},{"cell_type":"code","source":"df.columns = df.columns.str.lower()\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-04T17:35:40.693619Z","iopub.execute_input":"2021-06-04T17:35:40.693882Z","iopub.status.idle":"2021-06-04T17:35:40.729994Z","shell.execute_reply.started":"2021-06-04T17:35:40.693854Z","shell.execute_reply":"2021-06-04T17:35:40.728748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 10- Change all the No values to NoRain and all the Yes values to Rain in raintoday and raintomorrow columns.","metadata":{}},{"cell_type":"code","source":"df.raintoday.replace('No','NoRain',inplace = True)\ndf.raintoday.replace('Yes','Rain',inplace = True)\ndf.raintomorrow.replace('No','NoRain',inplace = True)\ndf.raintomorrow.replace('Yes','Rain',inplace = True)\ndf.sample(5)","metadata":{"execution":{"iopub.status.busy":"2021-06-04T17:35:40.731585Z","iopub.execute_input":"2021-06-04T17:35:40.731989Z","iopub.status.idle":"2021-06-04T17:35:40.788962Z","shell.execute_reply.started":"2021-06-04T17:35:40.731952Z","shell.execute_reply":"2021-06-04T17:35:40.788052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 11- Change the data type of \"date\" (object) column to datetime64 and reformat the date as DD/MM/YYYY.","metadata":{}},{"cell_type":"code","source":"df['date']= pd.to_datetime(df['date'])\ndf.date = df.date.dt.strftime('%d/%m/%Y')\ndf.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-06-04T17:35:40.790076Z","iopub.execute_input":"2021-06-04T17:35:40.790345Z","iopub.status.idle":"2021-06-04T17:35:41.536419Z","shell.execute_reply.started":"2021-06-04T17:35:40.790316Z","shell.execute_reply":"2021-06-04T17:35:41.535609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 12- Create a new column called \"difference\", calculate the difference between maxtemp and mintemp columns for each row, and store the value in this new column.","metadata":{}},{"cell_type":"code","source":"df['difference'] = df['maxtemp'] - df['mintemp']\ndf = df[['date', 'location', 'mintemp', 'maxtemp','difference','rainfall', 'evaporation',\n       'sunshine', 'windgustdir', 'windgustspeed', 'winddir9am', 'winddir3pm',\n       'windspeed9am', 'windspeed3pm', 'humidity9am', 'humidity3pm',\n       'pressure9am', 'pressure3pm', 'cloud9am', 'cloud3pm', 'temp9am',\n       'temp3pm', 'raintoday', 'raintomorrow']]\ndf","metadata":{"execution":{"iopub.status.busy":"2021-06-04T17:35:41.53735Z","iopub.execute_input":"2021-06-04T17:35:41.537721Z","iopub.status.idle":"2021-06-04T17:35:41.704899Z","shell.execute_reply.started":"2021-06-04T17:35:41.537692Z","shell.execute_reply":"2021-06-04T17:35:41.703922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 13- Remove the evaporation and sunshine columns from the dataset permanently.","metadata":{}},{"cell_type":"code","source":"df.drop('evaporation',axis = 1, inplace = True)\ndf.drop('sunshine',axis = 1, inplace = True)\ndf.sample(3)","metadata":{"execution":{"iopub.status.busy":"2021-06-04T17:35:41.706291Z","iopub.execute_input":"2021-06-04T17:35:41.706834Z","iopub.status.idle":"2021-06-04T17:35:41.773254Z","shell.execute_reply.started":"2021-06-04T17:35:41.706773Z","shell.execute_reply":"2021-06-04T17:35:41.772276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 14- Find out the most rainy day for each city.","metadata":{}},{"cell_type":"code","source":"df[df.groupby('location')['rainfall'].transform(max) == df['rainfall']]","metadata":{"execution":{"iopub.status.busy":"2021-06-04T17:35:41.774557Z","iopub.execute_input":"2021-06-04T17:35:41.775115Z","iopub.status.idle":"2021-06-04T17:35:41.866979Z","shell.execute_reply.started":"2021-06-04T17:35:41.775072Z","shell.execute_reply":"2021-06-04T17:35:41.865778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 15- Filter out all the data for the city 'Albury' and then sort according to maxtemp column.","metadata":{}},{"cell_type":"code","source":"df_Albury = df[df.location == 'Albury']\ndf_Albury","metadata":{"execution":{"iopub.status.busy":"2021-06-04T17:35:41.868505Z","iopub.execute_input":"2021-06-04T17:35:41.868898Z","iopub.status.idle":"2021-06-04T17:35:41.919785Z","shell.execute_reply.started":"2021-06-04T17:35:41.868856Z","shell.execute_reply":"2021-06-04T17:35:41.919041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_Albury.sort_values(by = 'maxtemp')","metadata":{"execution":{"iopub.status.busy":"2021-06-04T17:35:41.920646Z","iopub.execute_input":"2021-06-04T17:35:41.921003Z","iopub.status.idle":"2021-06-04T17:35:41.961269Z","shell.execute_reply.started":"2021-06-04T17:35:41.92097Z","shell.execute_reply":"2021-06-04T17:35:41.960412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 16- Find out the NaN counts for each column","metadata":{"execution":{"iopub.status.busy":"2021-06-04T15:06:01.94253Z","iopub.execute_input":"2021-06-04T15:06:01.94292Z","iopub.status.idle":"2021-06-04T15:06:01.947142Z","shell.execute_reply.started":"2021-06-04T15:06:01.94289Z","shell.execute_reply":"2021-06-04T15:06:01.946045Z"}}},{"cell_type":"code","source":"dfNaN=  pd.DataFrame(df.isnull().sum(), columns = ['isnull'])\ndfNaN.reset_index(level=0, inplace=True)\ndfNaN","metadata":{"execution":{"iopub.status.busy":"2021-06-04T17:35:41.962428Z","iopub.execute_input":"2021-06-04T17:35:41.962673Z","iopub.status.idle":"2021-06-04T17:35:42.016078Z","shell.execute_reply.started":"2021-06-04T17:35:41.962648Z","shell.execute_reply":"2021-06-04T17:35:42.014851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 17- Remove the rows with NaN values in \"windgustdir\" column from the dataframe permanently.","metadata":{}},{"cell_type":"code","source":"df.dropna(subset=['windgustdir'],inplace=True)\ndf.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-04T17:35:42.017357Z","iopub.execute_input":"2021-06-04T17:35:42.017629Z","iopub.status.idle":"2021-06-04T17:35:42.089048Z","shell.execute_reply.started":"2021-06-04T17:35:42.0176Z","shell.execute_reply":"2021-06-04T17:35:42.088242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 18- Create a new dataframe, use \"Location\" column as the index of the dataframe, display the min, max, and median values of \"evaporation\" and \"sunshine\" columns in this dataframe.","metadata":{}},{"cell_type":"code","source":"d","metadata":{"execution":{"iopub.status.busy":"2021-06-04T17:35:42.090025Z","iopub.execute_input":"2021-06-04T17:35:42.090771Z","iopub.status.idle":"2021-06-04T17:35:42.177993Z","shell.execute_reply.started":"2021-06-04T17:35:42.090731Z","shell.execute_reply":"2021-06-04T17:35:42.177041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = d.copy()\ndf.groupby('Location')[\"Evaporation\",\"Sunshine\"].aggregate(['min', np.median, 'max'])","metadata":{"execution":{"iopub.status.busy":"2021-06-04T17:35:42.179442Z","iopub.execute_input":"2021-06-04T17:35:42.179837Z","iopub.status.idle":"2021-06-04T17:35:42.245986Z","shell.execute_reply.started":"2021-06-04T17:35:42.179793Z","shell.execute_reply":"2021-06-04T17:35:42.244987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 19- Find out the hottest day of \"Perth\". Example output: Timestamp('2015-01-05 00:00:00')","metadata":{}},{"cell_type":"code","source":"df[df[\"Location\"]==\"Perth\"].sort_values(by=\"MaxTemp\", ascending=False).iloc[0,0]","metadata":{"execution":{"iopub.status.busy":"2021-06-04T17:35:42.247099Z","iopub.execute_input":"2021-06-04T17:35:42.24737Z","iopub.status.idle":"2021-06-04T17:35:42.265202Z","shell.execute_reply.started":"2021-06-04T17:35:42.247342Z","shell.execute_reply":"2021-06-04T17:35:42.263928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 20- Group your dataframe by location and find out the averages of all numeric values.","metadata":{}},{"cell_type":"code","source":"df.groupby(by=[\"Location\"]).mean()","metadata":{"execution":{"iopub.status.busy":"2021-06-04T17:35:42.26958Z","iopub.execute_input":"2021-06-04T17:35:42.26988Z","iopub.status.idle":"2021-06-04T17:35:42.340128Z","shell.execute_reply.started":"2021-06-04T17:35:42.26985Z","shell.execute_reply":"2021-06-04T17:35:42.339097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list(df.columns)","metadata":{"execution":{"iopub.status.busy":"2021-06-04T17:35:42.341907Z","iopub.execute_input":"2021-06-04T17:35:42.3423Z","iopub.status.idle":"2021-06-04T17:35:42.347474Z","shell.execute_reply.started":"2021-06-04T17:35:42.342268Z","shell.execute_reply":"2021-06-04T17:35:42.346495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 21-Find categorical variables","metadata":{}},{"cell_type":"code","source":"categorical = [var for var in df.columns if df[var].dtype =='O']\ncategorical","metadata":{"execution":{"iopub.status.busy":"2021-06-04T17:35:42.348417Z","iopub.execute_input":"2021-06-04T17:35:42.348656Z","iopub.status.idle":"2021-06-04T17:35:42.363758Z","shell.execute_reply.started":"2021-06-04T17:35:42.348632Z","shell.execute_reply":"2021-06-04T17:35:42.362826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 22- Find continuous variables","metadata":{}},{"cell_type":"code","source":"categorical = [var for var in df.columns if df[var].dtype !='O']\ncategorical","metadata":{"execution":{"iopub.status.busy":"2021-06-04T17:35:42.365014Z","iopub.execute_input":"2021-06-04T17:35:42.365449Z","iopub.status.idle":"2021-06-04T17:35:42.380618Z","shell.execute_reply.started":"2021-06-04T17:35:42.365413Z","shell.execute_reply":"2021-06-04T17:35:42.379506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cat = df.select_dtypes(include='object')\ndf_cat","metadata":{"execution":{"iopub.status.busy":"2021-06-04T17:35:42.382039Z","iopub.execute_input":"2021-06-04T17:35:42.382585Z","iopub.status.idle":"2021-06-04T17:35:42.411758Z","shell.execute_reply.started":"2021-06-04T17:35:42.382552Z","shell.execute_reply":"2021-06-04T17:35:42.410861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cat.describe().T","metadata":{"execution":{"iopub.status.busy":"2021-06-04T17:35:42.412862Z","iopub.execute_input":"2021-06-04T17:35:42.41314Z","iopub.status.idle":"2021-06-04T17:35:42.562535Z","shell.execute_reply.started":"2021-06-04T17:35:42.413112Z","shell.execute_reply":"2021-06-04T17:35:42.561467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_num = df.select_dtypes(include='float64')\ndf_num","metadata":{"execution":{"iopub.status.busy":"2021-06-04T17:35:42.563639Z","iopub.execute_input":"2021-06-04T17:35:42.563911Z","iopub.status.idle":"2021-06-04T17:35:42.598238Z","shell.execute_reply.started":"2021-06-04T17:35:42.563884Z","shell.execute_reply":"2021-06-04T17:35:42.597074Z"},"trusted":true},"execution_count":null,"outputs":[]}]}