{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train=pd.read_csv('/kaggle/input/covid-19-nlp-text-classification/Corona_NLP_train.csv',encoding=\"latin1\")\ndata_test=pd.read_csv('/kaggle/input/covid-19-nlp-text-classification/Corona_NLP_test.csv',encoding='latin1')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Basic EDA ü§î**","metadata":{}},{"cell_type":"code","source":"print(data_train['Sentiment'].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# *Merging the extreme cases with their parent class*","metadata":{}},{"cell_type":"code","source":"for i in range(0,len(data_train)):\n    if(data_train['Sentiment'][i]=='Extremely Negative'):\n        data_train['Sentiment'][i]='Negative'\n    elif(data_train['Sentiment'][i]=='Extremely Positive'):\n        data_train['Sentiment'][i]='Positive'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data_train['Sentiment'].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train['Sentiment'].isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  *Let's convert the Sentiment Labels into numericals for easier processing*","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"le=LabelEncoder()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train['Sentiment']=le.fit_transform(data_train['Sentiment'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Converting into one hot encoding form is important when doing MultiClass Classification in Tensorflow\ny=pd.get_dummies(data_train['Sentiment'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(le.inverse_transform([0,1,2]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n=0\nne=0\np=0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(0,len(data_train)):\n    if(data_train['Sentiment'][i]==0):\n        n=n+1\n    elif(data_train['Sentiment'][i]==1):\n        ne=ne+1\n    elif(data_train['Sentiment'][i]==2):\n        p=p+1\n   ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# *Printing the total data for each individual classes*","metadata":{}},{"cell_type":"code","source":"print('Total Labels belonging to Negative Category are ',n)\nprint('Total Labels belonging to Neutral Category are ',ne)\nprint('Total Labels belonging to Positive Category are ',p)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Total entries in the train dataset is ',len(data_train))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Segregating the tweet class from their original dataset\nX=data_train.iloc[:,4]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_text,validation_text,train_labels,validation_labels=train_test_split(X.to_numpy(),y.to_numpy(),test_size=0.2,random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##printing validation labels to check if they are in one hot encoded form or not\nvalidation_labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(train_text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nimport string","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# *Cleaning the textual data- Removing all Hashtags, Mentions, Punctuations and Links*","metadata":{}},{"cell_type":"code","source":"for i in range(0,len(train_text)):\n    temp=train_text[i]\n    temp=re.sub(\"@\\S+\", \" \", temp)\n    temp=re.sub(\"https*\\S+\", \" \", temp)\n    temp=re.sub(\"#\\S+\", \" \", temp)\n    temp=re.sub(\"\\'\\w+\", '', temp)\n    temp=re.sub('[%s]' % re.escape(string.punctuation), ' ', temp)\n    temp=re.sub(r'\\w*\\d+\\w*', '', temp)\n    temp=re.sub('\\s{2,}', \" \", temp)\n    train_text[i]=temp\n    ##print(temp)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(0,len(validation_text)):\n    temp=validation_text[i]\n    temp=re.sub(\"@\\S+\", \" \", temp)\n    temp=re.sub(\"https*\\S+\", \" \", temp)\n    temp=re.sub(\"#\\S+\", \" \", temp)\n    temp=re.sub(\"\\'\\w+\", '', temp)\n    temp=re.sub('[%s]' % re.escape(string.punctuation), ' ', temp)\n    temp=re.sub(r'\\w*\\d+\\w*', '', temp)\n    temp=re.sub('\\s{2,}', \" \", temp)\n    validation_text[i]=temp\n    ##print(temp)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# *Print some random strings to check if the data has been preprocessed and cleaned well*","metadata":{}},{"cell_type":"code","source":"import random","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(0,10):\n    print('New Tweet')\n    print('***********')\n    random_number=random.randint(0,len(train_text)-1)\n    print(train_text[random_number])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(0,10):\n    print('New Tweet')\n    print('***********')\n    random_number=random.randint(0,len(validation_text)-1)\n    print(validation_text[random_number])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(train_text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using Tensorflow 2.x to create models üòç","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sum_length_of_tweet=0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##finding the average length of each tweet\nfor i in X:\n    temp=i\n    sum_length_of_tweet=sum_length_of_tweet+len(temp.split())\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_length=round(sum_length_of_tweet/len(X))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(max_length)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Tokenizer?","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# *Tokenization and Padding the textual data*","metadata":{}},{"cell_type":"code","source":"tokenizer=Tokenizer(num_words=10000,oov_token='</OOV>')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(tokenizer.word_index)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.sequence import pad_sequences","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.fit_on_texts(train_text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_text_sequences=tokenizer.texts_to_sequences(train_text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_text_padded=pad_sequences(train_text_sequences,maxlen=max_length,padding='post')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_text_sequences=tokenizer.texts_to_sequences(validation_text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_text_padded=pad_sequences(validation_text_sequences,maxlen=max_length,padding='post')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# *Let's print some examples to check if it functions the way we expect it to work or not*","metadata":{}},{"cell_type":"code","source":"for i in range(0,10):\n    index=random.randint(0,len(train_text)-1)\n    print('Original Sentence')\n    print('*******')\n    print(train_text[index])\n    print('Padded Sentence')\n    print('*********')\n    print(train_text_padded[index])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(0,10):\n    index=random.randint(0,len(validation_text)-1)\n    print('Original Sentence')\n    print('*******')\n    print(validation_text[index])\n    print('Padded Sentence')\n    print('*********')\n    print(validation_text_padded[index])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_text_padded.shape[1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# a) Making Baseline Model","metadata":{}},{"cell_type":"code","source":"model_1=tf.keras.models.Sequential([\n    tf.keras.layers.Embedding(10000,128,input_length=train_text_padded.shape[1]),\n    tf.keras.layers.GlobalAveragePooling1D(),\n    tf.keras.layers.Dense(8,activation='relu'),\n    tf.keras.layers.Dense(3,activation='softmax')\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_1.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_1.compile(loss=tf.keras.losses.CategoricalCrossentropy(),optimizer=tf.keras.optimizers.Adam(),metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_1=model_1.fit(train_text_padded,train_labels,epochs=4,validation_data=(validation_text_padded,validation_labels))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span style=color:red>*Baseline Model looks good. It gives us an accuracy of 81% on the validation dataset*</span>","metadata":{}},{"cell_type":"markdown","source":"# b) Improving the baseline Model","metadata":{}},{"cell_type":"code","source":"model_1.evaluate(validation_text_padded,validation_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_2=tf.keras.models.Sequential([\n    tf.keras.layers.Embedding(10000,128,input_length=train_text_padded.shape[1]),\n    tf.keras.layers.GlobalAveragePooling1D(),\n    tf.keras.layers.Dense(16,activation='relu'),\n    tf.keras.layers.Dense(8,activation='relu'),\n    tf.keras.layers.Dense(3,activation='softmax')\n])\nmodel_2.compile(loss=tf.keras.losses.CategoricalCrossentropy(),optimizer=tf.keras.optimizers.Adam(),metrics=['accuracy'])\nhistory_2=model_2.fit(train_text_padded,train_labels,epochs=4,validation_data=(validation_text_padded,validation_labels))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# c) LSTM based Model","metadata":{}},{"cell_type":"code","source":"model_3=tf.keras.models.Sequential([\n    tf.keras.layers.Embedding(10000,128,input_length=max_length),\n    tf.keras.layers.LSTM(8),\n    tf.keras.layers.Dense(8,activation='relu'),\n    tf.keras.layers.Dense(3,activation='softmax')\n])\nmodel_3.compile(loss=tf.keras.losses.CategoricalCrossentropy(),optimizer=tf.keras.optimizers.Adam(),metrics=['accuracy'])\nhistory_3=model_3.fit(train_text_padded,train_labels,epochs=3,validation_data=(validation_text_padded,validation_labels))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span style=color:red>*Accuracy improves to ~85% on the validation dataset while using LSTM Based Architecture*</span>","metadata":{}},{"cell_type":"markdown","source":"# d) Improving the LSTM based model even further","metadata":{}},{"cell_type":"code","source":"model_4=tf.keras.models.Sequential([\n    tf.keras.layers.Embedding(10000,128,input_length=train_text_padded.shape[1]),\n    tf.keras.layers.LSTM(512),\n    tf.keras.layers.Dense(256,activation='relu'),\n    tf.keras.layers.Dense(128,activation='relu'),\n    tf.keras.layers.Dense(32,activation='relu'),\n    tf.keras.layers.Dense(3,activation='softmax')\n])\nmodel_4.compile(loss=tf.keras.losses.CategoricalCrossentropy(),optimizer=tf.keras.optimizers.Adam(),metrics=['accuracy'])\nhistory_4=model_4.fit(train_text_padded,train_labels,epochs=4,validation_data=(validation_text_padded,validation_labels))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span style=color:red>*Again close to 85% on the validation dataset. Looks good*</span>","metadata":{}},{"cell_type":"code","source":"len(train_text_padded[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_4.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# e) Trying Universal Sentence Encoder from TensorHub.","metadata":{}},{"cell_type":"code","source":"import tensorflow_hub as hub\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_embed=embed(train_text)\ntest_embed=embed(validation_text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_embed[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_6=tf.keras.models.Sequential([\n    tf.keras.layers.Dense(3,activation='softmax')\n])\nmodel_6.compile(loss=tf.keras.losses.CategoricalCrossentropy(),optimizer=tf.keras.optimizers.Adam(),metrics=['accuracy'])\nmodel_6.fit(train_embed,train_labels,epochs=30,validation_data=(test_embed,validation_labels))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# f) Final attempt: Bidirectional LSTM based Architecture","metadata":{}},{"cell_type":"code","source":"model_new=tf.keras.models.Sequential([\n    tf.keras.layers.Embedding(10000,128,input_length=max_length),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,return_sequences=True)),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n    tf.keras.layers.Dense(16,activation='relu'),\n    tf.keras.layers.Dense(3,activation='softmax')\n])\nmodel_new.compile(loss=tf.keras.losses.CategoricalCrossentropy(),optimizer=tf.keras.optimizers.Adam(),metrics=['accuracy'])\nmodel_new.fit(train_embed,train_labels,epochs=5,validation_data=(test_embed,validation_labels))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# *We got our best result from Model 4 ie Improved LSTM architecture. We will be using the same model on our test dataset*","metadata":{}},{"cell_type":"code","source":"data_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_test.iloc[:,4]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(0,len(data_test)):\n    if(data_test['Sentiment'][i]=='Extremely Negative'):\n        data_test['Sentiment'][i]='Negative'\n    elif(data_test['Sentiment'][i]=='Extremely Positive'):\n        data_test['Sentiment'][i]='Positive'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test=data_test.iloc[:,4]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##preprocessing the test dataset\nfor i in range(0,len(X_test)):\n    temp=X_test[i]\n    temp=re.sub(\"@\\S+\", \" \", temp)\n    temp=re.sub(\"https*\\S+\", \" \", temp)\n    temp=re.sub(\"#\\S+\", \" \", temp)\n    temp=re.sub(\"\\'\\w+\", '', temp)\n    temp=re.sub('[%s]' % re.escape(string.punctuation), ' ', temp)\n    temp=re.sub(r'\\w*\\d+\\w*', '', temp)\n    temp=re.sub('\\s{2,}', \" \", temp)\n    X_test[i]=temp\n    ##print(temp)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_result=[]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(0,len(X_test)):\n    text=[X_test[i]]\n    text=tokenizer.texts_to_sequences(text)\n    text=pad_sequences(text,maxlen=max_length,padding='post')\n    result=model_4.predict_classes(text)\n    if(result==0):\n        final_result.append('Negative')\n    elif(result==1):\n        final_result.append('Neutral')\n    elif(result==2):\n        final_result.append('Positive')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"actual_result=data_test.iloc[:,5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(actual_result)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plotting the confusion matrix to check for accuracy.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(actual_result,final_result)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# *We have got more than 83% accuracy on the test dataset which is fabulous. Kudos for sticking around ü§ù*","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}