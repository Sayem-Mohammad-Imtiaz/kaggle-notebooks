{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/housing-prices-in-metropolitan-areas-of-india/Mumbai.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns',None)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_data=df.select_dtypes(exclude='object').drop(['Price'],axis=1).copy()\nnumeric_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_data=df.select_dtypes(include='object')\ncategorical_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Count plot (categorical, univariate analysis)\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n\ndf1=df.copy()\ndf1['Area'] = pd.cut(df1['Area'], bins=[0, 250, 500, 750, 1000, 1250, 1500, 1750, 2000, 2250, 2500, 2750, 3000, np.inf])\nfig=plt.figure(figsize=(20,30))\nfor i,col in enumerate(numeric_data):\n    fig.add_subplot(10,4,i+1)\n    sns.countplot(df1[col])\n    plt.xlabel(col,size=15)\n    plt.xticks(rotation=90)\nplt.tight_layout(pad=1)\nplt.show()\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots(figsize=(23,20))\nax.set_title('Houses at each Location',fontsize=20)\nsns.countplot(y='Location',data=df, order=df.Location.value_counts().index[:50])\nax.set_xlabel('Locations',fontsize=20)\nax.set_ylabel('No. of Houses',fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Count plot (categorical, univariate analysis)\nfig=plt.figure(figsize=(18,20))\nsns.countplot(df1['Area'])\nplt.xlabel('Area',fontsize=15)\nplt.ylabel('No. of Houses',fontsize=15)\nplt.xticks(rotation=40)\nplt.tight_layout(pad=1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2=df.copy().replace(9,np.nan)\ndf2=df2.fillna(method='bfill',axis=0).fillna(0)\ndf2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Correlation\nnum=df2.select_dtypes(exclude='object')\nnumeric_correlation=num.corr()\nplt.figure(figsize=(10,10))\nplt.title('Correlation')\nsns.heatmap(numeric_correlation>0.8, annot=True, square=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(numeric_correlation['Price'].sort_values(ascending=False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dropping features due to high correlation\ndf2.drop(['Hospital','AC','Refrigerator','LiftAvailable'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Missing Values\npd.DataFrame(df2.isnull().sum(), columns=['sum']).sort_values(by=['sum'],ascending=False).head(51)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.title(\"Distrubution of SalePrice\")\ndist = sns.distplot(df2['Price'],norm_hist=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.title(\"Distrubution of SalePrice\")\ndist = sns.distplot(np.log(df2['Price']),norm_hist=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom xgboost import XGBRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom lightgbm import LGBMRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom catboost import CatBoostRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx = df2.drop(['Price'], axis=1) \ny = np.log1p(df2['Price'])\nX_train, X_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=1)\n\ncategorical_cols = [cname for cname in x.columns if\n                    x[cname].dtype == \"object\"] \n                \n\n\nnumerical_cols = [cname for cname in x.columns if\n                 x[cname].dtype in ['int64','float64','uint8']]\n\n\nmy_cols = numerical_cols + categorical_cols\nX_train = X_train[my_cols].copy()\nX_val = X_val[my_cols].copy()\nprint(categorical_cols,numerical_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\n\nnum_transformer = Pipeline(steps=[\n    ('num_imputer', SimpleImputer(strategy='constant'))\n    ])\n\ncat_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n    ])\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num',num_transformer,numerical_cols),       \n        ('cat',cat_transformer,categorical_cols),\n        ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reversing log-transform on y\ndef inv_y(transformed_y):\n    return np.exp(transformed_y)\n\nn_folds = 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# XGBoost\nmodel = XGBRegressor(learning_rate=0.01, n_estimators=3460, max_depth=3, min_child_weight=0,gamma=0, subsample=0.7,colsample_bytree=0.7,objective='reg:squarederror', nthread=-1,scale_pos_weight=1, seed=27, reg_alpha=0.00006)\nclf = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('model', model)])\nclf.fit(X_train, y_train)\npredict = clf.predict(X_val)\nprint('XGBoost: ' + str(mean_absolute_error(inv_y(predict), inv_y(y_val))))\n\n\n# Lasso  \nfrom sklearn.linear_model import LassoCV\n\nmodel = LassoCV(max_iter=1e7,  random_state=14, cv=n_folds)\nclf = Pipeline(steps=[('preprocessor', preprocessor),\n                          ('model', model)])\nclf.fit(X_train, y_train)\npredict = clf.predict(X_val)\nprint('Lasso: ' + str(mean_absolute_error(inv_y(predict), inv_y(y_val))))\n\n# GradientBoosting   \nmodel = GradientBoostingRegressor(n_estimators=300, learning_rate=0.05, max_depth=4, random_state=5)\nclf = Pipeline(steps=[('preprocessor', preprocessor),\n                          ('model', model)])\nclf.fit(X_train, y_train)\npredict = clf.predict(X_val)\nprint('Gradient: ' + str(mean_absolute_error(inv_y(predict), inv_y(y_val))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Only using columns with no missing (not available) values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df3=df[['Price','Area','No. of Bedrooms','Resale','Location']].copy()\ndf3.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx = df3.drop(['Price'], axis=1) \ny = np.log1p(df3['Price'])\nX_train, X_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=1)\n\ncategorical_cols = [cname for cname in x.columns if\n                    x[cname].dtype == \"object\"] \n                \n\n\nnumerical_cols = [cname for cname in x.columns if\n                 x[cname].dtype in ['int64','float64','uint8']]\n\n\nmy_cols = numerical_cols + categorical_cols\nX_train = X_train[my_cols].copy()\nX_val = X_val[my_cols].copy()\nprint(categorical_cols,numerical_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\n\nnum_transformer = Pipeline(steps=[\n    ('num_imputer', SimpleImputer(strategy='constant'))\n    ])\n\ncat_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n    ])\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num',num_transformer,numerical_cols),       \n        ('cat',cat_transformer,categorical_cols),\n        ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# XGBoost\nmodel = XGBRegressor(learning_rate=0.01, n_estimators=3460, max_depth=3, min_child_weight=0,gamma=0, subsample=0.7,colsample_bytree=0.7,objective='reg:squarederror', nthread=-1,scale_pos_weight=1, seed=27, reg_alpha=0.00006)\nclf = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('model', model)])\nclf.fit(X_train, y_train)\npredict = clf.predict(X_val)\nprint('XGBoost: ' + str(mean_absolute_error(inv_y(predict), inv_y(y_val))))\n\n\n# Lasso  \nfrom sklearn.linear_model import LassoCV\n\nmodel = LassoCV(max_iter=1e7,  random_state=14, cv=n_folds)\nclf = Pipeline(steps=[('preprocessor', preprocessor),\n                          ('model', model)])\nclf.fit(X_train, y_train)\npredict = clf.predict(X_val)\nprint('Lasso: ' + str(mean_absolute_error(inv_y(predict), inv_y(y_val))))\n\n# GradientBoosting   \nmodel = GradientBoostingRegressor(n_estimators=300, learning_rate=0.05, max_depth=4, random_state=5)\nclf = Pipeline(steps=[('preprocessor', preprocessor),\n                          ('model', model)])\nclf.fit(X_train, y_train)\npredict = clf.predict(X_val)\nprint('Gradient: ' + str(mean_absolute_error(inv_y(predict), inv_y(y_val))))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}