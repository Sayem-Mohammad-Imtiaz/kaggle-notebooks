{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Overview\n* What is Cerbo?\n* Using Cerbo for Diabetes Prediction\n    * Data Visualization \n    * Modelling\n\n"},{"metadata":{},"cell_type":"markdown","source":"## What is Cerbo?\n\nI will be using the high-level machine learning API known as  [Cerbo](https://github.com/StartOnAI/Cerbo)! It can also be found [here](https://pypi.org/project/cerbo/). \n\nIt is extremely easy to use and you can train state of the art(SOTA) ML Models in 4 lines of code(Continue looking at this notebook to see how)!\n\nCerbo wraps both Scikit-Learn, and Tensorflow(mainly with Keras) in an easy to use way and it provides a ton of useful functions such as,\n  *     Creating your own data(Multidimensional data for regression and clustering)\n  *     Loading in CSV Files(As seen in this dataset)\n  *     Reading from Image Directory's for CNN's!\n    \nIt also has many machine learning and deep learning algorithms such as:\n  *      CNNs\n  *      GANs\n  *      Boosting(XGB, Gradient Boosting, and Ada Boost)\n  *      KNN's\n  *      And More!\n\nCerbo is also an open-source project so if you are interested in contributing just write a pull request and we will look over it!"},{"metadata":{},"cell_type":"markdown","source":"# Code"},{"metadata":{},"cell_type":"markdown","source":"Today, I will be demonstrating how to use Cerbo on the Diabetes Prediction Dataset!"},{"metadata":{},"cell_type":"markdown","source":"## Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# To install Cerbo just do\n!pip install cerbo","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To import the data you can simply do\nimport cerbo.preprocessing as cp\nimport cerbo.ML as cml","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading Data and Getting Insights"},{"metadata":{},"cell_type":"markdown","source":"To load in the data you have to use a method in ```cerbo.preprocessing``` called ```load_custom_data```. The parameters you have to provide to ```load_custom_data```, are\n   * Location of CSV File\n   * The Column you have to predict\n   * Num_Features(For scatter_matrix)\n   * id(Put True if there is an ID column in the CSV file)"},{"metadata":{"trusted":true},"cell_type":"code","source":"loc = \"/kaggle/input/pima-indians-diabetes-database/diabetes.csv\"\n\ndata, col_names = cp.load_custom_data(loc, \"Outcome\", num_features=5, id=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"After running the ``load_custom_data`` method you can see that we first get a scatter_matrix showing the correlation of some set of features to another. You can change the value of ``num_features`` to display the scatter_matrix for more features!\n\n\nNext, it outputs a correlation map showing the correlations between each of the input features. \n\n\nNote: Data is a dictionary containing 2 NumPy Arrays(One For the Inputs, and one for the outputs)"},{"metadata":{},"cell_type":"markdown","source":"## Training Models\n\n\nNow we are at the step where we can train models. For now, I will just show you how to write a KNN, Boosting(XGB), Decision Tree, and Logistic Regression. And it will only take 1 line to train all of these models and get **Training** and **Testing** accuracy"},{"metadata":{},"cell_type":"markdown","source":"## KNN\n\nEach model returns the actual model, along with a list of predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nTask = \"C\" stands for classification do \"R\" for Regression\ndata = data (The dictionary containing the data)\nneighbors = 2 (# of neighbors for KNN)\n\"\"\"\n\nknn = cml.KNN(task=\"c\", data=data, neighbors=2) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To save the model do\n\n```save_model(\"model_name\")```"},{"metadata":{"trusted":true},"cell_type":"code","source":"cml.save_model(knn)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Boosting(XGB)"},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb = cml.Boosting(task=\"c\", data=data, algo=\"xgb\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cml.save_model(xgb)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = cml.LogisticReg(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cml.save_model(lr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forests"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = cml.RandomForest(task=\"c\", data=data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cml.save_model(rf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# What we learned?\n\nWe covered a lot about this new ML API called Cerbo. We showed how you can train models in quite literally 4 lines(2 import statements, 2 lines of code!). With all of this information you can use this library to make ML extremely streamlined and make it have a much lower barrier of entry!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}