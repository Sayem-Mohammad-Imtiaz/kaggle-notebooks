{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/insurance/insurance.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Explore the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The mean and median values of variables 'age', 'bmi' and 'children' shows they are normally distributed."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.plot(kind='box', subplots=True, layout=(5,5),\nsharex=False, sharey=False, figsize=(20,10))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are no null values in our data set."},{"metadata":{"trusted":true},"cell_type":"code","source":"# changing datatype for nominal/ordinal data\nfor column in ['sex', 'smoker', 'region']:\n    df[column] = df[column].astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# this function plots the frequency distribution of a categorical feature\ndef show_frequency_distribution(feature_name, feature_values):\n    freq = (feature_name.value_counts() ).sort_index()\n    df = pd.DataFrame((feature_name.value_counts()).sort_index())\n    bars = feature_values\n    fig = plt.figure(figsize=(5,3))\n    ax1 = fig.add_subplot(1, 2, 1)\n    y = np.arange(len(bars))\n    _ = plt.bar(freq.index, freq , color = 'salmon');\n    _ = plt.xticks(freq.index, bars, rotation = 45);\n    _ = plt.ylabel(\"Frequency count\");\n    _ = plt.xlabel(str(feature_name.name) + \" type\");\n    _ = plt.title(\"Frequency Distribution of \" + str(feature_name.name));\n    ax2 = fig.add_subplot(1, 2, 2)\n    font_size=14\n    bbox=[1, 0, 1, 1]\n    ax2.axis('off')\n    table = ax2.table(cellText = df.values, rowLabels = feature_values, bbox=bbox, colLabels=df.columns)\n    table.auto_set_font_size(False)\n    table.set_fontsize(font_size)\n    plt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in ['sex', 'smoker', 'region', 'children']:\n    show_frequency_distribution(df[column], list(df[column].value_counts().sort_index().index))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(df['age'], df['charges'], hue = df['sex'], alpha = 0.5)\nplt.title(\"Exploring relation between 'age' and 'charges'\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(df['bmi'], df['charges'], hue = df['sex'], alpha = 0.5)\nplt.title(\"Exploring relation between 'bmi' and 'charges'\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Modelling**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Label Encoding\nfrom sklearn.preprocessing import LabelEncoder\n\nlabelencoder = LabelEncoder()\n\nfor column in ['sex', 'smoker', 'region']:\n    df[column] = labelencoder.fit_transform(df[column])\n    \ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop('charges', axis = 1)\ny = df['charges']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0, 1))\nX_scaled = scaler.fit_transform(X)\nX = pd.DataFrame(X_scaled, columns = X.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Looking for the most significant features to predict medical charges"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Ridge\nmodel = Ridge()\nmodel.fit(X_train, y_train)\nimportance = model.coef_\nfeat_importances = pd.Series(model.coef_, index=X.columns)\nfeat_importances.plot(kind='barh')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#apply SelectKBest class to extract top 10 best features\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_regression\nbestfeatures = SelectKBest(score_func=f_regression, k=6)\nfit = bestfeatures.fit(X_train,y_train)\ndfscores = pd.DataFrame(fit.scores_)\ndfcolumns = pd.DataFrame(X.columns)\n#concat two dataframes for better visualization \nfeatureScores = pd.concat([dfcolumns,dfscores],axis=1)\nfeatureScores.columns = ['Specs','Score']  #naming the dataframe columns\nprint(featureScores.nlargest(6,'Score'))  #print 10 best features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Above two methods of feature ranking show that 'sex' and 'region' are not important to predict the medical charges. Therefore, we will exclude them before building the final model."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train.drop(['sex', 'region'], axis = 1)\nX_test = X_test.drop(['sex', 'region'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error, r2_score\nfrom sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nlr.fit(X_train, y_train)\ny_pred_lr = lr.predict(X_test)\n\nmae = mean_absolute_error(y_test, y_pred_lr) \nr2_value = r2_score(y_test, y_pred_lr)                     \n\nprint(\"*** Multiple Linear Regression ***\")\nprint(\"Mean Absolute Error:\", mae)\nprint(\"R^2 Value:\", r2_value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit the data to polynomial linear regression model and check the accuracy\nfrom sklearn.preprocessing import PolynomialFeatures\npolyFeat = PolynomialFeatures(degree=3, include_bias=True)\npolyTrainX = polyFeat.fit_transform(X_train)\npolyTestX = polyFeat.fit_transform(X_test)\npr = LinearRegression()\npr.fit(polyTrainX, y_train)\ny_pred_pr = pr.predict(polyTestX)\n\nmae = mean_absolute_error(y_test, y_pred_pr)   \nr2_value = r2_score(y_test, y_pred_pr)                     \n\nprint(\"*** Polynomial Linear Regression ***\")\nprint(\"Mean Absolute Error:\", mae)\nprint(\"R^2 Value:\", r2_value)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"While using Polynomial Regressor the R^2 score increases by around 10%. Therefore, we will finalize the Polynomial Regressor for this problem."},{"metadata":{},"cell_type":"markdown","source":"# Learning curve for both the models"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import validation_curve, learning_curve\n\ndef draw_learning_curve(model, x, y):\n    train_sizes,train_scores, test_scores = learning_curve(model, x, y, \n                                                       train_sizes=[50, 100, 300, 500, 700, 900], cv=10)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    \n    plt.plot(train_sizes, train_scores_mean, color='blue', label='Train score')\n    plt.plot(train_sizes, test_scores_mean, color='red', label='Cross-validation score')\n    \n    plt.legend(loc='best')\n    plt.xlabel('Training size')\n    plt.ylabel('score')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"draw_learning_curve(lr,X_train, y_train)\nplt.title(\"Learning curve for Multiple Linear Regressor\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"draw_learning_curve(pr,polyTrainX, y_train)\nplt.title(\"Learning curve for Polynomial Regressor\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predTest = pd.DataFrame({\"prediction\": y_pred_pr, \"observed\": y_test})\nplt.scatter(predTest['prediction'], predTest['observed'])\nplt.title(\"Polynomial Regressor: Prediction Vs Actual Data\")\nplt.xlabel(\"Predicted Medical Charges\") \nplt.ylabel(\"Observed Medical Charges\")\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}