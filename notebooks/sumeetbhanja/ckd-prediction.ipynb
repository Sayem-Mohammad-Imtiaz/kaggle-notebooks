{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn import datasets\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import LinearSVC\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ckd_data = pd.read_csv(\"/kaggle/input/ckdisease/kidney_disease.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ckd_data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 66, 162, 185\nprint(ckd_data.loc[[66]])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Changing all the tab spaces into NaN\nprint(ckd_data.loc[[185]].wc)\nckd_data.at[185, 'wc'] = 'NaN'\nckd_data.at[162, 'rc'] = 'NaN'\nckd_data.at[66, 'pcv'] = 'NaN'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nckd_train_data, ckd_test_data = train_test_split(ckd_data, test_size=0.2, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Separate out the labels\nckd_train_data_label = ckd_train_data[\"classification\"].copy()\nckd_test_data_label = ckd_test_data[\"classification\"].copy()\nckd_train_data_label.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# List of Features only dataset. Drop the labels\nckd_train_data = ckd_train_data.drop(\"classification\", axis=1)\nckd_test_data = ckd_test_data.drop(\"classification\", axis=1)\nckd_train_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def impute_nan_add_variable(DataFrame,ColName):\n    #1. add new column and replace if category is null then 1 else 0\n    DataFrame[ColName+\"_Imputed\"] =   np.where(DataFrame[ColName].isnull(),1,0)\n    \n    # 2. Take most occured category in that vairable (.mode())\n    Mode_Category = DataFrame[ColName].mode()[0]\n    \n    ## 2.1 Replace NAN values with most occured category in actual vairable\n    DataFrame[ColName].fillna(Mode_Category,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Call function to impute NAN values for categorical variables and add new importance feature\nfor Columns in ['rbc','pc', 'pcc', 'ba', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane']:\n    impute_nan_add_variable(ckd_train_data,Columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ckd_train_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy=\"median\")),\n    ('std_scalar', StandardScaler()),\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ckd_train_data_numeric = ckd_train_data.drop(['rbc','pc', 'pcc', 'ba', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OrdinalEncoder\n\nnum_attribs = list(ckd_train_data_numeric)\ncat_attribs = ['rbc','pc', 'pcc', 'ba', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane']\n\nfull_pipeline = ColumnTransformer([\n    (\"num\", num_pipeline, num_attribs),\n    (\"cat\", OrdinalEncoder(), cat_attribs),\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ckd_train_data_prepared = full_pipeline.fit_transform(ckd_train_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ckd_train_data_binary_labels = (ckd_train_data_label == 'ckd')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.svm import LinearSVC\nsvm_clf1 = LinearSVC(C=1, loss=\"hinge\", random_state=42)\nsvm_clf1.fit(ckd_train_data_prepared, ckd_train_data_binary_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.svm import SVC\nrbf_kernel_svm_clf = SVC(kernel=\"rbf\", gamma=5, C=0.001)\nrbf_kernel_svm_clf.fit(ckd_train_data_prepared, ckd_train_data_binary_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\nrnd_clf.fit(ckd_train_data_prepared, ckd_train_data_binary_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets evaluate the cross validation to compare the models performance on this\n# binary classification problem. \nfrom sklearn.model_selection import cross_val_predict\nckd_train_data_LSVC_predictions = cross_val_predict(svm_clf1, ckd_train_data_prepared, ckd_train_data_binary_labels, cv=3)\nckd_train_data_rbf_kernel_SVM_predictions = cross_val_predict(rbf_kernel_svm_clf, ckd_train_data_prepared, ckd_train_data_binary_labels, cv=3)\nckd_train_data_RF_predictions = cross_val_predict(rnd_clf, ckd_train_data_prepared, ckd_train_data_binary_labels, cv=3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Comparing the confusion matrix of the 3 algorithm options\nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(ckd_train_data_binary_labels, ckd_train_data_LSVC_predictions)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_matrix(ckd_train_data_binary_labels, ckd_train_data_rbf_kernel_SVM_predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_matrix(ckd_train_data_binary_labels, ckd_train_data_RF_predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# As we can see that random forest performed the best when comparing confusion matrix.\n# Lets now use it to predict on the test set.\n\n# First prepare the test data\n#Prepare the test data\nfor Columns in ['rbc','pc', 'pcc', 'ba', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane']:\n    impute_nan_add_variable(ckd_test_data,Columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Execute the pipeline on the test data.\nckd_test_data_prepared = full_pipeline.fit_transform(ckd_test_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make the predictions using random forest classifier\nckd_test_data_RF_predictions = rnd_clf.predict(ckd_test_data_prepared)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ckd_test_data_RF_predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets look at the confusion matrix of the test predictions\nckd_test_data_binary_labels = (ckd_test_data_label == 'ckd')\nconfusion_matrix(ckd_test_data_binary_labels, ckd_test_data_RF_predictions) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prediction using the linear SVC\nckd_test_data_Linear_SVC_predictions = svm_clf1.predict(ckd_test_data_prepared)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion matrix of Linear SVC predictions\nconfusion_matrix(ckd_test_data_binary_labels, ckd_test_data_Linear_SVC_predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score\nprecision_score(ckd_test_data_binary_labels, ckd_test_data_Linear_SVC_predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"recall_score(ckd_test_data_binary_labels, ckd_test_data_Linear_SVC_predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score\nf1_score(ckd_test_data_binary_labels, ckd_test_data_Linear_SVC_predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ckd_test_data_prediction_scores = cross_val_predict(svm_clf1, ckd_test_data_prepared, ckd_test_data_binary_labels, cv=3, method=\"decision_function\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_curve\nfpr, tpr, thresholds = roc_curve(ckd_test_data_binary_labels, ckd_test_data_prediction_scores)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_roc_curve(fpr, tpr, label=None):\n    plt.plot(fpr, tpr, linewidth=2, label=label)\n    plt.plot([0,1], [0,1], 'k--') # Dashboard diagnol\n    #plt.axis([0, 1, 0, 1])                                    \n    plt.xlabel('False Positive Rate (Fall-Out)', fontsize=16) \n    plt.ylabel('True Positive Rate (Recall)', fontsize=16)\n    plt.grid(True) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplot_roc_curve(fpr, tpr, \"SVC\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}