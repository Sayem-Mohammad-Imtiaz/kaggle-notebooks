{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Import"},{"metadata":{"trusted":true},"cell_type":"code","source":"!nvidia-smi\n\nimport os\nimport sys\nimport cv2\nimport time\nimport random\nimport logging\nimport collections\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as tf\nfrom scipy import interp\nimport albumentations as A\nfrom itertools import cycle\nfrom sklearn import metrics\nfrom IPython import display\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import classification_report\nfrom sklearn.utils.multiclass import unique_labels\nfrom sklearn.metrics import confusion_matrix as sk_cm\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"class_to_num = {\n    'Angry': 0,\n    'Disgust': 1,\n    'Fear': 2,\n    'Happy': 3,\n    'Sad': 4,\n    'Surprise': 5,\n    'Neutral': 6\n}\n\nnum_to_class = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n\nNUM_CLASSES = len(num_to_class)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from myutilitymethods import MyMethods\nfrom mycnn import MyCNN\nfrom mydeepcnn import MyDeepCNN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mm = MyMethods(NUM_CLASSES, num_to_class, class_to_num)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Methods"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_all_confusion_matrices(y_true, y_pred, y_true_val, y_pred_val, y_true_test, y_pred_test, \n                                classes, save_title, normalize=False, title=None, cmap='GnBu', dpi=150):\n    '''Plot train, validation, and test confusion matrices'''\n    if not title:\n        if normalize:\n            title = 'Normalized Confusion Matrices'\n        else:\n            title = 'Non-Normalized Confusion Matrices'\n    # Compute confusion matrix\n    cm_train = sk_cm(y_true, y_pred)\n    cm_val = sk_cm(y_true_val, y_pred_val)\n    cm_test = sk_cm(y_true_test, y_pred_test)\n    # Only use the labels that appear in the data\n    classes = classes[unique_labels(y_true, y_pred)]\n    if normalize: \n        cm_train = cm_train.astype('float') / cm_train.sum(axis=1)[:, np.newaxis]\n        cm_val   = cm_val.astype('float')   / cm_val.sum(axis=1)  [:, np.newaxis]\n        cm_test  = cm_test.astype('float')  / cm_test.sum(axis=1) [:, np.newaxis]\n    # Lists  \n    cms = [cm_train, cm_val, cm_test]\n    titles = ['Train', 'Validation', 'Test']\n    fig, axes = plt.subplots(nrows=1, ncols=3, dpi=dpi, figsize=(15, 8))\n    # Loop\n    for i, ax in enumerate(axes):\n        im = ax.imshow(cms[i], interpolation='nearest', cmap=cmap, vmin=0, vmax=1)\n        # Label\n        ax.set(xticks=np.arange(cms[i].shape[1]),\n               yticks=np.arange(cms[i].shape[0]),\n               xticklabels=classes, \n               yticklabels=classes,\n               title=titles[i]\n               )\n        # Rotate the tick labels and set their alignment.\n        plt.setp(ax.get_yticklabels(), rotation=90, ha=\"right\", rotation_mode=\"anchor\")\n    # Loop\n    for c, cm in enumerate(cms):\n        # Loop over data dimensions and create text annotations.\n        fmt = '.2f' if normalize else 'd'\n        thresh = cm.max() / 2.\n        # Loop\n        for i in range(cm.shape[0]):\n            for j in range(cm.shape[1]):\n                axes[c].text(j, i, format(cm[i, j], fmt), \n                             ha=\"center\", va=\"center\", \n                             color=\"white\" if cm[i, j] > thresh else \"black\")\n    # For only one ax\n    axes[0].set(ylabel='True label',)\n    axes[1].set(xlabel='Predicted label')\n    # Adjust\n    fig.subplots_adjust(right=0.8)\n    cbar_ax = fig.add_axes([0.83, 0.315, 0.025, 0.375]) # [left, bottom, width, height]\n    fig.colorbar(im, cax=cbar_ax)\n    \n    # Save\n    fig.savefig(f'{save_title}.pdf', bbox_inches='tight', format='pdf', dpi=200)\n    \n    # Plot\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_fpr_tpr_auc_dicts(y, probs_list):\n    '''Compute and return the ROC curve and ROC area for each class in dictionaries'''\n    # Dicts\n    fpr = dict()\n    tpr = dict()\n    thresholds = dict()\n    roc_auc = dict()\n    \n    # For test\n    for i in range(NUM_CLASSES):\n        fpr[i], tpr[i], thresholds[i] = metrics.roc_curve(y[:, i], probs_list[:, i])\n        roc_auc[i] = metrics.auc(fpr[i], tpr[i])\n        \n    # Compute micro-average ROC curve and ROC area\n    fpr[\"micro\"], tpr[\"micro\"], _ = metrics.roc_curve(y.ravel(), probs_list.ravel())\n    roc_auc[\"micro\"] = metrics.auc(fpr[\"micro\"], tpr[\"micro\"])\n    \n    # Compute macro-average ROC curve and ROC area\n    \n    # First aggregate all false positive rates\n    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(NUM_CLASSES)]))\n    \n    # Then interpolate all ROC curves at this points\n    mean_tpr = np.zeros_like(all_fpr)\n    for i in range(NUM_CLASSES):\n        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n    \n    # Finally average it and compute AUC\n    mean_tpr /= NUM_CLASSES\n    \n    fpr[\"macro\"] = all_fpr\n    tpr[\"macro\"] = mean_tpr\n    roc_auc[\"macro\"] = metrics.auc(fpr[\"macro\"], tpr[\"macro\"])\n    \n    return fpr, tpr, thresholds, roc_auc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_roc_auc_curves(fpr, tpr, roc_auc, xlim=(-0.0025, 0.03), ylim=(0.99, 1.001), seed=0, save_title=None):\n    '''Plot ROC AUC Curves'''\n    fig, axes = plt.subplots(nrows=1, ncols=2, dpi=150, figsize=(10,5))\n    \n    lw = 2\n    axes[0].set_xlabel('False Positive Rate')\n    axes[1].set_xlabel('False Positive Rate')\n    axes[0].set_ylabel('True Positive Rate')\n    \n    if NUM_CLASSES!=4:\n        class_colors = randomColorGenerator(NUM_CLASSES, seed)\n    \n    for i in range(NUM_CLASSES):\n        axes[0].plot(fpr[i], tpr[i], color=class_colors[i], label='{0} ({1:0.2f}%)' ''.format(num_to_class[i], roc_auc[i]*100))\n        axes[1].plot(fpr[i], tpr[i], color=class_colors[i], lw=lw, label='{0} ({1:0.2f}%)' ''.format(num_to_class[i], roc_auc[i]*100))\n    \n    axes[0].plot(fpr['micro'], tpr['micro'], label='Micro avg ({:0.2f}%)' ''.format(roc_auc['micro']*100), linestyle=':', color='deeppink')\n    axes[0].plot(fpr['macro'], tpr['macro'], label='Macro avg ({:0.2f}%)' ''.format(roc_auc['macro']*100), linestyle=':', color='navy')\n    axes[0].plot([0, 1], [0, 1], color='k', linestyle='--', lw=0.5)\n    axes[0].scatter(0,1, label='Ideal', s=2)\n    \n    axes[1].plot(fpr['micro'], tpr['micro'], lw=lw, label='Micro avg ({:0.2f}%)'.format(roc_auc['micro']*100), linestyle=':', color='deeppink')\n    axes[1].plot(fpr['macro'], tpr['macro'], lw=lw, label='Macro avg ({:0.2f}%)'.format(roc_auc['macro']*100), linestyle=':', color='navy')\n    axes[1].plot([0, 1], [0, 1], color='k', linestyle='--', lw=0.5)\n    axes[1].scatter(0,1, label='Ideal', s=50)\n    \n    axes[1].set_xlim(xlim)\n    axes[1].set_ylim(ylim)\n    \n    axes[0].grid(True, linestyle='dotted', alpha=1)\n    axes[1].grid(True, linestyle='dotted', alpha=1)\n    \n    axes[0].legend(loc=4)\n    axes[1].legend(loc=4)\n    \n    plt.legend(loc=\"lower right\")\n    plt.tight_layout()\n    fig.savefig(f'{save_title}.pdf', bbox_inches='tight', format='pdf', dpi=200)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def randomColorGenerator(number_of_colors=1, seed=0):\n    '''Generate list of random colors'''\n    np.random.seed(seed)\n    return [\"#\"+''.join([np.random.choice(list('0123456789ABCDEF')) for j in range(6)]) for i in range(number_of_colors)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_data = pd.read_csv('../input/fer2013/fer2013.csv', header=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = raw_data.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = data[:, 0]\npixels = data[:, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nx = np.zeros((pixels.shape[0], 48*48))\n\nfor x_i in range(x.shape[0]):\n    p = pixels[x_i].split(' ')\n    \n    for y_i in range(x.shape[1]):\n        x[x_i, y_i] = int(p[y_i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = x.reshape(x.shape[0], 48, 48)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print('x shape:', x.shape)\nprint('y shape:', y.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Process Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"indices_to_remove = []\n\nfor i,x_i in enumerate(x):\n    if x_i.std() == 0:\n        indices_to_remove.append(i)\n        \nx = np.delete(x, indices_to_remove, axis=0)\ny = np.delete(y, indices_to_remove, axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert to 3 channels\nimgs = []\nfor i in range(len(x)):\n    imgs.append(cv2.cvtColor(x[i].astype('uint8'), cv2.COLOR_GRAY2RGB))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.concatenate(imgs)\nx = x.reshape(x.shape[0]//48, x.shape[1], x.shape[1], x.shape[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Standardise data\nx = mm.standardise_images(x)\n\n# Reshape\nx = np.concatenate(x)\nx = x.reshape(x.shape[0]//x.shape[1], x.shape[1], x.shape[1], x.shape[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Resize data\nimgs = []\nfor i in range(len(x)):\n    imgs.append(mm.resize_image(x[i]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reshape\nx = np.concatenate(imgs)\nx = x.reshape(x.shape[0]//x.shape[1], x.shape[1], x.shape[1], x.shape[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Shuffle once so order of emotions is random\nx, y = shuffle(x, y, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split\nx_train, y_train, x_test, y_test = mm.split_train_test(x, y, split=0.95)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Explore Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"sets = ((x,y), (x_train, y_train), (x_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"for my_set in sets:\n    mm.plot_pca(my_set[0], my_set[1], dpi=75)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Entire dataset\ncounts = collections.Counter(y)\nnbs = []\nfor k in counts:\n    nbs.append(counts[k])\n    \nplt.figure(dpi=75)\nplt.bar(num_to_class, nbs)\nplt.tight_layout()\nplt.savefig('DataBarPlot.pdf', bbox_inches='tight', format='pdf', dpi=200)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train set\ncounts = collections.Counter(y_train)\ntrain_nbs = []\nfor k in counts:\n    train_nbs.append(counts[k])\n    \nplt.figure(dpi=75)\nplt.bar(num_to_class, train_nbs)\nplt.tight_layout()\nplt.savefig('TrainBarPlot.pdf', bbox_inches='tight', format='pdf', dpi=200)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test set\ncounts = collections.Counter(y_test)\ntest_nbs = []\nfor k in counts:\n    test_nbs.append(counts[k])\n    \nplt.figure(dpi=75)\nplt.bar(num_to_class, test_nbs)\nplt.tight_layout()\nplt.savefig('TestBarPlot.pdf', bbox_inches='tight', format='pdf', dpi=200)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(dpi=75)\nplt.bar(num_to_class, train_nbs, label='train')\nplt.bar(num_to_class, test_nbs, label='test', bottom=train_nbs)\nplt.legend()\nplt.tight_layout()\nplt.savefig('TrainTestBarPlot.pdf', bbox_inches='tight', format='pdf', dpi=200)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Assert"},{"metadata":{"trusted":true},"cell_type":"code","source":"# One-hot encode\nif y_train.ndim == 1:\n    y_train = mm.one_hot_encode(list(y_train))\n\nif y_test.ndim == 1:\n    y_test = mm.one_hot_encode(list(y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Assert shapes\nassert(y_train.shape[1]==NUM_CLASSES)\nassert(y_test.shape[1]==NUM_CLASSES)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Assert std devs\nassert(np.isclose(np.round(x_train[0].std(), 3), 1, atol=0.5))\nassert(np.isclose(np.round(x_test[0].std(), 3), 1, atol=0.5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Assert means\nassert(np.isclose(np.round(x_train[0].mean(), 3), 0, atol=0.5))\nassert(np.isclose(np.round(x_test[0].mean(), 3), 0, atol=0.5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Assert 4D\nassert(len(x_train.shape)==4)\nassert(len(x_test.shape)==4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check\nprint('x_train :', x_train.shape)\nprint('y_train :', y_train.shape)\nprint('')\nprint('x_test  :', x_test.shape)\nprint('y_test  :', y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n  model.sess\nexcept NameError:\n    pass\nelse:\n    model.sess.close()\ntf.reset_default_graph()\n\n# Setup model\nmodel = MyCNN(x_train, \n              y_train, \n              x_test,\n              y_test,\n              output_dir='./FER_logdir/',\n              num_to_class=num_to_class, \n              class_to_num=class_to_num,\n              lr=5e-5,\n              nb_epochs=50, \n              batch_size_train=30,\n              seed=0,\n              final_activation='softmax')\n\n# Initialise model\nmodel.create_model()\nmodel.compute_loss()\nmodel.optimizer()\nmodel.set_up_saver()\ntf.initialize_all_variables().run(session=model.sess)\n\n# Make path if necessary\nif not os.path.exists(model.output_dir):\n    os.makedirs(model.output_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.model_variables()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.model_summary()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Train model w/o k-fold cross validation\nmodel.train(verbose=False, cross_k_fold_validation=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test model w/o k-fold cross validation\nmodel.test()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot variables over training and validation w/o k-fold cross validation\nmm.plot_metrics(model.accuracy_list, \n                model.losses_list, \n                model.val_accuracy_list, \n                model.val_losses_list,\n                save_title='wo_kCV_metrics')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_all_confusion_matrices(np.argmax(model.y_train, axis=1), model.preds_list,\n                            np.argmax(model.y_val, axis=1), model.preds_list_val,\n                            np.argmax(model.y_test, axis=1), model.preds_list_test,\n                            np.array(num_to_class), 'CM_wo_kCV', normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get validation metrics report\nreport = classification_report(np.argmax(model.y_train, axis=1), \n                               model.preds_list, \n                               target_names=class_to_num, \n                               output_dict=True)\nmy_df = pd.DataFrame.from_dict(report).T.round(2)\nmy_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(my_df.to_latex())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get validation metrics report\nreport = classification_report(np.argmax(model.y_val, axis=1), \n                               model.preds_list_val, \n                               target_names=class_to_num, \n                               output_dict=True)\nmy_df = pd.DataFrame.from_dict(report).T.round(2)\nmy_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(my_df.to_latex())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get testing metrics report\nreport = classification_report(np.argmax(model.y_test, axis=1), \n                               model.preds_list_test, \n                               target_names=class_to_num, \n                               output_dict=True)\nmy_df = pd.DataFrame.from_dict(report).T.round(2)\nmy_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(my_df.to_latex())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train ROC/AUC w/o-cross val\nfpr, tpr, thresholds, roc_auc = make_fpr_tpr_auc_dicts(model.y_train, model.probs_list)\nplot_roc_auc_curves(fpr, tpr, roc_auc, xlim=(0, 0.2), ylim=(0.8, 1), seed=5, save_title='TrainROC_wo_kCV')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train ROC/AUC w/o-cross val\nfpr, tpr, thresholds, roc_auc = make_fpr_tpr_auc_dicts(model.y_test, model.probs_list_test)\nplot_roc_auc_curves(fpr, tpr, roc_auc, xlim=(0, 0.2), ylim=(0.8, 1), seed=5, save_title='TestROC_wo_kCV')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.sess.close()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# W/Cross k."},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n  sess\nexcept NameError:\n    pass\nelse:\n    sess.close()\ntf.reset_default_graph()\n\n# Setup model_2\nmodel_2 = MyCNN(x_train[:33150], \n                y_train[:33150], \n                x_test,\n                y_test,\n                output_dir='./FER_logdir/',\n                num_to_class=num_to_class, \n                class_to_num=class_to_num,\n                lr=5e-5,\n                nb_epochs=50, \n                batch_size_train=30,\n                seed=0,\n                final_activation='softmax')\n\n# Initialise model_2\nmodel_2.create_model()\nmodel_2.compute_loss()\nmodel_2.optimizer()\nmodel_2.set_up_saver()\ntf.initialize_all_variables().run(session=model_2.sess)\n\n# Make path if necessary\nif not os.path.exists(model_2.output_dir):\n    os.makedirs(model_2.output_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train model w/k-CV\nmodel_2.train(verbose=False, cross_k_fold_validation=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot variables over training and validation w/k-CV\nmm.plot_metrics(model_2.accuracy_list, \n                model_2.losses_list, \n                model_2.val_accuracy_list, \n                model_2.val_losses_list,\n                save_title='w_kCV_metrics')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test model w/k-CV\nmodel_2.test()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot CMs w/k-CV\nplot_all_confusion_matrices(np.argmax(model_2.y_train, axis=1), model_2.preds_list,\n                            np.argmax(model_2.y_val, axis=1),   model_2.preds_list_val,\n                            np.argmax(model_2.y_test, axis=1),  model_2.preds_list_test,\n                            np.array(num_to_class), 'CM_w_kCV', normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get validation metrics report\nreport = classification_report(np.argmax(model_2.y_train, axis=1), \n                               model_2.preds_list, \n                               target_names=class_to_num, \n                               output_dict=True)\nmy_df = pd.DataFrame.from_dict(report).T.round(2)\nmy_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(my_df.to_latex())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get validation metrics report\nreport = classification_report(np.argmax(model_2.y_val, axis=1), \n                               model_2.preds_list_val, \n                               target_names=class_to_num, \n                               output_dict=True)\nmy_df = pd.DataFrame.from_dict(report).T.round(2)\nmy_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(my_df.to_latex())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get testing metrics report\nreport = classification_report(np.argmax(model_2.y_test, axis=1), \n                               model_2.preds_list_test, \n                               target_names=class_to_num, \n                               output_dict=True)\nmy_df = pd.DataFrame.from_dict(report).T.round(2)\nmy_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(my_df.to_latex())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train ROC/AUC w/k-cross val\nfpr, tpr, thresholds, roc_auc = make_fpr_tpr_auc_dicts(model_2.y_train, model_2.probs_list)\nplot_roc_auc_curves(fpr, tpr, roc_auc, xlim=(0, 0.2), ylim=(0.8, 1), seed=5, save_title='TrainROC_w_kCV')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test ROC/AUC w/k-cross val\nfpr, tpr, thresholds, roc_auc = make_fpr_tpr_auc_dicts(model_2.y_test, model_2.probs_list_test)\nplot_roc_auc_curves(fpr, tpr, roc_auc, xlim=(0, 1), ylim=(0, 1), seed=5, save_title='TestROC_w_kCV')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_2.sess.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Model 3"},{"metadata":{"trusted":true},"cell_type":"code","source":"# (Re-)Split\nx_train, y_train, x_val, y_val, x_test, y_test = mm.split_train_val_test(x, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One-hot encode\nif y_train.ndim == 1:\n    y_train = mm.one_hot_encode(list(y_train))\n    \nif y_val.ndim == 1:\n    y_val = mm.one_hot_encode(list(y_val))\n\nif y_test.ndim == 1:\n    y_test = mm.one_hot_encode(list(y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Assert shapes\nassert(y_train.shape[1]==NUM_CLASSES)\nassert(y_val.shape[1]==NUM_CLASSES)\nassert(y_test.shape[1]==NUM_CLASSES)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n  sess\nexcept NameError:\n    pass\nelse:\n    sess.close()\ntf.reset_default_graph()\n\n# Setup model_3\nmodel_3 = MyDeepCNN(x_train,\n                    y_train,\n                    x_val,\n                    y_val,\n                    x_test,\n                    y_test,\n                    output_dir='./FER_logdir/',\n                    lr=1e-3,\n                    beta_1=0.9,\n                    beta_2=0.999,\n                    nb_epochs=50,\n                    epsilon=1e-7,\n                    batch_size=64,\n                    seed=0,\n                    num_features=64)\n\n# Initialise model_3\nmodel_3.create_model()\n\n# Make path if necessary\nif not os.path.exists(model_3.output_dir):\n    os.makedirs(model_3.output_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_3.model_variables()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_3.model_summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train\nmodel_3.train(verbose=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test\nmodel_3.test()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot variables over training and validation - 5e-6 - 100 epochs\nmm.plot_metrics(model_3.history.history['acc'], \n                model_3.history.history['loss'], \n                model_3.history.history['val_acc'], \n                model_3.history.history['val_loss'],\n                save_title='deepcnn_metrics')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"probs_list_train = model_3.model.predict(x_train, batch_size=64)\nprobs_list_val = model_3.model.predict(x_val, batch_size=64)\nprobs_list_test = model_3.model.predict(x_test, batch_size=64)\n\ny_hat_train = np.argmax(probs_list_train, axis=1)\ny_hat_val = np.argmax(probs_list_val, axis=1)\ny_hat_test = np.argmax(probs_list_test, axis=1)\n\ny_real_train = np.argmax(y_train, axis=1)\ny_real_val = np.argmax(y_val, axis=1)\ny_real_test = np.argmax(y_test, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get validation metrics report\nreport = classification_report(y_real_train, \n                               y_hat_train, \n                               target_names=class_to_num, \n                               output_dict=True)\nmy_df = pd.DataFrame.from_dict(report).T.round(2)\nmy_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(my_df.to_latex())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get validation metrics report\nreport = classification_report(y_real_val, \n                               y_hat_val, \n                               target_names=class_to_num, \n                               output_dict=True)\nmy_df = pd.DataFrame.from_dict(report).T.round(2)\nmy_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(my_df.to_latex())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get validation metrics report\nreport = classification_report(y_real_test, \n                               y_hat_test, \n                               target_names=class_to_num, \n                               output_dict=True)\nmy_df = pd.DataFrame.from_dict(report).T.round(2)\nmy_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(my_df.to_latex())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_all_confusion_matrices(y_real_train, y_hat_train,\n                            y_real_val, y_hat_val,\n                            y_real_test, y_hat_test,\n                            np.array(num_to_class), 'CM_deepcnn', normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train ROC/AUC\nfpr, tpr, thresholds, roc_auc = make_fpr_tpr_auc_dicts(y_train, probs_list_train)\nplot_roc_auc_curves(fpr, tpr, roc_auc, xlim=(0, 0.6), ylim=(0.6, 1), seed=5, save_title='TrainROC_deepcnn')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Val ROC/AUC\nfpr, tpr, thresholds, roc_auc = make_fpr_tpr_auc_dicts(y_val, probs_list_val)\nplot_roc_auc_curves(fpr, tpr, roc_auc, xlim=(0, 1), ylim=(0, 1), seed=5, save_title='ValROC_deepcnn')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test ROC/AUC\nfpr, tpr, thresholds, roc_auc = make_fpr_tpr_auc_dicts(y_test, probs_list_test)\nplot_roc_auc_curves(fpr, tpr, roc_auc, xlim=(0, 1), ylim=(0, 1), seed=5, save_title='TestROC_deepcnn')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_3.sess.close()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}