{"cells":[{"metadata":{},"cell_type":"markdown","source":"<font color = 'green'>\n<h1>Breast Cancer Wisconsin (Diagnostic)<h1>"},{"metadata":{},"cell_type":"markdown","source":"# Introduction\nFeatures are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image.\nn the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\n\nThis database is also available through the UW CS ftp server:\nftp ftp.cs.wisc.edu\ncd math-prog/cpo-dataset/machine-learn/WDBC/\n\nAlso can be found on UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\n<br>\n<br>\n<font color = 'blue'>\n<b>Content: </b>\n\n1. [Prepare Problems](#1)\n    * [Load Libraries](#2)\n    * [Load Dataset](#3)    \n1. [Descriptive Analysis](#4)\n1. [EDA](#5)\n1. [Missing Values](#6)\n1. [Data Visualization](#7)\n    * [Count Plot](#8)\n    * [Pie Chart](#9)\n    * [Distribution Plot](#10)\n   \n1. [Outlier Detection](#11)\n    * [Let's The Outliers via Bubble Chart](#12)\n1. [Drop Outliers](#13)\n1. [Create Train and Test Dataset](#14)\n1. [Standardization](#15)\n1. [KNN Model](#16)\n    * [KNN Tuning](#17)\n    * [Make Prediction After Tuning](#18)\n\n1. [Principal Component Analysis (PCA)](#19)\n    * [Visualize Of New Dataframe](#20)\n    * [Classification After PCA](#21)\n1. [Neighborhood Components Analysis (NCA)](#22)\n    * [Visualize Of New Dataframe](#23)\n    * [Classification After NCA](#24)\n1. [Compare Accuracies](#25)"},{"metadata":{},"cell_type":"markdown","source":"<font color = 'red'>\n<a id = \"1\"></a><br>\n<h2>Prepare Problems<h2>\n<font color = 'blue'>\n      Predict whether the cancer is benign or malignant"},{"metadata":{},"cell_type":"markdown","source":"<a id = \"2\"></a><br>\n## Load Libraries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Load Libraries:\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nimport plotly.offline as pyo \nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nfrom matplotlib.colors import ListedColormap\n#\nfrom sklearn.metrics import classification_report \nfrom sklearn.metrics import confusion_matrix \nfrom sklearn.metrics import accuracy_score \n#\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.model_selection import KFold \nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import metrics\n#\nfrom sklearn.neighbors import KNeighborsClassifier, NeighborhoodComponentsAnalysis, LocalOutlierFactor\nfrom sklearn.decomposition import PCA\n#\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n#\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"3\"></a><br>\n## Load Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/breast-cancer-wisconsin-data/data.csv\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop Unnecessary columns\ndata.drop([\"Unnamed: 32\",\"id\"],axis=1,inplace=True)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Attribute Information:\n\n- 1) ID number\n* 2) Diagnosis (M = malignant, B = benign)\n3-32)\n\nTen real-valued features are computed for each cell nucleus:\n\n*  radius (mean of distances from center to points on the perimeter)\n*  texture (standard deviation of gray-scale values)\n*  perimeter\n*  area\n*  smoothness (local variation in radius lengths)\n*  compactness (perimeter^2 / area - 1.0)\n*  concavity (severity of concave portions of the contour)\n*  concave points (number of concave portions of the contour)\n*  symmetry\n*  fractal dimension (\"coastline approximation\" - 1)\n\nThe mean, standard error and \"worst\" or largest (mean of the three\nlargest values) of these features were computed for each image,\nresulting in 30 features. For instance, field 3 is Mean Radius, field\n13 is Radius SE, field 23 is Worst Radius.\n\nAll feature values are recoded with four significant digits.\n\nMissing attribute values: none\n\nClass distribution: 357 benign, 212 malignant"},{"metadata":{},"cell_type":"markdown","source":"<a id = \"4\"></a><br>\n## Descriptive Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# data shape:\nrow, columns = data.shape\nprint(\"Data Row:\", row)\nprint(\"Data Columns:\", columns)\n# column names:\ndata.columns\n# descriptions \ndisplay(data.describe().T)\n# class distribution \nprint(\"Data is  balanced:\",data.groupby('diagnosis').size())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"5\"></a><br>\n## EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"# correlation:\ncorr_matrix = data.corr()\nsns.clustermap(corr_matrix,annot=True,fmt=\".2f\",figsize=(20,14))\nplt.title(\"Correlation Between Features\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"6\"></a><br>\n## Missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"7\"></a><br>\n## Data Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_m = data[data.diagnosis == \"M\"]\ndata_b = data[data.diagnosis == \"B\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"8\"></a><br>\n## Count Plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"trace = [go.Bar(x=data.diagnosis.unique(), y=(len(data_m),len(data_b)),\n               marker=dict(color=[\"blue\",\"brown\"]))]\n               \nlayout = go.Layout(title=\"Count of M = malignant, B = benign \")# üst üste gelecek şekilde..\nfig = go.Figure(data=trace,layout=layout)   \npyo.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"9\"></a><br>\n## Pie Chart"},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = [\"M\",\"B\"]\nvalues = [len(data_m),len(data_b)]\ntrace = [go.Pie(labels=labels, values=values,\n               marker=dict(colors=[\"blue\",\"brown\"]))]\nlayout = go.Layout(title=\"Percentage of M = malignant, B = benign \")\nfig = go.Figure(data=trace,layout=layout)\npyo.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"10\"></a><br>\n## Distribution Plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"def dist_plot(data_feature): \n    hist_data = [data_m[data_feature], data_b[data_feature]]\n    \n    group_labels = ['malignant', 'benign']\n    colors=[\"blue\",\"brown\"]\n    \n    fig = ff.create_distplot(hist_data, group_labels, colors = colors)\n    fig['layout'].update(title = data_feature)\n    return pyo.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### You can make more lots via dist_plot()"},{"metadata":{"trusted":true},"cell_type":"code","source":"dist_plot('radius_mean')\ndist_plot('texture_mean')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"11\"></a><br>\n## Outlier Detection"},{"metadata":{},"cell_type":"markdown","source":"### Outlier detection with Local Outlier Factor (LOF)"},{"metadata":{},"cell_type":"markdown","source":"The Local Outlier Factor (LOF) algorithm is an unsupervised anomaly detection method which computes the local density deviation of a given data point with respect to its neighbors. It considers as outliers the samples that have a substantially lower density than their neighbors. This example shows how to use LOF for outlier detection which is the default use case of this estimator in scikit-learn. Note that when LOF is used for outlier detection it has no predict, decision_function and score_samples methods. See User Guide: for details on the difference between outlier detection and novelty detection and how to use LOF for novelty detection.\n\nThe number of neighbors considered (parameter n_neighbors) is typically set 1) greater than the minimum number of samples a cluster has to contain, so that other samples can be local outliers relative to this cluster, and 2) smaller than the maximum number of close by samples that can potentially be local outliers. In practice, such informations are generally not available, and taking n_neighbors=20 appears to work well in general."},{"metadata":{},"cell_type":"markdown","source":"To get : https://scikit-learn.org/stable/auto_examples/neighbors/plot_lof_outlier_detection.html"},{"metadata":{},"cell_type":"markdown","source":"![](https://scikit-learn.org/stable/_images/sphx_glr_plot_lof_outlier_detection_001.png)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Change object to integer:\ndata[\"diagnosis\"] = [1 if item == \"M\" else 0  for item in data[\"diagnosis\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = data[\"diagnosis\"]\nx = data.drop([\"diagnosis\"],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = x.columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = LocalOutlierFactor()\ny_pred = clf.fit_predict(x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* property fit_predict :\n* is_inlierarray, shape (n_samples,)\n* Returns -1 for anomalies/outliers and 1 for inliers."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_score = clf.negative_outlier_factor_\noutlier_score = pd.DataFrame()\noutlier_score[\"score\"] = X_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outlier_score.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"12\"></a><br>\n## Let's The Outliers via Bubble Chart"},{"metadata":{"trusted":true},"cell_type":"code","source":"# So make threshold: we decide about max and min of \"outlier_score\"\nthreshold = -2\nfiltre = outlier_score[\"score\"] < threshold\noutlier_index = outlier_score[filtre].index.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Radius for our outliers\nradius = (X_score.max()-X_score)/(X_score.max()-X_score.min())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trace0 = go.Scatter(x=x.iloc[outlier_index,0], y=x.iloc[outlier_index,1],\n                   mode=\"markers\",\n                   marker=dict(size=10,color=\"brown\"),\n                   name=\"outliers\"\n                   )\n\ntrace1 = go.Scatter(x=x.iloc[:,0], y=x.iloc[:,1],\n                   mode=\"markers\",\n                   marker=dict(size=50*radius,color=\"gold\"),\n                   name=\"real points\"\n                   )\n \nlayout = go.Layout(title=\"Outliers (Depends on Threshold Value)\",hovermode=\"closest\")\nfig = go.Figure(data=[trace0,trace1],layout=layout)\npyo.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"13\"></a><br>\n## Drop Outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = x.drop(outlier_index)\ny = y.drop(outlier_index)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"14\"></a><br>\n## Create Train and Test Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"15\"></a><br>\n## Standardization"},{"metadata":{"trusted":true},"cell_type":"code","source":"sc = StandardScaler()\nX_train = sc.fit_transform(x_train)\nX_test  = sc.transform(x_test) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"16\"></a><br>\n## KNN Model"},{"metadata":{},"cell_type":"markdown","source":"* Sentisitive for outliers\n* It is problem on big data\n* Curse of Dimensionality\n* Feature Scaling\n* It is problem on imbalance data\n* Depends on K, model will check K nearst neighbour"},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier()\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_cm = confusion_matrix(y_test,y_pred)\nknn_acc = metrics.accuracy_score(y_test, y_pred)\nprint(knn_cm)\nprint(knn_acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"17\"></a><br>\n## KNN Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tuning Decision Tree Model\nn_neighbors = [5,7,9,11,13,15,17,19,21]\nweights = [\"uniform\",\"distance\"]\nmetric = [\"euclidean\",\"manhattan\",\"minkowski\"]\nparam_grid = dict(n_neighbors=n_neighbors,weights=weights,metric=metric)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier()\ngs = GridSearchCV(estimator=knn,param_grid=param_grid,scoring=\"accuracy\", cv=10)\ngrid_search = gs.fit(x_train,y_train)\nbest_score = grid_search.best_score_\nbest_parameters = grid_search.best_params_\nprint(\"Best Score:\",best_score)\nprint(\"Best Parameters:\",best_parameters)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"18\"></a><br>\n## Make Prediction After Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(metric='manhattan',n_neighbors=9,weights='distance')\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_cm = confusion_matrix(y_test,y_pred)\nknn_acc = metrics.accuracy_score(y_test, y_pred)\nprint(knn_cm)\nprint(knn_acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"19\"></a><br>\n## Principal Component Analysis (PCA)"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/breast-cancer-wisconsin-data/data.csv\")\n# Drop Unnecessary columns\ndata.drop([\"Unnamed: 32\",\"id\"],axis=1,inplace=True)\n# Change object to integer:\ndata[\"diagnosis\"] = [1 if item == \"M\" else 0  for item in data[\"diagnosis\"]]\ny = data[\"diagnosis\"]\nx = data.drop([\"diagnosis\"],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PCA needs scaled data\nscaler = StandardScaler()\nx_scaled = scaler.fit_transform(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build PCA\npca = PCA(n_components = 2)\npca.fit(x_scaled)\nX_reduced_pca = pca.transform(x_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca_data = pd.DataFrame(X_reduced_pca,columns=[\"p1\",\"p2\"])\npca_data[\"diagnosis\"] = y","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"20\"></a><br>\n## Visualize Of New Dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"hue =pca_data[\"diagnosis\"]\ndata = [go.Scatter(x = pca_data.p1,\n                   y = pca_data.p2,\n                   mode = 'markers',\n                   marker=dict(\n                           size=12,\n                           color=hue,\n                           symbol=\"pentagon\",\n                           line=dict(width=2) #çevre çizgileri\n                           ))]  \n                            \nlayout = go.Layout(title=\"PCA\",\n                   xaxis=dict(title=\"p1\"),\n                   yaxis=dict(title=\"p2\"),\n                   hovermode=\"closest\")\nfig = go.Figure(data=data,layout=layout)   \npyo.iplot(fig)                ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"21\"></a><br>\n## Classification After PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"pca_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prepare X and Y"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pca = pca_data.diagnosis\nx_pca = pca_data.drop([\"diagnosis\"],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_pca, x_test_pca, y_train_pca, y_test_pca = train_test_split(x_pca, y_pca, test_size=0.33, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### KNN Model via PCA Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_pca = KNeighborsClassifier()\nknn_pca.fit(x_train_pca, y_train_pca)\ny_pred_pca = knn_pca.predict(x_test_pca)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_cm_pca = confusion_matrix(y_test_pca,y_pred_pca)\nknn_acc_pca = metrics.accuracy_score(y_test_pca, y_pred_pca)\nprint(knn_cm_pca)\nprint(knn_acc_pca)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's Which Points are in the correct area "},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualize \ncmap_light = ListedColormap(['orange',  'cornflowerblue'])\ncmap_bold = ListedColormap(['darkorange', 'darkblue'])\n\nh = .05 # step size in the mesh\nX = x_pca\nx_min, x_max = (X.iloc[:, 0].min() - 1), (X.iloc[:, 0].max() + 1)\ny_min, y_max = X.iloc[:, 1].min() - 1, X.iloc[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                     np.arange(y_min, y_max, h))\n\nZ = knn_pca.predict(np.c_[xx.ravel(), yy.ravel()])\n\n# Put the result into a color plot\nZ = Z.reshape(xx.shape)\nplt.figure(figsize=(20, 10), dpi=80)\nplt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n\n# Plot also the training points\nplt.scatter(X.iloc[:, 0], X.iloc[:, 1], c=y, cmap=cmap_bold,\n            edgecolor='k', s=20)\nplt.xlim(xx.min(), xx.max())\nplt.ylim(yy.min(), yy.max())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"22\"></a><br>\n## Neighborhood Components Analysis (NCA)"},{"metadata":{"trusted":true},"cell_type":"code","source":"nca = NeighborhoodComponentsAnalysis(n_components = 2, random_state = 42)\nnca.fit(x_scaled, y)\nx_nca = nca.transform(x_scaled)\nnca_data = pd.DataFrame(x_nca, columns = [\"p1\",\"p2\"])\nnca_data[\"diagnosis\"] = y","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"23\"></a><br>\n## Visualize Of New Dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"hue =nca_data[\"diagnosis\"]\ndata_nca = [go.Scatter(x = nca_data.p1,\n                   y = nca_data.p2,\n                   mode = 'markers',\n                   marker=dict(\n                           size=7,\n                           color=hue,\n                           symbol=\"circle\",\n                           line=dict(width=2) \n                           ))]  \n                            \nlayout = go.Layout(title=\"NCA\",\n                   xaxis=dict(title=\"p1\"),\n                   yaxis=dict(title=\"p2\"),\n                   hovermode=\"closest\")\nfig = go.Figure(data=data_nca,layout=layout)   \npyo.iplot(fig) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"24\"></a><br>\n## Classification After NCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_nca = nca_data.diagnosis\nx_nca = nca_data.drop([\"diagnosis\"],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_nca, x_test_nca, y_train_nca, y_test_nca = train_test_split(x_nca, y_nca, test_size=0.33, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### KNN Model via NCA Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_nca = KNeighborsClassifier()\nknn_nca.fit(x_train_nca, y_train_nca)\ny_pred_nca = knn_nca.predict(x_test_nca)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_cm_nca = confusion_matrix(y_test_nca,y_pred_nca)\nknn_acc_nca = metrics.accuracy_score(y_test_nca, y_pred_nca)\nprint(knn_cm_nca)\nprint(knn_acc_nca)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's Which Points are in the correct area "},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualize \ncmap_light = ListedColormap(['orange',  'cornflowerblue'])\ncmap_bold = ListedColormap(['darkorange', 'darkblue'])\n\nh = .3 # step size in the mesh\nX = x_nca\nx_min, x_max = (X.iloc[:, 0].min() - 1), (X.iloc[:, 0].max() + 1)\ny_min, y_max = X.iloc[:, 1].min() - 1, X.iloc[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                     np.arange(y_min, y_max, h))\n\nZ = knn_nca.predict(np.c_[xx.ravel(), yy.ravel()])\n\n# Put the result into a color plot\nZ = Z.reshape(xx.shape)\nplt.figure(figsize=(20, 10), dpi=80)\nplt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n\n# Plot also the training points\nplt.scatter(X.iloc[:, 0], X.iloc[:, 1], c=y, cmap=cmap_bold,\n            edgecolor='k', s=20)\nplt.xlim(xx.min(), xx.max())\nplt.ylim(yy.min(), yy.max())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"25\"></a><br>\n## Compare Accuracies"},{"metadata":{"trusted":true},"cell_type":"code","source":"models = [\"Default\",\"PCA\",\"NCA\"]\nvalues = [0.946,0.952,0.984]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compare Model's Acc\nf,ax = plt.subplots(figsize = (10,7))\nsns.barplot(x=models, y=values,palette=\"viridis\");\nplt.title(\"Compare Accuracies\",fontsize = 20,color='blue')\nplt.xlabel('Analysis',fontsize = 15,color='blue')\nplt.ylabel('Accuracies',fontsize = 15,color='blue')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}