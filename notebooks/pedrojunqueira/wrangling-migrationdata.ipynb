{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# My first public Kernel in Kaggle\n\nI have been seriously learning python for DS since April this year.\n\nI had a vague idea about the language but now I would say I feel more comfortable.\nTo understand the language I took a good Udemy course and then decided to do the entire Dataquest path in Python\n\nWhat I notice is that the best way to practice is to just get started.\nIt will take a while to things look \"perfect\" and I know I will make lots of mistake and not do things so elegantly at start, but I put a purpose to just get started and like just do things as I go along and google, stack overflow my way to fluency.\nJust at randomly going through a data set and wrangling and analysing you improve your analytical skill.\nIn the kernel below I try to do just that and I learn a few things along the way.\nI will keep on adding to it to get to a stage where we can conclude something about this data.\n"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"mg = pd.read_csv('../input/missing-migrants-project/MissingMigrants-Global-2019-12-31_correct.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom datetime import datetime\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mg.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mg.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mg.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mg['Region of Incident'].value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.pivot_table(mg,values='Total Dead and Missing',index='Reported Date',aggfunc=np.sum).sort_index().head()\n# Cannot sort as the date is a string and do not like to see in alphabetical order\n# Will Create a date field","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Found a good article here https://www.datacamp.com/community/tutorials/converting-strings-datetime-objects","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Get one scalar to learn the new function\ndate_s = mg.iloc[1,2]\ndate_s","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"date_test = datetime.strptime(date_s,'%B %d, %Y')\nprint(date_test)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now create a new proper datetime column\nmg['Reported Date dt']= mg['Reported Date'].apply(lambda x: datetime.strptime(x,'%B %d, %Y'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.pivot_table(mg,values='Total Dead and Missing',index='Reported Date dt',aggfunc=np.sum).sort_index().plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.pivot_table(mg,values='Total Dead and Missing',index='Reported Year',aggfunc=np.sum).sort_index().plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualise a table per year with number of dead\npd.pivot_table(mg,values='Total Dead and Missing',index='Reported Year',aggfunc=np.sum).sort_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Maximum date is : {}'.format(mg['Reported Date dt'].max()))\n# last reported date was end of 1st Quarted 2019\nprint('Minimum date is : {}'.format(mg['Reported Date dt'].min()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Interesting that there was a great report increase in 2015 and 2016 then it came down in the years of 2017 and 2018 with the lowest. Lets not consider 2019 as the year is not yet finish. The latest data is from March 2019. Also need to disregard 2014 for comparison as there is not a full year there.\nAs a Data Scientist our first job is to be sceptical until we have clear and objective evidence. \nWe don't really know if all the incidents were reported and if the numbers reported are accurate. \nOne thing that I would think is. Why the numbers went down?\n\n* International Media pressure?\n* Decrease of conflict, which decreased migration?\n* More humane treatment of migrants by the police coast?\n"},{"metadata":{},"cell_type":"markdown","source":"Let's now visualise the proportion of missing people of Male, Female and Children"},{"metadata":{"trusted":true},"cell_type":"code","source":"\npd.pivot_table(mg,values=['Number of Males','Number of Females','Number of Children'],\n               index='Reported Year',\n               aggfunc={'Number of Males': np.sum,'Number of Females': np.sum,'Number of Children': np.sum}).plot(kind='bar')\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It looks that the split of male and female and children is not always reported because the total Male and Female is not equals the total number of missing or dead.\nSo we cannot simply analyse the data for all, however lets take the proportion of Male Female for those that the total Male+Female=Total Missing or Dead."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a column that sum Total Male and Female\nmg['Total MFC']= mg['Number of Males']+mg['Number of Females']+mg['Number of Children']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# filter the data frame that meet the criteria and check how many records has with correctly reporting Male and Female\nmg[mg['Total MFC']==mg['Total Dead and Missing']].shape[0]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"only 45 reports looks have done \"correctly\"... not a good thing but let's see anyway"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a dataframe with only the observations with correct report of Male,Female and Children\nmg_reportMFC = mg[mg['Total MFC']==mg['Total Dead and Missing']]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's visualise both charts and observe with all data including the non reported MFC and the reported and check if the proportion are similar"},{"metadata":{"trusted":true},"cell_type":"code","source":"datasets=[mg,mg_reportMFC]\n\nfor data in datasets:\n    pd.pivot_table(data,values=['Number of Males','Number of Females','Number of Children'],\n                   index='Reported Year',\n                   aggfunc={'Number of Males': np.sum,'Number of Females': np.sum,'Number of Children': np.sum}).plot(kind='bar')\n  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.pivot_table(mg,values=['Number of Males','Number of Females','Number of Children'],\n               index='Reported Year',\n               aggfunc={'Number of Males': np.sum,'Number of Females': np.sum,'Number of Children': np.sum})\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# transform into tidy format using melt\n\ntidy =pd.pivot_table(mg_reportMFC,values=['Number of Males','Number of Females','Number of Children'],\n               index='Reported Year',\n               aggfunc={'Number of Males': np.sum,'Number of Females': np.sum,'Number of Children': np.sum})\n\ntidy['year']=tidy.index\npd.melt(tidy,id_vars=['year'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"It is very similar visually the proportion for both dataframe. In 2016 there are more children than women on the \"Correct\" data and in 2014 looks like there much more children"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Another oportunity to improve the data is to split location coordinates\nThe location coordinates is in only one column and it would be good to split them into to by manipulating string ising the expand property\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# split on ',' coma and expand then rename columns\nlat_lon = mg['Location Coordinates'].str.split(',',expand=True).rename(index=int, columns={0: \"lat\", 1: \"lon\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Concat expanded columns\nmg =pd.concat([mg,lat_lon],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mg.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Will attemp use folim to project this in a map\n# here is a good page https://alysivji.github.io/getting-started-with-folium.html\n# Folium package looks very good\n\nimport folium\n\n#wow it is in Kaggle\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmg.info()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cast lat lon as float\nmg['lat'] = mg['lat'].astype(float)\nmg['lon'] = mg['lon'].astype(float)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_lat =mg['lat'].max()\nmax_lon =mg['lon'].max()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is not finish. Will come back to plot the missing migrants in a map and see how it looks"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting a random sample of 3000 records to get an idea where in the world migrants are missing\n\nm = folium.Map([max_lat, max_lon], zoom_start=3)\n\nfor point in mg.loc[:,['lat','lon']].dropna().sample(frac=1).values.tolist()[:3000]:\n    folium.Circle(\n        radius=100,\n        location=point,\n        color='blue',\n        fill=True,\n    ).add_to(m)\n    \nm        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}