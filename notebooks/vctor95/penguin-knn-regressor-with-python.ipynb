{"cells":[{"metadata":{},"cell_type":"markdown","source":"**PREDICTING BODY MASS WITH KNN REGRESSOR**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import libraries\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom plotnine import *\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsRegressor\npenguin = pd.read_csv(\"../input/palmer-archipelago-antarctica-penguin-data/penguins_size.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**GENERAL ANALYSIS**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Observing the first rows\npenguin.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Statistical summary\npenguin.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#variable type\npenguin.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#function showing null per column\ndef nulator(df):\n    nulls = df.isnull().sum()\n    return nulls\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#applying function\nnulator(penguin)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#taking the few nulls out\npenguin = penguin.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking the nulls are out now\nnulator(penguin)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**VISUALIZING VARIABLE DISTRIBUTIONS**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#columns conversion into list in order to apply a visualization loop\nvariables = penguin.columns.to_list()\nvariables","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Loop returning the distribution of every variable\nfor value in variables:\n    graph = ggplot(penguin) + geom_bar(color=\"black\", fill=\"skyblue\") + aes(x=value) + theme_bw() + labs(title= \"variable distribution\" + \" \" + value)\n    print(graph)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"penguin.species.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"penguin.island.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#conversion into binary values for later application of predictors\n\ndict_species = {\"Adelie\":\"1\",\n               \"Chinstrap\":\"2\",\n               \"Gentoo\":\"3\"}\npenguin[\"species\"].replace(dict_species, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dict_island = {'Torgersen': \"1\", 'Biscoe': \"2\", 'Dream':\"3\"}\npenguin[\"island\"].replace(dict_island, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dict_sex = {\"FEMALE\":\"0\", \"MALE\":\"1\"}\npenguin[\"sex\"].replace(dict_sex, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Something was wrong in following steps when applying int conversion to sex column so we check what is going on:\npenguin.sex.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#finding and erasing wrong value\npenguin[penguin[\"sex\"] == \".\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"penguin = penguin.drop([336], axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#int tipe is applied to all the non float columns\npenguin[\"species\"] = penguin[\"species\"].astype(\"int\")\npenguin[\"island\"] = penguin[\"island\"].astype(\"int\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"penguin[\"sex\"] = penguin[\"sex\"].astype(\"int\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Based on the data, we come up with the idea of creating a predictor for body mass. \n#We set X and Y \nY = penguin[\"body_mass_g\"]\nX = penguin.drop(\"body_mass_g\", axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We show the correlation matrix. If too variables are too correlated to one another, we should erase one of them\n\nmatriz_correlaciones = penguin.corr(method=\"pearson\")\nn_ticks = len(penguin.columns)\nplt.figure(figsize=(9,9))\nplt.xticks(range(n_ticks), penguin.columns, rotation=\"vertical\")\nplt.yticks(range(n_ticks), penguin.columns)\nplt.colorbar(plt.imshow(matriz_correlaciones, interpolation=\"nearest\", vmin=-1., vmax=1, cmap=plt.get_cmap(\"Oranges\")))\nplt.title(\"Matriz de correlación de Pearson\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#further look on correlations:\n\ncorrelaciones_target = matriz_correlaciones.values[ -1, : -1]\nindices_inversos =  abs(correlaciones_target[ : ]).argsort()[ : : -1]\ndiccionario = {}\nfor nombre, correlacion in zip( X.columns[indices_inversos], list(correlaciones_target[indices_inversos] ) ):\n    diccionario[nombre] = correlacion\npd.DataFrame.from_dict(diccionario, orient='index', columns=['Correlación con la target'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Very low correlation of species and island with the target (bopdy mass), we take them out\nX = X.drop([\"species\", \"island\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#data standardizing\n\nobj_escalar = StandardScaler()\nX_standardized = obj_escalar.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**MODEL DESIGN**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Train-test division\nX_train, X_test, y_train, y_test = train_test_split(X_standardized, Y, test_size=.3, random_state=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#KNN model starting\nknn = KNeighborsRegressor(n_neighbors=5)\n\n# Fitting\nknn.fit(X_train, y_train)\n\n#Score checking\nknn.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_complexity_curve(k_list, knn_model, x_train, x_test, y_train, y_test):\n    \n    train_scores = []\n    test_scores = []\n    \n    # For each k\n    for k in k_list:\n        # Initialize, fit, predict\n        knn = knn_model(k)\n        \n        knn.fit(x_train, y_train)\n        \n        train_scores.append(knn.score(x_train, y_train))\n        test_scores.append(knn.score(x_test, y_test))\n\n    # Plot\n    fig, ax = plt.subplots()\n    \n    ax.plot(k_list, train_scores, label='Training Accuracy', color='red')\n    ax.plot(k_list, test_scores, label='Testing Accuracy', color='black')\n\n    ax.set(title='k-NN with Different Values for $k$',\n           xlabel='Number of Neighbors',\n           ylabel='Accuracy')\n    \n    ax.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We check the curves in order to find out what would be the best value for K.\nneighbors = np.arange(1, 50)\nplot_complexity_curve(neighbors, KNeighborsRegressor, X_train, X_test, y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We confirm what it the highest accuracy value given 50 different K values:\nn=0\nneighbors_value = {}\nfor value in range(1,50):\n    n+=1\n    \n    # Initialize kNN\n    knn = KNeighborsRegressor(n_neighbors=n)\n\n    # Fit and score\n    knn.fit(X_train, y_train)\n    neighbors_value[knn.score(X_test, y_test)] = n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(max(neighbors_value))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(neighbors_value.get(max(neighbors_value)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We create the best model given an optimal k of 10\n\n#KNN model starting\nknn_best = KNeighborsRegressor(n_neighbors=10)\n\n# Fitting\nknn_best.fit(X_train, y_train)\n\n#Score checking\nknn_best.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**THE MODEL RETURNED AN ACCURACY OF 85% WHICH CAN BE CONSIDERED GOOD**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}