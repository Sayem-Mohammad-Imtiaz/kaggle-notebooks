{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"0039c256-84c0-34ac-a255-2723c6967c4e"},"source":"Data Visualisation"},{"cell_type":"markdown","metadata":{"_cell_guid":"d512b5dc-5893-928f-eb1f-22150d712956"},"source":"Data Visualisation"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"62d0daef-c213-2e02-eff5-56b5d21ae945"},"outputs":[],"source":"# import \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nsns.set(style=\"white\", color_codes=True)\n\n# load dataset\nvoice = pd.read_csv(\"../input/voice.csv\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2da190c2-0d9a-07ae-1ddb-d954955be998"},"outputs":[],"source":"# let's see what is going on here\nvoice.describe()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2b2acd3d-d3da-2069-fbb7-cd63ef60195f"},"outputs":[],"source":"# meanfreq: mean frequency (in kHz)\n# sd: standard deviation of frequency\n# median: median frequency (in kHz)\n# Q25: first quantile (in kHz)\n# Q75: third quantile (in kHz)\n# IQR: interquantile range (in kHz)\n# skew: skewness (see note in specprop description)\n# kurt: kurtosis (see note in specprop description)\n# sp.ent: spectral entropy\n# sfm: spectral flatness\n# mode: mode frequency\n# centroid: frequency centroid (see specprop)\n# meanfun: average of fundamental frequency measured across acoustic signal\n# minfun: minimum fundamental frequency measured across acoustic signal\n# maxfun: maximum fundamental frequency measured across acoustic signal\n# meandom: average of dominant frequency measured across acoustic signal\n# mindom: minimum of dominant frequency measured across acoustic signal\n# maxdom: maximum of dominant frequency measured across acoustic signal\n# dfrange: range of dominant frequency measured across acoustic signal\n# modindx: modulation index. Calculated as the accumulated absolute difference between adjacent measurements of fundamental frequencies divided by the frequency range"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"697eec8c-0fa7-1e98-f9b8-04f6fcff4828"},"outputs":[],"source":"voice.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"52a03b28-090d-53cd-1e07-3ded02334f7f"},"outputs":[],"source":"voice[\"meanfun\"].order()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8aa9f56f-f354-d86a-30d3-8e8990717bb4"},"outputs":[],"source":"voice[\"label\"].value_counts()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"813f0993-41c9-f4fb-af0b-167a7b39c797"},"outputs":[],"source":"sns.FacetGrid(voice, hue=\"label\", size=10).map(plt.scatter, \"meanfun\", \"meanfreq\").add_legend()\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"83c379ec-e8ad-f27b-8c08-6643953bcb85"},"outputs":[],"source":"sns.FacetGrid(voice, hue=\"label\", size=10).map(plt.scatter, \"meanfun\", \"meandom\").add_legend()\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"551c3353-dd7b-5ff4-3b31-a37b5cd401eb"},"outputs":[],"source":"sns.FacetGrid(voice, hue=\"label\", size=6).map(sns.kdeplot, \"meanfun\").add_legend()\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79e4dccf-99d2-3390-626f-2ba306b5581d"},"outputs":[],"source":"# to see the effect of every feature ==> radviz cycle\nfrom pandas.tools.plotting import radviz\nradviz(voice, \"label\")\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0912f80c-a588-75c9-fa73-4cc70a73dea5"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aed5b0e9-81f4-fa58-128a-936d2bc213c1"},"outputs":[],"source":"# let's see what is going on here\nvoice.describe()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2dc9a749-2e1d-e050-d851-5dd1a98539df"},"outputs":[],"source":"# meanfreq: mean frequency (in kHz)\n# sd: standard deviation of frequency\n# median: median frequency (in kHz)\n# Q25: first quantile (in kHz)\n# Q75: third quantile (in kHz)\n# IQR: interquantile range (in kHz)\n# skew: skewness (see note in specprop description)\n# kurt: kurtosis (see note in specprop description)\n# sp.ent: spectral entropy\n# sfm: spectral flatness\n# mode: mode frequency\n# centroid: frequency centroid (see specprop)\n# meanfun: average of fundamental frequency measured across acoustic signal\n# minfun: minimum fundamental frequency measured across acoustic signal\n# maxfun: maximum fundamental frequency measured across acoustic signal\n# meandom: average of dominant frequency measured across acoustic signal\n# mindom: minimum of dominant frequency measured across acoustic signal\n# maxdom: maximum of dominant frequency measured across acoustic signal\n# dfrange: range of dominant frequency measured across acoustic signal\n# modindx: modulation index. Calculated as the accumulated absolute difference between adjacent measurements of fundamental frequencies divided by the frequency range"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a7cac5c6-c479-08fd-104a-64d3a2da3315"},"outputs":[],"source":"voice.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3d53104a-873c-4649-298d-a28beb4a6644"},"outputs":[],"source":"voice[\"meanfun\"].order()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"be13f398-7445-2241-72ce-2269a85b9dd1"},"outputs":[],"source":"voice[\"label\"].value_counts()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fb1401a6-03bb-5052-1a00-4a5167938c81"},"outputs":[],"source":"sns.FacetGrid(voice, hue=\"label\", size=10).map(plt.scatter, \"meanfun\", \"meanfreq\").add_legend()\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"de1e337a-5e66-ff07-3e47-4400b7d8d5b5"},"outputs":[],"source":"sns.FacetGrid(voice, hue=\"label\", size=10).map(plt.scatter, \"meanfun\", \"meandom\").add_legend()\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"88bd7d8c-2450-fdb2-720e-b38f2d1d0029"},"outputs":[],"source":"sns.FacetGrid(voice, hue=\"label\", size=6).map(sns.kdeplot, \"meanfun\").add_legend()\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"442b2e71-09f8-560e-7801-2f19e05647f9"},"outputs":[],"source":"# to see the effect of every feature ==> radviz cycle\nfrom pandas.tools.plotting import radviz\nradviz(voice, \"label\")\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"fa11d4a4-22ab-9098-63f8-54668c48c2df"},"source":"Logistic Regression"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"61b08d4b-3b35-d93e-fc78-582a6fe8daab"},"outputs":[],"source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.cross_validation import cross_val_score"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"444432a2-bb33-ef68-84c0-235e9230d31a"},"outputs":[],"source":"# preprocessing, split features and outcomes \nX = voice.iloc[:, :-1]\nY = voice.iloc[:, 20]\n\n# convert label\nlabel = labelEncoder()\ny = label.fit_transform(Y)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"00c2a688-0857-9bce-d5e1-abadcf6270e7"},"outputs":[],"source":"# split data in training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1) "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e96d5f09-415a-2f7b-70c8-1385b9bf4f13"},"outputs":[],"source":"# pipeline of operations\nestimators = [('scl', StandardScaler()), ('pca', PCA(n_components=2)), ('clf', LogisticRegression(random_state=1))]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9fd7b4e8-8c24-d69f-f23f-4f7b4252d752"},"outputs":[],"source":"# fit the estimator\npipe_lr = Pipeline(estimators)\npipe_lr.fit(X_train, y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fede3840-73ce-a12f-9ba7-1871e78bd3f0"},"outputs":[],"source":"# not sure about this !\n# n_job decided how many cpu will you use to calc\n# cv decided how many pices of data do you want to split\n# mean accurary rate\nscores = cross_val_score(estimator=pipe_lr, X=X_train, y=y_train, cv=10, n_jobs=1)"},{"cell_type":"markdown","metadata":{"_cell_guid":"107cef7f-d7ae-5b5c-7faf-26a658267d60"},"source":"Learning Curves "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bf19a1ef-ca78-ce9f-3386-67897119655f"},"outputs":[],"source":"# learning curve for training \nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.learning_curve import learning_curve\n\npipe_lr = Pipeline([('scl', StandardScaler()), ('clf', LogisticRegression(penalty='l2', random_state=0))])\ntrain_sizes, train_scores, test_scores = learning_curve(estimator=pipe_lr, X=X_train, y=y_train, train_sizes=np.linspace(0.1, 1.0, 10), cv=10, n_jobs=1)\n\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\n\nplt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='training accuracy')\nplt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\nplt.plot(train_sizes, test_mean, color='green', linestyle='--', marker='s', markersize=5, label='validation accuracy')\nplt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')\nplt.grid()\nplt.xlabel('Number of training samples')\nplt.ylabel('Accuracy')\nplt.title('Learning Curve')\nplt.legend(loc='lower right')\nplt.ylim([0.8, 1.0])\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b3757c3e-3f53-f18b-7f0e-79fcceb27c56"},"outputs":[],"source":"# learning curve for validation\nfrom sklearn.learning_curve import validation_curve\n\nparam_range = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\ntrain_scores, test_scores = validation_curve(estimator=pipe_lr, X=X_train, y=y_train, param_name='clf__C', param_range=param_range, cv=10)\n\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\n\nplt.plot(param_range, train_mean, color='blue', marker='o', markersize=5, label='training accuracy')\nplt.fill_between(param_range, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\nplt.plot(param_range, test_mean, color='green', linestyle='--', marker='s', markersize=5, label='validation accuracy')\nplt.fill_between(param_range, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')\n\nplt.grid()\nplt.xscale('log')\nplt.legend(loc='lower right')\nplt.xlabel('Parameter C')\nplt.ylabel('Accuracy')\nplt.title('Validation Curve')\nplt.ylim([0.8, 1.0])\nplt.show()\n"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}