{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Student Test Scores Analysis - Linear Regression","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The following analysis is performed on a generated data structure of hypothetical student test scores and the student's various characteristics. \n\nThe analysis includes an exploratory data analysis, regression modeling, and assumption checks.\n\nMuch of the modeling code was sourced from the following article: https://towardsdatascience.com/verifying-the-assumptions-of-linear-regression-in-python-and-r-f4cd2907d4c0","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Load Libraries**","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\npd.set_option('display.max_columns', None)\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Environment Set Up","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Load Data**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/students-performance-in-exams/StudentsPerformance.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Overview**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Check for nulls**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Awesome, no nulls","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Rename Columns**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.rename(columns = {'race/ethnicity':'race'}, inplace = True)\ndf.rename(columns = {'parental level of education':'parent_education'}, inplace = True)\ndf.rename(columns = {'test preparation course':'prep_course'}, inplace = True)\ndf.rename(columns = {'math score':'math_score'}, inplace = True)\ndf.rename(columns = {'reading score':'reading_score'}, inplace = True)\ndf.rename(columns = {'writing score':'writing_score'}, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Create a total_score column**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['total_score'] = df['math_score'] + df['reading_score'] + df['writing_score']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check the column now","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Exploration - Visualization","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Load Libaries**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Variable Distributions**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (6,8))\nsns.set(style = 'darkgrid', font = 'sans-serif', font_scale = 1.25, palette = 'Set2')\nax = sns.countplot(\n    x = 'gender',\n    data = df,\n    edgecolor = 'black')\nax.set_title('Distribution of Student Genders', fontsize = 15)\nax.set(xlabel = 'Gender', ylabel = 'Frequency')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (9,6))\nsns.set(style = 'darkgrid', font = 'sans-serif', font_scale = 1.25, palette = 'deep')\nax = sns.countplot(\n    x = 'race',\n    data = df,\n    edgecolor = 'black')\nax.set_title('Distribution of Student Race/Ethnicity', fontsize = 15)\nax.set(xlabel = 'Race/Ethnicity', ylabel = 'Frequency')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (13,6))\nsns.set(style = 'darkgrid', font = 'sans-serif', font_scale = 1.25, palette = 'deep')\nax = sns.countplot(\n    x = 'parent_education',\n    data = df,\n    edgecolor = 'black')\nax.set_title('Distribution of Parent Education Level', fontsize = 20)\nax.set(xlabel = 'Parental Education Level', ylabel = 'Frequency')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (6,8))\nsns.set(style = 'darkgrid', font = 'sans-serif', font_scale = 1.25, palette = 'deep')\nax = sns.countplot(\n    x = 'lunch',\n    data = df,\n    edgecolor = 'black')\nax.set_title('Distribution of Lunch Options', fontsize = 15)\nax.set(xlabel = 'Lunch Option', ylabel = 'Frequency')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (6,8))\nsns.set(style = 'darkgrid', font = 'sans-serif', font_scale = 1.25, palette = 'deep')\nax = sns.countplot(\n    x = 'prep_course',\n    data = df,\n    edgecolor = 'black')\nax.set_title('Distribution of Prep Course', fontsize = 15)\nax.set(xlabel = 'Prep Course', ylabel = 'Frequency')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style = 'darkgrid', font = 'sans-serif', font_scale = 1.25)\nplt.figure(figsize = (10,6))\nplt.hist(df['math_score'], bins = 20, color = 'cornflowerblue')\nplt.xlabel('Math Score', fontsize = 13)\nplt.ylabel('Frequency', fontsize = 13)\nplt.title('Distribution of Math Scores', fontsize = 13)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style = 'darkgrid', font = 'sans-serif', font_scale = 1.25)\nplt.figure(figsize = (10,6))\nplt.hist(df['reading_score'], bins = 20, color = 'lightcoral')\nplt.xlabel('Reading Score', fontsize = 13)\nplt.ylabel('Frequency', fontsize = 13)\nplt.title('Distribution of Reading Scores', fontsize = 13)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style = 'darkgrid', font = 'sans-serif', font_scale = 1.25)\nplt.figure(figsize = (10,6))\nplt.hist(df['writing_score'], bins = 20, color = 'goldenrod')\nplt.xlabel('Writing Score', fontsize = 13)\nplt.ylabel('Frequency', fontsize = 13)\nplt.title('Distribution of Writing Score', fontsize = 13)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style = 'darkgrid', font = 'sans-serif', font_scale = 1.25)\nplt.figure(figsize = (10,6))\nplt.hist(df['total_score'], bins = 20, color = 'darkorchid')\nplt.xlabel('Total Score', fontsize = 13)\nplt.ylabel('Frequency', fontsize = 13)\nplt.title('Distribution of Total Score', fontsize = 13)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling - Linear Regression","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Setting up**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df[['gender', 'race', 'parent_education', 'prep_course', 'lunch']]\nX = pd.get_dummies(df1, columns = ['gender', 'race', 'parent_education', 'prep_course', 'lunch'], dtype = int)\ny = df['total_score']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nimport statsmodels.api as sm\n\nX_constant = sm.add_constant(X)\nlin_reg = sm.OLS(y, X_constant).fit()\nlin_reg.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Checking Assumptions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.stats.api as sms\nsns.set_style('darkgrid')\nsns.mpl.rcParams['figure.figsize'] = (15.0, 9.0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Assumption Check: Linearity**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Y (response variable) is assumed to be a linear function of the features. We will inspect plots of observed vs predicted values AND residuals vs predicted values. We hope to find a linear plot for the former and a horizontal line for the latter.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def linearity_test(model, y):\n    fitted_vals = model.predict()\n    resids = model.resid\n    \n    fig, ax = plt.subplots(1,2)\n    \n    sns.regplot(x = fitted_vals, y = y, lowess = True, ax = ax[0], line_kws = {'color': 'red'})\n    ax[0].set_title('Observed vs. Predicted Values', fontsize = 16)\n    ax[0].set(xlabel = 'Predicted', ylabel = 'Observed')\n    \n    sns.regplot(x = fitted_vals, y = resids, lowess = True, ax = ax[1], line_kws = {'color' : 'red'})\n    ax[1].set_title('Residuals vs. Predicted Values', fontsize = 16)\n    ax[1].set(xlabel = 'Predicted', ylabel = 'Residuals')\n    \nlinearity_test(lin_reg, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks good! Linearity assumption is satisifed.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Assumption Check: Mean of residuals is zero**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lin_reg.resid.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Good, very small.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Assumption check: no multicollinearity**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"First, lets take a look at the corr map","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,8))\nsns.heatmap(X.corr(), annot = True, cmap = 'cubehelix_r')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It definitely looks like the variables are not highly correlated. Let's make a function to determine the VIF of each variable","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = [variance_inflation_factor(X_constant.values, i) for i in range(X_constant.shape[1])]\npd.DataFrame({'vif': vif[1:]}, index = X.columns).to_csv","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To be honest, I'm not sure why the output is \"inf\" for most of these variables when it should be super low.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Assumption Check: homoscedasticity (equality of residual variance)**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def homoscedasticity_test(model):\n    fitted_vals = model.predict()\n    resids = model.resid\n    resids_standardized = model.get_influence().resid_studentized_internal\n\n    fig, ax = plt.subplots(1,2)\n\n    sns.regplot(x=fitted_vals, y=resids, lowess=True, ax=ax[0], line_kws={'color': 'red'})\n    ax[0].set_title('Residuals vs Fitted', fontsize=16)\n    ax[0].set(xlabel='Fitted Values', ylabel='Residuals')\n\n    sns.regplot(x=fitted_vals, y=np.sqrt(np.abs(resids_standardized)), lowess=True, ax=ax[1], line_kws={'color': 'red'})\n    ax[1].set_title('Scale-Location', fontsize=16)\n    ax[1].set(xlabel='Fitted Values', ylabel='sqrt(abs(Residuals))')\n\n    bp_test = pd.DataFrame(sms.het_breuschpagan(resids, model.model.exog), \n                           columns=['value'],\n                           index=['Lagrange multiplier statistic', 'p-value', 'f-value', 'f p-value'])\n\n    gq_test = pd.DataFrame(sms.het_goldfeldquandt(resids, model.model.exog)[:-1],\n                           columns=['value'],\n                           index=['F statistic', 'p-value'])\n\n    print('\\n Breusch-Pagan test ----')\n    print(bp_test)\n    print('\\n Goldfeld-Quandt test ----')\n    print(gq_test)\n    print('\\n Residuals plots ----')\n\nhomoscedasticity_test(lin_reg)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plots look like they satisfy the assumption, and the outputs certify that assertion with p-values > 0.05","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Assumption Check: no autocorrelation of residuals","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.tsa.api as smt\n\nacf = smt.graphics.plot_acf(lin_reg.resid, lags = 40, alpha = 0.05)\nacf.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Assumption Check: normality of residuals**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import stats\n\ndef normality_of_residuals_test(model):\n    sm.ProbPlot(model.resid).qqplot(line='s');\n    plt.title('Q-Q plot');\n\n    jb = stats.jarque_bera(model.resid)\n    sw = stats.shapiro(model.resid)\n    ad = stats.anderson(model.resid, dist='norm')\n    ks = stats.kstest(model.resid, 'norm')\n    \n    print(f'Jarque-Bera test ---- statistic: {jb[0]:.4f}, p-value: {jb[1]}')\n    print(f'Shapiro-Wilk test ---- statistic: {sw[0]:.4f}, p-value: {sw[1]:.4f}')\n    print(f'Kolmogorov-Smirnov test ---- statistic: {ks.statistic:.4f}, p-value: {ks.pvalue:.4f}')\n    print(f'Anderson-Darling test ---- statistic: {ad.statistic:.4f}, 5% critical value: {ad.critical_values[2]:.4f}')\n    print('If the returned AD statistic is larger than the critical value, then for the 5% significance level, the null hypothesis that the data come from the Normal distribution should be rejected. ')\n    \nnormality_of_residuals_test(lin_reg)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The plot looks pretty good, quite normally distributed. Additionally, the Jarque-Bera, Kolmogorov-Smirnov and Shapiro-Wilk test confirm this. However the Anderson-Darling test appears to claim that the residuals are not normally distributed because the test statistic is greater than the critical value.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's finish out this notebook with another iteration of the linear regression test to review our results.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lin_reg.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It appears that parental education is the greatest predictor of student success (in this fake dataset).","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}