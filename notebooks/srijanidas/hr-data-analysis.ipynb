{"cells":[{"metadata":{"id":"U6cscqtonJvL"},"cell_type":"markdown","source":"# Source of this dataset\n","execution_count":null},{"metadata":{"id":"ijb4MEeHo0b8"},"cell_type":"markdown","source":"https://www.kaggle.com/vjchoudhary7/hr-analytics-case-study/","execution_count":null},{"metadata":{"id":"-PHnnfWBnVFK"},"cell_type":"markdown","source":"# About the data\n","execution_count":null},{"metadata":{"id":"1xPP3Tsko6xv"},"cell_type":"markdown","source":"Depending on the data available for the employees and attrition information (whether the employee has left the company on previous year or not), we need to be able to predict the probability of an employee to stay in the company.\nAlso this data should help us to reduce attrition rate focusing on the right factors.","execution_count":null},{"metadata":{"id":"x_0DGfodnZbC"},"cell_type":"markdown","source":"# Importing Modules","execution_count":null},{"metadata":{"id":"TpMkPhlEp6k3","outputId":"6d9d1f30-35a2-4523-a341-e60c4634aa74","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"id":"CSJCh9t8njCM"},"cell_type":"markdown","source":"# Loading the data","execution_count":null},{"metadata":{"id":"o6e47Q13qTq0","trusted":true},"cell_type":"code","source":"employee_survey = pd.read_csv(\"../input/hr-analytics-case-study/employee_survey_data.csv\")\nmanager_survey = pd.read_csv(\"../input/hr-analytics-case-study/manager_survey_data.csv\")\ngeneral_data = pd.read_csv(\"../input/hr-analytics-case-study/general_data.csv\")","execution_count":null,"outputs":[]},{"metadata":{"id":"xOc0RUyyrmcd","outputId":"1196f67e-f119-4712-a82b-933fc43faff5","trusted":true},"cell_type":"code","source":"print(employee_survey.columns)\nprint(manager_survey.columns)\nprint(general_data.columns)","execution_count":null,"outputs":[]},{"metadata":{"id":"QsCgKKlfrrwQ"},"cell_type":"markdown","source":"We will merge the 3 datasets on the common column \"EmployeeID\" and work on a single dataset.","execution_count":null},{"metadata":{"id":"412vD8zDr7GJ","outputId":"40f24542-adbc-4fd0-c61c-8d3738711cda","trusted":true},"cell_type":"code","source":"from functools import reduce\ndf_list = [employee_survey, manager_survey, general_data]\nemp_df = reduce(lambda left,right: pd.merge(left,right,how='inner',on='EmployeeID'), df_list)\nemp_df.columns","execution_count":null,"outputs":[]},{"metadata":{"id":"8QRSZFF1sPfK"},"cell_type":"markdown","source":"Let's have a quick look at the data we are going to analyze.","execution_count":null},{"metadata":{"id":"L3wPteeGsZcF","outputId":"188db1fb-68f0-426d-fd0a-11ef0acd04df","trusted":true},"cell_type":"code","source":"emp_df.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"xpPDCoXEsgta","outputId":"83b2fd4f-61b9-4ba6-b42d-f9925ef8938b","trusted":true},"cell_type":"code","source":"emp_df.info()","execution_count":null,"outputs":[]},{"metadata":{"id":"8UNrYHsGsnE3","outputId":"82bb24ed-9807-438d-c2d9-95dadb40fe79","trusted":true},"cell_type":"code","source":"emp_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"id":"JTP9-rOhtdhe","outputId":"e7d68146-8d91-4f29-ea2f-04f8ac8e2bbf","trusted":true},"cell_type":"code","source":"print(emp_df['Over18'].unique())\nprint(emp_df['EmployeeCount'].unique())\nprint(emp_df['StandardHours'].unique())","execution_count":null,"outputs":[]},{"metadata":{"id":"p7gmMcDntC_K"},"cell_type":"markdown","source":"By inspecting the features quickly, we can see that we can get rid of the following features for the mentioned reasons\n\n*   EmployeeID - is a unique ID, Attrition rate does not depend on this\n*   Over18 - has a single value for all columns (i.e. Y)\n*   EmployeeCount - has a single value for all columns (i.e. 1)\n*   StandardHours - has a single value for all columns (i.e. 8)\n\n","execution_count":null},{"metadata":{"id":"4oz1sHhGt2dl"},"cell_type":"markdown","source":"# Drop Unnecessary Features (Part 1)","execution_count":null},{"metadata":{"id":"IRbycoTYuA09","trusted":true},"cell_type":"code","source":"# This function takes the dataframe and list of features to be dropped\n# returns the updated dataframe\n\ndef drop_features(df, feat_list):\n    for col in feat_list:\n        if col in df.columns:\n            df.drop(col, axis=1, inplace=True)\n            print(f\"{col} is dropped\")\n        else:\n            print(f\"{col} is already dropped\")","execution_count":null,"outputs":[]},{"metadata":{"id":"Y1xw1ejFuN_5","outputId":"f38071e1-ed03-4e2d-b52c-c956e672923e","trusted":true},"cell_type":"code","source":"drop_features(emp_df, ['EmployeeID', 'EmployeeCount', 'Over18', 'StandardHours'])","execution_count":null,"outputs":[]},{"metadata":{"id":"4D3JcNUnn2zA"},"cell_type":"markdown","source":"# Visualizing Categorical Data","execution_count":null},{"metadata":{"id":"ofFyyCYZuX0V"},"cell_type":"markdown","source":"Our target column is \"Attrition\"\n\nLet's check out all the labeled columns in the dataframe\n- We will list the categorical features\n- get their position/column index\n- see how target column \"Attrition\" is related with them","execution_count":null},{"metadata":{"id":"eGNDxvBfuqP5","outputId":"585b8657-d6eb-4f88-c252-ffce7ed3f036","trusted":true},"cell_type":"code","source":"print(\"The categorical columns and their index-\")\nfor col in emp_df.columns:\n    if emp_df[col].dtype == 'object':\n        print(col, emp_df.columns.get_loc(col))","execution_count":null,"outputs":[]},{"metadata":{"id":"2r8kTNE_vCpq","trusted":true},"cell_type":"code","source":"def show_percentage_of_people_left(column_name):\n    df = emp_df.groupby(column_name)['Attrition'].describe()\n    df['percentage of people left'] = (1 - (df['freq']/df['count']))*100\n    print(df)\n    print('===============================')","execution_count":null,"outputs":[]},{"metadata":{"id":"v_fTAsryvHv5","outputId":"9e3ed7b9-bbb2-4cde-d68a-42c62a3f7b6d","trusted":true},"cell_type":"code","source":"for col in ['BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus']:\n    show_percentage_of_people_left(col)","execution_count":null,"outputs":[]},{"metadata":{"id":"hyuaWmr7vaBx"},"cell_type":"markdown","source":"Let's visualize the categorical data in plots as well.\n\n- For working with the categorical data, we need to encode them.\nOnehotencoding will increase the number of features dramatically \n(for e.g. for the column 'JobRole', it will add 8 columns!)\n\n- Understanding the trend of Attrition depending on the various labels would help us to bind similar labels together \nand thus reduce the column numbers.\n\n- We will also reduce a column after the encoding to avoid dummy variable trap","execution_count":null},{"metadata":{"id":"2ugweYYuvO20","outputId":"be82ed25-f61d-49da-8772-412ca7f9fefe","trusted":true},"cell_type":"code","source":"sns.countplot(x='Attrition', hue='BusinessTravel', data=emp_df)","execution_count":null,"outputs":[]},{"metadata":{"id":"6qWuc8Fkv0I2","outputId":"ed99a038-247b-4680-f8f7-45a8d467e781","trusted":true},"cell_type":"code","source":"sns.countplot(x='Attrition', hue='Department', data=emp_df)","execution_count":null,"outputs":[]},{"metadata":{"id":"uVRuqWzxv8VX"},"cell_type":"markdown","source":" **Observation** : Human Resource Department has quite higher attrition rate than others\n","execution_count":null},{"metadata":{"id":"hTVJQlX1v_DT","outputId":"f4b3892a-4e47-4ce9-916e-7d4f2bed695e","trusted":true},"cell_type":"code","source":"sns.countplot(x='Attrition', hue='EducationField', data=emp_df)","execution_count":null,"outputs":[]},{"metadata":{"id":"IxvKbWsFwK0_"},"cell_type":"markdown","source":"**Observation** : Human Resource has quite high attrition rate than others","execution_count":null},{"metadata":{"id":"sl-9x3w03ky6","outputId":"24b96d5a-7b1f-4b96-a813-2ab662912a6a","trusted":true},"cell_type":"code","source":"sns.countplot(x='Attrition', hue='Gender', data=emp_df)","execution_count":null,"outputs":[]},{"metadata":{"id":"xoVF8fCU3q-0","outputId":"58c092bf-414c-4647-bc48-0979bd1df12f","trusted":true},"cell_type":"code","source":"sns.countplot(x='Attrition', hue='JobRole', data=emp_df)","execution_count":null,"outputs":[]},{"metadata":{"id":"I-T7iKqb3u9m","outputId":"716e9559-defd-44da-f814-244167dc23d9","trusted":true},"cell_type":"code","source":"sns.countplot(x='Attrition', hue='MaritalStatus', data=emp_df)","execution_count":null,"outputs":[]},{"metadata":{"id":"L7EuIsnW-csu"},"cell_type":"markdown","source":"# Encoding Categorical Data","execution_count":null},{"metadata":{"id":"G6XsPf6T4Q7w"},"cell_type":"markdown","source":"**Encoding \"MaritalStatus\"**\n\nWe will encode this column \"MaritalStatus\" in a new column named \"Single\"\n\n- Value : 1 means Single, Attrition rate 25% \n- Value : 0 means Married/Divorced, Attrition rate ~11% on average","execution_count":null},{"metadata":{"id":"iOmjyULH4AGl","trusted":true},"cell_type":"code","source":"emp_df['Single'] = pd.get_dummies(emp_df[\"MaritalStatus\"])['Single']","execution_count":null,"outputs":[]},{"metadata":{"id":"3WeQ_Ulb5EAh"},"cell_type":"markdown","source":"**Encoding \"JobRole\"**\n\n```\n\nLet's divide this into 3 categories-\n1st:\nResearch Director           240      2  No  183                     23.75\n2nd:\nLaboratory Technician       777      2  No  651                   16.2162\nResearch Scientist          876      2  No  717                   18.1507\nSales Executive             978      2  No  813                   16.8712\n3rd:\nHealthcare Representative   393      2  No  336                   14.5038\nHuman Resources             156      2  No  135                   13.4615\nManager                     306      2  No  264                   13.7255\nManufacturing Director      435      2  No  387                   11.0345\nSales Representative        249      2  No  213                   14.4578\n\nColumn Representation-\nRD    LT_RS_SE  \n1     0        - means 1st category (Attrition rate 23%)\n0     1        - means 2nd category (avg. Attrition rate 17%)\n0     0        - means 3rd category (avg. Attrition rate 13%)\n\n```\nUsing the first line of code to avoid the warning as below\n\nC:\\Users\\Dell\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nRef link:\n\nhttps://www.dataquest.io/blog/settingwithcopywarning/\n\nHere it is safe to ignore this error as we do want to update our original dataframe.\n","execution_count":null},{"metadata":{"id":"DE54wlK05Tga","trusted":true},"cell_type":"code","source":"pd.set_option('mode.chained_assignment', None)\n\nemp_df['RD'] = np.zeros(emp_df.shape[0])\nemp_df['LT_RS_SE'] = np.zeros(emp_df.shape[0])\n\nfor row_num in range(0, emp_df.shape[0]):\n    if emp_df['JobRole'][row_num] == 'Research Director':\n        emp_df['RD'][row_num] = 1\n    if emp_df['JobRole'][row_num] in ['Laboratory Technician', 'Research Scientist', 'Sales Executive']:\n        emp_df['LT_RS_SE'][row_num] = 1","execution_count":null,"outputs":[]},{"metadata":{"id":"HOIcdury6UJO","trusted":true},"cell_type":"code","source":"emp_df['Male'] = pd.get_dummies(emp_df[\"Gender\"])[\"Male\"]\n\n# In EducationField\n# HR : Avg Attrition Rate 40 %\n# Others : Avg Attrition Rate 14 %\nemp_df[\"EducationField_HR\"] = pd.get_dummies(emp_df[\"EducationField\"], prefix='EducationField')[\"EducationField_Human Resources\"]\n\n# In Department\n# HR : Avg Attrition Rate 30 %\n# Others : Avg Attrition Rate 15 %\n\nemp_df[\"Department_HR\"] = pd.get_dummies(emp_df[\"Department\"], prefix='Department')[\"Department_Human Resources\"]\n\nemp_df[\"Travel_Frequently\"] = pd.get_dummies(emp_df[\"BusinessTravel\"])[\"Travel_Frequently\"]\nemp_df[\"Travel_Rarely\"] = pd.get_dummies(emp_df[\"BusinessTravel\"])[\"Travel_Rarely\"]\n\nemp_df[\"Attrition_Yes\"] = pd.get_dummies(emp_df[\"Attrition\"], prefix='Attrition')[\"Attrition_Yes\"]","execution_count":null,"outputs":[]},{"metadata":{"id":"n6HIAPtw75t-"},"cell_type":"markdown","source":"Now that all our categorical columns as encoded, we can remove the original columns.","execution_count":null},{"metadata":{"id":"2C7fSFlo8D-V"},"cell_type":"markdown","source":"# Drop Unnecessary Features (Part 2)","execution_count":null},{"metadata":{"id":"DXte6_-e78N7","outputId":"07452802-75d5-44c9-b7ba-c5d3820dd014","trusted":true},"cell_type":"code","source":"drop_features(emp_df, ['BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus', 'Attrition'])","execution_count":null,"outputs":[]},{"metadata":{"id":"75sFYS8w8V1u","outputId":"534e59ac-8bf2-4018-c1fd-c72654f57e6c","trusted":true},"cell_type":"code","source":"emp_df.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"Rj6z2tRw8aOr","outputId":"52778bf8-97ac-4179-ac54-0ace365cb6d1","trusted":true},"cell_type":"code","source":"emp_df.info()","execution_count":null,"outputs":[]},{"metadata":{"id":"t1OVRINE8kma"},"cell_type":"markdown","source":"# Study Correlation of the features","execution_count":null},{"metadata":{"id":"Fym8F-ST8rUL","outputId":"bb2bfdcd-3e93-49a7-ebbf-8f34e0f2b03a","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(24,10))\nsns.heatmap(emp_df.corr(), annot=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"6rPO-heG80P0"},"cell_type":"markdown","source":"**Observations :**\n- \"DistanceFromHome\" and \"StockOptionLevel\" are barely correlated with Attrition, hence can be removed\n- \"PercentageSalaryHike\" is highly correlated with \"PerformanceRating\", \"PercentageSalaryHike\" can be removed\n- \"YearsAtCompany\", \"YearsSinceLastPromotion\", \"YearsWithCurrManager\", \"TotalWorkingYears\" are highly correlated\n- Removing \"YearsSinceLastPromotion\", \"YearsWithCurrManager\", \"TotalWorkingYears\"\n- Keeping both HR columns (education field and department) as other educational fields/dept.s won't be considered otherwise\n- Keeping both travel_frequently and travel_rarely, as we will lose non_travel data otherwise","execution_count":null},{"metadata":{"id":"Un6o_6WI9XNJ"},"cell_type":"markdown","source":"# Drop Unnecessary Features (Part 3)","execution_count":null},{"metadata":{"id":"UPrIdRiA9d2s","outputId":"31fb2281-610b-4f61-f841-096995b4cddd","trusted":true},"cell_type":"code","source":"drop_features(emp_df, [\"DistanceFromHome\", \"StockOptionLevel\", \"PercentSalaryHike\", \"YearsSinceLastPromotion\", \"YearsWithCurrManager\", \"TotalWorkingYears\"])","execution_count":null,"outputs":[]},{"metadata":{"id":"OtO-qdVV9tfZ","outputId":"529064f8-b3d4-4a85-bfec-86b9e9c9842e","trusted":true},"cell_type":"code","source":"emp_df.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"EIQDnK8g966N","outputId":"8ff8a90c-b83f-4f57-9165-830d2faac7b5","trusted":true},"cell_type":"code","source":"emp_df.columns","execution_count":null,"outputs":[]},{"metadata":{"id":"xK6y1x88_EvT"},"cell_type":"markdown","source":"# Visualizing Numerical Data","execution_count":null},{"metadata":{"id":"QhOMyxk-_UnJ","outputId":"ef3a2029-79b8-4dfc-ad8f-1073621b2cc1","trusted":true},"cell_type":"code","source":"sns.jointplot(emp_df['Age'], emp_df['NumCompaniesWorked'], data=emp_df, kind='kde')","execution_count":null,"outputs":[]},{"metadata":{"id":"GVJhfdCy_hMo"},"cell_type":"markdown","source":"**Observation :** Most employees have worked in 1-2 companies, aged between 28-35 (roughly).","execution_count":null},{"metadata":{"id":"aQ1Jh-UL_x2W","outputId":"47d340bf-eb06-4fbf-d5b8-b4f7bae44bbf","trusted":true},"cell_type":"code","source":"sns.jointplot(emp_df['Age'], emp_df['NumCompaniesWorked'], data=emp_df, kind='hex')","execution_count":null,"outputs":[]},{"metadata":{"id":"kjeNl7ip_5H9","outputId":"4a3aab5e-854a-4e95-e005-1e51787941c8","trusted":true},"cell_type":"code","source":"sns.jointplot(emp_df['JobLevel'], emp_df['NumCompaniesWorked'], data=emp_df, kind='kde')","execution_count":null,"outputs":[]},{"metadata":{"id":"sGjYXq3bABCX","outputId":"46a21e64-098e-4074-c135-03672b4748f4","trusted":true},"cell_type":"code","source":"sns.countplot(emp_df['EnvironmentSatisfaction'], hue=emp_df['Attrition_Yes'], data=emp_df)","execution_count":null,"outputs":[]},{"metadata":{"id":"OM_vDlFMAFor","outputId":"7e7200c5-12c5-4fd0-db6f-09ebedffd60c","trusted":true},"cell_type":"code","source":"sns.countplot(emp_df['JobSatisfaction'], hue=emp_df['Attrition_Yes'], data=emp_df)","execution_count":null,"outputs":[]},{"metadata":{"id":"Vbcr8y5cALhH","outputId":"de38a338-746c-495b-e6fc-349a550938af","trusted":true},"cell_type":"code","source":"sns.countplot(emp_df['WorkLifeBalance'], hue=emp_df['Attrition_Yes'], data=emp_df)","execution_count":null,"outputs":[]},{"metadata":{"id":"w9OGsWOZANs-"},"cell_type":"markdown","source":"**Observation** : Employees with poor work-life balance are more likely to leave","execution_count":null},{"metadata":{"id":"fqqYW28hAhzn","outputId":"9ab75aff-c2f2-4046-b62d-5fa46186c675","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(18,10))\nsns.countplot(emp_df['Age'], hue=emp_df['Attrition_Yes'], data=emp_df)","execution_count":null,"outputs":[]},{"metadata":{"id":"H-OubCysn-kv"},"cell_type":"markdown","source":"# Splitting the data for training and testing","execution_count":null},{"metadata":{"id":"vd6AvC5B9-FS","trusted":true},"cell_type":"code","source":"X = emp_df.iloc[:, :-1].values\ny = emp_df.iloc[:, -1].values","execution_count":null,"outputs":[]},{"metadata":{"id":"T9g01kJE9_U5","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=47)","execution_count":null,"outputs":[]},{"metadata":{"id":"sEnSh9TDoMQj"},"cell_type":"markdown","source":"# Handling Missing Values","execution_count":null},{"metadata":{"id":"sFkzUBQVA0v6","outputId":"c352f4b4-0384-4483-cea0-d94600efe9bb","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(24,10))\nsns.heatmap(emp_df.isnull())","execution_count":null,"outputs":[]},{"metadata":{"id":"fIcF3kj0BNH2","outputId":"41e0c405-7eac-4153-b45b-b2e87d19b119","trusted":true},"cell_type":"code","source":"for col in ['EnvironmentSatisfaction', 'JobSatisfaction', 'WorkLifeBalance', 'NumCompaniesWorked']:\n  print(\"Column : \", col)\n  print(\"Mean : \", emp_df[col].mean())\n  print(\"Mode : \", emp_df[col].mode())\n  print(\"Unique values : \", emp_df[col].unique())\n  print(\"Index : \", emp_df.columns.get_loc(col))","execution_count":null,"outputs":[]},{"metadata":{"id":"GmXgCix5CqBF"},"cell_type":"markdown","source":"**Comment **: \n- We will impute missing values of 'EnvironmentSatisfaction', 'WorkLifeBalance', 'NumCompaniesWorked' with most frequent values \n- We will impute missing values of 'JobSatisfaction' with const. 3\n\n- This features are not continuous, hence chose whole number(mode) than fraction(mean)","execution_count":null},{"metadata":{"id":"cny4PtXJDxCR"},"cell_type":"markdown","source":"**Imputing missing values with SimpleImputer**\n\n- SimpleImputer takes 2-D numpy array\n```\nX_train[:, 0].reshape(X_train[:, 0].shape[0], 1) is a 2-D array made from X_train[:, 0] which is a 1-D array\n```\n- shape of the 2-D array is (n, 1) and shape of 1-D array is (n,)\n- array.shape[0] = no. of rows\n- array.shape[1] = no. of cols, this gives error for 1-D array\n- Missing value imputation is done after splitting the data in training and test set.\n- Note that fit is done only once with training set, not on complete set to avoid data leakage\n- training and test set both are transformed with the same value(for eg. mean) calculated by fit() method applied on training set\n\n","execution_count":null},{"metadata":{"id":"7SkV5TVFDoNG","trusted":true},"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nimputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\nimputer_const = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=3)\n\n# for 'EnvironmentSatisfaction', 'WorkLifeBalance', 'NumCompaniesWorked'\n\nfor col in [0, 2, 9]:\n    imputer.fit(X_train[:, col].reshape(X_train[:, col].shape[0], 1))\n    X_train[:, col] = imputer.transform(X_train[:, col].reshape(X_train[:, col].shape[0], 1))[:, 0]\n    X_test[:, col] = imputer.transform(X_test[:, col].reshape(X_test[:, col].shape[0], 1))[:, 0]\n\n# for 'JobSatisfaction'\ncol = 1\nimputer_const.fit(X_train[:, col].reshape(X_train[:, col].shape[0], 1))\nX_train[:, col] = imputer_const.transform(X_train[:, col].reshape(X_train[:, col].shape[0], 1))[:, 0]\nX_test[:, col] = imputer_const.transform(X_test[:, col].reshape(X_test[:, col].shape[0], 1))[:, 0]","execution_count":null,"outputs":[]},{"metadata":{"id":"dnDXU19QEv0z"},"cell_type":"markdown","source":"Verifying if missing values are correctlty filled up.","execution_count":null},{"metadata":{"id":"BlxV042RE3pP","outputId":"c94a4293-5911-4f0b-ea62-335d63a1f7ca","trusted":true},"cell_type":"code","source":"for i in [0, 1, 2, 9]:\n    array_sum = np.sum(X_train[:,i])\n    array_has_nan = np.isnan(array_sum)\n    print(array_has_nan)\n    \n    array_sum = np.sum(X_test[:,i])\n    array_has_nan = np.isnan(array_sum)\n    print(array_has_nan)","execution_count":null,"outputs":[]},{"metadata":{"id":"qJDYR-AuoStv"},"cell_type":"markdown","source":"# Scaling the data","execution_count":null},{"metadata":{"id":"vqkct9R9FCF2"},"cell_type":"markdown","source":"- Scaling the data is required for Logistic Regression. \n- Decision Tree Classifier and Random Forest do not need Scaled data.\n- Scaling is done only on the independant columns.","execution_count":null},{"metadata":{"id":"ejUsi6oKFgri","trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train_scaled = scaler.transform(X_train)\nX_test_scaled = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"3Mx8XD8pFnAU"},"cell_type":"markdown","source":"**Importing Modules for Performance Evaluation** ","execution_count":null},{"metadata":{"id":"Iwr7UJYMF47O","trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"id":"vOGEEbKhog1j"},"cell_type":"markdown","source":"# Logistic Regression","execution_count":null},{"metadata":{"id":"2fENjjt4GBA5","outputId":"41571263-d138-4cf7-883e-eb46e512098a","trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()\n\nmodel.fit(X_train_scaled, y_train)\n\ny_pred = model.predict(X_test_scaled)\nprint(accuracy_score(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"id":"d7qv5OvMomno"},"cell_type":"markdown","source":"# Decision Tree Classification\n","execution_count":null},{"metadata":{"id":"oVHjNI15GGmE","outputId":"27da4371-880f-4629-9d62-cedf72a7069d","trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nmodel = DecisionTreeClassifier()\n\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\n\nprint(accuracy_score(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"id":"3n_ARL-3oqfT"},"cell_type":"markdown","source":"# Random Forest Classification","execution_count":null},{"metadata":{"id":"MgQfv4xMGRQu","outputId":"a95d3e55-9266-4658-9307-5b0c3d362963","trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier()\n\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\n\nprint(accuracy_score(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"id":"wyagEpTdovy5"},"cell_type":"markdown","source":"# Conclusion","execution_count":null},{"metadata":{"id":"T1-neAeZHqYJ"},"cell_type":"markdown","source":"- We got 84.5 % accuracy with our Logistic Regression Model\n- Decision Tree Classifier predicted result with 98.8% accuracy.\n- We have been able to achieve maximum of 99.4% accuracy with Random Forest Classifier!\n\n","execution_count":null},{"metadata":{"id":"50g9vfVbGbe0"},"cell_type":"markdown","source":"**Note** :\n\n- It is important to encode all the categorical columns before starting to train the classification models. Otherwise it throws error similar to \"ValueError: could not convert string to float: b\"\n- Reference Link - https://stackoverflow.com/questions/38108832/passing-categorical-data-to-sklearn-decision-tree#:~:text=question%20is%20misleading.-,As%20it%20stands%2C%20sklearn%20decision%20trees%20do%20not%20handle%20categorical,()%20will%20treat%20as%20numeric.\n\n- This was observed for Logistic Regression, Decision Tree and Random Forest","execution_count":null},{"metadata":{"id":"2WySVBA0HKMh","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}