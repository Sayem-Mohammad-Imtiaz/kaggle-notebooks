{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\nWelcome user, in this notebook I will process heart failure clinic data.During the process ; before , I will visualize their data with variety tools then train data to predict results with regression methods.It's gonna be nice.Let's start to jobs.\n\n<font color=\"blue\"/>\n\n<b>Content</b>\n\n   1. [Imports Library](#1)\n       * [Reading Input File](#2)\n   2. [Explore Data](#3)\n       * [Overview Data](#4)\n       * [Detect Missing Values](#ek4)\n       * [Investigate Columns](#5)\n           * [Target Columns(DEATH_EVENT)](#ek1)\n           * [Univariate Variable Analysis](#ek2)\n           * [Figure Out Relationship Between Columns According to Target](#ek3)\n           * [Visualize Whole Columns](#6)\n               * [Age -- DEATH_EVENT](#7)\n               * [Anaemia](#8)\n               * [Creatinine Phosphokinase -- Deaths Event](#9)\n               * [Diabetes](#10)\n               * [Ejection Fraction](#11)\n               * [High Blood Pressure](#12)\n               * [Platelets](#13)\n               * [Serum Creatinine](#14)\n               * [Serum Sodium](#15)\n               * [Sex](#16)\n               * [Smoking](#17) \n               * [Time](#18)\n               * [DEATH EVENT](#19)\n   3. [Preprocessing and Define Model](#20)\n       * [Outliers Detection](#21)\n       * [Preprocessing](#22)\n       * [Define Model](#23)\n       * [Using Pipeline](#24)\n       * [Implement Algorithms on Model](#25)\n           * [KNN](#26)\n           * [Logistic Regression](#27)\n           * [Random Forest Classification](#28)\n           * [XGBoost](#29)\n           * [DecisionTree Classification](#30)\n   4. [Final Predict](#31)\n  "},{"metadata":{},"cell_type":"markdown","source":"<a id=\"1\"></a>\n## Imports Library"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom plotly.offline import init_notebook_mode, iplot, plot\nimport plotly as py\nimport plotly.graph_objs as go\nfrom collections import Counter\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import Lasso\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBRegressor\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler,OneHotEncoder, OrdinalEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import cross_val_score\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"2\"></a>\n### Reading Input File"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"filePath = \"/kaggle/input/heart-failure-clinical-data/heart_failure_clinical_records_dataset.csv\"\n\nheartData = pd.read_csv(filePath)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"3\"></a>\n## Explore Data"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4\"></a>\n### Overview Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"heartData.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"heartData.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"heartData.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(heartData.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"heartData.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"heartData.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"ek4\"></a>\n### Detect Missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"heartData.columns[heartData.isnull().any()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data has not any missign value , it's perfect"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"5\"></a>\n### Investigate Columns\n\nAs you seen , data has 13 columns and each one dtype is numeric.In this section we will seen columns on plots.Also I will examine target columns that DEATH_EVENT."},{"metadata":{},"cell_type":"markdown","source":"<a id=\"ek1\"></a>\n#### Target Columns(DEATH_EVENT)"},{"metadata":{"trusted":true},"cell_type":"code","source":"numericCol = [col for col in heartData.columns if heartData[col].dtype in [\"int64\",\"float64\"]]\nnumericCol","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if (len(numericCol) == len(heartData.columns)):\n    print(\"Whole columns dtypes is numeric.\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"target = heartData[\"DEATH_EVENT\"]\nsns.distplot(target)\nplt.title(\"Distribiton of Death Event\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"ek2\"></a>\n#### Univariate Variable Analysis(Exclude DEATH_EVENT)\n\n* I will occur multiply plots to show distribiton of columns exclude target column that DEATH_EVENT.\n* I will use this plots variety :\n    * distplot\n    * boxplot\n    * kdeplot"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_attributes = heartData.drop(\"DEATH_EVENT\",axis=1).copy()\n\nfig = plt.figure(figsize=(12,18))\n\nfor i in range(len(num_attributes.columns)):\n    fig.add_subplot(4,3,i+1)\n    sns.distplot(num_attributes.iloc[:,i].dropna())\n    plt.xlabel(num_attributes.columns[i])\n\nplt.show()    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(12,18))\n\nfor i in range(len(num_attributes.columns)):\n    fig.add_subplot(4,3,i+1)\n    sns.boxplot(num_attributes.iloc[:,i].dropna())\n    plt.xlabel(num_attributes.columns[i])\n\nplt.show()    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(12,18))\n\nfor i in range(len(num_attributes.columns)):\n    fig.add_subplot(4,3,i+1)\n    sns.kdeplot(num_attributes.iloc[:,i].dropna())\n    plt.xlabel(num_attributes.columns[i])\n\nplt.show()    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"ek3\"></a>\n#### Figure Out Relationship Between Columns According to Target"},{"metadata":{"trusted":true},"cell_type":"code","source":"correlation = heartData.corr()\nplt.figure(figsize=(12,15))\nsns.heatmap(correlation,annot=True,fmt=\".2f\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# correlation according to target column that DEATH_EVENT\n\ncorrToTarget = heartData.corr()[\"DEATH_EVENT\"].sort_values(ascending=False)\nsns.pointplot(x=corrToTarget.index,y=corrToTarget.values)\nplt.xticks(rotation=90)\nplt.title(\"Correlation Rates According to Target Column That DEATH_EVENT\")\nplt.ylabel(\"Correlation rates\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6\"></a>\n#### Visualize Whole Columns "},{"metadata":{},"cell_type":"markdown","source":"<a id=\"7\"></a>\n**Age -- DEATH_EVENT**"},{"metadata":{"trusted":true},"cell_type":"code","source":"recover = heartData.age[heartData.DEATH_EVENT==1]\ndead = heartData.age[heartData.DEATH_EVENT==0]\n\n\ntrace1 = go.Histogram(\n    x=recover,\n    opacity=0.75,\n    name = \"1\",\n    marker=dict(color='rgba(171, 50, 96, 0.6)'))\n\ntrace2 = go.Histogram(\n    x=dead,\n    opacity=0.75,\n    name = \"0\",\n    marker=dict(color='rgba(12, 50, 196, 0.6)'))\n\ndata = [trace1, trace2]\n\nlayout = go.Layout(barmode='overlay',\n                   title='patients age distribiton according to Deaths event',\n                   xaxis=dict(title='ages distribition'),\n                   yaxis=dict( title='Count'),\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=heartData.DEATH_EVENT,y=heartData.age)\nplt.xticks(rotation=45)\nplt.title(\"patients age distribiton according to age\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"8\"></a>\n**Anaemia**"},{"metadata":{"trusted":true},"cell_type":"code","source":"anaemia = heartData.anaemia.value_counts()\nanaemia.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = {\n    \"values\" : anaemia.values,\n    \"labels\" : anaemia.index,\n    \"type\" : \"pie\",\n    \"hoverinfo\":\"label+percent\",\n    \"hole\":.3\n}\n\nlayout={\n    \"title\":\"Rates anaemia bar chart\"\n}\nfig=go.Figure(data=data,layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"9\"></a>\n**Creatinine Phosphokinase -- Deaths Event**"},{"metadata":{"trusted":true},"cell_type":"code","source":"belongToRecover = heartData.creatinine_phosphokinase[heartData.DEATH_EVENT == 1]\nbelongToDead = heartData.creatinine_phosphokinase[heartData.DEATH_EVENT == 0]\n\ntrace1 = go.Histogram(\n    x=belongToRecover,\n    opacity=0.75,\n    name = \"1\",\n    marker=dict(color='rgba(171, 50, 96, 0.6)'))\n\ntrace2 = go.Histogram(\n    x=belongToDead,\n    opacity=0.75,\n    name = \"0\",\n    marker=dict(color='rgba(12, 50, 196, 0.6)'))\n\ndata = [trace1, trace2]\n\nlayout = go.Layout(barmode='overlay',\n                   title='patients creatinine phosphokinase distribiton according to Deaths event',\n                   xaxis=dict(title='ages distribition'),\n                   yaxis=dict(title='Count'),\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"10\"></a>\n**Diabetes**"},{"metadata":{"trusted":true},"cell_type":"code","source":"diabetes = heartData.diabetes.value_counts()\ndiabetes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = {\n    \"values\" : diabetes.values,\n    \"labels\" : diabetes.index,\n    \"type\" : \"pie\",\n    \"hoverinfo\":\"label+percent\",\n    \"hole\":.3\n}\n\nlayout={\n    \"title\":\"Rates diabetes bar chart\"\n}\nfig=go.Figure(data=data,layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"11\"></a>\n**Ejection Fraction**"},{"metadata":{"trusted":true},"cell_type":"code","source":"belongToRecover = heartData.ejection_fraction[heartData.DEATH_EVENT == 1]\nbelongToDead = heartData.ejection_fraction[heartData.DEATH_EVENT == 0]\n\ntrace1 = go.Histogram(\n    x=belongToRecover,\n    opacity=0.75,\n    name = \"1\",\n    marker=dict(color='rgba(171, 50, 96, 0.6)'))\n\ntrace2 = go.Histogram(\n    x=belongToDead,\n    opacity=0.75,\n    name = \"0\",\n    marker=dict(color='rgba(12, 50, 196, 0.6)'))\n\ndata = [trace1, trace2]\n\nlayout = go.Layout(barmode='overlay',\n                   title='patients ejection fraction distribiton according to Deaths event',\n                   xaxis=dict(title='ages distribition'),\n                   yaxis=dict(title='Count'),\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trace1 = go.Box(\n    x = heartData.DEATH_EVENT,\n    y = heartData.ejection_fraction,\n        marker = dict(\n        color = 'rgb(12, 128, 128)',\n    )\n)\nlayout = go.Layout(title=\"ejection fraction distribiton of deaths event with box plot\")\nfig = go.Figure(data=data,layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"12\"></a>\n**High Blood Pressure**"},{"metadata":{"trusted":true},"cell_type":"code","source":"bloodPressure = heartData.high_blood_pressure.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = {\n    \"values\" : bloodPressure.values,\n    \"labels\" : bloodPressure.index,\n    \"type\" : \"pie\",\n    \"hoverinfo\":\"label+percent\",\n    \"hole\":.3\n}\n\nlayout={\n    \"title\":\"Rates high blood pressure bar chart\"\n}\nfig=go.Figure(data=data,layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"13\"></a>\n**Platelets**"},{"metadata":{"trusted":true},"cell_type":"code","source":"belongToRecover = heartData.platelets[heartData.DEATH_EVENT == 1]\nbelongToDead = heartData.platelets[heartData.DEATH_EVENT == 0]\n\ntrace1 = go.Histogram(\n    x=belongToRecover,\n    opacity=0.75,\n    name = \"1\",\n    marker=dict(color='rgba(171, 50, 96, 0.6)'))\n\ntrace2 = go.Histogram(\n    x=belongToDead,\n    opacity=0.75,\n    name = \"0\",\n    marker=dict(color='rgba(12, 50, 196, 0.6)'))\n\ndata = [trace1, trace2]\n\nlayout = go.Layout(barmode='overlay',\n                   title='patients platelets distribiton according to Deaths event',\n                   xaxis=dict(title='ages distribition'),\n                   yaxis=dict(title='Count'),\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"14\"></a>\n**Serum Creatinine**"},{"metadata":{"trusted":true},"cell_type":"code","source":"belongToRecover = heartData.serum_creatinine[heartData.DEATH_EVENT == 1]\nbelongToDead = heartData.serum_creatinine[heartData.DEATH_EVENT == 0]\n\ntrace1 = go.Histogram(\n    x=belongToRecover,\n    opacity=0.75,\n    name = \"1\",\n    marker=dict(color='rgba(171, 50, 96, 0.6)'))\n\ntrace2 = go.Histogram(\n    x=belongToDead,\n    opacity=0.75,\n    name = \"0\",\n    marker=dict(color='rgba(12, 50, 196, 0.6)'))\n\ndata = [trace1, trace2]\n\nlayout = go.Layout(barmode='overlay',\n                   title='patients serum creatinine distribiton according to Deaths event',\n                   xaxis=dict(title='ages distribition'),\n                   yaxis=dict(title='Count'),\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trace1 = go.Box(\n    x = heartData.DEATH_EVENT,\n    y = heartData.serum_creatinine,\n        marker = dict(\n        color = 'rgb(12, 128, 128)',\n    )\n)\nlayout = go.Layout(title=\"serum creatinine distribiton of deaths event with box plot\")\nfig = go.Figure(data=data,layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"15\"></a>\n**Serum Sodium**"},{"metadata":{"trusted":true},"cell_type":"code","source":"heartData.serum_sodium","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"belongToRecover = heartData.serum_sodium[heartData.DEATH_EVENT == 1]\nbelongToDead = heartData.serum_sodium[heartData.DEATH_EVENT == 0]\n\ntrace1 = go.Histogram(\n    x=belongToRecover,\n    opacity=0.75,\n    name = \"1\",\n    marker=dict(color='rgba(171, 50, 96, 0.6)'))\n\ntrace2 = go.Histogram(\n    x=belongToDead,\n    opacity=0.75,\n    name = \"0\",\n    marker=dict(color='rgba(12, 50, 196, 0.6)'))\n\ndata = [trace1, trace2]\n\nlayout = go.Layout(barmode='overlay',\n                   title='patients serum sodium distribiton according to Deaths event',\n                   xaxis=dict(title='ages distribition'),\n                   yaxis=dict(title='Count'),\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trace1 = go.Box(\n    x = heartData.DEATH_EVENT,\n    y = heartData.serum_sodium,\n        marker = dict(\n        color = 'rgb(12, 128, 128)',\n    )\n)\nlayout = go.Layout(title=\"serum sodium distribiton of deaths event with box plot\")\nfig = go.Figure(data=data,layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"16\"></a>\n**Sex**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sex=heartData.sex.value_counts()\n\ndata = {\n    \"values\" : sex.values,\n    \"labels\" : sex.index,\n    \"type\" : \"pie\",\n    \"hoverinfo\":\"label+percent\",\n    \"hole\":.3\n}\n\nlayout={\n    \"title\":\"Rates sex bar chart\"\n}\nfig=go.Figure(data=data,layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"17\"></a>\n**Smoking**"},{"metadata":{"trusted":true},"cell_type":"code","source":"smoke = heartData.smoking.value_counts()\n\ndata = {\n    \"values\" : smoke.values,\n    \"labels\" : smoke.index,\n    \"type\" : \"pie\",\n    \"hoverinfo\":\"label+percent\",\n    \"hole\":.3\n}\n\nlayout={\n    \"title\":\"Rates smoke bar chart\"\n}\nfig=go.Figure(data=data,layout=layout)\niplot(fig)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"18\"></a>\n**Time**"},{"metadata":{"trusted":true},"cell_type":"code","source":"belongToRecover = heartData.time[heartData.DEATH_EVENT == 1]\nbelongToDead = heartData.time[heartData.DEATH_EVENT == 0]\n\ntrace1 = go.Histogram(\n    x=belongToRecover,\n    opacity=0.75,\n    name = \"1\",\n    marker=dict(color='rgba(171, 50, 96, 0.6)'))\n\ntrace2 = go.Histogram(\n    x=belongToDead,\n    opacity=0.75,\n    name = \"0\",\n    marker=dict(color='rgba(12, 50, 196, 0.6)'))\n\ndata = [trace1, trace2]\n\nlayout = go.Layout(barmode='overlay',\n                   title='patients time distribiton according to Deaths event',\n                   xaxis=dict(title='ages distribition'),\n                   yaxis=dict(title='Count'),\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trace1 = go.Box(\n    x = heartData.DEATH_EVENT,\n    y = heartData.time,\n        marker = dict(\n        color = 'rgb(12, 128, 128)',\n    )\n)\nlayout = go.Layout(title=\"time distribiton of deaths event with box plot\")\nfig = go.Figure(data=data,layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"19\"></a>\n**DEATH EVENT**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ndeath = heartData.DEATH_EVENT.value_counts()\n\ndata = {\n    \"values\" : death.values,\n    \"labels\" : death.index,\n    \"type\" : \"pie\",\n    \"hoverinfo\":\"label+percent\",\n    \"hole\":.3\n}\n\nlayout={\n    \"title\":\"Rates death bar chart\"\n}\nfig=go.Figure(data=data,layout=layout)\niplot(fig)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"20\"></a>\n## Preprocessing and Define Model\nIn this section I will make some preprocess for define model and predict results.Also it is ought to make before implement your model.Firstly I will detect outliers in data."},{"metadata":{},"cell_type":"markdown","source":"<a id=\"21\"></a>\n### Outliers Detection"},{"metadata":{"trusted":true},"cell_type":"code","source":"def detectOutliers(df,features):\n    outlier_indices=[]\n    for c in features:\n        Q1=np.percentile(df[c],25)\n        Q2=np.percentile(df[c],75)\n        IQR = Q2-Q1\n        outlierStep = IQR*1.5\n        outlierListCol = df[(df[c] < Q1-outlierStep) | (df[c]>Q2+outlierStep)].index\n        outlier_indices.extend(outlierListCol)\n    outlier_indices=Counter(outlier_indices)\n    multiple_outliers=list(i for i,v in outlier_indices.items() if v>2)\n    return multiple_outliers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"heartData.loc[detectOutliers(heartData,heartData.columns)]\n# there arent any outliers exist","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"22\"></a>\n### Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"Whole columns dtypes is numeric.[I controled above already](#5)"},{"metadata":{"trusted":true},"cell_type":"code","source":"heartData.dropna(axis=0,subset=[\"DEATH_EVENT\"],inplace=True)\ny = heartData.DEATH_EVENT\nx = heartData.drop([\"DEATH_EVENT\"],axis=1)\nX_train,X_test,y_train,y_test = train_test_split(x,y,train_size=0.8,test_size=0.2,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"23\"></a>\n### Define Model\nIn this section , I will try to define models and compare models to find each which has most high score.This is the point.However reach the point , we must do something namely we will develop models.Before we will set columns with according to their types.Then I will use pipeline to facility to develop and change model.Finally , I am going to implement each model on pipelines."},{"metadata":{"trusted":true},"cell_type":"code","source":"x.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After the columns control , I will detect columns which include process in <b>myCols</b> variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"constant_num_cols = x.columns\n#len(constant_num_cols) 12\nmyCols = constant_num_cols","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After that , I am going to adjust again variable's columns as myCols. "},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train[myCols].copy()\nX_test = X_test[myCols].copy()\nx = heartData[myCols].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"24\"></a>\n#### Using Pipeline"},{"metadata":{},"cell_type":"markdown","source":"We keep continue to create models with pipeline.As you know , pipeline is one of the most benefits way to create model."},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_transform_c = Pipeline(steps = [\n    (\"imputer\",SimpleImputer(strategy=\"mean\")),\n    (\"scaler\", StandardScaler())\n])\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"num_mean\",numerical_transform_c,constant_num_cols)\n    ]\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"25\"></a>\n### Implement Algorithms on Model"},{"metadata":{},"cell_type":"markdown","source":"**Lets start to implement models with KNN**"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"26\"></a>\n#### KNN\n\nI am going to implement KNN algorithm but before I will ought to find most suitable n_neighbours"},{"metadata":{"trusted":true},"cell_type":"code","source":"neighbours = np.arange(1,30)\ntestAccuracy = []\ntrainAccuracy = []\n\nfor i,k in enumerate(neighbours):\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(X_train,y_train)\n    trainAccuracy.append(knn.score(X_train,y_train))\n    testAccuracy.append(knn.score(X_test,y_test))\n\nplt.figure(figsize=(15,16))\nplt.plot(neighbours,testAccuracy,label=\"Test accuracy\")\nplt.plot(neighbours,trainAccuracy,label=\"Train Accuracy\")\nplt.legend()\nplt.title(\"Detect most suitable value for n_neighbours\")\nplt.xticks(neighbours)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = {\"n_neighbors\" : np.arange(1,30)}\nknn = KNeighborsClassifier()\nknn_cv = GridSearchCV(knn,grid,cv=3)\nknn_cv.fit(X_train,y_train)\n\nprint(\"Tuned parameter k : {}\".format(knn_cv.best_params_))\nprint(\"Best score for Knn = {}\".format(knn_cv.best_score_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems to be most high value is 10 or 11.Then , let's implement knn algorithms while n_neighbours equal 11"},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = KNeighborsClassifier(n_neighbors=11)\n\nmy_pipeline1 = Pipeline(steps = [\n    (\"preprocessor\",preprocessor),\n    (\"model\",model1)\n])\n\npreds1 = my_pipeline1.fit(X_train,y_train)\n\nprint(\"KNN algortihms score = {}\".format(my_pipeline1.score(X_test,y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now , let's look at algorithms predict on confusion matrix."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = my_pipeline1.predict(X_test)\ny_true = y_test\ncm_1 = confusion_matrix(y_pred,y_true)\n\nf,ax = plt.subplots(figsize=(6,6))\nplt.title(\"KNN algortihms score matrix\")\nsns.heatmap(cm_1,annot=True,color=\"red\",fmt=\"0.5f\",ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Cross-validation results for KNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"k=5\nknn_cross_validation = cross_val_score(my_pipeline1,X_train,y_train,cv=k)\n\nprint(\"CV Knn scores = {}\".format(knn_cross_validation))\nprint(\"CV Knn scores average : {}\".format(np.sum(knn_cross_validation)/k))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"27\"></a>\n####  Logistic Regression"},{"metadata":{},"cell_type":"markdown","source":"Before implement to logistic regression , I am going to find most suitable variable that <b>max_iter</b>"},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = {\"max_iter\" : np.arange(50,560,50)}\nlogreg = LogisticRegression()\nlog_cv = GridSearchCV(logreg,grid,cv=3)\nlog_cv.fit(X_train,y_train)\n\nprint(\"Tuned parameter n_estimators : {}\".format(log_cv.best_params_))\nprint(\"Best score for Logistic regression = {}\".format(log_cv.best_score_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's implement logistic regression while max_iter equal 150"},{"metadata":{"trusted":true},"cell_type":"code","source":"model2 = LogisticRegression(random_state=42,max_iter=150)\n\nmy_pipeline2 = Pipeline(steps = [\n    (\"preprocessor\",preprocessor),\n    (\"model\",model2)\n])\n\nmy_pipeline2.fit(X_train,y_train)\n\nprint(\"Logistic regression score = {}\".format(my_pipeline2.score(X_test,y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's look at our predicts with logistic regression on confusion matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred2 = my_pipeline2.predict(X_test)\ny_true2 = y_test\ncm_2 = confusion_matrix(y_pred2,y_true2)\n\nf,ax1 = plt.subplots(figsize=(6,6))\nplt.title(\"Logistic regression score matrix\")\nsns.heatmap(cm_2,annot=True,color=\"red\",fmt=\"0.5f\",ax=ax1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Cross-validation results for Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"logistic_cross_val = cross_val_score(my_pipeline2,X_train,y_train,cv=k)\n\nprint(\"CV Logistic reg. scores = {}\".format(logistic_cross_val))\nprint(\"CV Logistic reg. scores average : {}\".format(np.sum(logistic_cross_val)/k))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"28\"></a>\n#### Random Forest Classification"},{"metadata":{},"cell_type":"markdown","source":"Before implement to Random Forest Classification, I am going to find most suitable variable that <b>n_estimators</b>"},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = {\"n_estimators\" : np.arange(50,560,50)}\nrfc = RandomForestClassifier()\nrfc_cv = GridSearchCV(rfc,grid,cv=3)\nrfc_cv.fit(X_train,y_train)\n\nprint(\"Tuned parameter n_estimators : {}\".format(rfc_cv.best_params_))\nprint(\"Best score for random forest = {}\".format(rfc_cv.best_score_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's implement Random Forest Classification while n_estimators equal 20"},{"metadata":{"trusted":true},"cell_type":"code","source":"model3 = RandomForestClassifier(n_estimators=200,random_state=1)\nmy_pipeline3 = Pipeline(steps = [\n    (\"preprocessor\",preprocessor),\n    (\"model\",model3)\n])\n\nmy_pipeline3.fit(X_train,y_train)\nprint(\"Random Forest Classification Score = {}\".format(my_pipeline3.score(X_test,y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's look at our scores with Random Forest Classification on confusion matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred3 = my_pipeline3.predict(X_test)\ny_true3 = y_test\ncm_3 = confusion_matrix(y_pred3,y_true3)\n\nf,ax3 = plt.subplots(figsize=(6,6))\nsns.heatmap(cm_3,annot=True,fmt=\"0.5f\",ax=ax3)\nplt.title(\"Random Forest Classification Score Matrix\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Cross-validation results for Random Forest Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"random_forest_cross_validation = cross_val_score(my_pipeline3,X_train,y_train,cv=k)\n\nprint(\"CV Random Forest class. scores = {}\".format(random_forest_cross_validation))\nprint(\"CV Random Forest class. scores average : {}\".format(np.sum(random_forest_cross_validation)/k))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"29\"></a>\n#### XGBoost"},{"metadata":{},"cell_type":"markdown","source":"Before implement XGBoost algorithms , I am going to find most suitable variable that <b>n_estimators</b>"},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = {\"n_estimators\" : np.arange(100,1600,100)}\nXGbr = XGBRegressor()\nXGbr_cv = GridSearchCV(XGbr,grid,cv=3)\nXGbr_cv.fit(X_train,y_train)\n\nprint(\"Tuned parameter n_estimators : {}\".format(XGbr_cv.best_params_))\nprint(\"Best score = {}\".format(XGbr_cv.best_score_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Score will became very low so I am gong to pass <b>XGBoost</b>"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"30\"></a>\n#### Desicion Tree Classification"},{"metadata":{},"cell_type":"markdown","source":"Let's implement decision tree classification with pipeline."},{"metadata":{"trusted":true},"cell_type":"code","source":"model4 = DecisionTreeClassifier()\nmy_pipeline4 = Pipeline(steps = [\n    (\"preprocessor\",preprocessor),\n    (\"model\",model4)\n])\n\nmy_pipeline4.fit(X_train,y_train)\nprint(\"Desicion Tree Classification Score = {}\".format(my_pipeline4.score(X_test,y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred4 = my_pipeline4.predict(X_test)\ny_true4 = y_test\ncm_4 = confusion_matrix(y_pred4,y_true4)\n\nf,ax4 = plt.subplots(figsize=(6,6))\nsns.heatmap(cm_4,annot=True,fmt=\"0.5f\")\nplt.title(\"Desicion Tree Classification Score matrix\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Cross-validation results for Decision Tree Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"decision_tree_cross_validation = cross_val_score(my_pipeline4,X_train,y_train,cv=k)\n\nprint(\"CV Desicion Tree Classification scores = {}\".format(decision_tree_cross_validation))\nprint(\"CV Desicion Tree Classification. scores average : {}\".format(np.sum(decision_tree_cross_validation)/k))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**According to whole models and results , seems to random forest going to be most useful model.**"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"31\"></a>\n## Final Predict"},{"metadata":{},"cell_type":"markdown","source":"To sum up I will implement random forest classification on data.Before final process , we will ought set x and y variables.Then we can process model and data."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_full,X_test_full,y_train_full,y_test_full = train_test_split(x,y,train_size=0.8,test_size=0.2,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Set columns and variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train_full.copy()\nX_test = X_test_full.copy()\ny=y_train.copy()\nX_tr = X_train[myCols].copy()\nX_te = X_test[myCols].copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Carried out final model"},{"metadata":{"trusted":true},"cell_type":"code","source":"myFinalModel = RandomForestClassifier(n_estimators=200,random_state=1)\n\nmyFinalPipeline = Pipeline(steps = [\n    (\"preprocessor\",preprocessor),\n    (\"model\",myFinalModel)\n])\n\nmyFinalPipeline.fit(X_tr,y)\n\nfinalPreds = myFinalPipeline.predict(X_te)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = pd.DataFrame({\n    \"Id\" : X_te.index,\n    \"DEATH_EVENT\" : finalPreds\n})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"compression_opts = dict(method=\"zip\",archive_name=\"submission.csv\")\noutput.to_csv(\"submission.zip\",index=False,compression=compression_opts)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}