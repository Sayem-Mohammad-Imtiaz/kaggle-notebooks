{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# https://towardsdatascience.com/bert-text-classification-using-pytorch-723dfb8b6b5b\n\nimport numpy\nimport pandas\n%matplotlib inline\n\nReviews = pandas.read_csv('../input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\nprint(Reviews.shape)\nprint(Reviews.head())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import re\n\n# First, let's make a small function to clean our strings, because as we have seen before, there are tons of unwanted punctuations and other useless tags\ndef clear_sentence(sentence: str) -> str:\n    '''A function to clear texts using regex.'''\n    sentence = re.sub(r'\\W', ' ', str(sentence))\n    sentence = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', sentence)\n    sentence = re.sub(r'\\^[a-zA-Z]\\s+', ' ', sentence) \n    sentence = re.sub(r'\\s+', ' ', sentence, flags=re.I)\n    sentence = re.sub(r'^b\\s+', '', sentence)\n    sentence = sentence.lower()\n    return sentence","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Reviews['review'] = [clear_sentence(sentence) for sentence in Reviews['review']]\n\n#x = Reviews['review'].tolist()\n#y = Reviews['sentiment'].tolist()\nReviews.sentiment = pandas.factorize(Reviews.sentiment)[0]\n#X_train, X_test, y_train, y_test = train_test_split(x, y_binary, test_size=0.2, random_state=0)\nprint(Reviews.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Libraries\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport torch\n\n# Preliminaries\n\nfrom torchtext.data import Field, TabularDataset, BucketIterator, Iterator\n\n# Models\n\nimport torch.nn as nn\nfrom transformers import BertTokenizer, BertForSequenceClassification\n\n# Training\n\nimport torch.optim as optim\n\n# Evaluation\n\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nimport seaborn as sns\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torchtext.data import Field, Dataset, Example\nimport pandas as pd\n# https://stackoverflow.com/questions/52602071/dataframe-as-datasource-in-torchtext\nclass DataFrameDataset(Dataset):\n    def __init__(self, examples, fields, filter_pred=None):\n        self.examples = examples.apply(SeriesExample.fromSeries, args=(fields,), axis=1).tolist()\n        if filter_pred is not None:\n            self.examples = filter(filter_pred, self.examples)\n        self.fields = dict(fields)\n         # Unpack field tuples\n        for n, f in list(self.fields.items()):\n            if isinstance(n, tuple):\n                self.fields.update(zip(n, f))\n                del self.fields[n]\nclass SeriesExample(Example):\n\n    def fromSeries(cls, data, fields):\n        return cls.fromdict(data.to_dict(), fields)\n\n    def fromdict(cls, data, fields):\n        ex = cls()\n\n        for key, field in fields.items():\n            if key not in data:\n                raise ValueError(\"Specified key {} was not found in \"\n                 \"the input data\".format(key))\n            if field is not None:\n                setattr(ex, key, field.preprocess(data[key]))\n            else:\n                setattr(ex, key, data[key])\n        return ex","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\n# Model parameter\nMAX_SEQ_LEN = 128\nPAD_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\nUNK_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.unk_token)\n\n# Fields\n\nlabel_field = Field(sequential=False, use_vocab=False, batch_first=True, dtype=torch.float)\ntext_field = Field(use_vocab=False, tokenize=tokenizer.encode, lower=False, include_lengths=False, batch_first=True,\n                   fix_length=MAX_SEQ_LEN, pad_token=PAD_INDEX, unk_token=UNK_INDEX)\nfields = { 'sentiment' : LABEL, 'review' : TEXT }\n\ntrain, test =  train_test_split(Reviews)\n\ntrain = DataFrameDataset(train, fields)\ntest = DataFrameDataset(valid, fields)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_iter = BucketIterator(train, batch_size=16, sort_key=lambda x: len(x.text),\n                            device=device, train=True, sort=True, sort_within_batch=True)\nteste_iter = BucketIterator(test, batch_size=16, sort_key=lambda x: len(x.text),\n                            device=device, train=True, sort=True, sort_within_batch=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class BERT(nn.Module):\n\n    def __init__(self):\n        super(BERT, self).__init__()\n\n        options_name = \"bert-base-uncased\"\n        self.encoder = BertForSequenceClassification.from_pretrained(options_name)\n\n    def forward(self, text, label):\n        loss, text_fea = self.encoder(text, labels=label)[:2]\n\n        return loss, text_fea","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save and Load Functions\n\ndef save_checkpoint(save_path, model, valid_loss):\n\n    if save_path == None:\n        return\n    \n    state_dict = {'model_state_dict': model.state_dict(),\n                  'valid_loss': valid_loss}\n    \n    torch.save(state_dict, save_path)\n    print(f'Model saved to ==> {save_path}')\n\ndef load_checkpoint(load_path, model):\n    \n    if load_path==None:\n        return\n    \n    state_dict = torch.load(load_path, map_location=device)\n    print(f'Model loaded from <== {load_path}')\n    \n    model.load_state_dict(state_dict['model_state_dict'])\n    return state_dict['valid_loss']\n\n\ndef save_metrics(save_path, train_loss_list, valid_loss_list, global_steps_list):\n\n    if save_path == None:\n        return\n    \n    state_dict = {'train_loss_list': train_loss_list,\n                  'valid_loss_list': valid_loss_list,\n                  'global_steps_list': global_steps_list}\n    \n    torch.save(state_dict, save_path)\n    print(f'Model saved to ==> {save_path}')\n\n\ndef load_metrics(load_path):\n\n    if load_path==None:\n        return\n    \n    state_dict = torch.load(load_path, map_location=device)\n    print(f'Model loaded from <== {load_path}')\n    \n    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training Function\n\ndef train(model,\n          optimizer,\n          criterion = nn.BCELoss(),\n          train_loader = train_iter,\n          valid_loader = valid_iter,\n          num_epochs = 5,\n          eval_every = len(train_iter) // 2,\n          file_path = destination_folder,\n          best_valid_loss = float(\"Inf\")):\n    \n    # initialize running values\n    running_loss = 0.0\n    valid_running_loss = 0.0\n    global_step = 0\n    train_loss_list = []\n    valid_loss_list = []\n    global_steps_list = []\n\n    # training loop\n    model.train()\n    for epoch in range(num_epochs):\n        for (labels, title, text, titletext), _ in train_loader:\n            labels = labels.type(torch.LongTensor)           \n            labels = labels.to(device)\n            titletext = titletext.type(torch.LongTensor)  \n            titletext = titletext.to(device)\n            output = model(titletext, labels)\n            loss, _ = output\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            # update running values\n            running_loss += loss.item()\n            global_step += 1\n\n            # evaluation step\n            if global_step % eval_every == 0:\n                model.eval()\n                with torch.no_grad():                    \n\n                    # validation loop\n                    for (labels, title, text, titletext), _ in valid_loader:\n                        labels = labels.type(torch.LongTensor)           \n                        labels = labels.to(device)\n                        titletext = titletext.type(torch.LongTensor)  \n                        titletext = titletext.to(device)\n                        output = model(titletext, labels)\n                        loss, _ = output\n                        \n                        valid_running_loss += loss.item()\n\n                # evaluation\n                average_train_loss = running_loss / eval_every\n                average_valid_loss = valid_running_loss / len(valid_loader)\n                train_loss_list.append(average_train_loss)\n                valid_loss_list.append(average_valid_loss)\n                global_steps_list.append(global_step)\n\n                # resetting running values\n                running_loss = 0.0                \n                valid_running_loss = 0.0\n                model.train()\n\n                # print progress\n                print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\n                      .format(epoch+1, num_epochs, global_step, num_epochs*len(train_loader),\n                              average_train_loss, average_valid_loss))\n                \n                # checkpoint\n                if best_valid_loss > average_valid_loss:\n                    best_valid_loss = average_valid_loss\n                    save_checkpoint(file_path + '/' + 'model.pt', model, best_valid_loss)\n                    save_metrics(file_path + '/' + 'metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n    \n    save_metrics(file_path + '/' + 'metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n    print('Finished Training!')\n\nmodel = BERT().to(device)\noptimizer = optim.Adam(model.parameters(), lr=2e-5)\n\ntrain(model=model, optimizer=optimizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loss_list, valid_loss_list, global_steps_list = load_metrics(destination_folder + '/metrics.pt')\nplt.plot(global_steps_list, train_loss_list, label='Train')\nplt.plot(global_steps_list, valid_loss_list, label='Valid')\nplt.xlabel('Global Steps')\nplt.ylabel('Loss')\nplt.legend()\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluation Function\n\ndef evaluate(model, test_loader):\n    y_pred = []\n    y_true = []\n\n    model.eval()\n    with torch.no_grad():\n        for (labels, title, text, titletext), _ in test_loader:\n\n                labels = labels.type(torch.LongTensor)           \n                labels = labels.to(device)\n                titletext = titletext.type(torch.LongTensor)  \n                titletext = titletext.to(device)\n                output = model(titletext, labels)\n\n                _, output = output\n                y_pred.extend(torch.argmax(output, 1).tolist())\n                y_true.extend(labels.tolist())\n    \n    print('Classification Report:')\n    print(classification_report(y_true, y_pred, labels=[1,0], digits=4))\n    \n    cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n    ax= plt.subplot()\n    sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n\n    ax.set_title('Confusion Matrix')\n\n    ax.set_xlabel('Predicted Labels')\n    ax.set_ylabel('True Labels')\n\n    ax.xaxis.set_ticklabels(['FAKE', 'REAL'])\n    ax.yaxis.set_ticklabels(['FAKE', 'REAL'])\n    \nbest_model = BERT().to(device)\n\nload_checkpoint(destination_folder + '/model.pt', best_model)\n\nevaluate(best_model, test_iter)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}