{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport doctest\nfrom sklearn.metrics import accuracy_score\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_train=pd.read_csv(\"/kaggle/input/mnist-in-csv/mnist_train.csv\")\ndf_test=pd.read_csv(\"/kaggle/input/mnist-in-csv/mnist_test.csv\")\n#выбираем 2 цифры на любой вкус\nnum1=0\nnum2=1\nfilter1=df_train[\"label\"]==num1\nfilter2=df_train[\"label\"]==num2\nfilter3=df_test[\"label\"]==num1\nfilter4=df_test[\"label\"]==num2\ndata_train=df_train.where(filter1 | filter2)\ndata_test=df_train.where(filter3 | filter4)\ndata_train=data_train.dropna()\ndata_test=data_train.dropna()\nprint(data_train.shape)\ndata_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train1 = pd.get_dummies(data_train,columns=['label'],drop_first=True)\ndata_train1.rename(columns={data_train1.columns.tolist()[-1]: 'label'}, inplace=True)\n\ndata_test1 = pd.get_dummies(data_test,columns=['label'],drop_first=True)\ndata_test1.rename(columns={data_test1.columns.tolist()[-1]: 'label'}, inplace=True)\n\ndata_test1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data_train.shape)\n\ndata_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=data_train1.drop('label',axis=1)\nX_train = X_train /255\nY_train=data_train1['label']\n\nX_test=data_test1.drop('label',axis=1)\nX_test = X_test /255\nY_test=data_test1['label']\n\nX_train1=X_train.to_numpy()\nX_train1=np.resize(X_train,(len(X_train),28,28))\n\nX_test1=X_test.to_numpy()\nX_test1=np.resize(X_test,(len(X_test),28,28))\n\nY_test1=Y_test.to_numpy()\n\nimages=5\nfig, ax = plt.subplots(nrows=1, ncols=images)\nfor i in range(images):\n    ax[i].imshow(X_train1[i])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#переводим пиксели, которые закрашены хоть как-то, в закрашены полностью\nX_train1=X_train1.astype(bool).astype(int)\nX_test1=X_test1.astype(bool).astype(int)\nY_test1=Y_test1.astype(bool).astype(int)\n\nimages=6\nfig, ax = plt.subplots(nrows=1, ncols=images)\nfor i in range(images):\n    ax[i].imshow(X_train1[i])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class EMAlgorithm(object):\n    \n    def __init__(self, iterations=10):     \n        self.iterations = iterations   \n      \n    def ptxk(self, x,prob):\n        \"\"\"\n        Return the probability that the picture x shows a number k\n    \n        >>> EM = EMAlgorithm()\n        >>> EM.ptxk(np.array([[[0,1],[0,1]],[[1,0],[1,0]]]), np.array([[0.5, 0.5],[0.5, 0.5]]))\n        array([[[0.5, 0.5],\n                [0.5, 0.5]],\n        <BLANKLINE>\n               [[0.5, 0.5],\n                [0.5, 0.5]]])\n        >>> EM.ptxk(np.array([[[1,0],[1,0]],[[0,1],[0,1]]]), np.array([[0.25, 0.75],[0.75, 0.25]]))\n        array([[[0.25, 0.75],\n                [0.25, 0.75]],\n        <BLANKLINE>\n               [[0.75, 0.25],\n                [0.75, 0.25]]])\n        >>> EM.ptxk(np.array([[[0,0],[0,0]],[[0,0],[0,0]]]), np.array([[0, 1],[1, 0]]))\n        array([[[0., 0.],\n                [0., 0.]],\n        <BLANKLINE>\n               [[0., 0.],\n                [0., 0.]]])\n        \"\"\"\n        #Сумма pt(k|x) по всем X\n        summa = np.sum(prob,axis=0) \n        ptx_k = np.zeros((2, x.shape[1], x.shape[2]))\n    \n        #Сумма xi * pt(k|x)\n        for i in range(prob.shape[0]):\n            ptx_k[0] += x[i]*prob[i][0]\n            ptx_k[1] += x[i]*prob[i][1]\n    \n        #Сумма xi * pt(k|x) / Сумма pt(k|x)\n        ptx_k[0]=ptx_k[0]/summa[0]\n        ptx_k[1]=ptx_k[1]/summa[1]\n    \n        return ptx_k\n                     \n                     \n\n    def ptkx(self, ptxk, pk):\n        \"\"\"\n        Return the probability that the picture x belongs to the class k\n    \n        >>> EM = EMAlgorithm()\n        >>> EM.ptkx(np.array([[0.25, 0.75],[0.5, 0.5]]), np.array([0.45, 0.55]))\n        array([[0.21428571, 0.78571429],\n               [0.45      , 0.55      ]])\n        \"\"\"\n        summa = (ptxk[:,0]*pk[0] + ptxk[:,1]*pk[1])\n        #Сумма pt(x|0)\n        pt0x = (ptxk[:,0] * pk[0])/summa\n        #Сумма pt(x|1)\n        pt1x = (ptxk[:,1]*pk[1])/summa\n        return np.stack((pt0x, pt1x), axis=-1)\n\n    def ptk(self, aposterior_probs):\n        \"\"\"\n        Return average for each column\n    \n        >>> EM = EMAlgorithm()\n        >>> EM.ptk(np.array([[0,1],[0.5,0],[0.5,0],[1,1]]))\n        array([0.5, 0.5])\n        >>> EM.ptk(np.array([[0.,0.]]))\n        array([0., 0.])\n        \"\"\"\n        return aposterior_probs.mean(axis=0)\n    \n    def bern_distr(self, x, params):\n        \"\"\"\n        Return Bernoulli Distribution of x with parametres from params\n        \n        >>> EM = EMAlgorithm()\n        >>> EM.bern_distr(np.array([[0,0],[0,1]]), np.array([0.5, 1]))\n        array([[0.25, 0.  ],\n               [0.25, 0.  ]])\n        \"\"\"\n        \n        params = np.repeat(np.expand_dims(params, axis=0), repeats=x.shape[0], axis=0)\n        params = params.reshape((params.shape[0], params.shape[1], -1))\n        x = np.repeat(np.expand_dims(x, axis=1), repeats=2, axis=1)\n        x = x.reshape((x.shape[0], x.shape[1], -1))\n        return np.multiply(np.power(params, x).prod(axis=-1), np.power(1 - params, (1 - x)).prod(axis=-1))\n    \n    def p0(self ,n):\n        x = np.random.random((n, 1))\n        return np.concatenate((x, 1-x),axis=1)\n    \n    def fit(self, X_train, X_test, Y_test):\n        pkx = self.p0(X_train.shape[0])\n        for iteration in range(self.iterations):\n            print(\"ITER\",iteration + 1)\n            pk=self.ptk(pkx)\n            pxk = self.ptxk(X_train, pkx)\n            pkx = self.ptkx(self.bern_distr(X_train,pxk), pk)   \n            prediction = self.bern_distr(X_test, pxk).argmax(axis=1)\n            print(\"accuracy\", accuracy_score(prediction,Y_test)) \n            fig, (ax1,ax2) = plt.subplots(nrows=1, ncols=2)\n            ax1.imshow(pxk[0])\n            ax2.imshow(pxk[1])\n        \n        print(doctest.testmod())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EM = EMAlgorithm(iterations = 5)\nEM.fit(X_train1, X_test1, Y_test1)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}