{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import functools, operator, numpy as np, pandas as pd, os, sys\nfrom numpy import int64\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Dense, Activation, Dropout\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint\nfrom sklearn.metrics import accuracy_score, silhouette_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom statistics import mean \n    \nimport warnings; warnings.simplefilter('ignore')\n\ndef read_file_to_XY_dfs(file):\n    # arguments: file path including the name, ex: /users/xyz/docs/temp_text.tsv\n    # reads the file into a dataframe and renames the y column name to 'label_df'\n    # returns a dataframe with the labels and another dataframe with only the labels\n    df = pd.read_csv(file, header=None, sep=\"\\t\")\n    labels_df = df.loc[:, df.columns == 0]\n    labels_df.columns = ['label']\n    df = df.drop(0, axis=1)\n    return df, labels_df\n    \ndef data_preprocess(df, labels_df):\n    classes_num = len(set(list(labels_df['label'])))\n    labels_df = np.array(labels_df['label']-1, dtype=int64)\n    labels_df = np.eye(classes_num)[labels_df]\n    return df, labels_df\n\ndef corr1D(x1, x2):\n    # arguments: two numpy arrays\n    # calculates the full correlation between the arrays\n    # returns the full correlation(for each shift value) between the passed arguments\n    return np.correlate(x1, x2, 'full')\n\ndef corr2D(a, b):\n    m = len(a)\n    CC_complete = []\n    row = []\n    for w in np.arange(1, 2*len(a)):\n        k = w - m\n        if k >= 0:\n            row = []\n            for l in np.arange(m - k):\n                row.append(a[l+k]*b[l])\n        if k < 0:\n            row = []\n            for l in np.arange(m + k):\n                row.append(b[l-k]*a[l])\n        CC_complete.append(row)\n    CC_complete = functools.reduce(operator.iconcat, CC_complete, [])\n    return CC_complete\n\ndef cal_xx_df(df):\n    corr_list = []\n    for index_outer, i in df.iterrows():\n        temp = np.array(i.iloc[:-1])\n        corr_list.append(np.multiply(temp, temp))\n    corr_df = pd.DataFrame(corr_list)\n    \n    def roll_smooth(data):\n        return (data.rolling(window=normalizing_window, win_type='triang', min_periods=1, axis=0).mean())\n    corr_df = corr_df.apply(roll_smooth, axis=1)\n    \n    return corr_df\n\ndef cal_xxx_df(df):\n    corr_list = []\n    for index_outer, i in df.iterrows():\n        temp = np.array(i.iloc[:-1])\n        corr_list.append(np.multiply(np.multiply(temp, temp), temp))\n    corr_df = pd.DataFrame(corr_list)\n    \n    def roll_smooth(data):\n        return (data.rolling(window=normalizing_window, win_type='triang', min_periods=1, axis=0).mean())\n    corr_df = corr_df.apply(roll_smooth, axis=1)\n    \n    return corr_df\n\ndef calc_corr_df(df, corr_2d):\n    corr_list = []\n    for index_outer, i in df.iterrows():\n        if corr_2d == False:\n            corr_list.append(corr1D(np.array(i.iloc[:-1]), np.array(i.iloc[:-1])))\n        elif corr_2d == True:\n            corr_list.append(corr2D(np.array(i.iloc[:-1]), np.array(i.iloc[:-1])))\n    corr_df = pd.DataFrame(corr_list)\n    \n    def roll_smooth(data):\n        return (data.rolling(window=normalizing_window, win_type='triang', min_periods=1, axis=0).mean())\n    corr_df = corr_df.apply(roll_smooth, axis=1)\n    \n    return corr_df\n\ndef calc_corr_all_df(df, corr_2d):\n    corr_list = []\n    labels_list = []\n    for index_outer, i in df.iterrows():\n        for outer_outer, j in df.iterrows():\n            label_1 = int(i.iloc[-1:])\n            label_2 = int(j.iloc[-1:])\n            if label_1 == label_2 and outer_outer > index_outer:\n                if corr_2d == False:\n                    corr_list.append(corr1D(np.array(i.iloc[:-1]), np.array(j.iloc[:-1])))\n                elif corr_2d == True:\n                    corr_list.append(corr2D(np.array(i.iloc[:-1]), np.array(j.iloc[:-1])))\n                labels_list.append(str(100 + label_1) + str(100 + label_2))\n    corr_df = pd.DataFrame(corr_list)\n    labels_df = pd.DataFrame(labels_list)\n    def roll_smooth(data):\n        return (data.rolling(window=normalizing_window, win_type='triang', min_periods=1, axis=0).mean())\n    corr_df = corr_df.apply(roll_smooth, axis=1)\n    \n    return corr_df, labels_df\n\ndef data_split(df, labels_df, split_ratio):\n    msk = np.random.rand(len(df)) < split_ratio\n    x_train = df[msk]\n    x_test = df[~msk]\n    y_train = labels_df[msk]\n    y_test = labels_df[~msk]\n    \n    x_train = x_train.reset_index(drop=True)\n    x_test = x_test.reset_index(drop=True)\n    y_train = y_train.reset_index(drop=True)\n    y_test = y_test.reset_index(drop=True)\n\n    return x_train, y_train, x_test, y_test\n\ndef fit_knn(x_train, y_train, n_neighbors):\n    classifier = KNeighborsClassifier(n_neighbors=n_neighbors, metric='euclidean') #minkowski\n    classifier.fit(x_train, y_train)\n    return classifier\n    \ndef classifier_accuracy(classifier, x_test, y_test):\n    y_pred = classifier.predict(x_test)\n    return accuracy_score(y_test, y_pred)\n\nprint('data_set|corr1D accr|corr2D accr|raw accr')\nprint('------------------------------------------------------------------')\n\nnormalizing_window = 5\nn_neighbors = 1\nsplit_ratio = 0.75\nfolds = 1\n\ndata_dir = '/Users/jay/Downloads/UCRArchive_2018/'\ndata_set_list = os.listdir(data_dir)\n\nfrom scipy import stats\n\nfor data_name in ['ECG200']: #['Herring', SmoothSubspace', 'Worms', 'MiddlePhalanxTW', 'DistalPhalanxTW']\n    train_file = data_dir + data_name + '/' + data_name + '_TRAIN.tsv'\n    test_file = data_dir + data_name + '/' + data_name + '_TEST.tsv'\n    df_train, labels_df_train = read_file_to_XY_dfs(train_file)\n    df_test, labels_df_test = read_file_to_XY_dfs(test_file)\n\n    df = df_train.append(df_test)\n    df = df.reset_index(drop=True)\n    labels_df = labels_df_train.append(labels_df_test)\n    labels_df = labels_df.reset_index(drop=True)\n  \n    del df_train, df_test, labels_df_train, labels_df_test\n\n\n#     x_train, y_train = read_file_to_XY_dfs(train_file)\n#     x_test, y_test = read_file_to_XY_dfs(test_file)\n#         print(x_train.head(2))\n#         print(y_train.head(2))\n\n#         corr_1d_df = calc_corr_df(df, corr_2d = False)\n#         corr_2d_df = calc_corr_df(df, corr_2d = True)\n#     print(df.head(2))\n#     print(labels_df.head(2))\n    df['label']=labels_df\n#     print(df.head(2))\n    \n    new_corr_df, new_labels_df = calc_corr_all_df(df, corr_2d = False)\n    x_train, y_train, x_test, y_test = data_split(new_corr_df, new_labels_df, split_ratio)      \n    classifier = fit_knn(x_train, y_train, n_neighbors)\n    result_1d = round(classifier_accuracy(classifier, x_test, y_test), 3)\n\n    new_corr_df, new_labels_df = calc_corr_all_df(df, corr_2d = True)\n    x_train, y_train, x_test, y_test = data_split(new_corr_df, new_labels_df, split_ratio)      \n    classifier = fit_knn(x_train, y_train, n_neighbors)\n    result_2d = round(classifier_accuracy(classifier, x_test, y_test), 3)\n\n    df = df.drop('label', axis=1)\n    x_train, y_train, x_test, y_test = data_split(df, labels_df, split_ratio)      \n    classifier = fit_knn(x_train, y_train, n_neighbors)\n    result = round(classifier_accuracy(classifier, x_test, y_test), 3)\n    print(data_name, result_1d, result_2d, result)\n\n    \n \n'''\ndata_set|raw accr|corr1D accr|corr2D accr|corrXX accr|corrXXX accr\n------------------------------------------------------------------\nMiddlePhalanxTW  0.925  0.993  0.56\nHerring  0.854  0.999  0.462\nECG200 0.974 0.998 0.878\n\n'''","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":1}