{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/amazon-top-50-bestselling-books-2009-2019/bestsellers with categories.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.sort_values(['Year','Name']).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Check and drop duplicates"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Name'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['Name']=='StrengthsFinder 2.0']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop_duplicates('Name', keep='last', inplace=True)\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\n\ndf['User Rating'].hist(bins=50)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(2, 2, figsize=(16,10))\n\naxs[0,0].hist(df['Reviews'], bins=50)\naxs[0,1].hist(df['Price'], bins=50)\naxs[1,0].hist(df['Year'], bins=50)\naxs[1,1].hist(df['Genre'], bins=50)\n\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter('Reviews', 'User Rating', data=df, color='r')\nplt.scatter('Price', 'User Rating', data=df, color='b')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Fiction = df['Genre']=='Fiction'\nNon_Fiction = df['Genre']=='Non Fiction'\nplt.boxplot([df[Fiction]['User Rating'], df[Non_Fiction]['User Rating']])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"****Generate dummies"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_dummies=pd.get_dummies(df, drop_first=True, columns=['Year', 'Genre'])\ndf_dummies.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_dummies.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****More EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns \n\ncolumn_list = ['User Rating', 'Reviews', 'Price', 'Year_2010',\n       'Year_2011', 'Year_2012', 'Year_2013', 'Year_2014', 'Year_2015',\n       'Year_2016', 'Year_2017', 'Year_2018', 'Year_2019',\n       'Genre_Non Fiction']\n\ncorr_matrix = df_dummies[column_list].corr()\nplt.figure(figsize=(16,12))\nsns.heatmap(corr_matrix, annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The correlation do not seems to shows much notable relationship. "},{"metadata":{},"cell_type":"markdown","source":"# Model 1: Simple Linear Regression"},{"metadata":{},"cell_type":"markdown","source":"I'm choosing User Rating as the independent variable, eventhough the correlation is alsmot non-existent (-0.056). This is based on business intuition. Looking from the chart a good variables should be Year. But realisticly, do we really believe that there is an intrinsic relationship between user rating and the year the book got published?"},{"metadata":{"trusted":true},"cell_type":"code","source":"X0 = df['Reviews'].values.reshape(-1,1)\ny0 = df['User Rating'].values.reshape(-1,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nimport statsmodels.api as sm\nfrom scipy import stats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_lr(X, y):\n    \n    \"\"\"\n    Run linear regression on the data, calculate RMSE, R_squared and plot regression plot on test data\n    \n    Arg: \n    X: Dataframe of independent variables \n    y: Array of predicted variables\n    \n    Returns:\n    Int\n    Figure and ax objects\n    \n    Raise:\n    ValueError: If X is not array or dataframe or y is not array\n    \"\"\"\n    #Train and fit:\n    reg = LinearRegression()\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n    reg.fit(X_train, y_train)\n    y_pred = reg.predict(X_test)\n    y_pred_train = reg.predict(X_train)\n    \n    # Get regression score:\n    R_squared = reg.score(X_test, y_test)\n    RMSE = np.sqrt(mean_squared_error(y_test, y_pred))\n\n    print(str(RMSE) +','+str(R_squared) + ': RMSE, R_squared')\n    \n    #Plot\n    fig, axs = plt.subplots(1,2, figsize=(16,4))\n    \n    if X.shape[1] == 1: \n         axs[0].scatter(X_test, y_test)\n         axs[0].plot(X_test, y_pred, color='r')\n         axs[0].set(xlabel='X_test', ylabel = 'y_pred', title ='Regression line on test data')\n    \n         axs[1].scatter(X_train, y_train)\n         axs[1].plot(X_train, y_pred_train, color='r')\n         axs[1].set(xlabel='X_train', ylabel = 'y_pred_train', title ='Regression line on train data')\n    \n         plt.show()\n    \n        \n    else:\n        axs[0].scatter(X_test.iloc[:,0], y_test)\n        axs[0].scatter(X_test.iloc[:,0], y_pred, color='r')\n        axs[0].set(xlabel='X_test', ylabel = 'y_pred', title ='Predicted values on test data')\n    \n        axs[1].scatter(X_train.iloc[:,0], y_train)\n        axs[1].scatter(X_train.iloc[:,0], y_pred_train, color='r')\n        axs[1].set(xlabel='X_train', ylabel = 'y_pred_train', title ='Predicted values on train data')\n    \n        plt.show()\n     \n        \n    \n        \n\n    \nrun_lr(X0, y0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Remove outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(df['Reviews'], bins=100)\noutlier_limit = (df['Reviews'].mean() + 3*df['Reviews'].std())\nplt.axvline(x=outlier_limit, color='r')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_no_outlier = df_dummies[df_dummies['Reviews'] <= outlier_limit]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X1 = df_no_outlier['Reviews'].values.reshape(-1,1)\ny1 = df_no_outlier['User Rating'].values.reshape(-1,1)\nprint(len(X1), len(y1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"run_lr(X1, y1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"How about Price as independent variable:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X2 = df_no_outlier['Price'].values.reshape(-1,1)\ny2 = df_no_outlier['User Rating'].values.reshape(-1,1)\nprint(len(X2), len(y2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"run_lr(X2, y2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now fiction as independent:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X3 = df_no_outlier['Genre_Non Fiction'].values.reshape(-1,1)\ny3 = df_no_outlier['User Rating'].values.reshape(-1,1)\nrun_lr(X3, y3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model 2: Multiple Linear Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df_no_outlier['User Rating'].values.reshape(-1,1)\n\nfull_var_list = ['Year_2010',\n       'Year_2011', 'Year_2012', 'Year_2013', 'Year_2014', 'Year_2015',\n       'Year_2016', 'Year_2017', 'Year_2018', 'Year_2019',\n       'Genre_Non Fiction']\nmain_list = ['Reviews', 'Price']\n\nR2 = []\nrMSE = []\n\nfor var in full_var_list:\n    main_list.append(var)\n    X = df_no_outlier[main_list]\n    \n     #Train and fit:\n    reg = LinearRegression()\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n    reg.fit(X_train, y_train)\n    y_pred = reg.predict(X_test)\n    y_pred_train = reg.predict(X_train)\n    \n    # Get regression score:\n    R_squared = reg.score(X_test, y_test)\n    RMSE = np.sqrt(mean_squared_error(y_test, y_pred))\n    R2.append(R_squared)\n    rMSE.append(RMSE)\n    \n    print('Add ' + var + ' to the model')\n\n    #Plot\n    fig, axs = plt.subplots(1,2, figsize=(16,4))\n    \n    axs[0].scatter(X_test.iloc[:,0], y_test)\n    axs[0].scatter(X_test.iloc[:,0], y_pred, color='r')\n    axs[0].set(xlabel='X_test', ylabel = 'y_pred', title ='Predicted values on test data')\n    \n    axs[1].scatter(X_train.iloc[:,0], y_train)\n    axs[1].scatter(X_train.iloc[:,0], y_pred_train, color='r')\n    axs[1].set(xlabel='X_train', ylabel = 'y_pred_train', title ='Predicted values on train data')\n    \n    plt.show()    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,8))\nplt.plot(full_var_list, R2, color='r', label = 'R Squared')\nplt.plot(full_var_list, rMSE, color='b', label = 'RMSE')\nplt.legend()\nplt.title('Impact of adding variables to model', fontsize=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking at the chart above, let's just add all variables to this model then"},{"metadata":{},"cell_type":"markdown","source":"#  Model 3: All variables and Let's do some scaling"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Take a look at our data again: \n\nplt.figure(figsize=(16,4))\ndf_no_outlier.boxplot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_no_outlier.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df_no_outlier['User Rating']\nX=df_no_outlier.iloc[:, 3:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\n\nsteps=[('scaler', StandardScaler()), ('Ln', LinearRegression())]\n\npipeline = Pipeline(steps)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n\nln_scaled = pipeline.fit(X_train, y_train)\n\ny_pred = pipeline.predict(X_test)\n\nR_squared = ln_scaled.score(X_test, y_test)\nRMSE = np.sqrt(mean_squared_error(y_test, y_pred))\n\nprint(str(RMSE) +','+str(R_squared) + ': RMSE, R_squared')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,4))\nplt.scatter(X_test.iloc[:,0], y_pred, color='#ff6037', alpha= 0.8, label='Predicted')\nplt.scatter(X_test.iloc[:,0], y_test, marker='x', label='Actual')\nplt.title('Visual Regression result')\nplt.xlabel('Num of Reviews')\nplt.ylabel('User Rating')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****Model 4: Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.pipeline import Pipeline\nimport xgboost as xgb\n\na={'xgb_model__n_estimators':[50, 100, 200],'xgb_model__max_depth':[2,5]}\n\nsteps=[('scaler', StandardScaler()), ('xgb_model', xgb.XGBRegressor())]\n\npipeline = Pipeline(steps)\nrandomized_rmse = RandomizedSearchCV(estimator=pipeline, param_distributions=a, n_iter=5, scoring={'MSE':'neg_mean_squared_error', 'R_squared':'r2'}, refit='MSE', cv=10, verbose=1)\n\nrandomized_rmse.fit(X, y)\n\nprint(randomized_rmse.best_estimator_)\nprint(randomized_rmse.best_score_)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}