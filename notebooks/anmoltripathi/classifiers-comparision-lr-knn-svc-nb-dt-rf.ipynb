{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Wine Quality Classification "},{"metadata":{},"cell_type":"markdown","source":"#### by Logistic Regression, k-Nearest Neighbor, Support Vector Classifier, Naive Bayes, Decision Tree and Random Forest"},{"metadata":{},"cell_type":"markdown","source":"In this notebook, I will be implementing multiple classfication algorithms on a binary (or multiclass if required) classification problem. I created simple functions <br>for generating ROC curve for both binary or multiclass classification (using One-vs-Rest),\n<br>for visualising results in 2 dimensions via Principal Component Analysis,\n<br>for getting classification report,\n<br>for looking classification results row wise along with each class' prediction probabilty.<br><br>\nFeel free to use it as a template for any other classification problem. Do upvote :)"},{"metadata":{},"cell_type":"markdown","source":"## Importing Libraries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# For Data Visualisation\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib.colors import ListedColormap\n\n# For Data Manipulation\nimport numpy as np \nimport pandas as pd\nimport sklearn\nfrom itertools import cycle\n\n\n# For Data Preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# For Classification Results\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import plot_roc_curve\nfrom sklearn.preprocessing import label_binarize\nfrom scipy import interp\nfrom sklearn.exceptions import NotFittedError\n\n# Dimensionality Reduction\nfrom sklearn.decomposition import PCA\n\n# Importing Models\nfrom sklearn.linear_model import LogisticRegression #Logistic Regression\nfrom sklearn.neighbors import KNeighborsClassifier as KNN #K-Nearest Neighbors\nfrom sklearn.svm import SVC #Support Vector Classifier\nfrom sklearn.naive_bayes import GaussianNB #Naive Bayes\nfrom sklearn.tree import DecisionTreeClassifier #Decision Tree Classifier\nfrom sklearn.ensemble import RandomForestClassifier #Random Forest Classifier\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Reading Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Checking for Dataset skewness"},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = df[\"quality\"].value_counts().plot.bar(figsize=(7,5))\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.02, p.get_height() * 1.02))\n    \nprint(df[\"quality\"].value_counts(normalize=True)*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see the dataset is skewed (unbalanced). <br>\nOf whole dataset **~5% belong to class 4, 8 and 3 combined**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Checking for missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum() #No missing values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are no missing values. Pretty clean dataset!"},{"metadata":{},"cell_type":"markdown","source":"It is suggested to make the ```quality``` a binary variable. Let's say for ```quality``` >= 7 is good quality or ```is good``` = 1 and for ```quality``` < 7 is not of good quality or ```is good``` = 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"is good\"] = 0\ndf.loc[df[\"quality\"]>=7,\"is good\"] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = df[\"is good\"].value_counts().plot.bar(figsize=(7,5))\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x(), p.get_height() * 0.5), color=\"white\")\n    \nprint(df[\"is good\"].value_counts(normalize=True)*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploring Features "},{"metadata":{"trusted":true},"cell_type":"code","source":"features = df.columns[:-2]\noutput = df.columns[-1]\nprint(\"Features: \\n{}, \\n\\nLabels: \\n{}\".format(features.values,output))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Analysing Feature Distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"# sns.pairplot(df[features],palette='coolwarm')\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see there are many "},{"metadata":{"trusted":true},"cell_type":"code","source":"for f in features:\n    print('Feature:{}\\n Skew = {} \\n\\n'.format(f,df[f].skew()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Analysing Feature Correlation"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = df[features].corr()\nplt.figure(figsize=(16,16))\nsns.heatmap(corr, cbar = True,  square = True, annot=True, fmt= '.2f',annot_kws={'size': 15},\n           xticklabels= features, yticklabels= features, alpha = 0.7,   cmap= 'coolwarm')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for f in features:\n    df.boxplot(column=f, by=output)\n    plt.title(f)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Splitting"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df[features].values\ny = df[output].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30)\nprint('Training size: {}, Testing size: {}'.format(X_train.size,X_test.size))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Scaling"},{"metadata":{"trusted":true},"cell_type":"code","source":"sc_X = StandardScaler()\nX_train = sc_X.fit_transform(X_train)\nX_test = sc_X.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Functions for Analysing Results"},{"metadata":{},"cell_type":"markdown","source":"## Probability Output"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def get_probabilty_output(X_test, model_fitted, value_count=10):\n    def highlight_max(data, color='yellow'):\n        attr = 'background-color: {}'.format(color)\n        if data.ndim == 1:  # Series from .apply(axis=0) or axis=1\n            is_max = data == data.max()\n            return [attr if v else '' for v in is_max]\n        else:  # from .apply(axis=None)\n            is_max = data == data.max().max()\n            return pd.DataFrame(np.where(is_max, attr, ''), index=data.index, columns=data.columns)\n        \n    y_scores = model_fitted.predict_proba(X_test)\n    prob_df = pd.DataFrame(y_scores*100).head(value_count)\n    styled_df = prob_df.style.background_gradient(cmap='Reds')\n    styled_df = styled_df.highlight_max(axis=1, color='green')\n    return styled_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Classification Report"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def get_classification_report(y_test,predictions,average=\"macro\"):\n    #Confusion Matrix\n    cm = confusion_matrix(y_test, predictions)\n    sns.heatmap(cm, annot=True)\n    plt.title(\"Confusion Matrix\")\n    \n    acc = accuracy_score(y_test, predictions)\n    pre = precision_score(y_test, predictions, average=average)\n    rec = recall_score(y_test, predictions, average=average)\n    # Prediction Report\n    print(classification_report(y_test, predictions, digits=3))\n    print(\"Overall Accuracy:\", acc)\n    print(\"Overall Precision:\", pre)\n    print(\"Overall Recall:\", rec)\n    \n    return acc,pre,rec\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Classification ROC"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def get_classification_ROC(X,y,model,test_size,model_fitted=False,random_state=0):\n    \n    def check_fitted(clf): \n        return hasattr(clf, \"classes_\")\n    \n    if(len(np.unique(y)) == 2):\n        #Binary Classifier\n        if not check_fitted(model):\n            model = model.fit(X,y)\n        \n        plot_roc_curve(model, X, y)\n        y_score = model.predict_proba(X)[:, 1]\n        fpr, tpr, threshold = roc_curve(y, y_score)\n        auc = roc_auc_score(y, y_score)\n        return auc\n#         print(\"False Positive Rate: {} \\nTrue Positive Rate: {} \\nThreshold:{}\".format(fpr,tpr,threshold))\n    \n    else:\n        #Multiclass Classifier\n        y_bin = label_binarize(y, classes=np.unique(y))\n        n_classes = y_bin.shape[1]\n\n        # shuffle and split training and test sets\n        X_train, X_test, y_train, y_test = train_test_split(X, y_bin, test_size=test_size, random_state=random_state)\n\n        # Learn to predict each class against the other\n        classifier = OneVsRestClassifier(model)\n        model_fitted = classifier.fit(X_train, y_train)\n        try:\n            y_score = model_fitted.decision_function(X_test)\n        except:\n            y_score = model_fitted.predict_proba(X_test)\n\n\n\n        # Compute ROC curve and ROC area for each class\n        fpr = dict()\n        tpr = dict()\n        roc_auc = dict()\n        for i in range(n_classes):\n            fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n            roc_auc[i] = auc(fpr[i], tpr[i])\n\n\n        # Compute micro-average ROC curve and ROC area\n        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\n\n        plt.figure()\n        lw = 2\n        plt.plot(fpr[2], tpr[2], color='darkorange',\n                 lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n        plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n        plt.xlim([0.0, 1.0])\n        plt.ylim([0.0, 1.05])\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title('Receiver operating characteristic averaged')\n        plt.legend(loc=\"lower right\")\n        plt.show()\n\n\n\n        # First aggregate all false positive rates\n        all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\n        # Then interpolate all ROC curves at this points\n        mean_tpr = np.zeros_like(all_fpr)\n        for i in range(n_classes):\n            mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\n        # Finally average it and compute AUC\n        mean_tpr /= n_classes\n\n        fpr[\"macro\"] = all_fpr\n        tpr[\"macro\"] = mean_tpr\n        roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\n        # Plot all ROC curves\n        plt.figure(figsize=(10,10))\n        plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n                 label='micro-average ROC curve (area = {0:0.2f})'\n                       ''.format(roc_auc[\"micro\"]),\n                 color='deeppink', linestyle=':', linewidth=4)\n\n        plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n                 label='macro-average ROC curve (area = {0:0.2f})'\n                       ''.format(roc_auc[\"macro\"]),\n                 color='navy', linestyle=':', linewidth=4)\n\n        colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'red', 'blue', 'purple', 'green'])\n        for i, color in zip(range(n_classes), colors):\n            plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n                     label='ROC curve of class {0} (area = {1:0.2f})'\n                     ''.format(i, roc_auc[i]))\n\n        plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n        plt.xlim([0.0, 1.0])\n        plt.ylim([0.0, 1.05])\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title('multi-class ROC (One vs All)')\n        plt.legend(loc=\"lower right\")\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualisation Through PCA"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def visualisation_through_PCA(X_PCA, y, model_PCA, model_name=\"Classification Model\"):\n    X_set, y_set = X_PCA, y\n    X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                         np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n    plt.contourf(X1, X2, model_PCA.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n                 alpha = 0.75, cmap = ListedColormap(('red', 'green', 'blue', 'yellow', 'purple', 'grey')))\n    plt.xlim(X1.min(), X1.max())\n    plt.ylim(X2.min(), X2.max())\n    for i, j in enumerate(np.unique(y_set)):\n        plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                    c = ListedColormap(('red', 'green', 'blue', 'yellow', 'purple', 'grey'))(i), label = j)\n    plt.title(model_name)\n    plt.xlabel('Principal Component 1')\n    plt.ylabel('Principal Component 2')\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Generating Principal Components of the feature dataset "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"pca = PCA(n_components = 2)\nX_train_PCA_2 = pca.fit_transform(X_train)\nX_test_PCA_2 = pca.transform(X_test)\nexplained_variance = pca.explained_variance_ratio_\nprint(\"Variance Explained by each of the Principal Components: {:.{prec}f}% and {:.{prec}f}%, \\nTotal Variance Explained: {:.{prec}f}%\".format((explained_variance*100)[0],\n                                                                                                                                               (explained_variance*100)[1],\n                                                                                                                                                  explained_variance.sum()*100,prec=3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Although, we can see the explained variance is ~46% hence, it is **NOT** suggested to go for just 2 components. But since we need to visualise the the dataset and classification boundries, we will go for 2 components. "},{"metadata":{},"cell_type":"markdown","source":"# Classification Models"},{"metadata":{},"cell_type":"markdown","source":"Let's start defining classification models <br> Models which are implemented: <br>\n* Logitic Regression\n* k-Nearest Neighbors\n* Support Vector Classifier\n* Naive Bayes\n* Decision Tree\n* Random Forest"},{"metadata":{},"cell_type":"markdown","source":"# Logisitic Regression "},{"metadata":{},"cell_type":"markdown","source":"### Creating Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters_LR = {\n    \"solver\" : ('newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'),\n    \"penalty\" : ('l1', 'l2', 'elasticnet', 'none'),\n    \"C\" : [0.01, 0.1, 1, 10, 1000]\n    \n}\n\nmodel_LR = LogisticRegression()\nmodel_LR_with_best_params = GridSearchCV(model_LR, parameters_LR)\nmodel_LR_with_best_params.fit(X_train,y_train)\nmodel_LR_best_params = model_LR_with_best_params.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_LR_best_params","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predicting"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_LR = model_LR_with_best_params.predict(X_test)\nprint(\"Predictions:\",predictions_LR[:10])\nprint(\"Actual:\",y_test[:10])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Result"},{"metadata":{"trusted":true},"cell_type":"code","source":"get_probabilty_output(X_test=X_test, model_fitted=model_LR_with_best_params, value_count=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_LR,pre_LR,rec_LR = get_classification_report(y_test,predictions_LR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc_LR = get_classification_ROC(X_test,y_test,model_LR_with_best_params,test_size=0.3,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fitting model on Principal Component dataset"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# model_LR_PCA = LogisticRegression(random_state = 0)\n# model_LR_PCA.fit(X_train_PCA_2, y_train)\n# predictions_LR_PCA = model_LR_PCA.predict(X_test_PCA_2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualising through PCA"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# visualisation_through_PCA(X_train_PCA_2, y_train, model_LR_PCA, model_name=\"Logisitic Regression (Training Set)\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# visualisation_through_PCA(X_test_PCA_2, y_test, model_LR_PCA, model_name=\"Logisitic Regression (Test Set)\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# k-Nearest Neighbor Classifier"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Creating Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters_KNN = {\n    \"n_neighbors\" : [2,5,7,15],\n    \"weights\" : ('uniform','distance'),\n    \"algorithm\" : ('auto','ball_tree','kd_tree','brute'),\n    'p': [1,2,5]\n    \n    \n}\n\nmodel_KNN = KNN(n_jobs=-1)\nmodel_KNN_with_best_params = GridSearchCV(model_KNN, parameters_KNN)\nmodel_KNN_with_best_params.fit(X_train,y_train)\nmodel_KNN_best_params = model_KNN_with_best_params.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_KNN_best_params","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predicting "},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_KNN = model_KNN_with_best_params.predict(X_test)\nprint(\"Predictions:\",predictions_KNN[:10])\nprint(\"Actual:\",y_test[:10])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Result"},{"metadata":{"trusted":true},"cell_type":"code","source":"get_probabilty_output(X_test=X_test, model_fitted=model_KNN_with_best_params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_KNN,pre_KNN,rec_KNN = get_classification_report(y_test,predictions_KNN)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc_KNN = get_classification_ROC(X_test,y_test,model_KNN_with_best_params,test_size=0.3,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Fitting model on Principal Component dataset"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# model_KNN_PCA = KNN(5)\n# model_KNN_PCA.fit(X_train_PCA_2, y_train)\n# predictions_KNN_PCA = model_KNN_PCA.predict(X_test_PCA_2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualising through PCA"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# visualisation_through_PCA(X_train_PCA_2, y_train, model_KNN_PCA, model_name=\"k-Nearest Neighbors (Training Set)\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# visualisation_through_PCA(X_test_PCA_2, y_test, model_KNN_PCA, model_name=\"k-Nearest Neighbors (Test Set)\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Support Vector Classifier (SVC)"},{"metadata":{},"cell_type":"markdown","source":"### Creating Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters_SVC = {\n    \"C\": [0.1, 1, 10],\n    \"kernel\": ('linear','poly','rbf'),\n    \"degree\": [2,4] \n    \n}\n\nmodel_SVC = SVC(probability=True)\nmodel_SVC_with_best_params = GridSearchCV(model_SVC, parameters_SVC)\nmodel_SVC_with_best_params.fit(X_train,y_train)\nmodel_SVC_best_params = model_SVC_with_best_params.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_SVC_best_params","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predicting"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_SVC = model_SVC_with_best_params.predict(X_test)\nprint(\"Predictions:\",predictions_SVC[:10])\nprint(\"Actual:\",y_test[:10])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"get_probabilty_output(X_test=X_test, model_fitted=model_SVC_with_best_params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_SVC,pre_SVC,rec_SVC = get_classification_report(y_test,predictions_SVC)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc_SVC = get_classification_ROC(X_test,y_test,model_SVC_with_best_params,test_size=0.3,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Fitting model on Principal Component dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# model_SVC_PCA = model_SVC = SVC(kernel=kernel, random_state=random_state, probability=True)\n# model_SVC_PCA.fit(X_train_PCA_2, y_train)\n# predictions_SVC_PCA = model_SVC_PCA.predict(X_test_PCA_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Visualising through PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualisation_through_PCA(X_train_PCA_2, y_train, model_SVC_PCA, model_name=\"Support Vector Classifier (Training Set)\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualisation_through_PCA(X_test_PCA_2, y_test, model_SVC_PCA, model_name=\"Support Vector Classifier (Test Set)\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Naive Bayes Classifier"},{"metadata":{},"cell_type":"markdown","source":"### Creating Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_NB = GaussianNB()\nmodel_NB.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predicting"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_NB = model_NB.predict(X_test)\nprint(\"Predictions:\",predictions_NB[:10])\nprint(\"Actual:\",y_test[:10])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"get_probabilty_output(X_test=X_test, model_fitted=model_NB)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_NB,pre_NB,rec_NB = get_classification_report(y_test,predictions_NB)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc_NB = get_classification_ROC(X_test,y_test,model_NB,test_size=0.3,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Fitting model on Principal Component dataset"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# model_NB_PCA = GaussianNB()\n# model_NB_PCA.fit(X_train_PCA_2, y_train)\n# predictions_NB_PCA = model_NB_PCA.predict(X_test_PCA_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Visualising through PCA"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# visualisation_through_PCA(X_train_PCA_2, y_train, model_NB_PCA, model_name=\"Naive Bayes Classifier (Training Set)\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# visualisation_through_PCA(X_test_PCA_2, y_test, model_NB_PCA, model_name=\"Naive Bayes Classifier (Test Set)\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decision Tree Classifier "},{"metadata":{},"cell_type":"markdown","source":"### Creating Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters_DT = {\n    'criterion':('gini','entropy'),\n    'max_features': ('auto','sqrt','log2')\n}\n\n\nmodel_DT = DecisionTreeClassifier()\nmodel_DT_with_best_params = GridSearchCV(model_DT, parameters_DT)\nmodel_DT_with_best_params.fit(X_train,y_train)\nmodel_DT_best_params = model_DT_with_best_params.best_params_\nmodel_DT_with_best_params.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_DT_best_params","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predicting"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_DT = model_DT_with_best_params.predict(X_test)\nprint(\"Predictions:\",predictions_DT[:10])\nprint(\"Actual:\",y_test[:10])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"get_probabilty_output(X_test=X_test, model_fitted=model_DT_with_best_params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_DT,pre_DT,rec_DT = get_classification_report(y_test,predictions_DT)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc_DT = get_classification_ROC(X_test,y_test,model_DT_with_best_params,test_size=0.3,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Fitting model on Principal Component dataset"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# model_DT_PCA = DecisionTreeClassifier(criterion=\"entropy\", random_state=0)\n# model_DT_PCA.fit(X_train_PCA_2, y_train)\n# predictions_DT_PCA = model_DT_PCA.predict(X_test_PCA_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Visualisation through PCA"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# visualisation_through_PCA(X_train_PCA_2, y_train, model_DT_PCA, model_name=\"Decision Tree Classifier (Training Set)\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# visualisation_through_PCA(X_test_PCA_2, y_test, model_DT_PCA, model_name=\"Decision Tree Classifier (Test Set)\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest Classifier"},{"metadata":{},"cell_type":"markdown","source":"### Creating Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters_RF = {\n    'criterion':('gini','entropy'),\n    'max_features': ('auto','sqrt','log2'),\n    'n_estimators': [100,150,200,250,300]\n}\n\n\nmodel_RF = RandomForestClassifier(n_jobs=-1)\nmodel_RF_with_best_params = GridSearchCV(model_RF, parameters_RF)\nmodel_RF_with_best_params.fit(X_train,y_train)\nmodel_RF_best_params = model_RF_with_best_params.best_params_\nmodel_RF_with_best_params.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_RF_best_params","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predicting"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_RF = model_RF_with_best_params.predict(X_test)\nprint(\"Predictions:\",predictions_DT[:10])\nprint(\"Actual:\",y_test[:10])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"get_probabilty_output(X_test=X_test, model_fitted=model_RF_with_best_params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_RF,pre_RF,rec_RF = get_classification_report(y_test,predictions_RF)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc_RF = get_classification_ROC(X_test,y_test,model_RF_with_best_params,test_size=0.3,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fitting model on Principal Component dataset"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# model_RF_PCA = RandomForestClassifier(n_estimators = 10, criterion=\"entropy\", random_state=0)\n# model_RF_PCA.fit(X_train_PCA_2, y_train)\n# predictions_RF_PCA = model_RF_PCA.predict(X_test_PCA_2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualising PCA"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# visualisation_through_PCA(X_train_PCA_2, y_train, model_RF_PCA, model_name=\"Random Forest Classifier (Training Set)\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# visualisation_through_PCA(X_test_PCA_2, y_test, model_RF_PCA, model_name=\"Random Forest Classifier (Test Set)\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Final Results"},{"metadata":{},"cell_type":"markdown","source":"## Model Comparision"},{"metadata":{"trusted":true},"cell_type":"code","source":"result = pd.DataFrame(\n    [[\"LogisticRegression\",auc_LR,acc_LR,pre_LR,rec_LR],\n    [\"kNearestNeighbor\",auc_KNN,acc_KNN,pre_KNN,rec_KNN],\n    [\"SupportVectorClassifier\",auc_SVC,acc_SVC,pre_SVC,rec_SVC],\n    [\"NaiveBayes\",auc_NB,acc_NB,pre_NB,rec_NB],\n    [\"DecisionTree\",auc_DT,acc_DT,pre_DT,rec_DT],\n    [\"RandomForest\",auc_RF,acc_RF,pre_RF,rec_RF]],\n    columns=[\"Classifier\",\"AUC\",\"Accuracy\",\"Precision\",\"Recall\"]\n)\n\nresult","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,5))\nax = fig.add_axes([0,0,1,1])\nx = result.Classifier\ny = result.AUC\nsns.barplot(x=x, y=y)\nplt.title(\"AUC Score Comparision\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,5))\nax = fig.add_axes([0,0,1,1])\nx = result.Classifier\ny = result.Accuracy\nsns.barplot(x=x, y=y)\nplt.title(\"Accuracy Comparision\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,5))\nax = fig.add_axes([0,0,1,1])\nx = result.Classifier\ny = result.Precision\nsns.barplot(x=x, y=y)\nplt.title(\"Precision Comparision\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,5))\nax = fig.add_axes([0,0,1,1])\nx = result.Classifier\ny = result.Recall\nsns.barplot(x=x, y=y)\nplt.title(\"Recall Comparision\")\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}