{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport nltk\nfrom nltk.sentiment import vader\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nvader_model = SentimentIntensityAnalyzer()\nimport spacy\nfrom sklearn import metrics\nnlp = spacy.load('en')\n\nimport re\nfrom collections import Counter","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/mbti_1.csv\")\nposts = df['posts'].values.tolist()\ntypes = df['type'].values.tolist()\nprint(len(posts),len(types))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocess data:\n\n## Replace post separator ||| with semi-colon ;\ndf['posts'] = df['posts'].replace(to_replace = r'\\|\\|\\|', value = r';',regex=True)\n\n## Replace all http links with 'url'\npattern_url = r'http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+'\nsubs_url = r'url'\ndf['posts'] = df['posts'].replace(to_replace = pattern_url, value = subs_url, regex = True)\n\n## Remove Personality Type Words - to ensure the validity of the estimation for unseen instances\npers_types = ['INFP' ,'INFJ', 'INTP', 'INTJ', 'ENTP', 'ENFP', 'ISTP' ,'ISFP' ,'ENTJ', 'ISTJ','ENFJ', 'ISFJ' ,'ESTP', 'ESFP' ,'ESFJ' ,'ESTJ']\np = re.compile(\"(\" + \"|\".join(pers_types) + \")\")\ndf['posts'] = df['posts'].replace(to_replace = p, value = r'PTypeToken', regex = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.head())\nprint(df.tail())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_dict = {}\nfor i in range(len(posts)):\n    total_dict[i] = [types[i],posts[i]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Personality types and their frequencies:')\ntypes = df.groupby('type').count()\ntypes.sort_values(\"posts\", ascending=False, inplace=True)\nprint(types)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"types['posts'].plot(kind=\"bar\", title=\"Number of Users per Personality type\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Function that counts the number of parts of speech\ndef bag_of_words(group, type_label):\n    posts = [t for t in group.get_group(type_label)['posts']]\n    nlp = spacy.load('en_core_web_sm')\n    count_tags = Counter()\n    for posts_per_user in posts:\n        doc = nlp(str(posts_per_user))\n        count_tags.update(Counter([token.pos_ for token in doc]))\n    return count_tags","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function that plots parts of speech\ndef tags_pie_plot(count_tags):\n    bag_of_tags = list(count_tags.keys())\n    bag_of_tags_values = [count_tags.get(l) for l in bag_of_tags[:5]]\n    \n#     fig = figure()\n    fig = plt.pie(bag_of_tags_values, labels = bag_of_tags[:5], autopct = '%1.1f%%', startangle = 140)\n    \n    return fig","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"types_grouped = df.groupby('type')\nfor t in pers_types:\n    count_tags = bag_of_words(types_grouped, t)\n    tags_pie_plot(count_tags)\n    print(t)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def replace_nth_string(string, old, new, n):\n    num=0\n    start=-1\n    while num<n:\n        start=string.find(old, start+1)\n        if start == -1:return -1\n        num+=1\n    positioned_string = start\n    if n == -1:\n        return string\n    return string[:positioned_string]+new+string[positioned_string+len(old):]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Remove 'like' that is not a verb\ndef pos_sentence(message):\n    sen_array = nltk.word_tokenize(message)\n    tagged = nltk.pos_tag(sen_array)\n    i = 0\n    indx = []\n    for x,y in tagged:\n        if x == 'like':\n            i += 1\n            if y != 'VB':\n                indx.append(i)\n    new_msg = message\n    for i in indx:\n        new_msg = replace_nth_string(message, 'like', '', i)\n    return new_msg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import clear_output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pos_feature = []\nentity_feature =[]\nlen_posts = []\ni = 0\nfor posts_per_user in df['posts']:\n    clear_output(wait=True)\n    doc = nlp(posts_per_user)\n    count_tags = Counter([token.pos_ for token in doc])\n    count_labels = Counter([token.label_ for token in doc.ents])\n    pos_feature.append(count_tags)\n    entity_feature.append(count_labels)\n    len_posts.append({'length': len(posts_per_user)})\n    print(\"Current progress: \", i)\n    i+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_vader(textual_unit, \n              lemmatize=False, \n              parts_of_speech_to_consider=set(),\n              verbose=0):\n    \"\"\"\n    Run VADER on a sentence from spacy\n    \n    :param str textual unit: a textual unit, e.g., sentence, sentences (one string)\n    (by looping over doc.sents)\n    :param bool lemmatize: If True, provide lemmas to VADER instead of words\n    :param set parts_of_speech_to_consider:\n    -empty set -> all parts of speech are provided\n    -non-empty set: only these parts of speech are considered\n    :param int verbose: if set to 1, information is printed\n    about input and output\n    \n    :rtype: dict\n    :return: vader output dict\n    \"\"\"\n    doc = nlp(textual_unit)\n        \n    input_to_vader = []\n\n    for sent in doc.sents:\n        for token in sent:\n\n            to_add = token.text\n\n            if lemmatize:\n                to_add = token.lemma_\n\n                if to_add == '-PRON-': \n                    to_add = token.text\n\n            if parts_of_speech_to_consider:\n                if token.pos_ in parts_of_speech_to_consider:\n                    input_to_vader.append(to_add) \n            else:\n                input_to_vader.append(to_add)\n\n    scores = vader_model.polarity_scores(' '.join(input_to_vader))\n    \n    if verbose >= 1:\n        print()\n        print('INPUT SENTENCE', sent)\n        print('INPUT TO VADER', input_to_vader)\n        print('VADER OUTPUT', scores)\n\n    return scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def vader_output_to_label(vader_output):\n    \"\"\"\n    map vader output e.g.,\n    {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.4215}\n    to one of the following values:\n    a) positive float -> 'positive'\n    b) 0.0 -> 'neutral'\n    c) negative float -> 'negative'\n    \n    :param dict vader_output: output dict from vader\n    \n    :rtype: str\n    :return: 'negative' | 'neutral' | 'positive'\n    \"\"\"\n    compound = vader_output['compound']\n    negative = vader_output['neg']\n    positive = vader_output['pos']\n    neutral = vader_output['neu']\n    \n    minimum = 2\n    to_return = \"positive\"\n    if abs(compound-positive) < minimum:\n        minimum = compound-positive\n        to_return = 'positive'\n    if abs(compound-negative) < minimum:\n        minimum = compound-negative\n        to_return = 'negative'\n    if abs(compound-neutral) < minimum:\n        minimum = compound-neutral\n        to_return = 'neutral'\n    return to_return\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"messages = []\nall_vader_output = []\noriginal = {} #wait for mai to convert csv to readable dict\nall_id_vader = {}\nvader_dict = {'INFP': 0, 'INFJ': 0, 'INTP': 0, 'INTJ': 0, 'ENTP': 0, 'ENFP': 0,\\\n             'ISTP': 0, 'ISFP': 0, 'ENTJ': 0, 'ISFJ': 0, 'ESTP': 0, 'ESFP': 0,\\\n             'ESFJ': 0, 'ESFJ': 0, 'ESTJ': 0, 'ISTJ': 0, 'ENFJ': 0,} #add here all the keys/characters\n\nfor id_, val_arr in total_dict.items():\n    clear_output(wait=True)\n    message = val_arr[1]\n    new_msg = pos_sentence(message)\n    vader_output = run_vader(new_msg)\n    vader_label =  vader_output_to_label(vader_output)\n    #all_id_vader.append{id:vadel_label}\n    messages.append(message)\n    all_vader_output.append({'sen': vader_label})\n    \n    if vader_label == \"negative\":\n        vader_dict[val_arr[0]] -= 1\n    if vader_label == \"positive\":\n        vader_dict[val_arr[0]] += 1\n    #if neutral, do nothing\n    print(\"Current progress: \", id_)\n    \nfor character, score in vader_dict.items():\n    if score < 0:\n        print(character, \" has a mean negative sentiment.\")\n    if score == 0:\n        print(character, \" has a mean neutral sentiment.\")\n    if score > 0:\n        print(character, \" has a mean positive sentiment.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"types = df.groupby('type').count()\nposts = types[\"posts\"]\nfor i,j in vader_dict.items():\n    if j/posts[i] < 0.07:\n        print(i, ' neutral')\n    else:\n        print(i, 'positive')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i = 0\narr_neg = []\nfor j in all_vader_output:\n    if j['sen'] == 'negative':\n        arr_neg.append(i)\n    i+=1\n\nkey = list(total_dict.values())\n\ntypes_neg = []\nfor i in arr_neg:\n    types_neg.append(key[i][0])\n\ni = 0\narr_pos = []\nfor j in all_vader_output:\n    if j['sen'] == 'positive':\n        arr_pos.append(i)\n    i+=1\n\ntypes_pos = []\nfor i in arr_pos:\n    types_pos.append(key[i][0])\n\ni = 0\narr_neu = []\nfor j in all_vader_output:\n    if j['sen'] == 'neutral':\n        arr_neu.append(i)\n    i+=1\n\ntypes_neu = []\nfor i in arr_neu:\n    types_neu.append(key[i][0])\n\nprint('negative: ', Counter(types_neg))\nprint('positive: ', Counter(types_pos))\nprint('neutral: ', Counter(types_neu))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction import DictVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn import svm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Combine all features into a list of dicts of features\nfeatures = [dict(**a,**b,**c,**d) for a,b,c,d in zip(pos_feature,len_posts,all_vader_output,entity_feature)]\n# Extract labels\nlabels = df['type']\n# Vectorize features\nvec = DictVectorizer()\nnew_features = vec.fit_transform(features).toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_features.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_2d_space(X, y, label='Classes'):   \n    colors = ['#1F77B4', '#FF7F0E']\n    markers = ['o', 's']\n    for l, c, m in zip(np.unique(y), colors, markers):\n        plt.scatter(\n            X[y==l, 0],\n            X[y==l, 1],\n            c=c, label=l, marker=m\n        )\n    plt.title(label)\n    plt.legend(loc='upper right')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\n\npca = PCA(n_components=2)\nX = pca.fit_transform(new_features)\n\nplot_2d_space(X, labels, 'Imbalanced dataset (2 PCA components)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fix the imbalance of the dataset\nfrom imblearn.combine import SMOTETomek\n\nsmt = SMOTETomek(ratio='auto')\nX_smt, y_smt = smt.fit_sample(X, labels)\n\nplot_2d_space(X_smt, y_smt, 'SMOTE + Tomek links')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split data into training and test\nposts_train, posts_test, type_train, type_test = train_test_split(\n    X_smt,\n    y_smt, \n    test_size = 0.20, # we use 80% for training and 20% for development\n    random_state = 123\n    ) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lin_clf = svm.LinearSVC(dual=False)\nlin_clf.fit(posts_train,type_train)\npredicted_labels = lin_clf.predict(posts_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"report = metrics.classification_report(y_true=type_test,y_pred=predicted_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('balanced dataset: ')\nprint(report)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split data into training and test\nposts_train, posts_test, type_train, type_test = train_test_split(\n    new_features,\n    labels, \n    test_size = 0.20, # we use 80% for training and 20% for development\n    random_state = 123\n    ) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lin_clf = svm.LinearSVC(dual=False)\nlin_clf.fit(posts_train,type_train)\npredicted_labels = lin_clf.predict(posts_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"report = metrics.classification_report(y_true=type_test,y_pred=predicted_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('unbalanced dataset: ')\nprint(report)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}