{"cells":[{"metadata":{"_uuid":"4e781cfa-2dad-489c-8be8-4cfdcd0838e1","_cell_guid":"8dd8dbdd-6d26-47fa-97dd-ec1443023ca2","trusted":true},"cell_type":"code","source":"#Samuel A\n#This project is going to try to classify the paintings of Titian, Pablo Piccasso and Vincent van Gogh\n#Using transfer learning \n\nimport os\nimport time\nimport random\nfrom PIL import Image as PImage\nimport numpy as np # linear algebra\nfrom numpy import asarray\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import models, layers\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Dropout, BatchNormalization, Activation\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report, f1_score, recall_score, precision_score\nimport math\nimport gc\n\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"25664609-df03-48b7-a45c-2e4dc4e0b6f1","_cell_guid":"94a02113-a876-4845-8fc3-5c0b94c738ed","trusted":true},"cell_type":"code","source":"#Artists classes\na=['titian','picasso','gogh']\na_encoded = [0,1,2]\n\ntitian_images = []\ntitian_labels = []\n\npicasso_images = []\npicasso_labels = []\n\ngogh_images = []\ngogh_labels = []\n\ninput_shape = (200,200,3)\n\n#number of classes\nclasses = len(a_encoded)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6dc11538-0ef8-4e5c-b97e-577da4936cd8","_cell_guid":"9b4e4570-64c3-4abe-b688-e31fe38fbc2b","trusted":true},"cell_type":"code","source":"#Show image count\ndef show_image_count(t,p,v):\n    print('tit_ttl: ' + str(t))\n    print('picc_ttl: ' + str(p))\n    print('gogh_ttl: ' + str(v))\n    print('ttl: '+ str(t+p+v)+' images')\n    \n#Draw a picture   \ndef show_image(var):\n    plt.imshow(var)\n    plt.axis('Off')\n    plt.show()\n\n#Load images from path and convert to an array of pixels\ndef get_image(path,target_width,target_height):\n    #img = PImage.open(path)\n    img = load_img(path, target_size=(target_width,target_height))\n    pixels = img_to_array(img)\n    return pixels\n\n#Save image to an array\ndef load_images_from_path(dirname,file,array,labels,label,target_width,target_height):\n        path = os.path.join(dirname,file)\n        img = get_image(path, target_width,target_height)\n        array.append(img)\n        labels.append(label)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d2436ec2-db0b-467d-bcc4-0c63fc4069e3","_cell_guid":"cd3cdba3-3582-4010-81c2-b9a9ae8fc7c8","trusted":true},"cell_type":"code","source":"#Load entire data from the 3 mentioned artists\ndef load_data():\n    \n    t,p,v = 0,0,0\n    \n    for dirname, _, filenames in os.walk('/kaggle/input/best-artworks-of-all-time/images/images/'):\n        for filename in filenames:\n            \n            #path = os.path.join(dirname, filename)\n            nfolder = dirname.split(\"/\")\n            folder = nfolder[len(nfolder)-1]\n        \n            #Titian\n            if folder == 'Titian':\n                load_images_from_path(dirname,filename,titian_images,titian_labels,a_encoded[0],200,200)\n                t += 1\n        \n            #Pablo_Picasso\n            if folder == 'Pablo_Picasso':\n                load_images_from_path(dirname, filename, picasso_images, picasso_labels, a_encoded[1],200,200)\n                p+= 1\n        \n            #Vincent_van_Gogh \n            if folder == 'Vincent_van_Gogh':\n                load_images_from_path(dirname, filename, gogh_images, gogh_labels, a_encoded[2],200,200)\n                v+= 1\n        \n    show_image_count(t,p,v)\n    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3c897dc9-11bc-4b74-943d-cedead3dce15","_cell_guid":"69d12a61-7159-4dd4-b81e-736c843b3fec","trusted":true},"cell_type":"code","source":"#Plot a graph with data given\ndef plot_graph(train_loss_acc, val_loss_acc, title, y_label, x_label, legend):\n    plt.plot(train_loss_acc)\n    plt.plot(val_loss_acc)\n    plt.title(title)\n    plt.ylabel(y_label)\n    plt.xlabel(x_label)\n    plt.legend(legend, loc='upper left')\n    plt.show()\n\n#Show classification report\ndef show_classification_report(y_test, preds, names):\n    print('\\n')\n    print('***** Classification Report*****')\n    print(classification_report(y_test.argmax(axis=1), preds, target_names=names))\n    \n#Show confusion matrix\ndef show_confusion_matrix(y_test, preds):\n    print('\\n')\n    print('***** Confusion Matrix *****')\n    print(confusion_matrix(y_test.argmax(axis=1), preds))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"41a30bcf-7da7-43e9-8785-cb411dacd023","_cell_guid":"459816a7-7abb-4f80-8c64-251d60766b78","trusted":true},"cell_type":"code","source":"#Load all the data\nload_data()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b8d3a61c-396d-41f1-b2ae-29292226e977","_cell_guid":"9ebad0df-1594-46e9-8502-48f07779a099","trusted":true},"cell_type":"code","source":"#Select training_data\n\ntrain_titian_images = titian_images[20:200]\ntrain_titian_labels = titian_labels[20:200]\n\ntrain_picasso_images = picasso_images[20:200]\ntrain_picasso_labels = picasso_labels[20:200]\n\ntrain_gogh_images = gogh_images[20:200]\ntrain_gogh_labels = gogh_labels[20:200]\n\n#############################################################\n#Select validation data\n\nval_titian_images = titian_images[0:20]\nval_titian_labels = titian_labels[0:20]\n\nval_picasso_images = picasso_images[0:20]\nval_picasso_labels = picasso_labels[0:20]\n\nval_gogh_images = gogh_images[0:20]\nval_gogh_labels = gogh_labels[0:20]\n\n############################################################\n\n#Join all images and labels\nvalidation_images = val_titian_images + val_picasso_images + val_gogh_images\nvalidation_labels = val_titian_labels + val_picasso_labels + val_gogh_labels\n#####################################################################################\n\ntraining_images = train_titian_images + train_picasso_images + train_gogh_images\ntraining_labels = train_titian_labels + train_picasso_labels + train_gogh_labels\n\n#####################################################################################\n\n#Shuffle all the data\ntrain_data = list(zip(training_images, training_labels))\nrandom.shuffle(train_data)\ntraining_images, training_labels = zip(*train_data)\n\nval_data = list(zip(validation_images, validation_labels))\nrandom.shuffle(val_data)\nvalidation_images, validation_labels = zip(*val_data)\n\n#Convert arrays to numpy arrays\ntraining_images = asarray(training_images)\ntraining_labels = asarray(training_labels)\n\nvalidation_images = asarray(validation_images)\nvalidation_labels = asarray(validation_labels)\n\nprint('train data shape: ', training_images.shape)\nprint('train label shape: ', training_labels.shape)\nprint('val data shape: ', validation_images.shape)\nprint('val label shape: ', validation_labels.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"87f67a75-8ae5-4ed2-9394-a982b658c10d","_cell_guid":"581e408b-3a13-479d-b156-da9d8dc96516","trusted":true},"cell_type":"code","source":"#prepare testing data\ntest_titian_images = titian_images[200:]\ntest_titian_labels = titian_labels[200:]\n\ntest_picasso_images = picasso_images[200:255]\ntest_picasso_labels = picasso_labels[200:255]\n\ntest_gogh_images = gogh_images[200:255]\ntest_gogh_labels = gogh_labels[200:255]\n\ntest_images = test_titian_images + test_picasso_images + test_gogh_images\ntest_labels = test_titian_labels + test_picasso_labels + test_gogh_labels\n\ntest_data = list(zip(test_images, test_labels))\nrandom.shuffle(test_data)\ntest_images, test_labels = zip(*test_data)\n\ntest_images = asarray(test_images)\ntest_labels = asarray(test_labels)\n\nprint('test data shape: ', test_images.shape)\nprint('test label shape: ', test_labels.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"49aa77eb-348c-4ff5-a6ad-4f6443d0a43a","_cell_guid":"656279f2-9069-4ac6-9cf4-49a7c3c589e2","trusted":true},"cell_type":"code","source":"# Convert values to float\ntraining_images = training_images.astype('float32')\nvalidation_images = validation_images.astype('float32')\ntest_images = test_images.astype('float32')\n\n#One hot encode labels\ntraining_labels = to_categorical(training_labels)\nvalidation_labels = to_categorical(validation_labels)\ntest_labels = to_categorical(test_labels)\n\nprint(training_labels[0])\n\n#Normalize data\ntraining_images = training_images/255\nvalidation_images = validation_images/255\ntest_images = test_images/255\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#######################################################\npicasso_excess_images = picasso_images[255:]\npicasso_excess_labels = picasso_labels[255:]\n\ngogh_excess_images = gogh_images[255:]\ngogh_excess_labels = gogh_labels[255:]\n#--------------------------------------------------------\n\npicasso_excess_images = asarray(picasso_excess_images)\ngogh_excess_images = asarray(gogh_excess_images)\n\n#----------------------------------------------------------\n\npicasso_excess_images = picasso_excess_images.astype('float32')\ngogh_excess_images = gogh_excess_images.astype('float32')\n\n#--------------------------------------------------------\n\npicasso_excess_labels = to_categorical(picasso_excess_labels)\ngogh_excess_labels = to_categorical(gogh_excess_labels)\n\n#-----------------------------------------------------------\n\npicasso_excess_images = picasso_excess_images/255\ngogh_excess_images = gogh_excess_images/255\n\n#------------------------------------------------------------\n\n\n#something to play around with later\n#######################################################\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('train_data_shape: ', training_images.shape)\nprint('val_data_shape: ', validation_images.shape)\n\nprint('train_label_shape: ',training_labels.shape)\nprint('val_label_shape: ',validation_labels.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cf0d468a-b24b-443b-8e37-a138cb2d5aa9","_cell_guid":"47a0c635-4af1-44c5-9104-00a52a88dc31","trusted":true},"cell_type":"code","source":"#Augment the train data\ntrain_image_generator = ImageDataGenerator(\n    rotation_range = 30,\n    horizontal_flip = True,\n    width_shift_range = 0.2,\n    height_shift_range = 0.2,\n    shear_range = 0.2,\n    zoom_range = 0.2,\n    vertical_flip = True,\n    fill_mode = 'nearest'\n)\n\n#Augment the train data\nval_image_generator = ImageDataGenerator(\n    rotation_range = 30,\n    horizontal_flip = True,\n    width_shift_range = 0.2,\n    height_shift_range = 0.2,\n    shear_range = 0.2,\n    zoom_range = 0.2,\n    vertical_flip = True,\n    fill_mode = 'nearest'\n)\n\ntest_image_generator = ImageDataGenerator()\n\ntrain_generator = train_image_generator.flow(training_images, training_labels)\nval_generator = val_image_generator.flow(validation_images, validation_labels)\ntest_generator = test_image_generator.flow(test_images, test_labels)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f71add3d-ae04-4a2b-bced-73beb7388012","_cell_guid":"87b7be44-19d9-4a30-91cd-490b90c12c69","trusted":true},"cell_type":"code","source":"#Transfer learning using the InceptionResNetV2\n\nfrom tensorflow.keras.applications import InceptionResNetV2, Xception, MobileNetV2","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c22765a8-e1ed-4fa0-9bd6-e33c11d6c064","_cell_guid":"9bcdd952-01fc-4de4-a1c0-feb92d50d2e6","trusted":true},"cell_type":"code","source":"base = InceptionResNetV2(weights='imagenet', include_top = False, input_shape=input_shape)\nbase2 = MobileNetV2(weights='imagenet', include_top = False, input_shape=input_shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create callbacks for earlystopping and modelcheckpoint so we stop training at the right time and save the best model\n#after training.. we monitor the validation loss and stop training when it is at its minimum\n\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=1)\nmc = ModelCheckpoint('/kaggle/working/paintclf.h5', monitor='val_loss', mode='min', save_best_only=True)\ncallbacks = [es,mc]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a65819dd-e04c-4627-8df1-44c8e7479a55","_cell_guid":"5e2e9e3a-f19b-4b9d-95e1-050e1631e14a","trusted":true},"cell_type":"code","source":"#Summary of the InceptionResNetV2 model\n#base.summary()\n#Enable TPU\n# tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n# tf.config.experimental_connect_to_cluster(tpu)\n# tf.tpu.experimental.initialize_tpu_system(tpu)\n# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a979df65-7196-4527-93d7-ce8bcd7d34f8","_cell_guid":"55f2b973-a71b-4382-a4f4-ea22a357ff43","trusted":true},"cell_type":"code","source":"#hyper parameters\nepochs = 2000\nbatch_size=64\n\n#Disable training for inception, bc we want to train just our added layers\nbase.trainable = False\nbase2.trainable = False\n\n#Define our a new model with Inception as our convolutional base and start training\n# with tpu_strategy.scope():\ndef inceptionresnetV2_model():\n    model = models.Sequential()\n    model.add(base)\n    model.add(layers.Flatten())\n    model.add(layers.Dense(150, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)))\n    model.add(layers.Dense(classes, activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n    \n    return model\n    \ndef mobilenetv2_model():\n    model = models.Sequential()\n    model.add(base2)\n    model.add(layers.Flatten())\n    model.add(layers.Dense(10, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)))\n    model.add(layers.Dense(classes, activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n    \n    return model\n    \n\nstart = time.time()\nprint('Training started')\n\nmodel = mobilenetv2_model()\n\nhistory = model.fit_generator(train_generator,\n                              #steps_per_epoch=(math.ceil(training_images//batch_size)),\n                              validation_data=val_generator,\n                              #validation_steps = (math.ceil(validation_images//batch_size)),\n                              callbacks=callbacks,\n                              epochs=epochs, \n                              verbose=1)\n\nend = time.time() - start\nprint('Training done, ET: '+str(end)+'s')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"12c7c985-33b6-44de-bf1b-5e08ac639f27","_cell_guid":"8573b218-3e89-4c9b-9823-c6af92f50462","trusted":true},"cell_type":"code","source":"#Evaluate model and show accuracy\nn_eval = model.evaluate(test_images, \n                        test_labels, \n#                         steps=(len(test_images//batch_size)), \n                        verbose=0)\nprint(\"Model Accuracy: \", round((n_eval[1]*100),2))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e8033234-5003-423f-bce5-ccd921057dcd","_cell_guid":"f9413025-f8d4-48e8-8d53-a9b3927d3c6f","trusted":true},"cell_type":"code","source":"#Save our model\n# model2.save('/kaggle/working/incp'+str(n_eval[1])+'.h5')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3101c321-b71a-4989-b70a-4b0bf8c59d00","_cell_guid":"5af71315-8bcd-4b44-a907-4412a5e466f2","trusted":true},"cell_type":"code","source":"# Make predictions\ntest_generator.reset()\nsteps = (test_generator.n//test_generator.batch_size)\nn_preds = model.predict(test_images, verbose=0)\nn_preds = np.argmax(n_preds, axis=1)\n\ndecoded_one_hot_labels = np.argmax(test_labels, axis=1)\n\n\n# print(n_preds)\nf1 = f1_score(decoded_one_hot_labels, n_preds, labels=None, pos_label=1, average='weighted', sample_weight=None)\npr = precision_score(decoded_one_hot_labels, n_preds, labels=None, pos_label=1, average='weighted', sample_weight=None)\nrc = recall_score(decoded_one_hot_labels, n_preds, labels=None, pos_label=1, average='weighted', sample_weight=None)\n\nprint(\"Precision: \",round((pr *100),2))\nprint(\"Recall: \",round((rc*100),2))\nprint(\"F1-score: \",round((f1*100),2))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e0527dec-1aa9-483c-9c9e-2eb8e59da807","_cell_guid":"1dfafcbb-2349-43bd-88dd-b6dd665b63cd","trusted":true},"cell_type":"code","source":"#Show classification report\nshow_classification_report(test_labels,n_preds,a)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"414d1f53-2364-494e-9084-27df90946fa4","_cell_guid":"84f52aba-e11c-435d-b132-61a92ee08585","trusted":true},"cell_type":"code","source":"#Show confusion matrix\nshow_confusion_matrix(test_labels, n_preds)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e40b23ec-2a35-44c0-8a54-b6fa23db4ec6","_cell_guid":"d7c2c6e9-872e-4c19-abed-421fb473a7b4","trusted":true},"cell_type":"code","source":"#Plot graph of model loss and accuracy\nplot_graph(history.history['loss'], history.history['val_loss'], 'Model Loss', \"loss\", 'epochs', ['train','val'])\nplot_graph(history.history['accuracy'], history.history['val_accuracy'], 'Model Accuracy', \"accuracy\", 'epochs', ['train','val'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e4b7076f-b587-440e-a4a6-ce09dc0755fc","_cell_guid":"bc3337f4-6aa4-4d12-bfdb-fa4b519350a5","trusted":true},"cell_type":"code","source":"#make single prediction\ndef make_single_prediction(data,target_width,target_height,size,depth,model):\n    #Resahpe array to fit input shape of the cnn\n    input_tensor = data.reshape(size,target_width,target_height,depth)\n    pred = model.predict_proba(input_tensor)\n    print(\"Predicted: %s\" % (a[pred[0].argmax()]) + ' Confidence Level: %s' % round((pred[0].max() * 100), 2)+ '%')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7ad632ad-f22a-40d5-a0ce-ea3accf9e85f","_cell_guid":"6e252fcf-d17a-4cd2-a241-1fd13d4af5bc","trusted":true},"cell_type":"code","source":"#index of painting\nidd = 12\ndata = test_images[idd]\nlabel = test_labels[idd]\n\n#decode one hot encoding to get true label\nindex = np.argmax(label, axis=None, out=None)\nshow_image(data)\n\nprint('Painting by: '+ a[index])\nmake_single_prediction(data,200,200,1,3,model)\n#------------------------------------------------------\n\ndata2 = picasso_excess_images[idd]\nlabel2 = picasso_excess_labels[idd]\nindex2 = np.argmax(label2, axis=None, out=None)\nshow_image(data2)\n\nprint('Painting by: '+ a[index2])\nmake_single_prediction(data2,200,200,1,3,model)\n\n#---------------------------------------------------------\n\ndata3 = gogh_excess_images[idd]\nlabel3 = gogh_excess_labels[idd]\nindex3 = np.argmax(label3, axis=None, out=None)\nshow_image(data3)\n\nprint('Painting by: '+ a[index3])\nmake_single_prediction(data3,200,200,1,3,model)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}