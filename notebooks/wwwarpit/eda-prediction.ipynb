{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings(action='ignore')\npd.set_option('display.max_columns',None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nnRowsRead = 1000 # specify 'None' if want to read whole file\n# kc_house_data.csv has 21613 rows in reality, but we are only loading/previewing the first 1000 rows\ndf = pd.read_csv('/kaggle/input/housesalesprediction/kc_house_data.csv', delimiter=',', nrows = nRowsRead)\ndf.dataframeName = 'kc_house_data.csv'\nnRow, nCol = df.shape\nprint(f'There are {nRow} rows and {nCol} columns')","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#calculating types of dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#extracting date form datetime","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['date']=df['date'].str[0:8]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['date']","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#converting into datetime for furthur analysis","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['date']=pd.to_datetime(df['date'],format=\"%Y/%m/%d\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#AFTER CONVERSION AGAIN CHECK THE DATATYPES AGAIN","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#CHECKING FOR ANY SYMBOLS OR SPECIAL CHARACTERISTICS","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[~df.applymap(np.isreal).all(1)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(df,diag_kind='kde')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#INFERENCES FROM THE PAIRPLOT","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#price and #sqft living are almost linearly related\n#price and #sqft above are almost linearly related\n#sqft above and #sqft living are almost linearly related\n#sqft living and sqft_basement","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#CHECKING FOR OUTLIERS","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.plot.box(figsize=(20,10))\nplt.xticks(rotation=45)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in df.iloc[:,2:]:\n    df[i].plot.box()\n    plt.show()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#FROM ABOVE WE CAN SAY THAT WATERFALL AND VIEW ARE CATEGORICAL COLUMNS\n#BATHROOM HAS A VALUE OF 33 THAT CAN BE DROPPED WHICH IS A EXTREME OUTLIER\n#OTHER COLUMNS HAS OUTLIERS TOO","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking for skewness","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.skew()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sqft_lot,sqft_lot15 is highly right skewed data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#CHECKING FOR NULL VALUES","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# EXTRACTING YEAR FROM THE DATE COLUMN AND CREATING ANOTHER COLUMN CONTAINING ONLY YEAR ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['present']=df['date'].dt.year","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#CREATING A NEW COLUMN AGE TO CHECK THE HOW OLD THE HOUSE IS..FOR FURTHER ANALYSIS","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['age']=df['present']-df['yr_renovated']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in df['age'].index:\n    if df['age'][i]>500:\n        df['age'][i]=df['present'][i]-df['yr_built'][i]\n   ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,10))\nsns.heatmap(df.corr(),annot=True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#'grade' and 'sqrt' above are highly correlated to price but these are also related to other columns of the dataset\n#sqrt_living is highly correlated to price","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## STARTING BUILDING THE MODEL ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1=df.drop(['yr_built','yr_renovated','zipcode','lat','long','date','id'],axis=1)\ndf1.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=df1.drop('price',axis=1)\ny=df1['price']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nvif=pd.DataFrame()\nvif['columns']=X.columns\nvif['vif']=[variance_inflation_factor(X.values,i) for i in range(len(X.columns))]\nvif","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler,PowerTransformer\nfrom sklearn.linear_model import LinearRegression,Lasso,Ridge\nfrom sklearn.pipeline import Pipeline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xtrain,xtest,ytrain,ytest=train_test_split(X,y,train_size=0.75,random_state=1)\nss=StandardScaler()\nxtrains=ss.fit_transform(xtrain)\nxtests=ss.transform(xtest)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#present and grade are having maximum multicollinearity also,sqft_living,sqft_above,sqft_basement having multicollinearity\n#inf ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipe=Pipeline((\n    \n('lr',LinearRegression()),\n))\npipe.fit(xtrain,ytrain)\na=pipe.score(xtest,ytest)\na","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipe=Pipeline((\n('ss',StandardScaler()),\n('pt',PowerTransformer()),\n('lr',LinearRegression())\n))\npipe.fit(xtrain,ytrain)\npipe.score(xtest,ytest)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using PowerTransformer the score is getting worse","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#so via linear model highest score that we get is 0.64 \n#lets try to improve that score via various models","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Regularizing the data\npipe=Pipeline((\n('ss',StandardScaler()),\n('lasso',Lasso())\n))\npipe.fit(xtrain,ytrain)\nb=pipe.score(xtest,ytest)\nb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipe=Pipeline((\n('ss',StandardScaler()),\n('ridge',Ridge())\n))\npipe.fit(xtrain,ytrain)\nc=pipe.score(xtest,ytest)\nc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#regularization is not helping much\nfrom sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor,GradientBoostingRegressor","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipe=Pipeline((\n('ss',StandardScaler()),\n('svr',SVR())\n))\npipe.fit(xtrain,ytrain)\nd=pipe.score(xtest,ytest)\nd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipe=Pipeline((\n('ss',StandardScaler()),\n('pt',PowerTransformer()),\n('dtr',DecisionTreeRegressor())\n))\npipe.fit(xtrain,ytrain)\ne=pipe.score(xtest,ytest)\ne","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipe=Pipeline((\n('pt',PowerTransformer()),\n('rfr',RandomForestRegressor())\n))\npipe.fit(xtrain,ytrain)\nf=pipe.score(xtest,ytest)\nf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipe=Pipeline((\n('pt',PowerTransformer()),\n('adr',AdaBoostRegressor())\n))\npipe.fit(xtrain,ytrain)\ng=pipe.score(xtest,ytest)\ng","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipe=Pipeline((\n('pt',PowerTransformer()),\n('adr',GradientBoostingRegressor())\n))\npipe.fit(xtrain,ytrain)\nh=pipe.score(xtest,ytest)\nh","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l=[a,b,c,d,e,f,g,h]\nl1=['LinearRegression','Lasso','Ridge','SVR','DecisionTreeRegressor','RandomForestRegressor','AdaBoostRegressor','GradientBoostingRegressor']\nmodel=pd.DataFrame({'models':l1,'score':l})\nmodel","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\nmodel=model.sort_values(ascending=True,by='score')\nsns.barplot(model['models'],model['score'])\nplt.xticks(rotation=60)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from here we can say gradient boosting and random forest is performing better we cando hyparameter tuning in that","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score,GridSearchCV","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfr=RandomForestRegressor()\ngb=GradientBoostingRegressor()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cross=cross_val_score(rfr,X,y,scoring='r2',cv=10,n_jobs=-1)\ncross","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cross.mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cross=cross_val_score(gb,X,y,scoring='r2',cv=10,n_jobs=-1)\ncross","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cross.mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CV score of Random forest is much better so its hyperparameter tuning should be done","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfr=RandomForestRegressor(random_state=1)\nparam=[{'n_estimators':[20,50,100,500,800,1000],'max_depth':[2,4,5,7,8,10]}]\ngrid=GridSearchCV(estimator=rfr,param_grid=param,cv=8,n_jobs=-1)\ngrid.fit(xtrain,ytrain)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid.best_score_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#buildig model with best parameters","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xtrain,xtest,ytrain,ytest=train_test_split(X,y,train_size=0.75,random_state=1)\nrfr1=RandomForestRegressor(n_estimators=100,max_depth=10,random_state=1)\nrfr1.fit(xtrain,ytrain)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfr1.score(xtest,ytest)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#It is not improving score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Now doing feature selection","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X1=X.drop(['condition','present'],axis=1)\ny=df1['price']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xtrain1,xtest1,ytrain1,ytest1=train_test_split(X1,y,train_size=0.75,random_state=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfr=RandomForestRegressor(n_estimators=100,max_depth=10,random_state=1)\nrfr.fit(xtrain1,ytrain1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfr.score(xtest1,ytest1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dropping features is not improving score,so we will stick to initial features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipe=Pipeline((\n('pt',PowerTransformer()),\n('rfr',RandomForestRegressor())\n))\npipe.fit(xtrain,ytrain)\nypred=pipe.predict(xtest)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l=list(ypred)\nl1=list(ytest)\nnew_price=pd.DataFrame({'Actual_price':l1,'Predicted_price':l})\nnew_price.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}