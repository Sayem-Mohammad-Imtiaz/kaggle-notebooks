{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**•DOMAIN:** Digital content and entertainment industry<br/>\n**•CONTEXT:** The objective of this project is to build a text classification model that\nanalyses the customer's sentiments based on their reviews in the IMDB database. The\nmodel uses a complex deep learning model to build an embedding layer followed by\na classification algorithm to analyse the sentiment of the customers.<br/>\n**• DATA DESCRIPTION:** The Dataset of 50,000 movie reviews from IMDB, labelled by\nsentiment (positive/negative). Reviews have been preprocessed, and each review is\nencoded as a sequence of word indexes (integers). For convenience, the words are\nindexed by their frequency in the dataset, meaning the for that has index 1 is the\nmost frequent word. Use the first 20 words from each review to speed up training,\nusing a max vocabulary size of 10,000. As a convention, \"0\" does not stand for a\nspecific word, but instead is used to encode any unknown word.<br/>\n\n**• PROJECT OBJECTIVE:** Build a sequential NLP classifier which can use input text\nparameters to determine the customer sentiments.<br/>\n","metadata":{}},{"cell_type":"markdown","source":"**Importing necessary packages**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**STEP -1 import and analyze the data set**","metadata":{}},{"cell_type":"code","source":"#loading imdb data with most frequent 10000 words\n\nfrom keras.datasets import imdb\n(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Let's check dimentions of dataset**","metadata":{}},{"cell_type":"code","source":"X_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Function to perform relevant sequence adding on the data**","metadata":{}},{"cell_type":"code","source":"def vectorize(sequences, dimension = 10000):\n    results = np.zeros((len(sequences), dimension))\n    for i, sequence in enumerate(sequences):\n        results[i, sequence] = 1\n    return results\n \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#consolidating data for EDA\ndata = np.concatenate((X_train, X_test), axis=0)\nlabel = np.concatenate((y_train, y_test), axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Categories:\", np.unique(label))\nprint(\"Number of unique words:\", len(np.unique(np.hstack(data))))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"length = [len(i) for i in data]\nprint(\"Average Review length:\", np.mean(length))\nprint(\"Standard Deviation:\", round(np.std(length)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Let's look at a single training example:**","metadata":{}},{"cell_type":"code","source":"print(\"Label:\", label[0])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Let's decode the first review**","metadata":{}},{"cell_type":"code","source":"index = imdb.get_word_index()\nreverse_index = dict([(value, key) for (key, value) in index.items()]) \ndecoded = \" \".join( [reverse_index.get(i - 3, \"#\") for i in data[0]] )\nprint(decoded) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Adding sequence to data\ndata = vectorize(data)\nlabel = np.array(label).astype(\"float32\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Let's check distribution of data**","metadata":{}},{"cell_type":"code","source":"#To plot for EDA\nimport seaborn as sns\nsns.set(color_codes=True)\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labelDF=pd.DataFrame({'label':label})\nsns.countplot(x='label', data=labelDF)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For above analysis it is clear that data has equel distribution of sentiments.This will help us building a good model.","metadata":{}},{"cell_type":"markdown","source":"**Creating train and test data set**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(data,label, test_size=0.30, random_state=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Let's create  sequential model**","metadata":{}},{"cell_type":"code","source":"from keras.utils import to_categorical\nfrom keras import models\nfrom keras import layers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = models.Sequential()\n# Input - Layer\nmodel.add(layers.Dense(50, activation = \"relu\", input_shape=(10000, )))\n# Hidden - Layers\nmodel.add(layers.Dropout(0.3, noise_shape=None, seed=None))\nmodel.add(layers.Dense(50, activation = \"relu\"))\nmodel.add(layers.Dropout(0.2, noise_shape=None, seed=None))\nmodel.add(layers.Dense(50, activation = \"relu\"))\n# Output- Layer\nmodel.add(layers.Dense(1, activation = \"sigmoid\"))\nmodel.summary()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#For early stopping \nimport tensorflow as tf\ncallback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(\n optimizer = \"adam\",\n loss = \"binary_crossentropy\",\n metrics = [\"accuracy\"]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = model.fit(\n X_train, y_train,\n epochs= 100,\n batch_size = 40,\n validation_data = (X_test, y_test),\n callbacks=[callback]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Let's check mean accuracy of our model**","metadata":{}},{"cell_type":"code","source":"print(np.mean(results.history[\"val_accuracy\"]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's plot training history of our model\n\n# list all data in history\nprint(results.history.keys())\n# summarize history for accuracy\nplt.plot(results.history['accuracy'])\nplt.plot(results.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(results.history['loss'])\nplt.plot(results.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}