{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.offline as py\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os\nos.listdir(\"../input\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/GrammarandProductReviews.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since our prediction model will be beased on the text reviews, we will drop the rows having null value."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.dropna(subset = ['reviews.text'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# What are the words that people have used the most in their reviews?"},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS\nstopwords = set(STOPWORDS)\n\ndef show_wordcloud(data, title=None):\n    wordcloud = WordCloud(\n    background_color = 'black',\n    stopwords=stopwords,\n    max_words=200,\n    max_font_size=40,\n    scale=3,\n    random_state=1 #choose at random\n    ).generate(str(data))\n    \n    fig = plt.figure(1, figsize=(15,15))\n    plt.axis('off')\n    if title:\n        fig.suptitle(title, fontsize=20)\n        fig.subplots_adjust(top = 2.3)\n        \n    plt.imshow(wordcloud)\n    plt.show()\n    \nshow_wordcloud(data['reviews.text'])\n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# So, What is the maximum no. of ratings that people gave?"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['reviews.rating'].value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# NOW, lets have a look what do the length of the reviews tell about the ratings"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['reviews_length'] = data['reviews.text'].apply(len)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(font_scale = 2.0)\n\ng = sns.FacetGrid(data, col='reviews.rating', size=5)\ng.map(plt.hist, 'reviews_length')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# who all are giving fake reviews?"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['reviews.didPurchase'].fillna('Review N/A', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,8))\nax = sns.countplot(data['reviews.didPurchase'])\nax.set_xlabel(xlabel='Peoples Reviews', fontsize=17)\nax.set_ylabel(ylabel='No. of Reviews', fontsize=17)\nax.axes.set_title('Genuine No. of Reviews', fontsize=17)\nax.tick_params(labelsize=13)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Correlation matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(font_scale=1.4)\nplt.figure(figsize = (10,5))\nsns.heatmap(data.corr(), cmap='coolwarm', annot=True, linewidth=.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom scipy.sparse import hstack\nfrom sklearn.feature_extraction.text import TfidfVectorizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_text = data['reviews.text']\ntrain_text = data['reviews.text']\ny=data['reviews.rating']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# using the n-gram tfidf vectorizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"word_vectorizer = TfidfVectorizer(\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='word',\n    token_pattern=r'\\w{1,}',\n    stop_words='english',\n    ngram_range=(1,1),\n    max_features=10000)\nword_vectorizer.fit(all_text)\ntrain_word_features = word_vectorizer.transform(train_text)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"char_vectorizer = TfidfVectorizer(\n    sublinear_tf= True,\n    strip_accents='unicode',\n    analyzer='char',\n    stop_words='english',\n    ngram_range=(2,6),\n    max_features=50000)\nchar_vectorizer.fit(all_text)\ntrain_char_features = char_vectorizer.transform(train_text)\n\ntrain_features = hstack([train_char_features, train_word_features])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# feature training"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(\ntrain_features, y, test_size=0.3, random_state=101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n# if any categorical data has available, convert to numerical\nEncoder = LabelEncoder()\ny_train = Encoder.fit_transform(y_train)\ny_test = Encoder.fit_transform(y_test)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nclassifier = RandomForestClassifier()\nclassifier.fit(X_train, y_train)\nr_pred = classifier.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nrf_accuracy = accuracy_score(r_pred, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('random forest model accuracy is', rf_accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import LinearSVC","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LinearSVC()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s_pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svm_accuracy = accuracy_score(s_pred, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('svm accuracy is', svm_accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Deep Learning"},{"metadata":{},"cell_type":"markdown","source":"We will do one thing here, we will classify ratings<4 as sentiments, i.e. we will replace ratings less than 4 as not happy and vice-versa.\n\n1 for happy\n\n2 for unhappy\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['sentiment'] = data['reviews.rating']<4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_text, test_text, train_y, test_y = train_test_split(\n    data['reviews.text'], data['sentiment'], test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding, LSTM\nfrom keras.utils.np_utils import to_categorical\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import load_model \nfrom keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_NB_WORDS = 20000\n\n#get the text\ntexts_train = train_text.astype(str)\ntexts_test = test_text.astype(str)\n\n#vectorize sample into 2d int\ntokenizer = Tokenizer(nb_words = MAX_NB_WORDS,\n                     char_level=False)\ntokenizer.fit_on_texts(texts_train)\nsequences = tokenizer.texts_to_sequences(texts_train)\nsequences_test = tokenizer.texts_to_sequences(texts_test)\n\nword_index = tokenizer.word_index\nprint('Found %s unique tokens.' % len(word_index))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# to get equal size of all sentense"},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_SEQUENCE_LENGTH = 200\n#pad sequences are used to bring all sentences to same size\n#pad sequence with o's\nx_train = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\nx_test = pad_sequences(sequences_test, maxlen=\n                      MAX_SEQUENCE_LENGTH)\nprint('shape of data tensor:', x_train.shape)\nprint('shape of data test tensor:', x_test.shape)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Creation"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(MAX_NB_WORDS, 128))\nmodel.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2, input_shape =(1,)))\nmodel.add(Dense(1, activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x_train, train_y,batch_size=64, epochs = 20, validation_data=(x_test, test_y))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}