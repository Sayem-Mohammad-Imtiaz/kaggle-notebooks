{"cells":[{"metadata":{},"cell_type":"markdown","source":"**The data consists of 10,000 observations of space taken by the SDSS. Every observation is described by 17 feature columns and 1 class column which identifies it to be either a star, galaxy or quasar.\nTask to identify Star, Galaxy or Quasar.**","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importing Libraries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\n\n#from sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, recall_score","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/sloan-digital-sky-survey/Skyserver_SQL2_27_2018 6_51_39 PM.csv')\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Understanding Dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plotting the class column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df['class'].unique())\nsns.countplot(df['class'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['run'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['objid'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Understanding unique values if present in columns, which will help to reduce dimensionality in future processing.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in df.keys():\n    print(\"Colname:=\",i)\n    print(df[i].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finding the correaltion between attributes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Apparently we don't need 'rerun', 'objid' columns","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Here we create a dictionary which will map Class to numeric form and then replace it.\nStar will become 1 and so on.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dictionary={'STAR':1,'GALAXY':2,'QSO':3}\ndf.replace({'class':dictionary},inplace=True)\n\n# you can use LabelEncoder here also","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df['class']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dropping the columns which we donot need.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(['class','rerun'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Also dropping 'objid'","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop('objid',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using minmax scaling, we reduce the scale size to betwee 0 and 1. This helps the dataset to be more accuracte and removes high range anamolies. Apparently this must be used while dealing with large range of datasets.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\nsdss = scaler.fit_transform(df)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(sdss, y, test_size=0.2, random_state=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic Regression\nlr = LogisticRegression(C=2, max_iter=1500)\nlr.fit(X_train, y_train)\ny_pred = lr.predict(X_test)\n\nprint(\"Accuracy of Logistic Regression= \", accuracy_score(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)\nprint(\"Accuracy of KNeighborsClassifier = \", accuracy_score(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# RandomForestClassifier\nrf = RandomForestClassifier(max_depth=18, n_estimators=120)\nrf.fit(X_train, y_train)\ny_pred = rf.predict(X_test)\nprint(\"Accuracy of RandomForestClassifier = \", accuracy_score(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# XGBClassifier\nxgb= XGBClassifier()\nxgb.fit(X_train,y_train)\ny_pred =xgb.predict(X_test)\nprint(\"Accuracy of XGBClassifier = \", accuracy_score(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\n\nlgb=lgb.LGBMClassifier()\nlgb.fit(X_train,y_train)\ny_pred =lgb.predict(X_test)\nprint(\"Accuracy of lightgbm = \", accuracy_score(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# GradientBoostingClassifier\ngb = GradientBoostingClassifier()\ngb.fit(X_train,y_train)\ny_pred =gb.predict(X_test)\nprint(\"Accuracy of GradientBoostingClassifier = \", accuracy_score(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}