{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Using Random Forest with the Red Wine datase.Model evaluation with ROC curve."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df,hue=\"quality\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize =(10,10))\nsns.heatmap(df.corr(),annot=True,linewidths=0.2,cmap='plasma');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.quality.value_counts()\nprint(df.quality.value_counts().plot(kind='bar'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop(['quality'],axis=1)\ny = df.quality\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=38,stratify=y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_features = df.describe().columns[:-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define preprocessing for numeric columns (normalize them so they're on the same scale)\n \nnumeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n\n# Combine preprocessing steps\npreprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numeric_features)])\n        \n# Create preprocessing and training pipeline\npipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                           ('randomforest', RandomForestClassifier(max_depth=15,n_estimators=400))])\n\n\n# fit the pipeline to train a random forest classifier model on the training set\nrfc = pipeline.fit(X_train, (y_train))\n\npredictions = rfc.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test,predictions)\npd.crosstab(y_test, predictions, rownames = ['Actual'], colnames =['Predicted'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Comment: \n* unable to predict quality 3,4,8 due to high imbalance of the data and less data for training."},{"metadata":{},"cell_type":"markdown","source":"ref: https://www.wine-searcher.com/wine-scores\n\nScore\tExplanation\n\n95–100\tClassic: a great wine\n\n90–94\tOutstanding: a wine of superior character and style\n\n85–89\tVery good: a wine with special qualities 9-10\n\n80–84\tGood: a solid, well-made wine 6-8\n\n75–79\tMediocre: a drinkable wine that may have minor flaws 3-5\n\n50–74\tNot recommended  0-2\n\nUsing the guide above, here's the classification we will use for this dataset\n* Bad - 0-2\n* Mediocre - 3-5\n* Good - 6\n* Very Good - 7-8\n* Outstanding - 9-10"},{"metadata":{},"cell_type":"markdown","source":"### create 3 bins"},{"metadata":{"trusted":true},"cell_type":"code","source":"df2 = df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create 3 bins for mediocre,medium and good wine\n\nbins = [2,5,6,np.inf]\nlabels = [\"mediocre\", \"medium\", \"good\"]\ndf2['quality'] = pd.cut(df2['quality'],bins=bins, labels=labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.quality.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# label encode quality\nfrom sklearn.preprocessing import LabelEncoder\nlabel = LabelEncoder()\ndf2['quality'] = label.fit_transform(df2['quality'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label.classes_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df2.drop(['quality'],axis=1)\ny = df2.quality","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from itertools import cycle\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.metrics import roc_auc_score\n\n# Binarize the output\ny = label_binarize(y, classes=[0,1,2])\nn_classes = y.shape[1]\n\n# shuffle and split training and test sets\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=38,stratify=y)\n\n\n# Define preprocessing for numeric columns (normalize them so they're on the same scale)\n \nnumeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n\n# Combine preprocessing steps\npreprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numeric_features)])\n        \n# Create preprocessing and training pipeline\npipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                           ('randomforest', RandomForestClassifier())])\n\n\n# fit the pipeline to train a random forest classifier model on the training set\n\nrfc = pipeline.fit(X_train, (y_train))\n\npredictions =rfc.predict(X_test)\n\nprint(classification_report(y_test,predictions))\n\n# Compute ROC curve and ROC area for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], predictions[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Compute micro-average ROC curve and ROC area\n\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), predictions.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# First aggregate all false positive rates\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\n# Then interpolate all ROC curves at this points\nmean_tpr = np.zeros_like(all_fpr)\nfor i in range(n_classes):\n    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n\n# Finally average it and compute AUC\nmean_tpr /= n_classes\n\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\n# Plot all ROC curves\nplt.figure()\nplt.subplots(figsize=(15,10))\nplt.plot(fpr[\"micro\"], tpr[\"micro\"],\n         label='micro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"micro\"]),\n         color='deeppink', linestyle=':', linewidth=4)\n\nplt.plot(fpr[\"macro\"], tpr[\"macro\"],\n         label='macro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"macro\"]),\n         color='navy', linestyle=':', linewidth=4)\n\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue','green','blue','red'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n             label='ROC curve for  {0} wine quality (area = {1:0.2f})'\n             ''.format(label.classes_[i], roc_auc[i]))\n    \nplt.plot([0, 1], [0, 1], 'k--', lw=2)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Some extension of Receiver operating characteristic to multi-class')\nplt.legend(loc=\"lower right\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### create 2 bins"},{"metadata":{"trusted":true},"cell_type":"code","source":"df3 = df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create 2 bins for good and bad wine\n\nbins = [2, 6.5, 8]\nlabels = [\"bad\", \"good\"]\ndf3['quality'] = pd.cut(df3['quality'],bins=bins, labels=labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df3['quality'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# label encode quality\nlabel = LabelEncoder()\ndf3['quality'] = label.fit_transform(df3['quality'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label.classes_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df3.drop(['quality'],axis=1)\ny = df3.quality","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#shuffle and split training and test sets\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=38,stratify=y)\n\n\n# Define preprocessing for numeric columns (normalize them so they're on the same scale)\n \nnumeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n\n# Combine preprocessing steps\npreprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numeric_features)])\n        \n# Create preprocessing and training pipeline\npipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                           ('randomforest', RandomForestClassifier(max_depth=15))])\n\n\n# fit the pipeline to train a random forest classifier model on the training set\n\nrfc = pipeline.fit(X_train, (y_train))\n\npredictions =rfc.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test,predictions)\npd.crosstab(y_test, predictions, rownames = ['Actual'], colnames =['Predicted'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_auc_score(y_test, predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def draw_roc_curve(y_pred_prob):\n    fpr, tpr, thresholds = roc_curve(y_true=y_test, y_score=y_pred_prob)\n    plt.subplots(figsize=(15,10))\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.plot(fpr, tpr, label='Random Forest Classifier')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Random Forest Classifier ROC Curve')\n    plt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_prob = rfc.predict_proba(X_test)[:,1]\ndraw_roc_curve(y_pred_prob)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# set threshold to 0.35\n\nthreshold = 0.35\n\nfrom sklearn.preprocessing import binarize\n\ny_pred_prob = y_pred_prob.reshape(1,-1)\n\ny_pred_class = binarize(y_pred_prob,threshold=threshold)[0]\n\ny_pred_class = y_pred_class.astype('int')\n\nprint(confusion_matrix(y_test,y_pred_class))\n\nprint(classification_report(y_test,y_pred_class))\n\nprint(f'roc_auc_score : {roc_auc_score(y_test, y_pred_class)}')\n\ndraw_roc_curve(y_pred_class)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# set threshold to 0.15\n\nthreshold = 0.15\n\ny_pred_prob = y_pred_prob.reshape(1,-1)\n\ny_pred_class = binarize(y_pred_prob,threshold=threshold)[0]\n\ny_pred_class = y_pred_class.astype('int')\n\nprint(confusion_matrix(y_test,y_pred_class))\n\nprint(classification_report(y_test,y_pred_class))\n\nprint(f'roc_auc_score : {roc_auc_score(y_test, y_pred_class)}')\n\ndraw_roc_curve(y_pred_class)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Comment:\n\n* with 2 bins and lower threshold (i.e 0.15) , we have a good roc_auc_score : 0.85"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}