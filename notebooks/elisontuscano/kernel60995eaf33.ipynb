{"cells":[{"metadata":{},"cell_type":"markdown","source":"# <center>Game Review Rating Predictor</center>\nName: Elison Tuscano<br>\nUTA ID:1001738728\n\nFor Web demo : [click here](https://gamerating.herokuapp.com)\n\nFor Github Source Code : [click here](https://github.com/elisontuscano/Game-Review-Predictor)\n\nFor Video demo : [click here](https://youtu.be/DKhssm9wXPw)\n\nFor Blog : [click here](http://elisontuscano.uta.cloud/cv/Blog.html)"},{"metadata":{},"cell_type":"markdown","source":"## Contents:\n1. Approach\n    - [Click Here](#Approach)\n\n2. Data Visualization \n    - [Click Here](#Data-Visualization )\n\n3. Prepare Input Data\n    - [Click Here](#Input-Data:)\n    \n4. Classification techniques\n    - [Click Here](#Classification:)\n    \n  1. Naive Bayes\n  2. Random Forest\n  3. Ridge Classifier\n  4. Ensemble Voting Classifier\n  5. Trying Artificial neural network\n  \n\n5. Choosing the Best one:\n    - [Click Here](#Best-Classifier)\n    \n6. Finally Testing on Test Data\n    - [Click Here](#Final-Test)\n    \n6. Deployment Instruction\n    - [Click Here](#Deploy)\n    \n\nChallenges\n- [Click Here](#Challenges: )\n\n\nReferences\n- [Click Here](#References: )"},{"metadata":{},"cell_type":"markdown","source":"## Approach\n### Introduction\nText analysis is an important part of AI technology that uses Natural Language Processing to transform unstructured text into Normalized, Structured data suitable for Machine Learning algorithms. There are various methods to convert raw textual data into meaningfull information by performing mathematical computations inorder to transform text data into numerical data. The aim of this project is to handle large data and create a review rating classifier to predict the rating.The text data is first cleaned by removing special characters, removing stopwords \nand vectorizing it. The vectorized text is served as an input to the classification models. Different models are compared and best is applyed on the test Data.Finally a web user interface is create for the application and hosted on cloud inorder to access it from anywhere\n\n### Aim of this project\nThe purpose of this project is to predict a rating for a certain review provided for the user. The main challenge of this project is to handle large dataset and understand different classification model. After that create a Web user interface and host it to cloud.\n\n## Dataset Description\nThe Dataset was obtained from kaggle whose link is given in reference. The dataset is size 1Gb divided into 3 files. Out of those 3 files we will be using onlu the bgg-13m-review file as it content reviews and their rating which is required to create our model.The dataset has 13 million reviews but as some rows are empty we drop them are left with 2.6 million reviews. we will only be using :\n- comment\n- rating\n\n### Reading the Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport re\nimport os\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import metrics\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n#hide Warnings\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset=pd.read_csv('../input/boardgamegeek-reviews/bgg-13m-reviews.csv')\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Only the comment and rating columm will be used. Comment will be used to predict the rating of the user. Currently for the purpose of this application i will not use anything else hence i will remove other columns to reduce space and computation cost."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset=dataset.iloc[:,[2,3]]\ndataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The available dataset is 13 million but it contains few empty rows in the dataset as we can see above. We will drop the empty rows as it will just consfuse our classification model. Pandas comes with a build function called dropna which will detect all the 'NaN' i.e empty rows and delete them."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.dropna(subset=['comment'],inplace=True)\ndataset=dataset.sample(frac=1).reset_index(drop=True)\ndataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After removing the empty rows the dataset is reduced to 2.6 million containing reviews and their ratings. As we will be used review to predict the rating. X our independent input variable will be the comment column and Y will be the dependent output variable.<br>\nhence we store the comment and rating in X and Y respectively."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(dataset['rating'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above historgram shows the distribution of ratings. As we can see above the highest rows for rating consist of 7 and lowest is 1 . Majority of rating are from 6-10 .Hence we can say that the data available is unbalanced."},{"metadata":{"trusted":true},"cell_type":"code","source":"X=dataset['comment'].values\nY=dataset['rating'].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The ratings are floating numbers ranged from 1 to 10. So 8.5 and 8.6 will be counted as 2 different categories hence we round them up."},{"metadata":{"trusted":true},"cell_type":"code","source":"for index ,rate in enumerate(Y):\n    Y[index]=int(round(rate))\nY","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ideally the whole dataset would be divide into 75% training and 25 % testing.From the 75%training we further divide the data into 75% training and 25% development. Running different model and parameter testing on training and testing with devevelopment data optimal approach is selected and the final accuracy is removed on test data.\n\nNow as the dataset is huge which require a machine with good computation power what i will do i take 10% for training purpose and remaining shall be kept for testing. from the training data 75% would be training data and 25% would be development data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test, X_Sample1, Y_test, Y_Sample1 = train_test_split(X, Y, test_size = 0.1)\nX_train, X_dev, Y_train, Y_dev = train_test_split(X_Sample1, Y_Sample1, test_size = 0.25)\nX_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"X_train.shape tells us the size of the actual train data at our disposal which we will be using to create our classification models."},{"metadata":{},"cell_type":"markdown","source":"## Data Visualization \nlet's try to Visualize and try to find few insights if possible from the Dataset before applying any classification algorithm."},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"plt.hist(dataset['rating'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>There certainly is a change after rounding the ratings but the majority of the data still remains between 6-10 indicating the data is unbalanced.\n\nBelow are the Top 10 most frequently occurring words with their word count.</b>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import cufflinks as cf\ncf.go_offline()\ncf.set_config_file(offline=False, world_readable=True)\ndef get_top_n_words(corpus, n=None):\n    vec = CountVectorizer().fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]\ncommon_words = get_top_n_words(X_train, 10)\n#for word, freq in common_words:\n#    print(word, freq)\ndf1 = pd.DataFrame(common_words, columns = ['comment' , 'count'])\ndf1.groupby('comment').sum()['count'].sort_values(ascending=False).iplot(\n    kind='bar', yTitle='Count', linecolor='black', title='Top 10 words in review before removing stop words')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>As majority of the words are stopwards it is better to remove the stop words as they do not provide any additional information.</b>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_top_n_words(corpus, n=None):\n    vec = CountVectorizer(stop_words = 'english').fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]\ncommon_words = get_top_n_words(X_train, 10)\n#for word, freq in common_words:\n#    print(word, freq)\ndf2 = pd.DataFrame(common_words, columns = ['comment' , 'count'])\ndf2.groupby('comment').sum()['count'].sort_values(ascending=False).iplot(\n    kind='bar', yTitle='Count', linecolor='black', title='Top 10 words in review after removing stop words')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>The most occuring word in our dataset is 'game' after removing the stopwords which makes sense. other top 10 frequency words are( like , fun ,good) which implies that the data is inclined more towards positive ratings . The lack of negative words can be clearly seen through this bar graph</b>"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"def get_top_n_bigram(corpus, n=None):\n    vec = CountVectorizer(ngram_range=(2, 2), stop_words='english').fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]\ncommon_words = get_top_n_bigram(X_train, 10)\n#for word, freq in common_words:\n#    print(word, freq)\ndf4 = pd.DataFrame(common_words, columns = ['comment' , 'count'])\ndf4.groupby('comment').sum()['count'].sort_values(ascending=False).iplot(\n    kind='bar', yTitle='Count', linecolor='black', title='Top 10 bigrams in review after removing stop words')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Once Again the biagram is leaning towards the postive reviews ."},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_top_n_trigram(corpus, n=None):\n    vec = CountVectorizer(ngram_range=(3, 3), stop_words='english').fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]\ncommon_words = get_top_n_trigram(X_train, 10)\n#for word, freq in common_words:\n#    print(word, freq)\ndf6 = pd.DataFrame(common_words, columns = ['comment' , 'count'])\ndf6.groupby('comment').sum()['count'].sort_values(ascending=False).iplot(\n    kind='bar', yTitle='Count', linecolor='black', title='Top 10 trigrams in review after removing stop words')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Input Data:"},{"metadata":{},"cell_type":"markdown","source":"comment cannot be directly given to the classification model hence we need to follow some setup before giving as an input to our dataset\n\n- Removal of HTML tags: The data sometimes contains HTML tags inside the review   which need to be removed.\n- Removal of special Characters such as punctuation mark, hashtag,etc which does not help in predicting the senti- ment which should be removed from each review.\n- Tokenization :It is a method that divides the variety of document into small parts called tokens.\nEx: I like this game.\nAfter tokenization the sentence will be shown as ”I”,”like”,”this”,”game”.\n- Removal of Stop wards: Stop words are the commonly occurring words such as ”and”,”the”,etc. They occur in almost all of the document but does not help in predicting the sentiment as removing them creates an efficient model\n- Finally reviews are ready to be converted into bag of words to provide as an input to our classification model.\n\nA bag of word is representation of word with its frequency count in the document. Each word is represented with its occurrence in number of documents in the training data. This list will help us to calculate probability of that word occurring and probability of that word occurring in a particular sentiment. But traditional approach to use frequency count, also takes into consideration words that occur in majority of the document. As these words occur a lot only taking frequency count will give them a higher weight-age even thou these words are not a crucial part of the review. Hence we will use TF-IDF to create bag of words in our application which also take inverse document frequency into consideration to give weight-age to the word.\n\n<b>TF-idf (term frequency-inverse document frequency)</b>\nis a statistical measure that evaluates how relevant a word is to a document in a collection of documents. Two metrics are multiplied to achieve this: how many times a word appears in a document, and the inverse document frequency of the word across a set of documents. With this we take the first 10000 crucial words from the data into consideration and represent them in vectorized format to give as input to our classification model.Tfidf also has option to remove stopwards and other benefits like remove words than occur less than a certain threshold"},{"metadata":{"trusted":true},"cell_type":"code","source":"#set up tfidfvectorizor\ntfidf_vectorizor=TfidfVectorizer(stop_words='english', max_df=0.7,max_features=10000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fit and transform train and test set\ntfidf_train=tfidf_vectorizor.fit_transform(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we have our transformed comments saved in tfidf_train this will be used as an input for our classification model. Let's Transform the developement Data as well according to train data"},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf_dev=tfidf_vectorizor.transform(X_dev)\ntfidf_dev.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have our transformed Comment Vectorized and ready to be enter as input for the classification model. Let's start with Classification model."},{"metadata":{},"cell_type":"markdown","source":"## Classification:\n\nWe will create a few classification models and compare them together to decide the best algorithm for our problem.\n\n### Naive Bayes\n"},{"metadata":{},"cell_type":"markdown","source":"Naive Bayes is a probabilistic supervised machine learning algorithm. naive Bayes uses Bayes theorem to calculate probability (review / class1), probability (review / class2), and so on. All of these probabilities are compared. Review belongs to the Class with higher probability.\n\nlet's take a simple example with only 2 class positive and negative and understand how the algorithm works.<br>\nBayes Theorem:<br>\nP(a / b)=[P (b / a) * P (a)] / [P (b)]<br>\nExample:<br>\nP(positive/good)= [P (good / positive) * P (positive)] / [P (good)]<br>\nwhere,<br>\nP(good/positive) = Number positive documents containing the word ”good” / Number of all positive documents . <br>P(positive)=Number of all positive documents / Total Number of Documents<br>\nP(good) = number of documents containing ’good’ / number of all documents<br>\n\nFor every word in the review probability of that word with the sentiment shall be removed and multiplied together in order to get the actual answer.<br>\nP( a1,a2,a3,a4.. / b)<br>\nExample: ”It was a good movie”<br>\nAfter Cleaning and removing Stop-words:”It good movie”<br>\nProbability of the review for positive will be calculated: <br>P(positive/It)*P(positive/good/)*P(positive/movie)<br>\nSimilarly Probability of the review for negative will be calculated: <br>P(negative/It)*P(negative/good)*P(negative/movie)<br>\n\nBased on this probablity concept we need to predict the class labels ranging from 1 to 10."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting Naive Bayes to the Training set\nNaiveClassifier = MultinomialNB()\nNaiveClassifier.fit(tfidf_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting the Test set results\ny_pred = np.round(NaiveClassifier.predict(tfidf_dev))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The model is fitting and result is predicted on development data. Now we shall remove the accuracy by comparing actual label VS predicted label"},{"metadata":{"trusted":true},"cell_type":"code","source":"def accuracy_metric(actual, predicted):\n    correct = 0\n    for i in range(len(actual)):\n        if actual[i] == predicted[i]:\n            correct += 1\n    return correct / float(len(actual)) * 100.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nbscore=accuracy_score(Y_dev ,np.round(y_pred)) *100\nprint('Accuracy on development data : {} %'.format(nbscore))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As the accuracy of the model is found to be 30% which is not that bad considering there are 10 classes to predict and we have taken a small sample of available data\n\nBut Even if the actual rating is 8 and the algorithm predicted rating is 7 It is still considered wrong. To address this issue we can use range accuracy by keeping a buffer of 1. So when actual rating is 8 the predicted rating should in range between [6,7,8] to accepted as correct. Lets calculated accuracy with this approach."},{"metadata":{"trusted":true},"cell_type":"code","source":"def range_accuracy_metric(actual, predicted):\n    correct = 0\n    for i in range(len(actual)):\n        if actual[i] == predicted[i] or actual[i] == (predicted[i]+1) or actual[i] == (predicted[i]-1) :\n            correct += 1\n    return correct / float(len(actual)) * 100.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"range_nbscore=range_accuracy_metric(Y_dev, np.round(y_pred))\nprint('Range Accuracy on development data : {} %'.format(range_nbscore))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Only accuracy is can be deceiving hence we see the whole classification report with presion ,recall ,f1-score and support to see the performance of the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(metrics.classification_report(Y_dev,np.round(y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest\n\nComparison with Random Forest: Random forest is a supervised learning algorithm used for classification. Random forest is an ensemble learning method for classi- fication, regression and other task by constructing multiple decision tree. As it constructs multiple decision tree it provides more chances of error elimination."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nRFClassifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy')\nRFClassifier.fit(tfidf_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting the Test set results\ny_pred = np.round(RFClassifier.predict(tfidf_dev))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfscore=accuracy_score(Y_dev ,np.round(y_pred)) *100\nprint('Accuracy on development data : {} %'.format(rfscore))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"range_rfscore=range_accuracy_metric(Y_dev, np.round(y_pred))\nprint('Range Accuracy on development data : {} %'.format(range_rfscore))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(metrics.classification_report(Y_dev,np.round(y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ridge Classifier\nRidge classifier is a classification algorithm that uses ridge regression to classify multi-nomial values. For multi-class classification, n_class classifiers are trained in a one-versus-all approach\n\nLet's try one more algorithm and then try ensemble method to combine these algorithm with ensemble voting classifier. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import RidgeClassifier\nRidgeclassifier=RidgeClassifier()\nRidgeclassifier.fit(tfidf_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Predicting the Test set results\ny_pred = np.round(Ridgeclassifier.predict(tfidf_dev))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ridge_score=accuracy_score(Y_dev ,np.round(y_pred)) *100\nprint('Accuracy on development data : {} %'.format(ridge_score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"range_ridge_score=range_accuracy_metric(Y_dev, np.round(y_pred))\nprint('Range Accuracy on development data : {} %'.format(range_ridge_score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(metrics.classification_report(Y_dev,np.round(y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ensemble method- Voting Classifier\n\nVoting is one of the simplest ways of combining the predictions from multiple machine learning algorithms.\n\nIt works by first creating two or more standalone models from your training dataset. A Voting Classifier can then be used to wrap your models and average the predictions of the sub-models when asked to make predictions for new data."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\nestimators = []\nestimators.append(('naive', NaiveClassifier))\nestimators.append(('random', RFClassifier))\nestimators.append(('ridge', Ridgeclassifier))\n# create the ensemble model\nensemble = VotingClassifier(estimators)\nensemble.fit(tfidf_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = np.round(ensemble.predict(tfidf_dev))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ebscore=accuracy_score(Y_dev ,np.round(y_pred)) *100\nprint('Accuracy on development data : {} %'.format(ebscore))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"range_ebscore=range_accuracy_metric(Y_dev, np.round(y_pred))\nprint('Range Accuracy on development data : {} %'.format(range_ebscore))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(metrics.classification_report(Y_dev,np.round(y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Artificial Neural Network\n\nANN is a part of deep learning where each node is represented as a neuron. It has an input layer, hidden layer and output layer. Each input will be represented by a neuron in the input layer. We have 10000 words vector which will be provided to our 10000 input neurons. The output required is to classify the rating from 1- 10 hence we use sparse_categorical_entropy.\n\nIt has total of 2.5 million params. Activation function used is ”relu” for our hidden layers and activation function used for output layer is ”softmax ” as we want the answer to be categorized. Adam a type of stochastic gradient descent is used as the optimizer. The neural network was created using tensor- flow and keras. \n\nAs neural network is computationaly expensive they below code was runned only once on a small sample. Even with small data it managed to get accuracy closed to 50%. They code is working and kept in mardown file so wont be used further for our comaprison "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing the Keras libraries and packages\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n# Initialising the ANN\nclassifier = Sequential()\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(output_dim = 256, init = 'uniform', activation = 'relu', input_dim = 10000))\n# Adding the second hidden layer\nclassifier.add(Dense(output_dim = 64, init = 'uniform', activation = 'relu'))\n# Adding the output layer\nclassifier.add(Dense(output_dim = 11, init = 'uniform', activation = 'softmax'))\n\nclassifier.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"```python\n# Compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n# Fitting the ANN to the Training set\nclassifier.fit(tfidf_train, Y_train, batch_size = 10, nb_epoch = 5,validation_data=(tfidf_dev,Y_dev))\n```"},{"metadata":{},"cell_type":"markdown","source":"\n\n    Train on 197832 samples, validate on 65944 samples\n    Epoch 1/5\n    197832/197832 [==============================] - 397s 2ms/step - loss: 1.7407 - accuracy: 0.3109 - val_loss: 1.7073 - val_accuracy: 0.3221\n    Epoch 2/5\n    197832/197832 [==============================] - 405s 2ms/step - loss: 1.6444 - accuracy: 0.3454 - val_loss: 1.7066 - val_accuracy: 0.3239\n    Epoch 3/5\n    197832/197832 [==============================] - 412s 2ms/step - loss: 1.5061 - accuracy: 0.4081 - val_loss: 1.7890 - val_accuracy: 0.3102\n    Epoch 4/5\n    197832/197832 [==============================] - 420s 2ms/step - loss: 1.2689 - accuracy: 0.5124 - val_loss: 2.0374 - val_accuracy: 0.2928\n    Epoch 5/5\n    197832/197832 [==============================] - 419s 2ms/step - loss: 1.0152 - accuracy: 0.6188 - val_loss: 2.5407 - val_accuracy: 0.2789\n\n\n    <keras.callbacks.callbacks.History at 0x1a4600d4d0>"},{"metadata":{},"cell_type":"markdown","source":"### Best Classifier\n\nOnce we have accuracies and range accuracies of all the classifiers we can compare them to see which fits best with our data. Let's visualize them in a bar plot to get a better understanding."},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = ['Naive', 'RandomForest', 'Ridge', 'Ensemble']\nacc=np.round([nbscore,rfscore,ridge_score,ebscore])\nrangeacc= np.round([range_nbscore,range_rfscore,range_ridge_score,range_ebscore])\n\nx = np.arange(len(labels))\nwidth = 0.35 \n\nfig, ax = plt.subplots()\nrects1 = ax.bar(x - width/2, acc, width, label='accuracy')\nrects2 = ax.bar(x + width/2, rangeacc, width, label='Range Accuracy')\n\nax.set_title('Bar Graph for accuracy and range accuracy')\nax.set_xlabel('Classifiers')\nax.set_ylabel('Accuracy')\nax.set_xticks(x)\nax.set_xticklabels(labels)\nax.legend()\n\ndef autolabel(rects):\n    for rect in rects:\n        height = rect.get_height()\n        ax.annotate('{}'.format(height),\n                    xy=(rect.get_x() + rect.get_width() / 2, height),\n                    xytext=(0, 3), \n                    textcoords=\"offset points\",\n                    ha='center', va='bottom')\n\n\nautolabel(rects1)\nautolabel(rects2)\n\nfig.tight_layout()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see above that Ridge Classifier gives us the best accuracy so far hence we will be using Ridge Classifier on our test Data. We will remove the Final Accuracy of the test data using our Ridge Classifier model."},{"metadata":{},"cell_type":"markdown","source":"## Saving the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.externals import joblib\njoblib.dump(Ridgeclassifier,'model/ridge_model.sav')\njoblib.dump(tfidf_vectorizor,'model/tfidf_model.sav')\njoblib.dump(NaiveClassifier,'model/naive_model.sav')\njoblib.dump(RFClassifier,'model/randomforest_model.sav')\njoblib.dump(ensemble,'model/ensemble_model.sav')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Final Test"},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf_test=tfidf_vectorizor.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = np.round(Ridgeclassifier.predict(tfidf_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score=accuracy_score(Y_test ,np.round(y_pred)) *100\nprint('Accuracy on development data : {} %'.format(score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rangescore=range_accuracy_metric(Y_test, np.round(y_pred))\nprint('Range Accuracy on development data : {} %'.format(rangescore))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is the Final accuracy of our model. Let's see how we can used our saved model and make a Friendly Web user interface which we can deploy to cloud"},{"metadata":{},"cell_type":"markdown","source":"# Deploy"},{"metadata":{},"cell_type":"markdown","source":"Now to use our application during production we need a User Interface. We will make this with help of flask. Flask is a python library used to create local server can connect it to Web interface.\n\nThere is a link in reference that explains flask in detail. our aim is to provide a text area for the user to type the review. we send that input to our classifier and predict the rating. Flask code is my github repository in app.py file\n\nOn running the app.py file Flask creates a local server and renders the index.html file in templates folder. for further details see the github code.\n\nWe need to create the requirement.txt file. command for that is\n>pip freeze>requirement.txt\n\nTo let heroku know that it has to run the app.py file we will mention that in the Profile\n>web:gunicorn app:app\n\nFinally to host the application to heroku we initiatiliaze git repository and publish to heroku with simple git push.\n>git init\n\n>git add .\n\n>git commit\n\n>git push heroku master\n\nDone !!! Your application will be hosted to heroku cloud platform"},{"metadata":{},"cell_type":"markdown","source":"## Challenges:"},{"metadata":{},"cell_type":"markdown","source":"As the dataset was huge Initially had to sample the data and try different techniques to get the best option and test that technique on the whole data. Tried various algorithms to classify the review and predict the rating finally combining them with ensemble voting classifier\n\nIn order to make GUI and deploy it to cloud. Studied Flask and connecting prediction model to it. Understood the working of heroku clost hosting for deploying the classification model.\n\n\nAs the accuracy for 10 class label is not more than 30%. Created a accuracy function to calculate range accuracy with range of [+1 ,-1] which gives a better understanding of the performance of the algorithm."},{"metadata":{},"cell_type":"markdown","source":"## References:\n\n1. Dataset:https://www.kaggle.com/jvanelteren/boardgamegeek-reviews \n\n2. Deploy with Flask : https://www.youtube.com/watch?v=Z1RJmh_OqeA&feature=youtu.be\n\n3. https://machinelearningmastery.com/ensemble-machine-learning-algorithms-python-scikit-learn/\n\n4. https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifier.html\n\n5. https://matplotlib.org/3.2.1/gallery/lines_bars_and_markers/barchart.html#sphx-glr-gallery-lines-bars-and-markers-barchart-py\n\n6. https://towardsdatascience.com/a-complete-exploratory-data-analysis-and-visualization-for-text-data-29fb1b96fb6a\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":4}