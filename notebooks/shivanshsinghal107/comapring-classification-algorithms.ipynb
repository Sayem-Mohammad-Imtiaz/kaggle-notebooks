{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom mlxtend.plotting import plot_decision_regions","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/unsupervised-learning-on-country-data/Country-data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Removing Outliers & visualzing data distribution","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16, 8))\nplt.scatter(df['country'], df['gdpp'])\nplt.ylabel(\"GDP\")\nplt.xlabel(\"Country\")\nplt.xticks([])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# removing outliers\ndf = df.loc[df['gdpp'] <= 50000]\n# calculating mean GDP\nmean_gdp = np.mean(df['gdpp'])\ndf['Class'] = 1\n# dividing classes\nfor i in df.index:\n    if df.loc[i, 'gdpp'] < mean_gdp:\n        df.loc[i, 'Class'] = 0\n    elif df.loc[i, 'gdpp'] > 2*mean_gdp:\n        df.loc[i, 'Class'] = 2\nplt.figure(figsize = (16, 8))\nplt.scatter(df['country'], df['gdpp'])\nplt.ylabel(\"GDP\")\nplt.xlabel(\"Country\")\nplt.xticks([])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gdp_above_twoavg = df.loc[df['Class'] == 2]\ngdp_above_avg = df.loc[df['Class'] == 1]\ngdp_below_avg = df.loc[df['Class'] == 0]\nplt.figure(figsize = (16, 8))\nplt.scatter(gdp_above_twoavg['country'], gdp_above_twoavg['gdpp'], label = \"GDP above 2*avg\")\nplt.scatter(gdp_above_avg['country'], gdp_above_avg['gdpp'], label = \"GDP btw avg-2*avg\")\nplt.scatter(gdp_below_avg['country'], gdp_below_avg['gdpp'], label = \"GDP below avg\")\nplt.xlabel(\"Country\")\nplt.ylabel(\"GDP\")\nplt.xticks([])\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Making labels and features from the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df['Class']\nX = df.drop(['Class', 'country'], axis = 1)\nX.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Splitting the data into train & test sets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plotting Function","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_classes(X, y, clf, title):\n    values = {}\n    ranges = {}\n    for i in range(0, 8):\n        if i == 4:\n            pass\n        else:\n            values[i] = 50\n            ranges[i] = 500\n    plot_decision_regions(X, y, clf=clf,\n                          legend=2, feature_index = [4, 8],\n                          filler_feature_values = values,\n                          filler_feature_ranges = ranges)\n    plt.xlabel(\"Income per capita\")\n    plt.ylabel(\"Country GDP\")\n    plt.title(title)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Normalization","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg = LogisticRegression(C = 10, max_iter = 1000).fit(X_train, y_train)\nprint(f\"Train Score: {logreg.score(X_train, y_train)}\")\nprint(f\"Test Score: {logreg.score(X_test, y_test)}\")\nplot_classes(X_train.values, y_train.values, logreg, 'Logistic Regression on train set')\nplot_classes(X_test.values, y_test.values, logreg, 'Logistic Regression on test set')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression with Feature Normalization","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg = LogisticRegression(C = 10, max_iter = 1000).fit(X_train_scaled, y_train)\nprint(f\"Train Score: {logreg.score(X_train, y_train)}\")\nprint(f\"Test Score: {logreg.score(X_test, y_test)}\")\nvalues = {}\nranges = {}\nfor i in range(0, 8):\n    if i == 4:\n        pass\n    else:\n        values[i] = 1\n        ranges[i] = 5\nplot_decision_regions(X_train_scaled, y_train.values, clf=logreg,\n                      legend=2, feature_index = [4, 8],\n                      filler_feature_values = values,\n                      filler_feature_ranges = ranges)\nplt.xlabel(\"Income per capita\")\nplt.ylabel(\"Country GDP\")\nplt.title(\"Logistic Regression on train set with Feature Normalization\")\nplt.show()\nplt.figure()\nplot_decision_regions(X_test_scaled, y_test.values, clf=logreg,\n                      legend=2, feature_index = [4, 8],\n                      filler_feature_values = values,\n                      filler_feature_ranges = ranges)\nplt.xlabel(\"Income per capita\")\nplt.ylabel(\"Country GDP\")\nplt.title(\"Logistic Regression on test set with Feature Normalization\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# k Neighbors Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, y_train)\nprint(f\"Train Score: {knn.score(X_train, y_train)}\")\nprint(f\"Test Score: {knn.score(X_test, y_test)}\")\nplot_classes(X_train.values, y_train.values, knn, 'kNN on train set with k=3')\nplot_classes(X_test.values, y_test.values, knn, 'kNN on test set with k=3')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## kNN with Feature Normalization","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"knn.fit(X_train_scaled, y_train)\nprint(f\"Train Score: {knn.score(X_train_scaled, y_train)}\")\nprint(f\"Test Score: {knn.score(X_test_scaled, y_test)}\")\nvalues = {}\nranges = {}\nfor i in range(0, 8):\n    if i == 4:\n        pass\n    else:\n        values[i] = 0.5\n        ranges[i] = 5\nplot_decision_regions(X_train_scaled, y_train.values, clf=knn,\n                      legend=2, feature_index = [4, 8],\n                      filler_feature_values = values,\n                      filler_feature_ranges = ranges)\nplt.xlabel(\"Income per capita\")\nplt.ylabel(\"Country GDP\")\nplt.title(\"kNN on train set with Feature Normalization & k=3\")\nplt.show()\nplt.figure()\nplot_decision_regions(X_test_scaled, y_test.values, clf=knn,\n                      legend=2, feature_index = [4, 8],\n                      filler_feature_values = values,\n                      filler_feature_ranges = ranges)\nplt.xlabel(\"Income per capita\")\nplt.ylabel(\"Country GDP\")\nplt.title(\"kNN on test set with Feature Normalization & k=3\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Support Vector Machine(SVM)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Kernelized Support Vector Machine","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"svm = SVC(gamma = 'auto', C = 10).fit(X_train, y_train)\nprint(f\"Train Score: {svm.score(X_train, y_train)}\")\nprint(f\"Test Score: {svm.score(X_test, y_test)}\")\nvalues = {}\nranges = {}\nfor i in range(0, 8):\n    if i == 4:\n        pass\n    else:\n        values[i] = 100\n        ranges[i] = 500\nplot_decision_regions(X_train.values, y_train.values, clf=svm,\n                      legend=2, feature_index = [4, 8],\n                      filler_feature_values = values,\n                      filler_feature_ranges = ranges)\nplt.xlabel(\"Income per capita\")\nplt.ylabel(\"Country GDP\")\nplt.title(\"SVM on train set\")\nplt.show()\nplt.figure()\nplot_decision_regions(X_test.values, y_test.values, clf=svm,\n                      legend=2, feature_index = [4, 8],\n                      filler_feature_values = values,\n                      filler_feature_ranges = ranges)\nplt.xlabel(\"Income per capita\")\nplt.ylabel(\"Country GDP\")\nplt.title(\"SVM on test set\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SVM with Feature Normalization","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"svm = SVC(gamma = 'auto', C = 10).fit(X_train_scaled, y_train)\nprint(f\"Train Score: {svm.score(X_train_scaled, y_train)}\")\nprint(f\"Test Score: {svm.score(X_test_scaled, y_test)}\")\nvalues = {}\nranges = {}\nfor i in range(0, 8):\n    if i == 4:\n        pass\n    else:\n        values[i] = 0.8\n        ranges[i] = 4\nplot_decision_regions(X_train_scaled, y_train.values, clf=svm,\n                      legend=2, feature_index = [4, 8],\n                      filler_feature_values = values,\n                      filler_feature_ranges = ranges)\nplt.xlabel(\"Income per capita\")\nplt.ylabel(\"Country GDP\")\nplt.title(\"SVM on train set with Feature Normalization\")\nplt.show()\nplt.figure()\nplot_decision_regions(X_test_scaled, y_test.values, clf=svm,\n                      legend=2, feature_index = [4, 8],\n                      filler_feature_values = values,\n                      filler_feature_ranges = ranges)\nplt.xlabel(\"Income per capita\")\nplt.ylabel(\"Country GDP\")\nplt.title(\"SVM on test set with Feature Normalization\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decision Tree","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tree = DecisionTreeClassifier().fit(X_train, y_train)\nprint(f\"Train Score: {tree.score(X_train, y_train)}\")\nprint(f\"Test Score: {tree.score(X_test, y_test)}\")\nplot_classes(X_train.values, y_train.values, tree, 'Decision Tree on train set')\nplot_classes(X_test.values, y_test.values, tree, 'Decision Tree on test set')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Decision Tree with Feature Normalization","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tree = DecisionTreeClassifier().fit(X_train_scaled, y_train)\nprint(f\"Train Score: {tree.score(X_train_scaled, y_train)}\")\nprint(f\"Test Score: {tree.score(X_test_scaled, y_test)}\")\nplot_classes(X_train_scaled, y_train.values, tree, 'Decision Tree on train set with Feature Normalization')\nplot_classes(X_test_scaled, y_test.values, tree, 'Decision Tree on test set with Feature Normalization')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Note that results of Decision Tree are same with simple features & normalized features, which should be as decision tree does not bother whether features are normalized or not, it simply classify based on values. So no matter what the scales are for various features, decision tree would always give the same result**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Polynomial Features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"poly = PolynomialFeatures(degree = 2)\nX_train_poly = poly.fit_transform(X_train)\nX_test_poly = poly.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg = LogisticRegression(C = 10, max_iter = 1000).fit(X_train_poly, y_train)\nprint(f\"Train Score: {logreg.score(X_train_poly, y_train)}\")\nprint(f\"Test Score: {logreg.score(X_test_poly, y_test)}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## kNN","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"knn.fit(X_train_poly, y_train)\nprint(f\"Train Score: {knn.score(X_train_poly, y_train)}\")\nprint(f\"Test Score: {knn.score(X_test_poly, y_test)}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SVM","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"svm = SVC(gamma = 5, C = 10).fit(X_train_poly, y_train)\nprint(f\"Train Score: {svm.score(X_train_poly, y_train)}\")\nprint(f\"Test Score: {svm.score(X_test_poly, y_test)}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Decision Tree","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tree = DecisionTreeClassifier().fit(X_train_poly, y_train)\nprint(f\"Train Score: {tree.score(X_train_poly, y_train)}\")\nprint(f\"Test Score: {tree.score(X_test_poly, y_test)}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**According to results of all various algorithms, the performances are in the following order(best to worst(comaratively)):**\n1. Decision Tree\n2. kNN Classification\n3. Logistic Regression\n4. SVM","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}