{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd # 데이터 처리 모듈\nimport matplotlib.pyplot as plt # 데이터 시각화 모듈 \nimport seaborn as sns # 데이터 시각화 모듈\nfrom sklearn.model_selection import train_test_split # 데이터 분할 모듈\n              \n\ndef disable_warning():\n    import warnings\n    warnings.filterwarnings('ignore')\n\n    \n# data_f = load_csv('../input/plant-diary-new/plant_diary_new.csv')\ndef load_csv(file):\n    import pandas as pd # 데이터 처리 모듈\n    # CSV 파일 읽어오기\n    imsi = pd.read_csv(file)\n    return imsi;\n\n\ndef show_files(f):\n    import os\n    for dirname, _, filenames in os.walk(f):\n        for filename in filenames:\n            return os.path.join(dirname, filename)\n\n        \ndef hist(df):\n    data_f.hist(edgecolor='black', linewidth=1.2)\n    fig = plt.gcf()\n    fig.set_size_inches(12,10)\n    plt.show()\n\n\n    \ndef label2value(col):\n    #Labeling the object datas\n    from sklearn.preprocessing import LabelEncoder\n    labelencoder=LabelEncoder()\n    for dataset in [data_f]:\n        dataset.loc[:,col]=labelencoder.fit_transform(dataset.loc[:,col].values)\n      \n    \n# heatmap(df, ['day', 'height', 'leaf_width', 'leaf_length', 'owner'])\ndef heatmap(dataf, cols):\n    plt.figure(figsize=(12,8))\n    sns.heatmap(data_f[cols].corr(),annot=True)\n\n    \ndef split_4_parts(df, li, dap_col):\n    # 학습용(문제, 정답), 테스트용(문제, 정답)으로 데이터 나누기\n    train, test = train_test_split(df, train_size = 0.8)\n\n    # 학습용 문제와 정답\n    a = train[li]\n    b = train[dap_col]\n\n    # 시험 문제와 정답\n    c = test[li]\n    d = test[dap_col]\n\n    return a, b, c, d\n\n\n# 다양한 예측 알고리즘 패키지를 임포트함.              \nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\n\ndef run_4_regressors(a, b, c, d):\n    # [1] 결정트리 예측기 머신러닝 알고리즘 학습\n    gildong = DecisionTreeRegressor(random_state = 0)\n    gildong.fit(train_X, train_y) #학습용 문제, 학습용 정답  \n    score1 = gildong.score(test_X, test_y) # 시험 문제, 시험 정답\n    # score의 의미: 정확하게 예측하면 1, 평균으로 예측하면 0, 더 못 예측하면 음수  \n\n    # [2] 랜덤 포레스트 예측기 머신러닝 알고리즘\n    youngja = RandomForestRegressor(n_estimators=28,random_state=0)\n    youngja.fit(train_X, train_y)\n    score2 = youngja.score(test_X, test_y)\n\n    # [3] K근접이웃 예측기 머신러닝 알고리즘\n    cheolsu = KNeighborsRegressor(n_neighbors=2)\n    cheolsu.fit(train_X, train_y)\n    score3 = cheolsu.score(test_X, test_y)\n\n    # [4] 선형회귀 머신러닝 알고리즘\n    minsu = LinearRegression()\n    minsu.fit(train_X, train_y)\n    score4 = minsu.score(test_X, test_y)\n\n    plt.plot(['DT','RF','K-NN','LR'], [score1, score2, score3, score4])\n    print('스코어: {0:.2f}, {1:.2f}, {2:.2f}, {3:.2f}'.format(score1, score2, score3, score4))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_f = load_csv('../input/world-happiness/2015.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_f.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_f","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#행복 순위는 행복 지수에 따라 정해지는 것이라 제거하고, 나라 이름은 행복 지수와 관련이 없기 때문에 제거한다.\ndata_f = data_f.drop(['Happiness Rank', 'Country'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist(data_f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#국가의 지역 값이 문자열이기 때문에 알고리즘을 이용해 학습시킬 수 없으므로 숫자값으로 변환한다.\nlabel2value('Region')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_f[['Region']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"heatmap(data_f,['Happiness Score', 'Region', 'Economy (GDP per Capita)', 'Family', 'Health (Life Expectancy)', 'Freedom', 'Trust (Government Corruption)', 'Generosity', 'Dystopia Residual'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X, train_y, test_X, test_y = split_4_parts(data_f, ['Region', 'Economy (GDP per Capita)', 'Family', 'Health (Life Expectancy)', 'Freedom', 'Trust (Government Corruption)', 'Generosity', 'Dystopia Residual'], ['Happiness Score'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"run_4_regressors(train_X, train_y, test_X, test_y)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}