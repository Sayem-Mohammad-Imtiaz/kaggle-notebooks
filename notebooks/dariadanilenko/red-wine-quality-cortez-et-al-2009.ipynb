{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Подключаем необходимые библиотеки."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(rc={'figure.figsize':(10, 8)}); # you can change this if needed","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Методы ближайших соседей\n**1.1 Загружаем датасет**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')\ndf.head(20).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**1.2 Извлекаем target-переменную**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_target = df['quality']\ndf_target","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"В данном датасете собраны данные о свойствах красного вина - всего 12 фич, из которых 11 изначальные, и 1 target - quality. Так как класифицировать здесь нечего - все собранные данные относятся к красному вину - рассматривается задача регрессии. А точнее - какие признаки и в какой степени влияют на целевую переменную."},{"metadata":{},"cell_type":"markdown","source":"**1.3 Каково распределение target-переменной? Проанализирем и сделаем выводы**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import normaltest\nsns.kdeplot(df_target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Для проверки распределения на нормальность, воспользуемся тестом д'Агостино. Предполагаем, что переменная имеет распределение Гаусса (нормальное). Тогда, в случае если **p-value > 0.05** мы подтвердим это предположение, в обратном же случае примем альтернативную гипотезу - что нормального распределения нет."},{"metadata":{"trusted":true},"cell_type":"code","source":"data, p = normaltest(df_target)\nprint(\"p-value = \", p)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Исследовав распределение target-переменной с помощью теста, можно прийти к выводу, что выборка не имеет нормального распределения"},{"metadata":{},"cell_type":"markdown","source":"**1.4 Проведем предобработку и масштабирование данных**"},{"metadata":{},"cell_type":"markdown","source":"Так как в датасете отсутствуют категориальные переменные, необходимости в перекодировании отсутствует. Но, как можно судить по графику распределения target-переменной - он смещен  вправо, а значит мы можем прологорифмировать ее. Введем новый столбец для хранения новой target-переменной."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['quality_log'] = np.log(df['quality'])\ndf_target_log = df['quality_log']\nprint(df_target)\nprint(df_target_log)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Для масштабирования воспользуемся классом StandardScaler. Подготовим датафрейм для дальнейшего разделения на выборки - сохраним target-переменную отдельно."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\ndf_scaled = df.drop('quality', axis = 1)\ndf_scaled = df.drop('quality_log', axis = 1)\ndf_scaled_fin = scaler.fit_transform(df_scaled)\ndf_scaled_fin","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**1.5 Разобьем набор данных на обучающую и валидационную (тестовую) выборки**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(df_scaled_fin, df_target_log, test_size=0.25, random_state=412)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**1.6 Обучим алгоритм регрессии**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsRegressor\nknn = KNeighborsRegressor(n_neighbors=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn.fit(X_train, y_train)\ny_pred = knn.predict(X_valid)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Оценим качество модели с помощью mean_squared_error - для регрессии."},{"metadata":{"trusted":true},"cell_type":"code","source":"knn.score(X_valid, y_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nmean_squared_error(y_valid, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"mean_squared_error довольно маленькая, а значение score довольно большое, а значит модель можно считать качественной."},{"metadata":{},"cell_type":"markdown","source":"# 2. Настройка оптимального числа ближайших соседей в методе kNN\n**2.1 Создаем генератор разбиений**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nkf = KFold(n_splits=5, shuffle=True, random_state=412)\nknn = KNeighborsRegressor(n_neighbors=100)\nscores = cross_val_score(knn, df_scaled_fin, df_target_log, cv=kf, scoring='neg_mean_squared_error')\nscores.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Чем больше значение которое мы получим, тем выше достоверность модели (меньше разница между моделью и данными). Т.к. метод neg_mean_squared_error возвращает отрицательное значение метрики, он вполне нам подходит. Значение довольно малое, а значит величина ошибки мала."},{"metadata":{},"cell_type":"markdown","source":"**2.2 Используем GridSearchCV**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nknn_params = {'n_neighbors': np.arange(1, 51)}\nknn_grid = GridSearchCV(knn, knn_params, scoring='neg_mean_squared_error', cv=kf)\nknn_grid.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_grid.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_grid.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_grid.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Лучшее значение ближайших соседей k = 3. Это значение при котором будет самое высокая оценка модели."},{"metadata":{"trusted":true},"cell_type":"code","source":"results_df = pd.DataFrame(knn_grid.cv_results_)\nresults_df.T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(results_df['param_n_neighbors'], results_df['mean_test_score'])\n\nplt.xlabel('n_neighbors')\nplt.ylabel('Test error')\nplt.title('Validation curve')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Подведем итоги: лучшее значение параметра k = 3,\n                высшое значение score = -0.0034659943977269152 - наиболее близкая к нулю."},{"metadata":{},"cell_type":"markdown","source":"# 3. Выбор метрики в методе kNN"},{"metadata":{},"cell_type":"markdown","source":"**3.1 Переберем разные варианты значений параметра p**"},{"metadata":{"trusted":true},"cell_type":"code","source":"p_params = {\"p\": np.linspace(1,10,200)}\nknn = KNeighborsRegressor(n_neighbors = 3, weights = \"distance\", n_jobs = -1) #метрика Минковского идет по умолчанию\nknn_cv = GridSearchCV(knn, p_params, cv = kf, scoring=\"neg_mean_squared_error\")\nknn_cv.fit(df_scaled_fin, df_target_log)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**3.2 Определим, при каком p качество на кросс-валидации оказалось оптимальным**"},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_cv.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_cv.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_cv.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"При значении параметра p = 6.517587939698493 мы получаем оптимальное значение score = -0.0022425669832474974."},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_cv_results = pd.DataFrame(knn_cv.cv_results_)\nknn_cv_results.T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(knn_cv_results[\"param_p\"],knn_cv_results[\"mean_test_score\"])\nplt.xlabel('n_neighbors')\nplt.ylabel('Test error')\nplt.title('Validation curve')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Другие метрические методы"},{"metadata":{},"cell_type":"markdown","source":"RadiusNeighborsClassifier и NearestCentroid являются методами классификации, а значит не подходят для нашей задачи. Значит, будем исследовать RadiusNeighborsRegressor."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import RadiusNeighborsRegressor\nrnr = RadiusNeighborsRegressor(radius = 7)\nrnr.fit(X_train, y_train)\ny_pred = rnr.predict(X_valid)\ny_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rnr.score(X_valid, y_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_squared_error(y_valid, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Значения полученные с помощью метода RadiusNeighborsRegressor довольно сильно отличаются: значение score = 0.07797313675581374, довольно маленькое, а значение ошибки наоборот, выше чем при KNN. Таким образом можно предположить, что метод KNN точнее чем RNR. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}