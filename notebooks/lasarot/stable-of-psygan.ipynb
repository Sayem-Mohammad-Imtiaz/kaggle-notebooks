{"cells":[{"metadata":{},"cell_type":"markdown","source":"renorm and should be pretty good.\n\n#  todo: include pngs? just looking for jpgs rn\n# gradp?\n\n\n# search latent for good disc ratings?\n\n# save weights"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#import libraries\n\nimport numpy as np\nimport tensorflow as tf\nimport imageio\nimport glob\nfrom IPython.display import Image, display,FileLink,clear_output\n\nimport os\nfrom scipy import misc, ndimage, stats\nimport random\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#base settings\n\nbatch_size = 16 #how many images to run each iteration\n\nzN = 128 #length of latent vector\n\nsideX = 256 #sidelength in x dimension (numpy switches these around) (low res for testing)\nsideY = 256","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This'll be a simple SNGAN. Keras layers would be simpler, but it's easier to just use tf.nn to apply the spectral normalization"},{"metadata":{"trusted":true},"cell_type":"code","source":"#utils/layers\n#spec norm from Junho Kim https://github.com/taki0112/Spectral_Normalization-Tensorflow\ndef spectral_norm(w, iteration=1):\n   w_shape = w.shape.as_list()\n   w = tf.reshape(w, [-1, w_shape[-1]])\n\n   u = tf.get_variable(\"u\", [1, w_shape[-1]], initializer=tf.random_normal_initializer(), trainable=False)\n\n   u_hat = u\n   v_hat = None\n   for i in range(iteration):\n       \"\"\"\n       power iteration\n       Usually iteration = 1 will be enough\n       \"\"\"\n       v_ = tf.matmul(u_hat, tf.transpose(w))\n       v_hat = tf.nn.l2_normalize(v_)\n\n       u_ = tf.matmul(v_hat, w)\n       u_hat = tf.nn.l2_normalize(u_)\n\n   u_hat = tf.stop_gradient(u_hat)\n   v_hat = tf.stop_gradient(v_hat)\n\n   sigma = tf.matmul(tf.matmul(v_hat, w), tf.transpose(u_hat))\n\n   with tf.control_dependencies([u.assign(u_hat)]):\n       w_norm = w / sigma\n       w_norm = tf.reshape(w_norm, w_shape)\n\n\n   return w_norm\n\n\ndef upsamp(x,sc=2):\n  x = tf.image.resize_image_with_pad(x,sc*x.get_shape().as_list()[1],sc*x.get_shape().as_list()[2])\n#   x = conv2D(x,x.shape[-1],1,1)\n#   x = tf.keras.layers.Conv2DTranspose(x.get_shape().as_list()[-1],4,2,padding='SAME')(x)\n  return x\n\ndef conv2D(x,c,kd=3,strides=1,fin=False,spN = True):\n  with tf.variable_scope(None,'c'):\n    inFil = (x.shape[1]//strides,x.shape[2]//strides)\n    \n    \n    w = tf.get_variable('kernel',[kd,kd,x.get_shape()[-1],c])\n    if spN:\n        w = spectral_norm(w)\n    \n    b = tf.get_variable('bias',[c],initializer=tf.constant_initializer(0.0))\n    x = tf.nn.conv2d(input=x,filter=w,strides=[1,strides,strides,1],padding='SAME')+b\n#     dif = ((inFil[0]-x.shape[1])//2,(inFil[1]-x.shape[2])//2) #set padding to valid\n#     pd = [[0,0],[dif[0],dif[0]],[dif[1],dif[1]],[0,0]]\n    \n#     x = tf.pad(x,pd,'REFLECT')\n    \n    if fin:\n      x = tf.tanh(x)\n      print(x.shape)\n    return x\n\ndef dense(x,units,spN=True):\n  with tf.variable_scope(None,'d'):\n\n#     fl = tf.keras.layers.Flatten()(x)\n    ind = x.get_shape()[-1]\n    \n    w = tf.get_variable('weights',shape=[ind,units])\n    if spN:\n        w = spectral_norm(w)\n    b = tf.get_variable('bias',[units],initializer=tf.constant_initializer(0.0))\n    return tf.matmul(x,w)+b\n                     \ndef relu(x):\n  return tf.maximum(x,tf.zeros_like(x))\n\ndef leaky(x):\n  return tf.maximum(x,.2*x)\n\ndef batchN(x):\n    x = tf.contrib.layers.batch_norm(x,renorm=True)\n    return x\n\ndef iN(x):\n    return tf.contrib.layers.instance_norm(x)\n\n\n\ndef block(x,filters,k='l',up = False, down = False): \n  with tf.variable_scope(None,'resn'):\n    inFil = x.shape.as_list()[-1]\n    cur = filters//4\n    \n    if not down:\n      a = batchN(x)\n      a = leaky(a)\n      \n      a = conv2D(a,cur,1,1)\n        \n      a = batchN(a)\n      a = leaky(a)\n    \n      a = conv2D(a,cur)\n        \n      a = batchN(a)\n      a = leaky(a)\n    \n    else:\n      a = leaky(x)\n      a = conv2D(a,cur,1,1)\n      a = leaky(a)\n      a = conv2D(a,cur)\n      a = leaky(a)\n      \n    \n    if up:\n      a = upsamp(a)\n      x = x[:,:,:,:filters]\n      x = upsamp(x)\n      a = conv2D(a,filters,1,1)\n    elif down:\n#       pd = (filters-inFil)//2\n#       x = tf.pad(x,[[0,0],[0,0],[0,0],[pd,pd]])\n      x = conv2D(x,filters,2,2)\n      a = conv2D(a,filters,2,2)\n#       a = tf.nn.avg_pool(a,[1,2,2,1],[1,2,2,1],'SAME')\n\n#       x = tf.nn.avg_pool(x,[1,2,2,1],[1,2,2,1],'SAME')\n    else:\n      a = conv2D(a,filters,1,1)\n    a = tf.add(x,a)\n    return a\n\ndef lN(x):\n    return tf.contrib.layers.layer_norm(x)\n\ndef stdL(x,groups=4,features=1): #hardcoded?\n    sh = x.shape\n    y = tf.reshape(x,(groups,features,-1,x.shape[1],x.shape[2],x.shape[3]))\n    y = tf.sqrt(tf.nn.moments(y,[0])[1])\n    y = tf.reduce_mean(y,[2,3,4],keep_dims=True)\n    y = tf.reduce_mean(y,[2])\n    y = tf.reshape(y,(-1,1,1,1))\n    y = tf.tile(y,(groups,x.shape[1],x.shape[2],features))\n    y = tf.concat([x,y],axis=-1)\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#setup data functions\ndef load():\n    paths = []\n    for filepath in glob.iglob('/kaggle/input/psychart/' + '**/*.jpg', recursive=True):\n        try:\n#             misc.imresize(filepath,(256,256))\n            paths.append(filepath)\n        except:\n            print(filepath,'broke')\n            \n    tf.convert_to_tensor(paths, dtype=tf.string)\n    dataset = tf.data.Dataset.from_tensor_slices((paths))\n    dataset = dataset.repeat().shuffle(len(paths))\n    return dataset\ndef maper(path):\n    image = tf.image.decode_jpeg(tf.read_file(path))\n    \n    #augment images\n    \n#     image = tf.image.random_crop(image,[sideY,sideX,3])\n    #instead of cropping to a random x by y location, do the whole thing with a random up-to 20th shaved off each side\n    rnds = tf.random.uniform([4],0,.1)\n    image = tf.image.crop_and_resize(tf.expand_dims(image,axis=0),[[rnds[0],rnds[1],\n                                             1-rnds[2],1-rnds[3]]]\n                                     ,[0],(sideY,sideX))\n    image = tf.squeeze(image)\n#     image = tf.image.rot90(image,tf.random.uniform([],0,4,dtype=tf.int32))\n    image = tf.image.random_hue(image,.5)\n    image = tf.image.random_saturation(image,.9,2)\n    image = tf.image.random_brightness(image,.8)\n\n    \n#     image = tf.image.resize_images(image,(sideY,sideX))\n    image = (tf.cast(image,tf.float32)/255)*2-1 #normalize data\n    \n    return image    \n\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#setup model\n\ntf.reset_default_graph()#run this to restart\n\ndef generator(latent):#moves from noise (a latent vector) to images\n    with tf.variable_scope('gen'):\n        dep = 4\n        x = dense(latent,sideY//2**dep*sideX//2**dep*512)\n        x = tf.reshape(x,(-1,sideY//2**dep,sideX//2**dep,512))\n        ch = 256\n        for i in range(dep):\n            x = upsamp(x)\n            x = conv2D(x,ch)\n            x = leaky(x)\n            x = batchN(x) #renorm is on if batchN\n            ch//=2\n        x = conv2D(x,3,fin=True)\n        return x\n\ndef discriminator(x): #tell generator how far it is from real images\n    with tf.variable_scope('rdis',reuse=tf.AUTO_REUSE):\n        ch = 64\n        x = tf.reshape(x,(-1,sideY,sideX,3*2)) # pacgan\n        for i in range(4):\n            x = conv2D(x,ch,4,2)\n            x = leaky(x)\n            ch*=2\n            if i == 3:\n                x = stdL(x)\n        x = tf.reshape(x,(batch_size,-1))\n        x = dense(x,1)\n        return x\n    \nlatent = tf.placeholder(dtype=tf.float32,shape=(None,zN))\nsyn = generator(latent)\n\ndataset = load()\ndataset = dataset.map(maper, num_parallel_calls=4)\ndataset = dataset.batch(batch_size)\ndataset = dataset.prefetch(1)\n\nimg = dataset.make_one_shot_iterator().get_next()\nimg.set_shape((batch_size,sideY,sideX,3))\n\n\ndreal = discriminator(img)\ndfake = discriminator(syn)\n\ntr = tf.trainable_variables()\ngenv = [var for var in tr if 'gen' in var.name]\n\ndiscv = [var for var in tr if 'rdis' in var.name]\n\n#hinge loss\nd_loss = tf.reduce_mean(tf.maximum(0.,1.-dreal)) + tf.reduce_mean(tf.maximum(0.,1.+dfake))\ng_loss = tf.reduce_mean(-dfake)\n\n\ngopt = tf.train.AdamOptimizer(.0002,.0,.9).minimize(g_loss,var_list=genv)\n  \ndopt = tf.train.AdamOptimizer(.0002,.0,.9).minimize(d_loss,var_list=discv)\n\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True\n\nsess = tf.Session(config=config)\n\nsess.run(tf.global_variables_initializer())\n\n\nits = 0\nprint('Ready')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train model\n\n#for comitting just change st in gen_batch to its and do the whole batch\n\n#for watching\ndef gen_batch(st=3,rows=True,singles=False):\n    out = syn.eval({latent:np.random.normal(size=(batch_size,zN))})\n    cn=0\n    if not rows:\n        bimg = np.zeros((3*sideY,3*sideX,3)) #only using part of the full 20-image batches\n        for x in range(3):\n            for y in range(3):\n                bimg[x*sideY:(x+1)*sideY,y*sideX:(y+1)*sideX,:] = out[cn]\n                cn+=1\n        imageio.imwrite(str(st)+'.jpg', bimg)\n        display(Image(str(st)+'.jpg'))\n    elif singles:\n        for ims in range(3):\n            imageio.imwrite(str(st)+'.jpg', out[ims])\n            display(Image(str(st)+'.jpg'))\n            \n    else:\n        bimg = np.zeros((1*sideY,5*sideX,3)) #should use all of batches,b ut idc rn\n        for x in range(1):\n            for y in range(5):\n                bimg[x*sideY:(x+1)*sideY,y*sideX:(y+1)*sideX,:] = out[cn]\n                cn+=1\n        imageio.imwrite(str(st)+'.jpg', bimg)\n        display(Image(str(st)+'.jpg'))\ndef train():\n  global its\n  with sess.as_default():\n    for i in range(10000):\n      \n      for n in range(1):\n        dopt.run({latent:np.random.normal(size=(batch_size,zN))})\n      \n      \n      gopt.run({latent:np.random.normal(size=(batch_size,zN))})\n      its+=1\n      \n      if its%100 == 0 or i == 0:\n        done = np.resize(img.eval()[0],(sideX,sideY,3))\n        imageio.imwrite('3.jpg', done)\n        display(Image('3.jpg'))\n        \n        for j in range(2):\n            gen_batch(st=its,rows = False)\n        \n        de = d_loss.eval({latent:np.random.normal(size=(batch_size,zN))})\n        ge = g_loss.eval({latent:np.random.normal(size=(batch_size,zN))})\n        print('\\nG',ge,'D',de,'at',its,'\\n')      \n       \nwith sess.as_default():\n    train()\n\n#get to at least 6000\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#generate\nwith sess.as_default():\n    for i in range(2):\n        gen_batch(rows=False,singles=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#interpolate (may want to implement a circle about the distribution vs cutting through)\n\n#batch_size may screw with this...\n\ndef interp(shape,steps,trunc=False):\n    if trunc:\n        start = stats.truncnorm.rvs(-1.4,1.4,size=shape)\n    else:\n        start = np.random.normal(size=shape)\n    \n\n    stepA = np.zeros((start.shape))\n    for i in range(points-1):\n      stepA[i] = np.subtract(start[i+1],start[i])/steps\n    stepA[points-1] = np.subtract(start[0],start[points-1])/steps\n\n    ind = 0\n    exampIn = np.zeros(([shape[0]*steps]+list(shape[1:])))\n\n    for qt in range(points):\n      for zt in range(steps):\n        exampIn[ind] = start[qt]+stepA[qt]*(zt+1)\n        ind+=1\n    return exampIn\n\n\nwith sess.as_default(): #does order not hold over multiple bathes for some reason?\n    steps = 12\n    points = 4\n\n#     np.random.seed(87)\n\n    lat = interp((points,zN),steps)\n    \n    fed = {latent:lat}\n    out = syn.eval(fed)\n    print(out.shape)\n    out = np.reshape(out,(points*steps,sideY,sideX,3))\n    images = []\n    for im in out:\n        images.append(im)\n    \n    imageio.mimsave('g.gif', images)\n    display(Image('g.gif'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FileLink('g.gif')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}