{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Name: Jay Shah\n## Date: 11-08-2021\n### Pima Indians Diabetes Analysis ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport xgboost\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.ensemble import RandomForestClassifier as rfc\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RandomizedSearchCV\n\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import mean_squared_error as mse\nfrom sklearn.metrics import confusion_matrix\n\nfrom mlxtend.plotting import plot_confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:26:35.450132Z","iopub.execute_input":"2021-08-11T13:26:35.450632Z","iopub.status.idle":"2021-08-11T13:26:35.459439Z","shell.execute_reply.started":"2021-08-11T13:26:35.450597Z","shell.execute_reply":"2021-08-11T13:26:35.458399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Reading the dataframe","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/pima-indians-diabetes-database/diabetes.csv')\ndf","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:26:35.485997Z","iopub.execute_input":"2021-08-11T13:26:35.486726Z","iopub.status.idle":"2021-08-11T13:26:35.516325Z","shell.execute_reply.started":"2021-08-11T13:26:35.486683Z","shell.execute_reply":"2021-08-11T13:26:35.515306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Total number of rows are:',df.shape[0])\nprint('Total number of columns are:',df.shape[1])","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:26:35.517752Z","iopub.execute_input":"2021-08-11T13:26:35.518342Z","iopub.status.idle":"2021-08-11T13:26:35.525503Z","shell.execute_reply.started":"2021-08-11T13:26:35.518298Z","shell.execute_reply":"2021-08-11T13:26:35.524417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:26:35.539699Z","iopub.execute_input":"2021-08-11T13:26:35.540065Z","iopub.status.idle":"2021-08-11T13:26:35.546812Z","shell.execute_reply.started":"2021-08-11T13:26:35.54003Z","shell.execute_reply":"2021-08-11T13:26:35.545625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:26:35.595927Z","iopub.execute_input":"2021-08-11T13:26:35.596455Z","iopub.status.idle":"2021-08-11T13:26:35.634434Z","shell.execute_reply.started":"2021-08-11T13:26:35.59642Z","shell.execute_reply":"2021-08-11T13:26:35.63353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Checking if there are any NA values present or not ","metadata":{}},{"cell_type":"code","source":"df.isna().sum(axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:26:35.635766Z","iopub.execute_input":"2021-08-11T13:26:35.63655Z","iopub.status.idle":"2021-08-11T13:26:35.646851Z","shell.execute_reply.started":"2021-08-11T13:26:35.636489Z","shell.execute_reply":"2021-08-11T13:26:35.645432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Building a correlation matrix","metadata":{}},{"cell_type":"code","source":"df.corr()","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:26:35.648757Z","iopub.execute_input":"2021-08-11T13:26:35.649073Z","iopub.status.idle":"2021-08-11T13:26:35.674182Z","shell.execute_reply.started":"2021-08-11T13:26:35.649043Z","shell.execute_reply":"2021-08-11T13:26:35.673046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correlation_mat = df.corr()\ncorr_features = correlation_mat.index\nplt.figure(figsize=(20,20))\ng = sns.heatmap(df[corr_features].corr(),annot=True,cmap='RdYlGn')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:26:35.676198Z","iopub.execute_input":"2021-08-11T13:26:35.676657Z","iopub.status.idle":"2021-08-11T13:26:36.360329Z","shell.execute_reply.started":"2021-08-11T13:26:35.676611Z","shell.execute_reply":"2021-08-11T13:26:36.359365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Checking whether the dataset is balanced or not ","metadata":{}},{"cell_type":"code","source":"print('There are total',df['Outcome'].nunique(),'unique values in the outcome column')\nprint('Unique values in outcome column are',df['Outcome'].unique())","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:26:36.361935Z","iopub.execute_input":"2021-08-11T13:26:36.362718Z","iopub.status.idle":"2021-08-11T13:26:36.370466Z","shell.execute_reply.started":"2021-08-11T13:26:36.362403Z","shell.execute_reply":"2021-08-11T13:26:36.368785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Total number of 0(False count) are',(df['Outcome']==0).sum())\nprint('Total number of 1(True count) are',(df['Outcome']==1).sum())","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:26:36.372637Z","iopub.execute_input":"2021-08-11T13:26:36.372972Z","iopub.status.idle":"2021-08-11T13:26:36.388657Z","shell.execute_reply.started":"2021-08-11T13:26:36.372943Z","shell.execute_reply":"2021-08-11T13:26:36.386939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(5,5))\ncolors = ['#04FFCD','#FF04E6']\nsns.countplot(x='Outcome',data=df,palette=colors)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:26:36.390139Z","iopub.execute_input":"2021-08-11T13:26:36.390838Z","iopub.status.idle":"2021-08-11T13:26:36.515049Z","shell.execute_reply.started":"2021-08-11T13:26:36.390796Z","shell.execute_reply":"2021-08-11T13:26:36.51422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Checking some consistency in the dataset ","metadata":{}},{"cell_type":"code","source":"df.head(15)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:26:36.51617Z","iopub.execute_input":"2021-08-11T13:26:36.516628Z","iopub.status.idle":"2021-08-11T13:26:36.532587Z","shell.execute_reply.started":"2021-08-11T13:26:36.516585Z","shell.execute_reply":"2021-08-11T13:26:36.53164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> From the above output dataframe, it is clearly visible that some of the features have 0 as a value. Hence, in this scenario one can say that the dataset is not consistent as these values just cannot be 0. Below I will just check that how many missing 0's are present in the feature columns. \n\n> In order to compute the 0 values, I have computed the mean of a feature which has 0 values and then replaced that 0 values with the computed mean below.","metadata":{}},{"cell_type":"code","source":"print('Number of rows missing Glucose: {0}'.format(len(df.loc[df['Glucose'] == 0])))\nprint('Number of rows missing Blood Pressure: {0}'.format(len(df.loc[df['BloodPressure'] == 0])))\nprint('Number of rows missing Insulin: {0}'.format(len(df.loc[df['Insulin'] == 0])))\nprint('Number of rows missing BMI: {0}'.format(len(df.loc[df['BMI'] == 0])))\nprint('Number of rows missing Skin Thickness: {0}'.format(len(df.loc[df['SkinThickness'] == 0])))\nprint('Number of rows missing Age: {0}'.format(len(df.loc[df['Age'] == 0])))\nprint('Number of rows missing Diabetes Pedigree Function: {0}'.format(len(df.loc[df['DiabetesPedigreeFunction'] == 0])))","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:26:36.533777Z","iopub.execute_input":"2021-08-11T13:26:36.534112Z","iopub.status.idle":"2021-08-11T13:26:36.560448Z","shell.execute_reply.started":"2021-08-11T13:26:36.534069Z","shell.execute_reply":"2021-08-11T13:26:36.559083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = df['Glucose'].mean()\ndf['Glucose'].replace(0,x,inplace=True)\nx = df['BloodPressure'].mean()\ndf['BloodPressure'].replace(0,x,inplace=True)\nx = df['Insulin'].mean()\ndf['Insulin'].replace(0,x,inplace=True)\nx = df['BMI'].mean()\ndf['BMI'].replace(0,x,inplace=True)\nx = df['SkinThickness'].mean()\ndf['SkinThickness'].replace(0,x,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:26:36.562985Z","iopub.execute_input":"2021-08-11T13:26:36.563386Z","iopub.status.idle":"2021-08-11T13:26:36.580405Z","shell.execute_reply.started":"2021-08-11T13:26:36.56335Z","shell.execute_reply":"2021-08-11T13:26:36.579006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:26:36.582323Z","iopub.execute_input":"2021-08-11T13:26:36.582842Z","iopub.status.idle":"2021-08-11T13:26:36.605939Z","shell.execute_reply.started":"2021-08-11T13:26:36.582803Z","shell.execute_reply":"2021-08-11T13:26:36.604221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. Using Autoviz library for data visualization ","metadata":{}},{"cell_type":"code","source":"!pip install autoviz","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install xlrd","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:26:43.552031Z","iopub.execute_input":"2021-08-11T13:26:43.552467Z","iopub.status.idle":"2021-08-11T13:26:49.907531Z","shell.execute_reply.started":"2021-08-11T13:26:43.552427Z","shell.execute_reply":"2021-08-11T13:26:49.906486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from autoviz.AutoViz_Class import AutoViz_Class\nAV = AutoViz_Class()","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:26:49.909124Z","iopub.execute_input":"2021-08-11T13:26:49.909624Z","iopub.status.idle":"2021-08-11T13:26:49.914941Z","shell.execute_reply.started":"2021-08-11T13:26:49.909582Z","shell.execute_reply":"2021-08-11T13:26:49.913644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dft = AV.AutoViz('/kaggle/input/pima-indians-diabetes-database/diabetes.csv', \n                 dfte=df,\n                 header=0, \n                 verbose=2, \n                 lowess=False,\n                 chart_format=\"svg\", \n                 max_rows_analyzed=1000, \n                 max_cols_analyzed=10)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:26:49.916812Z","iopub.execute_input":"2021-08-11T13:26:49.91735Z","iopub.status.idle":"2021-08-11T13:27:00.032643Z","shell.execute_reply.started":"2021-08-11T13:26:49.917301Z","shell.execute_reply":"2021-08-11T13:27:00.031514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Now, I will split the dataset into training and testing in the below block of code and then I will apply various machine learning algorithms for prediction.\n\n","metadata":{}},{"cell_type":"markdown","source":"## 7. Splitting the dataset for training & testing and standardizing the data","metadata":{}},{"cell_type":"code","source":"y = df['Outcome']\nX = df.drop(columns=['Outcome'])\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:27:00.034023Z","iopub.execute_input":"2021-08-11T13:27:00.034356Z","iopub.status.idle":"2021-08-11T13:27:00.047356Z","shell.execute_reply.started":"2021-08-11T13:27:00.034322Z","shell.execute_reply":"2021-08-11T13:27:00.04595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:27:00.049431Z","iopub.execute_input":"2021-08-11T13:27:00.049929Z","iopub.status.idle":"2021-08-11T13:27:00.075199Z","shell.execute_reply.started":"2021-08-11T13:27:00.049879Z","shell.execute_reply":"2021-08-11T13:27:00.07365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Now, we will standardize the whole data.Data standardization is the process of rescaling the attributes so that they have mean as 0 and variance as 1.\n\n> The ultimate goal to perform standardization is to bring down all the features to a common scale without distorting the differences in the range of the values.\n\n> In sklearn.preprocessing.StandardScaler(), centering and scaling happens independently on each feature.\n\n> The formula which performs standardization is $(x-mean)/(sd)$\n\n> fit_transform() is used on the training data so that we can scale the training data and also learn the scaling parameters of that data.","metadata":{}},{"cell_type":"code","source":"scaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_train_scaled","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:27:00.077068Z","iopub.execute_input":"2021-08-11T13:27:00.077816Z","iopub.status.idle":"2021-08-11T13:27:00.095271Z","shell.execute_reply.started":"2021-08-11T13:27:00.07776Z","shell.execute_reply":"2021-08-11T13:27:00.09389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_scaled = scaler.transform(X_test)\nX_test_scaled","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:27:00.097619Z","iopub.execute_input":"2021-08-11T13:27:00.098215Z","iopub.status.idle":"2021-08-11T13:27:00.110875Z","shell.execute_reply.started":"2021-08-11T13:27:00.098164Z","shell.execute_reply":"2021-08-11T13:27:00.109892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 8. Applying Random Forest Classifier Algorithm for prediction ","metadata":{}},{"cell_type":"code","source":"rfc_model = rfc(random_state=10)\nrfc_model.fit(X_train_scaled, y_train.ravel())","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:27:00.112962Z","iopub.execute_input":"2021-08-11T13:27:00.113706Z","iopub.status.idle":"2021-08-11T13:27:00.309666Z","shell.execute_reply.started":"2021-08-11T13:27:00.113645Z","shell.execute_reply":"2021-08-11T13:27:00.308531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_predicted = rfc_model.predict(X_test_scaled)\nprint(\"Accuracy of Random Forest Model is = {0: .3f}\".format(metrics.accuracy_score(y_test,y_predicted)))","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:27:00.311712Z","iopub.execute_input":"2021-08-11T13:27:00.312143Z","iopub.status.idle":"2021-08-11T13:27:00.33549Z","shell.execute_reply.started":"2021-08-11T13:27:00.312097Z","shell.execute_reply":"2021-08-11T13:27:00.334414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_actual = y_test\ny_actual = y_actual.to_numpy() #  COnverting to numpy array\ny_actual","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:27:00.336803Z","iopub.execute_input":"2021-08-11T13:27:00.337078Z","iopub.status.idle":"2021-08-11T13:27:00.344781Z","shell.execute_reply.started":"2021-08-11T13:27:00.337051Z","shell.execute_reply":"2021-08-11T13:27:00.343629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Now, we will calculate mean square error.","metadata":{}},{"cell_type":"code","source":"print(\"The mean squared error is:\",mse(y_actual,y_predicted))","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:27:00.346557Z","iopub.execute_input":"2021-08-11T13:27:00.346862Z","iopub.status.idle":"2021-08-11T13:27:00.362854Z","shell.execute_reply.started":"2021-08-11T13:27:00.346831Z","shell.execute_reply":"2021-08-11T13:27:00.36172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Below obtained is a classification report and a confusion matrix is plotted.","metadata":{}},{"cell_type":"code","source":"target_names = ['class 0', 'class 1']\nprint(classification_report(y_actual, y_predicted, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:27:00.364712Z","iopub.execute_input":"2021-08-11T13:27:00.365474Z","iopub.status.idle":"2021-08-11T13:27:00.379628Z","shell.execute_reply.started":"2021-08-11T13:27:00.365426Z","shell.execute_reply":"2021-08-11T13:27:00.378765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conf_matrix = confusion_matrix(y_true=y_actual, y_pred=y_predicted)\nfig, ax = plot_confusion_matrix(conf_mat=conf_matrix, figsize=(8,8), cmap=plt.cm.Greens)\nplt.xlabel('Predictions', fontsize=18)\nplt.ylabel('Actuals', fontsize=18)\nplt.title('Confusion Matrix', fontsize=18)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:27:00.382936Z","iopub.execute_input":"2021-08-11T13:27:00.383676Z","iopub.status.idle":"2021-08-11T13:27:00.514393Z","shell.execute_reply.started":"2021-08-11T13:27:00.383638Z","shell.execute_reply":"2021-08-11T13:27:00.513622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 9. Hyper-parameter Optimization using RandomizedSearchCV in XgBoost Classifier","metadata":{}},{"cell_type":"code","source":"params = {\n    \"learning_rate\" : [0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4],\n    \"max_depth\" : [3,4,5,6,8,10,12,13,15],\n    \"min_child_weight\" : [1,3,5,7],\n    \"gamma\" : [0,0.1,0.2,0.3,0.4,0.42,0.45],\n    \"colsample_bytree\" : [0.3,0.4,0.5,0.7],\n}","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:27:00.515747Z","iopub.execute_input":"2021-08-11T13:27:00.516208Z","iopub.status.idle":"2021-08-11T13:27:00.521326Z","shell.execute_reply.started":"2021-08-11T13:27:00.516146Z","shell.execute_reply":"2021-08-11T13:27:00.520195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_model = xgboost.XGBClassifier(eval_metric='logloss')\nrandom_search=RandomizedSearchCV(xgb_model,\n                                 param_distributions=params,\n                                 n_iter=5,\n                                 scoring='roc_auc',\n                                 n_jobs=1,\n                                 cv=5,\n                                 verbose=3\n                                )","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:27:00.522591Z","iopub.execute_input":"2021-08-11T13:27:00.52287Z","iopub.status.idle":"2021-08-11T13:27:00.533773Z","shell.execute_reply.started":"2021-08-11T13:27:00.522839Z","shell.execute_reply":"2021-08-11T13:27:00.532628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Below is the timer function which will calculate how much time is taken by RandomizedSearchCV","metadata":{}},{"cell_type":"code","source":"random_search.fit(X_train_scaled,y_train.ravel())","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:27:00.536195Z","iopub.execute_input":"2021-08-11T13:27:00.536743Z","iopub.status.idle":"2021-08-11T13:27:03.066549Z","shell.execute_reply.started":"2021-08-11T13:27:00.536695Z","shell.execute_reply":"2021-08-11T13:27:03.065755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"estimator = random_search.best_estimator_\nestimator.missing=1\nprint(estimator)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:27:03.069451Z","iopub.execute_input":"2021-08-11T13:27:03.069873Z","iopub.status.idle":"2021-08-11T13:27:03.080021Z","shell.execute_reply.started":"2021-08-11T13:27:03.069836Z","shell.execute_reply":"2021-08-11T13:27:03.078748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_model = estimator","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:27:03.081331Z","iopub.execute_input":"2021-08-11T13:27:03.081698Z","iopub.status.idle":"2021-08-11T13:27:03.0879Z","shell.execute_reply.started":"2021-08-11T13:27:03.081645Z","shell.execute_reply":"2021-08-11T13:27:03.086912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_model.fit(X_train_scaled,y_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:27:03.088925Z","iopub.execute_input":"2021-08-11T13:27:03.089367Z","iopub.status.idle":"2021-08-11T13:27:03.16449Z","shell.execute_reply.started":"2021-08-11T13:27:03.089334Z","shell.execute_reply":"2021-08-11T13:27:03.163314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_predicted = xgb_model.predict(X_test_scaled)\ny_predicted","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:27:03.165627Z","iopub.execute_input":"2021-08-11T13:27:03.166042Z","iopub.status.idle":"2021-08-11T13:27:03.181306Z","shell.execute_reply.started":"2021-08-11T13:27:03.166004Z","shell.execute_reply":"2021-08-11T13:27:03.179548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = cross_val_score(xgb_model,X_train_scaled,y_train.ravel(),cv=10)\nscore","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:27:03.182721Z","iopub.execute_input":"2021-08-11T13:27:03.183127Z","iopub.status.idle":"2021-08-11T13:27:03.849456Z","shell.execute_reply.started":"2021-08-11T13:27:03.183082Z","shell.execute_reply":"2021-08-11T13:27:03.848472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Score obtained after hyper parameter tuning in XgBoost is:\",score.mean())","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:27:03.850854Z","iopub.execute_input":"2021-08-11T13:27:03.851139Z","iopub.status.idle":"2021-08-11T13:27:03.85666Z","shell.execute_reply.started":"2021-08-11T13:27:03.851109Z","shell.execute_reply":"2021-08-11T13:27:03.855631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Below obtained is the classification report","metadata":{}},{"cell_type":"code","source":"target_names = ['class 0', 'class 1']\nprint(classification_report(y_actual, y_predicted, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:27:03.857983Z","iopub.execute_input":"2021-08-11T13:27:03.858311Z","iopub.status.idle":"2021-08-11T13:27:03.87577Z","shell.execute_reply.started":"2021-08-11T13:27:03.858273Z","shell.execute_reply":"2021-08-11T13:27:03.874588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Now, we will calculate mean square error.","metadata":{}},{"cell_type":"code","source":"print(\"The mean squared error is:\",mse(y_actual,y_predicted))","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:27:03.877701Z","iopub.execute_input":"2021-08-11T13:27:03.878256Z","iopub.status.idle":"2021-08-11T13:27:03.885694Z","shell.execute_reply.started":"2021-08-11T13:27:03.878189Z","shell.execute_reply":"2021-08-11T13:27:03.884466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Plotting the confusion matrix below:","metadata":{}},{"cell_type":"code","source":"conf_matrix = confusion_matrix(y_true=y_actual, y_pred=y_predicted)\nfig, ax = plot_confusion_matrix(conf_mat=conf_matrix, figsize=(8,8), cmap=plt.cm.Greens)\nplt.xlabel('Predictions', fontsize=18)\nplt.ylabel('Actuals', fontsize=18)\nplt.title('Confusion Matrix', fontsize=18)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-11T13:27:03.887275Z","iopub.execute_input":"2021-08-11T13:27:03.887674Z","iopub.status.idle":"2021-08-11T13:27:04.023337Z","shell.execute_reply.started":"2021-08-11T13:27:03.887631Z","shell.execute_reply":"2021-08-11T13:27:04.022167Z"},"trusted":true},"execution_count":null,"outputs":[]}]}