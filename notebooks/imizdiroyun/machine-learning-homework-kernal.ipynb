{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/world-happiness/2019.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_mean = sum(data[\"Score\"])/len(data[\"Score\"])\ndata[\"happy\"] = [\"yes\"if i>data_mean else \"no\" for i in data[\"Score\"]] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = [\"green\" if i==\"yes\" else \"red\" for i in data[\"happy\"]]\ncolors","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.plotting.scatter_matrix(data.loc[:, data.columns != 'Country or region '],\n                           c = colors,\n                           figsize = [20,20],\n                           diagonal='hist',\n                           alpha=0.5,\n                           s = 200,\n                           marker = '.',\n                           edgecolor= \"black\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* As you can see when GDP Per Capital, Social Support, Healthy Life Expectancy values increase Score`s value increase too,\n* When Perceptions of Corrpution is higher than 0.2 Score increase, \n* In Social Support value at around 0.8 there are many datas and after 0.8 all datas have high Score,\n* There are no corr between Score and Generosity.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize \ndata1 = data.loc[:, data.columns != 'Country or region ']\nx = np.array(data1.loc[:,'Score']).reshape(-1,1)\ny = np.array(data1.loc[:,'GDP per capita']).reshape(-1,1)\n# Scatter\nplt.figure(figsize=[10,10])\nplt.scatter(x=x,y=y)\nplt.xlabel('Score')\nplt.ylabel('GDP')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LinearRegression\n\n# Score vs GDP\n\nfrom sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nprediction = np.linspace(min(x),max(x)).reshape(-1,1)\nlr.fit(x,y)\npredicted = lr.predict(prediction)\nr2 = lr.score(x,y)\nprint(\"r^2 score: \",r2)\nplt.plot(prediction, predicted, color='black', linewidth=3)\nplt.scatter(x=x,y=y)\nplt.xlabel('Score')\nplt.ylabel('GDP')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Score vs Social support \n\nx = np.array(data1.loc[:,'Score']).reshape(-1,1)\ny = np.array(data1.loc[:,'Social support']).reshape(-1,1)\n\nprediction = np.linspace(min(x),max(x)).reshape(-1,1)\nlr.fit(x,y)\npredicted = lr.predict(prediction)\nr2 = lr.score(x,y)\nprint(\"r^2 score: \",r2)\nplt.plot(prediction, predicted, color='black', linewidth=3)\nplt.scatter(x=x,y=y)\nplt.xlabel('Score')\nplt.ylabel('Social support')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Score vs Healthy life expectancy \n\nx = np.array(data1.loc[:,'Score']).reshape(-1,1)\ny = np.array(data1.loc[:,'Healthy life expectancy']).reshape(-1,1)\n\nprediction = np.linspace(min(x),max(x)).reshape(-1,1)\nlr.fit(x,y)\npredicted = lr.predict(prediction)\nr2 = lr.score(x,y)\nprint(\"r^2 score: \",r2)\nplt.plot(prediction, predicted, color='black', linewidth=3)\nplt.scatter(x=x,y=y)\nplt.xlabel('Score')\nplt.ylabel('Healthy life expectancy')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* As you can see, Score vs GDP regression has the highest r^2 point. So it is best for us to use it in linear prediction.\n* But first if we want to predict Overall rank, we should find the LR between Score and Overall rank.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Score vs Overall rank\n\nx = np.array(data1.loc[:,'Score']).reshape(-1,1)\ny = np.array(data1.loc[:,'Overall rank']).reshape(-1,1)\n\nprediction = np.linspace(min(x),max(x)).reshape(-1,1)\nlr.fit(x,y)\npredicted = lr.predict(prediction)\nr2 = lr.score(x,y)\nprint(\"r^2 score: \",r2)\nplt.plot(prediction, predicted, color='black', linewidth=3)\nplt.scatter(x=x,y=y)\nplt.xlabel('Score')\nplt.ylabel('Overall rank')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*  Score vs Overall rank LR has 0.97 r^2 score which is high enough for using it in prediction. We can predict Overall rank from Score correctly","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data['Country or region']=='Cameroon']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*  Let's Test Our Model\n*  Let's Try To Find Cameroon Overall rank from it's GDP. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.array(data1.loc[:,'GDP per capita']).reshape(-1,1)\ny = np.array(data1.loc[:,'Score']).reshape(-1,1)\nlr.fit(x,y)\npredicted = lr.predict([[0.549]])\nprint(\"Cameroon Predicted Score: \", predicted )\n\nx2 = np.array(data1.loc[:,'Score']).reshape(-1,1)\ny2 = np.array(data1.loc[:,'Overall rank']).reshape(-1,1)\n\nlr.fit(x2,y2)\npredicted2 = lr.predict([[4.61710843]])\nprint(\"Cameroon Predicted Overall Rank: \", predicted2 )\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cameroon's real Overall Rank is 96 but our model finds 110. This result is not bad but we should improve our model with other corrs to find more accurate results.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We can use other Regressions to see if we our model can predict better.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Multiple LR\n\n# Score vs GDP & Social Support\n\nx = data.iloc[:,[3,4]].values\ny = data.Score.values.reshape(-1,1)\n\nlr = LinearRegression()\nlr.fit(x,y)\n\nlr.fit(x,y)\npredicted = lr.predict([[0.549,0.91]])\nprint(\"Cameroon Predicted Score: \", predicted )\n\nx2 = np.array(data1.loc[:,'Score']).reshape(-1,1)\ny2 = np.array(data1.loc[:,'Overall rank']).reshape(-1,1)\n\nlr.fit(x2,y2)\npredicted2 = lr.predict([[4.46812163]])\nprint(\"Cameroon Predicted Overall Rank: \", predicted2 )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our model predicted 116 when we add Social Support. As you can see, using only GDP is more accurate then using GDP and Social Support ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Score vs GDP & Healthy life expectancy\n\nx = data.iloc[:,[3,5]].values\ny = data.Score.values.reshape(-1,1)\n\nlr = LinearRegression()\nlr.fit(x,y)\n\nlr.fit(x,y)\npredicted = lr.predict([[0.549,0.331]])\nprint(\"Cameroon Predicted Score: \", predicted )\n\nx2 = np.array(data1.loc[:,'Score']).reshape(-1,1)\ny2 = np.array(data1.loc[:,'Overall rank']).reshape(-1,1)\n\nlr.fit(x2,y2)\npredicted2 = lr.predict([[4.23823909]])\nprint(\"Cameroon Predicted Overall Rank: \", predicted2 )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Our model predicted 125,when we use MLR our model's accuracy decrease, we should try other Regressions,\n* as you can see in scatter_matrix plot above, we don't need to use Polynomial LR,\n* let's try Decision Tree Regression and Random Forest.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data['Country or region']=='Cameroon']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decision Tree Regression\ny = np.array(data1.loc[:,'Score']).reshape(-1,1)\nx = np.array(data1.loc[:,'GDP per capita']).reshape(-1,1)\n\nfrom sklearn.tree import DecisionTreeRegressor\ndt_reg = DecisionTreeRegressor()\ndt_reg.fit(x,y)\n\nprint(\"predicted Score: \",dt_reg.predict([[0.549]]))\n\n\nx = np.array(data1.loc[:,'Score']).reshape(-1,1)\ny = np.array(data1.loc[:,'Overall rank']).reshape(-1,1)\n\ndt_reg.fit(x,y)\n\nprint(\"predicted Overall rank: \",dt_reg.predict([[5.044]]))\n\n# Lets look at DTR's R^2 Score \nfrom sklearn.metrics import r2_score\n\ny = np.array(data1.loc[:,'Score']).reshape(-1,1)\nx = np.array(data1.loc[:,'GDP per capita']).reshape(-1,1)\ndt_reg.fit(x,y)\ny_head = dt_reg.predict(x)\nprint(\"r_square score: \", r2_score(y,y_head))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Our model predicted correct when we use DTR but it has a reason. DTR seperate data to layers. When we give model a value, model remap it with other datas. It can work well if we use it this way but it is hard to train our model with it.\n* Let's try Random Forest.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y = np.array(data1.loc[:,'Score']).reshape(-1,1)\nx = np.array(data1.loc[:,'GDP per capita']).reshape(-1,1)\n\nfrom sklearn.ensemble import RandomForestRegressor\nrf = RandomForestRegressor(n_estimators = 100, random_state=42  )\nrf.fit(x,y)\nprint(\"predicted Score: \",rf.predict([[0.549]]))\n\n\nx = np.array(data1.loc[:,'Score']).reshape(-1,1)\ny = np.array(data1.loc[:,'Overall rank']).reshape(-1,1)\n\nrf.fit(x,y)\nprint(\"predicted Score: \",rf.predict([[5.021]]))\n\n# Lets look at DTR's R^2 Score \nfrom sklearn.metrics import r2_score\n\ny = np.array(data1.loc[:,'Score']).reshape(-1,1)\nx = np.array(data1.loc[:,'GDP per capita']).reshape(-1,1)\ndt_reg.fit(x,y)\ny_head = dt_reg.predict(x)\nprint(\"r_square score: \", r2_score(y,y_head))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Our model predicted correct again.\n* I prefer using Random Forest, it is better then DTR because with RF, it is easier to train a model.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}