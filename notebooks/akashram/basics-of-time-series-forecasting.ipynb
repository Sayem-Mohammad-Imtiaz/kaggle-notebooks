{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](https://f4.bcbits.com/img/a1460053395_10.jpg)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\">\n\n### In this Notebook, we will look at(Theory & Code),\n\n1. Various components of time-series data such as trend, seasonality, cyclical component, and random component. \n\n2. Moving Average, Exponenial Smoothing, Auto-Regressive (AR), Moving Average (MA), and Auto-Regressive Integrated Moving Average (ARIMA) models.\n\n3. Building forecasting models in Python.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# CONTENTS\n\n1. [What is VMAP & ITC](#vitc)\n2. [Components of Time series](#cmp)\n3. [Models](#tc)\n\n   3.1 [Moving Average](#mv)\n   3.2 [Exponential Smoothing](#exps)\n\n4. [Decomposing Time Series](dts)\n\n5. [ARIMA](#arima)\n\n   5.1 [AR Model](#ar)\n   5.2 [MA Model](#ma)\n   5.3 [ARMA](#arma)\n   5.4 [ARIMA](#arimaa)\n\n6. [Summary](#summ)","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nfrom fbprophet import Prophet\nfrom matplotlib import pyplot as plt\nimport plotly.express as px\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nimport warnings\nwarnings.filterwarnings('ignore')\nnp.random.seed(42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Been noticing people go gaga over ITC stock, especially on twitter.\n\n### So, lets look into it","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id=\"vitc\"></a>\n![](https://lh3.googleusercontent.com/proxy/YINfgR9lpvMaA7OkTVtML679-6em_cIsiEa5FQ8mXUFWnHiunYrda0ObEQ7UaUnarDTHa22-LRmvB4-gV82l04q3-YpVf9vtj2WB7Sa6NbR27vSVIg)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n\nITC Limited is an Indian multinational conglomerate company headquartered in Kolkata, West Bengal.\n\nEstablished in 1910 as the Imperial Tobacco Company of India Limited, the company was renamed as the India Tobacco Company Limited in 1970 and later to I.T.C. The Company now stands rechristened to ITC Limited, where 'ITC' is today no longer an acronym or an initialised form.\n\nIt employs over 30,000 people at more than 60 locations across India and is part of Forbes 2000 list.\n\nSource - [Here](https://en.wikipedia.org/wiki/ITC_Limited)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"itc = pd.read_csv(\"/kaggle/input/nifty50-stock-market-data/ITC.csv\")\nitc.set_index(\"Date\", drop=False, inplace=True)\nitc.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'There are {itc.shape[0]} rows and {itc.shape[1]} columns')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\">\n#### Across the following sections, we will consider VMAP as the target variable and look at the basic approaches to forecast that, but first lets look at how it has performed over the years.\n\n#### So What is VWAP? \n\n#### The volume weighted average price (VWAP) is a trading benchmark used by traders that gives the average price a security has traded at throughout the day, based on both volume and price. It is important because it provides traders with insight into both the trend and value of a security. You can read more [here](https://en.wikipedia.org/wiki/Volume-weighted_average_price)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"itcv = itc.VWAP.reset_index()\nfig = px.line(itcv, x=\"Date\", y=\"VWAP\", title='VMAP of ITC over the years')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### There is a sharp decline in 2005. Lets see what happened there.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_vwap = itc[['Date','VWAP']]\ndf_vwap['Date'] = df_vwap['Date'].apply(pd.to_datetime)\ndf_vwap.set_index(\"Date\", inplace = True)\ndf_vwap.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vwap_2005 = df_vwap['2005':'2006']\nvwap_2005 = vwap_2005.reset_index()\nfig = px.line(vwap_2005, x=\"Date\", y=\"VWAP\", title='VMAP of ITC over the years')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n\n### Something happened between Sep 20 and Sep 22nd, 2005.\n\n### So, The Face value had dropped from 10 to 1, and guess the date? Yep, Sep 21, 2005. More on it [here](https://www.moneycontrol.com/company-facts/itc/splits/itc)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\">\n\n<a id=\"cmp\"></a>\n\n### Components of Time-Series Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n\n- The time-series data Y(t) is a random variable, usually collected at regular time intervals and in chronological order.\n- If the time-series data contains observations of just a single variable (such as demand of a product at time t), \nthen it is termed as univariate time-series data. \n\n- If the data consists of more than one variable, \nfor example, demand for a product at time t, price at time t, amount of money spent by the company on promotion at time t, \ncompetitors’ price at time t, etc., then it is called multivariate timeseries data. \n\nA time-series data can be broken into the four following components:\n\n- Trend Component - Trend is the consistent long-term upward or downward movement of the data. \n- Seasonal Component (St): Seasonal component (measured using seasonality index) is the repetitive upward or downward movement (or fluctuations) from the trend that occurs within a calendar year at fixed intervals (i.e., time between seasons is fixed) such as seasons, quarters, months, days of the week, etc. The upward or downward fluctuation may be caused due to festivals, customs within a society,  school holidays, business practices within the market such as “end of season sale”, and so on.\n- Cyclical Component (Ct): Cyclical component is fluctuation around the trend line at random interval \n   (i.e., the time between cycles is random) that happens due to macro-economic changes such as recession, unemployment,\n   etc. Cyclical fluctuations have repetitive patterns with time between repetitions of more than a year.\n   Whereas in the case of seasonality, the fluctuations are observed within a calendar year and are driven by factors such as     festivals and customs that exist in a society. A major difference between seasonal fluctuation and cyclical fluctuation is that seasonal fluctuation occurs at fixed period within a calendar year, whereas cyclical fluctuations have random time between fluctuations. That is, the periodicity of seasonal fluctuations is constant, whereas the periodicity of cyclical fluctuations is not constant.\n- Irregular Component (It): Irregular component is the white noise or random uncorrelated changes that follow a normal distribution with mean value of 0 and constant variance.    ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\">\n\n<a id=\"tc\"></a>\n\n### Forecasting Techniques","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n\nThere are several techniques, the famous ones being;\n    - Moving average, \n    - Exponential smoothing, and \n    - AutoRegressive Integrated Moving Average (ARIMA)\n    \nMoving average and exponential smoothing predict the future value of a time-series data as a function of past observations. \n\nThe regression-based models such as auto-regressive (AR), auto-regressive and moving average (ARMA), \nauto-regressive integrated moving average (ARIMA) use more sophisticated regression models. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n\n<a id=\"mv\"></a>\n\n### Forecasting using Moving Average","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\">\n\nMoving average is one of the simplest forecasting techniques which forecasts the future value of a timeseries data using average (or weighted average) of the past N observations. \n\nForecasted value for time t +1 using the simple moving average is given by\n        \n![](https://github.com/rakash/images1/blob/master/fma.png?raw=true)\n            \nPandas has a function rolling() which can be used with an aggregate function like mean() for calculating moving average for a time window. \n\nFor example, to calculate 12 month’s moving average using last 12 months’ data starting from last month (previous period), rolling() will take a parameter window, which is set to 12 to indicate moving average of 12-months data, and then use Pandas’ shift() function, which takes parameter 1 to specify that the 12-months data should start from last month. \n\nshift(1) means calculating moving average for the specified window period starting from previous observation (in this case last month).\n\n\nHere, we will take data from 2018 April to 2019 April, to forecast VWAP of May 2019 using Moving Average","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"itcv = itc.VWAP.reset_index()\nfig = px.line(itcv, x=\"Date\", y=\"VWAP\", title='VMAP of ITC over the years')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"vwap_itc_2020 = df_vwap['2019-04':'2020-05']\nvwap_itc_2020['mavg_12'] = vwap_itc_2020['VWAP'].rolling(window = 12).mean().shift(1)\npd.set_option('display.float_format', lambda x: '%.2f'% x)\nmayd = vwap_itc_2020.tail(19)\nmayd = mayd.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import plotly.graph_objects as go\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(\n    x=mayd['Date'],\n    y=mayd['VWAP'],\n    name=\"Actual VWAP\"\n))\n\nfig.add_trace(go.Scatter(\n    x=mayd['Date'],\n    y=mayd['mavg_12'],\n    name=\"Moving Average\"\n))\n\nfig.update_layout(\n    title=\"VWAP - Actual vs Moving Average of ITC for the Month of May 2020\",\n    xaxis_title=\"Date\",\n    yaxis_title=\"VWAP\",\n    font=dict(\n        family=\"Courier New, monospace\",\n        size=12,\n        color=\"#7f7f7f\"\n    )\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n\n### Calculating Forecast Accuracy\n\n\nRoot mean square error (RMSE) and mean absolute percentage error (MAPE) are the two most popular accuracy measures of forecasting. We will be discussing these measures in this section.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\">\n\n### Mean Absolute Percentage Error\n\n\nMean absolute percentage error (MAPE) is the average of absolute percentage error.\nAssume that the validation data has n observations and forecasting is carried out on these n observations. \nThe mean absolute percentage error is given by\n\n![](https://github.com/rakash/images1/blob/master/mape.png?raw=true)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_mape(actual, predicted):\n    y_true, y_pred = np.array(actual), np.array(predicted)\n    return np.round( np.mean(np.abs((actual - predicted)/ actual)) * 100, 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_mape(mayd['VWAP'].values, mayd['mavg_12'].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"#### The MAPE in this case is 7.21. So, forecasting using moving average gives us a MAPE of 7.2%. I would say its a decent number. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\">\n\n### Root mean square error (RMSE)\n\nis the square root of average of squared error calculated over the validation dataset, and is the standard deviation of the errors for unbiased estimator.\n\nRMSE is given by\n\n![](https://github.com/rakash/images1/blob/master/rmse.png?raw=true)\n\n\nLower RMSE implies better prediction. However, it depends on the scale of the time-series data.\n\nMSE (Mean Squared Error) can be calculated using mean_squared_error() method in sklearn.metrics.\n\nWe can pass MSE value to np.sqrt() to calculate RMSE.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error \nnp.sqrt(mean_squared_error(mayd['VWAP'].values, mayd['mavg_12'].values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n\n<a id=\"exps\"></a>\n\n### Forecasting using Exponential Smoothing","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\">\n\nOne of the drawbacks of the simple moving average technique is that it gives equal weight to all the previous observations used in forecasting the future value. Exponential smoothing technique (also known as simple exponential smoothing; SES) assigns differential weights to past observations;\n\nEquation:\n\n![](https://github.com/rakash/images1/blob/master/exp.png?raw=true)\n\n\nwhere α is called the smoothing constant, and its value lies between 0 and 1. Ft+1 is the forecasted value at time t + 1 using actual value Yt at time t and forecasted values Ft of time t. But the model applies differential weights to both the inputs using smoothing constant α.\n\n\nThe ewm() method in Pandas provides the features for computing the exponential moving average taking alpha as a parameter.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"vwap_itc_2020['ewm'] = vwap_itc_2020['VWAP'].ewm(alpha = 0.2 ).mean()\npd.set_option('display.float_format', lambda x: '%.2f'% x)\nemayd = vwap_itc_2020.tail(19)\nemayd = emayd.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import plotly.graph_objects as go\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(\n    x=emayd['Date'],\n    y=emayd['VWAP'],\n    name=\"Actual VWAP\"\n))\n\nfig.add_trace(go.Scatter(\n    x=emayd['Date'],\n    y=emayd['ewm'],\n    name=\"Exponential Smoothing\"\n))\n\nfig.update_layout(\n    title=\"VWAP - Actual vs Exponential Smoothing of ITC for the Month of May 2020\",\n    xaxis_title=\"Date\",\n    yaxis_title=\"VWAP\",\n    font=dict(\n        family=\"Courier New, monospace\",\n        size=8,\n        color=\"#7f7f7f\"\n    )\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.graph_objects as go\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(\n    x=emayd['Date'],\n    y=emayd['VWAP'],\n    name=\"Actual VWAP\"\n))\n\n\nfig.add_trace(go.Scatter(\n    x=emayd['Date'],\n    y=emayd['mavg_12'],\n    name=\"Moving Average\"\n))\n\nfig.add_trace(go.Scatter(\n    x=emayd['Date'],\n    y=emayd['ewm'],\n    name=\"Exponential Smoothing\"\n))\n\nfig.update_layout(\n    title=\"VWAP - Actual vs vs Moving Average vs Exponential Smoothing of ITC for the Month of May 2020\",\n    xaxis_title=\"Date\",\n    yaxis_title=\"VWAP\",\n    font=dict(\n        family=\"Courier New, monospace\",\n        size=8,\n        color=\"#7f7f7f\"\n    )\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### IMPORTANT: Moving average and Exponential smoothing assume a fairly steady time-series data with no significant trend, seasonal or cyclical components, that is, the data is stationary.\n\n#### However, many dataset will have trend and seasonality.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n\n<a id=\"dts\"></a>\n\n### DECOMPOSING TIME SERIES","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\">\n\nThe time-series data can be modelled as addition or product of trend, seasonality, cyclical, and irregular components.\nThe additive time-series model is given by \n\n        Yt = Tt + St + Ct + It\n\nThe additive models assume that the seasonal and cyclical components are independent of the trend component.\nAdditive models are not very common, since in many cases the seasonal component may not be independent of the trend. \n\nA small example:\n\nThe seasonality effect on sales during festival times like Diwali does not result in constant increase in sales over the years. For example, the increase in sales of cars during festival season is not just 100 units every year. The seasonality effect has a multiplicative effect on sales based on the trend over the years like 10% additional units based on the trend in the current year. So, in many cases the seasonality effect is multiplied with the trend and not just added as in additive model. \n\nThe multiplicative time-series model is given by\n\n        Yt = Tt × St × Ct × It\n        \n \n \nFor decomposing a time-series data, we can leverage the following libraries:\n1. statsmodel.tsa provides various features for time-series analysis. \n2. seasonal_decompose() in statsmodel.tsa.seasonal decomposes a time series into trend, seasonal, and residuals. It takes frequency parameters; for example, the frequency is 12 for monthly data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"vwap_itc_20201 = vwap_itc_2020.reset_index()\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n\n# Multiplicative Decomposition \nresult_mul = seasonal_decompose(vwap_itc_2020['VWAP'], model='multiplicative', extrapolate_trend = 'freq', freq=12)\n\n# Additive Decomposition\nresult_add = seasonal_decompose(vwap_itc_2020['VWAP'], model='additive', extrapolate_trend = 'freq', freq=12)\n\n# Plot\nplt.rcParams.update({'figure.figsize': (10,10)})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Multiplicative Decompose","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"result_mul.plot().suptitle('Multiplicative Decompose', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Additive Decompose","execution_count":null},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"result_add.plot().suptitle('Additive Decompose', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n\n### Extracting only the seasonal and trend component for the last 1 year","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"vwap_itc_2020['mul_seasonal'] = result_mul.seasonal\nvwap_itc_2020['mul_trend'] = result_mul.trend\n\nvwap_itc_2020['add_seasonal'] = result_add.seasonal\nvwap_itc_2020['add_trend'] = result_add.trend","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n\n### Visualizing Trend and Seasonal Component for the last year of ITC VWAP","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import plotly.graph_objects as go\nfig = go.Figure()\n\nvwap_itc_2020d = vwap_itc_2020.reset_index()\n\nfig.add_trace(go.Scatter(\n    x=vwap_itc_2020d['Date'],\n    y=vwap_itc_2020d['mul_seasonal'],\n    name=\"Multiplicative Seasonal Component\"\n))\n\nfig.add_trace(go.Scatter(\n    x=vwap_itc_2020d['Date'],\n    y=vwap_itc_2020d['add_seasonal'],\n    name=\"Additive Seasonal Component\"\n))\n\nfig.update_layout(\n    title=\"Seasonal Component\",\n    xaxis_title=\"Date\",\n    yaxis_title=\"VWAP\",\n    font=dict(\n        family=\"Courier New, monospace\",\n        size=12,\n        color=\"#7f7f7f\"\n    )\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import plotly.graph_objects as go\nfig = go.Figure()\n\nvwap_itc_2020d = vwap_itc_2020.reset_index()\n\nfig.add_trace(go.Scatter(\n    x=vwap_itc_2020d['Date'],\n    y=vwap_itc_2020d['mul_trend'],\n    name=\"Multiplicative Trend\"\n))\n\nfig.add_trace(go.Scatter(\n    x=vwap_itc_2020d['Date'],\n    y=vwap_itc_2020d['add_trend'],\n    name=\"Additive Trend\"\n))\n\nfig.update_layout(\n    title=\"Trend Component\",\n    xaxis_title=\"Date\",\n    yaxis_title=\"VWAP\",\n    font=dict(\n        family=\"Courier New, monospace\",\n        size=12,\n        color=\"#7f7f7f\"\n    )\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n\n<a id=\"arima\"></a>\n\n### AUTO-REGRESSIVE INTEGRATED MOVING AVERAGE MODELS","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\">\n\nAuto-regressive (AR) and moving average (MA) models are popular models that are frequently used for forecasting.\nAR and MA models are combined to create models such as auto-regressive moving average (ARMA) and auto-regressive\nintegrated moving average (ARIMA) models. \n\nARMA models are basically regression models. \n\nAuto-regression simply means regression of a variable on itself measured at different time periods. We will discuss each component in the subsequent sections.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n\n<a id=\"ar\"></a>\n\n### AR Models","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\">\n\nAuto-regression is a regression of a variable on itself measured at different time points. Auto-regressive model with lag 1,\nAR (1), is given by\n\n\n![](https://github.com/rakash/images1/blob/master/ar1.png?raw=true)\n\nThe above equation can be generalized to include p lags and is called a AR(p) model. The Equation can be re-written as;\n\n\n![](https://github.com/rakash/images1/blob/master/ar2.png?raw=true)\n\n\nwhere et+1 is a sequence of uncorrelated residuals assumed to follow the normal distribution with zero mean and constant standard deviation. \n\n(Yt − m) can be interpreted as a deviation from mean value m; it is known as mean centered series.\n\nOne of the important tasks in using the AR model in forecasting is model identification, which is, identifying the value of p (the number of lags). \n\nOne of the standard approaches used for model identification is using\n    - auto-correlation function (ACF) and \n    - partial auto-correlation function (PACF)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n\n### ACF","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\">\n\nAuto-correlation of lag k is the correlation between Yt and Yt–k measured at different k values \n(e.g., Yt and Yt−1 or Yt and Yt−2). \n\nA plot of auto-correlation for different values of k is called an auto-correlation function \n(ACF) or correlogram. \n\n#### statsmodels.graphics.tsaplots.plot_acf plots the autocorrelation plot.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n\n### PACF","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\">\n\nPartial auto-correlation of lag k is the correlation between Yt and Yt−k when the influence of all \nintermediate values (Yt−1, Yt−2, …, Yt−k+1) is removed (partial out) from both Yt and Yt−k. \n\nA plot of partial auto-correlation for different values of k is called partial auto-correlation function (PACF). \n\nstatsmodels.graphics.tsaplots.plot_pacf plots the partial auto-correlation plot.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n\n<a id=\"arma\"></a>\n\n### Building an ARMA MODEL","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#ACF plot to show auto-correlation upto lag of 20\n    \nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nplt.rcParams.update({'figure.figsize': (10,6)})\nacf_plot = plot_acf(vwap_itc_2020d.VWAP, lags=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The shaded area represents the upper and lower bounds for critical values, where the null hypothesis cannot be\nrejected (auto-correlation value is 0). ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams.update({'figure.figsize': (10,6)})\n\nacf_plot = plot_pacf(vwap_itc_2020d.VWAP, lags=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\">\n\nTo select the appropriate p in the AR model, the following thumb rule can be used:\n\n1. The partial auto-correlation is significant for first p-values (first p lags) and cuts off to zero.\n\n2. The ACF decreases exponentially. (Signs of stationarity).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n\n#### Building an AR Model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\">\n\nstatsmodels.tsa.arima_model.ARIMA can be used to build AR model.\n\nIt takes the following two parameters:\n\n1. endog: list of values – It is the endogenous variable of the time series. \n\n2. order: The (p, d, q) – ARIMA model parameters. Order of AR is given by the value p, the order of integration is d, and the order of MA is given by q.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.arima_model import ARIMA\narima = ARIMA(vwap_itc_2020.VWAP[0:265].astype(np.float64), order = (1,0,0))\narima1 = ARIMA(vwap_itc_2020.VWAP[0:265].astype(np.float64), order = (0,0,0))\nar_model = arima.fit()\nar_model1 = arima1.fit()\nar_model.summary2()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n\n### Forecasting and measuring accuracy","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast_arima = ar_model.predict(265, 283)\nforecast_arima1 = ar_model1.predict(265, 283)\n\nget_mape(vwap_itc_2020.VWAP[265:285].values, forecast_arima.values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### A little higher than the moving average Mape value","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Forecast with P = 0 ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"get_mape(vwap_itc_2020.VWAP[265:285].values, forecast_arima1.values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n\n<a id=\"ma\"></a>\n\n### Building an MA Model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\">\n\nMA processes are regression models in which the past residuals are used for forecasting future values of the time-series data. \n\nA moving average process of lag 1 can be written as\n\n\n![](https://github.com/rakash/images1/blob/master/ma1.png?raw=true)\n\nThe value of q (number of lags) in a moving average process can be identified using the following rules:\n\n1. Auto-correlation value is significant for first q lags and cuts off to zero. \n\n2. The PACF decreases exponentially. \n\nBuilding a baseline with q=1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"arima = ARIMA(vwap_itc_2020.VWAP[0:265].astype(np.float64), order = (0,0,1))\nma_model = arima.fit()\nma_model.summary2()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast_arima = ma_model.predict(265, 283)\n\nget_mape(vwap_itc_2020.VWAP[265:285].values, forecast_arima.values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The mape is high","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n\n<a id=\"arma\"></a>\n\n### Building the ARMA Model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\">\n\nAuto-regressive moving average (ARMA) is a combination auto-regressive and moving average process. \nARMA(p, q) process combines AR(p) and MA(q) processes.\nThe values of p and q in an ARMA process can be identified using the following thumb rules:\n    \n1. Auto-correlation values are significant for first q values (first q lags) and cuts off to zero. \n2. Partial auto-correlation values are significant for first p values and cuts off to zero.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"arima = ARIMA(vwap_itc_2020.VWAP[0:265].astype(np.float64), order = (1,0,1)) \narma_model = arima.fit() \narma_model.summary2()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast_arma = arma_model.predict(265, 283)\nget_mape(vwap_itc_2020.VWAP[265:285].values, forecast_arma.values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### The Mape seems to be the same as AR(1) model. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n\n<a id=\"arimaa\"></a>\n\n### ARIMA Model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\">\n\nARMA models can be used only when the time-series data is stationary. \nARIMA models are used when the time-series data is non-stationary. \nTime-series data is called stationary if the mean, variance, and covariance are constant over time. \n\n\nARIMA has the following three components and is represented as ARIMA (p, d, q): \n1. AR component with p lags AR(p). \n2. Integration component (d). \n3. MA with q lags, MA(q).\n\n\nThe main objective of the integration component is to convert a non-stationary time-series process to a stationary process so that the AR and MA processes can be used for forecasting.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n\n#### What is Stationary data?\n\nTime-series data should satisfy the following conditions to be stationary: \n    \n1. The mean values of Yt at different values of t are constant. \n2. The variances of Yt at different time periods are constant (Homoscedasticity). \n3. The covariance of Yt and Yt−k for different lags depend only on k and not on time t.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n### Finding if a series is Stationary","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\">\n\nTo find out if a time series is stationary, Dickey−Fuller test can also be conducted.\n\nDickey–Fuller test checks whether the b in the equation in AR model section above is equal to 1 or less than equal to 1. \n\nEquation: ![](https://github.com/rakash/images1/blob/master/ar1.png?raw=true)\n\nIt is a hypothesis test in which the null hypothesis and alternative hypothesis are given by,\n\nH0: b = 1 (the time series is non-stationary)\nHA: b < 1 (the time series is stationary)\n    \nstatsmodels.tsa.stattools.adfuller is a Dicky−Fuller test and returns test statistics and p-value for the test of the null hypothesis.\n\nIf the p-value is less than 0.05, the time series is stationary.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.stattools import adfuller\n\ndef adfuller_test(ts): \n    adfuller_result = adfuller(ts, autolag=None)\n    adfuller_out = pd.Series(adfuller_result[0:4],\n                             index=['Test Statistic', 'p-value', 'Lags Used', 'Number of Observations Used'])\n    print(adfuller_out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"adfuller_test(vwap_itc_2020.VWAP)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\">\n\nThe p-value (>0.05) indicates that we cannot reject the null hypothesis and hence, the series is not stationary. \n\nDifferencing the original time series is an usual approach for converting the non-stationary process into a stationary process (called difference stationarity). \n\nFor example, the first difference (d = 1) is the difference between consecutive values of the time series (Yt). That is, the first difference is given by\n\n![](https://github.com/rakash/images1/blob/master/dk1.png?raw=true)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n\n### Differencing","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\">\n\nFirst difference between consecutive Yt values can be computed by subtracting the previous day’s value from that day’s value.\n\nWe can use shift() function in Pandas to shift the values before subtracting. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"vwap_itc_2020['vdiff'] = vwap_itc_2020.VWAP - vwap_itc_2020.VWAP.shift(1)\nvwap_itc_2020.head(5)\nvwap_itc_2020 = vwap_itc_2020.dropna()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n\n### Plotting the first-order difference values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.graph_objects as go\nfig = go.Figure()\n\nvwap_itc_20201 = vwap_itc_2020.reset_index()\n\nfig.add_trace(go.Scatter(\n    x=vwap_itc_20201['Date'],\n    y=vwap_itc_20201['vdiff'],\n    name=\"First-Order Differencing\"\n))\n\nfig.update_layout(\n    xaxis_title=\"Date\",\n    yaxis_title=\"First-order difference\",\n    font=dict(\n        family=\"Courier New, monospace\",\n        size=12,\n        color=\"#7f7f7f\"\n    )\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The ACF plot for the same","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pacf_plot = plot_acf(vwap_itc_20201.vdiff.dropna(), lags=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n\n### We build a basic arima model with d=1(first-order differencing)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"arima = ARIMA(vwap_itc_2020.VWAP[0:265].astype(np.float64), order = (1,1,1)) \narima_model = arima.fit()\narima_model.summary2()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n### Forecasting using the d component","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"predict, stderr, ci = arima_model.forecast(steps=7)\nget_mape(vwap_itc_2020.VWAP[265:285].values, predict)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\">\n### So, The ARIMA model with first-order differencing gives forecast accuracy of ~10%.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n\n<a id=\"summ\"></a>\n\n### Summary:\n\n1. Several techniques such as moving average, exponential smoothing, and auto-regressive models are used for forecasting future value of Yt. \n\n2. The forecasting models are mostly validated using accuracy measures such as RMSE and MAPE. \n\n3. Auto-regressive (AR) models are regression-based models in which dependent variable is Yt and the independent variables are Yt−1, Yt−2, etc. \n\n4. AR models can be used only when the data is stationary.\n\n5. Moving average (MA) models are regression models in which the independent variables are past error values. \n\n6. Auto-regressive integrated moving average (ARIMA) has three components: \n    a. Auto-regressive component with p lags − AR(p) \n    b. Moving average component with q lags − MA(q) \n    c. Integration which is differencing the original data to make it stationary (denoted by d)","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\">\n\n### End of Basics - Will add more approaches(ARIMAX/SARIMAX, NN's) to this notebook. Do upvote! ","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}