{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Audi Prices","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Hi! I'm new to ML so feel free to give any advice or feedback!\nI inspired some feature engineering code from Gireesh https://www.kaggle.com/gireeshs/volkswagen-price-regression-r-2-0-9555 Kernel","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**The objective of the analysis is to compare different regression algorithms to predict in the best way the selling price of Audi cars, given different variables**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"*Importing packages*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split # Train-test split\nfrom sklearn.preprocessing import MinMaxScaler # Scaling data\nfrom sklearn.feature_selection import SelectKBest, f_regression # NÂ° variables\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.svm import SVR\n\nimport warnings\nwarnings.filterwarnings('ignore') # Ignoring sklearn warnings\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nsns.set()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.read_csv('../input/used-car-dataset-ford-and-mercedes/audi.csv')\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The dataset has:**\n\n- 5 numerical columns: Price, mileage, tax, mpg and EngineSize.\n- 3 categorical columns: Model, transmission and FuelType\n- 1 date column: year","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Getting to know the data**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"*How are the cars distributed by the registration year?*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(dataset['year'], bins = 10, color = 'orange', label = 'KDE')\nplt.legend()\nplt.gcf().set_size_inches(12, 5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*How many models are in the set?*\n*How many types of transmission?*\n*How many types of fuel?*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(dataset.model.unique())\nprint('--'* 50)\n\nprint(dataset.transmission.unique())\nprint('--'* 50)\n\nprint(dataset.fuelType.unique())\nprint('--'* 50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax =plt.subplots(1,2, sharey = True)\nplt.gcf().set_size_inches(12, 5)\nsns.countplot(dataset['fuelType'], ax = ax[0])\nsns.countplot(dataset['transmission'], ax = ax[1])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**So there are just 3 types of transmission and 3 types of fuel, it seems there are many models.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Model = pd.DataFrame(dataset['model'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x = Model.index, y = Model['model'])\n\nlabels = Model.index.tolist()\nplt.gcf().set_size_inches(15, 7)\n\nplt.title('Models vs quantity', fontsize = 20)\nplt.xlabel('Model', fontsize = 15)\n\nplt.xticks(ticks = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15] , labels = labels, rotation = 'vertical')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Price analysis*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(dataset.corr(), annot = True, linewidths=.5, cmap='cubehelix')\nplt.title('Correlation', fontsize = 20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**All the variables except 'tax' are strong predictors for the car price. Also, there is surely a correlation between the model, fuel type and transmission, so later on we will do some OHE for those variables** ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"f, (ax1, ax2) = plt.subplots(1, 2, sharey = True)\n\nplt.gcf().set_size_inches(15, 7)\nax1.plot(dataset.mileage, dataset.price, c = 'green')\nax1.set_title('Mileage vs. Price', c = 'green', fontsize = 25)\nax2.scatter(dataset.engineSize, dataset.price, c='red')\nax2.set_title('Engine size vs. Price', c ='red', fontsize = 25)\n\nplt.ylabel('Price', fontsize = 25)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**There are clear correlations:**\n\n- The price goes down as the car has more mileage (it might be really worn out).\n- The price goes up as the engine size gets bigger. There are some cars that do not follow this tendency, so we should assume that the different models have an impact on the price.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"*Preparing the data for the model*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset2 = dataset.copy()\ndataset2 = dataset2[['model','year','transmission','mileage','fuelType','tax','mpg','engineSize','price']]\ndataset2.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**OHE for model, transmission and fuel type**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_audi_D = pd.get_dummies(dataset2)\ndata_audi_D.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**To avoid multicollinearity issues, I'll drop one column for model, one for transmission, and one from fuel type.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_audi_D = data_audi_D.drop(['model_ A1', 'transmission_Automatic', 'fuelType_Diesel'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Scaling the data**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"MinMaxScaler = MinMaxScaler() \ndata_audi_D_Scaled = MinMaxScaler.fit_transform(data_audi_D)\ndata_audi_D_Scaled = pd.DataFrame(data_audi_D_Scaled, columns = data_audi_D.columns)\ndata_audi_D_Scaled.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Separating variables**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(data_audi_D_Scaled.drop(columns = ['price']),\n                                                    data_audi_D_Scaled[['price']],\n                                                    test_size = 0.2, random_state = 0)\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*There are 35 independent variables*","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Selecting the best features for the regression with SelectKBest, f_regression**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"column_names = data_audi_D_Scaled.drop(columns = ['price']).columns\n\nno_of_features = []\nr_squared_train = []\nr_squared_test = []\n\nfor k in range(3, 35, 2): # From 3 to 35 variables (every single one)\n    selector = SelectKBest(f_regression, k = k)\n    X_train_transformed = selector.fit_transform(X_train, y_train)\n    X_test_transformed = selector.transform(X_test)\n    regressor = LinearRegression()\n    regressor.fit(X_train_transformed, y_train)\n    no_of_features.append(k)\n    r_squared_train.append(regressor.score(X_train_transformed, y_train))\n    r_squared_test.append(regressor.score(X_test_transformed, y_test))\n    \nsns.lineplot(x = no_of_features, y = r_squared_train, legend = 'full')\nsns.lineplot(x = no_of_features, y = r_squared_test, legend = 'full')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*We get a steable curve from 27 variables on, so that is the amount of variables I'm using*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Doing the same as above but only with k = 27\n\nselector = SelectKBest(f_regression, k = 27)\nX_train_transformed = selector.fit_transform(X_train, y_train)\nX_test_transformed = selector.transform(X_test)\ncolumn_names[selector.get_support()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Linear Modeling**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def regression_model(model):\n    \"\"\"\n    Will fit the regression model passed and will return the regressor object and the score\n    \"\"\"\n    regressor = model\n    regressor.fit(X_train_transformed, y_train)\n    score = regressor.score(X_test_transformed, y_test) # R2\n    return regressor, score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_performance = pd.DataFrame(columns = [\"Features\", \"Model\", \"Score\"])\n\nmodels_to_evaluate = [LinearRegression(), Ridge(), Lasso(), SVR(), RandomForestRegressor(), MLPRegressor()]\n\nfor model in models_to_evaluate:\n    regressor, score = regression_model(model)\n    model_performance = model_performance.append({\"Features\": \"Linear\",\"Model\": model, \"Score\": score}, ignore_index=True)\n\nmodel_performance","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Polynomial Modelling**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"*Transforming X variable*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"poly = PolynomialFeatures()\nX_train_transformed_poly = poly.fit_transform(X_train)\nX_test_transformed_poly = poly.transform(X_test)\n\nprint(X_train_transformed_poly.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"no_of_features = []\nr_squared = []\n\nfor k in range(10, 400, 5): # Seeing what happens up to 400 variables\n    selector = SelectKBest(f_regression, k = k)\n    X_train_transformed = selector.fit_transform(X_train_transformed_poly, y_train)\n    regressor = LinearRegression()\n    regressor.fit(X_train_transformed, y_train)\n    no_of_features.append(k)\n    r_squared.append(regressor.score(X_train_transformed, y_train))\n    \nsns.lineplot(x = no_of_features, y = r_squared)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*We get a steable curve from 250 variables on, so that is the amount of variables I'm using*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"selector = SelectKBest(f_regression, k = 250)\n\nX_train_transformed = selector.fit_transform(X_train_transformed_poly, y_train)\nX_test_transformed = selector.transform(X_test_transformed_poly)\n\nmodels_to_evaluate = [LinearRegression(), Ridge(), Lasso(), SVR(), RandomForestRegressor(), MLPRegressor()]\n\nfor model in models_to_evaluate:\n    regressor, score = regression_model(model)\n    model_performance = model_performance.append({\"Features\": \"Polynomial\",\"Model\": model, \"Score\": score}, ignore_index=True)\n\nmodel_performance","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The maximum score is 0.96 with RandomForest polynomial regression**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Predictions with RandomForest polynomial regression**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"regressor_final = RandomForestRegressor(n_estimators = 1000, random_state = 42)\nregressor.fit(X_train_transformed_poly, y_train)\n\ny_pred = regressor.predict(X_test_transformed_poly)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = y_test.reset_index() # To join the Dataframes\n\n\ny_pred_df = pd.DataFrame({'Price_prediction': y_pred.flatten()})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Comparison = y_test.join(y_pred_df) \nComparison = Comparison.drop(['index'], axis=1)\nComparison.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Fifty_comparison = Comparison.head(50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Fifty_comparison.plot(kind = 'bar', figsize=(20,15))\nplt.grid(which = 'both', linestyle = '-', linewidth = '0.5', color = 'green')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thanks for reaching the end!","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}