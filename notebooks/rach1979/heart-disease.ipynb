{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%reset -f\n\n# Call data manipulation libraries\nimport pandas as pd\nimport numpy as np\n\n# Feature creation libraries\nfrom sklearn.random_projection import SparseRandomProjection as sr  # Projection features\nfrom sklearn.cluster import KMeans                    # Cluster features\nfrom sklearn.preprocessing import PolynomialFeatures  # Interaction features\n\n#  For feature selection\n# Ref: http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import mutual_info_classif  # Selection criteria\n\n# Data processing\n# 1.4.1 Scaling data in various manner\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, scale\n# 1.4.2 Transform categorical (integer) to dummy\nfrom sklearn.preprocessing import OneHotEncoder\n\n# Splitting data\nfrom sklearn.model_selection import train_test_split\n\n#  Decision tree modeling\n# http://scikit-learn.org/stable/modules/classes.html#module-sklearn.tree\n# http://scikit-learn.org/stable/modules/tree.html#tree\nfrom sklearn.tree import  DecisionTreeClassifier as dt\n\n# 1.7 RandomForest modeling\nfrom sklearn.ensemble import RandomForestClassifier as rf\n\n# 1.8 Plotting libraries to plot feature importance\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# 1.9 Misc\nimport os, time, gc","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":" #Read train/test files\nheart = pd.read_csv(\"../input/heart.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4baec69020a789d88ae1a6821980dceffa5541ec"},"cell_type":"code","source":"heart.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d7a3c8e23bcf04c199a2132014fd8d6dd4ad4f8"},"cell_type":"code","source":"heart.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2492886efef26f60fc49a44672b67ccdac7a0270"},"cell_type":"code","source":"#  Split into Test and Training Data\nX_train, X_test, y_train, y_test = train_test_split(\n        heart.drop('target', 1), \n        heart['target'], \n        test_size = 0.3, \n        random_state=10\n        ) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0e695bb243904d735d4744bb1430acac6b0d6b30"},"cell_type":"code","source":"# Look at data\nX_train.head(2)\nX_train.shape                        # 212 x 13\nX_test.shape                         # 91 x 13","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb1d159df6b2a61a03ef6b4af7c25616931cfe86"},"cell_type":"code","source":"y_test.shape                        # 91 x \ny_train.shape                       # 212 x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6179b813ea9202c17d0abe83d99198287882abfb"},"cell_type":"code","source":"# Data types\nX_train.dtypes.value_counts()   # All afeatures are integer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa96d1c2ad48b327af1a334bf9afece93117ea33"},"cell_type":"code","source":"# 2.4 Target classes are almost balanced\nheart.target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fefc50a8283f207691c44281a3068162ebb55b62"},"cell_type":"code","source":"##Feature Engineering##\n\n## i)   Shooting in dark. These features may help or may not help\n## ii)  There is no exact science as to which features will help","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3dc45be164e0c25cbe7ae38a41f51a1c57d5f713"},"cell_type":"code","source":"##Using Statistical Numbers##\n\n#   Feature 1: Row sums of features 1:13. More successful\n#                when data is binary.\n\nX_train['sum'] = X_train.sum(numeric_only = True, axis=1)  # numeric_only= None is default\nX_test['sum'] = X_test.sum(numeric_only = True,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e585f8837c473e1e04fd400e6de36920b31a354d"},"cell_type":"code","source":"#  Assume that value of '0' in a cell implies missing feature\n#     Transform train and test dataframes\n#     replacing '0' with NaN\n#     Use pd.replace()\ntmp_train = X_train.replace(0, np.nan)\ntmp_test = X_test.replace(0,np.nan)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec389a1a86a3cfc1abdb8ba0ff69c52a89bdb54f"},"cell_type":"code","source":"# Check if tmp_train is same as train or is a view\n#     of train? That is check if tmp_train is a deep-copy\n\ntmp_train is X_train                # False\ntmp_train._is_view                # False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"223dc244ce9a7a15980ef76361920c1e170cd8a9"},"cell_type":"code","source":"#  Check if 0 has been replaced by NaN\ntmp_train.head(1)\ntmp_test.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6abc559bd535e8a55f57a68cd56e8cd463b9af4c"},"cell_type":"code","source":"# 5. Feature 2 : For every row, how many features exist\n#                that is are non-zero/not NaN.\n#                Use pd.notna()\ntmp_train.notna().head(1)\nX_train[\"count_not0\"] = tmp_train.notna().sum(axis = 1)\nX_test['count_not0'] = tmp_test.notna().sum(axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e0e94af43eb204e15467a70cce79b1f4f0c880e2"},"cell_type":"code","source":"# 6. Similary create other statistical features\n#    Feature 3\n#    Pandas has a number of statistical functions\n#    Ref: https://pandas.pydata.org/pandas-docs/stable/reference/frame.html#computations-descriptive-stats\n\nfeat = [ \"var\", \"median\", \"mean\", \"std\", \"max\", \"min\"]\nfor i in feat:\n    X_train[i] = tmp_train.aggregate(i,  axis =1)\n    X_test[i]  = tmp_test.aggregate(i,axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8a4b510c0a5b01204aa1192275741f3e469ea578"},"cell_type":"code","source":"# 7 Delete not needed variables and release memory\ndel(tmp_train)\ndel(tmp_test)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"351623187b0b7dfabedb72a3d386784536efda0d"},"cell_type":"code","source":"# 7.1 So what do we have finally\nX_train.shape                \nX_train.head(1)\nX_test.shape                 \nX_test.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"430e844e07f8ba2ab82fff00069f7847d51e0f9d"},"cell_type":"code","source":"# 8. Before we proceed further, keep target feature separately\ntarget = y_train\ntarget.tail(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a28f631b766600ee5775ce9d50e8b846495777e"},"cell_type":"code","source":"# 9. Store column names of our data somewhere\n#     We will need these later (at the end of this code)\ncolNames = X_train.columns.values\ncolNames","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"30dd2628fcf172e8006bc471c265fc9542b3eef9"},"cell_type":"code","source":"##Feature creation Using Random Projections##\n\n# 10. Random projection is a fast dimensionality reduction feature\n#     Also used to look at the structure of data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d8e6e304cc1cfafad8c0a0d5f7d3efffb7edd316"},"cell_type":"code","source":"# 11. Generate features using random projections\n#     First stack train and test data, one upon another\ntmp = pd.concat([X_train,X_test],\n                axis = 0,            # Stack one upon another (rbind)\n                ignore_index = True\n                )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88e604915929b7b135d3f85c03507dc0b7e0b349"},"cell_type":"code","source":"tmp.shape     # 303 X 21","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"99c4612d21ad48fb152ce1557537a4e2c1ac0773"},"cell_type":"code","source":"# 12.2 Transform tmp t0 numpy array\n#      Henceforth we will work with array only\ntmp = tmp.values\ntmp.shape       # 303 X 21","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e901fc6b4568ad80fe393650bf2ce8e6d45de4d"},"cell_type":"code","source":"# 13. Let us create 8 random projections/columns\n#     This decision, at present, is arbitrary\nNUM_OF_COM = 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ee11369b96b71d0c63e7fedf0dc63bd75fc4ee6"},"cell_type":"code","source":"# 13.1 Create an instance of class\nrp_instance = sr(n_components = NUM_OF_COM)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2092f91a1d7b8fcaefdea41f5295d11a5b97d1d0"},"cell_type":"code","source":"# 13.2 fit and transform the (original) dataset\n#      Random Projections with desired number\n#      of components are returned\nrp = rp_instance.fit_transform(tmp[:, :13])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8d9388498477c0e80e5926a885df10eeb2981b4"},"cell_type":"code","source":"# 13.3 Look at some features\nrp[: 5, :  3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c330b63e24f0a71a262667a0d0c750019f562eb9"},"cell_type":"code","source":"# 13.4 Create some column names for these columns\n#      We will use them at the end of this code\nrp_col_names = [\"r\" + str(i) for i in range(8)]\nrp_col_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c65bbad1ef6152ab8cd94d3be7945bc56bb480d"},"cell_type":"code","source":"##Feature creation using kmeans##\n\n# 14. Before clustering, scale data\n# 15.1 Create a StandardScaler instance\nse = StandardScaler()\n# 15.2 fit() and transform() in one step\ntmp = se.fit_transform(tmp)\n# 15.3\ntmp.shape               # 303 X 21 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"620119f804035d65831b31ea516f3b8635c8407f"},"cell_type":"code","source":"# 16. Perform kmeans using 13 features.\n#     No of centroids is no of classes in the 'target'\ncenters = target.nunique()    # 2 unique classes\ncenters    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7332657370e564a9acc6d0bcc3b91e7acf98d1dc"},"cell_type":"code","source":"# 17.1 Begin clustering\nstart = time.time()\n\n# 17.2 First create object to perform clustering\nkmeans = KMeans(n_clusters=centers, # How many clusters\n                n_jobs = 4)         # Parallel jobs for n_init\n\n# 17.3 Next train the model on the original data only\nkmeans.fit(tmp[:, : 13])\n\nend = time.time()\n(end-start)/60.0  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"35525fbf166176eeb20b0d99f398d9fa5052a8d9"},"cell_type":"code","source":"# 18 Get clusterlabel for each row (data-point)\nkmeans.labels_\nkmeans.labels_.size   # 303","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f0184bac8623fc902c7cced61124ec2d66451efe"},"cell_type":"code","source":"# 19. Cluster labels are categorical. So convert them to dummy\n\n# 19.1 Create an instance of OneHotEncoder class\nohe = OneHotEncoder(sparse = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"920d2e0341ea4b68e2b5ebd6b3d449771532d46f"},"cell_type":"code","source":"# 19.2 Use ohe to learn data\n#      ohe.fit(kmeans.labels_)\nohe.fit(kmeans.labels_.reshape(-1,1))     # reshape(-1,1) recommended by fit()\n                                          # '-1' is a placeholder for actual","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f9c7de343ad44b8d163d008e5ee62a4518284a2e"},"cell_type":"code","source":"# 19.3 Transform data now\ndummy_clusterlabels = ohe.transform(kmeans.labels_.reshape(-1,1))\ndummy_clusterlabels\ndummy_clusterlabels.shape    # 303 X 2 (as many as there are classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d503c083aa48b33743fe6eb797d2564aebc110ee"},"cell_type":"code","source":"# 19.4 We will use the following as names of new two columns\n#      We need them at the end of this code\n\nk_means_names = [\"k\" + str(i) for i in range(2)]\nk_means_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d0637cc1f955023b14fec13fc74444f2f0155b8"},"cell_type":"code","source":"##Creating Interaction features##\n##Using Polynomials##\n\n# 21. Will require lots of memory if we take large number of features\n#     Best strategy is to consider only impt features\n\ndegree = 2\npoly = PolynomialFeatures(degree,                 # Degree 2\n                          interaction_only=True,  # Avoid e.g. square(a)\n                          include_bias = False    # No constant term\n                          )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c6fdf064fcf619c0bca0f0e6974483befae8041"},"cell_type":"code","source":"# 21.1 Consider only first 8 features\n#      fit and transform\ndf =  poly.fit_transform(tmp[:, : 8])\n\n\ndf.shape     # 303 X 36","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2e181b3ab7c543cd1a4e665cf6657b2617023072"},"cell_type":"code","source":"# 21.2 Generate some names for these 36 columns\npoly_names = [ \"poly\" + str(i)  for i in range(36)]\npoly_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd4b48c2ec2e3c6aac83a17c977865e5173791f1"},"cell_type":"code","source":"##concatenate all features now##\n\n# 22 Append now all generated features together\n# 22 Append random projections, kmeans and polynomial features to tmp array\n\ntmp.shape          # 303 X 21","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d846b9418f5c207dcf61b6e6aac6974d9d94ebd5"},"cell_type":"code","source":"#  22.1 If variable, 'dummy_clusterlabels', exists, stack kmeans generated\n#       columns also else not. 'vars()'' is an inbuilt function in python.\n#       All python variables are contained in vars().\n\nif ('dummy_clusterlabels' in vars()):               #\n    tmp = np.hstack([tmp,rp,dummy_clusterlabels, df])\nelse:\n    tmp = np.hstack([tmp,rp, df])       # No kmeans      <==\n\n\ntmp.shape          # 303 X 64","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e40efaf15cd698f210934379d5e3b6796d6efe1e"},"cell_type":"code","source":"# 22.1 Combine train and test into X and y to split compatible datasets\nX = tmp\nX.shape        # 303 X 64","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4aec5632b9d4b3c8a3e9cdb93c159390a3f4a20c"},"cell_type":"code","source":"# 22.2 Combine y_train and y_test into y to split into compatible datasets later\ny = pd.concat([y_train,y_test],\n                axis = 0,            # Stack one upon another (rbind)\n                ignore_index = True\n                )\ny.shape        # 303,","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e1f260db7e2cb9b3a8f6dd7f6f666916c996cfd5"},"cell_type":"code","source":"# 22.3 Delete tmp - as a good programming practice\ndel tmp\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"02c2444b73723032fd268d8c3f99707b8a62b075"},"cell_type":"code","source":"###Model building###\n\n# 23. Split the feature engineered data into new training and test dataset\nX_train, X_test, y_train, y_test = train_test_split(\n                                                    X,\n                                                    y,\n                                                    test_size = 0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9522db9ddf5e0bde395a484936ce29ce16e0f37c"},"cell_type":"code","source":"##we now have the following data for model creation and testing\n###X_train: Training Data with new features\n\n####y_train: expected output for training data\n\n#####X_test: test data with new features\n\n#######y_test: expected output for test data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"36468ac87b91f84145f4101845bb8b82699684d8"},"cell_type":"code","source":"X_train.shape    # 212 X 64","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88129d99bf9f3a61d4f0fed1db046cdce9417986"},"cell_type":"code","source":"X_test.shape     # 91 X 64","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c04884b2cea5afe6ac8b8ca7650f61eae00b3898"},"cell_type":"code","source":"# 24 Decision tree classification\n# 24.1 Create an instance of class\nclf1_dt = dt(min_samples_split = 5,\n         min_samples_leaf= 3\n        )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a31923895f2abf871895f115c3d68ef516f468ef"},"cell_type":"code","source":"start = time.time()\n# 24.2 Fit/train the object on training data\n#      Build model\nclf1_dt = clf1_dt.fit(X_train, y_train)\nend = time.time()\n(end-start)/60      ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6085d0e3bc10254e9afa4be6364f49ee2315ce9f"},"cell_type":"code","source":"# 24.3 Use model to make predictions\nclasses1_dt = clf1_dt.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"43bc8938d442c4c47686a7d01b919479da34dcf9"},"cell_type":"code","source":"# 24.4 Check accuracy\n(classes1_dt == y_test).sum()/y_test.size    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f6bcd3ae08c45e61b39a8abff679f6a916d6f1c7"},"cell_type":"code","source":"# 25. Instantiate RandomForest classifier\nclf1_rf = rf(n_estimators=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2dc4bd0ed8dfb779dcbcec0b015dfcb7e2d2c79e"},"cell_type":"code","source":"# 25.1 Fit/train the object on training data\n#      Build model\n\nstart = time.time()\nclf1_rf = clf1_rf.fit(X_train, y_train)\nend = time.time()\n(end-start)/60         ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec716177fe61faafbc7b17d5a290e4fb8cda5d47"},"cell_type":"code","source":"# 25.2 Use model to make predictions\nclasses1_rf = clf1_rf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a5220d7ea48aca5f066543660012cba51fa36e7"},"cell_type":"code","source":"# 25.3 Check accuracy\n(classes1_rf == y_test).sum()/y_test.size   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e3f02668e80bcffc3871f78d63785104cf7e831b"},"cell_type":"code","source":"#Get feature importance\nclf1_rf.feature_importances_        # Column-wise feature importance\nclf1_rf.feature_importances_.size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60aa08ff58661677a0b1b8ca20643889108b615a"},"cell_type":"code","source":"#  To our list of column names, append all other col names\n#      generated by random projection, kmeans (onehotencoding)\n#      and polynomial features\n#      But first check if kmeans was used to generate features\n\nif ('dummy_clusterlabels' in vars()):       # If dummy_clusterlabels labels are defined\n    colNames = list(colNames) + rp_col_names+ k_means_names + poly_names\nelse:\n    colNames = colNames = list(colNames) + rp_col_names +  poly_names      # No kmeans      <==\n\n#  So how many columns?\nlen(colNames)     ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}