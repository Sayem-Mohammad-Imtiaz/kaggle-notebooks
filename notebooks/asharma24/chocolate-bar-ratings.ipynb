{"cells":[{"metadata":{"_uuid":"22a99c25-edd4-410a-b51d-34060baff029","_cell_guid":"c6a16ef7-3ab1-4a27-8639-b599b08cbb57","trusted":true},"cell_type":"code","source":"#!/usr/bin/env python\n# coding: utf-8\n\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport numpy as np \nimport pandas as pd\nimport warnings \n\nget_ipython().run_line_magic('matplotlib', 'inline')\n\nwarnings.filterwarnings('ignore')\n\ndef display_all(df):\n    with pd.option_context(\"display.max_rows\", 100, \"display.max_columns\", 100):\n        display_all(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cacao = pd.read_csv(\"../input/chocolate-bar-ratings/flavors_of_cacao.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cacao.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cacao.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hmmm Let's fix the column names...\ncacao.columns = cacao.columns.str.replace(\"\\n\", ' ', regex=True)\ncacao.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#One more column to fix \ncacao = cacao.rename(columns={\"Company\\xa0 (Maker-if known)\": \"Company\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cacao.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for nulls \ncacao.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cacao[\"Bean Type\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's just fill na with the mode...\ncacao[\"Bean Type\"] = cacao[\"Bean Type\"].fillna(\"Trinitario\")\ncacao[\"Bean Type\"].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cacao[\"Broad Bean Origin\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's fill na with the mode again...\ncacao[\"Broad Bean Origin\"] = cacao[\"Broad Bean Origin\"].fillna(\"Venezuela\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ok cool looks like no na values \ncacao.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in cacao.columns: \n    print(cacao[column].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploration","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explore the dataset -> check distribution of Chocolate Rating (Approximately Normal)\nplt.figure(figsize=(12,5))\n\nsns.distplot(cacao[\"Rating\"], bins=15)\n\nplt.xlabel(\"Rating\", fontsize=17)\nplt.title(\"Chocolate Rating Distribution\", fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cacao[\"Cocoa Percent\"] = cacao[\"Cocoa Percent\"].apply(lambda x: int(str(x)[:2]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cacao[\"Cocoa Percent\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,5))\n\nsns.distplot(cacao[\"Cocoa Percent\"], bins=20)\n\nplt.xlabel(\"Cocoa Percent\", fontsize=17)\nplt.title(\"Cocoa Percent Distribution\", fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,5))\n\nsns.distplot(cacao[\"Review Date\"], bins=12)\n\nplt.xlabel(\"Review Date\", fontsize=17)\nplt.title(\"Review Date Distribution\", fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check distribution of Target (Ratings)\n\nplt.figure(figsize=(12,5))\n\nsns.countplot(x=\"Rating\", data=cacao, palette='hls')\n\nplt.ylabel(\"Count\")\nplt.xlabel(\"Rating\")\nplt.title(\"Distribution of Chocolate Rating\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Target is to place them into five categories \ndef fix_ratings(rating):\n    if rating < 0.5: \n        return 0.0 \n    elif rating < 1.5: \n        return 1.0 \n    elif rating < 2.5: \n        return 2.0\n    elif rating < 3.5: \n        return 3.0\n    elif rating < 4.5: \n        return 4.0 \n    elif rating < 5.5: \n        return 5.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cacao[\"Rating\"] = cacao[\"Rating\"].apply(lambda x: fix_ratings(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,5))\n\nsns.countplot(x=\"Rating\", data=cacao, palette='hls')\n\nplt.xlabel(\"Rating\", fontsize=17)\nplt.ylabel(\"Count\", fontsize=17)\nplt.title(\"Rating by Count\", fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = cacao.drop(\"Rating\", axis=1)\ny = cacao[\"Rating\"].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cacao.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nohe = OneHotEncoder(handle_unknown=\"ignore\")\nohe.fit(X_train)\nX_train_enc = ohe.transform(X_train)\nX_test_enc = ohe.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder \nle = LabelEncoder()\nle.fit(y_train)\ny_train_enc = le.transform(y_train)\ny_test_enc = le.transform(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import np_utils\ny_train_cat = np_utils.to_categorical(y_train_enc)\ny_test_cat = np_utils.to_categorical(y_test_enc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler(with_mean=False)\nsc.fit(X_train_enc)\nX_train_enc_sc = sc.transform(X_train_enc)\nX_test_enc_sc = sc.transform(X_test_enc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_enc_sc.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_cat.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating holdout set to test on never seen before data (about 25%)\nholdout = int(.25 * X_train_enc_sc.shape[0])\nx_val = X_train_enc_sc[:holdout]\npartial_x_train = X_train_enc_sc[holdout:]\ny_val = y_train_cat[:holdout]\npartial_y_train = y_train_cat[holdout:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import layers\nfrom keras import models\nfrom keras import regularizers\nfrom keras import optimizers\n\nmodel = models.Sequential()\n\nmodel.add(layers.Dense(8, activation='relu', input_dim=X_train_enc.shape[1], \n                       kernel_regularizer=regularizers.l2(0.001)))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(5, activation='softmax'))\n\n# sgd = optimizers.SGD(lr = 0.01, momentum = 0.9)\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = model.fit(partial_x_train, partial_y_train, validation_data=(x_val, y_val),\n                    batch_size=64, epochs=25, verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_dict = history.history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_dict.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_loss = history_dict[\"loss\"]\nval_loss = history_dict[\"val_loss\"]\n\nepochs = range(1, len(training_loss) + 1)\n\nplt.plot(epochs, training_loss, 'bo', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_acc = history_dict['accuracy']\nval_acc = history_dict['val_accuracy']\n\nepochs = range(1, len(val_acc) + 1)\n\nplt.plot(epochs, training_acc, 'bo', label=\"Training Accuracy\")\nplt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's evaluate...\nscores = model.evaluate(X_test_enc_sc, y_test_cat, batch_size=128)\nprint(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is it for today. Appreciate any advice, recommendations, or feedback on how I could improve. One thought is that I perhaps may be overfitting at just around 8 epochs. Neural Networks seem to be overkill for this problem as I had a very simple layer (just 8 hidden units). But of course I could be wrong here so would love to hear any couterarguments,etc. Thanks!","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}