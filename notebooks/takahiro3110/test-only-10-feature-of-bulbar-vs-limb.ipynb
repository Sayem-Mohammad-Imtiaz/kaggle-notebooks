{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport random as rnd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble  import HistGradientBoostingClassifier\n#from sklearn.ensemble  import HistGradientBoostingRegressor\nfrom lightgbm import LGBMClassifier\nimport lightgbm as lgb\nfrom  warnings import simplefilter\nfrom sklearn.exceptions import ConvergenceWarning\nsimplefilter(\"ignore\", category=ConvergenceWarning)","metadata":{"_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('bulbar_vs_limb:\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/end-als/end-als/transcriptomics-data/DESeq2/bulbar_vs_limb.csv\")\ntrain","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****Sample number is only 112****","metadata":{}},{"cell_type":"code","source":"train['SiteOnset_Class'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = train.drop(['SiteOnset_Class','Participant_ID'], axis=1)\ny_train = train[\"SiteOnset_Class\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SVM = SVC()\nRF = RandomForestClassifier()\nLR = LogisticRegression()\nHGBC = HistGradientBoostingClassifier()\nLGB= LGBMClassifier()\n\nscores = []\nmodelnames = ['HistGradient','SVM','RandumForest','LightGBM','LogisticRegression']\nmodels = [HGBC,SVM,RF,LGB,LR]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in models:\n    score = cross_val_score(i, X_train, y_train, scoring = 'accuracy' , cv = 5).mean()\n    scores.append(score)\n\npd.DataFrame(scores, index=modelnames,\n            columns=['CV Scores']).sort_values(by = 'CV Scores', ascending = False)    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import cohen_kappa_score, mean_squared_error\nfrom sklearn.metrics import mean_squared_error as MSE\nfrom sklearn.metrics import mean_absolute_error as MAE\n\n#score_calc = 'neg_mean_absolute_error'\n#score_calc = 'r2'\n#score_calc = 'neg_mean_squared_log_error'\nscore_calc = 'accuracy'","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param_grid_lgb = { 'max_depth':[-1],\n             # 'min_samples_leaf':[5],\n             # 'num_leaves':[80],\n             # 'min_child_samples' :[3],\n             # 'learning_rate'  :[0.02],\n             # 'max_bin':[265],\n            # 'num_iterations':[300],\n            #  \"feature_fraction\": [0.5], \n            #  \"bagging_freq\": 1,\n           #  \"bagging_fraction\": [0.1] ,\n              \"seed\":[42] ,\n           #   'min_data_in_leaf': [50],\n            # 'neg_bagging_fraction':[0.2],\n            #  'reg_alpha': [0.05],\n           #   'reg_lambda': [0.1],   \n                 } ","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_searchlog_lgb = GridSearchCV(LGB, param_grid_lgb, cv =5, scoring = score_calc)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_searchlog_lgb.fit(X_train, y_train)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#LGB SCORE\n#print(grid_searchlog_lgb.score(X_train, y_train))\nprint(grid_searchlog_lgb.best_params_)\nprint(grid_searchlog_lgb.best_score_)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimised_lgb = grid_searchlog_lgb.best_estimator_","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****TOP30 Feature importance from LGBM ****","metadata":{}},{"cell_type":"code","source":"lgb.plot_importance(optimised_lgb, figsize=(12, 8),max_num_features = 30,)\n#plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****Use top 10 Feature****","metadata":{}},{"cell_type":"code","source":"X_train2 = train[[\"CROCC2\",\"NBPF3\",\"MEFV\",\"AC005597.1\",\"AC015910.1\",\"AC090617.7\",\"AL137804.1\",\"PKMP4\",\"ENSG00000266701\",\"CALB2\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train2","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores2 = []\nfor i in models:\n    score2 = cross_val_score(i, X_train2, y_train, scoring = 'accuracy' , cv = 5).mean()\n    scores2.append(score2)\n\npd.DataFrame(scores2, index=modelnames,\n            columns=['CV Scores']).sort_values(by = 'CV Scores', ascending = False)    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"grid_searchlog_lgb.fit(X_train2, y_train)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#LGB SCORE\n#print(grid_searchlog_lgb.score(X_train, y_train))\nprint(grid_searchlog_lgb.best_params_)\nprint(grid_searchlog_lgb.best_score_)","metadata":{"_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimised_lgb = grid_searchlog_lgb.best_estimator_","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb.plot_importance(optimised_lgb, figsize=(12, 8),max_num_features = 10,)\n","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****Check the 10 features histgram****","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom pylab import rcParams\n\nrcParams['figure.figsize'] = 10, 10 \n\nX_train2.hist(); \n\nplt.tight_layout() \n\nplt.show() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****Check corrmat****","metadata":{}},{"cell_type":"code","source":"X_train2['SiteOnset_Class'] = train['SiteOnset_Class']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corrmat = x = X_train2.corr()\nk = 11\ncols = corrmat.nlargest(k, 'SiteOnset_Class')['SiteOnset_Class'].index\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\ncm = np.corrcoef(x = X_train2[cols].values.T)\n\nsns.set(font_scale=1.25)\n\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}