{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!pip install torchsummary\nimport pandas as pd\nimport numpy as np\nimport os\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport cv2 \nfrom torchsummary import summary\nimport time\nfrom sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/bee-vs-wasp/kaggle_bee_vs_wasp/labels.csv',index_col =False)\nfor i in data.index:\n    data['path'].iloc[i] = data['path'].iloc[i].replace('\\\\', '/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le = LabelEncoder()\nle.fit(data['label'])\ndata['label'] = le.transform(data['label'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[:100]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_img = data[data['is_validation']==1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(valid_img.label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_valid = data[data['is_final_validation']==1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(final_valid.label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_img = data[(data['is_validation']==0) & (data['is_final_validation']==0)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(train_img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"w = train_img[:4]\ndir = '/kaggle/input/bee-vs-wasp/kaggle_bee_vs_wasp'\nlis = w['path'].tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nfor iterator,filename in enumerate(lis):\n    images = Image.open(os.path.join(dir,filename))\n    plt.subplot(4,2,iterator+1)\n    plt.imshow(images,cmap=plt.cm.bone)\n    \nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_img.label = valid_img.label.astype(np.int64)\nfinal_valid.label = final_valid.label.astype(np.int64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nfrom torchvision import datasets,transforms,models\nfrom torch.utils.data import Dataset,DataLoader\nimport torch.nn as nn\nfrom torch.optim import Adam,SGD\n\ntrain_transform = transforms.Compose([transforms.ToPILImage(),\n                                     transforms.RandomResizedCrop(224),\n                                     transforms.RandomHorizontalFlip(),\n                                     transforms.ToTensor(),\n                                     transforms.Normalize([0.485,0.456,0.406],[0.229,0.225,0.224])])\n\nvalid_transform = transforms.Compose([transforms.ToTensor(),\n                                     transforms.Normalize([0.485,0.456,0.406],[0.229,0.225,0.224])])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class BeeDataset(Dataset):\n    def __init__(self, df:pd.DataFrame, imgdir:str, train:bool,\n                 transforms=None):\n        self.df = df\n        self.imgdir = imgdir\n        self.train = train\n        self.transforms = transforms\n    \n    def __getitem__(self, index):\n        im_path = os.path.join(self.imgdir, self.df.iloc[index][\"path\"])\n        x = cv2.imread(im_path)\n        x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n        x = cv2.resize(x, (224, 224))\n\n        if self.transforms:\n            x = self.transforms(x)\n        \n        if self.train:\n            y = self.df.iloc[index][\"label\"]\n            return x, y\n        else:\n            return x\n    \n    def __len__(self):\n        return len(self.df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net,self).__init__()\n        self.model = models.resnet18(pretrained = True)\n        self.model.fc = nn.Linear(512,4)\n    def forward(self,x):\n        output = self.model(x)\n        return output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(valid_img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_img.label = train_img.label.astype(np.int64)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = BeeDataset(df =train_img,imgdir = '/kaggle/input/bee-vs-wasp/kaggle_bee_vs_wasp',train=True,\n                          transforms = train_transform)\nvalid_dataset = BeeDataset(df =valid_img,imgdir = '../input/bee-vs-wasp/kaggle_bee_vs_wasp',train=True,\n                          transforms = valid_transform)\ntest_dataset = BeeDataset(df =final_valid,imgdir = '../input/bee-vs-wasp/kaggle_bee_vs_wasp',train=True,\n                          transforms = valid_transform)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu' )\nprint(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\n\narch = Net()\narch.to(device)\n    \noptim = torch.optim.SGD(arch.parameters(),lr = 1e-3,momentum =0.9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader = DataLoader(dataset = train_dataset,shuffle = True,batch_size=32,num_workers = 4)\nvalid_loader = DataLoader(dataset = valid_dataset,shuffle = True,batch_size=32,num_workers = 4)\ntest_loader  = DataLoader(dataset = test_dataset, shuffle = True,batch_size=32,num_workers = 4)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"summary(model = arch, input_size = (3, 224, 224),batch_size =32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model,optimizer,n_epochs,criterion):\n    start_time = time.time()\n    for epoch in range(1,n_epochs-1):\n        epoch_time = time.time()\n        epoch_loss = 0\n        correct = 0\n        total = 0\n        print( \"Epoch {}/{}\".format(epoch,n_epochs))\n        \n        model.train()\n        \n        for inputs,labels in train_loader:\n            inputs = inputs.to(device)\n            \n            labels  = (labels).to(device)\n            optimizer.zero_grad()\n            output = model(inputs)\n            loss = criterion(output,labels)\n            loss.backward()\n            optimizer.step()\n            epoch_loss +=loss.item()\n            _,pred =torch.max(output,1)\n            correct += (pred.cpu()==labels.cpu()).sum().item()\n            total +=labels.shape[0]\n            \n        acc = correct/total\n        \n        model.eval()\n        a= 0\n        pred_val = 0\n        corr = 0\n        tot = 0\n        \n        with torch.no_grad():\n            for val_inp,val_label in valid_loader:\n                val_inp = val_inp.to(device)\n                val_label = val_label.to(device)\n                out_val = model(val_inp)\n                loss = criterion(out_val,val_label)\n                a += loss.item()\n                _,pred_val = torch.max(out_val,1)\n                corr += (pred_val.cpu()==val_label.cpu()).sum().item()\n                tot = val_label.shape[0]\n            acc_val = corr/tot\n        epoch_time2 = time.time()\n        print(\"Duration : {:.4f},Train Loss :{:.4f},Train Acc :{:.4f}, Valid Loss:{:.4f},Valid acc :{:.4f}\".format(\n        epoch_time2-epoch_time,epoch_loss/len(labels),acc,a/len(val_label),acc_val))\n    end_time= time.time()\n    print(\"Total time :{:.0f}s\".format(end_time - start_time))\n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def eval_model(model):\n    correct = 0\n    total = 0\n    \n    model.eval()\n    with torch.no_grad():\n        for images,label in test_loader:\n            images = images.to(device)\n            label = label.to(device)\n            output = model(images)\n            _, pred = torch.max(output,1)\n            correct += (pred == label).sum().item()\n            total += label.shape[0]\n    print(\"The accuracy in Test dataset is %d %%\" %(100*correct/total))\n            \n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_model(model=arch, optimizer=optim, n_epochs=20, criterion=criterion)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eval_model(arch)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}