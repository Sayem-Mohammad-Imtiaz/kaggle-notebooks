{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# First try at Movie Recommendation System.\n\nMy first try at mmakking a movie recommendation sysytem.\n\nWith the rise in Data collection the use of Recommendation System has become very frequent.\n\nRecommendation Systems are a type of **information filtering** system as they **improve** the **quality of search**.\n\nRatings are used to predict the preferences of  a viewer.\n\nAmazon uses such sysytems to recommend products to its customers.\n\nAnd the USP of both Netflix and Spotify is their recommendation engines.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# TYPES OF RECOMENDER SYSTEMS:\n* Collaborative Recommender system\n* Content-based recommender system\n* Demographic based recommender system\n* Utility based recommender system\n* Knowledge based recommender system \n* Hybrid recommender system","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Loading Data","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data1=pd.read_csv('../input/tmdb-movie-metadata/tmdb_5000_credits.csv')\ndata2=pd.read_csv('../input/tmdb-movie-metadata/tmdb_5000_movies.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets see whats in data1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data1.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ANd in data2","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data2.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Merging the data sets.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data1.columns=['id','title','cast','crew']\ndata3=data2.merge(data1,on='id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data3.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lets try Content Based Filtering\n\nIt’s mainly classified as an outgrowth and continuation of information filtering research. In this system, the objects are mainly defined by their associated features. A content-based recommender learns a profile of the new user’s interests based on the features present, in objects the user has rated. It’s basically a keyword specific recommender system here keywords are used to describe the items. Thus, in a content-based recommender system the algorithms used are such that it recommends users similar items that the user has liked in the past or is examining currently.\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The way we are going to do this is by using metadata like the Actors,Director,Genre,Plot Keywords","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Parse the stringified features into their corresponding python objects\nfrom ast import literal_eval\nfeatures = ['cast', 'crew', 'keywords', 'genres']\nfor feature in features:\n    data3[feature] = data3[feature].apply(literal_eval)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#geting the name of the director\ndef director(n):\n    for i in n:\n        if i['job']==\"Director\":\n            return i['name']\n    return np.nan\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create a function to return only 3 elements\ndef get_list(x):\n    if isinstance(x, list):\n        names = [i['name'] for i in x]\n        #Check if more than 3 elements exist. If yes, return only first three. If no, return entire list.\n        if len(names) > 3:\n            names = names[:3]\n        return names\n\n    #Return empty list in case of missing/malformed data\n    return []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#defining new director,cast,crew,keyword features\ndata3['director']=data3['crew'].apply(director)\nfeatures = ['cast', 'crew', 'keywords', 'genres']\nfor feature in features:\n    data3[feature] = data3[feature].apply(get_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking the new features\ndata3[['title_x','director','cast','crew','keywords','genres']].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to convert all strings to lower case and strip names of spaces\ndef clean_data(x):\n    if isinstance(x, list):\n        return [str.lower(i.replace(\" \", \"\")) for i in x]\n    else:\n        #Check if director exists. If not, return empty string\n        if isinstance(x, str):\n            return str.lower(x.replace(\" \", \"\"))\n        else:\n            return ''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply clean_data function to your features.\nfeatures = ['cast', 'keywords', 'director', 'genres']\n\nfor feature in features:\n    data3[feature] = data3[feature].apply(clean_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are now in a position to create our \"metadata soup\", which is a string that contains all the metadata that we want to feed to our vectorizer (namely actors, director and keywords).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def meta_soup(x):\n    return ' '.join(x['keywords']) + ' ' + ' '.join(x['cast']) + ' ' + x['director'] + ' ' + ' '.join(x['genres'])\ndata3['soup'] = data3.apply(meta_soup, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We use the **CountVectorizer()** instead of **TF-IDF**. This is because we do not want to down-weight the presence of an actor/director if he or she has acted or directed in relatively more movies. It doesn't make much intuitive sense","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\ncount = CountVectorizer(stop_words='english')\ncount_matrix = count.fit_transform(data3['soup'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compute the Cosine Similarity matrix based on the count_matrix\nfrom sklearn.metrics.pairwise import cosine_similarity\n\ncosine_sim = cosine_similarity(count_matrix, count_matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data3 = data3.reset_index()\nindices = pd.Series(data3.index, index=data3['title_y'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we create the recommendation function","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function that takes in movie title as input and outputs most similar movies\ndef get_recommendations(title, cosine_sim=cosine_sim):\n    # Get the index of the movie that matches the title\n    idx = indices[title]\n\n    # Get the pairwsie similarity scores of all movies with that movie\n    sim_scores = list(enumerate(cosine_sim[idx]))\n\n    # Sort the movies based on the similarity scores\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n\n    # Get the scores of the 10 most similar movies\n    sim_scores = sim_scores[1:11]\n\n    # Get the movie indices\n    movie_indices = [i[0] for i in sim_scores]\n\n    # Return the top 10 most similar movies\n    return data3['title_x'].iloc[movie_indices]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_recommendations(\"Spectre\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_recommendations(\"Apocalypse Now\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_recommendations(\"Before Sunrise\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let's try Collaborative Filtering\n\nThe content based engine suffers from some severe limitations. It is only capable of suggesting movies which are close to a certain movie. That is, it is not capable of capturing tastes and providing recommendations across genres.\n\n**Content-based** approach requires a good amount of information of items’ own features, rather than using users’ interactions and feedbacks. For example, it can be movie attributes such as genre, year, director, actor etc., or textual content of articles that can extracted by applying Natural Language Processing. **Collaborative Filtering**, on the other hand, doesn’t need anything else except users’ historical preference on a set of items. Because it’s based on historical data, the core assumption here is that the users who have agreed in the past tend to also agree in the future. In terms of user preference, it usually expressed by two categories. **Explicit Rating**, is a rate given by a user to an item on a sliding scale, like 5 stars for Titanic. This is the most direct feedback from users to show how much they like an item. Implicit Rating, suggests users preference indirectly, such as page views, clicks, purchase records, whether or not listen to a music track, and so on. In this article, I will take a close look at collaborative filtering that is a traditional and powerful tool for recommender systems.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**User Based Collaborative Filtering**\nWe have an n × m matrix of ratings, with user uᵢ, i = 1, ...n and item pⱼ, j=1, …m. Now we want to predict the rating rᵢⱼ if target user i did not watch/rate an item j. The process is to calculate the similarities between target user i and all other users, select the top X similar users, and take the weighted average of ratings from these X users with similarities as weights.\n![](https://miro.medium.com/max/700/1*mM089Lta5X6zkUkULcO9aA.png)\n\nWhile different people may have different baselines when giving ratings, some people tend to give high scores generally, some are pretty strict even though they are satisfied with items. To avoid this bias, we can subtract each user’s average rating of all items when computing weighted average, and add it back for target user, shown as below.\n![](https://miro.medium.com/max/700/1*gLbwJts3g_v2TbPRhFoNfA.png)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Item-based Collaborative Filtering**\n\nIn Item-based CF, we say two items are similar when they received similar ratings from a same user. Then, we will make prediction for a target user on an item by calculating weighted average of ratings on most X similar items from this user. One key advantage of Item-based CF is the stability which is that the ratings on a given item will not change significantly overtime, unlike the tastes of human beings.\n                        ![](https://miro.medium.com/max/700/1*dPzd5-dScFplypBGeSwgUw.png)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Single Value Decomposition**\n\nOne way to handle the scalability and sparsity issue created by CF is to leverage a latent factor model to capture the similarity between users and items. Essentially, we want to turn the recommendation problem into an optimization problem. We can view it as how good we are in predicting the rating for items given a user. One common metric is Root Mean Square Error (RMSE). The lower the RMSE, the better the performance.\n\nNow talking about latent factor you might be wondering what is it ?It is a broad idea which describes a property or concept that a user or an item have. For instance, for music, latent factor can refer to the genre that the music belongs to. SVD decreases the dimension of the utility matrix by extracting its latent factors. Essentially, we map each user and each item into a latent space with dimension r. Therefore, it helps us better understand the relationship between users and items as they become directly comparable. The below figure illustrates this idea.\n![](https://kevinkolcheck.com/wp-content/uploads/2017/12/latent-factors.png)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"To implement **Single Value Decomposition** were going to use the **surprise** library.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from surprise import Dataset,SVD,Reader\nfrom surprise.model_selection import cross_validate\nreader = Reader()\nratings = pd.read_csv('../input/the-movies-dataset/ratings_small.csv')\nratings.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\nsvd=SVD()\ncross_validate(svd, data, measures=['RMSE', 'MAE'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainset = data.build_full_trainset()\nsvd.fit(trainset)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets see what user no.10 has rated wach movie","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ratings[ratings['userId'] == 10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svd.predict(10, 2995, 3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For movie with ID 2995, we get an estimated prediction of 2.467. One startling feature of this recommender system is that it doesn't care what the movie is (or what it contains). It works purely on the basis of an assigned movie ID and tries to predict ratings based on how the other users have predicted the movie.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}