{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"d7b065a8-ec59-91b4-cf78-3694949fe78e"},"source":"##Analyzing the dataset and a survey of some popular ml techniques applied on it ##"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"676a8410-6785-0c23-3c92-ac3aac0ace97"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn import decomposition\nfrom sklearn import metrics\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cd2518b6-fcd6-9faf-e05c-b3f8849f6118"},"outputs":[],"source":"df1 = pd.read_csv('../input/class.csv')\ndf2 = pd.read_csv('../input/zoo.csv')\nprint(df1.describe())\nprint(df2.describe())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"137f5254-6d25-b142-c8d6-bdc497a6b646"},"outputs":[],"source":"df1.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"072dacd3-912f-074b-4678-b0b671c7a84c"},"outputs":[],"source":"df2.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"29189cd6-f3f2-0b06-f5d5-36d157fdfc8d"},"source":"Seeing the data, class.csv contains the details of the class like mammals, amphibians, etc. alongwith number of animals in this class, its code and the names of the animals\n\nanimal.csv contains the details of the animals in a 1/0 format suggesting if a particular feature like hair / eggs / milk, etc. is present or not alongwith the class type - we actually only need animal.csv to make a prediction"},{"cell_type":"markdown","metadata":{"_cell_guid":"a9bc3758-d5ee-87f5-992e-3532afab76c7"},"source":"## Trying to understand the corelations and PCA within the features ##\nFirst let us try to see if there's any correlation within the attributes and also try to do a PCA"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b697411c-1dc8-dceb-1722-f45c91a0e315"},"outputs":[],"source":"correlation = df2.corr()\nf, ax = plt.subplots(figsize=(9, 9))\nplt.rcParams.update({'font.size': 8})\nsns.heatmap(correlation, vmax=1,annot=True,cmap='cubehelix')"},{"cell_type":"markdown","metadata":{"_cell_guid":"463dce4d-f2a5-37ce-6147-824b3d10e961"},"source":"## Few observations from the heatmap of correlation matrix ##\nThere is a very strong correlation between the following types of features:\n\n 1. Having hair means it is very unlikely that the animal lays eggs & very likely that it gives milk\n 2. Having feathers has a relatively high correlation with the animal being  airborne and low correlation with it having teeth\n 3. If the animal lays eggs, it is **very unlikely** that it gives milk, similar low correlation for having teeth\n 4. If it is aquatic relatively high corrrelation for having fins & so on"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7fc8a53e-8bc9-ac87-a0d7-8a05b1bec8bf"},"outputs":[],"source":"a = df2.iloc[:,1:17].values\nb = df2.iloc[:,17].values\nprint(a[2],b[2])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f9dc9af0-d6a0-0e64-cf2a-94f75ea6d95b"},"outputs":[],"source":"#Classifiying data and target\nX = df2.iloc[:,1:17].values   # Not considering the name of the animal - placing it \ny = df2.iloc[:,17].values     # Class number to be assigned (labels)\n\n# Separating into test and training data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"183e8ee2-8fb4-24a2-128d-ec1b495ad547"},"outputs":[],"source":"# Have to include cross validation here as the sample size is too less"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4295d9f1-6dd8-4a22-8297-1ae52e799f20"},"outputs":[],"source":"b = df2.columns.values\nindex = [0,17]\nfeature_names = np.delete(b,index)\nfeature_names"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e5d83e0d-6d76-625e-81a6-60fef4bc4685"},"outputs":[],"source":"target_names = np.array(df1['Class_Type'])\ntarget_names"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b2c817dc-5e53-0343-92d3-117ff1a4f142"},"outputs":[],"source":"#Standardizing data\n\nfrom sklearn.preprocessing import StandardScaler\nX_std = StandardScaler().fit_transform(X_train)"},{"cell_type":"markdown","metadata":{"_cell_guid":"eb43ff26-a020-b591-63aa-7011836564b8"},"source":"## PCA ##\nTrying to reduce the number of features considered here - with PCA"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"09141d41-4abd-eb15-0757-1648572782ff"},"outputs":[],"source":"#pca = decomposition.PCA(n_components=3)\n#pca.fit(X)\n#X = pca.transform(X)"},{"cell_type":"markdown","metadata":{"_cell_guid":"eab2fef1-c054-0fdf-ab0e-104ed7d0ef32"},"source":"## Trying different models ##\n"},{"cell_type":"markdown","metadata":{"_cell_guid":"3c016af8-f703-1d0d-925e-8108781e7f6e"},"source":"## K-NN ##"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"57de5944-fdb6-b6d9-d22a-591d87e766a1"},"outputs":[],"source":"from sklearn.neighbors import KNeighborsClassifier\n# fit a k-nearest neighbor model to the data\nmodel = KNeighborsClassifier()\nmodel.fit(X_train, y_train)\nprint(model)\n# make predictions\nexpected = y_test\npredicted = model.predict(X_test)\n# summarize the fit of the model\nprint(metrics.classification_report(expected, predicted))\nprint(metrics.confusion_matrix(expected, predicted))"},{"cell_type":"markdown","metadata":{"_cell_guid":"2dfd8cba-f6bc-53dd-eee3-8ca39e0e11c1"},"source":"## Gaussian Naive Bayes ##"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"be019b74-105f-fcc9-8630-dc10fe796e36"},"outputs":[],"source":"# Fitting a Naive Bayes model to the data\nmodel = GaussianNB()\nmodel.fit(X_train, y_train)\n\nprint(model)\n\n# make predictions\nexpected = y_test\npredicted = model.predict(X_test)\n# summarize the fit of the model\nprint(metrics.classification_report(expected, predicted, target_names = target_names))\nprint(metrics.confusion_matrix(expected, predicted))"},{"cell_type":"markdown","metadata":{"_cell_guid":"c9471dbd-e804-30f0-8fe0-f1a4bef39972"},"source":"## SVM ##"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"483509f2-a54f-3c1f-38dd-6571e0836841"},"outputs":[],"source":"from sklearn import svm\nmodel = svm.LinearSVC()\nmodel.fit(X_train, y_train)\n\nprint(model)\n\n# make predictions\nexpected = y_test\npredicted = model.predict(X_test)\n\n# summarize the fit of the model\nprint(metrics.classification_report(expected, predicted, target_names = target_names))\nprint(metrics.confusion_matrix(expected, predicted))"},{"cell_type":"markdown","metadata":{"_cell_guid":"6483d568-08d2-7a38-e2d5-27db264694f4"},"source":"## Decision Trees ##"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7ace045d-d2e8-14c8-417a-1d2fbe244a43"},"outputs":[],"source":"from sklearn.tree import DecisionTreeClassifier\n\nmodel = DecisionTreeClassifier()\nmodel.fit(X_train,y_train)\n\nprint(model)\n\n# make predictions\nexpected = y_test\npredicted = model.predict(X_test)\n# summarize the fit of the model\n\nprint(metrics.classification_report(expected, predicted, target_names = target_names))\nprint(metrics.confusion_matrix(expected, predicted))"},{"cell_type":"markdown","metadata":{"_cell_guid":"216d1b63-7190-0ba2-1a40-538a3b28b522"},"source":"Trying to print the decision tree below:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"947d2b26-e401-7c7b-e7c1-9f7af01339b6"},"outputs":[],"source":"from IPython.display import Image\nfrom sklearn import tree\n#import pydot\nimport pydotplus as pydot\n\ndot_data = tree.export_graphviz(model, out_file=None, \n                         feature_names=feature_names,  \n                         class_names=target_names,  \n                         filled=True, rounded=True,  \n                         special_characters=True)  \n#graph = pydot.graph_from_dot_data(dot_data)  \n#Image(graph.create_png())  "},{"cell_type":"markdown","metadata":{"_cell_guid":"680172df-102d-353e-e28b-aea5746b9a09"},"source":"## Random Forest ##"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"639ce8a0-c032-7367-cfdf-10cf25440a22"},"outputs":[],"source":"from sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier()\nmodel.fit(X_train, y_train)\n\nprint(model)\n\n# make predictions\nexpected = y_test\npredicted = model.predict(X_test)\n# summarize the fit of the model\nprint(metrics.classification_report(expected, predicted, target_names = target_names))\nprint(metrics.confusion_matrix(expected, predicted))"},{"cell_type":"markdown","metadata":{"_cell_guid":"aeb3b8c4-0b36-62f8-e95c-e82a0c9597c5"},"source":"It seems that most models are performing poorly for reptiles and amphibians (Which makes sense as they are kind of similar) lets try looking at the dataset for both of these and try coming up with some form of PCA"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fc6c7ee0-195b-8449-fe8d-c64dc936d600"},"outputs":[],"source":"df3 = df2.loc[df2['class_type'].isin([3,5])]\ndf3"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f6d7fed9-aa97-b669-79e8-a816cf247261"},"outputs":[],"source":"correlation = df3.corr()\nf, ax = plt.subplots(figsize=(9, 9))\nplt.rcParams.update({'font.size': 8})\nsns.heatmap(correlation, vmax=1,annot=True,cmap='cubehelix')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8be9af19-e730-a1ad-5857-e72c36443d14"},"outputs":[],"source":"Applying feature Engineering"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c05e7d40-1bfb-3272-d884-03229d63e8f7"},"outputs":[],"source":"from sklearn.ensemble import ExtraTreesClassifier\nmodel = ExtraTreesClassifier()\nmodel.fit(X, y)\n\n# display the relative importance of each attribute\nprint(\"Importance percentages of each attribute\" + \"\\n\" + \"------------\")\nfor i in range(0,feature_names.shape[0]):\n    print('%s\\t%f' %(feature_names[i],model.feature_importances_[i] * 100) + '%')\n    \nfrom sklearn.feature_selection import RFE\nrfe = RFE(model, 10)\nrfe = rfe.fit(X, y)\n\n# summarize the selection of the attributes\nprint(rfe.support_)\nprint(rfe.ranking_)\n\n# Top 10 features\nprint(\"Selecting the following features:\")\nprint(feature_names[rfe.support_ == True])\n\ndf_new = df2.drop('animal_name',axis=1)\nfor i in feature_names[rfe.support_ == False]:\n    df_new = df_new.drop(i, axis=1)\n    print (\"Removing\", i)\nprint(df_new)\n\n#Classifiying data and target\nX = df_new.iloc[:,0:10].values   # Not considering the name of the animal - placing it \ny = df_new.iloc[:,10].values     # Class number to be assigned (labels)\n\n# Separating into test and training data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)"},{"cell_type":"markdown","metadata":{"_cell_guid":"87d2900a-c072-25cf-bb29-fd4781c01a2a"},"source":"## K-NN ##\n\nFor updated training and test data sets"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"312fe593-952c-6c8e-2c4a-5e2f4b470250"},"outputs":[],"source":"from sklearn.neighbors import KNeighborsClassifier\n# fit a k-nearest neighbor model to the data\nmodel = KNeighborsClassifier()\nmodel.fit(X_train, y_train)\nprint(model)\n# make predictions\nexpected = y_test\npredicted = model.predict(X_test)\n# summarize the fit of the model\nprint(metrics.classification_report(expected, predicted))\nprint(metrics.confusion_matrix(expected, predicted))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5b59d084-c3b9-62cf-19e2-790e44735a52"},"outputs":[],"source":"from sklearn import grid_search\nparameters = {'max_depth':range(3,20)}\nclf = grid_search.GridSearchCV(tree.DecisionTreeClassifier(), parameters, n_jobs=-1)\nclf.fit(X=X, y=y)\ntree_model = clf.best_estimator_\nprint (clf.best_score_, clf.best_params_)"},{"cell_type":"markdown","metadata":{"_cell_guid":"f39bcb2d-e79e-568d-fd5b-9c32c74c53f2"},"source":"## Gaussian Naive Bayes ##\n\nFor dataset with updated features"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d80180b3-f565-29ee-ca6c-705cfbda87ee"},"outputs":[],"source":"# Fitting a Naive Bayes model to the data\nmodel = GaussianNB()\nmodel.fit(X_train, y_train)\n\nprint(model)\n\n# make predictions\nexpected = y_test\npredicted = model.predict(X_test)\n# summarize the fit of the model\nprint(metrics.classification_report(expected, predicted, target_names = target_names))\nprint(metrics.confusion_matrix(expected, predicted))"},{"cell_type":"markdown","metadata":{"_cell_guid":"290bc04a-8998-cdb8-ed12-ecfed311b5ca"},"source":"## SVM ##\nFor dataset with updated features"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a30d59b4-1a82-0c6c-9044-2999c9bfd11b"},"outputs":[],"source":"from sklearn import svm\nmodel = svm.LinearSVC()\nmodel.fit(X_train, y_train)\n\nprint(model)\n\n# make predictions\nexpected = y_test\npredicted = model.predict(X_test)\n\n# summarize the fit of the model\nprint(metrics.classification_report(expected, predicted, target_names = target_names))\nprint(metrics.confusion_matrix(expected, predicted))"},{"cell_type":"markdown","metadata":{"_cell_guid":"b5f103ae-471f-45dd-f58d-f0f2ace40846"},"source":"## Decision Tree ##\nFor dataset with updated features"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"41081482-39b1-ca4f-7142-c1e379ae548d"},"outputs":[],"source":"from sklearn.tree import DecisionTreeClassifier\n\nmodel = DecisionTreeClassifier()\nmodel.fit(X_train,y_train)\n\nprint(model)\n\n# make predictions\nexpected = y_test\npredicted = model.predict(X_test)\n# summarize the fit of the model\n\nprint(metrics.classification_report(expected, predicted, target_names = target_names))\nprint(metrics.confusion_matrix(expected, predicted))"},{"cell_type":"markdown","metadata":{"_cell_guid":"c801a19b-d116-0286-4f9c-d6a1407c22a8"},"source":"##Random Forest##\nFor dataset with updated features"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e7b98e67-9f14-d043-2e6d-be0c3d9fd4d5"},"outputs":[],"source":"from sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier()\nmodel.fit(X_train, y_train)\n\nprint(model)\n\n# make predictions\nexpected = y_test\npredicted = model.predict(X_test)\n# summarize the fit of the model\nprint(metrics.classification_report(expected, predicted, target_names = target_names))\nprint(metrics.confusion_matrix(expected, predicted))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9932580b-b44d-33fc-995c-fa18dffb0adb"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}