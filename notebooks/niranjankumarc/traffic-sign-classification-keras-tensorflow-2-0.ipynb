{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Traffic Sign Classification with Keras and Tensorflow 2.0\n- Kernel is based on the tutorial by **Adrian Rosebrock** at [Pyimagesearch](https://www.pyimagesearch.com/2019/11/04/traffic-sign-classification-with-keras-and-deep-learning/)"},{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\nTraffic sign classification is the process of automatically recognizing traffic signs along the road, including speed limit signs, yield signs, merge signs, etc. Being able to automatically recognize traffic signs enables us to build “smarter cars”.\n\nSelf-driving cars need traffic sign recognition in order to properly parse and understand the roadway. Similarly, “driver alert” systems inside cars need to understand the roadway around them to help aid and protect drivers."},{"metadata":{},"cell_type":"markdown","source":"![](https://www.pyimagesearch.com/wp-content/uploads/2019/11/traffic_sign_classification_dataset.jpg)"},{"metadata":{},"cell_type":"markdown","source":"- The dataset we’ll be using to train our own custom traffic sign classifier is the German Traffic Sign Recognition Benchmark (GTSRB). The GTSRB dataset consists of 43 traffic sign classes and nearly 50,000 images."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nimport numpy as np\nimport os\n\n\n#import tensorflow \nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPooling2D, Activation, Flatten, Dropout\nfrom tensorflow.keras.layers import Dense","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check the tensorflow version\n\ntf.__version__","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#create a custom class to train the model.\n\nclass TrafficSignNet:\n    @staticmethod\n    def build(width, height, depth, classes):\n        model = Sequential()\n        inputShape = (height, width, depth)\n        chanDim = -1\n        \n        #layer: Conv -> RELU -> BN -> POOL\n        model.add(Conv2D(8, (5,5), padding = \"same\", input_shape = inputShape))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis = chanDim))\n        model.add(MaxPooling2D(pool_size = (2,2)))\n        \n        # first set of (CONV => RELU => CONV => RELU) * 2 => POOL\n        model.add(Conv2D(16, (3,3), padding = \"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis = chanDim))\n        model.add(Conv2D(16, (3,3), padding = \"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis = chanDim))\n        model.add(MaxPooling2D(pool_size = (2,2)))\n        \n        # second set of (CONV => RELU => CONV => RELU) * 2 => POOL\n        model.add(Conv2D(32, (3,3), padding = \"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis = chanDim))\n        model.add(Conv2D(32, (3,3), padding = \"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis = chanDim))\n        model.add(Conv2D(32, (3,3), padding = \"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis = chanDim))\n        model.add(MaxPooling2D(pool_size = (2,2)))\n        \n        #FC layers\n        model.add(Flatten())\n        model.add(Dense(128))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization())\n        model.add(Dropout(0.7))\n        \n        #FC layers\n        model.add(Flatten())\n        model.add(Dense(128))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization())\n        model.add(Dropout(0.5))\n        \n        #softmax\n        model.add(Dense(classes))\n        model.add(Activation(\"softmax\"))\n        \n        return model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#create a class object\n\nobjTSN = TrafficSignNet()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import necessary packages\n\nimport matplotlib.pyplot as plt\nplt.style.use(\"seaborn\")\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.metrics import confusion_matrix\nfrom skimage import transform, exposure, io\nimport random\nimport os","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- We can automatically improve image contrast by applying an algorithm called Contrast Limited Adaptive Histogram Equalization (CLAHE), the implementation of which can be found in the scikit-image library.\n\n- Using CLAHE we can improve the contrast of our traffic sign images."},{"metadata":{},"cell_type":"markdown","source":"# Load Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#define a function to load data from disk\n\ndef load_split(basePath, csvPath):\n    #intialize the list of data and labels\n    data = []\n    labels = []\n    \n    # load the contents of the CSV file, remove the first line (since it contains the CSV header)\n    rows = open(csvPath).read().strip().split(\"\\n\")[1:]\n    random.shuffle(rows)\n    \n    #loop over the rows of csv file\n    for (i, row) in enumerate(rows):\n        #check to see if we should show a status update\n        if i > 0 and i % 4000 == 0:\n            print(\"[INFO] processed {} total images\".format(i))\n            \n        # split the row into components and then grab the class ID and image path\n        (label, imagePath) = row.strip().split(\",\")[-2:]\n        \n        # derive the full path to the image file and load it\n        imagePath = os.path.sep.join([basePath, imagePath])\n        #print(imagePath)\n        image = io.imread(imagePath)\n        \n        #resize the image to be 32x32 pixels, ignoring aspect ratio, and perform CLAHE.\n        image = transform.resize(image, (32, 32))\n        image = exposure.equalize_adapthist(image, clip_limit = 0.1)\n        \n        #update the list of data and labels, respectively\n        data.append(image)\n        labels.append(int(label))\n        \n    #convert the data and labels into numpy arrays\n    data = np.array(data)\n    labels = np.array(labels)\n    \n    #return a tuple of the data and labels\n    return (data, labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#initialize the hyperparameters\nNUM_EPOCHS = 50\nINIT_LR = 1e-3\nBS = 64\n\n#load the label names\nlabelNames = ['20 km/h', '30 km/h', '50 km/h', '60 km/h', '70 km/h', '80 km/h', '80 km/h end', '100 km/h', '120 km/h', 'No overtaking',\n               'No overtaking for tracks', 'Crossroad with secondary way', 'Main road', 'Give way', 'Stop', 'Road up', 'Road up for track', 'Brock',\n               'Other dangerous', 'Turn left', 'Turn right', 'Winding road', 'Hollow road', 'Slippery road', 'Narrowing road', 'Roadwork', 'Traffic light',\n               'Pedestrian', 'Children', 'Bike', 'Snow', 'Deer', 'End of the limits', 'Only right', 'Only left', 'Only straight', 'Only straight and right', \n               'Only straight and left', 'Take right', 'Take left', 'Circle crossroad', 'End of overtaking limit', 'End of overtaking limit for track']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# derive the path to the training and testing CSV files\ntrainPath = os.path.sep.join([\"../input/gtsrb-german-traffic-sign\", \"Train.csv\"])\ntestPath = os.path.sep.join([\"../input/gtsrb-german-traffic-sign\", \"Test.csv\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainPath","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load the training and testing data\nprint(\"[INFO] loading training and testing data...\")\n(trainX, trainY) = load_split(\"../input/gtsrb-german-traffic-sign\", trainPath)\n(testX, testY) = load_split(\"../input/gtsrb-german-traffic-sign\", testPath)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#normalize the images\n\ntrainX = trainX.astype(\"float32\")/255.0\ntestX = testX.astype(\"float32\")/255.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#one hot encoding of labels\n\nnumLabels = len(np.unique(trainY))\ntrainY = to_categorical(trainY, numLabels)\ntestY = to_categorical(testY, numLabels)\n\n#take class weight into account\nclassTotals = trainY.sum(axis = 0)\nclassWeight = classTotals.max()/classTotals","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classWeight","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#construct the image data augmentation generator\n\naug = ImageDataGenerator(\n    \n    rotation_range = 10,\n    zoom_range = 0.15,\n    width_shift_range = 0.1,\n    height_shift_range = 0.2,\n    shear_range = 0.15,\n    horizontal_flip = False,\n    vertical_flip = False,\n    fill_mode = \"nearest\"\n)\n\n#initialize the optimizer and compile the model\n\nopt = Adam(lr = INIT_LR, decay = INIT_LR/(NUM_EPOCHS * 0.5))\nmodel = objTSN.build(width = 32, height = 32, depth = 3, classes=numLabels)\nmodel.compile(loss = \"categorical_crossentropy\", optimizer = opt, metrics = [\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train the Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#train the network\nH = model.fit_generator(\n    aug.flow(trainX, trainY, batch_size = BS),\n    validation_data = (testX, testY),\n    steps_per_epoch = trainX.shape[0]//BS,\n    epochs = NUM_EPOCHS,\n    class_weight = classWeight,\n    verbose = 1\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#evaluate network\npredictions = model.predict(testX, batch_size = BS)\nprint(classification_report(testY.argmax(axis = 1), predictions.argmax(axis = 1), target_names = labelNames))\n\n#save the model\nmodel.save(\"trainedmodel.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot the training loss and accuracy\n\nN = np.arange(0, NUM_EPOCHS)\nplt.style.use(\"ggplot\")\nplt.figure()\nplt.plot(N, H.history[\"loss\"], label = \"train_loss\")\nplt.plot(N, H.history[\"val_loss\"], label = \"val_loss\")\nplt.plot(N, H.history[\"accuracy\"], label = \"accuracy\")\nplt.plot(N, H.history[\"val_accuracy\"], label = \"val_acc\")\nplt.title(\"Training Loss and Accuracy on DataSet\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss/Accuracy\")\nplt.legend(loc = \"lower left\")\nplt.savefig(\"plot.png\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# References\n\n- [Traffic Sign Classification with Keras and Deep Learning](https://www.pyimagesearch.com/2019/11/04/traffic-sign-classification-with-keras-and-deep-learning/)"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}