{"cells":[{"metadata":{},"cell_type":"markdown","source":"# DATA SCIENTIST\n**In this tutorial, I only explain you what you need to be a data scientist neither more nor less.**\n\nData scientist need to have these skills:\n\n1. Basic Tools: Like python, R or SQL. You do not need to know everything. What you only need is to learn how to use **python**\n2. Basic Statistics: Like mean, median or standart deviation. If you know basic statistics, you can use **python** easily. \n3. Data Munging(datayı düzeltme): Working with messy and difficult data. Like a inconsistent date and string formatting. As you guess, **python** helps us.\n4. Data Visualization: Title is actually explanatory. We will visualize the data with **python** like matplot and seaborn libraries.\n5. Machine Learning: You do not need to understand math behind the machine learning technique. You only need is understanding basics of machine learning and learning how to implement it while using **python**."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/2017.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns=['Country','Happiness_Rank', 'Happiness_Score', 'Whisker_high',\n       'Whisker_low', 'Economy_GDP_per_Capita', 'Family',\n       'Health_Life_Expectancy', 'Freedom', 'Generosity',\n       'Trust_Government_Corruption', 'Dystopia_Residual']\ndata.corr()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# correlation\nf,ax = plt.subplots(figsize=(18,18))\nsns.heatmap(data.corr(),annot= True,linewidths= 5, fmt='.1f',ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"1\"></a> <br>\n# 1. INTRODUCTION TO PYTHON"},{"metadata":{},"cell_type":"markdown","source":"Line Plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Family.plot(kind='line',color='g',grid=True,label='Family',alpha=0.5,linewidth=1,linestyle=':')\ndata.Freedom.plot(color='r',grid=True,alpha=0.5,label='Freedom',linewidth=1,linestyle='-')  \nplt.legend()\nplt.xlabel('x axis')\nplt.ylabel('y axis')\nplt.title('Line Plot ')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Scatter Plots","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(data.Family,data.Freedom,color='b',alpha=0.5)\nplt.xlabel('Family')\nplt.ylabel('Freedom')\nplt.title('Family Freedom Scatter Plot')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" OR Scatter plot is used like:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.plot(kind='scatter',x='Family',y='Freedom',color='r',alpha=0.5)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Histogram is used like:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Health_Life_Expectancy.plot(kind='hist',bins=50,figsize=(12,12))\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Also, you can clear the histogram plot with:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Health_Life_Expectancy.plot(kind='hist',bins=50,figsize=(12,12))\nplt.clf() # clears the method","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dictionary"},{"metadata":{"trusted":true},"cell_type":"code","source":"dictionary = {'galatasaray':'taffarel','fenerbahçe':'volkan','beşiktaş':'rüştü','trabzonspor':'şenol'}\n# print(dictionary)\nprint(dictionary.keys())\nprint(dictionary.values())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# changing the value\ndictionary['galatasaray']='muslera'\nprint(dictionary)\n# adding a new entry\ndictionary['juventus']='ronaldo'\nprint(dictionary)\n# remove entry\n#del dictionary['juventus']\nprint(dictionary)\nprint('trabzonspor' in dictionary)\n#dictionary.clear\n#print(dictionary)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Pandas\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/2017.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"series = data['Economy..GDP.per.Capita.']\nprint(type(series))\ndf = data[['Economy..GDP.per.Capita.']]\nprint(type(df))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Logic, Control flow and Filtering\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# comparison operator\nprint(3 > 1)\nprint(3!=1)\n# Boolean operators\nprint(True and False)\nprint(True and False and True and True and True and True)\nprint(True or False)\nprint(True and False and True and False or True)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1-)Filtering pandas data frame\nx = data['Family']>1.3\ndata[x]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2-) Filtering pandas with logical_and or logical_or\ndata[np.logical_or(data['Family']>1.3,data['Happiness.Score']>7)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# also could be written as :\ndata[(data['Family']>1.5) | (data['Happiness.Score']>7)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"While and For Loops"},{"metadata":{"trusted":true},"cell_type":"code","source":"i = 0\nwhile i !=10:\n    print('i is :',i)\n    i = i + 1\nprint(i,' is equal to 10')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"liste = [1,2,3,4,5,6,7,8,9,10]\nfor a in liste:\n    print('a is :',a)\nprint('')\n\nfor index,values in enumerate(liste):\n    print(index,':',values)\nprint('')\n\ndictionary ={'gs':'muslera','fb':'volkan','bjk':'fabri'}\nprint(dictionary)\nfor keys,values in dictionary.items():\n    print(keys,':',values)\nprint('')\nfor index,values in data[['Family']][75:101].iterrows():\n    print(index,':',values)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"7\"></a> <br>\n# 2. PYTHON DATA SCIENCE TOOLBOX"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"8\"></a> <br>\n### USER DEFINED FUNCTION"},{"metadata":{"trusted":true},"cell_type":"code","source":"def tuble_ex():\n    \"\"\"return defined t tuble\"\"\"\n    t = (1,2,3)\n    return t\na,b,c = tuble_ex()\nprint(a,b,c)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"9\"></a> <br>\n### SCOPE"},{"metadata":{},"cell_type":"markdown","source":"-global scope : defined in script\n-local scope : defined in a function\n-built in scope : names in predefined\nsuch as len,print"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = 5  # global scope\ndef f():\n    x = 3   # local scope\n    return x\nprint(x)      # x = 5 global scope\nprint(f())    # x = 3 local scope","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# if there is no local scope\n# it uses global scope x\nx = 5\ndef f():\n    y = x*2\n    return y\nprint(f())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# if both does not exist built in scope is seached\nimport builtins\ndir(builtins)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"10\"></a> <br>\n### NESTED FUNCTION\n* function inside function."},{"metadata":{"trusted":true},"cell_type":"code","source":"# nested function\ndef square():\n    \"\"\" return square of value\"\"\"\n    def add():\n        \"\"\" add two local variable\"\"\"\n        x = 2\n        y = 3\n        z = x+y\n        return z\n    return add()**2\nprint(square())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"11\"></a> <br>\n### DEFAULT and FLEXIBLE ARGUMENTS\n* Default argument example:\n<br> def f(a, b=1):\n      \"\"\" b = 1 is default argument\"\"\"\n* Flexible argument example:\n<br> def f(*args):\n       \"\"\" *args can be one or more\"\"\"\n<br>def f(** kwargs)\n       \"\"\" **kwargs is a dictionary\"\"\"\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# default arguments\ndef f(a,b=1,c=2):\n    y = a + b +c\n    return y\nprint(f(5))\n# what if we want to change default arguments\nf(5,4,3)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# flexible arguments *args\ndef f(*args):\n    for i in args:\n        print(i)\nf(1)\nprint(\"\")\nf(1,2,3,4)\n# flexible arguments **kwargs that is dictionary\ndef f(**kwargs):\n    \"\"\"print key and value of dictionary\"\"\"\n    for keys,values in kwargs.items():\n        print(keys,':',values)\nf(country='spain',capital='madrid',population=123456)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"12\"></a> <br>\n### LAMBDA FUNCTION\nFaster way of writing function"},{"metadata":{"trusted":true},"cell_type":"code","source":"# lambda function\nsquare = lambda x: x**2  \nprint(square(4))\ntot = lambda x,y,z : x+y+z\nprint(tot(1,2,3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"13\"></a> <br>\n### ANONYMOUS FUNCTİON\nLike lambda function but it can take more than one arguments.\n* map(func,seq) : applies a function to all the items in a list\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"number_list = [5,7,3,865,55]\ny = map(lambda x: x**3,number_list)\nprint(list(y))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"15\"></a> <br>\n### LIST COMPREHENSİON\n**One of the most important topic of this kernel**\n<br>We use list comprehension for data analysis often. c\n<br> list comprehension: collapse for loops for building lists into a single line\n<br>Ex: num1 = [1,2,3] and we want to make it num2 = [2,3,4]. This can be done with for loop. However it is  unnecessarily long. We can make it one line code that is list comprehension."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Example of list comprehension\nnum1 = [1,2,3]\nnum2 = [i**6+30 for i in num1]\nprint(num2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Conditionals on iterable\nnum1 = [3,13,21,65]\nnum2 = [i*18 if i<13 else i**2 if i>=13 and i<22 else i**(1/2) for i in num1]\nprint(num2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_1 = sum(data.Health_Life_Expectancy)/(len(data.Health_Life_Expectancy))\nprint(mean_1)\ndata['Health_Life_Expectancy_Level'] = ['high' if i >= mean_1 else 'low' for i in data.Health_Life_Expectancy] \ndata.loc[:200,['Health_Life_Expectancy_Level','Health_Life_Expectancy']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"16\"></a> <br>\n# 3.CLEANING DATA"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"17\"></a> <br>\n### DIAGNOSE DATA for CLEANING\nWe need to diagnose and clean data before exploring.\n<br>Unclean data:\n* Column name inconsistency like upper-lower case letter or space between words\n* missing data\n* different language\n\n<br> We will use head, tail, columns, shape and info methods to diagnose data\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/2017.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns = ['Country','Happiness.Rank','Happiness.Score','Whisker.high','Whisker.low','Economy.GDP.per.Capita','Family','Health.Life.Expectancy','Freedom','Generosity','Trust.Government.Corruption','Dystopia.Residual']\ndata.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.tail(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"18\"></a> <br>\n### EXPLORATORY DATA ANALYSIS\nvalue_counts(): Frequency counts\n<br>outliers: the value that is considerably higher or lower from rest of the data\n* Lets say value at 75% is Q3 and value at 25% is Q1. \n* Outlier are smaller than Q1 - 1.5(Q3-Q1) and bigger than Q3 + 1.5(Q3-Q1). (Q3-Q1) = IQR\n<br>We will use describe() method. Describe method includes:\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry\n\n<br> What is quantile?\n\n* 1,4,5,6,8,9,11,12,13,14,15,16,17\n* The median is the number that is in **middle** of the sequence. In this case it would be 11.\n\n* The lower quartile is the median in between the smallest number and the median i.e. in between 1 and 11, which is 6.\n* The upper quartile, you find the median between the median and the largest number i.e. between 11 and 17, which will be 14 according to the question above."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data['Happiness.Score'].value_counts(dropna=False)) # if there is non values that is also be counted","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"19\"></a> <br>\n### VISUAL EXPLORATORY DATA ANALYSIS\n* Box plots: visualize basic statistics like outliers, min/max or quantiles"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"20\"></a> <br>\n### TIDY DATA\nWe tidy data with melt().\nDescribing melt is confusing. Therefore lets make example to understand it."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new = data.head()\ndata_new","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets melt\n# id_vars = what we do not wish to melt\n# value_vars = what we want to melt\ndata_new = data.tail(10)\nmelted = pd.melt(frame=data_new,id_vars='Country',value_vars=['Whisker.high','Whisker.low'])\nmelted","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"21\"></a> <br>\n### PIVOTING DATA\nReverse of melting."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Index is country\n# I want to make that columns are variable\n# Finally values in columns are value\nmelted.pivot(index='Country',columns='variable',values='value')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"22\"></a> <br>\n### CONCATENATING DATA\nWe can concatenate two dataframe "},{"metadata":{"trusted":true},"cell_type":"code","source":"data1 = data.head()\ndata2 = data.tail()\nconc_data_row = pd.concat([data1,data2],axis=0,ignore_index=True)\nconc_data_row","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1 = data['Health.Life.Expectancy'].head()\ndata2 = data['Trust.Government.Corruption'].head()\nconc_data_col = pd.concat([data1,data2],axis=1)\nconc_data_col","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"23\"></a> <br>\n### DATA TYPES\nThere are 5 basic data types: object(string),booleab,  integer, float and categorical.\n<br> We can make conversion data types like from str to categorical or from int to float\n<br> Why is category important: \n* make dataframe smaller in memory \n* can be utilized for anlaysis especially for sklear(we will learn later)"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"24\"></a> <br>\n### MISSING DATA and TESTING WITH ASSERT\nIf we encounter with missing data, what we can do:\n* leave as is\n* drop them with dropna()\n* fill missing value with fillna()\n* fill missing values with test statistics like mean\n<br>Assert statement: check that you can turn on or turn off when you are done with your testing of the program"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Family'].value_counts(dropna=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1 = data\ndata1['Family'].dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert 1==1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"Family\"].fillna('empty',inplace = True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert  data['Family'].notnull().all()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"25\"></a> <br>\n# 4. PANDAS FOUNDATION "},{"metadata":{},"cell_type":"markdown","source":"<a id=\"26\"></a> <br>\n### REVİEW of PANDAS\nAs you notice, I do not give all idea in a same time. Although, we learn some basics of pandas, we will go deeper in pandas.\n* single column = series\n* NaN = not a number\n* dataframe.values = numpy\n"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"27\"></a> <br>\n### BUILDING DATA FRAMES FROM SCRATCH\n* We can build data frames from csv as we did earlier.\n* Also we can build dataframe from dictionaries\n    * zip() method: This function returns a list of tuples, where the i-th tuple contains the i-th element from each of the argument sequences or iterables.\n* Adding new column\n* Broadcasting: Create new column and assign a value to entire column"},{"metadata":{"trusted":true},"cell_type":"code","source":"### dataframes from dictionary\ncountry = ['Turkey','Azerbeycan','Germany']\ncapital = ['Ankara','Bakü','Berlin']\nliste_row = ['Country','Capital']\nliste_col = [country,capital]\nzipped = list(zip(liste_row,liste_col))\ndictionary = dict(zipped)\ndf = pd.DataFrame(dictionary)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# add new columns\ndf['Population'] = [200,100,150]\ndf\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# broadcasting\ndf['Income']=0\ndf\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"28\"></a> <br>\n### VISUAL EXPLORATORY DATA ANALYSIS\n* Plot\n* Subplot\n* Histogram:\n    * bins: number of bins\n    * range(tuble): min and max values of bins\n    * normed(boolean): normalize or not\n    * cumulative(boolean): compute cumulative distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting all data\ndata1 = data.loc[:,['Family','Health.Life.Expectancy','Generosity']]\ndata1.plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# subplots\ndata1.plot(subplots=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# scatter plot\ndata1.plot(kind='scatter',x='Family',y='Generosity')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# hist plot\ndata1.plot(kind='hist',y='Family',bins=50,range=(0,155),normed=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# histogram subplot with non cumulative and cumulative \nfig,axes = plt.subplots(nrows=2,ncols=1)\ndata1.plot(kind='hist',y='Family',bins=50,range=(0,100),normed=True,ax=axes[0])\ndata1.plot(kind = \"hist\",y = \"Family\",bins = 50,range= (0,250),normed = True,ax = axes[1],cumulative = True)\nplt.savefig('graph.png')\nplt\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"29\"></a> <br>\n### STATISTICAL EXPLORATORY DATA ANALYSIS\nI already explained it at previous parts. However lets look at one more time.\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"30\"></a> <br>\n### INDEXING PANDAS TIME SERIES\n* datetime = object\n* parse_dates(boolean): Transform date to ISO 8601 (yyyy-mm-dd hh:mm:ss ) format"},{"metadata":{"trusted":true},"cell_type":"code","source":"time_list = ['1992-03-08','1992-04-12']\nprint(type(time_list[1])) # as we can see date is string\n# however we want it to be datetime object\ndatatime_object = pd.to_datetime(time_list)\nprint(type(datatime_object))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# close warning\nimport warnings\nwarnings.filterwarnings('ignore')\n# lets practise\ndata2 = data.head()\ndate_list = ['1992-01-10','1992-02-10','1992-03-10','1993-03-15','1993-03-16']\ndate_datetime = pd.to_datetime(date_list)\ndata2['data'] = date_datetime\ndata2 = data2.set_index('data')\ndata2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now we can select according to our date index\nprint(data2.loc['1993-03-16'])\nprint(data2.loc['1992-03-10':'1993-03-16'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"31\"></a> <br>\n### RESAMPLING PANDAS TIME SERIES\n* Resampling: statistical method over different time intervals\n    * Needs string to specify frequency like \"M\" = month or \"A\" = year\n* Downsampling: reduce date time rows to slower frequency like from daily to weekly\n* Upsampling: increase date time rows to faster frequency like from daily to hourly\n* Interpolate: Interpolate values according to different methods like ‘linear’, ‘time’ or index’ \n    * https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.interpolate.html\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will use data2 that we create at previous part\ndata2.resample('A').mean() # resample about years","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data2.resample('M').mean() # resample about months\n# As you can see there are a lot of nan because data2 does not include all months","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# In real life (data is real. Not created from us like data2) we can solve this problem with interpolate\n# We can interpolete from first value\ndata2.resample('M').first().interpolate('linear')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Or we can interpolate with mean()\ndata2.resample(\"M\").mean().interpolate(\"linear\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"32\"></a> <br>\n# 5)MANIPULATING DATA FRAMES WITH PANDAS"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"33\"></a> <br>\n### INDEXING DATA FRAMES\n* Indexing using square brackets\n* Using column attribute and row label\n* Using loc accessor\n* Selecting only some columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"# read data\ndata = pd.read_csv('../input/2017.csv')\ndata = data.set_index('Country')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# indexing using square brackets\ndata['Health..Life.Expectancy.'][153]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using column attribute and row label\ndata.Family[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using loc accessor\ndata.loc['Netherlands','Family']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Selecting only some columns\ndata[['Whisker.high','Whisker.low']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"34\"></a> <br>\n### SLICING DATA FRAME\n* Difference between selecting columns\n    * Series and data frames\n* Slicing and indexing series\n* Reverse slicing \n* From something to end"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Difference between selecting columns: series and dataframes\nprint(type(data['Freedom'])) # series\nprint(type(data[['Freedom','Trust..Government.Corruption.']])) # DataFrame","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Slicing and indexing series\ndata.loc['Australia':'Chile','Family':'Freedom']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.loc['Chile':'Australia':-1,'Family':'Freedom']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# From something to end\ndata.loc['Mali','Whisker.high':]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"35\"></a> <br>\n### FILTERING DATA FRAMES\nCreating boolean series\nCombining filters\nFiltering column based others"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating boolean series\nboolean = data.Family>1.5\ndata[boolean]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Combining filters\nfirst_filter = data['Economy..GDP.per.Capita.']>1.3\nsecond_filter = data['Health..Life.Expectancy.']>0.85\ndata[first_filter & second_filter]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filtering column based others\ndata.Family[data.Generosity>0.5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"36\"></a> <br>\n### TRANSFORMING DATA\n* Plain python functions\n* Lambda function: to apply arbitrary python function to every element\n* Defining column using other columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plain python functions\ndef sum(x):\n    return x+5\ndata['Whisker.high'].apply(sum)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Or we can use lambda function\ndata['Whisker.high'].apply(lambda x:x+5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining column using other columns\ndata['total_power'] = data['Happiness.Score']*data['Freedom']\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"37\"></a> <br>\n### INDEX OBJECTS AND LABELED DATA\nindex: sequence of label\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# our index name is this:\nprint(data.index.name)\n# lets change it\ndata.index.name = 'Countries'\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"38\"></a> <br>\n### HIERARCHICAL INDEXING\n* Setting indexing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets read data frame one more time to start from beginning\ndata = pd.read_csv('../input/2017.csv')\ndata.head()\n# As you can see there is index. However we want to set one or more column to be index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setting index : Country is outer Happiness.Rank is inner index\ndata1 = data.set_index(['Country','Happiness.Rank'])\ndata1.head(100)\n# data1.loc[\"Iceland\",\"Family\"] # how to use indexes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"39\"></a> <br>\n### PIVOTING DATA FRAMES\n* pivoting: reshape tool"},{"metadata":{"trusted":true},"cell_type":"code","source":"dic = {'treatment':['A','A','B','B'],'gender':['F','M','F','M'],'response':[10,45,5,9],'age':[15,4,72,65]}\ndf = pd.DataFrame(dic)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pivoting\ndf.pivot(index='treatment',columns='gender',values='response')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"40\"></a> <br>\n### STACKING and UNSTACKING DATAFRAME\n* deal with multi label indexes\n* level: position of unstacked index\n* swaplevel: change inner and outer level index position"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df.set_index(['treatment','gender'])\ndf1\n# lets unstack it","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# level determines indexes\ndf1.unstack(level=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.unstack(level=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# change inner and outer level index position\ndf2 = df1.swaplevel(0,1)\ndf2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"41\"></a> <br>\n### MELTING DATA FRAMES\n* Reverse of pivoting"},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df.pivot(index=\"treatment\",columns = \"gender\",values=\"response\")\npd.melt(frame=df,id_vars='treatment',value_vars=['response','age'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"42\"></a> <br>\n### CATEGORICALS AND GROUPBY"},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# according to treatment take means of other features\ndf.groupby(\"treatment\").mean()   # mean is aggregation / reduction method\n# there are other methods like sum, std,max or min","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we can only choose one of the feature\ndf.groupby(\"treatment\").age.max() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Or we can choose multiple features\ndf.groupby(\"treatment\")[[\"age\",\"response\"]].min() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"42\"></a> <br>\n### The End\n### Powered by Mehmet Salih Ünal"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}