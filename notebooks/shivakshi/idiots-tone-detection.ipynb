{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2021-06-20T07:24:39.632841Z","iopub.status.busy":"2021-06-20T07:24:39.632452Z","iopub.status.idle":"2021-06-20T07:24:39.647774Z","shell.execute_reply":"2021-06-20T07:24:39.646643Z","shell.execute_reply.started":"2021-06-20T07:24:39.632809Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib as plt\nimport re\nfrom nltk.stem.porter import PorterStemmer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport re\nimport nltk\nnltk.download('stopwords')\nfrom sklearn import *","metadata":{"execution":{"iopub.execute_input":"2021-06-20T09:32:52.667306Z","iopub.status.busy":"2021-06-20T09:32:52.66674Z","iopub.status.idle":"2021-06-20T09:32:53.141418Z","shell.execute_reply":"2021-06-20T09:32:53.140401Z","shell.execute_reply.started":"2021-06-20T09:32:52.667273Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train=pd.read_csv(\"../input/twitter-sentiment-analysis-hatred-speech/train.csv\")\ndf_train.head()","metadata":{"execution":{"iopub.execute_input":"2021-06-20T09:32:58.886419Z","iopub.status.busy":"2021-06-20T09:32:58.885836Z","iopub.status.idle":"2021-06-20T09:32:58.949508Z","shell.execute_reply":"2021-06-20T09:32:58.948537Z","shell.execute_reply.started":"2021-06-20T09:32:58.886367Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clear_tweets(text):\n    text=re.sub('<[^>]*>','',text)\n    emojis=re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',text)\n    text=re.sub('[\\W]+',' ',text.lower()) +' '.join(emojis).replace('-','')\n\n    return text   ","metadata":{"execution":{"iopub.execute_input":"2021-06-20T09:33:00.221404Z","iopub.status.busy":"2021-06-20T09:33:00.220842Z","iopub.status.idle":"2021-06-20T09:33:00.226818Z","shell.execute_reply":"2021-06-20T09:33:00.225836Z","shell.execute_reply.started":"2021-06-20T09:33:00.221364Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['tweet']=df_train['tweet'].apply(clear_tweets)\ndf_train.head()","metadata":{"execution":{"iopub.execute_input":"2021-06-20T09:33:01.386361Z","iopub.status.busy":"2021-06-20T09:33:01.385775Z","iopub.status.idle":"2021-06-20T09:33:01.914297Z","shell.execute_reply":"2021-06-20T09:33:01.913187Z","shell.execute_reply.started":"2021-06-20T09:33:01.386311Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['label'].unique()","metadata":{"execution":{"iopub.execute_input":"2021-06-20T09:33:02.356265Z","iopub.status.busy":"2021-06-20T09:33:02.355814Z","iopub.status.idle":"2021-06-20T09:33:02.36311Z","shell.execute_reply":"2021-06-20T09:33:02.362118Z","shell.execute_reply.started":"2021-06-20T09:33:02.35623Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nstop=stopwords.words('english')\n\nstop_words = set(stopwords.words(\"english\"))\n","metadata":{"execution":{"iopub.execute_input":"2021-06-20T09:33:03.096205Z","iopub.status.busy":"2021-06-20T09:33:03.095785Z","iopub.status.idle":"2021-06-20T09:33:03.101923Z","shell.execute_reply":"2021-06-20T09:33:03.100994Z","shell.execute_reply.started":"2021-06-20T09:33:03.09617Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stemmer = PorterStemmer()","metadata":{"execution":{"iopub.execute_input":"2021-06-20T09:33:03.956276Z","iopub.status.busy":"2021-06-20T09:33:03.955686Z","iopub.status.idle":"2021-06-20T09:33:03.960973Z","shell.execute_reply":"2021-06-20T09:33:03.96011Z","shell.execute_reply.started":"2021-06-20T09:33:03.956229Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def func_2(tweets):\n    token=word_tokenize(tweets)\n    filtered_list = []\n    for word in token:\n        if word.casefold() not in stop_words:\n            filtered_list.append(word)\n    stemmed_words = [stemmer.stem(word) for word in filtered_list]\n    return stemmed_words","metadata":{"execution":{"iopub.execute_input":"2021-06-20T09:33:04.456433Z","iopub.status.busy":"2021-06-20T09:33:04.455864Z","iopub.status.idle":"2021-06-20T09:33:04.46305Z","shell.execute_reply":"2021-06-20T09:33:04.462108Z","shell.execute_reply.started":"2021-06-20T09:33:04.456385Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nnltk.download('punkt')\nnew_list=[]\narr=[]\ni=0\nfor tweet in df_train['tweet']:\n    new_list=func_2(tweet)\n    joined_str=\"\"\n    for word in new_list:\n        joined_str=joined_str+\" \"+word\n    arr.append(joined_str)","metadata":{"execution":{"iopub.execute_input":"2021-06-20T09:33:05.291243Z","iopub.status.busy":"2021-06-20T09:33:05.290821Z","iopub.status.idle":"2021-06-20T09:33:19.292371Z","shell.execute_reply":"2021-06-20T09:33:19.291447Z","shell.execute_reply.started":"2021-06-20T09:33:05.291208Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['new_tweet']=arr","metadata":{"execution":{"iopub.execute_input":"2021-06-20T09:33:19.294055Z","iopub.status.busy":"2021-06-20T09:33:19.29372Z","iopub.status.idle":"2021-06-20T09:33:19.302277Z","shell.execute_reply":"2021-06-20T09:33:19.301294Z","shell.execute_reply.started":"2021-06-20T09:33:19.29403Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train","metadata":{"execution":{"iopub.execute_input":"2021-06-20T09:33:19.304345Z","iopub.status.busy":"2021-06-20T09:33:19.304005Z","iopub.status.idle":"2021-06-20T09:33:19.3212Z","shell.execute_reply":"2021-06-20T09:33:19.320179Z","shell.execute_reply.started":"2021-06-20T09:33:19.304314Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_neg=[]\nX_pos=[]\nY_pos=[]\nY_neg=[]\nfor t in df_train['new_tweet'][df_train['label']==0]:\n    X_neg.append(t)\n    \nfor t in df_train['label'][df_train['label']==0]:\n    Y_neg.append(t)\n\nfor t in df_train['new_tweet'][df_train['label']==1]:\n    X_pos.append(t)\n    \nfor t in df_train['label'][df_train['label']==1]:\n    Y_pos.append(t)","metadata":{"execution":{"iopub.execute_input":"2021-06-20T09:33:19.323179Z","iopub.status.busy":"2021-06-20T09:33:19.322825Z","iopub.status.idle":"2021-06-20T09:33:19.356344Z","shell.execute_reply":"2021-06-20T09:33:19.355363Z","shell.execute_reply.started":"2021-06-20T09:33:19.323149Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\nvectorizer = TfidfVectorizer(max_features=10000)\n\nX_vec=vectorizer.fit_transform(df_train.new_tweet)","metadata":{"execution":{"iopub.execute_input":"2021-06-20T09:41:07.689348Z","iopub.status.busy":"2021-06-20T09:41:07.68893Z","iopub.status.idle":"2021-06-20T09:41:08.265693Z","shell.execute_reply":"2021-06-20T09:41:08.264671Z","shell.execute_reply.started":"2021-06-20T09:41:07.689316Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y=df_train.label.values\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X_vec,y,random_state=1,test_size=0.25,shuffle=False)","metadata":{"execution":{"iopub.execute_input":"2021-06-20T09:41:08.591608Z","iopub.status.busy":"2021-06-20T09:41:08.591217Z","iopub.status.idle":"2021-06-20T09:41:08.599363Z","shell.execute_reply":"2021-06-20T09:41:08.598302Z","shell.execute_reply.started":"2021-06-20T09:41:08.591572Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegressionCV\nclf=LogisticRegressionCV(cv=6,scoring='accuracy',random_state=0,n_jobs=-1,verbose=3,max_iter=500).fit(X_train,y_train)\ny_pred = clf.predict(X_test)\nfrom sklearn import metrics\n\n# Model Accuracy, how often is the classifier correct?\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","metadata":{"execution":{"iopub.execute_input":"2021-06-20T09:41:09.351611Z","iopub.status.busy":"2021-06-20T09:41:09.351199Z","iopub.status.idle":"2021-06-20T09:41:26.17128Z","shell.execute_reply":"2021-06-20T09:41:26.170038Z","shell.execute_reply.started":"2021-06-20T09:41:09.351577Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test=pd.read_csv(\"../input/twitter-sentiment-analysis-hatred-speech/test.csv\")\ntest=df_test['tweet']\ntest=test.apply(clear_tweets)\ntest=test.apply(func_2)\n\n\n\narr=[]\n\nfor tweet in test:\n\n    joined_str=\"\"\n    for word in tweet:\n        joined_str=joined_str+\" \"+word\n    arr.append(joined_str)\n\ntest=pd.DataFrame(arr,columns=['tweet'])\n\n\ntest.head()\n","metadata":{"execution":{"iopub.execute_input":"2021-06-20T09:41:26.179472Z","iopub.status.busy":"2021-06-20T09:41:26.176805Z","iopub.status.idle":"2021-06-20T09:41:34.144885Z","shell.execute_reply":"2021-06-20T09:41:34.143974Z","shell.execute_reply.started":"2021-06-20T09:41:26.1794Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xtest=vectorizer.fit_transform(test.tweet)\nxtest.shape\nytest=clf.predict(xtest)\n","metadata":{"execution":{"iopub.execute_input":"2021-06-20T09:46:45.991315Z","iopub.status.busy":"2021-06-20T09:46:45.990902Z","iopub.status.idle":"2021-06-20T09:46:46.288396Z","shell.execute_reply":"2021-06-20T09:46:46.287541Z","shell.execute_reply.started":"2021-06-20T09:46:45.991278Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final=pd.DataFrame(df_test['tweet'],columns=['tweet'])\nfinal['label']=ytest\nfinal.head()","metadata":{"execution":{"iopub.execute_input":"2021-06-20T09:54:16.662574Z","iopub.status.busy":"2021-06-20T09:54:16.662014Z","iopub.status.idle":"2021-06-20T09:54:16.674305Z","shell.execute_reply":"2021-06-20T09:54:16.673405Z","shell.execute_reply.started":"2021-06-20T09:54:16.662526Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=['Congratulations to His Excellency Ebrahim Raisi on his election as President of the Islamic Republic of Iran',\n      ' I look forward to working with him to further strengthen the warm ties between India and Iran.',\n      'Baghor shrine is a modest temple that only has a stone platform under Neem tree and a triangular shaped Yantra worshiped as Goddess in the middle of platform.',\n      'Yet, it has been worshiped continuously since 11,000 years from Paleolithic hunter gatherers to modern day inhabitants',\n      'This video legitimately made me wanna try Takis, and then the comment section talked me completely out of it.',\n      'i am living',\n      'guys for some reason i am in a minecraft tournament i am gonna be streaming it in like an hour',\n      'astronaut in the ocean was written and performed by a youth pastor i’m sure of it']","metadata":{"execution":{"iopub.execute_input":"2021-06-20T09:06:48.773368Z","iopub.status.busy":"2021-06-20T09:06:48.77295Z","iopub.status.idle":"2021-06-20T09:06:49.671727Z","shell.execute_reply":"2021-06-20T09:06:49.670728Z","shell.execute_reply.started":"2021-06-20T09:06:48.773331Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=pd.DataFrame(data,columns=['tweet'])\ndata.head()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntext=data['tweet'].apply(clear_tweets)\ntext=text.apply(func_2)\n\narr=[]\nfor tweet in text:\n    joined_str=\"\"\n    for word in tweet:\n        joined_str=joined_str+\" \"+word\n    arr.append(joined_str)\n    \ntext=pd.DataFrame(arr,columns=['tweet'])\ntest.shape\n\ntest=test.append(text,ignore_index=True)\ntest.tail(10)\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nvec= TfidfVectorizer(max_features=10000)  \n\nfrom sklearn.linear_model import LogisticRegressionCV\nclf=LogisticRegressionCV(cv=6,scoring='accuracy',random_state=0,n_jobs=-1,verbose=3,max_iter=500).fit(X_train,y_train)\nxval=vec.fit_transform(test.tweet)\n\nyval=clf.predict(xval)\n\nfinal=pd.DataFrame(test['tweet'],columns=['tweet'])\nfinal['label']=yval\nfinal.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(final['label']).value_counts()\nfinal.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final.tail(20)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final['label'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tweet=['You are beautiful love ']\ndata=pd.DataFrame(tweet,columns=['tweet'])\ndata.head()\ntext=data['tweet'].apply(clear_tweets)\ntext=text.apply(func_2)\n\narr=[]\nfor tweet in text:\n    joined_str=\"\"\n    for word in tweet:\n        joined_str=joined_str+\" \"+word\n    arr.append(joined_str)\n    \ntext=pd.DataFrame(arr,columns=['tweet'])\n# test.shape\n\ntest=test.append(text,ignore_index=True)\n# test.tail(10)\nvec= TfidfVectorizer(max_features=10000)\nclf=LogisticRegressionCV(cv=6,scoring='accuracy',random_state=0,n_jobs=-1,verbose=3,max_iter=500).fit(X_train,y_train)\nxval=vec.fit_transform(test.tweet)\n\nyval=clf.predict(xval)\n\nfinal=pd.DataFrame(test['tweet'],columns=['tweet'])\nfinal['label']=yval\nfinal.head()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final['label'].tail(1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\n","metadata":{},"execution_count":null,"outputs":[]}]}