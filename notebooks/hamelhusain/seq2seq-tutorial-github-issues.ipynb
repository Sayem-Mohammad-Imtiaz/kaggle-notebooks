{"cells":[{"metadata":{"_uuid":"77282ca6f97a7740db9f87619452f0a87c03f595","_cell_guid":"a11e8844-b449-4bef-aed7-46687dac4452","trusted":true},"cell_type":"code","source":"import pandas as pd\npd.set_option('display.max_colwidth', 500)\nfrom sklearn.model_selection import train_test_split\nfrom ktext.preprocess import processor","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"52eee747b23516cb801b5922cd9cc81ebc3731f4","_cell_guid":"617564a3-b52b-4fff-a067-67736855eaa9"},"cell_type":"markdown","source":"## Read Data And Preview","outputs":[],"execution_count":null},{"metadata":{"_uuid":"99be74c506654cbd98fcef466e8c458b1f1026d3","_cell_guid":"6274092b-29bd-4c75-9dea-7206f4fe1fed","trusted":true},"cell_type":"code","source":"traindf, testdf = train_test_split(pd.read_csv('../input/github_issues.csv').sample(n=60000), \n                                   test_size=.10)\ntrain_body_raw = traindf.body.tolist()\ntrain_title_raw = traindf.issue_title.tolist()\ntraindf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"404a096f706e71370c8a610635b7c0a5f93dc138","_cell_guid":"0c57efcc-1db4-45c0-93ef-026877e8b611"},"cell_type":"markdown","source":"Isssue Body and Title are stored in seperate lists.  Lets inspect the issue title list:","outputs":[],"execution_count":null},{"metadata":{"_uuid":"5f6b13cd6759e37ce6a83f0f943a8c93cf906a64","_cell_guid":"4959d954-2952-4033-85d9-5daf389c89ed","trusted":true},"cell_type":"code","source":"# Preview what is in this list\ntrain_title_raw[0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ccd61e51938f17e9681859976f71a12b0fca0e50","_cell_guid":"f8e524d0-ed7b-46bb-ba38-8b33f5cedb75"},"cell_type":"markdown","source":"## Use `ktext` to pre-process data","outputs":[],"execution_count":null},{"metadata":{"_uuid":"d773fec2ced563f35c42b54644e2b01a84baf58c","_cell_guid":"1967292a-1611-46bf-a171-89bf80b94e03","trusted":true},"cell_type":"code","source":"num_encoder_tokens = 5500\nbody_pp = processor(keep_n=num_encoder_tokens, padding_maxlen=50)\ntrain_body_vecs = body_pp.fit_transform(train_body_raw)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42cb7e0db7a9501e5cae6055db7c7ec01d8136b1","_cell_guid":"2c75a0fc-b262-45e6-b3a9-d65182b551f4"},"cell_type":"markdown","source":"**Look at one example of processed issue bodies**","outputs":[],"execution_count":null},{"metadata":{"_uuid":"49a378a782f6ee4aabbfe5518f4c942d006c1c15","_cell_guid":"9e56021c-fed6-42b4-b768-afbe5aab5f27","trusted":true},"cell_type":"code","source":"print('\\noriginal string:\\n', train_body_raw[0], '\\n')\nprint('after pre-processing:\\n', train_body_vecs[0], '\\n')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42fbc4f0c32651f0baefd87d2e7050526d4bb4b3","_cell_guid":"0513217d-3ce1-412a-8f76-afe0a98604d0","trusted":true},"cell_type":"code","source":"# Instantiate a text processor for the titles, with some different parameters\n#  append_indicators = True appends the tokens '_start_' and '_end_' to each\n#                      document\n#  padding = 'post' means that zero padding is appended to the end of the \n#             of the document (as opposed to the default which is 'pre')\nnum_decoder_tokens=4500\ntitle_pp = processor(append_indicators=True, keep_n=num_decoder_tokens, \n                     padding_maxlen=12, padding ='post')\n\n# process the title data\ntrain_title_vecs = title_pp.fit_transform(train_title_raw)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"00414a474ad8c0d3e283c704d30e653b5549e5da","_cell_guid":"4ec20e49-d1e6-40f6-acfa-00e5780dd8ed","trusted":true},"cell_type":"code","source":"max(title_pp.id2token.keys())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0105ab4ca68e285d66507862fe4a6274b59b0591","collapsed":true,"_cell_guid":"9c4d8488-ce1a-48a0-a595-3d78dfc07a85","trusted":true},"cell_type":"code","source":"def load_encoder_inputs(vectorized_body):\n    encoder_input_data = vectorized_body\n    doc_length = encoder_input_data.shape[1]\n    print(f'Shape of encoder input: {encoder_input_data.shape}')\n    return encoder_input_data, doc_length\n\n\ndef load_decoder_inputs(vectorized_title):\n    # For Decoder Input, you don't need the last word as that is only for prediction\n    # when we are training using Teacher Forcing.\n    decoder_input_data = vectorized_title[:, :-1]\n\n    # Decoder Target Data Is Ahead By 1 Time Step From Decoder Input Data (Teacher Forcing)\n    decoder_target_data = vectorized_title[:, 1:]\n\n    print(f'Shape of decoder input: {decoder_input_data.shape}')\n    print(f'Shape of decoder target: {decoder_target_data.shape}')\n    return decoder_input_data, decoder_target_data","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"36379ebefdbccefe0e32d6a4e08e66209016ed92","_cell_guid":"a254d40a-0b1b-475b-89d1-85d955e6806f","trusted":true},"cell_type":"code","source":"import numpy as np\nencoder_input_data, doc_length = load_encoder_inputs(train_body_vecs)\ndecoder_input_data, decoder_target_data = load_decoder_inputs(train_title_vecs)\nnum_encoder_tokens = max(body_pp.id2token.keys()) + 1\nnum_decoder_tokens = max(title_pp.id2token.keys()) + 1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a6560ad29713d4f396763c84205ab0ba77195c3","collapsed":true,"_cell_guid":"aad7fdea-b331-4f28-b472-62127b838324","trusted":true},"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import Input, LSTM, GRU, Dense, Embedding, Bidirectional, BatchNormalization\nfrom keras import optimizers","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e01a2f2122c42f232c60391452c11c26d00f20b3","collapsed":true,"_cell_guid":"e3c2fd45-6325-484c-87e3-c97146911a62","trusted":true},"cell_type":"code","source":"#arbitrarly set latent dimension for embedding and hidden units\nlatent_dim = 80\n\n##### Define Model Architecture ######\n\n########################\n#### Encoder Model ####\nencoder_inputs = Input(shape=(doc_length,), name='Encoder-Input')\n\n# Word embeding for encoder (ex: Issue Body)\nx = Embedding(num_encoder_tokens, latent_dim, name='Body-Word-Embedding', mask_zero=False)(encoder_inputs)\nx = BatchNormalization(name='Encoder-Batchnorm-1')(x)\n\n# Intermediate GRU layer (optional)\n#x = GRU(latent_dim, name='Encoder-Intermediate-GRU', return_sequences=True)(x)\n#x = BatchNormalization(name='Encoder-Batchnorm-2')(x)\n\n# We do not need the `encoder_output` just the hidden state.\n_, state_h = GRU(latent_dim, return_state=True, name='Encoder-Last-GRU')(x)\n\n# Encapsulate the encoder as a separate entity so we can just \n#  encode without decoding if we want to.\nencoder_model = Model(inputs=encoder_inputs, outputs=state_h, name='Encoder-Model')\n\nseq2seq_encoder_out = encoder_model(encoder_inputs)\n\n########################\n#### Decoder Model ####\ndecoder_inputs = Input(shape=(None,), name='Decoder-Input')  # for teacher forcing\n\n# Word Embedding For Decoder (ex: Issue Titles)\ndec_emb = Embedding(num_decoder_tokens, latent_dim, name='Decoder-Word-Embedding', mask_zero=False)(decoder_inputs)\ndec_bn = BatchNormalization(name='Decoder-Batchnorm-1')(dec_emb)\n\n# Set up the decoder, using `decoder_state_input` as initial state.\ndecoder_gru = GRU(latent_dim, return_state=True, return_sequences=True, name='Decoder-GRU')\ndecoder_gru_output, _ = decoder_gru(dec_bn, initial_state=seq2seq_encoder_out)\nx = BatchNormalization(name='Decoder-Batchnorm-2')(decoder_gru_output)\n\n# Dense layer for prediction\ndecoder_dense = Dense(num_decoder_tokens+2, activation='softmax', name='Final-Output-Dense')\ndecoder_outputs = decoder_dense(x)\n\n########################\n#### Seq2Seq Model ####\n\n#seq2seq_decoder_out = decoder_model([decoder_inputs, seq2seq_encoder_out])\nseq2seq_Model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n\n\nseq2seq_Model.compile(optimizer=optimizers.Nadam(lr=0.001), loss='sparse_categorical_crossentropy')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6ede1ab46b1a0dded0b98baf03a8a6acf0476378","_cell_guid":"c39cee27-88b4-42db-8c95-a679ae0bb024","trusted":true},"cell_type":"code","source":"from keras.callbacks import CSVLogger, ModelCheckpoint\n\nscript_name_base = 'tutorial_seq2seq'\nmodel_checkpoint = ModelCheckpoint('{:}.epoch{{epoch:02d}}-val{{val_loss:.5f}}.hdf5'.format(script_name_base),\n                                   save_best_only=True)\n\nbatch_size = 100\nepochs = 4\nhistory = seq2seq_Model.fit([encoder_input_data, decoder_input_data], np.expand_dims(decoder_target_data, -1),\n          batch_size=batch_size,\n          epochs=epochs,\n          validation_split=0.10, callbacks=[model_checkpoint])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1e6acb8c0f8266334a4c1f00256b887787e3fa57","collapsed":true,"_cell_guid":"df1e6ee6-e4da-49fc-bd44-c1bdb1031499"},"cell_type":"markdown","source":"this# Inference","outputs":[],"execution_count":null},{"metadata":{"collapsed":true,"_uuid":"b1e9dcd5b249f390fe6aab470e55986fcbcf18db","_cell_guid":"287d755e-d8bc-47a2-8b53-d0674750a0ab","trusted":true},"cell_type":"code","source":"def extract_decoder_model(model):\n    \"\"\"\n    Extract the decoder from the original model.\n    Inputs:\n    ------\n    model: keras model object\n    Returns:\n    -------\n    A Keras model object with the following inputs and outputs:\n    Inputs of Keras Model That Is Returned:\n    1: the embedding index for the last predicted word or the <Start> indicator\n    2: the last hidden state, or in the case of the first word the hidden state from the encoder\n    Outputs of Keras Model That Is Returned:\n    1.  Prediction (class probabilities) for the next word\n    2.  The hidden state of the decoder, to be fed back into the decoder at the next time step\n    Implementation Notes:\n    ----------------------\n    Must extract relevant layers and reconstruct part of the computation graph\n    to allow for different inputs as we are not going to use teacher forcing at\n    inference time.\n    \"\"\"\n    # the latent dimension is the same throughout the architecture so we are going to\n    # cheat and grab the latent dimension of the embedding because that is the same as what is\n    # output from the decoder\n    latent_dim = model.get_layer('Decoder-Word-Embedding').output_shape[-1]\n\n    # Reconstruct the input into the decoder\n    decoder_inputs = model.get_layer('Decoder-Input').input\n    dec_emb = model.get_layer('Decoder-Word-Embedding')(decoder_inputs)\n    dec_bn = model.get_layer('Decoder-Batchnorm-1')(dec_emb)\n\n    # Instead of setting the intial state from the encoder and forgetting about it, during inference\n    # we are not doing teacher forcing, so we will have to have a feedback loop from predictions back into\n    # the GRU, thus we define this input layer for the state so we can add this capability\n    gru_inference_state_input = Input(shape=(latent_dim,), name='hidden_state_input')\n\n    # we need to reuse the weights that is why we are getting this\n    # If you inspect the decoder GRU that we created for training, it will take as input\n    # 2 tensors -> (1) is the embedding layer output for the teacher forcing\n    #                  (which will now be the last step's prediction, and will be _start_ on the first time step)\n    #              (2) is the state, which we will initialize with the encoder on the first time step, but then\n    #                   grab the state after the first prediction and feed that back in again.\n    gru_out, gru_state_out = model.get_layer('Decoder-GRU')([dec_bn, gru_inference_state_input])\n\n    # Reconstruct dense layers\n    dec_bn2 = model.get_layer('Decoder-Batchnorm-2')(gru_out)\n    dense_out = model.get_layer('Final-Output-Dense')(dec_bn2)\n    decoder_model = Model([decoder_inputs, gru_inference_state_input],\n                          [dense_out, gru_state_out])\n    return decoder_model\n\ndef extract_encoder_model(model):\n    \"\"\"\n    Extract the encoder from the original Sequence to Sequence Model.\n    Returns a keras model object that has one input (body of issue) and one\n    output (encoding of issue, which is the last hidden state).\n    Input:\n    -----\n    model: keras model object\n    Returns:\n    -----\n    keras model object\n    \"\"\"\n    encoder_model = model.get_layer('Encoder-Model')\n    return encoder_model","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"4d3714fd03fd908c101868a99b820125641f325b","_cell_guid":"86caa810-c55c-46bb-9737-13dd5e175c9e","trusted":true},"cell_type":"code","source":"class Seq2Seq_Inference(object):\n    def __init__(self,\n                 encoder_preprocessor,\n                 decoder_preprocessor,\n                 seq2seq_model):\n\n        self.pp_body = encoder_preprocessor\n        self.pp_title = decoder_preprocessor\n        self.seq2seq_model = seq2seq_model\n        self.encoder_model = extract_encoder_model(seq2seq_model)\n        self.decoder_model = extract_decoder_model(seq2seq_model)\n        self.default_max_len_title = self.pp_title.padding_maxlen\n        self.nn = None\n        self.rec_df = None\n\n    def generate_issue_title(self,\n                             raw_input_text,\n                             max_len_title=None):\n        \"\"\"\n        Use the seq2seq model to generate a title given the body of an issue.\n        Inputs\n        ------\n        raw_input: str\n            The body of the issue text as an input string\n        max_len_title: int (optional)\n            The maximum length of the title the model will generate\n        \"\"\"\n        if max_len_title is None:\n            max_len_title = self.default_max_len_title\n        # get the encoder's features for the decoder\n        raw_tokenized = self.pp_body.transform([raw_input_text])\n        body_encoding = self.encoder_model.predict(raw_tokenized)\n        # we want to save the encoder's embedding before its updated by decoder\n        #   because we can use that as an embedding for other tasks.\n        original_body_encoding = body_encoding\n        state_value = np.array(self.pp_title.token2id['_start_']).reshape(1, 1)\n\n        decoded_sentence = []\n        stop_condition = False\n        while not stop_condition:\n            preds, st = self.decoder_model.predict([state_value, body_encoding])\n\n            # We are going to ignore indices 0 (padding) and indices 1 (unknown)\n            # Argmax will return the integer index corresponding to the\n            #  prediction + 2 b/c we chopped off first two\n            pred_idx = np.argmax(preds[:, :, 2:]) + 2\n\n            # retrieve word from index prediction\n            pred_word_str = self.pp_title.id2token[pred_idx]\n\n            if pred_word_str == '_end_' or len(decoded_sentence) >= max_len_title:\n                stop_condition = True\n                break\n            decoded_sentence.append(pred_word_str)\n\n            # update the decoder for the next word\n            body_encoding = st\n            state_value = np.array(pred_idx).reshape(1, 1)\n\n        return original_body_encoding, ' '.join(decoded_sentence)\n\n\n    def print_example(self,\n                      i,\n                      body_text,\n                      title_text,\n                      url,\n                      threshold):\n        \"\"\"\n        Prints an example of the model's prediction for manual inspection.\n        \"\"\"\n        if i:\n            print('\\n\\n==============================================')\n            print(f'============== Example # {i} =================\\n')\n\n        if url:\n            print(url)\n\n        print(f\"Issue Body:\\n {body_text} \\n\")\n\n        if title_text:\n            print(f\"Original Title:\\n {title_text}\")\n\n        emb, gen_title = self.generate_issue_title(body_text)\n        print(f\"\\n****** Machine Generated Title (Prediction) ******:\\n {gen_title}\")\n\n\n    def demo_model_predictions(self,\n                               n,\n                               issue_df,\n                               threshold=1):\n        \"\"\"\n        Pick n random Issues and display predictions.\n        Input:\n        ------\n        n : int\n            Number of issues to display from issue_df\n        issue_df : pandas DataFrame\n            DataFrame that contains two columns: `body` and `issue_title`.\n        threshold : float\n            distance threshold for recommendation of similar issues.\n        Returns:\n        --------\n        None\n            Prints the original issue body and the model's prediction.\n        \"\"\"\n        # Extract body and title from DF\n        body_text = issue_df.body.tolist()\n        title_text = issue_df.issue_title.tolist()\n        url = issue_df.issue_url.tolist()\n\n        demo_list = np.random.randint(low=1, high=len(body_text), size=n)\n        for i in demo_list:\n            self.print_example(i,\n                               body_text=body_text[i],\n                               title_text=title_text[i],\n                               url=url[i],\n                               threshold=threshold)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"8e85ab7f92c0314d58550b5d87e1b2a93eb6aebe","_cell_guid":"cfc5832e-58ee-4fcc-b3a8-b8f4987e9088","trusted":true},"cell_type":"code","source":"seq2seq_inf = Seq2Seq_Inference(encoder_preprocessor=body_pp,\n                                 decoder_preprocessor=title_pp,\n                                 seq2seq_model=seq2seq_Model)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"_uuid":"faa84da6a3a560f93fe4d5f4e2965077c985e988","_cell_guid":"40dac3f5-b9b8-4b44-98ee-4c81ba92391d","trusted":true},"cell_type":"code","source":"seq2seq_inf.demo_model_predictions(n=25, issue_df=testdf)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"a17f297de9975b0603f4a4ccd3a3398f04947c6c","_cell_guid":"e34237e9-0c10-48dc-9b62-4d80314afab9","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}