{"cells":[{"metadata":{},"cell_type":"markdown","source":"## **GOALS**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The goal of this project is to predict the Heart Disease presence within the patients in this datasets. \n\nThis goal hopefully will be achieved through the simple Random Forest Classification Model & K - Nearest Neighbors Model. With maybe some EDA along the way.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The variables are explained below : \n\n1. age: The person's age \n2. sex: The person's gender (1 = Male, 0 = Female)\n3. cp: The chest pain experienced (4 types)\n4. trestbps: The person's resting blood pressure\n5. chol: The person's cholesterol measurement in mg/dl\n6. fbs: If the person's fasting blood sugar > 120 mg/dl (1 = True; 0 = False)\n7. restecg: Resting electrocardiographic measurement\n8. thalach: The person's maximum heart rate achieved\n9. exang: Exercise induced angina (1 = Yes; 0 = No)\n10. oldpeak: ST depression induced by exercise relative to rest\n11. slope: the slope of the peak exercise ST segment\n12. ca: The number of major vessels (0-3)\n13. thal: A blood disorder called thalassemia (3 = normal; 6 = fixed defect; 7 = reversable defect)\n14. target: Heart disease diagnose (0 = No, 1 = Yes)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## **IMPORTING LIBRARIES**","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **LOAD DATASET - OVERVIEW**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"First let's load the dataset, and check the datatype for each variables.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/heart-disease-uci/heart.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **SOME EDA**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's do some EDA to see the pattern within this dataset. I'll be using only the continous variables.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in df[['age', 'trestbps', 'chol', 'thalach', 'oldpeak']]:\n    sns.distplot(df[i])\n    plt.title('Distribution of ' + i)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10, 16))\nsns.countplot(y = df[df['target']==1]['age'])\nplt.title('Count Of Positive Cases by Age')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Here we can see that within this dataset, most the patients blood pressure on range of 100 to 140, with most of the cholesterol range in 200mg/dl to 300mg/dl. The person's maximum heart rate achieved from 150 to 170. Then we can see that the patients within range of 41 to 64 years are prone to Heart Disease as they showing more cases than the others.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## **GETTING DUMMIES**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Now let's get to the Labelling to our categorical variable, I'll use the pd.get_dummies to achieve this.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"a = pd.get_dummies(df['cp'], prefix = \"cp\")\nb = pd.get_dummies(df['thal'], prefix = \"thal\")\nc = pd.get_dummies(df['slope'], prefix = \"slope\")\n\nframes = [df, a, b, c]\ndf_heart = pd.concat(frames, axis = 1)\ndf_heart = df_heart.drop(columns = ['cp', 'thal', 'slope'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_heart.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_heart.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **SPLITTING DATA**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Now before fitting our models, I want to split it to 80% Train and 20% Test data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x = df_heart.drop(['target'], axis = 1)\ny = df_heart.target.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the data with 80% Train size\n\nx_train, x_test, y_train, y_test = train_test_split(x,y,train_size = 0.8,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From this point below, we'll start building the Machine Learning Model and fitting it to our train data, then start to predict it to test data.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## **RANDOM FOREST CLASSIFIER**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model Fitting\n\nRFC = RandomForestClassifier(n_estimators = 2000, min_samples_split= 2, min_samples_leaf = 1, max_depth = 25)\nRFC.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Forest Classifier predict\n\nyp_RFC = RFC.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion Matrix\n\ncm_RFC = confusion_matrix(y_test,yp_RFC)\ncm_RFC","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Labels for Confusion Matrix\n\nlabels = ['No Disease', 'Have Disease']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Printing Classification Report and Showing Confusion Matrix\n\nprint(classification_report(y_test, yp_RFC, target_names = labels))\nf, ax = plt.subplots(figsize=(8,5))\nsns.heatmap(cm_RFC, annot=True, fmt=\".0f\", ax=ax)\n\nax.xaxis.set_ticklabels(labels)\nax.yaxis.set_ticklabels(labels)\n\nplt.title('Heart Prediction With Random Forest Classifier')\nplt.xlabel(\"ACTUAL\")\nplt.ylabel(\"PREDICT\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Printing Score\n\nprint(RFC.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Classification Report for Summary\n\nreport_RFC = pd.DataFrame(classification_report(y_test, yp_RFC, target_names= labels, output_dict=True)).T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **K Nearest Neighbors**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Determining the K-Value\n\nk = round(len(x_train)**0.5)+1\nk","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting Model\n\nKNN = KNeighborsClassifier(n_neighbors = k)\nKNN.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# KNN Predict\n\nyp_KNN = KNN.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion Matrix\n\ncm_KNN = confusion_matrix(y_test,yp_KNN)\ncm_KNN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Printing Classification Report and Showing Confusion Matrix \n\nprint(classification_report(y_test, yp_KNN, target_names = labels))\nf, ax = plt.subplots(figsize=(8,5))\nsns.heatmap(cm_KNN, annot=True, fmt=\".0f\", ax=ax)\n\nax.xaxis.set_ticklabels(labels)\nax.yaxis.set_ticklabels(labels)\n\nplt.title('Heart Prediction With KNearest Neighbors')\nplt.xlabel(\"ACTUAL\")\nplt.ylabel(\"PREDICT\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Printing Score\n\nprint(KNN.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Classification Report for Summary\n\nreport_KNN = pd.DataFrame(classification_report(y_test, yp_KNN, target_names= labels, output_dict=True)).T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **SUMMARY**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Showing the Confusion Matrix for both models\n\nfig, (ax1,ax2) = plt.subplots(1,2, figsize=(16,6))\nsns.heatmap(cm_RFC, annot=True, fmt=\".0f\", ax=ax1)\nsns.heatmap(cm_KNN, annot=True, fmt=\".0f\", ax=ax2)\n\nax1.xaxis.set_ticklabels(labels), ax1.yaxis.set_ticklabels(labels)\nax2.xaxis.set_ticklabels(labels), ax2.yaxis.set_ticklabels(labels)\n\nax1.set_title('RFC'), ax2.set_title('KNN')\nax1.set_xlabel('ACTUAL'), ax2.set_xlabel('ACTUAL')\nax1.set_ylabel('PREDICTED'), ax2.set_ylabel('PREDICTED')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('RFC Model : ', RFC.score(x_test,y_test))\nprint('KNN Model : ', KNN.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Printing Classification Report Summary\npd.concat([report_RFC, report_KNN], keys = ['RFC MODEL', 'KNN MODEL'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the two models score comparison above, the Random Forest Classifier is having 0.88 score, while the K - Nearest Neighbors score is only 0.72. The F1-Score, Precision and Recall for Random Forest Classifier is also much higher than K - Nearest Neighbors. Therefore we can see that in predicting this case with the comparison between the two models above, Random Forest Classifier will be a better choice than the K-Nearest Neighbors.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}