{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"27ac5d60-ad4b-fc8c-4413-8fedbaf01a5d"},"source":"#### A Random Forest to try and predict beer styles... n process."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a55f1525-e873-d98e-447a-3cd2599c9950"},"outputs":[],"source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\n%matplotlib inline\nbeer = pd.read_csv(\"../input/beers.csv\")\nbrew = pd.read_csv(\"../input/breweries.csv\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"47607578-d9c2-732c-f731-16ebf0a6c7c9"},"outputs":[],"source":"####Transfrom the beer Data###\n\n#IBU will just be converted to the mean if the feature column, not ideal, but whatevs im lazy\n\nbeer = beer.dropna(subset = [\"style\"])\nclass_map = {label:idx for idx,label in enumerate((beer[\"style\"]))}\nname_map = {label:idx for idx,label in enumerate((beer[\"name\"]))}\nbeer[\"style\"] = beer[\"style\"].map(class_map)\nbeer[\"name\"] = beer[\"name\"].map(name_map)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"70a1b9b7-afa2-224e-b4ba-8c6631dc931a"},"outputs":[],"source":"from sklearn.preprocessing import Imputer\nimp = Imputer()\nimp.fit(beer)\nimputed_data = imp.transform(beer)\nbeer = pd.DataFrame(imputed_data, columns = beer.columns)\nbeer.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9af6d7e1-12ae-b2f2-9c81-c03900c603d8"},"outputs":[],"source":"###Transform the brewery Data###\n#Given that the Name of the brewery,city and state are not ranked either do a simmilr conversion\n#the inv_ _map is just a switcharoo: \n#{v:k for k,v in _map.items()}\ncities = np.unique(brew.city)\n\nbrewery_map = {label:idx for idx,label in enumerate((brew[\"name\"]))}\ncity_map = {label:idx for idx,label in enumerate(cities)}\nstate_map = {label:idx for idx, label in enumerate((brew[\"state\"]))}\n\nbrew[\"name\"] = brew[\"name\"].map(brewery_map)\nbrew[\"city\"] = brew[\"city\"].map(city_map)\nbrew[\"state\"] = brew[\"state\"].map(state_map)\nbrew.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c6a55658-fa51-7243-b979-74fd51392a01"},"outputs":[],"source":"#Im just going to drop the fucking NAs at this point, there's only 16 left\n\ndf = pd.merge(beer,brew)\ndf = df.dropna()\ndf.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b75ad87a-5922-1732-94fd-b71bc51d200b"},"outputs":[],"source":"##Feature Examination, another reason why im using a Random Forest...\n\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\nforest = RandomForestClassifier()\nX,y = df[['abv',\"ibu\",\"id\",\"name\",\"brewery_id\",\"city\",\"state\"]].values, df[\"style\"].values\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 0)\n\nfeat_labels = df[['abv',\"ibu\",\"id\",\"name\",\"brewery_id\",\"city\",\"state\"]]\nforest = RandomForestClassifier(n_estimators=1000,random_state=0,n_jobs=-1)\nforest.fit(X_train,y_train)\nimportance = forest.feature_importances_\nweights = ['abv',\"ibu\",\"id\",\"name\",\"brewery_id\",\"city\",\"state\"]\nindicies = np.argsort(importance)[::-1]\ny_pred = forest.predict(X_test)\n\nprint(\"Misclassified Samples: %d\" %(y_test != y_pred).sum())\nprint(\"Accuracy: %.2f\" % accuracy_score(y_test,y_pred))\n\n#Plot the rankings\nplt.title(\"Feature Importance\")\nplt.bar(range(X_train.shape[1]),importance[indicies],color = \"lightblue\",align = 'center')\nplt.xticks(range(X_train.shape[1]),feat_labels[indicies],rotation = 90)\nplt.xlim([-1,X_train.shape[1]])\nplt.tight_layout()\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e395030b-1add-55a9-d065-1751484a8dc9"},"outputs":[],"source":"#Try With less features and only the beer data\n#Not many NAs left at this point\nbeer = beer.dropna()\n\nX,y = beer[['abv',\"ibu\", \"ounces\"]].values, beer[\"style\"].values\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 0)\n\nforest = RandomForestClassifier(criterion=\"entropy\",n_estimators=10, random_state=1, n_jobs=2)\nforest.fit(X_train,y_train)\ny_pred = forest.predict(X_test)\n\nfeat_labels = beer[['abv',\"ibu\", \"ounces\"]]\nforest = RandomForestClassifier(n_estimators=1000,random_state=0,n_jobs=-1)\nforest.fit(X_train,y_train)\nimportance = forest.feature_importances_\nweights = ['abv',\"ibu\", \"ounces\"]\nindicies = np.argsort(importance)[::-1]\n\nprint(\"Misclassified Samples: %d\" %(y_test != y_pred).sum())\nprint(\"Accuracy: %.2f\" % accuracy_score(y_test,y_pred))\n\n#Plot the rankings\nplt.title(\"Feature Importance\")\nplt.bar(range(X_train.shape[1]),importance[indicies],color = \"lightblue\",align = 'center')\nplt.xticks(range(X_train.shape[1]),feat_labels[indicies],rotation = 90)\nplt.xlim([-1,X_train.shape[1]])\nplt.tight_layout()\nplt.show()"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}