{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Data Description\n##### Pregnancies: Number of times pregnant\n##### Glucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n##### BloodPressure: Diastolic blood pressure (mm Hg)\n##### SkinThickness: Triceps skin fold thickness (mm)\n##### Insulin: 2-Hour serum insulin (mu U/ml)\n##### BMI: Body mass index (weight in kg/(height in m)^2)\n##### DiabetesPedigreeFunction: Diabetes pedigree function\n##### Age: Age (years)\n##### Outcome: Class variable (0 or 1)"},{"metadata":{},"cell_type":"markdown","source":"# Installing\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom lightgbm import LGBMClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, \\\n    classification_report\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\n\nwarnings.simplefilter(action=\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"../input/diabetes-data-set/diabetes.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Since the number of observations is low, we will do an exploratory data analysis using the Cross Validation (CV) method instead of separating the data set as \"test and train\" with the holdout method."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Outcome\"].value_counts() * 100 / len(df) # bagimli degiskenin siniflarinin oranlarin bakiyoruz...","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def outcome_agg(col):\n    for i in col:  \n        print(df.groupby(\"Outcome\").agg({i: \"mean\"}))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_cols(df, target):\n    cols = []\n    for col in df.columns:\n        if col!=target:\n            cols.append(col)\n    return cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"var_names=get_cols(df, \"Outcome\")\nvar_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outcome_agg(var_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_cols2(df, target):\n    cols = [col for col in df.columns if col != target]\n    return cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_cols2(df, \"Outcome\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(\"Outcome\").agg({\"Pregnancies\": \"mean\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(\"Outcome\").agg({\"Glucose\": \"mean\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(\"Outcome\").agg({\"BloodPressure\": \"mean\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(\"Outcome\").agg({\"SkinThickness\": \"mean\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(\"Outcome\").agg({\"Insulin\": \"mean\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(\"Outcome\").agg({\"BMI\": \"mean\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(\"Outcome\").agg({\"DiabetesPedigreeFunction\": \"mean\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(\"Outcome\").agg({\"Age\": \"mean\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe([0.10, 0.25, 0.50, 0.75, 0.90, 0.95, 0.99]).T\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are looking at the description of numeric variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='Outcome', data=df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Outcome\"].value_counts().plot.pie(autopct = \"%.1f\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"df[\"Outcome\"].value_counts().plot.pie(autopct = \"%.1f\")    alternatif visual."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe([0.10, 0.25, 0.50, 0.75, 0.90, 0.95, 0.99]).T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Blood Pressure cannot be \"0\". Be careful! We need new feature..."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Outcome.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Outcome.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(6,4))\nsns.heatmap(df.corr(),cmap='Blues',annot=False);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"If we change the 0 values to NaN before looking at the correlation, we find a more significant correlation."},{"metadata":{"trusted":true},"cell_type":"code","source":"# NaN values of 0 for Glucose, Blood Pressure, Skin Thickness, Insulin, BMI\n# We can write Nan instead of 0\ncols = [\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"]\nfor col in cols:\n    df[col].replace(0,np.NaN,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Outcome correlation matrix\nk = 9 #number of variables for heatmap\ncols = df.corr().nlargest(k, 'Outcome')['Outcome'].index\ncm = df[cols].corr()\nplt.figure(figsize=(10,6))\nsns.heatmap(cm, annot=True, cmap = 'viridis');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# see how the data is distributed.\ndf.hist(figsize = (20,20));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def c_dis_plot(df, cols):\n    for col in cols:\n        sns.distplot(df[col], hist=False)\n        plt.axvline(df[col].mean(),color='r',label='mean')\n        plt.axvline(np.median(df[col]),color='b',label='median')\n        plt.axvline((df[col].mode())[0],color='g',label='mode')\n        plt.legend()\n        plt.show();\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c_dis_plot(df, var_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# A scatter plot for show how two variables are related to each other\nsns.lmplot(\"BloodPressure\", \"Glucose\", df, hue='Outcome', fit_reg=False, height = 5)\nsns.lmplot(\"Glucose\", \"SkinThickness\", df, hue='Outcome', fit_reg=False, height = 5)\nsns.lmplot(\"Glucose\", \"Insulin\", df, hue='Outcome', fit_reg=False, height = 5)\nsns.lmplot(\"Glucose\", \"BMI\", df, hue='Outcome', fit_reg=False, height = 5)\nsns.lmplot(\"Glucose\", \"Age\", df, hue='Outcome', fit_reg=False, height = 5)\nsns.lmplot(\"Glucose\", \"DiabetesPedigreeFunction\", df, hue='Outcome', fit_reg=False, height = 5)\nsns.lmplot(\"Insulin\",\"BloodPressure\",df, hue='Outcome', fit_reg=False, height = 5)\nsns.lmplot(\"Age\", \"BloodPressure\", df, hue='Outcome', fit_reg=False, height = 5)\nsns.lmplot(\"BMI\", \"SkinThickness\", df, hue='Outcome', fit_reg=False, height = 5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DATA PREPROCESSING"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Observation units for variables with a minimum value of zero are NaN, except for the pregnancy variable.\ndf.describe([0.05,0.25,0.50,0.75,0.90,0.95,0.99]).T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"# NaN values of 0 for Glucose, Blood Pressure, Skin Thickness, Insulin, BMI\n# We can write Nan instead of 0\ncols = [\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"]\nfor col in cols:\n    df[col].replace(0,np.NaN,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# now we can see missing values\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can fill in NaN values with a median according to the target\nfor col in df.columns:\n    df.loc[(df[\"Outcome\"]==0) & (df[col].isnull()),col] = df.loc[(df[\"Outcome\"]==0), col].median()\n    df.loc[(df[\"Outcome\"]==1) & (df[col].isnull()),col] = df.loc[(df[\"Outcome\"]==1), col].median()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"By looking at the distribution graphs above (93), a more accurate decision can be made about filling empty values with median, mode or mean."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"def outlier_thresholds(dataframe, variable):\n    quartile1 = dataframe[variable].quantile(0.10)\n    quartile3 = dataframe[variable].quantile(0.90)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def has_outliers(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    if dataframe[(dataframe[variable] < low_limit) | (dataframe[variable] > up_limit)].any(axis=None):\n        print(variable, \"yes\")\n    print(variable, \"no\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in df.columns:\n    has_outliers(df, col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def replace_with_thresholds(dataframe, numeric_columns):\n    for variable in numeric_columns:\n        low_limit, up_limit = outlier_thresholds(dataframe, variable)\n        dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n        dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"replace_with_thresholds(df, df.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in df.columns:\n    has_outliers(df, col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe([0.05,0.25,0.50,0.75,0.90,0.95,0.99]).T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### FEATURE ENGINEERING"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['New_Glucose_Class'] = pd.cut(x=df['Glucose'], bins=[0,139,200],labels = [\"Normal\",\"Prediabetes\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['New_BMI_Range'] = pd.cut(x=df['BMI'], bins=[0,18.5,24.9,29.9,100],labels = [\"Underweight\",\"Healty\",\"Overweight\",\"Obese\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['New_BloodPressure'] = pd.cut(x=df['BloodPressure'], bins=[0,79,89,123],labels = [\"Normal\",\"HS1\",\"HS2\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['New_SkinThickness'] = df['SkinThickness'].apply(lambda x: 1 if x <= 18.0 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Categorical Variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"def one_hot_encoder(dataframe, categorical_columns, nan_as_category=False):\n    original_columns = list(dataframe.columns)\n    dataframe = pd.get_dummies(dataframe, columns=categorical_columns,\n                               dummy_na=nan_as_category, drop_first=True)\n    new_columns = [col for col in dataframe.columns if col not in original_columns]\n    return dataframe, new_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_columns = [col for col in df.columns\n                           if len(df[col].unique()) <= 10\n                      and col != \"Outcome\"]\ncategorical_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df, new_cols_ohe = one_hot_encoder(df,categorical_columns)\nnew_cols_ohe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Standardization"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"* ! Robust is less susceptible to outliers..., x-median(x)/q3-q1 \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def robust_scaler(variable):\n    var_median = variable.median()\n    quartile1 = variable.quantile(0.25)\n    quartile3 = variable.quantile(0.75)\n    interquantile_range = quartile3 - quartile1\n    if int(interquantile_range) == 0:\n        quartile1 = variable.quantile(0.05)\n        quartile3 = variable.quantile(0.95)\n        interquantile_range = quartile3 - quartile1\n        if int(interquantile_range) == 0:\n            quartile1 = variable.quantile(0.10)\n            quartile3 = variable.quantile(0.99)\n            interquantile_range = quartile3 - quartile1\n            z = (variable - var_median) / interquantile_range\n            return round(z, 3)\n\n        z = (variable - var_median) / interquantile_range\n        return round(z, 3)\n    else:\n        z = (variable - var_median) / interquantile_range\n    return round(z, 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"like_num = [col for col in df.columns if df[col].dtypes != 'O' and len(df[col].value_counts()) < 10]\ncols_need_scale = [col for col in df.columns if col not in new_cols_ohe\n                   and col not in \"Outcome\"\n                   and col not in like_num]\n\nfor col in cols_need_scale:\n    df[col] = robust_scaler(df[col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# see how the data is distributed.\ndf.hist(figsize = (20,20));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MODELLING"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop(\"Outcome\",axis=1)\ny = df[\"Outcome\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.preprocessing import RobustScaler\nimport numpy as np\nfrom lightgbm import LGBMClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, \\\n    classification_report\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\npd.set_option('display.max_columns',None)\npd.set_option('display.max_rows',None)\nwarnings.simplefilter(action=\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = [('LR', LogisticRegression()),\n          ('KNN', KNeighborsClassifier()),\n          ('CART', DecisionTreeClassifier()),\n          ('RF', RandomForestClassifier()),\n          ('SVR', SVC(gamma='auto')),\n          ('XGBM', XGBClassifier()),\n          ('GB',GradientBoostingClassifier()),\n          (\"LightGBM\", LGBMClassifier())]\n\n# evaluate each model in turn\nresults = []\nnames = []\n\nfor name, model in models:\n    kfold = KFold(n_splits=10, random_state=123456)\n    cv_results = cross_val_score(model, X, y, cv=10, scoring=\"accuracy\")\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's choose the highest 4 models\n# GBM\ngbm_model = GradientBoostingClassifier()\n# Model Tuning\ngbm_params = {\"learning_rate\": [0.01, 0.1, 0.001],\n               \"max_depth\": [3,5, 8, 10],\n               \"n_estimators\": [200, 500, 1000],\n               \"subsample\": [1, 0.5, 0.8]}\ngbm_cv_model = GridSearchCV(gbm_model,\n                            gbm_params,\n                            cv=10,\n                            n_jobs=-1,\n                            verbose=2).fit(X, y)\ngbm_cv_model.best_params_\n# Final Model\ngbm_tuned = GradientBoostingClassifier(**gbm_cv_model.best_params_).fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LightGBM: \nlgb_model = LGBMClassifier()\n# Model Tuning\nlgbm_params = lgbm_params = {\"learning_rate\": [0.01, 0.5, 1],\n                             \"n_estimators\": [200, 500, 1000],\n                             \"max_depth\": [6, 8, 10],\n                             \"colsample_bytree\": [1, 0.5, 0.4]}\nlgbm_cv_model = GridSearchCV(lgb_model,\n                             lgbm_params,\n                             cv=10,\n                             n_jobs=-1,\n                             verbose=2).fit(X, y)\nlgbm_cv_model.best_params_\n# Final Model\nlgbm_tuned = LGBMClassifier(**lgbm_cv_model.best_params_).fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Forests:\nrf_model = RandomForestClassifier()\n# Model Tuning\nrf_params = {\"max_depth\": [5,10,None],\n            \"max_features\": [2,5,10],\n            \"n_estimators\": [100, 500, 900],\n            \"min_samples_split\": [2,10,30]}\nrf_cv_model = GridSearchCV(rf_model, \n                           rf_params, \n                           cv=10, \n                           n_jobs=-1, \n                           verbose=2).fit(X, y)\nrf_cv_model.best_params_\n# Final Model\nrf_tuned = RandomForestClassifier(**rf_cv_model.best_params_).fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate each model in turn\nmodels = [('RF', rf_tuned),\n          ('GBM',gbm_tuned )]\nresults = []\nnames = []\nfor name, model in models:\n    kfold = KFold(n_splits=10, random_state=123456)\n    cv_results = cross_val_score(model, X, y, cv=10, scoring=\"accuracy\")\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kfold = KFold(n_splits=10, random_state=123456)\ncv_results = cross_val_score(gbm_tuned, X, y, cv=10, scoring=\"accuracy\")\nmsg = \"%s: %f (%f)\" % (\"gbm\", cv_results.mean(), cv_results.std())\nprint(msg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_model = LogisticRegression().fit(X, y)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_model.intercept_\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_model.coef_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"y= 7.7029389 + 1.17252354e-01*Pregnancies + 3.36001406e-02*Glucose -1.40872987e-02*BloodPressure......etc.\n\nNote: There is a difference in logstic regression. We cannot interpret these coefficients as in classical regression, we interpret them as e^coefficient."},{"metadata":{},"cell_type":"markdown","source":"Let's predict the logistic regression model!"},{"metadata":{"trusted":true},"cell_type":"code","source":"log_model.predict(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_model.predict(X)[0:10]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y[0:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_model.predict_proba(X)[0:10]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have predicted probabilities, not the results. 0.28902396 in the first line, the occurrence of \"0\" class; 0.71097604, probability of occurrence of class \"1\" ..."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = log_model.predict(X)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We recorded the predicted values as y_pred. Now we're bringing in the accuracy values. Real value / predicted values"},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(y, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Prediction success is 0.78."},{"metadata":{},"cell_type":"markdown","source":"Now let's test the data set with the 10-fold cross-validation (CV) method, so let's divide the data by 10, build a model with 9 and test it with 1. "},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_val_score(log_model, X, y, cv=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"10 scores came for each cross valudation. Now let's add .mean () to see the average score ..."},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_val_score(log_model, X, y, cv=10).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We used the Cross Valudation method for logistic regression, and if we use it for all other models, we can compare the success of the models from the metric perspective. However, when we have plenty of data, using the holdout method as a \"train\" and \"test\" allows us to measure the predictive power more accurately. Because the model will try to guess the test data it has never seen."},{"metadata":{},"cell_type":"markdown","source":"When the number of classes is unbalanced, values such as \"support\", \"presicion\", \"recall\"  will be important when looking for what to do. Sometimes - class sometimes + class will be important ... look at this!! ....\n\n\"macro avg\" and \"weighted avg\" values should have gotten this value because of there are two classes !! I guess, it will increase when there are more classes ...\n"},{"metadata":{},"cell_type":"markdown","source":"### Visualization   \n \"roc_auc_score\" and \"roc_curve\" are another metric for classification problems."},{"metadata":{"trusted":true},"cell_type":"code","source":"logit_roc_auc = roc_auc_score(y, log_model.predict(X))\nfpr, tpr, thresholds = roc_curve(y, log_model.predict_proba(X)[:, 1])\nplt.figure()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(fpr, tpr, label='AUC (area = %0.2f)' % logit_roc_auc)\nplt.plot([0, 1], [0, 1], 'r--')\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"At the above, we tried to understand the predictive power of the model by looking at the accucy scores. Here, we are looking at the auc score with the curve above. This scor gives the area between the curve and the line."},{"metadata":{"trusted":true},"cell_type":"code","source":"logit_roc_auc = roc_auc_score(y, log_model.predict(X))\nfpr, tpr, thresholds = roc_curve(y, log_model.predict_proba(X)[:, 1])\nplt.figure()\nplt.plot(fpr, tpr, label='AUC (area = %0.2f)' % logit_roc_auc)\nplt.plot([0, 1], [0, 1], 'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")\nplt.savefig('Log_ROC')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")\nplt.savefig('Log_ROC')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_model = RandomForestClassifier(random_state=12345).fit(X, y)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"\ncross_val_score(rf_model, X, y, cv=10).mean()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We looked cross validation with all data"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_params = {\"n_estimators\": [200, 500],\n             \"max_features\": [5, 7],\n             \"min_samples_split\": [5, 10],\n             \"max_depth\": [5, None]}\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reminder: Since we use CV method in logistic regression above, we also use CV here. Since there is little data, we did not separate it as 'test-train'. The best way is to separate the data set called \"test\" and  \"train\", to apply CV to the train set, to test it with the test set."},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_model = RandomForestClassifier(random_state=12345)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We created an empty model, put it in GridSearchCV, leave the model to GridSearchCV to test it ...!"},{"metadata":{"trusted":true},"cell_type":"code","source":"gs_cv = GridSearchCV(rf_model,\n                     rf_params,\n                     cv=10,\n                     n_jobs=-1,\n                     verbose=2).fit(X, y)\n\ngs_cv.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_tuned = RandomForestClassifier(**gs_cv.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_val_score(rf_tuned, X, y, cv=10).mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Light GBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm = LGBMClassifier(random_state=12345)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_val_score(lgbm, X, y, cv=10).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm_params = {\"learning_rate\": [0.01],\n               \"n_estimators\": [100],\n               \"max_depth\": [3, 5]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gs_cv = GridSearchCV(lgbm,         # Try all the above parameters. Whichever parameters give the best results,  \n                     lgbm_params,  # fit the model with those parameters.\n                     cv=5,\n                     n_jobs=-1,\n                     verbose=2).fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We re-entered this Lightgbm and looked at our CV error again.\n\nlgbm_tuned = LGBMClassifier(**gs_cv.best_params_).fit(X, y)\ncross_val_score(lgbm_tuned, X, y, cv=10).mean()"},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm_tuned = LGBMClassifier(**gs_cv.best_params_).fit(X, y)\ncross_val_score(lgbm_tuned, X, y, cv=10).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_model = RandomForestClassifier(random_state=12345).fit(X, y)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_val_score(rf_model, X, y, cv=10).mean()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_params = {\"n_estimators\": [200, 500],\n             \"max_features\": [5, 7],\n             \"min_samples_split\": [5, 10],\n             \"max_depth\": [5, None]}\n\nrf_model = RandomForestClassifier(random_state=12345)\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gs_cv = GridSearchCV(rf_model,\n                     rf_params,\n                     cv=10,\n                     n_jobs=-1,\n                     verbose=2).fit(X, y)\n\ngs_cv.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_tuned = RandomForestClassifier(**gs_cv.best_params_)\ncross_val_score(rf_tuned, X, y, cv=10).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import MinMaxScaler\nfrom yellowbrick.cluster import KElbowVisualizer\nfrom scipy.cluster.hierarchy import linkage\nfrom scipy.cluster.hierarchy import dendrogram\n\nimport warnings","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sc = MinMaxScaler((0, 1))\ndf = sc.fit_transform(df)\ndf[0:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans = KMeans(n_clusters=4)\nk_fit = kmeans.fit(df)\nk_fit","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dir(k_fit)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k_fit.n_clusters\nk_fit.cluster_centers_\nk_fit.labels_\ndf[0:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k_means = KMeans(n_clusters=2).fit(df)\nkumeler = k_means.labels_\ntype(df)\ndf = pd.DataFrame(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(df.iloc[:, 0],\n            df.iloc[:, 1],\n            c=kumeler,\n            s=50,\n            cmap=\"viridis\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merkezler = k_means.cluster_centers_\n\nplt.scatter(df.iloc[:, 0],\n            df.iloc[:, 1],\n            c=kumeler,\n            s=50,\n            cmap=\"viridis\")\n\nplt.scatter(merkezler[:, 0],\n            merkezler[:, 1],\n            c=\"black\",\n            s=200,\n            alpha=0.5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans = KMeans()\nssd = []\nK = range(1, 30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for k in K:\n    kmeans = KMeans(n_clusters=k).fit(df)\n    ssd.append(kmeans.inertia_)\n\nssd\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(K, ssd, \"bx-\")\nplt.xlabel(\"Distance Residual Sums for different K Values\")\nplt.title(\"Elbow Method for Optimum Number of Clusters\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans = KMeans()\nvisu = KElbowVisualizer(kmeans, k=(2, 20))\nvisu.fit(df)\nvisu.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans = KMeans(n_clusters=5).fit(df)\nkumeler = kmeans.labels_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}