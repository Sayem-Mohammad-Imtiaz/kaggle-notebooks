{"cells":[{"metadata":{"_cell_guid":"c2c4a258-c804-4622-9155-b01ac0ee2412","_uuid":"f1bb865aa1a9dfc9906cf6cfdb869f871d82e36e"},"cell_type":"markdown","source":""},{"metadata":{"_kg_hide-input":true,"_cell_guid":"705714b1-870b-4f34-b5bf-cd027dafaefe","_uuid":"bb40a7b23734d82876d812fab6daecd83a46368c","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_samples, silhouette_score\nfrom nltk.tokenize import RegexpTokenizer\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom nltk.corpus import stopwords\nimport matplotlib.pyplot as plt\nfrom random import randint\nfrom wordcloud import WordCloud\nfrom collections import Counter","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_cell_guid":"1063f9e0-e494-4873-939f-8aa5ca40cc89","_uuid":"227fc0cb1d5216d52e057e1d2d7debd0e29abe46","scrolled":true,"trusted":true},"cell_type":"code","source":"df_raw = pd.read_csv('../input/data.csv',encoding=\"ISO-8859-1\")\nprint(df_raw.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fa3b3b22d6e8af8c203667175b75690d628b71b1"},"cell_type":"markdown","source":"<h1>Data preprocessing</h1>"},{"metadata":{"_kg_hide-input":true,"_cell_guid":"f9de6b67-a588-43ab-8f51-b28efdee9e32","_uuid":"9b915fa18b311e8f93ac862bd49d08d90e03ca48","trusted":true,"scrolled":false},"cell_type":"code","source":"df_raw.dropna(axis = 0, subset = ['Description'], inplace = True)\nprint('Dataframe dimensions:', df_raw.shape)\nprint(df_raw['Description'].head())\nprint(df_raw.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8e758b35b309ac82a6e58eaacf5e3f440c1fabdd","scrolled":true},"cell_type":"code","source":"df_desc = pd.DataFrame(df_raw['Description'].unique()).rename(columns = {0:'Description'})\nprint(df_desc.shape)\nprint(df_desc)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"38f194373abb9131b2e9be5f916d8dd3809c10cb"},"cell_type":"markdown","source":"Only unqiue decriptions are filtered."},{"metadata":{"_uuid":"3bc11d5eca36291a05eddb2a6fba5a87d3af515d"},"cell_type":"markdown","source":"<b>Data exploration</b>****"},{"metadata":{"trusted":true,"_uuid":"078caa460ff54b3f0e856f69417b6760d8c2f854"},"cell_type":"code","source":"# explore the punctuations in the data\nfind_dict={}\nnewp='\"#$%&\\'()*+-/:;<=>@[\\]^_`{|}~.?'\nfor i, row in df_desc.iterrows():\n    for c in newp:\n        #print(c)\n        #print(row)\n        if c in row['Description']:\n            val=find_dict.get(c,'')\n            find_dict[c]=val+'|'+row['Description']\n            #print('find:',c)\n           # print(row['Description'])\n#print(list(find_dict))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea204034381eee7d43bf01b73a76c91ca28aa928"},"cell_type":"markdown","source":"<b>Tokenization & Punctuation pre-processing & Stop words removal & Lematization</b>"},{"metadata":{"trusted":true,"_uuid":"c8b149d6c4bbdaf85f2d423db1af7fed8ac0c5ca"},"cell_type":"code","source":"def punc_processing(st):\n    for i,c in enumerate(list(st)):\n        if c == '\\'':\n            #clean example like 'n'\n            if i==0:\n                #print(st)\n                st_clean=st[1:(len(st)-1)]\n                #print(st_clean)\n                return st_clean\n            #clean example like b'fly\n            if i==1:\n                #print(st)\n                st_clean=st[2:]\n                #print(st_clean)\n                return st_clean\n            #clean example like mother's\n            if i!=0 and st[i-1]!=' ':\n                #print(st)\n                st_clean=st[:(i)]+st[(i+2):]\n                #print(st_clean)\n                return st_clean\n        if c == '\"':\n            #clean example like \"glamorous\"\n            if i==0:\n                #print(st)\n                st_clean=st[1:(len(st)-1)]\n                #print(st_clean)\n                return st_clean        \n    return st","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"963a4ff4219324ea1f11e10c17297c185b3c6f6c","scrolled":true},"cell_type":"code","source":"newp='[\"&\\'()+-/[\\].]'\nfront_quotation='[\\\"\\'(]'\nend_quotation='[\\\"\\')]'\nconnect_quotation='&/+,'\ntoker = RegexpTokenizer('[a-z]+'+newp+'[a-z]+|[a-z]+|'+front_quotation+'[a-z]+'+end_quotation)\nwordnet_lemmatizer=WordNetLemmatizer()\nstopWords = set(stopwords.words('english'))\nstopWords.update(['small', 'large', 'jumbo', 'set', 'pink', 'blue', 'tag', 'red', 'white'])\nfrom nltk.stem.snowball import SnowballStemmer\nstemmer = SnowballStemmer(\"english\")\n\ndf_desc['token']=None\ndf_desc['token_list']=None\n\nfor i, row in df_desc.iterrows():\n    descp_st=row['Description'].lower()\n    for quot in connect_quotation:\n        descp_st=descp_st.replace(quot, ' '+quot+' ')\n    #Tokenization\n    descp_l=toker.tokenize(descp_st)\n    #Punctuation pre-processing\n    descp_l=[punc_processing(x) for x in descp_l]\n    #Stop words removal\n    descp_l2=[x for x in descp_l if x not in stopWords ]\n    \n    #test if use steming to pre-process\n    #descp_l2=[stemmer.stem(x) for x in descp_l2]\n    \n    #Lematization\n    descp_l2=[wordnet_lemmatizer.lemmatize(x) for x in descp_l2]\n    df_desc.loc[i,'token_list']=descp_l2\n    df_desc.loc[i, 'token']=' '.join(descp_l2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"16368df6bce25f7773a5230894bc3b58ad3a3acb"},"cell_type":"markdown","source":"Description are tokenized into a list of tokens. During tokenization, words with punctuations are processed so that most semantic meaning remains."},{"metadata":{"_uuid":"641642ca8f4c37c725ff34fac3a345e649d74dab"},"cell_type":"markdown","source":"<b>Testing if pre-processing succed</b>"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"28f0e2ac577201dd33788830f15acad52b806a3e"},"cell_type":"code","source":"#test if stop word or words mislead clustering correctly\nprint('Number of common stop words:', len(stopwords.words('english')))\nprint('Example of common stop words(not all stop words listed):', stopwords.words('english')[:30], '\\n')\nprint('Number of unwanted words in these sample:', len(['small', 'large', 'jumbo', 'set', 'pink', 'blue', 'tag', 'red', 'white']))\nprint('Example of unwanted words in these sample:', ['small', 'large', 'jumbo', 'set', 'pink', 'blue', 'tag', 'red', 'white'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e79f26baeb98fe281c1a9c657b3dc48e206426ef","scrolled":true},"cell_type":"code","source":"#test if punctation are filttered correctly\nfind_dict={}\nnewp='\"#$%&\\'()*+-/:;<=>@[\\]^_`{|}~.?'\nfor i, row in df_desc.iterrows():\n    for c in newp:\n        if c in row['Description']:\n            #print('Punctuation:',c)\n            #print('Original description:',row['Description'])\n            #print('After pre-processing:',row['token_list'], '\\n')\n            newp.replace(c, '')\n            break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"fa2851a9383c655e39245f3e24251bb9bd9a631e"},"cell_type":"code","source":"#test if stopwords filttered correctly\n# col='OF'\n# for i, row in df_desc.iterrows():\n#     if col in row['Description']:\n#         print('Remove the word:',col)\n#         print(row['Description'])\n#         print(row['token_list'])\n#         print('\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"655fbde4a6e5f2764050841e1203527d31507801"},"cell_type":"code","source":"#test if lematize correctly\n# col='AGED'\n# for i, row in df_desc.iterrows():\n#     if col in row['Description']:\n#         print('Lematize the word:',col)\n#         print(row['Description'])\n#         print(row['token_list'])\n#         print('\\n')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b8b0f1b725b0188376ed9998eb8db207a228f429"},"cell_type":"markdown","source":"Above are to print the result to test if pre-processing is correct"},{"metadata":{"_uuid":"5d84fe2a7a7546b0d921f2e1eb5bc6ec5349d146"},"cell_type":"markdown","source":"<b>Vectorization as bag-of-words</b>"},{"metadata":{"trusted":true,"_uuid":"bfa0f6ab9ada0ab2d402f62f305c74f0d5051541","scrolled":true},"cell_type":"code","source":"print(df_desc[['Description','token_list']])\nvectorizer = CountVectorizer(min_df=1)\n\ndata_desc_doc = vectorizer.fit_transform(df_desc['token'])\nfeature_name = vectorizer.get_feature_names()\n\nprint('Number of words appeared in corpus:', len(feature_name))\nprint('Example of words appeared in corpus(not all listed):',feature_name[:30], '\\n')\nprint(df_desc.head(1))\nprint(data_desc_doc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"818a28dba8a52de6c634d85c657654ab64c20531"},"cell_type":"code","source":"print(data_desc_doc.toarray())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d44a9cc8a65acc4923b98d299b2e649b64f36a99"},"cell_type":"markdown","source":"Vectorization is applied to each row of data"},{"metadata":{"_uuid":"b127dd9eead721d3f50e5ab6f949d81a69552460"},"cell_type":"markdown","source":"<h1>K-means clustering</h1>"},{"metadata":{"_uuid":"0fa25c55ebf532852131be31d784bdf67f187ed0"},"cell_type":"markdown","source":"<b> Metrics evaluation using silhouette score </b>"},{"metadata":{"trusted":true,"_uuid":"207492300394c437601c7192ea75ad5511cbf0c5"},"cell_type":"code","source":"def findBestN(matrix):\n    for n in range(3,15):\n        kmeans = KMeans(n_clusters = n, n_init=20, random_state=0 )\n        kmeans.fit(matrix)\n        clusters = kmeans.predict(matrix)\n        silhouette_avg = silhouette_score(matrix, clusters)\n        print(\"For n_clusters =\", n, \"The average silhouette_score is :\", silhouette_avg)\n        \nfindBestN(data_desc_doc)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9148bd9867082ad0005070889e7610045b2827ac"},"cell_type":"markdown","source":"K-means clustering using different number of n is done. The result of greatest silhouette score is used as it gives best performance of clustering."},{"metadata":{"_uuid":"8aaa9698e567552a577c04251a0866fb352b8ee7"},"cell_type":"markdown","source":"<b> K-means clustering using 12 clustered group  </b>"},{"metadata":{"trusted":true,"_uuid":"19784ca5ae4f39a9784868f10843e56dcb09cd87","scrolled":true},"cell_type":"code","source":"best_no_of_cluster= 12\n#k means clustering\nkmeans = KMeans(n_clusters = best_no_of_cluster, n_init=20, random_state=0 )\nkmeans.fit(data_desc_doc)\nkm_result=kmeans.predict(data_desc_doc)\ndf_desc['cluster_group']=pd.Series(km_result)\n\ndef desinate_color(word=None, position=None,orientation=None,font_size=None,  font_path=None, random_state=0):\n    h = randint(rand_tone*3,rand_tone*3)\n    s = randint(90,100)\n    l = randint(40,60)\n    return \"hsl({}, {}%, {}%)\".format(h, s, l)\n\nfig = plt.figure(1, figsize=(20,20))\nfor a in range(0,best_no_of_cluster,1):    \n    df_temp=df_desc[df_desc['cluster_group']==a]\n    #print(a,' size:', df_temp.shape)\n    #print(df_temp)\n    \n    c = Counter()\n    rand_tone=a\n    for i, row in df_temp.iterrows():\n        c.update(row['token_list'])       \n    wordcloud = WordCloud(width=1000,height=400, background_color='lightgrey', color_func = desinate_color, relative_scaling=0.15, random_state=0)\n    wordcloud.generate_from_frequencies(c)\n    axis_1 = fig.add_subplot(4,3,(a+1))\n    axis_1.imshow(wordcloud)\n    axis_1.axis('off')\n    plt.title('Cluster n={}'.format(a+1))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b81f9ce8793c65f07d3ca6b250b0b4ad15d2e178"},"cell_type":"markdown","source":"K-means clustering using n=12 is used. Resulted is generated in form of word cloud."},{"metadata":{"trusted":true,"_uuid":"31679cd002c248875a8a1fc586dae2c73bdaa066"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7e4a0d43b6f3ea051ad4aede7803eba9e6a111ad"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0cd9578b2e50482388d650e80546377e5d82154e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}