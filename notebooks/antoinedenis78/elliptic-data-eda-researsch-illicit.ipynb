{"cells":[{"metadata":{},"cell_type":"markdown","source":"## General information\n\njeu de donnée :  Elliptic Data Set. \nobjectif : explore the data - trouver des datas illicite intéressante\n","execution_count":null},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"!pip install -U vega_datasets notebook vega","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"\nfrom __future__ import print_function, division\n\nimport numpy as np\nimport pandas as pd\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom tqdm import tqdm_notebook\npd.options.display.precision = 15\n\nimport time\nimport datetime\nimport gc\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom IPython.display import HTML\nimport json\nimport altair as alt\n\nimport networkx as nx\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport plotly.offline as py \nimport plotly.graph_objs as go \npy.init_notebook_mode(connected=True)\n\nalt.renderers.enable('notebook')\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.metrics import f1_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.cluster import KMeans\nfrom sklearn.model_selection import GridSearchCV\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nimport torch.nn.functional as F\ntorch.manual_seed(15)\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import altair as alt\nfrom altair.vega import v5\nfrom IPython.display import HTML\n\n# using ideas from this kernel: https://www.kaggle.com/notslush/altair-visualization-2018-stackoverflow-survey\ndef prepare_altair():\n    \"\"\"\n    Helper function to prepare altair for working.\n    \"\"\"\n\n    vega_url = 'https://cdn.jsdelivr.net/npm/vega@' + v5.SCHEMA_VERSION\n    vega_lib_url = 'https://cdn.jsdelivr.net/npm/vega-lib'\n    vega_lite_url = 'https://cdn.jsdelivr.net/npm/vega-lite@' + alt.SCHEMA_VERSION\n    vega_embed_url = 'https://cdn.jsdelivr.net/npm/vega-embed@3'\n    noext = \"?noext\"\n    \n    paths = {\n        'vega': vega_url + noext,\n        'vega-lib': vega_lib_url + noext,\n        'vega-lite': vega_lite_url + noext,\n        'vega-embed': vega_embed_url + noext\n    }\n    \n    workaround = f\"\"\"    requirejs.config({{\n        baseUrl: 'https://cdn.jsdelivr.net/npm/',\n        paths: {paths}\n    }});\n    \"\"\"\n    \n    return workaround\n    \n\ndef add_autoincrement(render_func):\n    # Keep track of unique <div/> IDs\n    cache = {}\n    def wrapped(chart, id=\"vega-chart\", autoincrement=True):\n        if autoincrement:\n            if id in cache:\n                counter = 1 + cache[id]\n                cache[id] = counter\n            else:\n                cache[id] = 0\n            actual_id = id if cache[id] == 0 else id + '-' + str(cache[id])\n        else:\n            if id not in cache:\n                cache[id] = 0\n            actual_id = id\n        return render_func(chart, id=actual_id)\n    # Cache will stay outside and \n    return wrapped\n           \n\n@add_autoincrement\ndef render(chart, id=\"vega-chart\"):\n    \"\"\"\n    Helper function to plot altair visualizations.\n    \"\"\"\n    chart_str = \"\"\"\n    <div id=\"{id}\"></div><script>\n    require([\"vega-embed\"], function(vg_embed) {{\n        const spec = {chart};     \n        vg_embed(\"#{id}\", spec, {{defaultStyle: true}}).catch(console.warn);\n        console.log(\"anything?\");\n    }});\n    console.log(\"really...anything?\");\n    </script>\n    \"\"\"\n    return HTML(\n        chart_str.format(\n            id=id,\n            chart=json.dumps(chart) if isinstance(chart, dict) else chart.to_json(indent=None)\n        )\n    )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"le dataset comporte 3 fichiers, voici le load","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Data loading and overview","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_classes = pd.read_csv('/kaggle/input/elliptic-data-set/elliptic_bitcoin_dataset/elliptic_txs_classes.csv')\ndf_features = pd.read_csv('/kaggle/input/elliptic-data-set/elliptic_bitcoin_dataset/elliptic_txs_features.csv', header=None)\ndf_edgelist = pd.read_csv('/kaggle/input/elliptic-data-set/elliptic_bitcoin_dataset/elliptic_txs_edgelist.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have the following data:\n- 203769 transactions / graph nodes;\n- 234355 bitcoin flows / graph edges;\n- `elliptic_txs_edgelist.csv` contains graph edges information;\n- `elliptic_txs_classes.csv` contains information about legality of transactions;\n- `elliptic_txs_features.csv` contains information about transaction features;","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_classes['class'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Class `1` = la transaction est illicite \n* Class '2' = la transaction est licite\n* On a ici 42019 transactions licite et 4545 transactions illicite\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_features.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Le document avec les features est totalement anonimysé, il n'a pas de noms de colonnes, voici les indications de la description des datas :\n- première colonne (avec comme nom `0`) est l' id de transaction;\n- la colonne '1' représente la période de chaque noeud. Ces dates / heures ont une intervale de 2 semaines. Chaque dates / heure contient des composant de transactions connectés, qui apparaissent dans la blockchain après moins de trois heures entre chaque.\n- Les 93 colonnes suivantes affichent des informations sur la transaction: nombre d'entrées / sorties, frais de transaction, volume de sortie et chiffres agrégés tels que le BTC moyen reçu (dépensé) par les entrées / sorties et le nombre moyen de transactions entrantes (sortantes) associées aux entrées / les sorties;\n- les 72 fonctionnalités restantes sont des fonctionnalités agrégées, obtenues en utilisant les informations de transaction un saut en arrière / en avant à partir du nœud central - donnant les coefficients maximum, minimum, d'écart type et de corrélation des transactions voisines pour les mêmes données d'information (nombre d'entrées / sorties, frais de transaction, etc.).\n\n- toutes ces informations sont intéressante car grâce à certaines de ces features nous allons pouvoir avoir des informations exacte sur les transaction et le trajet des BTC et donc faire un rapport entre celles ci et leur status frauduleux ou non.\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"On délimite ces colonnes ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# renaming columns\ndf_features.columns = ['id', 'time step'] + [f'trans_feat_{i}' for i in range(93)] + [f'agg_feat_{i}' for i in range(72)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_features.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Nombre de transactions et classes","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"On délimite les période et on regarde combien de transaction pour chaque ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_features['time step'].value_counts().sort_index().plot();\nplt.title('Number of transactions in each time step');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Considérant que le delta entre les pas de temps est de 2 semaines (comme dit dans la documentation), nous avons 98 semaines - presque 2 ans. Il y avait des tendances à la hausse et à la baisse, mais nous ne pouvons rien voir d'intéressant sur une simple observation de ces volumes. Divisons les transactions par classe.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"on divise maintenant les transactions par classe","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# merge with classes\ndf_features = pd.merge(df_features, df_classes, left_on='id', right_on='txId', how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 8))\ngrouped = df_features.groupby(['time step', 'class'])['id'].count().reset_index().rename(columns={'id': 'count'})\nsns.lineplot(x='time step', y='count', hue='class', data=grouped);\nplt.legend(loc=(1.0, 0.8));\nplt.title('Number of transactions in each time step by class');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Maintenant, nous pouvons voir qu'il y avait des pics de transactions illicites qui se produisaient généralement quand il y avait une augmentation générale du nombre de transactions.\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":" ## exemples de graphs","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Jetons un coup d'œil à un graphique à un moment donné. \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"bad_ids = df_features.loc[(df_features['time step'] == 37) & (df_features['class'] == '1'), 'id']\nshort_edges = df_edgelist.loc[df_edgelist['txId1'].isin(bad_ids)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"graph = nx.from_pandas_edgelist(short_edges, source = 'txId1', target = 'txId2', \n                                 create_using = nx.DiGraph())\npos = nx.spring_layout(graph)\nnx.draw(graph, cmap = plt.get_cmap('rainbow'), with_labels=True, pos=pos)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"graph1 = nx.from_pandas_edgelist(short_edges, source = 'txId1', target = 'txId2', \n                                 create_using = nx.Graph())\npos1 = nx.spring_layout(graph1)\nnx.draw(graph1, cmap = plt.get_cmap('rainbow'), with_labels=False, pos=pos1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Nous pouvons clairement voir que certains fraudeurs ont travaillé seuls et certains ont travaillé en groupe.\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Explorons les features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# grouped = df_features.groupby(['time step', 'class'])['trans_feat_0'].mean().reset_index()\n# chart = alt.Chart(grouped).mark_line().encode(\n#     x=alt.X(\"time step:N\", axis=alt.Axis(title='Time step', labelAngle=315)),\n#     y=alt.Y('trans_feat_0:Q', axis=alt.Axis(title='Mean of trans_feat_0')),\n#     color = 'class:N',\n#     tooltip=['time step:O', 'trans_feat_0:Q', 'class:N']\n# ).properties(title=\"Average trans_feat_0 in each time step by type\", width=600).interactive()\n# chart","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"etude de la première feature","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 8))\ngrouped = df_features.groupby(['time step', 'class'])['trans_feat_0'].mean().reset_index()\nsns.lineplot(x='time step', y='trans_feat_0', hue='class', data=grouped);\nplt.legend(loc=(1.0, 0.8));\nplt.title('Average trans_feat_0 in each time step by type');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# \nNous pouvons voir que cette feature peut séparer efficacement les transactions illicites des transactions licites.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"ANALYSE V2 , graphiques plus explicites\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"premièrement je récupère les données\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"edges = pd.read_csv(\"/kaggle/input/elliptic-data-set/elliptic_bitcoin_dataset/elliptic_bitcoin_dataset/elliptic_txs_edgelist.csv\")\nfeatures = pd.read_csv(\"/kaggle/input/elliptic-data-set/elliptic_bitcoin_dataset/elliptic_bitcoin_dataset/elliptic_txs_features.csv\",header=None)\nclasses = pd.read_csv(\"/kaggle/input/elliptic-data-set/elliptic_bitcoin_dataset/elliptic_bitcoin_dataset/elliptic_txs_classes.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"longueur des jeu de données","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"len(edges),len(features),len(classes)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On display les premier éléments des 3 fichier ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"display(edges.head(5),features.head(5),classes.head(5))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tx_features = [\"tx_feat_\"+str(i) for i in range(2,95)]\nagg_features = [\"agg_feat_\"+str(i) for i in range(1,73)]\nfeatures.columns = [\"txId\",\"time_step\"] + tx_features + agg_features\nfeatures = pd.merge(features,classes,left_on=\"txId\",right_on=\"txId\",how='left')\nfeatures['class'] = features['class'].apply(lambda x: '0' if x == \"unknown\" else x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Class = licite ou illicite, ou on ne sait pas , voici les résultats ,\n* Class `0` = on ne sait pas\n* Class `1` = la transaction est illicite \n* Class '2' = la transaction est licite","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"features.groupby('class').size()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_by_class = features[[\"time_step\",'class']].groupby(['time_step','class']).size().to_frame().reset_index()\nillicit_count = count_by_class[count_by_class['class'] == '1']\nlicit_count = count_by_class[count_by_class['class'] == '2']\nunknown_count = count_by_class[count_by_class['class'] == \"0\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"on compare la proportion de licite / illicite / unknow par rapport aux time step","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x_list = list(range(1,50))\nfig = go.Figure(data = [\n    go.Bar(name=\"Unknown\",x=x_list,y=unknown_count[0],marker = dict(color = 'rgba(120, 100, 180, 0.6)',\n        line = dict(\n            color = 'rgba(120, 100, 180, 1.0)',width=1))),\n    go.Bar(name=\"Licit\",x=x_list,y=licit_count[0],marker = dict(color = 'rgba(246, 78, 139, 0.6)',\n        line = dict(\n            color = 'rgba(246, 78, 139, 1.0)',width=1))),\n    go.Bar(name=\"Illicit\",x=x_list,y=illicit_count[0],marker = dict(color = 'rgba(58, 190, 120, 0.6)',\n        line = dict(\n            color = 'rgba(58, 190, 120, 1.0)',width=1)))\n\n])\nfig.update_layout(barmode='stack')\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ici on va chercher à voir la répartition des transactions illicite. On voit ici des populations qui sont rapproché. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"bad_ids = features[(features['time_step'] == 32) & ((features['class'] == '1'))]['txId']\nshort_edges = edges[edges['txId1'].isin(bad_ids)]\ngraph = nx.from_pandas_edgelist(short_edges, source = 'txId1', target = 'txId2', \n                                 create_using = nx.DiGraph())\npos = nx.spring_layout(graph)\n\nedge_x = []\nedge_y = []\nfor edge in graph.edges():\n    x0, y0 = pos[edge[0]]\n    x1, y1 = pos[edge[1]]\n    edge_x.append(x0)\n    edge_x.append(x1)\n    edge_x.append(None)\n    edge_y.append(y0)\n    edge_y.append(y1)\n    edge_y.append(None)\n\nedge_trace = go.Scatter(\n    x=edge_x, y=edge_y,\n    line=dict(width=0.5, color='blue'),\n    hoverinfo='none',\n    mode='lines')\n\nnode_x = []\nnode_y = []\nnode_text=[]\nfor node in graph.nodes():\n    x, y = pos[node]\n    node_x.append(x)\n    node_y.append(y)\n    node_text.append(node)\n\nnode_trace = go.Scatter(\n    x=node_x, y=node_y,\n    mode='markers',\n    hoverinfo='text',\n    marker=dict(\n        color=[],\n        size=10,\n        colorbar=dict(\n            thickness=15,\n            title='Transaction Type',\n            xanchor='left',\n            titleside='right',\n            tickmode='array',\n            tickvals=[0,1,2],\n            ticktext=['Unknown','Illicit','Licit']\n        ),\n        line_width=2))\nnode_trace.text=node_text\nnode_trace.marker.color = pd.to_numeric(features[features['txId'].isin(list(graph.nodes()))]['class'])\n\nfig = go.Figure(data=[edge_trace, node_trace],\n             layout=go.Layout(\n                title=\"Illicit Transactions\",\n                titlefont_size=16,\n                showlegend=False,\n                hovermode='closest',\n                margin=dict(b=20,l=5,r=5,t=40),\n                annotations=[ dict(\n                    showarrow=True,\n                    xref=\"paper\", yref=\"paper\",\n                    x=0.005, y=-0.002 ) ],\n                xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n                yaxis=dict(showgrid=False, zeroline=False, showticklabels=False))\n                )\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On voit clairement ci-dessus des groupement de transactions à caractère illicite et d'autres isolés","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Pyuis les licites. Très dispersé ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"good_ids = features[(features['time_step'] == 32) & ((features['class'] == '2'))]['txId']\nshort_edges = edges[edges['txId1'].isin(good_ids)]\ngraph = nx.from_pandas_edgelist(short_edges, source = 'txId1', target = 'txId2', \n                                 create_using = nx.DiGraph())\npos = nx.spring_layout(graph)\n\nedge_x = []\nedge_y = []\nfor edge in graph.edges():\n    x0, y0 = pos[edge[0]]\n    x1, y1 = pos[edge[1]]\n    edge_x.append(x0)\n    edge_x.append(x1)\n    edge_x.append(None)\n    edge_y.append(y0)\n    edge_y.append(y1)\n    edge_y.append(None)\n\nedge_trace = go.Scatter(\n    x=edge_x, y=edge_y,\n    line=dict(width=0.5, color='blue'),\n    hoverinfo='none',\n    mode='lines')\n\nnode_x = []\nnode_y = []\nnode_text=[]\nfor node in graph.nodes():\n    x, y = pos[node]\n    node_x.append(x)\n    node_y.append(y)\n    node_text.append(node)\n\nnode_trace = go.Scatter(\n    x=node_x, y=node_y,\n    mode='markers',\n    hoverinfo='text',\n    marker=dict(\n        color=[],\n        size=10,\n        colorbar=dict(\n            thickness=15,\n            title='Transaction Type',\n            xanchor='left',\n            titleside='right',\n            tickmode='array',\n            tickvals=[0,1,2],\n            ticktext=['Unknown','Illicit','Licit']\n        ),\n        line_width=2))\nnode_trace.text=node_text\nnode_trace.marker.color = pd.to_numeric(features[features['txId'].isin(graph.nodes())]['class'])\n\nfig = go.Figure(data=[edge_trace, node_trace],\n             layout=go.Layout(\n                title=\"Licit Transactions\",\n                titlefont_size=16,\n                showlegend=False,\n                hovermode='closest',\n                margin=dict(b=20,l=5,r=5,t=40),\n                annotations=[ dict(\n                    showarrow=True,\n                    xref=\"paper\", yref=\"paper\",\n                    x=0.005, y=-0.002 ) ],\n                xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n                yaxis=dict(showgrid=False, zeroline=False, showticklabels=False))\n                )\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* MACHINE LEARNING PART ,\n\non ne s'intéresse QUE aux transactions licite et illicite, le reste on ignore","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = features[(features['class']=='1') | (features['class']=='2')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.metrics import f1_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.cluster import KMeans\nfrom sklearn.model_selection import GridSearchCV\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nimport torch.nn.functional as F\ntorch.manual_seed(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data[tx_features+agg_features]\ny = data['class']\ny = y.apply(lambda x: 0 if x == '2' else 1 )\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=15,shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg = LogisticRegression().fit(X_train,y_train)\npreds = reg.predict(X_test)\nprec,rec,f1,num = precision_recall_fscore_support(y_test,preds, average=None)\nprint(\"Logistic Regression\")\nprint(\"Precision:%.3f \\nRecall:%.3f \\nF1 Score:%.3f\"%(prec[1],rec[1],f1[1]))\nmicro_f1 = f1_score(y_test,preds,average='micro')\nprint(\"Micro-Average F1 Score:\",micro_f1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = RandomForestClassifier(n_estimators=50, max_depth=100,random_state=15).fit(X_train,y_train)\npreds = clf.predict(X_test)\nprec,rec,f1,num = precision_recall_fscore_support(y_test,preds, average=None)\nprint(\"Random Forest Classifier\")\nprint(\"Precision:%.3f \\nRecall:%.3f \\nF1 Score:%.3f\"%(prec[1],rec[1],f1[1]))\nmicro_f1 = f1_score(y_test,preds,average='micro')\nprint(\"Micro-Average F1 Score:\",micro_f1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class LoadData(Dataset):\n    \n    def __init__(self,X,y):\n        self.X = X\n        self.y = y\n        \n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n\n        features = self.X.iloc[idx]\n        features = np.array([features])\n        label = y.iloc[idx]\n\n        return features,label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindata = LoadData(X_train,y_train)\ntrain_loader = DataLoader(traindata,batch_size=128,shuffle=True)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testdata = LoadData(X_test,y_test)\ntest_loader = DataLoader(testdata,batch_size=128,shuffle=False) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn.functional as F\n\nclass Network(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.hidden = nn.Linear(165,50 )\n\n        self.output = nn.Linear(50,1)\n        self.out = nn.Sigmoid()\n        \n    def forward(self, x):\n\n        x = F.relu(self.hidden(x))\n\n        x = self.out(self.output(x))\n        \n        return x\n\nmodel = Network()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\ncriterion=nn.BCELoss()\nn_epochs=10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for epoch in range(n_epochs):\n        model.to('cuda')\n        model.train()\n        running_loss = 0.\n        for data in train_loader:\n            x,label=data\n            x,label=x.cuda(),label.cuda()\n            output = model.forward(x.float())\n            output = output.squeeze()\n            loss = criterion(output.float(), label.float())\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        else:\n            print(f\"Training loss: {running_loss/len(train_loader)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_preds = []\nfor data in test_loader:\n    x,labels = data\n    x,labels = x.cuda(),labels.cuda()\n    preds = model.forward(x.float())\n    all_preds.extend(preds.squeeze().detach().cpu().numpy())\n\npreds = pd.Series(all_preds).apply(lambda x: round(x))\nprec,rec,f1,num = precision_recall_fscore_support(y_test,preds, average=None)\nprint(\"MLP\")\nprint(\"Precision:%.3f \\nRecall:%.3f \\nF1 Score:%.3f\"%(prec[1],rec[1],f1[1]))\nmicro_f1 = f1_score(y_test,preds,average='micro')\nprint(\"Micro-Average F1 Score:\",micro_f1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embed_names = [\"emb_\"+str(i) for i in range(1,51)]\nembeddings = pd.read_csv('/kaggle/input/ellipticemb50d/elliptic.emb',delimiter=\" \",skiprows=1,header=None)\nembeddings.columns = ['txId'] + [\"emb_\"+str(i) for i in range(1,51)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = features[(features['class']=='1') | (features['class']=='2')]\ndata = pd.merge(data,embeddings,how='inner')\nX = data[tx_features+agg_features+embed_names]\ny = data['class']\ny = y.apply(lambda x: 0 if x == '2' else 1 )\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=15,shuffle=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg = LogisticRegression().fit(X_train,y_train)\npreds = reg.predict(X_test)\nprec,rec,f1,num = precision_recall_fscore_support(y_test,preds, average=None)\nprint(\"Logistic Regression\")\nprint(\"Precision:%.3f \\nRecall:%.3f \\nF1 Score:%.3f\"%(prec[1],rec[1],f1[1]))\nmicro_f1 = f1_score(y_test,preds,average='micro')\nprint(\"Micro-Average F1 Score:\",micro_f1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = RandomForestClassifier(n_estimators=50, max_depth=100,random_state=15).fit(X_train,y_train)\npreds = clf.predict(X_test)\nprec,rec,f1,num = precision_recall_fscore_support(y_test,preds, average=None)\nprint(\"Random Forest Classifier\")\nprint(\"Precision:%.3f \\nRecall:%.3f \\nF1 Score:%.3f\"%(prec[1],rec[1],f1[1]))\nmicro_f1 = f1_score(y_test,preds,average='micro')\nprint(\"Micro-Average F1 Score:\",micro_f1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindata = LoadData(X_train,y_train)\ntrain_loader = DataLoader(traindata,batch_size=128,shuffle=True)  \n\ntestdata = LoadData(X_test,y_test)\ntest_loader = DataLoader(testdata,batch_size=128,shuffle=False)  \n\nimport torch.nn.functional as F\n\nclass Network(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.hidden = nn.Linear(215,50 )\n\n        self.output = nn.Linear(50,1)\n        self.out = nn.Sigmoid()\n        \n    def forward(self, x):\n\n        x = F.relu(self.hidden(x))\n\n        x = self.out(self.output(x))\n        \n        return x\n\nmodel = Network()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\ncriterion=nn.BCELoss()\nn_epochs=10\n\nfor epoch in range(n_epochs):\n        model.to('cuda')\n        model.train()\n        running_loss = 0.\n        for data in train_loader:\n            x,label=data\n            x,label=x.cuda(),label.cuda()\n            output = model.forward(x.float())\n            output = output.squeeze()\n            loss = criterion(output.float(), label.float())\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        else:\n            print(f\"Training loss: {running_loss/len(train_loader)}\")\n            \nall_preds = []\nfor data in test_loader:\n    x,labels = data\n    x,labels = x.cuda(),labels.cuda()\n    preds = model.forward(x.float())\n    all_preds.extend(preds.squeeze().detach().cpu().numpy())\n\npreds = pd.Series(all_preds).apply(lambda x: round(x))\nprec,rec,f1,num = precision_recall_fscore_support(y_test,preds, average=None)\nprint(\"MLP\")\nprint(\"Precision:%.3f \\nRecall:%.3f \\nF1 Score:%.3f\"%(prec[1],rec[1],f1[1]))\nmicro_f1 = f1_score(y_test,preds,average='micro')\nprint(\"Micro-Average F1 Score:\",micro_f1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}