{"cells":[{"metadata":{"_uuid":"29bf13802f4b62386dc1ca7a7e88e755adffdd2f"},"cell_type":"markdown","source":"**Tutorial on Ensemble Learning**\n<br>\nThis notebook is a reference for people wanting to use Ensemble Learning on their own projects."},{"metadata":{"_uuid":"a1f4d126bd96fa43cd209fb09917dab40b248e51"},"cell_type":"markdown","source":"First we load all necessary libraries"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# sklearn classifiers\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import cross_val_score","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"483e7a03f2f377cf729bb6639eee203bd1c6593a"},"cell_type":"markdown","source":"Next we make a dataframe from our dataset"},{"metadata":{"trusted":true,"_uuid":"43c33aef2e99b641e77f7a80e085224abb19b6b3"},"cell_type":"code","source":"df        = pd.read_csv(\"../input/StudentsPerformance.csv\", header=0)\ndf_course = pd.read_csv(\"../input/StudentsPerformance.csv\", header=0, usecols=['lunch'])\ndf_scores = pd.read_csv(\"../input/StudentsPerformance.csv\", header=0, usecols=['math score', 'reading score', 'writing score'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b9bc7afeb6c96fe6a29a0adecdbed3203201965d"},"cell_type":"markdown","source":"Quickly list out some of the first few instances"},{"metadata":{"trusted":true,"_uuid":"95ca9ada20f003f1c3f7daabe944c841655b952d"},"cell_type":"code","source":"df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5fbe41e0c0fa03a37f96c67a39a82a8c500345ae"},"cell_type":"markdown","source":"Get a general idea of the range of numbers"},{"metadata":{"trusted":true,"_uuid":"11d508ee282277821af78b43f63845578b0ae030"},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bb3b262fb8f4298a2fa7a5dfd5f2acf6b5e39424"},"cell_type":"markdown","source":"Here we transform the data we want to classify on"},{"metadata":{"trusted":true,"_uuid":"a86dd350861d070de2055e7629ce2808de8da140"},"cell_type":"code","source":"# Transform labels to binary (i.e. 1s and 0s)\nLEncoder = LabelEncoder()\nLEncoder.fit(df_course)\nT_Labels = LEncoder.transform(df_course)\n\n# What we are trying to guess\nmath_train    = df_scores.iloc[0:800, 0].values.reshape(-1,1)\nreading_train = df_scores.iloc[0:800, 1].values.reshape(-1,1)\nwriting_train = df_scores.iloc[0:800, 2].values.reshape(-1,1)\n\nmath_test    = df_scores.iloc[800:1000, 0].values.reshape(-1,1)\nreading_test = df_scores.iloc[800:1000, 1].values.reshape(-1,1)\nwriting_test = df_scores.iloc[800:1000, 2].values.reshape(-1,1)\n\nX_Train = T_Labels[0:800].reshape(-1,1)\nX_Test  = T_Labels[800:1000].reshape(-1,1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2f2c8b28a242bdb8f6eed14fe1186e96cfb425ea"},"cell_type":"markdown","source":"We train each classifier on the data"},{"metadata":{"trusted":true,"_uuid":"60167e23a7a1400814ae944e2d368950a697628c"},"cell_type":"code","source":"Gaussian_Classifier = GaussianNB()\nGaussian_Classifier.fit(math_train, X_Train)\nGaussianNB(priors=None, var_smoothing=1e-09)\n\nRandomForest = RandomForestClassifier(n_estimators=10, random_state=3)\nRandomForest = RandomForest.fit(math_train, X_Train)\n\nLogistic_Regression = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=123)\nLogistic_Regression.fit(math_test, X_Test)\n\nMLP = MLPClassifier(hidden_layer_sizes=(300, 200), random_state=123)\nMLP.fit(math_train, X_Train)\n\nr_list = RandomForest.predict_proba(math_test)\ng_list = Gaussian_Classifier.predict_proba(math_test)\nl_list = Logistic_Regression.predict_proba(math_test)\nm_list = MLP.predict_proba(math_test)\n\nprint(\"Random Forest prediction accuracy:\", end='')\nprint(RandomForest.score(math_test, X_Test))\nprint(\"Gaussian prediction accuracy:\", end='')\nprint(Gaussian_Classifier.score(math_test, X_Test))\nprint(\"Logistic Regression prediction accuracy:\", end='')\nprint(Logistic_Regression.score(math_test, X_Test))\nprint(\"Multilayer Perceptron prediction accuracy:\", end='')\nprint(MLP.score(math_test, X_Test))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a0036404fc4d8a3e9893fa2cbf664674a05d51b5"},"cell_type":"markdown","source":"Then we go through each classifier's prediction on an instance, and classify the instance based on the overall consensus of the classifiers.\n<br>\n\nIf all classifiers are partially certain one row is False, but one classifier, let's say MLP, says they are 100% sure it should be classified as True, then the ensemble classifier will classify the instance as True. (0.49+0.49+0.49+1.00) / 4 > 0.5"},{"metadata":{"trusted":true,"_uuid":"c82ddb534018a2eaad0d273f951371e028811fee"},"cell_type":"code","source":"predictions = []\nfor x in range(0, len(g_list)):\n    if ((r_list[x][0] + g_list[x][0] + l_list[x][0] + m_list[x][0]) / 4) > 0.5:\n        predictions.append(0)\n    else:\n        predictions.append(1)\n        \nnum_right = 0\n\nfor x in range(0, len(predictions)):\n    if predictions[x] == X_Test[x][0]:\n        num_right += 1\n\nprint(\"Ensemble prediction accuracy:\", end='')\nprint(float(num_right) / 200)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}