{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-11T07:32:05.437738Z","iopub.execute_input":"2021-07-11T07:32:05.438239Z","iopub.status.idle":"2021-07-11T07:32:05.483254Z","shell.execute_reply.started":"2021-07-11T07:32:05.438138Z","shell.execute_reply":"2021-07-11T07:32:05.481899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nimport plotly.express as px\nimport plotly.io as pio\npio.renderers.default='notebook'\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib as matplot\n\nimport re\nimport sklearn\nimport xgboost as xgb\nfrom sklearn.metrics import mean_squared_error\nimport pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:32:05.484833Z","iopub.execute_input":"2021-07-11T07:32:05.485143Z","iopub.status.idle":"2021-07-11T07:32:08.577685Z","shell.execute_reply.started":"2021-07-11T07:32:05.485114Z","shell.execute_reply":"2021-07-11T07:32:08.576642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Merging data**","metadata":{}},{"cell_type":"code","source":"#Merging 2013-14 datsets\ndf1 = pd.read_csv('../input/national-health-and-nutrition-examination-survey/labs.csv')\ndf2 = pd.read_csv('../input/national-health-and-nutrition-examination-survey/examination.csv')\ndf3 = pd.read_csv('../input/national-health-and-nutrition-examination-survey/demographic.csv')\ndf4a = pd.read_csv('../input/national-health-and-nutrition-examination-survey/diet.csv')\ndf5 = pd.read_csv('../input/national-health-and-nutrition-examination-survey/questionnaire.csv')\n\ndf2.drop(['SEQN'], axis = 1, inplace=True)\ndf3.drop(['SEQN'], axis = 1, inplace=True)\ndf4a.drop(['SEQN'], axis = 1, inplace=True)\ndf5.drop(['SEQN'], axis = 1, inplace=True)\n\ndfa = pd.concat([df1, df2], axis=1, join='inner')\ndfa = pd.concat([dfa, df3], axis=1, join='inner')\ndfa = pd.concat([dfa, df4a], axis=1, join='inner')\ndfa = pd.concat([dfa, df5], axis=1, join='inner')\n","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:32:08.58005Z","iopub.execute_input":"2021-07-11T07:32:08.580385Z","iopub.status.idle":"2021-07-11T07:32:11.123592Z","shell.execute_reply.started":"2021-07-11T07:32:08.580353Z","shell.execute_reply":"2021-07-11T07:32:11.122208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfa\n","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:32:11.125371Z","iopub.execute_input":"2021-07-11T07:32:11.125706Z","iopub.status.idle":"2021-07-11T07:32:11.182495Z","shell.execute_reply.started":"2021-07-11T07:32:11.125673Z","shell.execute_reply":"2021-07-11T07:32:11.181321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#reading 2015-16 healthdata\nd56 = pd.read_csv('../input/merged/merged_2015_2016.csv')\nd56.describe()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-11T07:32:11.18382Z","iopub.execute_input":"2021-07-11T07:32:11.184123Z","iopub.status.idle":"2021-07-11T07:32:12.245133Z","shell.execute_reply.started":"2021-07-11T07:32:11.184093Z","shell.execute_reply":"2021-07-11T07:32:12.243926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#reading 2017-18 healthdata\nd78 = pd.read_csv('../input/merged/merged_2017_2018.csv')\nd78.describe()\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-11T07:32:12.246541Z","iopub.execute_input":"2021-07-11T07:32:12.246963Z","iopub.status.idle":"2021-07-11T07:32:13.228369Z","shell.execute_reply.started":"2021-07-11T07:32:12.246925Z","shell.execute_reply":"2021-07-11T07:32:13.227103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a=d56.columns\n\nb=d78.columns\na","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-11T07:32:13.229887Z","iopub.execute_input":"2021-07-11T07:32:13.230302Z","iopub.status.idle":"2021-07-11T07:32:13.237755Z","shell.execute_reply.started":"2021-07-11T07:32:13.230259Z","shell.execute_reply":"2021-07-11T07:32:13.236918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#merging 2015,2016,2017,2018 data\ndf_m = pd.concat([d56,d78],ignore_index=True,axis=0)\n\ndf_m.describe()\ndf_m","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:32:13.240568Z","iopub.execute_input":"2021-07-11T07:32:13.240958Z","iopub.status.idle":"2021-07-11T07:32:14.054774Z","shell.execute_reply.started":"2021-07-11T07:32:13.240924Z","shell.execute_reply":"2021-07-11T07:32:14.053798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"df_m = pd.concat([d56,d78[a]],ignore_index=True,axis=0)\n'DR1TWS', 'DMDHRMAR', 'DMDHRBR4', 'DMDHREDU', 'DMDHRAGE', 'DMDHSEDU'\ndf_m = pd.concat([d78,d56[b]],ignore_index=True,axis=0)\n'DMDHRAGZ', 'DMDHREDZ', 'DMDHRMAZ', 'DMDHSEDZ', 'DR1TWSZ'","metadata":{"execution":{"iopub.status.busy":"2021-07-06T17:48:29.95237Z","iopub.execute_input":"2021-07-06T17:48:29.952726Z","iopub.status.idle":"2021-07-06T17:48:29.980584Z","shell.execute_reply.started":"2021-07-06T17:48:29.952695Z","shell.execute_reply":"2021-07-06T17:48:29.979147Z"}}},{"cell_type":"markdown","source":"**merged 2015,16,17,18**","metadata":{}},{"cell_type":"code","source":"#Dropiing non common rows across different datasets\n#\ndf_md=df_m.drop(['DR1TWS', 'DMDHRMAR', 'DMDHRBR4', 'DMDHREDU', 'DMDHRAGE', 'DMDHSEDU','DMDHRAGZ', 'DMDHREDZ', 'DMDHRMAZ', 'DMDHSEDZ', 'DR1TWSZ','DR1_330Z', 'DR1_320Z', 'DR1MRESP', 'DR1_300', 'DR1HELP'],axis=1)\ndf_md\n","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:32:14.056551Z","iopub.execute_input":"2021-07-11T07:32:14.056907Z","iopub.status.idle":"2021-07-11T07:32:14.111257Z","shell.execute_reply.started":"2021-07-11T07:32:14.056873Z","shell.execute_reply":"2021-07-11T07:32:14.11025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_mdc=df_md.columns\ndf_mdc","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:32:14.112444Z","iopub.execute_input":"2021-07-11T07:32:14.112776Z","iopub.status.idle":"2021-07-11T07:32:14.119667Z","shell.execute_reply.started":"2021-07-11T07:32:14.11273Z","shell.execute_reply":"2021-07-11T07:32:14.118777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dfa-2013-14dataframe\nprint(dfa[df_mdc])","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:32:14.120936Z","iopub.execute_input":"2021-07-11T07:32:14.121234Z","iopub.status.idle":"2021-07-11T07:32:14.24501Z","shell.execute_reply.started":"2021-07-11T07:32:14.121205Z","shell.execute_reply":"2021-07-11T07:32:14.243921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Merged data frame**","metadata":{}},{"cell_type":"code","source":"#Merging 2013,14,15,16,17,18 data\ndf_x = pd.concat([dfa[df_mdc],df_md],ignore_index=True,axis=0)\ndf_x.dropna(axis=1, how='all')\ndf_x.dropna(axis=0, how='all')\ndf_x","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:32:14.246372Z","iopub.execute_input":"2021-07-11T07:32:14.246752Z","iopub.status.idle":"2021-07-11T07:32:14.431567Z","shell.execute_reply.started":"2021-07-11T07:32:14.24672Z","shell.execute_reply":"2021-07-11T07:32:14.430787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Renaming required columns\ndf_x = df_x.rename(columns = {'SEQN' : 'ID',\n                          'RIDAGEYR': 'Age',\n                          'RIAGENDR' : 'Gender',\n                          'WTINT2YR' : 'Weight',\n                          'INDFMIN2' : 'Tot_family_income',\n                          'DMDFMSIZ'  :'Tot_no_fam_members',\n                          'DMDYRSUS' : 'Years_in_US', # Nan -> american i guess\n                          'INDFMPIR' : 'Family_income',\n                          'LBXGH' : 'GlycoHemoglobin',\n                          'BMXARMC' : 'ArmCircum',\n                          'BMDAVSAD' : 'SaggitalAbdominal',\n                          'MGDCGSZ' : 'GripStrength',\n                          'DRABF' : 'Breast_fed',\n                           'MCQ053':'Anemia_treatment',\n                            'LBXHGB': 'Hemoglobin',\n                            'MCQ220': 'Cancer',\n                            'BMXBMI': 'BMI',\n                            'DMDEDUC2':'Educationlevel',\n                            'INDHHINC': 'annualincome',\n                            'RIDRETH1':'Ethinicity',\n                            \n                           })\n\ndf_x.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:32:14.432553Z","iopub.execute_input":"2021-07-11T07:32:14.432945Z","iopub.status.idle":"2021-07-11T07:32:15.265112Z","shell.execute_reply.started":"2021-07-11T07:32:14.432917Z","shell.execute_reply":"2021-07-11T07:32:15.264026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Filling continous and categorical missing values\ndf_x['Tot_family_income'] = df_x['Tot_family_income'].interpolate(limit_direction ='both')\ndf_x['Hemoglobin'] = df_x['Hemoglobin'].interpolate(limit_direction ='both')\ndf_x['Age'] = df_x['Age'].interpolate(limit_direction ='both')\ndf_x['Weight'] = df_x['Weight'].interpolate(limit_direction ='both')\ndf_x['Tot_no_fam_members'] = df_x['Tot_no_fam_members'].interpolate(limit_direction ='both')\n    \ndf_x = df_x.fillna(df_x['Gender'].value_counts().index[0])\ndf_x = df_x.fillna(df_x['Anemia_treatment'].value_counts().index[0])\ndf_x.describe()\n    \n\n    ","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:32:15.266334Z","iopub.execute_input":"2021-07-11T07:32:15.266733Z","iopub.status.idle":"2021-07-11T07:32:16.049917Z","shell.execute_reply.started":"2021-07-11T07:32:15.266685Z","shell.execute_reply":"2021-07-11T07:32:16.048574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Filling rest of missing values\nimport pandas as pd\nimport numpy as np\nfrom sklearn.base import TransformerMixin\nclass DataFrameImputer(TransformerMixin):\n    def __init__(self):\n        \"\"\"Impute missing values.\n        Columns of dtype object are imputed with the most frequent value\n        in column.\n        Columns of other types are imputed with mean of column.\n        \"\"\"\n    def fit(self, X, y=None):\n        self.fill = pd.Series([X[c].value_counts().index[0]\n            if X[c].dtype == np.dtype('O') else X[c].mean() for c in X],\n            index=X.columns)\n        return self\n    def transform(self, X, y=None):\n        return X.fillna(self.fill)\n\n\nX = df_x\nprint('before...')\nprint(X)\ndf_x = DataFrameImputer().fit_transform(X)\nprint('after...')\nprint(df_x)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:32:16.053811Z","iopub.execute_input":"2021-07-11T07:32:16.054156Z","iopub.status.idle":"2021-07-11T07:32:16.226913Z","shell.execute_reply.started":"2021-07-11T07:32:16.054124Z","shell.execute_reply":"2021-07-11T07:32:16.225727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Anemia calculation**","metadata":{}},{"cell_type":"code","source":"df_x.loc[(df_x['Gender']==1) & (df_x['Hemoglobin'] < 13), 'Anemia'] = 1\ndf_x.loc[(df_x['Gender']==1) & (df_x['Hemoglobin'] > 13), 'Anemia'] = 0\n\ndf_x.loc[(df_x['Gender']==2) & (df_x['Hemoglobin'] < 12), 'Anemia'] = 1\ndf_x.loc[(df_x['Gender']==2) & (df_x['Hemoglobin'] > 12), 'Anemia'] = 0\n\nprint(df_x)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:32:16.228569Z","iopub.execute_input":"2021-07-11T07:32:16.229011Z","iopub.status.idle":"2021-07-11T07:32:16.271391Z","shell.execute_reply.started":"2021-07-11T07:32:16.228967Z","shell.execute_reply":"2021-07-11T07:32:16.270684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_x['Anemia']=df_x['Anemia'].fillna(0)\nprint(df_x)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:32:16.272362Z","iopub.execute_input":"2021-07-11T07:32:16.272799Z","iopub.status.idle":"2021-07-11T07:32:16.303004Z","shell.execute_reply.started":"2021-07-11T07:32:16.27275Z","shell.execute_reply":"2021-07-11T07:32:16.302006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Distribution of ANEMIA values\ndf_x['Anemia'].value_counts(normalize=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:32:16.304648Z","iopub.execute_input":"2021-07-11T07:32:16.305117Z","iopub.status.idle":"2021-07-11T07:32:16.315805Z","shell.execute_reply.started":"2021-07-11T07:32:16.305072Z","shell.execute_reply":"2021-07-11T07:32:16.314583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Percentage of null values**","metadata":{}},{"cell_type":"code","source":"null=100*(df_x.isnull().sum())/(df_x.shape[0])\n\ndf4ad_null=pd.DataFrame({'percentage':null})\n\ndf4ad_null.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:32:16.317206Z","iopub.execute_input":"2021-07-11T07:32:16.31754Z","iopub.status.idle":"2021-07-11T07:32:16.354704Z","shell.execute_reply.started":"2021-07-11T07:32:16.317507Z","shell.execute_reply":"2021-07-11T07:32:16.353753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Extracting important values from dataframe**","metadata":{}},{"cell_type":"code","source":"df_m1 = df_x.loc[:,['DR1DRSTZ',\n 'DRD350A',\n 'DRD350C',\n 'DRD350D',\n 'DRD350E',\n 'DRD350G',\n 'DRD350I',\n 'DRD350J',\n 'DRD350K',\n 'DRD360',\n 'DRD370C',\n 'DRD370G',\n 'DRD370H',\n 'DRD370I',\n 'DRD370J',\n 'DRD370K',\n 'DRD370L',\n 'DRD370N',\n 'DRD370O',\n 'DRD370P',\n 'DRD370Q',\n 'DRD370R',\n 'DRD370S',\n 'DRD370T',\n 'DRD370U',\n 'DRD370V',\n 'ID',\n 'Gender',\n 'Age',\n 'Weight',\n 'Tot_family_income',\n 'Tot_no_fam_members',\n 'Hemoglobin',\n 'Anemia_treatment',\n 'Cancer',\n 'BMI',\n 'Educationlevel',\n 'Ethinicity',\n 'Breast_fed',\n 'GlycoHemoglobin',\n 'Anemia'\n    ] ]\ndf_m1.describe()\nprint(df_m1)\n#removed drsthepd,drespnd,drabf","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:32:16.356089Z","iopub.execute_input":"2021-07-11T07:32:16.356377Z","iopub.status.idle":"2021-07-11T07:32:16.560162Z","shell.execute_reply.started":"2021-07-11T07:32:16.356347Z","shell.execute_reply":"2021-07-11T07:32:16.559013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nullv=100*(df_m1.isnull().sum())/(df_m1.shape[0])\n\nvar_allnull=pd.DataFrame({'percentage':nullv})\nprint(var_allnull)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-11T07:32:16.561308Z","iopub.execute_input":"2021-07-11T07:32:16.561595Z","iopub.status.idle":"2021-07-11T07:32:16.577876Z","shell.execute_reply.started":"2021-07-11T07:32:16.561567Z","shell.execute_reply":"2021-07-11T07:32:16.57656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Dropping ID column\ndf_m1.drop('ID',\n  axis='columns', inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:32:16.579744Z","iopub.execute_input":"2021-07-11T07:32:16.5803Z","iopub.status.idle":"2021-07-11T07:32:16.58939Z","shell.execute_reply.started":"2021-07-11T07:32:16.580254Z","shell.execute_reply":"2021-07-11T07:32:16.587978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n\n\n#deopping hemoglobin\nX = df_m1.drop(['Anemia','Hemoglobin'],axis=1)\ny = df_m1[['Anemia']]","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:32:16.594478Z","iopub.execute_input":"2021-07-11T07:32:16.594821Z","iopub.status.idle":"2021-07-11T07:32:16.607157Z","shell.execute_reply.started":"2021-07-11T07:32:16.594791Z","shell.execute_reply":"2021-07-11T07:32:16.605913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Split the dataset into train and Test\nfrom sklearn.model_selection import train_test_split\n\nseed = 195\ntest_size = 0.3\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:32:16.610042Z","iopub.execute_input":"2021-07-11T07:32:16.61039Z","iopub.status.idle":"2021-07-11T07:32:16.627943Z","shell.execute_reply.started":"2021-07-11T07:32:16.610348Z","shell.execute_reply":"2021-07-11T07:32:16.626661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**RFE using Random Forest regressor-Top 30 features**","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import RFE\n\n# Init the transformer\nrfe = RFE(estimator=RandomForestRegressor(), n_features_to_select=30)\n\n# Fit to the training data\n_ = rfe.fit(X, y)\nnewvar=X.loc[:, rfe.support_]\n\nnewvar.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:32:16.629212Z","iopub.execute_input":"2021-07-11T07:32:16.62968Z","iopub.status.idle":"2021-07-11T07:34:35.475115Z","shell.execute_reply.started":"2021-07-11T07:32:16.629633Z","shell.execute_reply":"2021-07-11T07:34:35.473492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Adding anemia to top 30 variables\nnewvar[\"Anemia\"] = df_m1[[\"Anemia\"]]\nprint(newvar)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:34:35.476961Z","iopub.execute_input":"2021-07-11T07:34:35.477421Z","iopub.status.idle":"2021-07-11T07:34:35.509437Z","shell.execute_reply.started":"2021-07-11T07:34:35.477368Z","shell.execute_reply":"2021-07-11T07:34:35.507882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"newvar.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:34:35.510839Z","iopub.execute_input":"2021-07-11T07:34:35.511322Z","iopub.status.idle":"2021-07-11T07:34:35.650729Z","shell.execute_reply.started":"2021-07-11T07:34:35.511282Z","shell.execute_reply":"2021-07-11T07:34:35.649266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Heat map-Top 30 features**","metadata":{}},{"cell_type":"code","source":"colormap = plt.cm.viridis\nplt.figure(figsize=(20,20))\nsns.heatmap(newvar.astype(float).corr(), linewidths=0.1, vmax=1.0, square=True, cmap=colormap, annot=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:34:35.652232Z","iopub.execute_input":"2021-07-11T07:34:35.652554Z","iopub.status.idle":"2021-07-11T07:34:40.313517Z","shell.execute_reply.started":"2021-07-11T07:34:35.652522Z","shell.execute_reply":"2021-07-11T07:34:40.312259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#deopping hemoglobin\nX = newvar.drop(['Anemia','Weight','Anemia_treatment'],axis=1)\ny = newvar[['Anemia']]","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:34:40.314986Z","iopub.execute_input":"2021-07-11T07:34:40.31555Z","iopub.status.idle":"2021-07-11T07:34:40.325713Z","shell.execute_reply.started":"2021-07-11T07:34:40.315503Z","shell.execute_reply":"2021-07-11T07:34:40.324619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:34:40.327661Z","iopub.execute_input":"2021-07-11T07:34:40.328383Z","iopub.status.idle":"2021-07-11T07:34:40.387246Z","shell.execute_reply.started":"2021-07-11T07:34:40.328336Z","shell.execute_reply":"2021-07-11T07:34:40.38597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Split the dataset into train and Test\nfrom sklearn.model_selection import train_test_split\n\nseed = 195\ntest_size = 0.3\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:34:40.388643Z","iopub.execute_input":"2021-07-11T07:34:40.389014Z","iopub.status.idle":"2021-07-11T07:34:40.405129Z","shell.execute_reply.started":"2021-07-11T07:34:40.388979Z","shell.execute_reply":"2021-07-11T07:34:40.40366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#scaled_pos_weight-calculation\nratio= float(np.sum(y_train == 0)) / np.sum(y_train == 1)\nratio\n","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:34:40.406996Z","iopub.execute_input":"2021-07-11T07:34:40.407483Z","iopub.status.idle":"2021-07-11T07:34:40.426859Z","shell.execute_reply.started":"2021-07-11T07:34:40.407437Z","shell.execute_reply":"2021-07-11T07:34:40.425505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**XGBClassifier-Optuna**","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb\nfrom optuna import create_study, logging\nfrom optuna.pruners import MedianPruner\nfrom optuna.integration import XGBoostPruningCallback\n","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:34:40.4283Z","iopub.execute_input":"2021-07-11T07:34:40.428793Z","iopub.status.idle":"2021-07-11T07:34:41.071481Z","shell.execute_reply.started":"2021-07-11T07:34:40.42873Z","shell.execute_reply":"2021-07-11T07:34:41.070338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import timeit\nimport pickle\nimport sys\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, \\\n                            precision_recall_curve, roc_curve, accuracy_score\nfrom sklearn.exceptions import NotFittedError","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-11T07:34:41.072867Z","iopub.execute_input":"2021-07-11T07:34:41.07322Z","iopub.status.idle":"2021-07-11T07:34:41.077487Z","shell.execute_reply.started":"2021-07-11T07:34:41.073188Z","shell.execute_reply":"2021-07-11T07:34:41.076624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**UTILITY FUNCTIONS**","metadata":{}},{"cell_type":"code","source":"def confusion_plot(matrix, labels=None):\n    \"\"\" Display binary confusion matrix as a Seaborn heatmap \"\"\"\n    \n    labels = labels if labels else ['Negative (0)', 'Positive (1)']\n    \n    fig, ax = plt.subplots(nrows=1, ncols=1)\n    sns.heatmap(data=matrix, cmap='Blues', annot=True, fmt='d',\n                xticklabels=labels, yticklabels=labels, ax=ax)\n    ax.set_xlabel('PREDICTED')\n    ax.set_ylabel('ACTUAL')\n    ax.set_title('Confusion Matrix')\n    plt.close()\n    \n    return fig","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:34:41.078871Z","iopub.execute_input":"2021-07-11T07:34:41.079319Z","iopub.status.idle":"2021-07-11T07:34:41.09915Z","shell.execute_reply.started":"2021-07-11T07:34:41.079276Z","shell.execute_reply":"2021-07-11T07:34:41.098049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def roc_plot(y_true, y_probs, label, compare=False, ax=None):\n    \"\"\" Plot Receiver Operating Characteristic (ROC) curve \n        Set `compare=True` to use this function to compare classifiers. \"\"\"\n    \n    fpr, tpr, thresh = roc_curve(y_true, y_probs,\n                                 drop_intermediate=False)\n    auc = round(roc_auc_score(y_true, y_probs), 2)\n    \n    fig, axis = (None, ax) if ax else plt.subplots(nrows=1, ncols=1)\n    label = ' '.join([label, f'({auc})']) if compare else None\n    sns.lineplot(x=fpr, y=tpr, ax=axis, label=label)\n    \n    if compare:\n        axis.legend(title='Classifier (AUC)', loc='lower right')\n    else:\n        axis.text(0.72, 0.05, f'AUC = { auc }', fontsize=12,\n                  bbox=dict(facecolor='green', alpha=0.4, pad=5))\n            \n        # Plot No-Info classifier\n        axis.fill_between(fpr, fpr, tpr, alpha=0.3, edgecolor='g',\n                          linestyle='--', linewidth=2)\n        \n    axis.set_xlim(0, 1)\n    axis.set_ylim(0, 1)\n    axis.set_title('ROC Curve')\n    axis.set_xlabel('False Positive Rate [FPR]\\n(1 - Specificity)')\n    axis.set_ylabel('True Positive Rate [TPR]\\n(Sensitivity or Recall)')\n    \n    plt.close()\n    \n    return axis if ax else fig","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:34:41.100508Z","iopub.execute_input":"2021-07-11T07:34:41.101108Z","iopub.status.idle":"2021-07-11T07:34:41.114223Z","shell.execute_reply.started":"2021-07-11T07:34:41.101058Z","shell.execute_reply":"2021-07-11T07:34:41.113064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def precision_recall_plot(y_true, y_probs, label, compare=False, ax=None):\n    \"\"\" Plot Precision-Recall curve.\n        Set `compare=True` to use this function to compare classifiers. \"\"\"\n    \n    p, r, thresh = precision_recall_curve(y_true, y_probs)\n    p, r, thresh = list(p), list(r), list(thresh)\n    p.pop()\n    r.pop()\n    \n    fig, axis = (None, ax) if ax else plt.subplots(nrows=1, ncols=1)\n    \n    if compare:\n        sns.lineplot(r, p, ax=axis, label=label)\n        axis.set_xlabel('Recall')\n        axis.set_ylabel('Precision')\n        axis.legend(loc='lower left')\n    else:\n        sns.lineplot(thresh, p, label='Precision', ax=axis)\n        axis.set_xlabel('Threshold')\n        axis.set_ylabel('Precision')\n        axis.legend(loc='lower left')\n\n        axis_twin = axis.twinx()\n        sns.lineplot(thresh, r, color='limegreen', label='Recall', ax=axis_twin)\n        axis_twin.set_ylabel('Recall')\n        axis_twin.set_ylim(0, 1)\n        axis_twin.legend(bbox_to_anchor=(0.24, 0.18))\n    \n    axis.set_xlim(0, 1)\n    axis.set_ylim(0, 1)\n    axis.set_title('Precision Vs Recall')\n    \n    plt.close()\n    return axis if ax else fig    ","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:34:41.115633Z","iopub.execute_input":"2021-07-11T07:34:41.116014Z","iopub.status.idle":"2021-07-11T07:34:41.129994Z","shell.execute_reply.started":"2021-07-11T07:34:41.115957Z","shell.execute_reply":"2021-07-11T07:34:41.129033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_clf(clf, x_train, y_train, sample_weight=None, refit=False):\n    train_time = 0\n    \n    try:\n        if refit:\n            raise NotFittedError\n        y_pred_train = clf.predict(x_train)\n    except NotFittedError:\n        start = timeit.default_timer()\n        \n        if sample_weight is not None:\n            clf.fit(x_train, y_train, sample_weight=sample_weight)\n        else:\n            clf.fit(x_train, y_train)\n        \n        end = timeit.default_timer()\n        train_time = end - start\n        \n        y_pred_train = clf.predict(x_train)\n    \n    train_acc = accuracy_score(y_train, y_pred_train)\n    return clf, y_pred_train, train_acc, train_time","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:34:41.131433Z","iopub.execute_input":"2021-07-11T07:34:41.132005Z","iopub.status.idle":"2021-07-11T07:34:41.149453Z","shell.execute_reply.started":"2021-07-11T07:34:41.131965Z","shell.execute_reply":"2021-07-11T07:34:41.148582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def feature_importance_plot(importances, feature_labels, ax=None):\n    fig, axis = (None, ax) if ax else plt.subplots(nrows=1, ncols=1, figsize=(5, 10))\n    sns.barplot(x=importances, y=feature_labels, ax=axis)\n    axis.set_title('Feature Importance Measures')\n    \n    plt.close()\n    \n    return axis if ax else fig\n","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:34:41.150946Z","iopub.execute_input":"2021-07-11T07:34:41.151487Z","iopub.status.idle":"2021-07-11T07:34:41.163754Z","shell.execute_reply.started":"2021-07-11T07:34:41.151433Z","shell.execute_reply":"2021-07-11T07:34:41.162636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_memory_size(clf):\n    return sys.getsizeof(pickle.dumps(clf))\ndef report(clf, x_train, y_train, x_test, y_test, display_scores=[],\n           sample_weight=None, refit=False, importance_plot=False,\n           confusion_labels=None, feature_labels=None, verbose=True):\n    \"\"\" Trains the passed classifier if not already trained and reports\n        various metrics of the trained classifier \"\"\"\n    \n    dump = dict()\n    \n    ## Train if not already trained\n    clf, train_predictions, \\\n    train_acc, train_time = train_clf(clf, x_train, y_train,\n                                      sample_weight=sample_weight,\n                                      refit=refit)\n    ## Testing\n    start = timeit.default_timer()\n    test_predictions = clf.predict(x_test)\n    end = timeit.default_timer()\n    test_time = end - start\n    \n    test_acc = accuracy_score(y_test, test_predictions)\n    y_probs = clf.predict_proba(x_test)[:, 1]\n    \n    roc_auc = roc_auc_score(y_test, y_probs)\n    ## Additional scores\n    scores_dict = dict()\n    for func in display_scores:\n        scores_dict[func.__name__] = [func(y_train, train_predictions),\n                                      func(y_test, test_predictions)]\n        \n    ## Model Memory\n    model_mem = round(model_memory_size(clf) / 1024, 2)\n    \n    print(clf)\n    print(\"\\n=============================> TRAIN-TEST DETAILS <======================================\")\n    \n    ## Metrics\n    print(f\"Train Size: {x_train.shape[0]} samples\")\n    print(f\" Test Size: {x_test.shape[0]} samples\")\n    print(\"---------------------------------------------\")\n    print(f\"Training Time: {round(train_time, 3)} seconds\")\n    print(f\" Testing Time: {round(test_time, 3)} seconds\")\n    print(\"---------------------------------------------\")\n    print(\"Train Accuracy: \", train_acc)\n    print(\" Test Accuracy: \", test_acc)\n    print(\"---------------------------------------------\")\n    \n    if display_scores:\n        for k, v in scores_dict.items():\n            score_name = ' '.join(map(lambda x: x.title(), k.split('_')))\n            print(f'Train {score_name}: ', v[0])\n            print(f' Test {score_name}: ', v[1])\n            print()\n        print(\"---------------------------------------------\") \n    print(\" Area Under ROC (test): \", roc_auc)\n    print(\"---------------------------------------------\")\n    print(f\"Model Memory Size: {model_mem} kB\")\n    print(\"\\n=============================> CLASSIFICATION REPORT <===================================\")\n    \n    ## Classification Report\n    clf_rep = classification_report(y_test, test_predictions, output_dict=True)\n    \n    print(classification_report(y_test, test_predictions,\n                                target_names=confusion_labels))\n    \n    \n    if verbose:\n        print(\"\\n================================> CONFUSION MATRIX <=====================================\")\n    \n        ## Confusion Matrix HeatMap\n        display(confusion_plot(confusion_matrix(y_test, test_predictions),\n                               labels=confusion_labels))\n        print(\"\\n=======================================> PLOTS <=========================================\")\n\n\n        ## Variable importance plot\n        fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(14, 10))\n        roc_axes = axes[0, 0]\n        pr_axes = axes[0, 1]\n        importances = None\n\n        if importance_plot:\n            if not feature_labels:\n                raise RuntimeError(\"'feature_labels' argument not passed \"\n                                   \"when 'importance_plot' is True\")\n\n            try:\n                importances = pd.Series(clf.feature_importances_,\n                                        index=feature_labels) \\\n                                .sort_values(ascending=False)\n            except AttributeError:\n                try:\n                    importances = pd.Series(clf.coef_.ravel(),\n                                            index=feature_labels) \\\n                                    .sort_values(ascending=False)\n                except AttributeError:\n                    pass\n\n            if importances is not None:\n                # Modifying grid\n                grid_spec = axes[0, 0].get_gridspec()\n                for ax in axes[:, 0]:\n                    ax.remove()   # remove first column axes\n                large_axs = fig.add_subplot(grid_spec[0:, 0])\n\n                # Plot importance curve\n                feature_importance_plot(importances=importances.values,\n                                        feature_labels=importances.index,\n                                        ax=large_axs)\n                large_axs.axvline(x=0)\n\n                # Axis for ROC and PR curve\n                roc_axes = axes[0, 1]\n                pr_axes = axes[1, 1]\n            else:\n                # remove second row axes\n                for ax in axes[1, :]:\n                    ax.remove()\n        else:\n            # remove second row axes\n            for ax in axes[1, :]:\n                ax.remove()\n\n\n        ## ROC and Precision-Recall curves\n        clf_name = clf.__class__.__name__\n        roc_plot(y_test, y_probs, clf_name, ax=roc_axes)\n        precision_recall_plot(y_test, y_probs, clf_name, ax=pr_axes)\n\n        fig.subplots_adjust(wspace=5)\n        fig.tight_layout()\n        display(fig)\n    \n    ## Dump to report_dict\n    dump = dict(clf=clf, accuracy=[train_acc, test_acc], **scores_dict,\n                train_time=train_time, train_predictions=train_predictions,\n                test_time=test_time, test_predictions=test_predictions,\n                test_probs=y_probs, report=clf_rep, roc_auc=roc_auc,\n                model_memory=model_mem)\n    \n    return clf, dump","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:34:41.165122Z","iopub.execute_input":"2021-07-11T07:34:41.165586Z","iopub.status.idle":"2021-07-11T07:34:41.192562Z","shell.execute_reply.started":"2021-07-11T07:34:41.16554Z","shell.execute_reply":"2021-07-11T07:34:41.191389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Main code-model tuning using optuna**","metadata":{}},{"cell_type":"code","source":"X = newvar.drop(['Anemia','Weight','Anemia_treatment'],axis=1)\ny = newvar[['Anemia']]","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:34:41.194041Z","iopub.execute_input":"2021-07-11T07:34:41.194577Z","iopub.status.idle":"2021-07-11T07:34:41.212205Z","shell.execute_reply.started":"2021-07-11T07:34:41.194524Z","shell.execute_reply":"2021-07-11T07:34:41.210972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport xgboost as xgb\nfrom optuna import create_study, logging\nfrom optuna.pruners import MedianPruner\nfrom optuna.integration import XGBoostPruningCallback\nfrom xgboost import XGBClassifier\nfrom sklearn.utils import class_weight\nfrom sklearn import metrics\n\nfrom sklearn.model_selection import train_test_split\n#deopping hemoglobin\n\ndata_splits = train_test_split(X, y, test_size=0.3, random_state=123,\n                               shuffle=True, stratify=y)\nx_train, x_test, y_train, y_test = data_splits\ndef objective(trial, X, y, group, score, params=dict()):\n    dtrain = xgb.DMatrix(X, label=y)\n    class_weight = (y.shape[0] - np.sum(y)) / np.sum(y)\n    \n    ## Initial Learning Parameters\n    params['learning_rate'] = 0.1\n    params['num_boost_round'] = 1000\n\n    if group == '1':\n        params['max_depth'] = trial.suggest_int('max_depth', 2, 15)\n        params['min_child_weight'] = trial.suggest_loguniform('min_child_weight',\n                                                              1e-10, 1e10)\n        params['n_estimators']=trial.suggest_int('n_estimators',500,1000)\n        params['scale_pos_weight']=trial.suggest_float('scale_pos_weight',3.5,5)\n    \n    if group == '2':\n        params['min_samples_split']=trial.suggest_int('min_samples_split',5,10)\n        params['subsample'] = trial.suggest_uniform('subsample', 0, 1)\n        params['colsample_bytree'] = trial.suggest_uniform('colsample_bytree', 0, 1)\n    \n    if group == '3':\n        params['learning_rate'] = trial.suggest_uniform('learning_rate', 0, 0.1)\n        params['num_boost_round'] = trial.suggest_int('num_boost_round', 100, 1000)\n\n    pruning_callback = XGBoostPruningCallback(trial, \"test-\" + score.__name__)\n    cv_scores = xgb.cv(params, dtrain, nfold=5,\n                       stratified=True,\n                       feval=score,\n                       early_stopping_rounds=10,\n                       callbacks=[pruning_callback],\n                       seed=0)\n\n    return cv_scores['test-' + score.__name__ + '-mean'].values[-1]\ndef execute_optimization(study_name, group, score, trials,\n                         params=dict(), direction='maximize'):\n    logging.set_verbosity(logging.ERROR)\n    \n    ## We use pruner to skip trials that are NOT fruitful\n    pruner = MedianPruner(n_warmup_steps=5)\n    \n    study = create_study(direction=direction,\n                         study_name=study_name,\n                         storage='sqlite:///optuna.db',\n                         load_if_exists=True,\n                         pruner=pruner)\n\n    study.optimize(lambda trial: objective(trial, x_train, y_train,\n                                           group, score, params),\n                   n_trials=trials,\n                   n_jobs=-1)\n    \n    \n    print(\"STUDY NAME: \", study_name)\n    print('------------------------------------------------')\n    print(\"EVALUATION METRIC: \", score.__name__)\n    print('------------------------------------------------')\n    print(\"BEST CV SCORE\", study.best_value)\n    print('------------------------------------------------')\n    print(f\"OPTIMAL GROUP - {group} PARAMS: \", study.best_params)\n    print('------------------------------------------------')\n    print(\"BEST TRIAL\", study.best_trial)\n    print('------------------------------------------------')\n    \n    \n    return study.best_params\n","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:34:41.213775Z","iopub.execute_input":"2021-07-11T07:34:41.21419Z","iopub.status.idle":"2021-07-11T07:34:41.416299Z","shell.execute_reply.started":"2021-07-11T07:34:41.214159Z","shell.execute_reply":"2021-07-11T07:34:41.415409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score_func = metrics.f1_score\ndef score_function(y_pred, dtrain):\n    y_pred = (y_pred > 0.5).astype(int)\n    y_true = (dtrain.get_label() > 0.5).astype(int)\n    return score_func.__name__, score_func(y_true, y_pred)\n\nscore_function.__name__ = score_func.__name__","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:34:41.417432Z","iopub.execute_input":"2021-07-11T07:34:41.417876Z","iopub.status.idle":"2021-07-11T07:34:41.423251Z","shell.execute_reply.started":"2021-07-11T07:34:41.417844Z","shell.execute_reply":"2021-07-11T07:34:41.421904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"stepwise_optimization(trials=10)","metadata":{}},{"cell_type":"code","source":"def stepwise_optimization(trials=10):\n    final_params = dict()\n    for g in ['1', '2', '3']:\n        print(f\"=========================== Optimizing Group - {g} ============================\")\n        update_params = execute_optimization('xgboost', g, score_function, trials,\n                                             params=final_params, direction='maximize')\n        final_params.update(update_params)\n        print(f\"PARAMS after optimizing GROUP - {g}: \", final_params)\n        print()\n        print()\n\n    print(\"=========================== FINAL OPTIMAL PARAMETERS ============================\")\n    print(final_params)\n    \n    return final_params","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:34:41.425012Z","iopub.execute_input":"2021-07-11T07:34:41.425461Z","iopub.status.idle":"2021-07-11T07:34:41.438088Z","shell.execute_reply.started":"2021-07-11T07:34:41.425414Z","shell.execute_reply":"2021-07-11T07:34:41.436824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params1 = stepwise_optimization()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:34:41.439485Z","iopub.execute_input":"2021-07-11T07:34:41.439802Z","iopub.status.idle":"2021-07-11T07:35:16.580547Z","shell.execute_reply.started":"2021-07-11T07:34:41.439773Z","shell.execute_reply":"2021-07-11T07:35:16.579331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params1","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:35:16.582374Z","iopub.execute_input":"2021-07-11T07:35:16.582808Z","iopub.status.idle":"2021-07-11T07:35:16.589938Z","shell.execute_reply.started":"2021-07-11T07:35:16.582745Z","shell.execute_reply":"2021-07-11T07:35:16.58872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params1={'learning_rate': 0.02578297296713958,\n 'num_boost_round': 585,\n 'max_depth': 7,\n 'min_child_weight': 18.93704847111416,\n 'n_estimators': 754,\n         'min_samples_split': 9,\n 'scale_pos_weight': 3.425510435559797,\n 'subsample': 0.505407237617943,\n 'colsample_bytree': 0.5538227649946694}","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:35:16.591555Z","iopub.execute_input":"2021-07-11T07:35:16.591999Z","iopub.status.idle":"2021-07-11T07:35:16.601795Z","shell.execute_reply.started":"2021-07-11T07:35:16.591956Z","shell.execute_reply":"2021-07-11T07:35:16.600329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"primary_eval_metric = metrics.f1_score","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:35:16.60344Z","iopub.execute_input":"2021-07-11T07:35:16.604014Z","iopub.status.idle":"2021-07-11T07:35:16.614223Z","shell.execute_reply.started":"2021-07-11T07:35:16.60397Z","shell.execute_reply":"2021-07-11T07:35:16.613009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n=list(x_train.columns)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:35:16.615583Z","iopub.execute_input":"2021-07-11T07:35:16.616001Z","iopub.status.idle":"2021-07-11T07:35:16.626935Z","shell.execute_reply.started":"2021-07-11T07:35:16.615967Z","shell.execute_reply":"2021-07-11T07:35:16.625946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:35:16.628861Z","iopub.execute_input":"2021-07-11T07:35:16.629345Z","iopub.status.idle":"2021-07-11T07:35:16.68566Z","shell.execute_reply.started":"2021-07-11T07:35:16.629233Z","shell.execute_reply":"2021-07-11T07:35:16.684502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_clf_tuned_1 = XGBClassifier(**params1, \n                                random_state=45, n_jobs=-1)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:35:16.687329Z","iopub.execute_input":"2021-07-11T07:35:16.687741Z","iopub.status.idle":"2021-07-11T07:35:16.692385Z","shell.execute_reply.started":"2021-07-11T07:35:16.687699Z","shell.execute_reply":"2021-07-11T07:35:16.691321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_clf_tuned_1.fit(x_train, y_train);\n\n\n ","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:35:16.693996Z","iopub.execute_input":"2021-07-11T07:35:16.694542Z","iopub.status.idle":"2021-07-11T07:35:27.093368Z","shell.execute_reply.started":"2021-07-11T07:35:16.694502Z","shell.execute_reply":"2021-07-11T07:35:27.092293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_clf_tuned_1, xgb_report_tuned_1 = report(xgb_clf_tuned_1, x_train, y_train,\n                                             x_test, y_test,\n                                             display_scores=[primary_eval_metric],\n                                             importance_plot=True,\n                                             feature_labels=n\n                                             )","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:35:27.09468Z","iopub.execute_input":"2021-07-11T07:35:27.095012Z","iopub.status.idle":"2021-07-11T07:36:01.881661Z","shell.execute_reply.started":"2021-07-11T07:35:27.094981Z","shell.execute_reply":"2021-07-11T07:36:01.880843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    ## Classification Report\n    ##clf_rep = classification_report(y_test, test_predictions, output_dict=True)\n    c=xgb_clf_tuned_1.fit(x_train, y_train);\n    test_predictions = c.predict(x_test)\n    print(classification_report(y_test, test_predictions\n                                ))\n    #prediction and Classification Report\n\n    ","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:36:01.883082Z","iopub.execute_input":"2021-07-11T07:36:01.883396Z","iopub.status.idle":"2021-07-11T07:36:11.746077Z","shell.execute_reply.started":"2021-07-11T07:36:01.883366Z","shell.execute_reply":"2021-07-11T07:36:11.744847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_train, c.predict(x_train)))","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:36:11.747793Z","iopub.execute_input":"2021-07-11T07:36:11.748217Z","iopub.status.idle":"2021-07-11T07:36:11.999787Z","shell.execute_reply.started":"2021-07-11T07:36:11.748172Z","shell.execute_reply":"2021-07-11T07:36:11.998583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params2 = stepwise_optimization(trials=50)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:36:12.00142Z","iopub.execute_input":"2021-07-11T07:36:12.001865Z","iopub.status.idle":"2021-07-11T07:38:00.266157Z","shell.execute_reply.started":"2021-07-11T07:36:12.001821Z","shell.execute_reply":"2021-07-11T07:38:00.265301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params2","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:38:00.267265Z","iopub.execute_input":"2021-07-11T07:38:00.267692Z","iopub.status.idle":"2021-07-11T07:38:00.273005Z","shell.execute_reply.started":"2021-07-11T07:38:00.267661Z","shell.execute_reply":"2021-07-11T07:38:00.271705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_clf_tuned_2 = XGBClassifier(**params2,\n                                 random_state=45, n_jobs=-1)\nxgb_clf_tuned_2.fit(x_train, y_train);\n\nxgb_clf_tuned_2, xgb_report_tuned_2 = report(xgb_clf_tuned_2, x_train, y_train,\n                                             x_test, y_test,\n                                             display_scores=[primary_eval_metric],\n                                             importance_plot=True,\n                                             feature_labels=n\n                                             )","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:38:00.274242Z","iopub.execute_input":"2021-07-11T07:38:00.274594Z","iopub.status.idle":"2021-07-11T07:38:46.440592Z","shell.execute_reply.started":"2021-07-11T07:38:00.274565Z","shell.execute_reply":"2021-07-11T07:38:46.439853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import load_digits\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import ShuffleSplit\n\n\ndef plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None,\n                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n    \"\"\"\n    Generate 3 plots: the test and training learning curve, the training\n    samples vs fit times curve, the fit times vs score curve.\n\n    Parameters\n    ----------\n    estimator : estimator instance\n        An estimator instance implementing `fit` and `predict` methods which\n        will be cloned for each validation.\n\n    title : str\n        Title for the chart.\n\n    X : array-like of shape (n_samples, n_features)\n        Training vector, where ``n_samples`` is the number of samples and\n        ``n_features`` is the number of features.\n\n    y : array-like of shape (n_samples) or (n_samples, n_features)\n        Target relative to ``X`` for classification or regression;\n        None for unsupervised learning.\n\n    axes : array-like of shape (3,), default=None\n        Axes to use for plotting the curves.\n\n    ylim : tuple of shape (2,), default=None\n        Defines minimum and maximum y-values plotted, e.g. (ymin, ymax).\n\n    cv : int, cross-validation generator or an iterable, default=None\n        Determines the cross-validation splitting strategy.\n        Possible inputs for cv are:\n\n          - None, to use the default 5-fold cross-validation,\n          - integer, to specify the number of folds.\n          - :term:`CV splitter`,\n          - An iterable yielding (train, test) splits as arrays of indices.\n\n        For integer/None inputs, if ``y`` is binary or multiclass,\n        :class:`StratifiedKFold` used. If the estimator is not a classifier\n        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n\n        Refer :ref:`User Guide <cross_validation>` for the various\n        cross-validators that can be used here.\n\n    n_jobs : int or None, default=None\n        Number of jobs to run in parallel.\n        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n        for more details.\n\n    train_sizes : array-like of shape (n_ticks,)\n        Relative or absolute numbers of training examples that will be used to\n        generate the learning curve. If the ``dtype`` is float, it is regarded\n        as a fraction of the maximum size of the training set (that is\n        determined by the selected validation method), i.e. it has to be within\n        (0, 1]. Otherwise it is interpreted as absolute sizes of the training\n        sets. Note that for classification the number of samples usually have\n        to be big enough to contain at least one sample from each class.\n        (default: np.linspace(0.1, 1.0, 5))\n    \"\"\"\n    if axes is None:\n        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n\n    axes[0].set_title(title)\n    if ylim is not None:\n        axes[0].set_ylim(*ylim)\n    axes[0].set_xlabel(\"Training examples\")\n    axes[0].set_ylabel(\"Score\")\n\n    train_sizes, train_scores, test_scores, fit_times, _ = \\\n        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n                       train_sizes=train_sizes,\n                       return_times=True)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    fit_times_mean = np.mean(fit_times, axis=1)\n    fit_times_std = np.std(fit_times, axis=1)\n\n    # Plot learning curve\n    axes[0].grid()\n    axes[0].fill_between(train_sizes, train_scores_mean - train_scores_std,\n                         train_scores_mean + train_scores_std, alpha=0.1,\n                         color=\"r\")\n    axes[0].fill_between(train_sizes, test_scores_mean - test_scores_std,\n                         test_scores_mean + test_scores_std, alpha=0.1,\n                         color=\"g\")\n    axes[0].plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n                 label=\"Training score\")\n    axes[0].plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n                 label=\"Cross-validation score\")\n    axes[0].legend(loc=\"best\")\n\n    # Plot n_samples vs fit_times\n    axes[1].grid()\n    axes[1].plot(train_sizes, fit_times_mean, 'o-')\n    axes[1].fill_between(train_sizes, fit_times_mean - fit_times_std,\n                         fit_times_mean + fit_times_std, alpha=0.1)\n    axes[1].set_xlabel(\"Training examples\")\n    axes[1].set_ylabel(\"fit_times\")\n    axes[1].set_title(\"Scalability of the model\")\n\n    # Plot fit_time vs score\n    axes[2].grid()\n    axes[2].plot(fit_times_mean, test_scores_mean, 'o-')\n    axes[2].fill_between(fit_times_mean, test_scores_mean - test_scores_std,\n                         test_scores_mean + test_scores_std, alpha=0.1)\n    axes[2].set_xlabel(\"fit_times\")\n    axes[2].set_ylabel(\"Score\")\n    axes[2].set_title(\"Performance of the model\")\n\n    return plt\n\n\nfig, axes = plt.subplots(3, 2, figsize=(10, 15))\n\nX, y = load_digits(return_X_y=True)\n\ntitle = \"Learning Curves (XGBclassifiermodel1)\"\n# Cross validation with 100 iterations to get smoother mean test and train\n# score curves, each time with 20% data randomly selected as a validation set.\ncv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n\nestimator = XGBClassifier(**params1, \n                                random_state=45, n_jobs=-1)\nplot_learning_curve(estimator, title, X, y, axes=axes[:, 0], ylim=(0.7, 1.01),\n                    cv=cv, n_jobs=4)\n\ntitle = r\"Learning Curves (XGBclassifier2, $\\gamma=0.001$)\"\n# SVC is more expensive so we do a lower number of CV iterations:\ncv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\nestimator =XGBClassifier(**params2,\n                                 random_state=45, n_jobs=-1)\nplot_learning_curve(estimator, title, X, y, axes=axes[:, 1], ylim=(0.7, 1.01),\n                    cv=cv, n_jobs=4)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T07:38:46.441789Z","iopub.execute_input":"2021-07-11T07:38:46.442187Z","iopub.status.idle":"2021-07-11T10:29:31.764849Z","shell.execute_reply.started":"2021-07-11T07:38:46.442158Z","shell.execute_reply":"2021-07-11T10:29:31.759852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**SHAP**","metadata":{}},{"cell_type":"code","source":"import shap\nimport xgboost\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pylab as pl","metadata":{"execution":{"iopub.status.busy":"2021-07-11T10:32:01.652674Z","iopub.execute_input":"2021-07-11T10:32:01.653102Z","iopub.status.idle":"2021-07-11T10:32:10.719648Z","shell.execute_reply.started":"2021-07-11T10:32:01.653059Z","shell.execute_reply":"2021-07-11T10:32:10.718871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#deopping hemoglobin\nX = df_m1.drop(['Anemia','Hemoglobin','Anemia_treatment'],axis=1)\ny = df_m1[['Anemia']]","metadata":{"execution":{"iopub.status.busy":"2021-07-11T10:32:10.720853Z","iopub.execute_input":"2021-07-11T10:32:10.721296Z","iopub.status.idle":"2021-07-11T10:32:10.732909Z","shell.execute_reply.started":"2021-07-11T10:32:10.721266Z","shell.execute_reply":"2021-07-11T10:32:10.731706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"execution":{"iopub.status.busy":"2021-07-11T10:32:10.735606Z","iopub.execute_input":"2021-07-11T10:32:10.736002Z","iopub.status.idle":"2021-07-11T10:32:10.799861Z","shell.execute_reply.started":"2021-07-11T10:32:10.735968Z","shell.execute_reply":"2021-07-11T10:32:10.798717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap_values = shap.TreeExplainer(xgb_clf_tuned_1).shap_values(x_train)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T10:32:10.801476Z","iopub.execute_input":"2021-07-11T10:32:10.801803Z","iopub.status.idle":"2021-07-11T10:33:09.934182Z","shell.execute_reply.started":"2021-07-11T10:32:10.801755Z","shell.execute_reply":"2021-07-11T10:33:09.933045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.summary_plot(shap_values, x_train)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T10:33:09.935701Z","iopub.execute_input":"2021-07-11T10:33:09.936244Z","iopub.status.idle":"2021-07-11T10:33:15.256069Z","shell.execute_reply.started":"2021-07-11T10:33:09.936194Z","shell.execute_reply":"2021-07-11T10:33:15.254998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.dependence_plot(\"GlycoHemoglobin\", shap_values, x_train,interaction_index=None)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T10:33:15.257364Z","iopub.execute_input":"2021-07-11T10:33:15.257696Z","iopub.status.idle":"2021-07-11T10:33:15.442446Z","shell.execute_reply.started":"2021-07-11T10:33:15.257664Z","shell.execute_reply":"2021-07-11T10:33:15.441192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.dependence_plot(\"Gender\", shap_values, x_train,interaction_index=None)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T10:33:15.443681Z","iopub.execute_input":"2021-07-11T10:33:15.444003Z","iopub.status.idle":"2021-07-11T10:33:15.614298Z","shell.execute_reply.started":"2021-07-11T10:33:15.44397Z","shell.execute_reply":"2021-07-11T10:33:15.61356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.dependence_plot(\"Age\", shap_values, x_train,interaction_index=None)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T10:33:15.616178Z","iopub.execute_input":"2021-07-11T10:33:15.616618Z","iopub.status.idle":"2021-07-11T10:33:15.796742Z","shell.execute_reply.started":"2021-07-11T10:33:15.616574Z","shell.execute_reply":"2021-07-11T10:33:15.795875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.dependence_plot(\"BMI\", shap_values, x_train,interaction_index=None)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T10:33:15.797991Z","iopub.execute_input":"2021-07-11T10:33:15.798432Z","iopub.status.idle":"2021-07-11T10:33:15.961585Z","shell.execute_reply.started":"2021-07-11T10:33:15.798385Z","shell.execute_reply":"2021-07-11T10:33:15.960667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.dependence_plot(\"DRD360\", shap_values, x_train,interaction_index=None)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T10:33:15.96279Z","iopub.execute_input":"2021-07-11T10:33:15.963256Z","iopub.status.idle":"2021-07-11T10:33:16.163607Z","shell.execute_reply.started":"2021-07-11T10:33:15.96321Z","shell.execute_reply":"2021-07-11T10:33:16.162796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.dependence_plot(\"DR1DRSTZ\", shap_values, x_train,interaction_index=None)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T10:33:16.164808Z","iopub.execute_input":"2021-07-11T10:33:16.165301Z","iopub.status.idle":"2021-07-11T10:33:16.351029Z","shell.execute_reply.started":"2021-07-11T10:33:16.165256Z","shell.execute_reply":"2021-07-11T10:33:16.350013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**LIGHTGBM**","metadata":{}},{"cell_type":"code","source":"import scipy\nimport scipy.stats\nfrom scipy import stats","metadata":{"execution":{"iopub.status.busy":"2021-07-11T10:29:31.798353Z","iopub.status.idle":"2021-07-11T10:29:31.798797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nimport gc\nseed = 195\ntest_size = 0.3\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)\nevals = {}\nevals['lgb'] = {}\nlparams = {}\nseeds = [0, 1]\nnfold = [5, 5]\nstratified=[False, False]\nshuffle=[True, True]\nn_estimators = 30000\nearly_stopping_rounds = 300\nverbose_eval = 0\nlearning_rate = 0.01\nreg_alpha = [0.4, 1]\nreg_lambda = [0.7, 1]\nsubsample = [0.45, 1]\ncolsample_bytree = [0.3, 0.225]\nmax_depth = -1\nverbose = -1\nn_jobs = 4\nlparams[0] = dict(boosting_type='gbdt',\n               objective='binary',\n               metric='auc',\n               learning_rate= learning_rate,\n               num_leaves= 200,\n               max_bin=500,\n               min_child_weight= 0.035,\n               subsample= subsample[0],\n               colsample_bytree= colsample_bytree[0],\n               min_data_in_leaf= 150,\n               max_depth= max_depth,\n               bagging_seed= seeds[0],\n               reg_alpha= reg_alpha[0],\n               reg_lambda= reg_lambda[0],\n               verbose= verbose,\n               seed= seeds[0],\n               n_jobs= n_jobs,)\nlparams[1] = dict(boosting_type='gbdt',\n               objective='binary',\n               metric='auc',\n               learning_rate= learning_rate,\n               n_estimators= n_estimators,\n               subsample= subsample[1],\n               colsample_bytree= colsample_bytree[1],\n               max_depth= max_depth,\n               bagging_seed= seeds[1],\n               reg_alpha= reg_alpha[1],\n               reg_lambda= reg_lambda[1],\n               verbose= verbose,\n               seed= seeds[1],\n               n_jobs= n_jobs,)\ntest_preds = np.zeros(len(X_test))    \ndtrain = lgb.Dataset(X_train, y_train)\ndtest = X_test.copy()\ntestlen = X_test.shape[0]\n\ngc.collect()\nfor i, seed in enumerate(seeds):\n    print(f'Training Model with SEED : {seed}')\n    evals['lgb'][i] = lgb.cv(lparams[i],\n                             dtrain,\n                             nfold=nfold[i], \n                             stratified=stratified[i],\n                             shuffle=shuffle[i],\n                             num_boost_round=n_estimators,\n                             early_stopping_rounds=early_stopping_rounds,\n                             verbose_eval=verbose_eval,\n                             return_cvbooster=True,\n                             seed = seed,\n                             show_stdv=True)\n    \n                  \n#     filename = 'lgb_'+ i+'_.sav'\n#     pickle.dump(evals['lgb'][i], open(filename, 'wb'))\n    print(f'SEED {i} Average fold  AUC {np.round(max(evals[\"lgb\"][i][\"auc-mean\"]),5)}')\n    \n    \n    test_preds += stats.rankdata(np.mean(evals['lgb'][i]['cvbooster'].predict(dtest, num_iteration=evals['lgb'][i]['cvbooster'].best_iteration), axis=0)) / (testlen * len(seeds))\n    ","metadata":{"execution":{"iopub.status.busy":"2021-07-11T10:29:31.799936Z","iopub.status.idle":"2021-07-11T10:29:31.80038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Model= lgb.train(params=lparams[1],train_set=dtrain)\n\n#prediction and Classification Report\nfrom sklearn.metrics import classification_report\n\npred = Model.predict(X_test)\npred_labels = np.rint(pred)\n   \nmean_accuracy=sklearn.metrics.accuracy_score(y_test, pred_labels),\n\nprint( (classification_report(y_test, pred_labels)))","metadata":{"execution":{"iopub.status.busy":"2021-07-11T10:29:31.801232Z","iopub.status.idle":"2021-07-11T10:29:31.801938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nauc_score1 = roc_auc_score(y_test, pred_labels)\nauc_score1","metadata":{"execution":{"iopub.status.busy":"2021-07-11T10:29:31.802879Z","iopub.status.idle":"2021-07-11T10:29:31.803327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**XGBClassifier with K-fold cross validation**","metadata":{}},{"cell_type":"code","source":"model1=xgb.XGBClassifier(\n learning_rate =0.1,\n n_estimators=500,\n max_depth=6,\n min_child_weight=1,\n gamma=0,\n subsample=0.8,\n colsample_bytree=0.8,\n objective= 'binary:logistic',\n scale_pos_weight=4.747735,\n seed=27,eval_metric=\"error\")\ntrain_model = model1.fit(X_train, y_train,eval_metric=\"error\",verbose=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T10:29:31.804128Z","iopub.status.idle":"2021-07-11T10:29:31.804563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# stratified k-fold cross validation evaluation of xgboost model\nfrom numpy import loadtxt\nimport xgboost\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_val_score\n\n# CV model\nkfold = StratifiedKFold(n_splits=5)\nresults = cross_val_score(model1, X, y, cv=kfold)\nprint(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))","metadata":{"execution":{"iopub.status.busy":"2021-07-11T10:29:31.805334Z","iopub.status.idle":"2021-07-11T10:29:31.805776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import XGBoost\nimport xgboost as xgb\n\n\n# define data_dmatrix\ndata_dmatrix = xgb.DMatrix(data=X,label=y)\nfrom xgboost import cv\n\nparams = {'learning_rate':0.1,\n 'n_estimators':500,\n 'max_depth':6,\n 'min_child_weight':1,\n 'gamma':0,\n 'subsample':0.8,\n 'colsample_bytree':0.8,\n 'objective': 'binary:logistic',\n 'scale_pos_weight':4.747735,\n 'seed':27}\n\nxgb_cv = cv(dtrain=data_dmatrix, params=params, nfold=5,num_boost_round=5,\n                     metrics=\"error\", as_pandas=True, seed=123)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T10:29:31.806541Z","iopub.status.idle":"2021-07-11T10:29:31.807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(((1-xgb_cv[\"test-error-mean\"]).iloc[-1]))\n","metadata":{"execution":{"iopub.status.busy":"2021-07-11T10:29:31.807783Z","iopub.status.idle":"2021-07-11T10:29:31.80821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_cv.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T10:29:31.80909Z","iopub.status.idle":"2021-07-11T10:29:31.809514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**XGBClassifier**","metadata":{}},{"cell_type":"code","source":"model1=xgb.XGBClassifier(\n learning_rate =0.1,\n n_estimators=500,\n max_depth=6,\n min_child_weight=1,\n gamma=0,\n subsample=0.8,\n colsample_bytree=0.8,\n objective= 'binary:logistic',\n scale_pos_weight=4.747735,\n seed=27,eval_metric=\"error\")\ntrain_model = model1.fit(X_train, y_train,eval_metric=\"error\",verbose=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T10:29:31.810291Z","iopub.status.idle":"2021-07-11T10:29:31.810709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#prediction and Classification Report\nfrom sklearn.metrics import classification_report\n\npred = train_model.predict(X_test)\n\nprint( (classification_report(y_test, pred)))","metadata":{"execution":{"iopub.status.busy":"2021-07-11T10:29:31.811601Z","iopub.status.idle":"2021-07-11T10:29:31.812057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_train, train_model.predict(X_train)))","metadata":{"execution":{"iopub.status.busy":"2021-07-11T10:29:31.812797Z","iopub.status.idle":"2021-07-11T10:29:31.81322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nprint('Accuracy: {0:.2f}'.format(accuracy_score(y_test, pred)))\n#print('Precision: {0:.2f}'.format(precision_score(y_test, pred)))\n#print('Recall: {0:.2f}'.format(recall_score(y_test, pred)))\n#print('AUC ROC: {0:.2f}'.format(roc_auc_score(y_test, pred)))","metadata":{"execution":{"iopub.status.busy":"2021-07-11T10:29:31.813965Z","iopub.status.idle":"2021-07-11T10:29:31.814382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb.plot_importance(train_model)\nplt.rcParams['figure.figsize'] = [15,9]\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T10:29:31.815204Z","iopub.status.idle":"2021-07-11T10:29:31.815631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**RANDOM FOREST CLASSIFIER**","metadata":{}},{"cell_type":"code","source":"#RAndom forest classifier\n# import Random Forest classifier\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import roc_curve, auc\n\n\nn_estimators = [1, 2, 4, 8, 16, 32, 64, 100, 200,500,1000]\ntrain_results = []\ntest_results = []\nfor estimator in n_estimators:\n   rf = RandomForestClassifier(n_estimators=estimator, n_jobs=-1)\n   rf.fit(X_train, y_train)\n   train_pred = rf.predict(X_train)\n   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n   roc_auc = auc(false_positive_rate, true_positive_rate)\n   train_results.append(roc_auc)\n   y_pred = rf.predict(X_test)\n   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n   roc_auc = auc(false_positive_rate, true_positive_rate)\n   test_results.append(roc_auc)\n    \nfrom matplotlib.legend_handler import HandlerLine2D\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nline1, = plt.plot(n_estimators, train_results, \"b\", label=\"Train AUC\")\nline2, = plt.plot(n_estimators, test_results, \"r\", label=\"Test AUC\")\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\nplt.ylabel(\"AUC score\")\nplt.xlabel(\"n_estimators\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T10:29:31.816727Z","iopub.status.idle":"2021-07-11T10:29:31.817201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_depths = np.linspace(1, 32, 32, endpoint=True)\ntrain_results = []\ntest_results = []\nfor max_depth in max_depths:\n   rf = RandomForestClassifier(max_depth=max_depth, n_jobs=-1)\n   rf.fit(X_train, y_train)\n   train_pred = rf.predict(X_train)\n   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n   roc_auc = auc(false_positive_rate, true_positive_rate)\n   train_results.append(roc_auc)\n   y_pred = rf.predict(X_test)\n   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n   roc_auc = auc(false_positive_rate, true_positive_rate)\n   test_results.append(roc_auc)\nfrom matplotlib.legend_handler import HandlerLine2D\nline1, = plt.plot(max_depths, train_results, \"b\", label=\"Train AUC\")\nline2, = plt.plot(max_depths, test_results, \"r\", label=\"Test AUC\" )\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\nplt.ylabel(\"AUC score\")\nplt.xlabel(\"Tree depth\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T10:29:31.818205Z","iopub.status.idle":"2021-07-11T10:29:31.818647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"min_samples_leafs = np.linspace(0.1,  0.5,50 ,endpoint=True)\ntrain_results = []\ntest_results = []\nfor min_samples_leaf in min_samples_leafs:\n   rf = RandomForestClassifier(min_samples_leaf=min_samples_leaf)\n   rf.fit(X_train, y_train)\n   train_pred = rf.predict(X_train)\n   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n   roc_auc = auc(false_positive_rate, true_positive_rate)\n   train_results.append(roc_auc)\n   y_pred = rf.predict(X_test)\n   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n   roc_auc = auc(false_positive_rate, true_positive_rate)\n   test_results.append(roc_auc)\nfrom matplotlib.legend_handler import HandlerLine2D\nline1, = plt.plot(min_samples_leafs, train_results,\"b\",label=\"Train AUC\")\nline2, = plt.plot(min_samples_leafs, test_results, \"r\", label=\"Test AUC\")\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\nplt.ylabel(\"AUC score\")\nplt.xlabel(\"min samples leaf\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T10:29:31.819441Z","iopub.status.idle":"2021-07-11T10:29:31.819897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#RAndom forest classifier\n# import Random Forest classifier\n\nfrom sklearn.ensemble import RandomForestClassifier\n#Split the dataset into train and Test\nfrom sklearn.model_selection import train_test_split\n\nseed = 195\ntest_size = 0.3\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)\n\n\n# instantiate the classifier \n\nrfc = RandomForestClassifier(class_weight=\"balanced\", n_estimators=500, min_samples_leaf=50, max_depth=7)\n\n\n\n# fit the model\n\nrfc.fit(X_train, y_train)\n\n\n\n# Predict the Test set results\n\ny_pred = rfc.predict(X_test)\n\n\n\n# Check accuracy score \n\nfrom sklearn.metrics import accuracy_score\n\nprint('Model accuracy score with  decision-trees : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n","metadata":{"execution":{"iopub.status.busy":"2021-07-11T10:29:31.820663Z","iopub.status.idle":"2021-07-11T10:29:31.821097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#prediction and Classification Report\nfrom sklearn.metrics import classification_report\n\npred = rfc.predict(X_test)\n\nprint( (classification_report(y_test, y_pred)))","metadata":{"execution":{"iopub.status.busy":"2021-07-11T10:29:31.822117Z","iopub.status.idle":"2021-07-11T10:29:31.822545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# view the feature scores\n\nfeature_scores = pd.Series(rfc.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n\nfeature_scores","metadata":{"execution":{"iopub.status.busy":"2021-07-09T09:54:30.388833Z","iopub.execute_input":"2021-07-09T09:54:30.389301Z","iopub.status.idle":"2021-07-09T09:54:30.468697Z","shell.execute_reply.started":"2021-07-09T09:54:30.389258Z","shell.execute_reply":"2021-07-09T09:54:30.467487Z"}}},{"cell_type":"markdown","source":"     n_estimators=500 minsample leaf 50\n     precision    recall  f1-score   support\n\n         0.0       0.90      0.81      0.85      7174\n         1.0       0.39      0.56      0.46      1527\n\n    accuracy                           0.77      8701\n   macro avg       0.64      0.69      0.66      8701\nweighted avg       0.81      0.77      0.78      8701\n","metadata":{}},{"cell_type":"markdown","source":"  max-depth 6 subsample 0.8\n      precision    recall  f1-score   support\n\n         0.0       0.89      0.84      0.86      7174\n         1.0       0.40      0.50      0.44      1527\n\n    accuracy                           0.78      8701\n   macro avg       0.64      0.67      0.65      8701\nweighted avg       0.80      0.78      0.79      8701\n\n\nAccuracy for model : 78.08\n\n","metadata":{}},{"cell_type":"markdown","source":"subsample 0.5 max depth 10\n\n\nprecision    recall  f1-score   support\n\n         0.0       0.86      0.91      0.89      7174\n         1.0       0.43      0.32      0.37      1527\n\n    accuracy                           0.81      8701\n   macro avg       0.65      0.61      0.63      8701\nweighted avg       0.79      0.81      0.79      8701\n","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"max-depth 6 subsample 0.8 \n  precision    recall  f1-score   support\n\n         0.0       0.87      0.89      0.88      7174\n         1.0       0.43      0.39      0.41      1527\n\n    accuracy                           0.80      8701\n   macro avg       0.65      0.64      0.65      8701\nweighted avg       0.80      0.80      0.80      8701\nAccuracy for model : 80.20","metadata":{}}]}