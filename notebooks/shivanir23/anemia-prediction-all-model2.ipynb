{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-07-17T07:53:03.2657Z","iopub.execute_input":"2021-07-17T07:53:03.26615Z","iopub.status.idle":"2021-07-17T07:53:03.279174Z","shell.execute_reply.started":"2021-07-17T07:53:03.266108Z","shell.execute_reply":"2021-07-17T07:53:03.277836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nimport plotly.express as px\nimport plotly.io as pio\npio.renderers.default='notebook'\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib as matplot\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import RFE\n\n\nimport re\nimport sklearn\nimport xgboost as xgb\nfrom sklearn.metrics import mean_squared_error\nimport pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n%matplotlib inline\n","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-07-17T07:53:03.471473Z","iopub.execute_input":"2021-07-17T07:53:03.471825Z","iopub.status.idle":"2021-07-17T07:53:03.491551Z","shell.execute_reply.started":"2021-07-17T07:53:03.471794Z","shell.execute_reply":"2021-07-17T07:53:03.490128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ANEMIA PREDICTION USING NHANES DATA FROM 2013-2018 ","metadata":{}},{"cell_type":"markdown","source":"**Merging data**","metadata":{}},{"cell_type":"code","source":"#Merging 2013-14 datsets\ndf1 = pd.read_csv('../input/national-health-and-nutrition-examination-survey/labs.csv')\ndf2 = pd.read_csv('../input/national-health-and-nutrition-examination-survey/examination.csv')\ndf3 = pd.read_csv('../input/national-health-and-nutrition-examination-survey/demographic.csv')\ndf4a = pd.read_csv('../input/national-health-and-nutrition-examination-survey/diet.csv')\ndf5 = pd.read_csv('../input/national-health-and-nutrition-examination-survey/questionnaire.csv')\n\ndf2.drop(['SEQN'], axis = 1, inplace=True)\ndf3.drop(['SEQN'], axis = 1, inplace=True)\ndf4a.drop(['SEQN'], axis = 1, inplace=True)\ndf5.drop(['SEQN'], axis = 1, inplace=True)\n\ndfa = pd.concat([df1, df2], axis=1, join='inner')\ndfa = pd.concat([dfa, df3], axis=1, join='inner')\ndfa = pd.concat([dfa, df4a], axis=1, join='inner')\ndfa = pd.concat([dfa, df5], axis=1, join='inner')\n","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:53:04.948729Z","iopub.execute_input":"2021-07-17T07:53:04.949084Z","iopub.status.idle":"2021-07-17T07:53:07.347355Z","shell.execute_reply.started":"2021-07-17T07:53:04.949054Z","shell.execute_reply":"2021-07-17T07:53:07.346476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#reading 2015-16 healthdata\nd56 = pd.read_csv('../input/merged/merged_2015_2016.csv')\nd56.describe()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-07-17T07:53:07.348666Z","iopub.execute_input":"2021-07-17T07:53:07.349098Z","iopub.status.idle":"2021-07-17T07:53:08.328915Z","shell.execute_reply.started":"2021-07-17T07:53:07.349065Z","shell.execute_reply":"2021-07-17T07:53:08.327866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#reading 2017-18 healthdata\nd78 = pd.read_csv('../input/merged/merged_2017_2018.csv')\nd78.describe()\n","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-07-17T07:53:08.330823Z","iopub.execute_input":"2021-07-17T07:53:08.33115Z","iopub.status.idle":"2021-07-17T07:53:09.238058Z","shell.execute_reply.started":"2021-07-17T07:53:08.33112Z","shell.execute_reply":"2021-07-17T07:53:09.236856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a=d56.columns\n\nb=d78.columns\n","metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"execution":{"iopub.status.busy":"2021-07-17T07:53:09.23975Z","iopub.execute_input":"2021-07-17T07:53:09.240055Z","iopub.status.idle":"2021-07-17T07:53:09.244849Z","shell.execute_reply.started":"2021-07-17T07:53:09.240023Z","shell.execute_reply":"2021-07-17T07:53:09.243856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#merging 2015,2016,2017,2018 data\ndf_m = pd.concat([d56,d78],ignore_index=True,axis=0)\n\ndf_m.describe()\n","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-07-17T07:53:09.246233Z","iopub.execute_input":"2021-07-17T07:53:09.246571Z","iopub.status.idle":"2021-07-17T07:53:10.086578Z","shell.execute_reply.started":"2021-07-17T07:53:09.246537Z","shell.execute_reply":"2021-07-17T07:53:10.085616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#merged 2015,16,17,18\n#Dropiing non common rows across different datasets\n#\ndf_md=df_m.drop(['DR1TWS', 'DMDHRMAR', 'DMDHRBR4', 'DMDHREDU', 'DMDHRAGE', 'DMDHSEDU','DMDHRAGZ', 'DMDHREDZ', 'DMDHRMAZ', 'DMDHSEDZ', 'DR1TWSZ','DR1_330Z', 'DR1_320Z', 'DR1MRESP', 'DR1_300', 'DR1HELP'],axis=1)\n\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-17T07:53:10.087822Z","iopub.execute_input":"2021-07-17T07:53:10.088116Z","iopub.status.idle":"2021-07-17T07:53:10.110633Z","shell.execute_reply.started":"2021-07-17T07:53:10.088086Z","shell.execute_reply":"2021-07-17T07:53:10.109801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_mdc=df_md.columns\n#dfa-2013-14dataframe\nprint(dfa[df_mdc])","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-07-17T07:53:10.11174Z","iopub.execute_input":"2021-07-17T07:53:10.112145Z","iopub.status.idle":"2021-07-17T07:53:10.329073Z","shell.execute_reply.started":"2021-07-17T07:53:10.112112Z","shell.execute_reply":"2021-07-17T07:53:10.328289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Merged data frame**","metadata":{}},{"cell_type":"code","source":"#Merging 2013,14,15,16,17,18 data\ndf_x = pd.concat([dfa[df_mdc],df_md],ignore_index=True,axis=0)\ndf_x.dropna(axis=1, how='all')\ndf_x.dropna(axis=0, how='all')\ndf_x","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:53:10.331383Z","iopub.execute_input":"2021-07-17T07:53:10.331829Z","iopub.status.idle":"2021-07-17T07:53:10.541506Z","shell.execute_reply.started":"2021-07-17T07:53:10.331795Z","shell.execute_reply":"2021-07-17T07:53:10.540532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Renaming required columns\ndf_x = df_x.rename(columns = {'SEQN' : 'ID',\n                          'RIDAGEYR': 'Age',\n                          'RIAGENDR' : 'Gender',\n                          'WTINT2YR' : 'Weight',\n                          'INDFMIN2' : 'Tot_family_income',\n                          'DMDFMSIZ'  :'Tot_no_fam_members',\n                          'DMDYRSUS' : 'Years_in_US', # Nan -> american i guess\n                          'INDFMPIR' : 'Family_income',\n                          'LBXGH' : 'GlycoHemoglobin',\n                          'BMXARMC' : 'ArmCircum',\n                          'BMDAVSAD' : 'SaggitalAbdominal',\n                          'MGDCGSZ' : 'GripStrength',\n                          'DRABF' : 'Breast_fed',\n                           'MCQ053':'Anemia_treatment',\n                            'LBXHGB': 'Hemoglobin',\n                            'MCQ220': 'Cancer',\n                            'BMXBMI': 'BMI',\n                            'DMDEDUC2':'Educationlevel',\n                            'INDHHINC': 'annualincome',\n                            'RIDRETH1':'Ethinicity',\n                            \n                           })\n\ndf_x.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:53:10.544245Z","iopub.execute_input":"2021-07-17T07:53:10.544967Z","iopub.status.idle":"2021-07-17T07:53:11.425574Z","shell.execute_reply.started":"2021-07-17T07:53:10.54491Z","shell.execute_reply":"2021-07-17T07:53:11.424519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Filling continous and categorical missing values\ndf_x['Tot_family_income'] = df_x['Tot_family_income'].interpolate(limit_direction ='both')\ndf_x['Hemoglobin'] = df_x['Hemoglobin'].interpolate(limit_direction ='both')\ndf_x['Age'] = df_x['Age'].interpolate(limit_direction ='both')\ndf_x['Weight'] = df_x['Weight'].interpolate(limit_direction ='both')\ndf_x['Tot_no_fam_members'] = df_x['Tot_no_fam_members'].interpolate(limit_direction ='both')\n    \ndf_x = df_x.fillna(df_x['Gender'].value_counts().index[0])\ndf_x = df_x.fillna(df_x['Anemia_treatment'].value_counts().index[0])\n\n    \n\n    ","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:53:11.426968Z","iopub.execute_input":"2021-07-17T07:53:11.427298Z","iopub.status.idle":"2021-07-17T07:53:11.529973Z","shell.execute_reply.started":"2021-07-17T07:53:11.427263Z","shell.execute_reply":"2021-07-17T07:53:11.52894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Filling rest of missing values\nimport pandas as pd\nimport numpy as np\nfrom sklearn.base import TransformerMixin\nclass DataFrameImputer(TransformerMixin):\n    def __init__(self):\n        \"\"\"Impute missing values.\n        Columns of dtype object are imputed with the most frequent value\n        in column.\n        Columns of other types are imputed with mean of column.\n        \"\"\"\n    def fit(self, X, y=None):\n        self.fill = pd.Series([X[c].value_counts().index[0]\n            if X[c].dtype == np.dtype('O') else X[c].mean() for c in X],\n            index=X.columns)\n        return self\n    def transform(self, X, y=None):\n        return X.fillna(self.fill)\n\n\nX = df_x\nprint('before...')\nprint(X)\ndf_x = DataFrameImputer().fit_transform(X)\nprint('after...')\nprint(df_x)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-07-17T07:53:11.531289Z","iopub.execute_input":"2021-07-17T07:53:11.531786Z","iopub.status.idle":"2021-07-17T07:53:11.716971Z","shell.execute_reply.started":"2021-07-17T07:53:11.53175Z","shell.execute_reply":"2021-07-17T07:53:11.715754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Anemia calculation**","metadata":{}},{"cell_type":"code","source":"df_x.loc[(df_x['Gender']==1) & (df_x['Hemoglobin'] < 13), 'Anemia'] = 1\ndf_x.loc[(df_x['Gender']==1) & (df_x['Hemoglobin'] > 13), 'Anemia'] = 0\n\ndf_x.loc[(df_x['Gender']==2) & (df_x['Hemoglobin'] < 12), 'Anemia'] = 1\ndf_x.loc[(df_x['Gender']==2) & (df_x['Hemoglobin'] > 12), 'Anemia'] = 0\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:53:11.718664Z","iopub.execute_input":"2021-07-17T07:53:11.71927Z","iopub.status.idle":"2021-07-17T07:53:11.735806Z","shell.execute_reply.started":"2021-07-17T07:53:11.719219Z","shell.execute_reply":"2021-07-17T07:53:11.734827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_x['Anemia']=df_x['Anemia'].fillna(0)\n#Distribution of ANEMIA values\ndf_x['Anemia'].value_counts(normalize=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:53:11.737407Z","iopub.execute_input":"2021-07-17T07:53:11.738Z","iopub.status.idle":"2021-07-17T07:53:11.748319Z","shell.execute_reply.started":"2021-07-17T07:53:11.73796Z","shell.execute_reply":"2021-07-17T07:53:11.747436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Percentage of null values**","metadata":{}},{"cell_type":"code","source":"null=100*(df_x.isnull().sum())/(df_x.shape[0])\n\ndf4ad_null=pd.DataFrame({'percentage':null})\n\ndf4ad_null.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:53:11.749651Z","iopub.execute_input":"2021-07-17T07:53:11.750108Z","iopub.status.idle":"2021-07-17T07:53:11.786623Z","shell.execute_reply.started":"2021-07-17T07:53:11.750063Z","shell.execute_reply":"2021-07-17T07:53:11.785674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Extracting important values from dataframe**","metadata":{}},{"cell_type":"code","source":"df_m1 = df_x.loc[:,['DR1DRSTZ',\n 'DRD350A',\n 'DRD350C',\n 'DRD350D',\n 'DRD350E',\n 'DRD350G',\n 'DRD350I',\n 'DRD350J',\n 'DRD350K',\n 'DRD360',\n 'DRD370C',\n 'DRD370G',\n 'DRD370H',\n 'DRD370I',\n 'DRD370J',\n 'DRD370K',\n 'DRD370L',\n 'DRD370N',\n 'DRD370O',\n 'DRD370P',\n 'DRD370Q',\n 'DRD370R',\n 'DRD370S',\n 'DRD370T',\n 'DRD370U',\n 'DRD370V',\n 'ID',\n 'Gender',\n 'Age',\n 'Weight',\n 'Tot_family_income',\n 'Tot_no_fam_members',\n 'Hemoglobin',\n 'Anemia_treatment',\n 'Cancer',\n 'BMI',\n 'Educationlevel',\n 'Ethinicity',\n 'Breast_fed',\n 'GlycoHemoglobin',\n 'Anemia'\n    ] ]\ndf_m1.describe()\n#removed drsthepd,drespnd,drabf","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:53:11.788082Z","iopub.execute_input":"2021-07-17T07:53:11.788578Z","iopub.status.idle":"2021-07-17T07:53:12.021698Z","shell.execute_reply.started":"2021-07-17T07:53:11.788529Z","shell.execute_reply":"2021-07-17T07:53:12.020604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Cleaning data**","metadata":{}},{"cell_type":"code","source":"nullv=100*(df_m1.isnull().sum())/(df_m1.shape[0])\n\nvar_allnull=pd.DataFrame({'percentage':nullv})\nprint(var_allnull)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-07-17T07:53:12.023259Z","iopub.execute_input":"2021-07-17T07:53:12.02387Z","iopub.status.idle":"2021-07-17T07:53:12.040298Z","shell.execute_reply.started":"2021-07-17T07:53:12.023824Z","shell.execute_reply":"2021-07-17T07:53:12.039106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Dropping ID column\ndf_m1.drop('ID',\n  axis='columns', inplace=True)\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-17T07:53:12.041558Z","iopub.execute_input":"2021-07-17T07:53:12.041971Z","iopub.status.idle":"2021-07-17T07:53:12.050367Z","shell.execute_reply.started":"2021-07-17T07:53:12.041939Z","shell.execute_reply":"2021-07-17T07:53:12.049436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DATA","metadata":{}},{"cell_type":"code","source":"#Renaming diet variables\n#Renaming required columns\ndf_m1 = df_m1.rename(columns = {\n                            'DRD360':'Fisheaten',\n                            'DR1DRSTZ':'Dietrecalsts',\n                             'DRD370T':'Othefisheaten',\n                             'DRD350G':'Scallopeaten',\n                            'DRD350A':'Clameaten',\n                            'DRD350E':'Musseleaten',\n    'DRD370U':'Othunknfish',\n    'DRD350D':'Lobsteaten',\n    'DRD370C':'Basseaten',\n    'DRD370G':'Haddockeaten',\n    'DRD350C':'Crayfish',\n    'DRD350I':'Shellfish',\n    'DRD350J':'Othshelfis',\n    'DRD350K':'Refshelfdat'\n    \n    \n                           })\n\ndf_m1.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:53:12.051576Z","iopub.execute_input":"2021-07-17T07:53:12.052001Z","iopub.status.idle":"2021-07-17T07:53:12.101488Z","shell.execute_reply.started":"2021-07-17T07:53:12.051961Z","shell.execute_reply":"2021-07-17T07:53:12.10033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_m1.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:53:12.102833Z","iopub.execute_input":"2021-07-17T07:53:12.103143Z","iopub.status.idle":"2021-07-17T07:53:12.266253Z","shell.execute_reply.started":"2021-07-17T07:53:12.103112Z","shell.execute_reply":"2021-07-17T07:53:12.265068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#deopping hemoglobin\nX = df_m1.drop(['Anemia','Hemoglobin'],axis=1)\ny = df_m1[['Anemia']]","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-17T07:53:12.268046Z","iopub.execute_input":"2021-07-17T07:53:12.268527Z","iopub.status.idle":"2021-07-17T07:53:12.279717Z","shell.execute_reply.started":"2021-07-17T07:53:12.268474Z","shell.execute_reply":"2021-07-17T07:53:12.278655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# RFE using Random Forest regressor-Top 30 features","metadata":{}},{"cell_type":"code","source":"#Split the dataset into train and Test\nfrom sklearn.model_selection import train_test_split\n\nseed = 195\ntest_size = 0.3\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:53:12.280965Z","iopub.execute_input":"2021-07-17T07:53:12.281421Z","iopub.status.idle":"2021-07-17T07:53:12.307824Z","shell.execute_reply.started":"2021-07-17T07:53:12.281382Z","shell.execute_reply":"2021-07-17T07:53:12.306962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Init the transformer\nrfe = RFE(estimator=RandomForestRegressor(), n_features_to_select=30)\n\n# Fit to the training data\n_ = rfe.fit(X, y)\nnewvar=X.loc[:, rfe.support_]\n\nnewvar.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:53:12.308979Z","iopub.execute_input":"2021-07-17T07:53:12.30942Z","iopub.status.idle":"2021-07-17T07:55:35.176174Z","shell.execute_reply.started":"2021-07-17T07:53:12.309385Z","shell.execute_reply":"2021-07-17T07:55:35.175201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Adding anemia to top 30 variables\nnewvar[\"Anemia\"] = df_m1[[\"Anemia\"]]\nnewvar.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:55:35.180914Z","iopub.execute_input":"2021-07-17T07:55:35.181271Z","iopub.status.idle":"2021-07-17T07:55:35.321825Z","shell.execute_reply.started":"2021-07-17T07:55:35.181235Z","shell.execute_reply":"2021-07-17T07:55:35.320921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Heat map-Top 30 features**","metadata":{}},{"cell_type":"code","source":"colormap = plt.cm.viridis\nplt.figure(figsize=(20,20))\nsns.heatmap(newvar.astype(float).corr(), linewidths=0.1, vmax=1.0, square=True, cmap=colormap, annot=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:55:35.324382Z","iopub.execute_input":"2021-07-17T07:55:35.324838Z","iopub.status.idle":"2021-07-17T07:55:39.964969Z","shell.execute_reply.started":"2021-07-17T07:55:35.324804Z","shell.execute_reply":"2021-07-17T07:55:39.964113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#deopping hemoglobin\nX = newvar.drop(['Anemia','Weight','Anemia_treatment'],axis=1)\ny = newvar[['Anemia']]","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:55:39.966127Z","iopub.execute_input":"2021-07-17T07:55:39.96656Z","iopub.status.idle":"2021-07-17T07:55:39.975503Z","shell.execute_reply.started":"2021-07-17T07:55:39.966524Z","shell.execute_reply":"2021-07-17T07:55:39.974467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LOGISTIC REGRESSION (Baseline model)","metadata":{}},{"cell_type":"code","source":"#Split the dataset into train and Test\nfrom sklearn.model_selection import train_test_split\n\nseed = 195\ntest_size = 0.3\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-17T07:55:39.976968Z","iopub.execute_input":"2021-07-17T07:55:39.977335Z","iopub.status.idle":"2021-07-17T07:55:40.002624Z","shell.execute_reply.started":"2021-07-17T07:55:39.977297Z","shell.execute_reply":"2021-07-17T07:55:40.001448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, \\\n                            precision_recall_curve, roc_curve, accuracy_score\nfrom sklearn.exceptions import NotFittedError\n\n# instantiate the model (using the default parameters)\nlogreg = LogisticRegression()\n\n# fit the model with data\nlogreg.fit(X_train,y_train)\n\n#\ny_pred=logreg.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:55:40.004199Z","iopub.execute_input":"2021-07-17T07:55:40.00456Z","iopub.status.idle":"2021-07-17T07:55:40.463045Z","shell.execute_reply.started":"2021-07-17T07:55:40.004524Z","shell.execute_reply":"2021-07-17T07:55:40.461777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classification Report-Test dataset\nprint(classification_report(y_test, y_pred\n                                ))","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:55:40.468739Z","iopub.execute_input":"2021-07-17T07:55:40.471673Z","iopub.status.idle":"2021-07-17T07:55:40.518933Z","shell.execute_reply.started":"2021-07-17T07:55:40.471587Z","shell.execute_reply":"2021-07-17T07:55:40.517735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Classification Report-Train dataset\n\nprint(classification_report(y_train, logreg.predict(X_train)))","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:55:40.524308Z","iopub.execute_input":"2021-07-17T07:55:40.527044Z","iopub.status.idle":"2021-07-17T07:55:40.624207Z","shell.execute_reply.started":"2021-07-17T07:55:40.526957Z","shell.execute_reply":"2021-07-17T07:55:40.622927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Confusion matrix**","metadata":{}},{"cell_type":"code","source":"# import the metrics class\nfrom sklearn import metrics\n\n#Confusion matrix\ncnf_matrix = metrics.confusion_matrix(y_test, y_pred)\ncnf_matrix\n\n#Plotting heatmap for cm\nclass_names=[0,1] # name  of classes\nfig, ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\n# create heatmap\nsns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\n\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.rcParams['figure.figsize'] = [5,3]\nplt.show()\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-17T07:55:40.629723Z","iopub.execute_input":"2021-07-17T07:55:40.632685Z","iopub.status.idle":"2021-07-17T07:55:40.891354Z","shell.execute_reply.started":"2021-07-17T07:55:40.632607Z","shell.execute_reply":"2021-07-17T07:55:40.890321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Split the dataset into train and Test\nfrom sklearn.model_selection import train_test_split\n\n\nseed = 195\ntest_size = 0.3\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-17T07:55:40.892835Z","iopub.execute_input":"2021-07-17T07:55:40.893221Z","iopub.status.idle":"2021-07-17T07:55:40.914039Z","shell.execute_reply.started":"2021-07-17T07:55:40.893163Z","shell.execute_reply":"2021-07-17T07:55:40.912857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#scaled_pos_weight-calculation for XGbclassifier for tackling classimbalance\nratio= float(np.sum(y_train == 0)) / np.sum(y_train == 1)\nratio\n","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:55:40.915396Z","iopub.execute_input":"2021-07-17T07:55:40.915869Z","iopub.status.idle":"2021-07-17T07:55:40.926514Z","shell.execute_reply.started":"2021-07-17T07:55:40.915836Z","shell.execute_reply":"2021-07-17T07:55:40.92556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGBClassifier-Optuna","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb\nfrom optuna import create_study, logging\nfrom optuna.pruners import MedianPruner\nfrom optuna.integration import XGBoostPruningCallback\n","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:55:40.92762Z","iopub.execute_input":"2021-07-17T07:55:40.928011Z","iopub.status.idle":"2021-07-17T07:55:40.935996Z","shell.execute_reply.started":"2021-07-17T07:55:40.927981Z","shell.execute_reply":"2021-07-17T07:55:40.934701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import timeit\nimport pickle\nimport sys\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, \\\n                            precision_recall_curve, roc_curve, accuracy_score\nfrom sklearn.exceptions import NotFittedError","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-17T07:55:40.937502Z","iopub.execute_input":"2021-07-17T07:55:40.937807Z","iopub.status.idle":"2021-07-17T07:55:40.950346Z","shell.execute_reply.started":"2021-07-17T07:55:40.937778Z","shell.execute_reply":"2021-07-17T07:55:40.949202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**UTILITY FUNCTIONS**","metadata":{}},{"cell_type":"code","source":"def confusion_plot(matrix, labels=None):\n    \"\"\" Display binary confusion matrix as a Seaborn heatmap \"\"\"\n    \n    labels = labels if labels else ['Negative (0)', 'Positive (1)']\n    \n    fig, ax = plt.subplots(nrows=1, ncols=1)\n    sns.heatmap(data=matrix, cmap='Blues', annot=True, fmt='d',\n                xticklabels=labels, yticklabels=labels, ax=ax)\n    ax.set_xlabel('PREDICTED')\n    ax.set_ylabel('ACTUAL')\n    ax.set_title('Confusion Matrix')\n    plt.close()\n    \n    return fig","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-17T07:55:40.951622Z","iopub.execute_input":"2021-07-17T07:55:40.951988Z","iopub.status.idle":"2021-07-17T07:55:40.963704Z","shell.execute_reply.started":"2021-07-17T07:55:40.951957Z","shell.execute_reply":"2021-07-17T07:55:40.962862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def roc_plot(y_true, y_probs, label, compare=False, ax=None):\n    \"\"\" Plot Receiver Operating Characteristic (ROC) curve \n        Set `compare=True` to use this function to compare classifiers. \"\"\"\n    \n    fpr, tpr, thresh = roc_curve(y_true, y_probs,\n                                 drop_intermediate=False)\n    auc = round(roc_auc_score(y_true, y_probs), 2)\n    \n    fig, axis = (None, ax) if ax else plt.subplots(nrows=1, ncols=1)\n    label = ' '.join([label, f'({auc})']) if compare else None\n    sns.lineplot(x=fpr, y=tpr, ax=axis, label=label)\n    \n    if compare:\n        axis.legend(title='Classifier (AUC)', loc='lower right')\n    else:\n        axis.text(0.72, 0.05, f'AUC = { auc }', fontsize=12,\n                  bbox=dict(facecolor='green', alpha=0.4, pad=5))\n            \n        # Plot No-Info classifier\n        axis.fill_between(fpr, fpr, tpr, alpha=0.3, edgecolor='g',\n                          linestyle='--', linewidth=2)\n        \n    axis.set_xlim(0, 1)\n    axis.set_ylim(0, 1)\n    axis.set_title('ROC Curve')\n    axis.set_xlabel('False Positive Rate [FPR]\\n(1 - Specificity)')\n    axis.set_ylabel('True Positive Rate [TPR]\\n(Sensitivity or Recall)')\n    \n    plt.close()\n    \n    return axis if ax else fig","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-17T07:55:40.965023Z","iopub.execute_input":"2021-07-17T07:55:40.965534Z","iopub.status.idle":"2021-07-17T07:55:40.978592Z","shell.execute_reply.started":"2021-07-17T07:55:40.9655Z","shell.execute_reply":"2021-07-17T07:55:40.977224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def precision_recall_plot(y_true, y_probs, label, compare=False, ax=None):\n    \"\"\" Plot Precision-Recall curve.\n        Set `compare=True` to use this function to compare classifiers. \"\"\"\n    \n    p, r, thresh = precision_recall_curve(y_true, y_probs)\n    p, r, thresh = list(p), list(r), list(thresh)\n    p.pop()\n    r.pop()\n    \n    fig, axis = (None, ax) if ax else plt.subplots(nrows=1, ncols=1)\n    \n    if compare:\n        sns.lineplot(r, p, ax=axis, label=label)\n        axis.set_xlabel('Recall')\n        axis.set_ylabel('Precision')\n        axis.legend(loc='lower left')\n    else:\n        sns.lineplot(thresh, p, label='Precision', ax=axis)\n        axis.set_xlabel('Threshold')\n        axis.set_ylabel('Precision')\n        axis.legend(loc='lower left')\n\n        axis_twin = axis.twinx()\n        sns.lineplot(thresh, r, color='limegreen', label='Recall', ax=axis_twin)\n        axis_twin.set_ylabel('Recall')\n        axis_twin.set_ylim(0, 1)\n        axis_twin.legend(bbox_to_anchor=(0.24, 0.18))\n    \n    axis.set_xlim(0, 1)\n    axis.set_ylim(0, 1)\n    axis.set_title('Precision Vs Recall')\n    \n    plt.close()\n    return axis if ax else fig    ","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-17T07:55:40.980363Z","iopub.execute_input":"2021-07-17T07:55:40.981099Z","iopub.status.idle":"2021-07-17T07:55:40.996431Z","shell.execute_reply.started":"2021-07-17T07:55:40.981051Z","shell.execute_reply":"2021-07-17T07:55:40.995384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_clf(clf, x_train, y_train, sample_weight=None, refit=False):\n    train_time = 0\n    \n    try:\n        if refit:\n            raise NotFittedError\n        y_pred_train = clf.predict(x_train)\n    except NotFittedError:\n        start = timeit.default_timer()\n        \n        if sample_weight is not None:\n            clf.fit(x_train, y_train, sample_weight=sample_weight)\n        else:\n            clf.fit(x_train, y_train)\n        \n        end = timeit.default_timer()\n        train_time = end - start\n        \n        y_pred_train = clf.predict(x_train)\n    \n    train_acc = accuracy_score(y_train, y_pred_train)\n    return clf, y_pred_train, train_acc, train_time","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-17T07:55:40.998108Z","iopub.execute_input":"2021-07-17T07:55:40.998625Z","iopub.status.idle":"2021-07-17T07:55:41.014176Z","shell.execute_reply.started":"2021-07-17T07:55:40.998578Z","shell.execute_reply":"2021-07-17T07:55:41.013076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def feature_importance_plot(importances, feature_labels, ax=None):\n    fig, axis = (None, ax) if ax else plt.subplots(nrows=1, ncols=1, figsize=(5, 10))\n    sns.barplot(x=importances, y=feature_labels, ax=axis)\n    axis.set_title('Feature Importance Measures')\n    \n    plt.close()\n    \n    return axis if ax else fig\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-17T07:55:41.015456Z","iopub.execute_input":"2021-07-17T07:55:41.015736Z","iopub.status.idle":"2021-07-17T07:55:41.027994Z","shell.execute_reply.started":"2021-07-17T07:55:41.015708Z","shell.execute_reply":"2021-07-17T07:55:41.026708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_memory_size(clf):\n    return sys.getsizeof(pickle.dumps(clf))\ndef report(clf, x_train, y_train, x_test, y_test, display_scores=[],\n           sample_weight=None, refit=False, importance_plot=False,\n           confusion_labels=None, feature_labels=None, verbose=True):\n    \"\"\" Trains the passed classifier if not already trained and reports\n        various metrics of the trained classifier \"\"\"\n    \n    dump = dict()\n    \n    ## Train if not already trained\n    clf, train_predictions, \\\n    train_acc, train_time = train_clf(clf, x_train, y_train,\n                                      sample_weight=sample_weight,\n                                      refit=refit)\n    ## Testing\n    start = timeit.default_timer()\n    test_predictions = clf.predict(x_test)\n    end = timeit.default_timer()\n    test_time = end - start\n    \n    test_acc = accuracy_score(y_test, test_predictions)\n    y_probs = clf.predict_proba(x_test)[:, 1]\n    \n    roc_auc = roc_auc_score(y_test, y_probs)\n    ## Additional scores\n    scores_dict = dict()\n    for func in display_scores:\n        scores_dict[func.__name__] = [func(y_train, train_predictions),\n                                      func(y_test, test_predictions)]\n        \n    ## Model Memory\n    model_mem = round(model_memory_size(clf) / 1024, 2)\n    \n    print(clf)\n    print(\"\\n=============================> TRAIN-TEST DETAILS <======================================\")\n    \n    ## Metrics\n    print(f\"Train Size: {x_train.shape[0]} samples\")\n    print(f\" Test Size: {x_test.shape[0]} samples\")\n    print(\"---------------------------------------------\")\n    print(f\"Training Time: {round(train_time, 3)} seconds\")\n    print(f\" Testing Time: {round(test_time, 3)} seconds\")\n    print(\"---------------------------------------------\")\n    print(\"Train Accuracy: \", train_acc)\n    print(\" Test Accuracy: \", test_acc)\n    print(\"---------------------------------------------\")\n    \n    if display_scores:\n        for k, v in scores_dict.items():\n            score_name = ' '.join(map(lambda x: x.title(), k.split('_')))\n            print(f'Train {score_name}: ', v[0])\n            print(f' Test {score_name}: ', v[1])\n            print()\n        print(\"---------------------------------------------\") \n    print(\" Area Under ROC (test): \", roc_auc)\n    print(\"---------------------------------------------\")\n    print(f\"Model Memory Size: {model_mem} kB\")\n    print(\"\\n=============================> CLASSIFICATION REPORT <===================================\")\n    \n    ## Classification Report\n    clf_rep = classification_report(y_test, test_predictions, output_dict=True)\n    \n    print(classification_report(y_test, test_predictions,\n                                target_names=confusion_labels))\n    \n    \n    if verbose:\n        print(\"\\n================================> CONFUSION MATRIX <=====================================\")\n    \n        ## Confusion Matrix HeatMap\n        display(confusion_plot(confusion_matrix(y_test, test_predictions),\n                               labels=confusion_labels))\n        print(\"\\n=======================================> PLOTS <=========================================\")\n\n\n        ## Variable importance plot\n        fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(14, 10))\n        roc_axes = axes[0, 0]\n        pr_axes = axes[0, 1]\n        importances = None\n\n        if importance_plot:\n            if not feature_labels:\n                raise RuntimeError(\"'feature_labels' argument not passed \"\n                                   \"when 'importance_plot' is True\")\n\n            try:\n                importances = pd.Series(clf.feature_importances_,\n                                        index=feature_labels) \\\n                                .sort_values(ascending=False)\n            except AttributeError:\n                try:\n                    importances = pd.Series(clf.coef_.ravel(),\n                                            index=feature_labels) \\\n                                    .sort_values(ascending=False)\n                except AttributeError:\n                    pass\n\n            if importances is not None:\n                # Modifying grid\n                grid_spec = axes[0, 0].get_gridspec()\n                for ax in axes[:, 0]:\n                    ax.remove()   # remove first column axes\n                large_axs = fig.add_subplot(grid_spec[0:, 0])\n\n                # Plot importance curve\n                feature_importance_plot(importances=importances.values,\n                                        feature_labels=importances.index,\n                                        ax=large_axs)\n                large_axs.axvline(x=0)\n\n                # Axis for ROC and PR curve\n                roc_axes = axes[0, 1]\n                pr_axes = axes[1, 1]\n            else:\n                # remove second row axes\n                for ax in axes[1, :]:\n                    ax.remove()\n        else:\n            # remove second row axes\n            for ax in axes[1, :]:\n                ax.remove()\n\n\n        ## ROC and Precision-Recall curves\n        clf_name = clf.__class__.__name__\n        roc_plot(y_test, y_probs, clf_name, ax=roc_axes)\n        precision_recall_plot(y_test, y_probs, clf_name, ax=pr_axes)\n\n        fig.subplots_adjust(wspace=5)\n        fig.tight_layout()\n        display(fig)\n    \n    ## Dump to report_dict\n    dump = dict(clf=clf, accuracy=[train_acc, test_acc], **scores_dict,\n                train_time=train_time, train_predictions=train_predictions,\n                test_time=test_time, test_predictions=test_predictions,\n                test_probs=y_probs, report=clf_rep, roc_auc=roc_auc,\n                model_memory=model_mem)\n    \n    return clf, dump","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-17T07:55:41.029466Z","iopub.execute_input":"2021-07-17T07:55:41.029762Z","iopub.status.idle":"2021-07-17T07:55:41.055299Z","shell.execute_reply.started":"2021-07-17T07:55:41.029734Z","shell.execute_reply":"2021-07-17T07:55:41.054502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Main code-model tuning using optuna","metadata":{}},{"cell_type":"code","source":"#Dropping features not useful for analysis\nX = newvar.drop(['Anemia','Weight','Anemia_treatment'],axis=1)\ny = newvar[['Anemia']]","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-17T07:55:41.056397Z","iopub.execute_input":"2021-07-17T07:55:41.056795Z","iopub.status.idle":"2021-07-17T07:55:41.079487Z","shell.execute_reply.started":"2021-07-17T07:55:41.056764Z","shell.execute_reply":"2021-07-17T07:55:41.078413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport xgboost as xgb\nfrom optuna import create_study, logging\nfrom optuna.pruners import MedianPruner\nfrom optuna.integration import XGBoostPruningCallback\nfrom xgboost import XGBClassifier\nfrom sklearn.utils import class_weight\nfrom sklearn import metrics\n\nfrom sklearn.model_selection import train_test_split\n#deopping hemoglobin\n\ndata_splits = train_test_split(X, y, test_size=0.3, random_state=123,\n                               shuffle=True, stratify=y)\nx_train, x_test, y_train, y_test = data_splits\ndef objective(trial, X, y, group, score, params=dict()):\n    dtrain = xgb.DMatrix(X, label=y)\n    class_weight = (y.shape[0] - np.sum(y)) / np.sum(y)\n    \n    ## Initial Learning Parameters\n    params['learning_rate'] = 0.1\n    params['num_boost_round'] = 1000\n\n    if group == '1':\n        params['max_depth'] = trial.suggest_int('max_depth', 2, 15)\n        params['min_child_weight'] = trial.suggest_loguniform('min_child_weight',\n                                                              1e-10, 1e10)\n        params['n_estimators']=trial.suggest_int('n_estimators',500,1000)\n        params['scale_pos_weight']=trial.suggest_float('scale_pos_weight',3.5,5)\n    \n    if group == '2':\n        params['min_samples_split']=trial.suggest_int('min_samples_split',5,10)\n        params['subsample'] = trial.suggest_uniform('subsample', 0, 1)\n        params['colsample_bytree'] = trial.suggest_uniform('colsample_bytree', 0, 1)\n    \n    if group == '3':\n        params['learning_rate'] = trial.suggest_uniform('learning_rate', 0, 0.1)\n        params['num_boost_round'] = trial.suggest_int('num_boost_round', 100, 1000)\n\n    pruning_callback = XGBoostPruningCallback(trial, \"test-\" + score.__name__)\n    cv_scores = xgb.cv(params, dtrain, nfold=5,\n                       stratified=True,\n                       feval=score,\n                       early_stopping_rounds=10,\n                       callbacks=[pruning_callback],\n                       seed=0)\n\n    return cv_scores['test-' + score.__name__ + '-mean'].values[-1]\ndef execute_optimization(study_name, group, score, trials,\n                         params=dict(), direction='maximize'):\n    logging.set_verbosity(logging.ERROR)\n    \n    ## We use pruner to skip trials that are NOT fruitful\n    pruner = MedianPruner(n_warmup_steps=5)\n    \n    study = create_study(direction=direction,\n                         study_name=study_name,\n                         storage='sqlite:///optuna.db',\n                         load_if_exists=True,\n                         pruner=pruner)\n\n    study.optimize(lambda trial: objective(trial, x_train, y_train,\n                                           group, score, params),\n                   n_trials=trials,\n                   n_jobs=-1)\n    \n    \n    print(\"STUDY NAME: \", study_name)\n    print('------------------------------------------------')\n    print(\"EVALUATION METRIC: \", score.__name__)\n    print('------------------------------------------------')\n    print(\"BEST CV SCORE\", study.best_value)\n    print('------------------------------------------------')\n    print(f\"OPTIMAL GROUP - {group} PARAMS: \", study.best_params)\n    print('------------------------------------------------')\n    print(\"BEST TRIAL\", study.best_trial)\n    print('------------------------------------------------')\n    \n    \n    return study.best_params\n","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:55:41.080898Z","iopub.execute_input":"2021-07-17T07:55:41.081235Z","iopub.status.idle":"2021-07-17T07:55:41.29099Z","shell.execute_reply.started":"2021-07-17T07:55:41.081201Z","shell.execute_reply":"2021-07-17T07:55:41.289693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score_func = metrics.f1_score\ndef score_function(y_pred, dtrain):\n    y_pred = (y_pred > 0.5).astype(int)\n    y_true = (dtrain.get_label() > 0.5).astype(int)\n    return score_func.__name__, score_func(y_true, y_pred)\n\nscore_function.__name__ = score_func.__name__","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-17T07:55:41.292315Z","iopub.execute_input":"2021-07-17T07:55:41.292684Z","iopub.status.idle":"2021-07-17T07:55:41.298304Z","shell.execute_reply.started":"2021-07-17T07:55:41.292649Z","shell.execute_reply":"2021-07-17T07:55:41.297216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params1={'learning_rate': 0.02578297296713958,\n 'num_boost_round': 585,\n 'objective': 'binary:logistic',\n 'max_depth': 7,\n 'min_child_weight': 18.93704847111416,\n 'n_estimators': 754,\n         'min_samples_split': 9,\n 'scale_pos_weight': 3.425510435559797,\n 'subsample': 0.505407237617943,\n 'colsample_bytree': 0.5538227649946694}","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:55:41.299874Z","iopub.execute_input":"2021-07-17T07:55:41.300207Z","iopub.status.idle":"2021-07-17T07:55:41.314208Z","shell.execute_reply.started":"2021-07-17T07:55:41.300171Z","shell.execute_reply":"2021-07-17T07:55:41.313085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"primary_eval_metric = metrics.f1_score\nn=list(x_train.columns)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:55:41.315998Z","iopub.execute_input":"2021-07-17T07:55:41.316468Z","iopub.status.idle":"2021-07-17T07:55:41.330808Z","shell.execute_reply.started":"2021-07-17T07:55:41.316417Z","shell.execute_reply":"2021-07-17T07:55:41.329597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Tuning model with parameters\nxgb_clf_tuned_1 = XGBClassifier(**params1, \n                                random_state=45, n_jobs=-1)\nxgb_clf_tuned_1.fit(x_train, y_train);\nxgb_clf_tuned_1, xgb_report_tuned_1 = report(xgb_clf_tuned_1, x_train, y_train,\n                                             x_test, y_test,\n                                             display_scores=[primary_eval_metric],\n                                             importance_plot=True,\n                                             feature_labels=n\n                                             )","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:55:41.332376Z","iopub.execute_input":"2021-07-17T07:55:41.332717Z","iopub.status.idle":"2021-07-17T07:56:26.06549Z","shell.execute_reply.started":"2021-07-17T07:55:41.332686Z","shell.execute_reply":"2021-07-17T07:56:26.064405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    ## Classification Report-Test dataset\n    c=xgb_clf_tuned_1.fit(x_train, y_train);\n    test_predictions = c.predict(x_test)\n    print(classification_report(y_test, test_predictions\n                                ))","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:56:26.066849Z","iopub.execute_input":"2021-07-17T07:56:26.067167Z","iopub.status.idle":"2021-07-17T07:56:35.878704Z","shell.execute_reply.started":"2021-07-17T07:56:26.067136Z","shell.execute_reply":"2021-07-17T07:56:35.877496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Classification Report-Train dataset**","metadata":{}},{"cell_type":"code","source":"\nprint(classification_report(y_train, c.predict(x_train)))","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:56:35.880529Z","iopub.execute_input":"2021-07-17T07:56:35.880961Z","iopub.status.idle":"2021-07-17T07:56:36.136528Z","shell.execute_reply.started":"2021-07-17T07:56:35.880915Z","shell.execute_reply":"2021-07-17T07:56:36.134678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SHAP","metadata":{}},{"cell_type":"code","source":"import shap\nimport xgboost\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pylab as pl","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:56:36.139431Z","iopub.execute_input":"2021-07-17T07:56:36.13981Z","iopub.status.idle":"2021-07-17T07:56:36.144397Z","shell.execute_reply.started":"2021-07-17T07:56:36.139773Z","shell.execute_reply":"2021-07-17T07:56:36.143178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#deopping hemoglobin\nX = df_m1.drop(['Anemia','Hemoglobin','Anemia_treatment'],axis=1)\ny = df_m1[['Anemia']]","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:56:36.145804Z","iopub.execute_input":"2021-07-17T07:56:36.146117Z","iopub.status.idle":"2021-07-17T07:56:36.16374Z","shell.execute_reply.started":"2021-07-17T07:56:36.146086Z","shell.execute_reply":"2021-07-17T07:56:36.162687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap_values = shap.TreeExplainer(xgb_clf_tuned_1).shap_values(x_train)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:56:36.165052Z","iopub.execute_input":"2021-07-17T07:56:36.165536Z","iopub.status.idle":"2021-07-17T07:57:36.128703Z","shell.execute_reply.started":"2021-07-17T07:56:36.165494Z","shell.execute_reply":"2021-07-17T07:57:36.127533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Summary Plot","metadata":{}},{"cell_type":"code","source":"shap.summary_plot(shap_values, x_train)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:57:36.134138Z","iopub.execute_input":"2021-07-17T07:57:36.134883Z","iopub.status.idle":"2021-07-17T07:57:41.562263Z","shell.execute_reply.started":"2021-07-17T07:57:36.134824Z","shell.execute_reply":"2021-07-17T07:57:41.561204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dependence plot -Top features","metadata":{}},{"cell_type":"code","source":"shap.dependence_plot(\"GlycoHemoglobin\", shap_values, x_train,interaction_index=None)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:57:41.563768Z","iopub.execute_input":"2021-07-17T07:57:41.564108Z","iopub.status.idle":"2021-07-17T07:57:41.7638Z","shell.execute_reply.started":"2021-07-17T07:57:41.564072Z","shell.execute_reply":"2021-07-17T07:57:41.762642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.dependence_plot(\"Gender\", shap_values, x_train,interaction_index=None)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:57:41.764982Z","iopub.execute_input":"2021-07-17T07:57:41.765278Z","iopub.status.idle":"2021-07-17T07:57:42.545171Z","shell.execute_reply.started":"2021-07-17T07:57:41.765248Z","shell.execute_reply":"2021-07-17T07:57:42.544054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.dependence_plot(\"Age\", shap_values, x_train,interaction_index=None)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:57:42.546461Z","iopub.execute_input":"2021-07-17T07:57:42.546774Z","iopub.status.idle":"2021-07-17T07:57:42.740543Z","shell.execute_reply.started":"2021-07-17T07:57:42.546744Z","shell.execute_reply":"2021-07-17T07:57:42.739265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.dependence_plot(\"BMI\", shap_values, x_train,interaction_index=None)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:57:42.742244Z","iopub.execute_input":"2021-07-17T07:57:42.742711Z","iopub.status.idle":"2021-07-17T07:57:42.914871Z","shell.execute_reply.started":"2021-07-17T07:57:42.74266Z","shell.execute_reply":"2021-07-17T07:57:42.913639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.dependence_plot(\"Fisheaten\", shap_values, x_train,interaction_index=None)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:57:42.916686Z","iopub.execute_input":"2021-07-17T07:57:42.917011Z","iopub.status.idle":"2021-07-17T07:57:43.125095Z","shell.execute_reply.started":"2021-07-17T07:57:42.916978Z","shell.execute_reply":"2021-07-17T07:57:43.123819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.dependence_plot(\"Dietrecalsts\", shap_values, x_train,interaction_index=None)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:57:43.126793Z","iopub.execute_input":"2021-07-17T07:57:43.127125Z","iopub.status.idle":"2021-07-17T07:57:43.329447Z","shell.execute_reply.started":"2021-07-17T07:57:43.127093Z","shell.execute_reply":"2021-07-17T07:57:43.328567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LIGHTGBM","metadata":{}},{"cell_type":"code","source":"import scipy\nimport scipy.stats\nfrom scipy import stats","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-17T07:57:43.330951Z","iopub.execute_input":"2021-07-17T07:57:43.331619Z","iopub.status.idle":"2021-07-17T07:57:43.33655Z","shell.execute_reply.started":"2021-07-17T07:57:43.331568Z","shell.execute_reply":"2021-07-17T07:57:43.335468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nimport gc\nseed = 195\ntest_size = 0.3\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)\nevals = {}\nevals['lgb'] = {}\nlparams = {}\nseeds = [0, 1]\nnfold = [5, 5]\nstratified=[False, False]\nshuffle=[True, True]\nn_estimators = 30000\nearly_stopping_rounds = 300\nverbose_eval = 0\nlearning_rate = 0.01\nreg_alpha = [0.4, 1]\nreg_lambda = [0.7, 1]\nsubsample = [0.45, 1]\ncolsample_bytree = [0.3, 0.225]\nmax_depth = -1\nverbose = -1\nn_jobs = 4\nlparams[0] = dict(boosting_type='gbdt',\n               objective='binary',\n               metric='auc',\n               learning_rate= learning_rate,\n               num_leaves= 200,\n               max_bin=500,\n               min_child_weight= 0.035,\n               subsample= subsample[0],\n               colsample_bytree= colsample_bytree[0],\n               min_data_in_leaf= 150,\n               max_depth= max_depth,\n               bagging_seed= seeds[0],\n               reg_alpha= reg_alpha[0],\n               reg_lambda= reg_lambda[0],\n               verbose= verbose,\n               seed= seeds[0],\n               n_jobs= n_jobs,)\nlparams[1] = dict(boosting_type='gbdt',\n               objective='binary',\n               metric='auc',\n               learning_rate= learning_rate,\n               n_estimators= n_estimators,\n               subsample= subsample[1],\n               colsample_bytree= colsample_bytree[1],\n               max_depth= max_depth,\n               bagging_seed= seeds[1],\n               reg_alpha= reg_alpha[1],\n               reg_lambda= reg_lambda[1],\n               verbose= verbose,\n               seed= seeds[1],\n               n_jobs= n_jobs,)\ntest_preds = np.zeros(len(X_test))    \ndtrain = lgb.Dataset(X_train, y_train)\ndtest = X_test.copy()\ntestlen = X_test.shape[0]\n\ngc.collect()\nfor i, seed in enumerate(seeds):\n    print(f'Training Model with SEED : {seed}')\n    evals['lgb'][i] = lgb.cv(lparams[i],\n                             dtrain,\n                             nfold=nfold[i], \n                             stratified=stratified[i],\n                             shuffle=shuffle[i],\n                             num_boost_round=n_estimators,\n                             early_stopping_rounds=early_stopping_rounds,\n                             verbose_eval=verbose_eval,\n                             return_cvbooster=True,\n                             seed = seed,\n                             show_stdv=True)\n    \n                  \n#     filename = 'lgb_'+ i+'_.sav'\n#     pickle.dump(evals['lgb'][i], open(filename, 'wb'))\n    print(f'SEED {i} Average fold  AUC {np.round(max(evals[\"lgb\"][i][\"auc-mean\"]),5)}')\n    \n    \n    test_preds += stats.rankdata(np.mean(evals['lgb'][i]['cvbooster'].predict(dtest, num_iteration=evals['lgb'][i]['cvbooster'].best_iteration), axis=0)) / (testlen * len(seeds))\n    ","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:57:43.338106Z","iopub.execute_input":"2021-07-17T07:57:43.338781Z","iopub.status.idle":"2021-07-17T07:58:18.108381Z","shell.execute_reply.started":"2021-07-17T07:57:43.338724Z","shell.execute_reply":"2021-07-17T07:58:18.107434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**LIGHTGBM RESULTS**","metadata":{}},{"cell_type":"code","source":"Model= lgb.train(params=lparams[1],train_set=dtrain)\n\n#prediction and Classification Report\nfrom sklearn.metrics import classification_report\n\npred = Model.predict(X_test)\npred_labels = np.rint(pred)\n   \nmean_accuracy=sklearn.metrics.accuracy_score(y_test, pred_labels),\n\nprint( (classification_report(y_test, pred_labels)))","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:58:18.109788Z","iopub.execute_input":"2021-07-17T07:58:18.11032Z","iopub.status.idle":"2021-07-17T07:59:32.989877Z","shell.execute_reply.started":"2021-07-17T07:58:18.11027Z","shell.execute_reply":"2021-07-17T07:59:32.988765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nauc_score1 = roc_auc_score(y_test, pred_labels)\nauc_score1","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:59:32.991397Z","iopub.execute_input":"2021-07-17T07:59:32.991723Z","iopub.status.idle":"2021-07-17T07:59:33.005121Z","shell.execute_reply.started":"2021-07-17T07:59:32.991687Z","shell.execute_reply":"2021-07-17T07:59:33.004009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGBClassifier with K-fold cross validation","metadata":{}},{"cell_type":"code","source":"model1=xgb.XGBClassifier(\n learning_rate =0.1,\n n_estimators=500,\n max_depth=6,\n min_child_weight=1,\n gamma=0,\n subsample=0.8,\n colsample_bytree=0.8,\n objective= 'binary:logistic',\n scale_pos_weight=4.747735,\n seed=27,eval_metric=\"error\")\ntrain_model = model1.fit(X_train, y_train,eval_metric=\"error\",verbose=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:59:33.006735Z","iopub.execute_input":"2021-07-17T07:59:33.007042Z","iopub.status.idle":"2021-07-17T07:59:41.991704Z","shell.execute_reply.started":"2021-07-17T07:59:33.00701Z","shell.execute_reply":"2021-07-17T07:59:41.99052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# stratified k-fold cross validation evaluation of xgboost model\nfrom numpy import loadtxt\nimport xgboost\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_val_score\n\n# CV model\nkfold = StratifiedKFold(n_splits=5)\nresults = cross_val_score(model1, X, y, cv=kfold)\nprint(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:59:41.995252Z","iopub.execute_input":"2021-07-17T07:59:41.995648Z","iopub.status.idle":"2021-07-17T08:00:35.777275Z","shell.execute_reply.started":"2021-07-17T07:59:41.995612Z","shell.execute_reply":"2021-07-17T08:00:35.776121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import XGBoost\nimport xgboost as xgb\n\n\n# define data_dmatrix\ndata_dmatrix = xgb.DMatrix(data=X,label=y)\nfrom xgboost import cv\n\nparams = {'learning_rate':0.1,\n 'n_estimators':500,\n 'max_depth':6,\n 'min_child_weight':1,\n 'gamma':0,\n 'subsample':0.8,\n 'colsample_bytree':0.8,\n 'objective': 'binary:logistic',\n 'scale_pos_weight':4.747735,\n 'seed':27}\n\nxgb_cv = cv(dtrain=data_dmatrix, params=params, nfold=5,num_boost_round=5,\n                     metrics=\"error\", as_pandas=True, seed=123)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T08:00:35.778843Z","iopub.execute_input":"2021-07-17T08:00:35.779213Z","iopub.status.idle":"2021-07-17T08:00:36.506114Z","shell.execute_reply.started":"2021-07-17T08:00:35.779178Z","shell.execute_reply":"2021-07-17T08:00:36.504964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(((1-xgb_cv[\"test-error-mean\"]).iloc[-1]))\n","metadata":{"execution":{"iopub.status.busy":"2021-07-17T08:00:36.508092Z","iopub.execute_input":"2021-07-17T08:00:36.508538Z","iopub.status.idle":"2021-07-17T08:00:36.516167Z","shell.execute_reply.started":"2021-07-17T08:00:36.508488Z","shell.execute_reply":"2021-07-17T08:00:36.515075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_cv.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T08:00:36.518065Z","iopub.execute_input":"2021-07-17T08:00:36.518821Z","iopub.status.idle":"2021-07-17T08:00:36.535951Z","shell.execute_reply.started":"2021-07-17T08:00:36.518768Z","shell.execute_reply":"2021-07-17T08:00:36.534716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGBClassifier","metadata":{}},{"cell_type":"code","source":"model1=xgb.XGBClassifier(\n learning_rate =0.1,\n n_estimators=500,\n max_depth=6,\n min_child_weight=1,\n gamma=0,\n subsample=0.8,\n colsample_bytree=0.8,\n objective= 'binary:logistic',\n scale_pos_weight=4.747735,\n seed=27,eval_metric=\"error\")\ntrain_model = model1.fit(X_train, y_train,eval_metric=\"error\",verbose=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T08:00:36.543379Z","iopub.execute_input":"2021-07-17T08:00:36.543797Z","iopub.status.idle":"2021-07-17T08:00:45.659675Z","shell.execute_reply.started":"2021-07-17T08:00:36.543759Z","shell.execute_reply":"2021-07-17T08:00:45.658373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#prediction and Classification Report-On test dataset\nfrom sklearn.metrics import classification_report\n\npred = train_model.predict(X_test)\n\nprint( (classification_report(y_test, pred)))","metadata":{"execution":{"iopub.status.busy":"2021-07-17T08:00:45.663797Z","iopub.execute_input":"2021-07-17T08:00:45.664207Z","iopub.status.idle":"2021-07-17T08:00:45.748929Z","shell.execute_reply.started":"2021-07-17T08:00:45.664171Z","shell.execute_reply":"2021-07-17T08:00:45.747776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#prediction and Classification Report-On train dataset\nprint(classification_report(y_train, train_model.predict(X_train)))","metadata":{"execution":{"iopub.status.busy":"2021-07-17T08:00:45.750492Z","iopub.execute_input":"2021-07-17T08:00:45.750831Z","iopub.status.idle":"2021-07-17T08:00:45.925562Z","shell.execute_reply.started":"2021-07-17T08:00:45.750798Z","shell.execute_reply":"2021-07-17T08:00:45.924189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nprint('Accuracy: {0:.2f}'.format(accuracy_score(y_test, pred)))\n#print('Precision: {0:.2f}'.format(precision_score(y_test, pred)))\n#print('Recall: {0:.2f}'.format(recall_score(y_test, pred)))\n#print('AUC ROC: {0:.2f}'.format(roc_auc_score(y_test, pred)))","metadata":{"execution":{"iopub.status.busy":"2021-07-17T08:00:45.926965Z","iopub.execute_input":"2021-07-17T08:00:45.927327Z","iopub.status.idle":"2021-07-17T08:00:45.934899Z","shell.execute_reply.started":"2021-07-17T08:00:45.92729Z","shell.execute_reply":"2021-07-17T08:00:45.933764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**FEATURE IMPORTANCE PLOT**","metadata":{}},{"cell_type":"code","source":"xgb.plot_importance(train_model)\nplt.rcParams['figure.figsize'] = [15,9]\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T08:00:45.936373Z","iopub.execute_input":"2021-07-17T08:00:45.936792Z","iopub.status.idle":"2021-07-17T08:00:46.729061Z","shell.execute_reply.started":"2021-07-17T08:00:45.93675Z","shell.execute_reply":"2021-07-17T08:00:46.727828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# RANDOM FOREST CLASSIFIER","metadata":{}},{"cell_type":"code","source":"#Random forest classifier-To select parameters,curves are plotted\n# import Random Forest classifier\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import roc_curve, auc\n\n\nn_estimators = [1, 2, 4, 8, 16, 32, 64, 100, 200,500,1000]\ntrain_results = []\ntest_results = []\nfor estimator in n_estimators:\n   rf = RandomForestClassifier(n_estimators=estimator, n_jobs=-1)\n   rf.fit(X_train, y_train)\n   train_pred = rf.predict(X_train)\n   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n   roc_auc = auc(false_positive_rate, true_positive_rate)\n   train_results.append(roc_auc)\n   y_pred = rf.predict(X_test)\n   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n   roc_auc = auc(false_positive_rate, true_positive_rate)\n   test_results.append(roc_auc)\n    \nfrom matplotlib.legend_handler import HandlerLine2D\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nline1, = plt.plot(n_estimators, train_results, \"b\", label=\"Train AUC\")\nline2, = plt.plot(n_estimators, test_results, \"r\", label=\"Test AUC\")\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\nplt.ylabel(\"AUC score\")\nplt.xlabel(\"n_estimators\")\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-17T08:00:46.73111Z","iopub.execute_input":"2021-07-17T08:00:46.731586Z","iopub.status.idle":"2021-07-17T08:01:19.959061Z","shell.execute_reply.started":"2021-07-17T08:00:46.731534Z","shell.execute_reply":"2021-07-17T08:01:19.957813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_depths = np.linspace(1, 32, 32, endpoint=True)\ntrain_results = []\ntest_results = []\nfor max_depth in max_depths:\n   rf = RandomForestClassifier(max_depth=max_depth, n_jobs=-1)\n   rf.fit(X_train, y_train)\n   train_pred = rf.predict(X_train)\n   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n   roc_auc = auc(false_positive_rate, true_positive_rate)\n   train_results.append(roc_auc)\n   y_pred = rf.predict(X_test)\n   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n   roc_auc = auc(false_positive_rate, true_positive_rate)\n   test_results.append(roc_auc)\nfrom matplotlib.legend_handler import HandlerLine2D\nline1, = plt.plot(max_depths, train_results, \"b\", label=\"Train AUC\")\nline2, = plt.plot(max_depths, test_results, \"r\", label=\"Test AUC\" )\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\nplt.ylabel(\"AUC score\")\nplt.xlabel(\"Tree depth\")\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-17T08:01:19.960498Z","iopub.execute_input":"2021-07-17T08:01:19.960829Z","iopub.status.idle":"2021-07-17T08:02:04.210044Z","shell.execute_reply.started":"2021-07-17T08:01:19.960797Z","shell.execute_reply":"2021-07-17T08:02:04.20894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"min_samples_leafs = np.linspace(0.1,  0.5,50 ,endpoint=True)\ntrain_results = []\ntest_results = []\nfor min_samples_leaf in min_samples_leafs:\n   rf = RandomForestClassifier(min_samples_leaf=min_samples_leaf)\n   rf.fit(X_train, y_train)\n   train_pred = rf.predict(X_train)\n   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n   roc_auc = auc(false_positive_rate, true_positive_rate)\n   train_results.append(roc_auc)\n   y_pred = rf.predict(X_test)\n   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n   roc_auc = auc(false_positive_rate, true_positive_rate)\n   test_results.append(roc_auc)\nfrom matplotlib.legend_handler import HandlerLine2D\nline1, = plt.plot(min_samples_leafs, train_results,\"b\",label=\"Train AUC\")\nline2, = plt.plot(min_samples_leafs, test_results, \"r\", label=\"Test AUC\")\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\nplt.ylabel(\"AUC score\")\nplt.xlabel(\"min samples leaf\")\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-17T08:02:04.211736Z","iopub.execute_input":"2021-07-17T08:02:04.212189Z","iopub.status.idle":"2021-07-17T08:02:36.895771Z","shell.execute_reply.started":"2021-07-17T08:02:04.212151Z","shell.execute_reply":"2021-07-17T08:02:36.894823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model\n\n\nfrom sklearn.ensemble import RandomForestClassifier\n#Split the dataset into train and Test\nfrom sklearn.model_selection import train_test_split\n\nseed = 195\ntest_size = 0.3\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)\n\n\n# instantiate the classifier \n\nrfc = RandomForestClassifier(class_weight=\"balanced\", n_estimators=500, min_samples_leaf=50, max_depth=7)\n\n\n\n# fit the model\n\nrfc.fit(X_train, y_train)\n\n\n\n# Predict the Test set results\n\ny_pred = rfc.predict(X_test)\n\n\n\n# Check accuracy score \n\nfrom sklearn.metrics import accuracy_score\n\nprint('Model accuracy score with  decision-trees : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n","metadata":{"execution":{"iopub.status.busy":"2021-07-17T08:02:36.897249Z","iopub.execute_input":"2021-07-17T08:02:36.897842Z","iopub.status.idle":"2021-07-17T08:02:43.670244Z","shell.execute_reply.started":"2021-07-17T08:02:36.897801Z","shell.execute_reply":"2021-07-17T08:02:43.669184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Random forest classifier results**","metadata":{}},{"cell_type":"code","source":"#prediction and Classification Report\nfrom sklearn.metrics import classification_report\n\npred = rfc.predict(X_test)\n\nprint( (classification_report(y_test, y_pred)))","metadata":{"execution":{"iopub.status.busy":"2021-07-17T08:02:43.671764Z","iopub.execute_input":"2021-07-17T08:02:43.672432Z","iopub.status.idle":"2021-07-17T08:02:44.11623Z","shell.execute_reply.started":"2021-07-17T08:02:43.672335Z","shell.execute_reply":"2021-07-17T08:02:44.115163Z"},"trusted":true},"execution_count":null,"outputs":[]}]}