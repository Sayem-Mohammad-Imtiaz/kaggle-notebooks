{"cells":[{"metadata":{},"cell_type":"markdown","source":"# <center><u>German Credit Data Set</u></center>"},{"metadata":{},"cell_type":"markdown","source":"Note: Class imbalance has been solved using Stratified CV which is mentioned in when we performed CV."},{"metadata":{},"cell_type":"raw","source":"Contents\n\n1.\tImporting Libraries\n2.\tLoading Data\n3.\tData Description\n4.\tData Quality Assessment and Statitical Analysis\n5.\tUnivariate Analysis\n6.\tBivariate Analysis\n7.\tSummary\n8.\tCorrelation of Variables\n9.\tChi Square Statistics\n10.\tOutliers Removal\n11.\tFeature Encoding \n12.\tMachine Learning\n    12.1.\tTransforming Features and Target Variable into Array\n    12.3.\tStratified Cross Validation\n    12.4.\tDefining Functions for Evaluation\n    12.5.\tLogistic Regression\n    12.6.\tKnn Algorithm\n    12.7.\tNaïve Bayes classifier\n    12.8.\tDecision Tree Classifier\n    12.9.\tRandom Forest Classifier\n    12.10.\tXGBoost\n    12.11.\tAdaBoost Classifier\n13.\tModel Metrics Comparision\n14.\tHyperparameter Tunning\n    14.1.\tLogistic Regression\n    14.2.\tKNN Classifier\n    14.3.\tDecision Tree\n    14.4.\tNaïve Bayes\n    14.5.\tRandom Forest\n    14.6.\tXGBoost\n    14.7.\tAdaBoost\n15.\tModel Metrics After Hyperparameter Tunning\n"},{"metadata":{},"cell_type":"markdown","source":"## 1. Importing Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n#visualizations\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\n\nimport plotly.offline as py\npy.init_notebook_mode(connected = True)\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\n\n#metrics and split\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom sklearn.metrics import precision_score, recall_score, f1_score\n\n#models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom xgboost import XGBClassifier\n\nimport warnings\nwarnings.filterwarnings('ignore')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Loading Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/german-credit-data-with-risk/german_credit_data.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Data Description"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Saving accounts and Checking account attributes have missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Data Quality Assessment & Statistical Analysis"},{"metadata":{},"cell_type":"markdown","source":"### 4.1. Filling missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 4.1.1 Savings account Attribute"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Saving accounts'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Total number of records is 1000 out of which 183 are null values in the Savings Account attrobute which accounts for 18.3% missing records. We therefore will fill these values using MCT"},{"metadata":{"trusted":true},"cell_type":"code","source":"#mode of Saving Accounts attribute\n\nmode_sav = df['Saving accounts'].mode()\nmode_sav","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Saving accounts'].fillna(mode_sav[0], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Saving accounts'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 4.1.2. Checking account Attribute"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Checking account'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Too many records are missing and for the better analysis of the data set with total 1000 records it will be appropiate to fill these values rather than dropping them"},{"metadata":{"trusted":true},"cell_type":"code","source":"#mode of Checking Accouny\nmode_check = df['Checking account'].mode()\nmode_check","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Checking account'].fillna(mode_check[0], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Checking account'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(columns=['Unnamed: 0'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>The given data set has 4 categorical and 4 numeric attributes/features. The target variable is also categorical.\n<br>\n<br>\nYoungest customer in our data set is 19 years old and the oldest is 75 years old. The average age of people in the given data set is 35. \n<br>\n<br>\nMajority of the customers lie in skilled class.\n<br>\n<br>\nThe max Credit amount granted to customer is 18424 while minimum was 250. The average credit amount granted is 3271. </b>"},{"metadata":{},"cell_type":"markdown","source":"## 5.Univariate Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"#labels\nlab = df[\"Risk\"].value_counts().keys().tolist()\n#values\nval = df[\"Risk\"].value_counts().values.tolist()\n\ntrace = go.Pie(labels = lab, values = val, marker = dict(colors = [ 'royalblue','lime'], line = dict(color =\"white\",width =2)),\n               rotation = 100,hoverinfo = \"label+value+text\", textinfo='label+percent',hole = .5)\n\nlayout = go.Layout(dict(title = \"Risk Count\",paper_bgcolor = \"rgb(243,243,243)\", plot_bgcolor  = \"rgb(243,243,243)\"))\n                        \ndata = [trace]\n\nfig = go.Figure(data = data,layout = layout)\n\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>The above plot shows that our data has class imbalance and therefore when using machine learning algorithms we will utilize stratified k fold cross validation that is specifically used to address class imbalance."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Defining funtion for ploting categorical attributes\n\ndef categorical_plots(var, data):\n        \n    #Adjustment of plots, bigger size and space b/w subplots\n    \n    fig = plt.figure(figsize=(15,5))\n    fig.subplots_adjust(wspace=0.3)\n    \n    plt.style.use('ggplot')\n        \n    #1st Plot:  Bar plot     \n        \n    plt.subplot(1,2,1)\n    sns.countplot(x=var, data= data)\n    plt.xticks(rotation = 45, horizontalalignment='right')\n    plt.xlabel(var.name + ' Distribution')\n    \n\n    #2nd Plot: PIE Chart\n    \n    labels =var.value_counts().index  #Labels that will be written against slices in pie charts\n    \n    #For the slice with highest value to be exploded, explode parameter is passed. Using for loop to make a tuple of \n    # number of slice using len(unique) and exploding the first slice by mentioning 0.1 at first index. Atlast converted list to tuple\n    \n    a=[0.1]\n    for i in range ((len(var.unique()))-1):\n        a.append(0)\n\n    explode1= tuple(a)\n    #if var.name != 'Customer Name':\n    ax1 = plt.subplot(1,2,2)\n    ax1.pie(var.value_counts(), labels=labels,autopct='%1.1f%%', shadow=True,explode= explode1 )\n    ax1.axis('equal')\n    plt.xlabel(var.name + ' Distribution')\n    plt.legend()\n        \n    show=plt.show()\n    \n    return(show)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#FOR NUMERICL PLOTS WE WILL BE USING THE FOLLOWING FUNCTION\n\ndef numerical_plots(var):\n    \n    #Adjustment of plots, bigger size and space b/w subplots\n    \n    fig = plt.figure(figsize=(15,4))\n    fig.subplots_adjust(wspace=0.3)\n    \n    #1st Plot:  Histogram with KDE plot          \n \n    plt.subplot(1,3,1)\n    sns.distplot(var, color='b')\n    plt.xlabel(var.name + ' Distribution')\n    \n    \n    #2nd Plot:  Box plot\n    \n    plt.subplot(1,3,2)\n    sns.boxplot(y=var)\n    plt.xlabel(var.name + ' Distribution')\n    \n\n    #3rd Plot:  Histogram    \n\n    plt.subplot(1,3,3)\n    var.hist(bins=15, color='steelblue', edgecolor='black', linewidth=1.0, xlabelsize=8, ylabelsize=8, grid=False)\n    plt.xlabel(var.name + ' Distribution')\n    #plt.grid(color='white')\n    \n    \n    show=plt.show()\n    \n    return(show)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 5.1.1. Age Attribute"},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_plots(df.Age)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The plots show that people aged between 20 to 40 tend to apply for credits more as compared to other age groups.\n<br>Among the customers who applied for credit, 50% or less were aged around 35 years.\n"},{"metadata":{},"cell_type":"markdown","source":"#### 5.1.2.Sex Attribute"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_plots(df.Sex, df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The plot shows that males apply more than female. Our data shows that 69% of the people who applied for credit were male, while female were 31%."},{"metadata":{},"cell_type":"markdown","source":"#### 5.1.3. Job Attribute"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_plots(df.Job,df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From 1000 people who applied for loan, highly skilled people were more than 600. That accounts for 63% of the total people who applied for credit.\n"},{"metadata":{},"cell_type":"markdown","source":"#### 5.1.4. Housing Attribute"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_plots(df.Housing,df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Customers who have their own properties/houses are in greater number who apply for loan."},{"metadata":{},"cell_type":"markdown","source":"#### 5.1.5. Saving Accounts attribute"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_plots(df['Saving accounts'],df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The plot shows that people who have little savings apply for loan more often as compared to people who have better or more savings."},{"metadata":{},"cell_type":"markdown","source":"#### 5.1.6. Checking account"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_plots(df['Checking account'],df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"People who have little amount in their checking accounts are the one in greater number who applied for loan."},{"metadata":{},"cell_type":"markdown","source":"#### 5.1.7. Credit Amount"},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_plots(df['Credit amount'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The distribution shows that aplications for credit amount less than 5000 are more as compared to higher loan applications.\n<br> Around 50% application were for credit amount =2500"},{"metadata":{},"cell_type":"markdown","source":"#### 5.1.8. Duration attribute"},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_plots(df.Duration)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The distribution shows that majority of the application are loan are for a duration between 10-25 months."},{"metadata":{},"cell_type":"markdown","source":"#### 5.1.9. Purpose Attribute"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_plots(df.Purpose,df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The plots clearly show that most of the loan applications are for buying cars. That accounts for 33.7% application. Interestingly the second most common purpose for loan is radio/TV."},{"metadata":{},"cell_type":"markdown","source":"#### 5.1.10. Risk Attribute"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_plots(df.Risk,df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Around 70% of the total application were classified as good risk. "},{"metadata":{},"cell_type":"markdown","source":"## 6. BiVariate Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(15,10))\nfig.subplots_adjust(wspace=0.5, hspace=0.5)\n\nc=1\nfor i in df.columns:\n    if df[i].dtype =='O' and i!='Risk':\n        plt.subplot(2,3,c)\n        sns.countplot(x=df[i], hue=df.Risk, data=df)\n        plt.xticks(rotation = 45, horizontalalignment='right')\n        c+=1\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(15,5))\nfig.subplots_adjust(wspace=0.3)\n\nc=1\nfor i in df.columns:\n    if df[i].dtype !='O' and i!='Job':\n        plt.subplot(1,3,c)\n        sns.boxplot(y=df[i], x=df.Risk)\n        #plt.xticks(rotation = 45, horizontalalignment='right')\n        c+=1\nplt.show()\n#for i in df.columns:\n #   if df[i].dtype !='O':\n  #      sns.boxplot(y=df[i], x=df.Risk)\n   #     plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A credit loan aplication of amount greater than 3000 will have more probability of being a Bad Risk as compared to Good.\n<br>When a loan is taken for a duration greater than 25 months then the probability of being a Bad Risk is high as compared to being Good.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('seaborn')\nsns.pairplot(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>From the plots we can observe:\n    <br>With an increase in age(>45) the number of credit applications decreases.\n    <br>Similarly, middle aged and old aged customers tend to apply for loan applications for shorter durations compared to adults.\n    "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('default')\n\nfig = plt.figure(figsize=(10,4))\nfig.subplots_adjust(wspace=0.5)\n\nplt.subplot(1,3,1)\nsns.boxplot(x=df.Sex,y=df['Credit amount'], hue=df.Risk, data=df)\n\n#Age2=np.where(df.Age)\nAge2 = np.where((df.Age<20),'TeenAger', np.where((df.Age>=20) & (df.Age<=30),'Adult',np.where((df.Age>30) & (df.Age<=50),'Middle-Aged','Old')))\nplt.subplot(1,3,2)\nsns.boxplot(x=Age2,y=df['Credit amount'], data=df)\nplt.xticks(rotation=45, horizontalalignment='right');\n\nplt.subplot(1,3,3)\nsns.boxplot(x=df.Purpose,y=df['Credit amount'], hue=df.Risk, data=df)\nplt.xticks(rotation=45, horizontalalignment='right');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('default')\n\nfig = plt.figure(figsize=(10,4))\nfig.subplots_adjust(wspace=0.5)\n\nplt.subplot(1,3,1)\nsns.boxplot(x=df.Sex,y=df['Age'], hue=df.Risk, data=df)\n\n#Age2=np.where(df.Age)\n#Age2 = np.where((df.Age<20),'TeenAger', np.where((df.Age>=20) & (df.Age<=30),'Adult',np.where((df.Age>30) & (df.Age<=50),'Middle-Aged','Old')))\nplt.subplot(1,3,2)\nsns.boxplot(x=Age2,y=df['Duration'], hue=df.Risk, data=df)\nplt.xticks(rotation=45, horizontalalignment='right');\n\nplt.subplot(1,3,3)\nsns.boxplot(x=df.Purpose,y=df['Age'], hue=df.Risk, data=df)\nplt.xticks(rotation=45, horizontalalignment='right');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 7. <b>Summary:</b>"},{"metadata":{},"cell_type":"markdown","source":"People aged between 20 to 40 tend to apply for credits more as compared to other age groups. The average of people who apply for loan is 35 years.\n\nMales apply for credits/loans more than females. 69% of the people who applied for credit were male, while female were 31%.\n\nFrom 1000 people who applied for loan, highly skilled people were more than 600. That accounts for 63% of the total people who applied for credit.\n\nCustomers who have their own properties/houses are in greater number who applied for loan.\n\nCustomers with little savings and little amounts in checking accounts apply for loan more often as compared to people who have better or more savings.\n\nAplications for credit amount less than 5000 are more as compared to higher loan applications.\n\nThe max Credit amount granted to customer was 18424 while minimum was 250. The average credit amount granted was 3271. </b>\n\nMajority of the application for loan are for a duration of 10-25 months.\n\nMost of the loan applications are for cars. That accounts for 33.7% application. Interestingly the second most common purpose for loan is radio/TV.\n\nA credit loan aplication of amount greater than 3000 will have more probability of being a Bad Risk as compared to Good.\n\nWhen a loan is taken for a duration greater than 25 months then the probability of being a Bad Risk is high as compared to being Good."},{"metadata":{},"cell_type":"markdown","source":"## 8. Correlation of Variables "},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Risk = np.where(df.Risk =='good',1,0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from yellowbrick.features import rank1d, rank2d\n\nfig, axes = plt.subplots(1, 2,figsize=(15,5))\n\n#heatmap using seaborn\ncorr = df.corr()\nplt.subplot(1,2,1)\nsns.heatmap(corr, annot=True)\n\n#2 dimensional Ranking using yellow brick\ndf2 =df.drop(columns=['Sex','Housing','Saving accounts','Checking account','Purpose'])\nrank2d(df2, ax=axes[1]);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b> 1. Credit amount and Duration attributes have a strong postive relationship. Greater the credit amount, greater will be the duration.\n    \n<br>2. Credit amount and Duration show a negative correlation with the target variabe Risk i.e. Larger credit loan applications may have higher probabilty of risk compared to smaller.\n\n<br>3. Similarly larger duration of loan tend towards Bad Risk applications.</b>"},{"metadata":{},"cell_type":"markdown","source":"## 9. Chi Square Statistics"},{"metadata":{"trusted":true},"cell_type":"code","source":"import scipy.stats as s\n\ndef chi2(data,target,alpha):\n    \n    for i in df.columns:\n    \n        if df[i].dtype == 'O' and i != target:\n            col = i\n\n            ov = pd.crosstab(data[col], data[target])\n            #max_least_income = ov.loc[ov[' <=50K'].idxmax()].name\n            #max_highest_income = ov.loc[ov[' >50K'].idxmax()].name\n            plt.style.use('ggplot')\n            ov.plot(kind='bar', figsize=(5,5), stacked=True)\n            plt.xlabel(i.title())\n                 \n            chi = s.chi2_contingency(ov)\n            chi2_s = chi[0]\n            p_value = chi[1]\n            dof = chi[2]\n            critical_value = s.chi2.ppf(q=1-alpha, df=dof)\n            \n            print('\\n\\033[1m\\033[4m', col.upper(),':\\033[0m \\n')\n            print('Significance Level = ', alpha)\n            print('Degree of Freedom = ', dof)\n            print('chi2 = ', chi2_s)\n            print('Critical Value = ',critical_value)\n            print('p-value = ', p_value)\n\n            if chi2_s >=critical_value or p_value <= alpha :\n                print('\\nWe reject the null hypotheses, there is a relationship between the two variables \\n')\n            else:\n                print('\\nThere is no relationship between the two variables and the null hypotheses is retained \\n')\n            \n            plt.show()\n            #print('\\033[1mThe bar chart shows that', max_least_income,i,'has the highest number of people with <=50k income and',max_highest_income,i,'has the highest number of people having income >50K \\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"chi2(df, 'Risk', 0.05)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>All categorical variables have a relationship with the target variable except 'Purpose' attribute. Among all the related variables saving account has the highest affect on the Risk.</b>"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(columns = ['Purpose'], inplace=True) #Since there is no relation ship with the target variable","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 10. Outliers Removal "},{"metadata":{},"cell_type":"markdown","source":"<b>In the univariate analysis we saw that age, credit amount and Duration attributes not only had outliers but were also positivey skewed. Therefore, before feeding the data to model we will remove reduce the skewness and remove the outliers using logarithimic transformation."},{"metadata":{"trusted":true},"cell_type":"code","source":"outliers = np.log(df[['Age', 'Duration','Credit amount']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(8,3))\nsns.distplot(outliers.Age, ax=ax1)\nsns.distplot(outliers.Duration, ax=ax2)\nsns.distplot(outliers[\"Credit amount\"], ax=ax3)\n\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 11. Feature Encoding & Data Normalization"},{"metadata":{},"cell_type":"markdown","source":"#### 11.1. Manual Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Sex =  np.where(df.Sex =='male',1,0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 11.2. One Hot Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Dummies_Housing = pd.get_dummies(df.Housing)\ndf.Dummies_Housing.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Dummies_Saving = pd.get_dummies(df['Saving accounts'])\ndf.Dummies_Saving.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Dummies_Checking = pd.get_dummies(df['Checking account'])\ndf.Dummies_Checking.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([df,df.Dummies_Housing,df.Dummies_Saving,df.Dummies_Checking], axis=1)\ndf.drop(columns=['Housing', 'Saving accounts', 'Checking account'], inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <center><u>12. Machine Learning</u></center>"},{"metadata":{},"cell_type":"markdown","source":"### 12.1. Transforming Features and Target Variable into Array"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df['Risk']\n\nx = df.drop(columns=['Risk'])\nx.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 12.1.2. Data Normalization"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nzscore = StandardScaler()\n\nfor i in x.columns:\n    df[i] = zscore.fit_transform(df[[i]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = x.to_dict(orient='records')\n\nfrom sklearn.feature_extraction import DictVectorizer\nvec = DictVectorizer()\nx = vec.fit_transform(x).toarray()\nx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y =np.asarray(y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <u>12.3. Stratified Cross Validation</u>"},{"metadata":{},"cell_type":"markdown","source":"<b>To cater the problems associated with class imbalance, we will use stratifed cross validation which will split data having equal portions of our target class in every split.</b>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nskf = StratifiedKFold(n_splits=5, random_state=None)\n\nfor train_index, val_index in skf.split(x,y): \n    #print(\"Train:\", train_index, \"Validation:\", val_index) \n    xtrain, xtest = x[train_index], x[val_index] \n    ytrain, ytest = y[train_index], y[val_index]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 12.4. Defining Functions for evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining a function to be used for evaluation for all algorithms\n\nfrom sklearn.metrics import roc_auc_score,roc_curve,scorer, classification_report, confusion_matrix\nimport plotly.tools as tls\n\ndef evaluation(algorithm):\n    #Classification Report\n    print (\"\\n \\033[1m Classification report : \\033[0m\\n\",classification_report(ytest,algorithm ))\n\n    #Accuracy\n    print (\"\\033[1mAccuracy Score   : \\033[0m\",accuracy_score(ytest, algorithm))\n\n    #conf_matrix\n    conf_matrix = confusion_matrix(ytest,algorithm)\n\n\n    #roc_auc_score\n    model_roc_auc = round(roc_auc_score(ytest, algorithm),3) \n    print (\"\\033[1mArea under curve : \\033[0m\",model_roc_auc)\n    fpr,tpr,thresholds = roc_curve(ytest,probabilities[:,1])\n\n    # roc curve plot\n    trace1 = go.Scatter(x = fpr,y = tpr,\n                        name = \"Roc : \" + str(model_roc_auc),\n                        line = dict(color = ('rgb(22, 96, 167)'),width = 2),\n                       )\n    trace3 = go.Scatter(x = [0,1],y=[0,1],\n                        line = dict(color = ('rgb(205, 12, 24)'),width = 2,\n                        dash = 'dot'))\n    #confusion matrix plot\n    trace2 = go.Heatmap(z = conf_matrix ,\n                        x = [\"Bad Risk \",\"Good Risk\"],\n                        y = [\"Bad Risk\",\"Good Risk\"],\n                        colorscale = \"Viridis\",name = \"matrix\" )\n    #subplots\n    fig = tls.make_subplots(rows=1, cols=2, horizontal_spacing = 0.40,subplot_titles=('ROC Curve','Confusion Matrix'))\n\n    fig.append_trace(trace1,1,1)\n    fig.append_trace(trace3,1,1)\n    fig.append_trace(trace2,1,2)\n\n\n    fig['layout'].update(showlegend=False, title=\"Model performance\" ,\n                         autosize = False,height = 400,width = 800,\n                         plot_bgcolor = 'rgba(240,240,240, 0.95)',\n                         paper_bgcolor = 'rgba(240,240,240, 0.95)',\n                         xaxis = dict(title = \"false positive rate\",\n                                 gridcolor = 'rgb(255, 255, 255)',\n                                 domain=[0, 0.6],\n                                 ticklen=5,gridwidth=2),\n                        yaxis = dict(title = \"true positive rate\",\n                                  gridcolor = 'rgb(255, 255, 255)',\n                                  zerolinewidth=1),\n                        margin = dict(b = 20))\n\n    py.iplot(fig)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Defining a function using Yellow brick library to be used for evaluation\n\nfrom yellowbrick.classifier import ConfusionMatrix, ClassificationReport, ROCAUC\nfrom yellowbrick.features import FeatureImportances\n\n\n\ndef visualize(model):\n\n    \n    fig, axes = plt.subplots(1, 3,figsize=(15,5))\n    fig.subplots_adjust(wspace=0.7)\n    \n    visualgrid = [\n        #FeatureImportances(model,ax=axes[0][0]),\n        ROCAUC(model, ax=axes[1],cmap='RdYlBu'),\n        ConfusionMatrix(model,cmap='BuPu', ax=axes[2]),\n        ClassificationReport(model, cmap='PuBu',ax=axes[0])\n        \n    ]\n\n    for viz in visualgrid:\n        viz.fit(xtrain, ytrain)\n        viz.score(xtest, ytest)\n        viz.finalize()\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 12.5.<u> Logistic Regression</u>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\n\n#Model Training\nmodel_LG =LogisticRegression()\nmodel_LG.fit(xtrain, ytrain);\n\n#Prediction\ny_pred_LG = model_LG.predict(xtest)\nprobabilities = model_LG.predict_proba(xtest)\nfpr,tpr,thresholds = roc_curve(ytest,probabilities[:,1])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression Evaluation Using Plotly"},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluation(y_pred_LG)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression Evaluation using YellowBrick"},{"metadata":{"trusted":true},"cell_type":"code","source":"visualize(model_LG)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 12.6. <u>KNN Algorithm</u>"},{"metadata":{},"cell_type":"markdown","source":"### Applying KNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\n#Model Traning\nmodel_knn = KNeighborsClassifier()\nmodel_knn.fit(xtrain,ytrain);\n\n#Prediction\ny_pred_knn = model_knn.predict(xtest)\nprobabilities = model_knn.predict_proba(xtest)\nfpr,tpr,thresholds = roc_curve(ytest,probabilities[:,1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### KNN Evaluation Using Plotly"},{"metadata":{"trusted":true},"cell_type":"code","source":"#print (\"\\n \\033[1m Classification report : \\033[0m\\n\",classification_report(ytest, y_pred_knn))\n#print (\"\\033[1mAccuracy Score   : \\033[0m\",accuracy_score(ytest, y_pred_knn))\nevaluation(y_pred_knn)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### KNN Evaluation Using YellowBrick"},{"metadata":{"trusted":true},"cell_type":"code","source":"visualize(model_knn)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 12.7. <u>Naive Bayes Classifier</u>"},{"metadata":{},"cell_type":"markdown","source":"### Applying Naive Bayes Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\n#Model Training\nmodel_nb = GaussianNB()\nmodel_nb.fit(xtrain, ytrain);\n\n# Model Prediction\ny_pred_nb = model_nb.predict(xtest)\nprobabilities = model_nb.predict_proba(xtest)\nfpr,tpr,thresholds = roc_curve(ytest,probabilities[:,1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Naive Bayes Evaluation Using Plotly"},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluation(y_pred_nb)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Naive Bayes Evaluation using YellowBrick"},{"metadata":{"trusted":true},"cell_type":"code","source":"visualize(model_nb)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 12.8. <u>Decision Tree Classifer</u>"},{"metadata":{},"cell_type":"markdown","source":"### Applying Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import tree\n\n# Model Traning\nmodel_DT = tree.DecisionTreeClassifier()\nmodel_DT.fit(xtrain,ytrain)\n\n#Predictions\ny_pred_DT = model_DT.predict(xtest)\nprobabilities = model_DT.predict_proba(xtest)\nfpr,tpr,thresholds = roc_curve(ytest,probabilities[:,1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Decision Tree Evaluation Using Plotly"},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluation(y_pred_DT)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Decision Tree Evaluation Using YellowBrick"},{"metadata":{"trusted":true},"cell_type":"code","source":"visualize(model_DT)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 12.9. <u>Random Forest Classifier</u>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n#Model Training\nmodel_rfc = RandomForestClassifier()\nmodel_rfc.fit(xtrain, ytrain);\n\n#Prediction\ny_pred_rfc = model_rfc.predict(xtest)\nprobabilities = model_rfc.predict_proba(xtest)\nfpr,tpr,thresholds = roc_curve(ytest,probabilities[:,1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest Classifier Evaluation Using Plotly:"},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluation(y_pred_rfc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest Classifier Evaluation Using Yellow Brick"},{"metadata":{"trusted":true},"cell_type":"code","source":"visualize(model_rfc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 12.10. <u>XGBoost</u>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\n\n#Model Training\nmodel_xgb  = xgb.XGBClassifier()\nmodel_xgb.fit(xtrain, ytrain);\n\n#Prediction\ny_pred_xgb = model_xgb.predict(xtest)\nprobabilities = model_xgb.predict_proba(xtest)\nfpr,tpr,thresholds = roc_curve(ytest,probabilities[:,1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### XGBoost Evaluation Using Plotly:"},{"metadata":{"trusted":true},"cell_type":"code","source":"#print (\"\\n \\033[1m Classification report : \\033[0m\\n\",classification_report(ytest, y_pred_xgb))\n#print (\"\\n \\033[1m Accuracy : \\033[0m\\n\",metrics.accuracy_score(ytest, y_pred_xgb))\nevaluation(y_pred_xgb)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### XGBoost Evaluation Using YellowBrick"},{"metadata":{"trusted":true},"cell_type":"code","source":"visualize(model_xgb)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 12.11. <u>AdaBoost Classifier</u>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n#Model Training\nmodel_adaboost = AdaBoostClassifier()\nmodel_adaboost.fit(xtrain, ytrain);\n\n#Prediction\ny_pred_ada = model_adaboost.predict(xtest)\nprobabilities = model_adaboost.predict_proba(xtest)\nfpr,tpr,thresholds = roc_curve(ytest,probabilities[:,1])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### AdaBoost Evaluation Using Plotly:"},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluation(y_pred_ada)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### AdaBoost Evaluation Using Yellow Brick:"},{"metadata":{"trusted":true},"cell_type":"code","source":"visualize(model_adaboost)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 13. Model Metrics Comparision"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\n\ndef model_report(model,training_x,testing_x,training_y,testing_y,name) :\n    model.fit(training_x,training_y)\n    predictions  = model.predict(testing_x)\n    accuracy     = accuracy_score(testing_y,predictions)\n    recallscore  = recall_score(testing_y,predictions)\n    precision    = precision_score(testing_y,predictions)\n    f1score      = f1_score(testing_y,predictions) \n    roc_auc      = roc_auc_score(testing_y,predictions)\n    \n    \n    df = pd.DataFrame({\"Model\"           : [name],\n                       \"Accuracy_score\"  : [accuracy],\n                       \"Recall_score\"    : [recallscore],\n                       \"Precision\"       : [precision],\n                       \"f1_score\"        : [f1score],\n                       \"roc-auc\"         : [roc_auc]\n                      })\n    return df\n\nmodel1 = model_report(model_LG,xtrain,xtest,ytrain,ytest,\n                      \"Logistic Reg. \")\n\n\nmodel2 = model_report(model_rfc,xtrain,xtest,ytrain,ytest,\n                     \"Random Forest Classifier\")\n\n\nmodel3 = model_report(model_xgb,xtrain,xtest,ytrain,ytest,\n                     \"XGBoost.\")\n\nmodel4 = model_report(model_knn,xtrain,xtest,ytrain,ytest,\n                      \"KNN Classifier\")\n\nmodel5 = model_report(model_nb,xtrain,xtest,ytrain,ytest,\n                      \"Naive Bayes\")\n\nmodel6 = model_report(model_DT,xtrain,xtest,ytrain,ytest,\n                      \"Decision Tree\")\n\nmodel7 = model_report(model_adaboost,xtrain,xtest,ytrain,ytest,\n                      \"AdaBoost\")\n\n\nmodel_performances = pd.concat([model1,model4,model6,model5,model2, model3, model7],axis = 0).reset_index()\n\nmodel_performances = model_performances.drop(columns = \"index\",axis =1)\n\ntable  = ff.create_table(np.round(model_performances,4))\n\npy.iplot(table)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <center>14. <u> Hyper Parameter Tunning</u></center>"},{"metadata":{},"cell_type":"markdown","source":"#### <b>We will be utilizing GridSearch to find best parameters for our model and train our model on the best found hyperparamters. \n\n<b><br>Then we will plot validation curve of any one paramaters for range of hypermaters for every model. \n    \n   <br>And lastly we will plot learning curves for every model to see if more data provided to the model will result in better performance or not.\n    "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom yellowbrick.model_selection import ValidationCurve\nfrom yellowbrick.model_selection import LearningCurve\nfrom sklearn.model_selection import validation_curve","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We will define three functions: One for validation curve using yellowbrick and other using scikit learn\n# Third Function for Learning Curve using yellowbrick\nplt.style.use('ggplot')\n#Function1 (Validation Curve using Yellow Brick)\n\ndef validation(model, meter, range1):\n    i=0\n    fig, axes = plt.subplots(2, 2,figsize=(15,10))\n    fig.subplots_adjust(wspace=0.3, hspace=0.3)\n    \n    cv = StratifiedKFold(n_splits=5) #To avoid class imbalance problem, using Stratified cross validation\n\n    visualgrid = [\n                ValidationCurve(model, param_name=meter,param_range = range1, cv=cv, scoring=\"accuracy\",ax=axes[0][0]),\n                \n                ValidationCurve(model, param_name= meter, param_range= range1, cv=cv, scoring=\"precision\",ax=axes[0][1]),\n             \n                ValidationCurve(model, param_name= meter, param_range= range1, cv=cv, scoring=\"recall\",ax=axes[1][0]),\n                \n                ValidationCurve(model, param_name= meter, param_range= range1, cv=cv, scoring=\"f1\",ax=axes[1][1])    ]\n    \n    score=['Accuracy','Precision','Recall','f1']\n    \n    print('The plots scores are in following order\\n:')\n    \n    for viz in visualgrid:\n        print('\\n',i+1,'.',score[i])\n        i+=1\n        viz.fit(x, y)\n        viz.finalize()\n            \n    plt.show()\n\n\n#Function3 (Learning Curve using Yellow Brick)\n\ndef learning (model):\n    \n    i=0\n    fig, axes = plt.subplots(2, 2,figsize=(15,10))\n    fig.subplots_adjust(wspace=0.3, hspace=0.3)\n    \n    cv = StratifiedKFold(n_splits=5) #To avoid class imbalance problem, using Stratified cross validation\n    sizes = np.linspace(0.3, 1.0, 10)\n\n    visualgrid = [\n                LearningCurve(model, cv=cv, scoring=\"accuracy\",train_sizes=sizes,ax=axes[0][0]),\n                \n                LearningCurve(model, cv=cv, scoring=\"precision\",train_sizes=sizes,ax=axes[0][1]),\n             \n                LearningCurve(model, cv=cv, scoring=\"recall\",train_sizes=sizes,ax=axes[1][0]),\n                \n                LearningCurve(model, cv=cv, scoring=\"f1\",train_sizes=sizes,ax=axes[1][1])    ]\n    \n    score=['Accuracy','Precision','Recall','f1']\n    \n    print('The plots scores are in following order\\n:')\n    \n    for viz in visualgrid:\n        print('\\n',i+1,'.',score[i])\n        i+=1\n        viz.fit(x, y)\n        viz.finalize()\n            \n    plt.show()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('ggplot')\n#Function 2 (Validation curve using scikit learn)\n\ndef validation_plots(name,algorithm, feature, range3):\n    \n    param_range = range3\n    #np.logspace(-5, 3)\n\n    cv = StratifiedKFold(n_splits=5) #To avoid class imbalance problem, using Stratified cross validation\n\n    train_scores, test_scores = validation_curve(algorithm, x, y, feature, param_range=param_range, cv=cv)\n\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n\n    plt.title(\"Validation Curve with\"+name)\n    plt.xlabel(feature)\n    plt.ylabel(\"Score\")\n    plt.ylim(0.0, 1.1)\n    #plt.xlim(-10,10)\n    \n    #scaling on x axis and plotting the mean score\n    plt.plot(param_range, train_scores_mean, label=\"Training score\", color=\"green\", lw=2, linestyle='dashdot')\n        \n    plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\", color=\"navy\", lw=2, linestyle='dashdot')\n        \n    plt.legend(loc=\"best\")\n    \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 14.1 <u> Logistic Regression</u>"},{"metadata":{"trusted":true},"cell_type":"code","source":"LG= LogisticRegression(penalty='l2')\nhyperparameters = {'dual':[True,False],'max_iter':[100,110,120,130,140],'C':[0.001,1.0,1.5,2.0,2.5,100]}\nLG_classifier =  GridSearchCV(LG, hyperparameters, refit=True, cv=5)\nLG_classifier.fit(xtrain,ytrain);\n#LG.fit(X_train,y_train);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The best fit value is found out to be :\" ,LG_classifier.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_LG2 = LG_classifier.predict(xtest)\n#y_pred_LG2 = LG.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"\\n \\033[1m Classification report : \\033[0m\\n\",classification_report(ytest, y_pred_LG2))\nprint (\"\\033[1mAccuracy Score   : \\033[0m\",accuracy_score(ytest, y_pred_LG2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 14.1.1. Validation Curve for Hyperameter C (Using Scikit Learn):"},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_plots('Logistic Regression',LogisticRegression(penalty='l2'),'C',np.arange(0.0001,100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>The validation curve for hyperparameter C clearly shows that model is well generalized on a wide rang of values for C i.e. if we select -1 or 100, for both the values Logistic Regression will have a score af around 0.70-0.71.</b>"},{"metadata":{},"cell_type":"markdown","source":"### 14.1.2. Validation Curves for HyperParameter C (Using YellowBrick):"},{"metadata":{"trusted":true},"cell_type":"code","source":"validation(LogisticRegression(penalty='l2'),'C',np.logspace(-5, 3))\n\n# Following are plots with scoring in the following order:\n\n# 1. Accuracy  2 . Precision  3. Recall  4. f1\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 14.1.3. Learning Curves for Logistic Regression (Using YellowBricks)"},{"metadata":{"trusted":true},"cell_type":"code","source":"learning(LogisticRegression(penalty='l2'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>All the 4 plots show that the training and validation score converge with increasing instances. i.e the models performace will be better as more data is provided to the model.</b>"},{"metadata":{},"cell_type":"markdown","source":"## 14.2. <u>KNN Classifer</u>"},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier()\nhyperparameters = {'n_neighbors' : list(range(1,40)), 'p':[1,2]}\nknn_classifier =  GridSearchCV(knn, hyperparameters, refit=True, cv=5)\nknn_classifier.fit(xtrain,ytrain);\n#knn.fit(X_train,y_train);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The best fit value is found out to be :\" ,knn_classifier.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_knn2 = knn_classifier.predict(xtest)\n#y_pred_knn2 = knn.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"\\n \\033[1m Classification report : \\033[0m\\n\",classification_report(ytest, y_pred_knn2))\nprint (\"\\033[1mAccuracy Score   : \\033[0m\",accuracy_score(ytest, y_pred_knn2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 14.2.1. Validation Curve for Hyperparameter n_neighbors (Using Scikit Learn):"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Validation Curve using Scikit Learn\nvalidation_plots('KNN',KNeighborsClassifier(),'n_neighbors',np.arange(1, 40))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>The Validation curve seconds the best paramter found out using gridsearch i.e. k =31 as we can see the training score and validation score converge when the number of neighbors are 31 and more.</b>"},{"metadata":{},"cell_type":"markdown","source":"### 14.2.2. Validation Curve for Hyperparameter n_neighbors(Using YellowBricks):"},{"metadata":{"trusted":true},"cell_type":"code","source":"validation(KNeighborsClassifier(),'n_neighbors',np.arange(1, 40))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b> Its clear from all the four plots that models performance gets better or more generalized as the number of neighbors increase.</b>"},{"metadata":{},"cell_type":"markdown","source":"### 14.2.3. Learning Curves for KNN (Using YellowBricks):"},{"metadata":{"trusted":true},"cell_type":"code","source":"learning(KNeighborsClassifier())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b> The learning curves show that the model performance will remain same even if more data is provided to the model."},{"metadata":{},"cell_type":"markdown","source":"## 14.3. <u>Decision Tree</u>"},{"metadata":{"trusted":true},"cell_type":"code","source":"DT = tree.DecisionTreeClassifier()\nhyperparameters = {'criterion' :['gini','entropy'], 'max_features':[2,4,6,8],'max_depth':[0.001,1,10, 20, 25, 30, 40, 50]},\nDT_classifier =  GridSearchCV(DT, hyperparameters, refit=True, cv=5)\nDT_classifier.fit(xtrain,ytrain);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The best fit value is found out to be :\" ,DT_classifier.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_DT2 = DT_classifier.predict(xtest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"\\n \\033[1m Classification report : \\033[0m\\n\",classification_report(ytest, y_pred_DT2))\nprint (\"\\033[1mAccuracy Score   : \\033[0m\",accuracy_score(ytest, y_pred_DT2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 14.3.1. Validation Curve for HyperParameter max_depth(Using Plotly):"},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_plots('DT',tree.DecisionTreeClassifier(),'max_depth',np.arange(0.001, 40))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b> The Validation curve shows that with increase in depth of the tree the model will tend t be overfit. With lesser depths model will generalize well."},{"metadata":{},"cell_type":"markdown","source":"### 14.3.2. Validation Curve for HyperParameter max_depth(Using YellowBricks):"},{"metadata":{"trusted":true},"cell_type":"code","source":"validation(tree.DecisionTreeClassifier(),'max_depth',np.arange(0.001, 10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b> All 4 curves show that increasing depth of tree will make the model overfit. The tree will be more generalized when the depth is less than 0."},{"metadata":{},"cell_type":"markdown","source":"### 14.3.3. Learning Curve for Decision Tree(Using YellowBricks):"},{"metadata":{"trusted":true},"cell_type":"code","source":"learning(DT)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b> All the learning curve show that there will be no positive impact on the performance of the decision tree even if more data is provided."},{"metadata":{},"cell_type":"markdown","source":"## 14.4. <u>Naive Bayes</u>"},{"metadata":{"trusted":true},"cell_type":"code","source":"NB = GaussianNB()\nhyperparameters = {'var_smoothing':np.logspace(0,-9, num=100)}\n\nNB_classifier =  GridSearchCV(NB, hyperparameters, refit=True, cv=5)\nNB_classifier.fit(xtrain,ytrain);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The best fit value is found out to be :\" ,NB_classifier.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_NB2 = NB_classifier.predict(xtest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"\\n \\033[1m Classification report : \\033[0m\\n\",classification_report(ytest, y_pred_NB2))\nprint (\"\\033[1mAccuracy Score   : \\033[0m\",accuracy_score(ytest, y_pred_NB2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 14.4.1.Validation Curve for HyperParameter var_smoothing(Using Plotly):"},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_plots('NB',GaussianNB(),'var_smoothing',np.logspace(0,-100, num=100))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 14.4.2. Validation Curve for HyperParameter var_smoothing(Using YellowBrick):"},{"metadata":{"trusted":true},"cell_type":"code","source":"validation(GaussianNB(),'var_smoothing',np.logspace(0,-9, num=100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 14.4.3. Learning Curves for Gaussian Naive Bayes (Using YellowBricks):"},{"metadata":{"trusted":true},"cell_type":"code","source":"learning(GaussianNB())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>The learning curves show that with incresing number of instances the model generalizes."},{"metadata":{},"cell_type":"markdown","source":"<b> When more data is provided to the model, it will generalize well which is clear from the learning curves as the training and validation scores converge with increasing data"},{"metadata":{},"cell_type":"markdown","source":"## 14.6. <u>Random Forest </u>"},{"metadata":{"trusted":true},"cell_type":"code","source":"RF= RandomForestClassifier()\nhyperparameters = {'n_estimators' :[1,2,5,10,15,25,30], 'max_features':[2,4,6,8],'max_depth':[0.01,1,10, 20, 25,30, 40, 50]}\nRF_classifier =  GridSearchCV(RF, hyperparameters, refit=True, cv=5)\nRF_classifier.fit(xtrain,ytrain);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The best fit value is found out to be :\" ,RF_classifier.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_rfc2 = RF_classifier.predict(xtest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"\\n \\033[1m Classification report : \\033[0m\\n\",classification_report(ytest, y_pred_rfc2))\nprint (\"\\033[1mAccuracy Score   : \\033[0m\",accuracy_score(ytest, y_pred_rfc2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 14.6.1. Validation Curve for HyperParameter max_depth (Using Plotly):"},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_plots('Random Forest',RandomForestClassifier(),'max_depth',np.arange(0.001, 40))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b> The Validation curve shows that with increase in depth of the model the model will tend t be overfit. With lesser depths model will generalize well.\n"},{"metadata":{},"cell_type":"markdown","source":"### 14.6.2. Validation Curve for HyperParameter max_depth (Using YellowBricks):"},{"metadata":{"trusted":true},"cell_type":"code","source":"validation(RandomForestClassifier(),'max_depth',np.arange(0.001, 10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b> All 4 curves show that increasing depth of random forest will make the model overfit. The model will be more generalized when the depth is less than 0."},{"metadata":{},"cell_type":"markdown","source":"### 14.6.3. Learning Curves for Random Forest (Using YellowBrick):"},{"metadata":{"trusted":true},"cell_type":"code","source":"learning(RandomForestClassifier())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b> The learning curves show that there will no positive impact on models performance with increase in number of instances"},{"metadata":{},"cell_type":"markdown","source":"## 14.7. <u>XGBoost</u>"},{"metadata":{"trusted":true},"cell_type":"code","source":"XGB= xgb.XGBClassifier()\nhyperparameters = {\"learning_rate\": [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ],\"max_depth\": [ 3, 4, 5, 6, 8, 10, 12, 15], \n                    \"gamma\":[ 0.0, 0.1, 0.2 , 0.3, 0.4 ]}\n                   \nXGB_classifier =  GridSearchCV(XGB, hyperparameters, refit=True, cv=5)\nXGB_classifier.fit(xtrain,ytrain);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The best fit value is found out to be :\" ,XGB_classifier.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_xgb2 = RF_classifier.predict(xtest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"\\n \\033[1m Classification report : \\033[0m\\n\",classification_report(ytest, y_pred_xgb2))\nprint (\"\\033[1mAccuracy Score   : \\033[0m\",accuracy_score(ytest, y_pred_xgb2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 14.7.1. Validation Curve for HyperParamter Learning Rate (Using Plotly):"},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_plots('XGBoost',xgb.XGBClassifier(),'learning_rate', np.arange(0,100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b> The validation curve shows that the model us generalized well on a wide range of learning rate values. The performance stablizes when learning rate reaches near 50."},{"metadata":{},"cell_type":"markdown","source":"### 14.7.2. Validation Curves for HyperParamter Learning Rate (Using YellowBricks):"},{"metadata":{"trusted":true},"cell_type":"code","source":"validation(xgb.XGBClassifier(),'learning_rate',np.arange(0,100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b> All the validation curve shows that the model us generalized well on a wide range of learning rate values. The performance stablizes when learning rate reaches near 50"},{"metadata":{},"cell_type":"markdown","source":"### 14.7.3. Learning Curves for XGBoost (Using yellowBricks):"},{"metadata":{"trusted":true},"cell_type":"code","source":"learning(xgb.XGBClassifier())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>The Learning curves show that there will no positive impact on models performance with increasing data."},{"metadata":{},"cell_type":"markdown","source":"## 14.8. <u>AdaBoost</u>"},{"metadata":{"trusted":true},"cell_type":"code","source":"ADA = AdaBoostClassifier()\n#ADA2= AdaBoostClassifier(learning_rate=0.25)\nhyperparameters = {\"learning_rate\": [0.0001,0.05, 0.10, 0.15, 0.20, 0.25,0.26,0.27, 0.30 ]}\n\nADA_classifier =  GridSearchCV(ADA, hyperparameters, refit=True, cv=5)\nADA_classifier.fit(xtrain,ytrain);\n#ADA2.fit(xtrain,ytrain)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The best fit value is found out to be :\" ,ADA_classifier.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_ada2 = ADA_classifier.predict(xtest)\n#y_pred_ada3 = ADA2.predict(xtest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"\\n \\033[1m Classification report : \\033[0m\\n\",classification_report(ytest, y_pred_ada2))\nprint (\"\\033[1mAccuracy Score   : \\033[0m\",accuracy_score(ytest, y_pred_ada2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 14.8.1. Validation Curve for Hyperparameter Learning Rate (using Plotly):"},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_plots('AdaBoost',AdaBoostClassifier(),'learning_rate',np.arange(1,10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>The validation curve shows that although model generalized well for learning rate >=2 but the overall score will be greaty reduced for both training and validation."},{"metadata":{},"cell_type":"markdown","source":"### 14.8.2. Validation Curve for Hyperparameter Learning Rate (using YellowBricks):"},{"metadata":{"trusted":true},"cell_type":"code","source":"validation(AdaBoostClassifier(),'learning_rate',np.arange(1,10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b> Validation curve shows that for learning rate =1 the model has some differnce in the training and validation scores which is acceptable as the overall score is good. But as the learning rate increases the models genrelizes at the same time its overall score decreases."},{"metadata":{},"cell_type":"markdown","source":"### 14.8.3. Learning Curves for AdaBoost (Using yellowBricks):\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"learning(AdaBoostClassifier())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>The learning curves show that training and validation score converge with increase in data and therfore model will generalize will with incresing number of instances."},{"metadata":{},"cell_type":"markdown","source":"## 15. Model Metrics After Hyper Parameter Tunning"},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_report(model,training_x,testing_x,training_y,testing_y,name) :\n    model.fit(training_x,training_y)\n    predictions  = model.predict(testing_x)\n    accuracy     = accuracy_score(testing_y,predictions)\n    recallscore  = recall_score(testing_y,predictions)\n    precision    = precision_score(testing_y,predictions)\n    f1score      = f1_score(testing_y,predictions) \n    roc_auc      = roc_auc_score(testing_y,predictions)\n    \n    \n    df = pd.DataFrame({\"Model\"           : [name],\n                       \"Accuracy_score\"  : [accuracy],\n                       \"Recall_score\"    : [recallscore],\n                       \"Precision\"       : [precision],\n                       \"f1_score\"        : [f1score],\n                       \"roc_auc\"         : [roc_auc]\n                       \n                      })\n    return df\n\nmodel1 = model_report(LG_classifier,xtrain,xtest,ytrain,ytest,\n                      \"Logistic Reg. \")\n\n\nmodel2 = model_report(RF_classifier,xtrain,xtest,ytrain,ytest,\n                     \"Random Forest Classifier\")\n\n\nmodel3 = model_report(XGB_classifier,xtrain,xtest,ytrain,ytest,\n                     \"XGBoost.\")\n\nmodel4 = model_report(knn_classifier,xtrain,xtest,ytrain,ytest,\n                      \"KNN Classifier\")\n\nmodel5 = model_report(NB_classifier,xtrain,xtest,ytrain,ytest,\n                      \"Naive Bayes\")\n\nmodel6 = model_report(DT_classifier,xtrain,xtest,ytrain,ytest,\n                      \"Decision Tree\")\n\nmodel7 = model_report(ADA_classifier,xtrain,xtest,ytrain,ytest,\n                      \"AdaBoost\")\n\n    \nmodel_performances = pd.concat([model1,model4,model6,model5,model2, model3,model7],axis = 0).reset_index()\n\nmodel_performances = model_performances.drop(columns = \"index\",axis =1)\n\ntable  = ff.create_table(np.round(model_performances,4))\n\npy.iplot(table)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Best Model"},{"metadata":{},"cell_type":"markdown","source":"\n<b>From the model metrics summary above we can see that Logistic Regression performed well when considering all the scores as compared to other algorithms. It has the highest f1 score and accuracy. Precision, recall and and roc_auc is also comparable with other algorithms. Hence for our case Logistic Regression performed best."},{"metadata":{},"cell_type":"markdown","source":"# <center> **--End --**</center>"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}