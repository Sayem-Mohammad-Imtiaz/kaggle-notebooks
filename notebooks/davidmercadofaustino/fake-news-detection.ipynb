{"cells":[{"metadata":{"id":"TtmH8FnJc56Q"},"cell_type":"markdown","source":"### Classificador de noticias\n Esse é um projeto que visa por meio de um dataset com a compilação de noticias de diversos meios de comunicação e sendo categorizado pela veracidade das noticias. \n\n Este data set esta no site do Kaggle :https://www.kaggle.com/jruvika/fake-news-detection","execution_count":null},{"metadata":{"id":"xjw8FP85c56U","trusted":true},"cell_type":"code","source":"# Importação de bibliotecas para utilização na Leitura e na manipulação de dados\nimport pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"id":"sox21HKCc56Z"},"cell_type":"markdown","source":"### Carregamento do Data Set","execution_count":null},{"metadata":{"id":"iqhEd8NBc56a","trusted":true},"cell_type":"code","source":"# Carregamento pelo pandas por meio do read CSV\ndf_fake_news = pd.read_csv(\"../input/fake-news-detection/data.csv\")","execution_count":null,"outputs":[]},{"metadata":{"id":"j9IQ9BewG9Az","outputId":"686ac26e-8cd3-415a-bac8-2ddf4962f429","trusted":true},"cell_type":"code","source":"df_fake_news.head(5) ","execution_count":null,"outputs":[]},{"metadata":{"id":"27GcOqPifB99","outputId":"2dcd1e7c-b11e-4979-d36e-4f5fd6a570ad","trusted":true},"cell_type":"code","source":"# Analise da qualidade dos dados importados\ndf_fake_news.describe()","execution_count":null,"outputs":[]},{"metadata":{"id":"MJuo67HHc56i"},"cell_type":"markdown","source":"### Análise Descritiva\nA principio seria analisado o corpo do texto(Body) do Data Frame. Como este possivelmente tem dados faltantes dentro da coluna, foi escolhido a manchete(Headline) para se usar como paramentro da analise.","execution_count":null},{"metadata":{"id":"A3qnxIv0c56j","trusted":true},"cell_type":"code","source":"#Importação do Collection para observar melhor os dados que serão analisados\nfrom collections import Counter","execution_count":null,"outputs":[]},{"metadata":{"id":"-1z5LvN7c56m","outputId":"fb728480-0dd7-48a8-c7e2-f1e3efd6311c","trusted":true},"cell_type":"code","source":"Counter(df_fake_news[\"Label\"])","execution_count":null,"outputs":[]},{"metadata":{"id":"EerwOOf8bIw4","trusted":true},"cell_type":"code","source":"# Alterar os dados da coluna Label para melhor vizualização dos resultados\ndf_fake_news['Label'].replace(1, 'News',regex=True, inplace=True) ","execution_count":null,"outputs":[]},{"metadata":{"id":"Jqu8BjeObut1","trusted":true},"cell_type":"code","source":"df_fake_news['Label'].replace(0, 'Fake News',regex=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"QPw3GDRbcO78","outputId":"23d79eb2-9069-4868-cfeb-1885d88f8da4","trusted":true},"cell_type":"code","source":"Counter(df_fake_news[\"Label\"])","execution_count":null,"outputs":[]},{"metadata":{"id":"eHev_YUGn6RQ"},"cell_type":"markdown","source":"Apesar do numero maior de Fake News foi tomada decisão de continuar sem retirada de elementos do Data Frame, pois a diferença não me pareceu significante para aplicar um drop() em linhas relativas ao Fake News","execution_count":null},{"metadata":{"id":"q7do0TY0c56o"},"cell_type":"markdown","source":"### Limpeza de Dados\nEsta parte é importante quando estamos trabalhando com o Naive Bayes para que ele possa ler os padrões e montar um modelo preditivo.","execution_count":null},{"metadata":{"id":"DP4AWeIKdKcM","outputId":"3b885238-c7f5-41cb-a6f6-a4e7bbe2d03d","trusted":true},"cell_type":"code","source":"#importação do NLTK para ajudar no processamento das informações para o Naive Bayes\nimport nltk\nnltk.download('stopwords')","execution_count":null,"outputs":[]},{"metadata":{"id":"XAtrHp8ZdQew","trusted":true},"cell_type":"code","source":"# Importação das stopwords para fazer a limpeza da coluna Headline\nfrom nltk.corpus import stopwords","execution_count":null,"outputs":[]},{"metadata":{"id":"0PkgGtcsc56s","trusted":true},"cell_type":"code","source":"# Estabelecendo as stopwords em inglês\nlist_stops_words = stopwords.words(\"english\")","execution_count":null,"outputs":[]},{"metadata":{"id":"oHttCGhic56w","trusted":true},"cell_type":"code","source":"df_fake_news[\"Headline\"] = df_fake_news['Headline'].str.lower()","execution_count":null,"outputs":[]},{"metadata":{"id":"cWmEANXyc56y","trusted":true},"cell_type":"code","source":"df_fake_news[\"Headline\"].replace('\\n',' ', regex=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"aV4-DnH9c563"},"cell_type":"markdown","source":"### Separação em Treinamento e Teste\nAgora com os dados já tratados temos que estabelecer as porcentagem de treino o nosso modelo de Maachine Learning","execution_count":null},{"metadata":{"id":"-arttbeOc564","trusted":true},"cell_type":"code","source":"#importação do sklearn para criar modelo de previsão\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(df_fake_news[\"Headline\"], df_fake_news[\"Label\"], \n                                                    test_size=0.30, \n                                                    random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"id":"5Kep5hovtZ74"},"cell_type":"markdown","source":"Foi estabelecido um treinamento com 70% dos dados e fazer testes com 30% dos dados. \n\nEsse treinamento é importante para que o algoritimo possa melhorar sua capacidade preditiva.","execution_count":null},{"metadata":{"id":"Kdm-fCRsc566"},"cell_type":"markdown","source":"### Pipeline Model\nForam exportado o **Pipeline** para melhorar o entendimento do codigo, **Naive Bayes** na sua forma de multinomial, ***Count Vectorizer** que segmentas todas as palavras e conta as frequencia de cada uma e o **Tf Idf** Transformer que diminui o peso das palavras mais frequentes.","execution_count":null},{"metadata":{"id":"nK3unTaXc567","trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer","execution_count":null,"outputs":[]},{"metadata":{"id":"Z5U1i0OCc56-","trusted":true},"cell_type":"code","source":"classify = Pipeline(\n                [('vect', CountVectorizer(stop_words= list_stops_words)), \n                 ('tfidf', TfidfTransformer()),\n                 ('clf', MultinomialNB())\n                 ])","execution_count":null,"outputs":[]},{"metadata":{"id":"3DtJ2rqAc57A","outputId":"87e81676-9d02-45dd-d759-483e16633d46","trusted":true},"cell_type":"code","source":"# treinamento do nosso modelo\nclassify.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"id":"YimZ2Ao6c57C"},"cell_type":"markdown","source":"### Avaliação do Modelo\nAgora temos nosso modelo treinado, medimos a capacidade de predição. Que consegue prever cerca de 83%. O Modelo também foi capaz de prever com precisão muito parecida tanto as Fake News quanto as Noticias verdadeira. Mas podemos ver que o modelo tem uma taxa baixa de recall nas Noticias Verdadeiras, que pode ser por conta da diferença amostral das duas variaveis.","execution_count":null},{"metadata":{"id":"qoQ-6LMAc57D","trusted":true},"cell_type":"code","source":"# Importação do metrics para medir o aprendizado da maquina\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"id":"QIxMVOMvc57G","outputId":"6d7e1274-2dce-4749-a5a4-247add5f6a69","trusted":true},"cell_type":"code","source":"# Medição da precisão do modelo utilizando as amostras\nclassify.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"hxlEhVtZc57I","outputId":"31c9a274-2d65-4100-b17e-206720a17ba2","trusted":true},"cell_type":"code","source":"# Capacidade de predição do modelo\npreds = classify.predict(X_test)\nprint(metrics.classification_report(y_test, preds))","execution_count":null,"outputs":[]},{"metadata":{"id":"7oJw3pJKc57L"},"cell_type":"markdown","source":"### Predição do Modelo\nAgora colocando o modelo para predizer uma Manchete","execution_count":null},{"metadata":{"id":"OIzmw5gJc57L","trusted":true},"cell_type":"code","source":"texto  = \"Trump and his allies respond with pseudo-science as US death toll hits 150,000\"","execution_count":null,"outputs":[]},{"metadata":{"id":"EFwFcXHmc57P","outputId":"8debb9af-114f-4704-85ce-e2fe34082833","trusted":true},"cell_type":"code","source":"# Testando a predição do modelo\nclassify.predict([texto])","execution_count":null,"outputs":[]},{"metadata":{"id":"27bccfOrNxry","outputId":"46c508af-7b3d-4a08-f390-010d877907c2","trusted":true},"cell_type":"code","source":"# Base da decisão pela classificação como News\nclassify.predict_proba([texto])","execution_count":null,"outputs":[]},{"metadata":{"id":"4xWBPaQcPzLB","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}