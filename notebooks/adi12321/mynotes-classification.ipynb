{"cells":[{"metadata":{},"cell_type":"markdown","source":"# My notes for Classification models"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Importing libraries\nimport os\nimport numpy as np\nimport pandas as pd\n#from sklearn.datasets import fetch_mldata, fetch_openml  # to get data for practice.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load data\ntrain=pd.read_csv('/kaggle/input/mnist-in-csv/mnist_train.csv')\ntest=pd.read_csv('/kaggle/input/mnist-in-csv/mnist_test.csv')\ntrain.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t= train.isnull().any()\ncount=0\nfor i in t:\n    if i ==False:\n        count+=1\nprint(count)\n\n#train column count\nprint(len(train.columns))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#row count\nlen(train.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make X and Y\nX_train = train.iloc[:, train.columns != 'label'] #all columns except label\ny_train = train.iloc[:, train.columns == 'label']  #only label column\n\nX_test = test.iloc[:, test.columns !='label']\ny_test = test.iloc[:, test.columns == 'label']\n\nX_train.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### View the image"},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nsample_digit=X_train.iloc[0] #get any row\nsample_digit_image = sample_digit.values.reshape(28,28) #reshape the values\n\nplt.imshow(sample_digit_image, cmap=matplotlib.cm.binary, interpolation='nearest')\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#label for the item is\ny_train.iloc[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#shuffling the dataset so that all kfolds get a good combination of digits\nimport numpy as np\n\nshuffling_index = np.random.permutation(60000) #returns a randomly permuted sequence or permuted range\nprint (shuffling_index)\nX_train,y_train=X_train.iloc[shuffling_index], y_train.iloc[shuffling_index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now do training...\n# Train for 1 digit ... for 'sample_digit' above or '5'\n\ny_train_5 = (y_train==5) #true fro all 5s and false for other digits\ny_test_5 = (y_test==5)\n\n#training with Stochastic Gradient Descent(SGD)\nfrom sklearn.linear_model import SGDClassifier\n\nsgd=SGDClassifier(random_state=1)\nsgd.fit(X_train,y_train_5)\n\nsgd.predict([sample_digit])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cross validation\nfrom sklearn.model_selection import cross_val_score\ncross_val_score(sgd,X_train, y_train_5, cv=3, scoring='accuracy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion matrix\n\nfrom sklearn.model_selection import cross_val_predict\ny_train_pred = cross_val_predict(sgd,X_train, y_train_5, cv=3)\n\nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(y_train_5, y_train_pred)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Confusion Matrix\n\nRows are the actual values\nColumns are predicted values\nP -> positive (for the condition in question)\nNotP ->Not positive (for the condition in question)\n\n||Predict_P|Predict_NotP|\n|:-------:|:-------:|:----------:|\n|**Actual_P**|TruePositive(TP)|FalseNegative(FN)|\n|**Actual_NotP**|FalsePositive(FP)|TrueNegative(TN)|\n\nPrecision = A measure of how many positive predictions were actually positive.\n\n**Precision = TruePositive / (TruePositive + False Positives)**\n\nRecall = A measure of how many actually positive were predicted as Positive.\n\n**Recall = TruePositive/(TruePositive + False Negative)**\n\n\n#### F1 Score\n\nIt is the harmonic mean of precision and recall.  \n\n$F_1 = 2/((1/precision)+(1/recall)) = 2*(precision*recall)/(precision+recall) = TP/(TP+(FN+FP)/2)$"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Precision and Recall\n\nfrom sklearn.metrics import precision_score, recall_score\nprint(precision_score(y_train_5, y_train_pred))\nprint(recall_score(y_train_5, y_train_pred))\n\nfrom sklearn.metrics import f1_score\nprint(f1_score(y_train_5, y_train_pred))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### ROC curve \n\nIt plots the True Positive Rate (TPR/ Recall) Vs False Positive Rate (FPR OR The ratio of negative instances that are classified as positive OR (1-TNR))\n\nTNR (True negative rate) is also called specificity.\n\nContinue from Pg 93 Multiclass Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}