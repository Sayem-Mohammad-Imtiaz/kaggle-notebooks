{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 3. Import libraries and modules\n!pip install git+https://github.com/qubvel/classification_models.git\nfrom classification_models.keras import Classifiers\nimport numpy as np\nnp.random.seed(123)  # for reproducibility\nimport pandas as pd\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten,Embedding\nfrom keras.layers import Convolution2D, MaxPooling2D\nfrom keras.utils import np_utils\nfrom sklearn.model_selection import train_test_split\nfrom matplotlib import pyplot as plt\n!pip install adabelief-tf==0.1.0\nfrom adabelief_tf import AdaBeliefOptimizer\n!pip install keras-rectified-adam\nfrom keras_radam import RAdam\n!pip install keras-adabound\nfrom keras_adabound import AdaBound\n!pip install git+https://github.com/tensorflow/addons\nimport tensorflow_addons\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-09-19T12:25:42.442773Z","iopub.execute_input":"2021-09-19T12:25:42.443158Z","iopub.status.idle":"2021-09-19T12:26:52.599058Z","shell.execute_reply.started":"2021-09-19T12:25:42.443065Z","shell.execute_reply":"2021-09-19T12:26:52.598015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport pandasql as psql\nimport pandas as pd\n\ntrain = pd.read_csv('../input/appliances-energy-prediction/KAG_energydata_complete.csv')\n\n# Drop 'label' column\n\nX_train = train.drop(labels = [\"date\"],axis = 1)\nX_train = X_train.drop(labels = [\"T_out\"],axis = 1)\nX_train = X_train.drop(labels = [\"RH_out\"],axis = 1)\n\nY_train = train[\"RH_out\"]\n# free some space\ndel train \n\n# Split the train and the validation set for the fitting\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=2)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-19T13:44:26.271697Z","iopub.execute_input":"2021-09-19T13:44:26.272128Z","iopub.status.idle":"2021-09-19T13:44:26.49118Z","shell.execute_reply.started":"2021-09-19T13:44:26.272088Z","shell.execute_reply":"2021-09-19T13:44:26.490238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-19T13:44:29.476451Z","iopub.execute_input":"2021-09-19T13:44:29.476765Z","iopub.status.idle":"2021-09-19T13:44:29.495722Z","shell.execute_reply.started":"2021-09-19T13:44:29.476736Z","shell.execute_reply":"2021-09-19T13:44:29.494709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.layers import LSTM,Input\n\nmodel = Sequential()\nmodel.add(Dense(64,input_dim=26,activation ='relu' ))\nmodel.add(Dense(128,input_dim=64,activation ='relu'))\nmodel.add(Dense(256,input_dim=128,activation ='relu'))\nmodel.add(Dense(512,input_dim=256,activation ='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1,activation ='linear'))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-09-19T13:44:57.71627Z","iopub.execute_input":"2021-09-19T13:44:57.716651Z","iopub.status.idle":"2021-09-19T13:44:57.767032Z","shell.execute_reply.started":"2021-09-19T13:44:57.716621Z","shell.execute_reply":"2021-09-19T13:44:57.766212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k = []\nok = 0\nyes = 0\nzet = 0\nyep = 0\n\n\nopt =  [keras.optimizers.Adam(learning_rate=0.001),\n                  keras.optimizers.SGD(learning_rate=0.01),\n                  keras.optimizers.Nadam(learning_rate=0.001),\n                  keras.optimizers.RMSprop(learning_rate=0.001),\n                  AdaBeliefOptimizer(learning_rate=0.001),\n                  RAdam(learning_rate=0.001),\n                  AdaBound(learning_rate=0.001, final_lr=0.1),\n                  tensorflow_addons.optimizers.yogi.Yogi(learning_rate=0.001)]\n        \nfor t in opt:\n    del model\n    #del base_model\n    #del x\n    #del output\n    if (t == opt[0]):\n        print(\"-------------------------------------optimizer = Adam-------------------------------------\")\n    elif (t == opt[1]):\n            print(\"-------------------------------------optimizer = SGD-------------------------------------\")\n    elif (t == opt[2]):\n            print(\"-------------------------------------optimizer = Nadam-------------------------------------\")\n    elif (t == opt[3]):\n            print(\"-------------------------------------optimizer = RMSprop-------------------------------------\")\n    elif (t == opt[4]):\n            print(\"-------------------------------------optimizer = AdaBelief-------------------------------------\")\n    elif (t == opt[5]):\n            print(\"-------------------------------------optimizer = RAdam-------------------------------------\")\n\n    elif (t == opt[6]):\n            print(\"-------------------------------------optimizer = AdaBound-------------------------------------\")\n\n    elif (t == opt[7]):\n            print(\"-------------------------------------optimizer = Yogi-------------------------------------\")\n\n    model = Sequential()\n    model.add(Dense(64,input_dim=26,activation ='relu' ))\n    model.add(Dense(128,input_dim=64,activation ='relu'))\n    model.add(Dense(256,input_dim=128,activation ='relu'))\n    model.add(Dense(512,input_dim=256,activation ='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(1,activation ='linear'))\n  \n    # 8. Compile model\n    model.compile(loss='mean_squared_error',\n              optimizer = t,\n              metrics=['mse'])\n\n\n       # 9. Fit model on training data\n    k.append(model.fit(X_train, Y_train, batch_size=32, epochs=100, validation_data=(X_val, Y_val),verbose=1))\n\n\n\nwhile (ok<len(k)):  \n\n\n\n    plt.figure(figsize=(10,10))\n    plt.plot(k[ok+0].history['mse'],color='b', label=\"opt = Adam\")\n    plt.plot(k[ok+1].history['mse'],color='r', label=\"opt = SGD\")\n    plt.plot(k[ok+2].history['mse'],color='g', label=\"opt = Nadam\")\n    plt.plot(k[ok+3].history['mse'],color='c', label=\"opt = RMSprop\")\n    plt.plot(k[ok+4].history['mse'],color='m', label=\"opt = AdaBelief\")\n    plt.plot(k[ok+5].history['mse'],color='k', label=\"opt = RAdam\")\n    plt.plot(k[ok+6].history['mse'],color='y', label=\"opt = AdaBound\")\n    plt.plot(k[ok+7].history['mse'],color='#A18820', label=\"opt = Yogi\")\n    \n    plt.xlabel('Epochs')\n    plt.ylabel('mse')\n    plt.legend()\n    plt.show() \n\n    ok +=8\n\n\n\n\n\n\n\nwhile (yes<len(k)):   \n\n\n\n    plt.figure(figsize=(10,10))\n    plt.plot(k[yes+0].history['loss'],color='b', label=\"opt = Adam\")\n    plt.plot(k[yes+1].history['loss'],color='r', label=\"opt = SGD\")\n    plt.plot(k[yes+2].history['loss'],color='g', label=\"opt = Nadam\")\n    plt.plot(k[yes+3].history['loss'],color='c', label=\"opt = RMSprop\")\n    plt.plot(k[yes+4].history['loss'],color='m', label=\"opt = AdaBelief\")\n    plt.plot(k[yes+5].history['loss'],color='k', label=\"opt = RAdam\")\n    plt.plot(k[yes+6].history['loss'],color='y', label=\"opt = AdaBound\")\n    plt.plot(k[yes+7].history['loss'],color='#A18820', label=\"opt = Yogi\")\n    \n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.show() \n\n    yes+=8\n\n\n\n\nwhile (zet<len(k)):   \n\n\n\n    plt.figure(figsize=(10,10))\n    plt.plot(k[zet+0].history['val_mse'],color='b', label=\"opt = Adam\")\n    plt.plot(k[zet+1].history['val_mse'],color='r', label=\"opt = SGD\")\n    plt.plot(k[zet+2].history['val_mse'],color='g', label=\"opt = Nadam\")\n    plt.plot(k[zet+3].history['val_mse'],color='c', label=\"opt = RMSprop\")\n    plt.plot(k[zet+4].history['val_mse'],color='m', label=\"opt = AdaBelief\")\n    plt.plot(k[zet+5].history['val_mse'],color='k', label=\"opt = RAdam\")\n    plt.plot(k[zet+6].history['val_mse'],color='y', label=\"opt = AdaBound\")\n    plt.plot(k[zet+7].history['val_mse'],color='#A18820', label=\"opt = Yogi\")\n    \n    plt.xlabel('Epochs')\n    plt.ylabel('val_mse')\n    plt.legend()\n    plt.show() \n\n    zet+=8\n\n\n\n\n\nwhile (yep<len(k)):   \n\n\n\n    plt.figure(figsize=(10,10))\n    plt.plot(k[yep+0].history['val_loss'],color='b', label=\"opt = Adam\")\n    plt.plot(k[yep+1].history['val_loss'],color='r', label=\"opt = SGD\")\n    plt.plot(k[yep+2].history['val_loss'],color='g', label=\"opt = Nadam\")\n    plt.plot(k[yep+3].history['val_loss'],color='c', label=\"opt = RMSprop\")\n    plt.plot(k[yep+4].history['val_loss'],color='m', label=\"opt = AdaBelief\")\n    plt.plot(k[yep+5].history['val_loss'],color='k', label=\"opt = RAdam\")\n    plt.plot(k[yep+6].history['val_loss'],color='y', label=\"opt = AdaBound\")\n    plt.plot(k[yep+7].history['val_loss'],color='#A18820', label=\"opt = Yogi\")\n    \n    plt.xlabel('Epochs')\n    plt.ylabel('val_loss')\n    plt.legend()\n    plt.show() \n\n    yep+=8","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-19T13:45:02.911012Z","iopub.execute_input":"2021-09-19T13:45:02.911367Z","iopub.status.idle":"2021-09-19T14:13:20.066254Z","shell.execute_reply.started":"2021-09-19T13:45:02.911328Z","shell.execute_reply":"2021-09-19T14:13:20.065374Z"},"trusted":true},"execution_count":null,"outputs":[]}]}