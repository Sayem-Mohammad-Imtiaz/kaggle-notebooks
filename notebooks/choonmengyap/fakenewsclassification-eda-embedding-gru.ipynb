{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Supervised ML - Predicting fake news using only titles","metadata":{}},{"cell_type":"code","source":"import pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt\n\nfrom nltk.stem import PorterStemmer\nimport re\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n# from wordcloud import WordCloud ##### Deprecated\n\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2021-07-02T10:20:14.567327Z","iopub.execute_input":"2021-07-02T10:20:14.567753Z","iopub.status.idle":"2021-07-02T10:20:22.498574Z","shell.execute_reply.started":"2021-07-02T10:20:14.567662Z","shell.execute_reply":"2021-07-02T10:20:22.497508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/source-based-news-classification/news_articles.csv')\ndata","metadata":{"execution":{"iopub.status.busy":"2021-07-02T10:20:22.500733Z","iopub.execute_input":"2021-07-02T10:20:22.501076Z","iopub.status.idle":"2021-07-02T10:20:22.880131Z","shell.execute_reply.started":"2021-07-02T10:20:22.501043Z","shell.execute_reply":"2021-07-02T10:20:22.878587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data.dropna(axis=0)\ndata","metadata":{"execution":{"iopub.status.busy":"2021-07-02T10:20:22.88228Z","iopub.execute_input":"2021-07-02T10:20:22.882692Z","iopub.status.idle":"2021-07-02T10:20:22.939135Z","shell.execute_reply.started":"2021-07-02T10:20:22.882651Z","shell.execute_reply":"2021-07-02T10:20:22.937886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analysis\n- We'll explore how frequent some words appear in the titles","metadata":{}},{"cell_type":"code","source":"def get_top_n_words(corpus, n = None):\n    \"\"\"\n    A function that returns the top 'n' unigrams used in the corpus\n    \"\"\"\n    vec = CountVectorizer().fit(corpus)\n    bag_of_words = vec.transform(corpus) ## Shape: (2045, 46774) -> There are 2045 sentences and 46774 words\n    sum_words = bag_of_words.sum(axis=0) ## Shape: (1, 46774) -> Count of occurance of each word\n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()] ## vec.vocabulary_.items returns the dictionary with (word, index)\n    freq_sorted = sorted(words_freq, key = lambda x: x[1], reverse = True)\n    return freq_sorted[:n]\n\ndef get_top_n_bigram(corpus, n = None):\n    \"\"\"\n    A function that returns the top 'n' bigrams used in the corpus\n    \"\"\"\n    vec = CountVectorizer(ngram_range = (2, 2)).fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis = 0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    freq_sorted = sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return freq_sorted[:n]","metadata":{"execution":{"iopub.status.busy":"2021-07-02T10:20:22.941326Z","iopub.execute_input":"2021-07-02T10:20:22.941805Z","iopub.status.idle":"2021-07-02T10:20:22.953802Z","shell.execute_reply.started":"2021-07-02T10:20:22.941744Z","shell.execute_reply":"2021-07-02T10:20:22.952444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top_unigram = get_top_n_words(data['title_without_stopwords'], 20)\nwords_unigram = [i[0] for i in top_unigram]\ncount_unigram = [i[1] for i in top_unigram]\n\ntop_bigram = get_top_n_bigram(data['text_without_stopwords'], 20)\nwords_bigram = [i[0] for i in top_bigram]\ncount_bigram = [i[1] for i in top_bigram]","metadata":{"execution":{"iopub.status.busy":"2021-07-02T10:20:22.955702Z","iopub.execute_input":"2021-07-02T10:20:22.956398Z","iopub.status.idle":"2021-07-02T10:20:27.533918Z","shell.execute_reply.started":"2021-07-02T10:20:22.956352Z","shell.execute_reply":"2021-07-02T10:20:27.532799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot bar charts for top unigrams\nfont_title = {'family': 'sans serif',\n        'color':  'white',\n        'weight': 'bold',\n        'size': 16,\n        }\nfont_text = {'family': 'sans serif',\n        'color':  'white',\n        'weight': 'bold',\n        'size': 12,\n        }\n\nwith plt.style.context(\"dark_background\"):\n    fig, ax = plt.subplots(figsize=(14,4))\n    bar = ax.bar(words_unigram, count_unigram, color='#6baed6')\n    ax.set_title(\"Top Unigrams\", fontdict=font_title, size=16)\n    ax.set_xticklabels(words_unigram, fontdict=font_text, rotation=90)\n    ax.grid(axis='y')","metadata":{"execution":{"iopub.status.busy":"2021-07-02T10:20:27.535444Z","iopub.execute_input":"2021-07-02T10:20:27.535908Z","iopub.status.idle":"2021-07-02T10:20:27.831938Z","shell.execute_reply.started":"2021-07-02T10:20:27.535864Z","shell.execute_reply":"2021-07-02T10:20:27.830764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot bar charts for top bigrams\nwith plt.style.context(\"dark_background\"):\n    fig, ax = plt.subplots(figsize=(14,4))\n    bar = ax.bar(words_bigram, count_bigram, color='#a1dab4')\n    ax.set_title(\"Top Unigrams\", fontdict=font_title, size=16)\n    ax.set_xticklabels(words_bigram, fontdict=font_text, rotation=90)\n    ax.grid(axis='y')","metadata":{"execution":{"iopub.status.busy":"2021-07-02T10:20:27.833193Z","iopub.execute_input":"2021-07-02T10:20:27.833489Z","iopub.status.idle":"2021-07-02T10:20:28.107959Z","shell.execute_reply.started":"2021-07-02T10:20:27.83346Z","shell.execute_reply":"2021-07-02T10:20:28.106656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualising frequency of words using WordCloud package\nfrom wordcloud import WordCloud\n\nwc = WordCloud(background_color=\"black\", max_words=100,\n               max_font_size=256,\n               random_state=42, width=1000, height=1000)\nwc.generate(' '.join(data['text_without_stopwords']))\nplt.imshow(wc, interpolation=\"bilinear\")\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-02T10:20:28.111535Z","iopub.execute_input":"2021-07-02T10:20:28.111951Z","iopub.status.idle":"2021-07-02T10:20:35.78604Z","shell.execute_reply.started":"2021-07-02T10:20:28.111917Z","shell.execute_reply":"2021-07-02T10:20:35.785171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Visualising the fake and real news percentage\nimport math\ndifferent_labels = data['label'].unique()\ncounts = data['label'].value_counts().values\n\nplt.figure(figsize=(6,6))\nplt.pie(counts, labels=['Fake', 'Real'], autopct='%1.1f%%')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-07-02T10:20:49.055064Z","iopub.execute_input":"2021-07-02T10:20:49.055453Z","iopub.status.idle":"2021-07-02T10:20:49.216298Z","shell.execute_reply.started":"2021-07-02T10:20:49.055416Z","shell.execute_reply":"2021-07-02T10:20:49.215289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing\n- Since the dataset already contained title without stopwords, we would do stemming, tokenisation and padding to produce a sequence of numbers to feed into our ML model later","metadata":{}},{"cell_type":"code","source":"titles_stopped = data['title_without_stopwords']\ntitles_stopped.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-02T10:21:07.084535Z","iopub.execute_input":"2021-07-02T10:21:07.084909Z","iopub.status.idle":"2021-07-02T10:21:07.093374Z","shell.execute_reply.started":"2021-07-02T10:21:07.084875Z","shell.execute_reply":"2021-07-02T10:21:07.092279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ps = PorterStemmer()\nps","metadata":{"execution":{"iopub.status.busy":"2021-07-02T10:21:07.517504Z","iopub.execute_input":"2021-07-02T10:21:07.517884Z","iopub.status.idle":"2021-07-02T10:21:07.523272Z","shell.execute_reply.started":"2021-07-02T10:21:07.517852Z","shell.execute_reply":"2021-07-02T10:21:07.522596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ps.stem(\"roasted\")","metadata":{"execution":{"iopub.status.busy":"2021-07-02T10:21:07.96937Z","iopub.execute_input":"2021-07-02T10:21:07.969709Z","iopub.status.idle":"2021-07-02T10:21:07.976409Z","shell.execute_reply.started":"2021-07-02T10:21:07.96968Z","shell.execute_reply":"2021-07-02T10:21:07.975177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_title(title):\n    new_title = title.split(\" \")\n    new_title = list(map(lambda x: ps.stem(x), new_title))\n    new_title = list(map(lambda x: x.strip(), new_title))\n    if '' in new_title:\n        new_title.remove('')\n    return new_title","metadata":{"execution":{"iopub.status.busy":"2021-07-02T10:21:08.16651Z","iopub.execute_input":"2021-07-02T10:21:08.16693Z","iopub.status.idle":"2021-07-02T10:21:08.172826Z","shell.execute_reply.started":"2021-07-02T10:21:08.166895Z","shell.execute_reply":"2021-07-02T10:21:08.171273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"titles_stemmed = titles_stopped.apply(process_title)\ntitles_stemmed","metadata":{"execution":{"iopub.status.busy":"2021-07-02T10:21:08.333569Z","iopub.execute_input":"2021-07-02T10:21:08.334153Z","iopub.status.idle":"2021-07-02T10:21:08.784501Z","shell.execute_reply.started":"2021-07-02T10:21:08.334102Z","shell.execute_reply":"2021-07-02T10:21:08.783483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get size of vocabulary\nvocabulary = set()\n\nfor title in titles_stemmed:\n    for word in title:\n        if word not in vocabulary:\n            vocabulary.add(word)\n\nvocab_length = len(vocabulary)\n\n# Get max length of a sequence\nmax_seq_length = 0\nfor title in titles_stemmed:\n    if len(title) > max_seq_length:\n        max_seq_length = len(title)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T10:21:08.785729Z","iopub.execute_input":"2021-07-02T10:21:08.78618Z","iopub.status.idle":"2021-07-02T10:21:08.795532Z","shell.execute_reply.started":"2021-07-02T10:21:08.786135Z","shell.execute_reply":"2021-07-02T10:21:08.79479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Viewing the words that have been added to our vocabulary\nimport more_itertools\nmore_itertools.take(10, vocabulary)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T10:21:08.796978Z","iopub.execute_input":"2021-07-02T10:21:08.797387Z","iopub.status.idle":"2021-07-02T10:21:08.819231Z","shell.execute_reply.started":"2021-07-02T10:21:08.797345Z","shell.execute_reply":"2021-07-02T10:21:08.817835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab_length","metadata":{"execution":{"iopub.status.busy":"2021-07-02T10:21:08.820572Z","iopub.execute_input":"2021-07-02T10:21:08.820936Z","iopub.status.idle":"2021-07-02T10:21:08.82714Z","shell.execute_reply.started":"2021-07-02T10:21:08.820892Z","shell.execute_reply":"2021-07-02T10:21:08.826087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_seq_length","metadata":{"execution":{"iopub.status.busy":"2021-07-02T10:21:08.881819Z","iopub.execute_input":"2021-07-02T10:21:08.882188Z","iopub.status.idle":"2021-07-02T10:21:08.887356Z","shell.execute_reply.started":"2021-07-02T10:21:08.882157Z","shell.execute_reply":"2021-07-02T10:21:08.886661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tokenising and padding our sequences\ntokenizer = Tokenizer(num_words=vocab_length)\ntokenizer.fit_on_texts(titles_stemmed)\n\nsequences = tokenizer.texts_to_sequences(titles_stemmed)\n\nword_index = tokenizer.word_index\n\nmodel_inputs = pad_sequences(sequences, maxlen=max_seq_length)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T10:21:08.986659Z","iopub.execute_input":"2021-07-02T10:21:08.987236Z","iopub.status.idle":"2021-07-02T10:21:09.040686Z","shell.execute_reply.started":"2021-07-02T10:21:08.987178Z","shell.execute_reply":"2021-07-02T10:21:09.039691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Viewing the sequences converted from the titles\nsequences[:10]","metadata":{"execution":{"iopub.status.busy":"2021-07-02T10:21:09.101838Z","iopub.execute_input":"2021-07-02T10:21:09.102353Z","iopub.status.idle":"2021-07-02T10:21:09.115157Z","shell.execute_reply.started":"2021-07-02T10:21:09.10231Z","shell.execute_reply":"2021-07-02T10:21:09.113723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Viewing the words mapped to tokens, with 1 being the most frequent word\nimport more_itertools\nmore_itertools.take(10, word_index.items())","metadata":{"execution":{"iopub.status.busy":"2021-07-02T10:21:09.211068Z","iopub.execute_input":"2021-07-02T10:21:09.211579Z","iopub.status.idle":"2021-07-02T10:21:09.217817Z","shell.execute_reply.started":"2021-07-02T10:21:09.211546Z","shell.execute_reply":"2021-07-02T10:21:09.216879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Viewing the effect of padding the sequences\nmodel_inputs","metadata":{"execution":{"iopub.status.busy":"2021-07-02T10:21:09.332734Z","iopub.execute_input":"2021-07-02T10:21:09.333334Z","iopub.status.idle":"2021-07-02T10:21:09.338344Z","shell.execute_reply.started":"2021-07-02T10:21:09.333287Z","shell.execute_reply":"2021-07-02T10:21:09.337616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_inputs.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-02T10:21:09.467793Z","iopub.execute_input":"2021-07-02T10:21:09.468282Z","iopub.status.idle":"2021-07-02T10:21:09.473249Z","shell.execute_reply.started":"2021-07-02T10:21:09.468253Z","shell.execute_reply":"2021-07-02T10:21:09.47233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['label'].unique()","metadata":{"execution":{"iopub.status.busy":"2021-07-02T10:21:09.580721Z","iopub.execute_input":"2021-07-02T10:21:09.581138Z","iopub.status.idle":"2021-07-02T10:21:09.588364Z","shell.execute_reply.started":"2021-07-02T10:21:09.581106Z","shell.execute_reply":"2021-07-02T10:21:09.587075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = np.array(data['label'].map(dict(Real=0, Fake=1)))\nlabels","metadata":{"execution":{"iopub.status.busy":"2021-07-02T10:21:09.704901Z","iopub.execute_input":"2021-07-02T10:21:09.705251Z","iopub.status.idle":"2021-07-02T10:21:09.712485Z","shell.execute_reply.started":"2021-07-02T10:21:09.705223Z","shell.execute_reply":"2021-07-02T10:21:09.711829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(model_inputs, labels, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T10:21:09.967534Z","iopub.execute_input":"2021-07-02T10:21:09.967925Z","iopub.status.idle":"2021-07-02T10:21:09.973821Z","shell.execute_reply.started":"2021-07-02T10:21:09.967891Z","shell.execute_reply":"2021-07-02T10:21:09.972671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('shape of X_train:', X_train.shape)\nprint('shape of y_train:', y_train.shape)\nprint('shape of X_test:', X_test.shape)\nprint('shape of y_test:', y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T10:21:10.097856Z","iopub.execute_input":"2021-07-02T10:21:10.09824Z","iopub.status.idle":"2021-07-02T10:21:10.105809Z","shell.execute_reply.started":"2021-07-02T10:21:10.098209Z","shell.execute_reply":"2021-07-02T10:21:10.104386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"execution":{"iopub.status.busy":"2021-07-02T10:21:10.215345Z","iopub.execute_input":"2021-07-02T10:21:10.21568Z","iopub.status.idle":"2021-07-02T10:21:10.22238Z","shell.execute_reply.started":"2021-07-02T10:21:10.215651Z","shell.execute_reply":"2021-07-02T10:21:10.22109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test","metadata":{"execution":{"iopub.status.busy":"2021-07-02T10:21:10.344173Z","iopub.execute_input":"2021-07-02T10:21:10.344508Z","iopub.status.idle":"2021-07-02T10:21:10.353188Z","shell.execute_reply.started":"2021-07-02T10:21:10.34448Z","shell.execute_reply":"2021-07-02T10:21:10.351889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_dim = 64\n\ninputs = tf.keras.Input(shape=(max_seq_length,))\n\nembedding = tf.keras.layers.Embedding(\n    input_dim=vocab_length,\n    output_dim=embedding_dim,\n    input_length=max_seq_length,\n)(inputs)\n\ngru = tf.keras.layers.GRU(units=embedding_dim)(embedding)\n\noutputs = tf.keras.layers.Dense(1, activation='sigmoid')(gru)\n\nmodel = tf.keras.Model(inputs, outputs)\n\nmodel.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=[\n        'accuracy',\n        tf.keras.metrics.AUC(name='auc')\n    ]\n)\n\nbatch_size = 16\nepochs = 5\n\nhistory = model.fit(\n    X_train,\n    y_train,\n    validation_split=0.2,\n    batch_size=batch_size,\n    epochs=epochs,\n    callbacks=[\n        tf.keras.callbacks.ReduceLROnPlateau(),\n        tf.keras.callbacks.ModelCheckpoint('model.h5', save_best_only=True)\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T10:21:10.485195Z","iopub.execute_input":"2021-07-02T10:21:10.48553Z","iopub.status.idle":"2021-07-02T10:21:23.290653Z","shell.execute_reply.started":"2021-07-02T10:21:10.485501Z","shell.execute_reply":"2021-07-02T10:21:23.289672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(2, figsize=(10,6))\nax1.plot(history.history['val_loss'])\nax1.plot(history.history['loss'])\nax2.plot(history.history['val_auc'])\nax2.plot(history.history['auc'])\n\nax1.legend(['val_loss', 'loss'])\nax2.legend(['val_auc', 'auc'])\nax1.set_title('Loss Over Time')\nax2.set_title('AUC Over Time')\nax1.set(xlabel='Epoch', ylabel='Loss')\nax2.set(xlabel='Epoch', ylabel='AUC')\n\nfig.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-07-02T10:21:23.29239Z","iopub.execute_input":"2021-07-02T10:21:23.292729Z","iopub.status.idle":"2021-07-02T10:21:23.713254Z","shell.execute_reply.started":"2021-07-02T10:21:23.292696Z","shell.execute_reply":"2021-07-02T10:21:23.712026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history.history","metadata":{"execution":{"iopub.status.busy":"2021-07-02T10:21:23.715032Z","iopub.execute_input":"2021-07-02T10:21:23.715323Z","iopub.status.idle":"2021-07-02T10:21:23.722066Z","shell.execute_reply.started":"2021-07-02T10:21:23.715295Z","shell.execute_reply":"2021-07-02T10:21:23.72103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights('./model.h5')","metadata":{"execution":{"iopub.status.busy":"2021-07-02T10:21:23.723514Z","iopub.execute_input":"2021-07-02T10:21:23.723935Z","iopub.status.idle":"2021-07-02T10:21:23.743912Z","shell.execute_reply.started":"2021-07-02T10:21:23.723903Z","shell.execute_reply":"2021-07-02T10:21:23.742691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T10:21:23.745132Z","iopub.execute_input":"2021-07-02T10:21:23.745449Z","iopub.status.idle":"2021-07-02T10:21:24.411131Z","shell.execute_reply.started":"2021-07-02T10:21:23.745418Z","shell.execute_reply":"2021-07-02T10:21:24.410115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Discussion\n-   The final result is an accuracy of about 67%. The results could be further improved if the texts of the articles are used, even better is we could append the texts to the titles and processed it altogether.\n\n-   Further work can look at using LIME or SHAP values to explain how the model has identified what words would carry more weightings to classify whether a news article is real or fake.","metadata":{}}]}