{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# Libraries\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import iplot\n\nimport scipy\nfrom scipy import stats\nfrom sklearn.preprocessing import LabelEncoder\n\nsns.set_palette('RdBu')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<center><h1> IBM HR analysis</h1></center>"},{"metadata":{},"cell_type":"markdown","source":"<center>![alkir/Thinkstock](https://compote.slate.com/images/75d251f2-6d54-4839-bfb1-96f40b237ef4.jpg) </center>"},{"metadata":{},"cell_type":"markdown","source":"## Introduction\n\nHello everyone,  this notebook is an assignment in CBD Robotics internship, in order to exploit my basic acknowledge.\n\n***The assignment concludes 2 main parts.***  \n#### First, show off fundamental EDA skills, include:  \n * Visulization with matplotlib.pyplot, seaborn, and plotly\n * Missing value treatment with isnull()..\n * pd.DataFrame's methods: info(), describe(), head(), tail()..  \n\n#### Second, statistically questions:\n * Which key factors influence attrition rates?\n * Which key factors influence satisfaction rates?\n\nAlso, the statistics  must use ***following testing***:\n * T-test  \n * ANOVA and MANOVA\n * Correlation calculation in Pearman method."},{"metadata":{},"cell_type":"markdown","source":"# Table of Contents\n\n1. Take a look at the dataset\n2. Missing data\n3. Descriptive statistic\n4. EDA\n5. Statistic Tesing\n * Which key factors to Attrition?\n * Which key factors to Job Satisfaction?\n6. Final verdict\n7. My potential mistakes"},{"metadata":{},"cell_type":"markdown","source":"# 1. Take a look"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"scrolled":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/ibm-hr-analytics-attrition-dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Observations                                   : ', df.shape[0])\nprint('Features -- exclude Attrition and Satisfication: ', df.shape[1] - 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Missing data\n\nI ran isnull(), read data desciption, manually look for any kind of missing data. There is no NaN nor any type of missing data in this set.  \n\n*** This dataset is way so clean.***"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Nan data points: ', df.isnull().sum().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Descriptive statistic"},{"metadata":{},"cell_type":"markdown","source":"Both Attrition and JobSafisfaction are categorical, so there is just small room for descriptive statistic here, which is: ***count*** and ***percentage***."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Attrition.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Attrition.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.JobSatisfaction.describe(percentiles=[0.01, 0.45, 0.90])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"# The big picture\nfig = make_subplots(rows=1, cols=2,\n                   specs=[[{\"type\": \"bar\"}, {\"type\": \"domain\"}]])\n\n# Sketch smaller details\ntrace0 = go.Histogram(x=df['Attrition'], name='In number', marker={'color':['red', 'blue']},\n                     showlegend=False)\ntrace1 = go.Pie(values=df['Attrition'].value_counts(), name='Percentage', labels=['No', 'Yes'],\n               textinfo='label+percent')\n\n# Add traces\nfig.append_trace(trace0, 1, 1)\nfig.append_trace(trace1, 1, 2)\n\n# Customize\nfig.update(layout_title_text='<b> Attrition </b>')\nfig.update_layout(showlegend=False)\n\n# Done\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The big picture\nfig = make_subplots(rows=3, cols=2,\n                   specs=[[{'rowspan':3}, {\"type\": \"domain\"}],\n                          [None,          {\"type\": \"domain\"}],\n                          [None,          {\"type\": \"domain\"}]])\n\n# Sketch smaller details\n\n## The bar chart - with Yes = negative columns.\nlabels = ['R&D', 'Sales', 'HR']\n\nyes = df['Department'][df.Attrition=='Yes'].value_counts()\ntrace_yes = go.Bar(x=labels, y=-yes, marker={'color':'red'}, showlegend=False) \n\nno  = df['Department'][df.Attrition=='No'].value_counts()\ntrace_no  = go.Bar(x=labels, y=no, marker={'color':'blue'}, showlegend=False )\n\n## Pie 1 -- upper right\nRD = df['Attrition'][df.Department=='Research & Development'].value_counts()\ntrace_3   = go.Pie(labels=['No', 'Yes'], values=RD, name='RD')\n\n## Pie 2\nSales = df['Attrition'][df.Department=='Sales'].value_counts()\ntrace_4   = go.Pie(labels=['No', 'Yes'], values=Sales, name='Sales')\n\n## Pie 3\nHR = df['Attrition'][df.Department=='Human Resources'].value_counts()\ntrace_5   = go.Pie(labels=['No', 'Yes'], values=HR, name='HR')\n\n# Add traces\nfig.append_trace(trace_yes, 1, 1)\nfig.append_trace(trace_no, 1, 1)\n\nfig.append_trace(trace_3, 1, 2)\nfig.append_trace(trace_4, 2, 2)\nfig.append_trace(trace_5, 3, 2)\n\n# Customize\nfig.update(layout_title_text='<b> Attrition by Department </b>')\n\n# Done\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.box(df, y='MonthlyIncome', x='Gender', color='Gender', \n             points='all', \n             color_discrete_map={'Female':'red', 'Male':'Green'})\n\nfig.update(layout_title_text='<b> Monthly Income by Gender </b>')\nfig.update_layout(showlegend=False)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The big picture\nfig = make_subplots(rows=6, cols=2,\n                   specs=[[{'rowspan':6}, {\"type\": \"domain\"}], # 1  --  1\n                          [None,          {\"type\": \"domain\"}], # 0  --  2\n                          [None,          {\"type\": \"domain\"}], # 0  --  3\n                          [None,          {\"type\": \"domain\"}], # 0  --  4\n                          [None,          {\"type\": \"domain\"}], # 0  --  5\n                          [None,          {\"type\": \"domain\"}]])# 0  --  6\n\n# Sketching\n## Bar chart\nlabels=['Life Sciences', 'Medical','Marketing', 'Technical Degree', 'Other', 'Human Resources']\n\nyes = df['EducationField'][df.Attrition=='Yes'].value_counts(ascending=False)\nno = df['EducationField'][df.Attrition=='No'].value_counts(ascending=False)\n\nfig.add_bar(y=-yes, x=labels, col=1, row=1, marker={'color':'red'},  showlegend=False)\nfig.add_bar(y=no,   x=labels, col=1, row=1, marker={'color':'blue'}, showlegend=False)\n\n## Pie chart\nLS     = df['Attrition'][df.EducationField=='Life Sciences'].value_counts()\nMed    = df['Attrition'][df.EducationField=='Medical'].value_counts()\nMar    = df['Attrition'][df.EducationField=='Marketing'].value_counts()\nTech   = df['Attrition'][df.EducationField=='Technical Degree'].value_counts()\nOther  = df['Attrition'][df.EducationField=='Other'].value_counts()\nHR     = df['Attrition'][df.EducationField=='Human Resources'].value_counts()\n\nfig.add_pie(labels=['No', 'Yes'], values=LS,    name='LS',    col=2, row=1)\nfig.add_pie(labels=['No', 'Yes'], values=Med,   name='Med',   col=2, row=2)\nfig.add_pie(labels=['No', 'Yes'], values=Mar,   name='Mar',   col=2, row=3)\nfig.add_pie(labels=['No', 'Yes'], values=Tech,  name='Tech',  col=2, row=4)\nfig.add_pie(labels=['No', 'Yes'], values=Other, name='Other', col=2, row=5)\nfig.add_pie(labels=['No', 'Yes'], values=HR,    name='HR',    col=2, row=6)\n\n# Customize\nfig.update(layout_title_text='<b> Attrition by Education Field </b>')\n# Done\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = make_subplots(rows=2, cols=2)\n\ntrace0 = go.Histogram(x=df['Department'], y=df['JobSatisfaction'], histfunc='avg')\ntrace1 = go.Histogram(x=df['EducationField'], y=df['JobSatisfaction'], histfunc='avg')\ntrace2 = go.Histogram(x=df['OverTime'], y=df['JobSatisfaction'], histfunc='avg')\ntrace3 = go.Histogram(x=df['MaritalStatus'], y=df['JobSatisfaction'], histfunc='avg')\n\nfig.add_trace(trace0, 1, 1)\nfig.add_trace(trace1, 1, 2)\nfig.add_trace(trace2, 2, 1)\nfig.add_trace(trace3, 2, 2)\n#fig = px.histogram(df, x='Department', y='JobSatisfaction',  histfunc='avg')\n\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.FacetGrid(data=df, row = 'Attrition', col = 'JobSatisfaction')\ng.map(plt.hist, 'MonthlyIncome', bins=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x='EducationField', y='MonthlyIncome',  data=df,\n           kind='violin')\nplt.xticks(rotation=45)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='DistanceFromHome', data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# DistanceFromHome -- Attrition\nsns.catplot(x='Attrition', y='DistanceFromHome', data=df,\n           kind='box')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.histogram(df, x='JobSatisfaction', color='JobSatisfaction')\n\nfig.update_layout(title='<b> JobSatisfaction </b>',\n                  xaxis={'tickmode': 'array',\n                         'tickvals': [1, 2, 3, 4]})\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Statistic Tesing\n"},{"metadata":{},"cell_type":"markdown","source":"## My thoughts\n\n### The questions:\n * Which key factors influence attrition rates?\n * Which key factors influence satisfaction rates?\n\n### I am thinking\n\n1. ***I have not known any how-influence measure.*** I have several basic tools of hypothesis testing: t-test, ANOVA and MANOVA, but none of them directly returns whether this influences that, just giving statistic testing of mean, variance, and so on.  \n\n So, I paraphrase questions which key factors influence become: In the population of feature A (ex: MonthlyIncome), *** whether Yes-Attrition mean is statiscal different from No-Attrition mean?  ***\nIf the differences are significant, we conclusion this features **influences** the attrition rate.\n\n\n2. ***T-test downside is only working with every pair of variable***. One variable must be our target, Attrition or Satisfaction, the underconsidering features would be the other one. Therefore, it is impossible to directly apply t-test across all of features.  \n\n So, I make a work around. ***For *feature* in *all features*, does this feature influence Attrition or Satisfication***. Then each pair will outputs a conclusion.\n\n\n3. ***ANOVA and MANOVA have drawbacks, too.*** While put a set of features under the test, they can not tell specifically which one differs from which one. They give an alert that something wrong happen, that's all.  \n\n \n4. ***The correlation, as this measure is tailored for examining the relationship between numerical variables,*** so I would save it for *** Job Satisfication*** and its relationships.\n\nThe mention of correlation measure and numerical variables reminds to a crucial issue: datatypes. ***Which tests are suitable to apply with different datatypes?*** I will propose a solution right later.\n\n\n\n\n    "},{"metadata":{},"cell_type":"markdown","source":"## Determining statistic methods according to datatypes\n\nTo select the suitable methods, we need to answer two major questions:\n* What is **datatype** of the **target**?  \n* What is **datatype** of the **feature**?  \n\nThe below diagram will give us the answers.\n\n![Workflow.jpg](https://www.upsieutoc.com/images/2020/04/13/Workflow.jpg)\n "},{"metadata":{},"cell_type":"markdown","source":"## Which features should be analyzed?  \n\nHaving know how to choose statistic methods due to the filter, now I have to pick out a number of features put in it.  \n\n***Running tests throughout all features is not necessary.*** If this notebook were a business project, it would be a must absolutely. However, the assignment is not a business but aiming to help to  get familiar with hypothesis testing, so I do not.\n\n\nBesides, I want to know if my answers are corrent, so the analyzing features should consist:\n * ***True positive*** - features really affect Attrition and Satisfaction.\n * ***True negative*** - features do not. \n * ***the Unknown*** - clueless, for my exploration.\n\nAlso, ***None of T-test nor ANOVA*** can handle pairs of ***a categorical target and a non-binary categorical features***, so I intently will not choose this kind of pair.\n"},{"metadata":{},"cell_type":"markdown","source":"## Which features should be analyzed?  \n\n### For the Attrition\n*** True Positives *** are choosen according to [Attrition in an Organization || Why Workers Quit?](https://www.kaggle.com/janiobachmann/attrition-in-an-organization-why-workers-quit), there are:\n* Over Time\n* Monthly Income\n* Age. \n\n*** True Negatives *** should be:\n* Distance From Home\n* Total Working Years \n* Martial Status.\n\n*** The Unknown *** are:\n* Job Level, Num Companies Worked, Years Since Last Promotion,  \n* Years With Curr Manager, Training Times Last Year, Monthly Rate  \n* Education, Percent Salary Hike.\n\n### For Job Satisfication\nThe features are ***exactly the same*** without any clue of which True Positive, True Negative, or the Unknown is."},{"metadata":{"trusted":true},"cell_type":"code","source":"features_to_analysis =      ['OverTime',         'MonthlyIncome',         'Age',\n                             'DistanceFromHome', 'TotalWorkingYears',     'MaritalStatus',\n                             'JobLevel',         'NumCompaniesWorked',    'YearsSinceLastPromotion',\n                             'MonthlyRate',      'TrainingTimesLastYear', 'YearsWithCurrManager',\n                             'Education',        'PercentSalaryHike']\nfeatures_to_analysis.sort()\nprint(features_to_analysis)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1. Datatypes of Features"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# Create table of feature datatypes.\ntable_datatypes = pd.DataFrame(columns=['Features', 'Datatype'])\n\n# 1st column: Features\ntable_datatypes['Features'] = features_to_analysis\n\n# 2nd column: Datatypes\ntable_datatypes['Datatype'] = [df[feature].dtypes for feature in features_to_analysis]\n\nprint(table_datatypes)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above table classifies:\n * *** Binary categories:*** OverTime -> needed to encode to 0 - 1 format.\n * *** Trinary categories: *** MaritalStatus -> ANOVA could be appropriate.\n * *** Nominal:*** Education and JobLevel -> should be considered numerical.\n * *** Numerical:*** All the rest. \n "},{"metadata":{},"cell_type":"markdown","source":"### 2. Preprocessing features"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# Binary encoding: MaritalStatus and OverTime:\nlb = LabelEncoder()\n\ndf['MaritalStatus_encoded'] = lb.fit_transform(df['MaritalStatus']).astype(int)\ndf['OverTime_encoded'] = lb.fit_transform(df['OverTime']).astype(int)\n\n# Origins replaced by encoded\nfeatures_to_analysis = ['MaritalStatus_encoded' if x=='MaritalStatus' else x for x in features_to_analysis]\nfeatures_to_analysis = ['OverTime_encoded' if x=='OverTime' else x for x in features_to_analysis]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. The Filter suggests methods based on Datatypes\n\nLet's drop targets and features down the filter, we will find the way.\n\n#### Attrition: a binary category, so:\n * All the Features to analysis: using Hypothesis testing, includes MaritalStatus and Overtime which already encoded.\n \n#### Job Satisfication is orinal, but let deem it numerical for now.\n * MaritalStatus and OverTime: are partly categorical -> using Hypothesis testing.\n * All the rest: Correlation."},{"metadata":{},"cell_type":"markdown","source":"### 4. Which key factors to Attrition?"},{"metadata":{},"cell_type":"markdown","source":"### Hypothesis Testing"},{"metadata":{},"cell_type":"markdown","source":"1. ***Populations***  \n\n * Population Yes: All employees who 'Yes' to Attrition.\n * Population No : All employee who 'No' to Attrition."},{"metadata":{},"cell_type":"markdown","source":"2. ***Statements***  \n\nFor each feature in the list of undertest features.  \n * H0: Mean of Population Yes == Mean of Population No  \n * H1: Mean of Population Yes != Mean of Population No"},{"metadata":{},"cell_type":"markdown","source":"3. ***Calculation***"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# Split df to Yes-No Attrition\ndf_Attrition_yes = df[df.Attrition == 'Yes']\ndf_Attrition_no = df[df.Attrition == 'No']\n\n# Run: One sample Two-sided T-test\nt_statistic = []\np_value     = []\n\nfor feature in features_to_analysis:\n    # t-test\n    sample  = df_Attrition_yes[feature]\n    popmean = df_Attrition_no[feature].mean() # mean of population\n    t_stats, p = stats.ttest_1samp(sample, popmean)\n           \n    t_statistic.append(t_stats)\n    p_value.append(p)    \n    \n    print('Feature: ', feature)\n    print('t-statistic: %4.2f -- p-value: %4.4f \\n' %(t_stats, p))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"4. ***Conclusions***"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# Create tabel\ntable = pd.DataFrame()\ntable['Features'] = features_to_analysis\ntable['t-statistic'] = t_statistic\ntable['p-value'] = p_value\n\n# Conclusions\nalpha = 0.05\ntable['Decisions'] = ['Rejected' if x<alpha else 'Failed to reject' for x in table['p-value']]\ntable['Key factors'] = ['Yes' if x=='Rejected' else 'No' for x in table['Decisions']]\n\n# Drop not-needed\n#table = table.drop(['t-statistic', 'p-value'], axis=1)\n\nprint(table[['Features', 'Decisions', 'Key factors']].sort_values(by='Key factors', ascending=False))\n\n#print(table.sort_values(by='Decisions'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"5. Comments  \n\n * ***True Positives*** - Age, MonthlyIncome, and OverTime: all correct.\n * ***True Negatives*** - DistanceFromHome, TotalWorkingYears, and MaritalStatus: the hypothesis testing considers them key factors.\n * ***For-curious features*** - Age and Years WithCurr Manager are key factors."},{"metadata":{},"cell_type":"markdown","source":"### 4. Which key factors to Job Satisfaction?"},{"metadata":{},"cell_type":"markdown","source":"Look back to its distribution first."},{"metadata":{},"cell_type":"markdown","source":"## Hypothesis Testing for MaritalStatus and OverTime"},{"metadata":{},"cell_type":"markdown","source":"1. ***Populations***  \n\n * Population: whole employees.\n * Samples:\n     * Sample 1: employees who is Single   and  Yes-OverTime.\n     * Sample 2: employees who is Married  and  Yes-OverTime.\n     * Sample 3: employees who is Divorced and  Yes-OverTime.\n     * Sample 4: employees who is Single   and  No-OverTime.\n     * Sample 5: employees who is Married  and  No-OverTime.\n     * Sample 6: employees who is Divorced and  No-OverTime."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preparing samples for ANOVA\npopulation = df[['MaritalStatus', 'OverTime', 'JobSatisfaction']]\n\nanova_samples = {}\ni = 1\n\n# Create Samples by conditions\nfor MS in population['MaritalStatus'].unique():\n    for OT in population['OverTime'].unique():\n        sample = population['JobSatisfaction'][(df.MaritalStatus==MS) & (df.OverTime==OT)]\n        sample.reset_index(drop=True, inplace=True)\n        anova_samples[i] = sample\n        \n        i += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. ***Statements***  \n\n * H0: Means of JobSatisfaction in 6 samples are equal.  \n * H1: Existing at least one pair that breaks H0.\n \n ***Level of Significant***: 0.05"},{"metadata":{},"cell_type":"markdown","source":"3. ***Calculation***\n\nTest: One way ANOVA"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, p = stats.f_oneway(anova_samples[1],\n                      anova_samples[2],\n                      anova_samples[3],\n                      anova_samples[4],\n                      anova_samples[5],\n                      anova_samples[6])\n\nprint('F-statistic: %4.2f' %(f))\nprint('p-value    : %4.2f' %(p))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"4. ***Conclusions***\n\n * p-value 0.36 > 0.05 -> ***Failed to reject*** H<sub>0</sub>: all 6 samples mean of Job Satisfaction are equal.  \n * MarituaStatus and OverTime: ***is not*** key values to JobSatisfaction"},{"metadata":{},"cell_type":"markdown","source":"## Correlation determination for the rest of Features to Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Features to run correlation\n\n# Those be analyzed already.\nfeatures_to_analysis.remove('MaritalStatus_encoded')\nfeatures_to_analysis.remove('OverTime_encoded')\n\n# Put JobSatisfaction in to determine Correlation matrix latter\nfeatures_to_analysis.append('JobSatisfaction')\n\nprint(features_to_analysis)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix = df[features_to_analysis].corr()\n\n# The heatmap\nfigure = plt.figure(figsize=(16,12))\n\nmask = np.triu(corr_matrix) # Hide the upper part.\nsns.heatmap(corr_matrix, annot=True, fmt='.2f', linewidths=0.5, cmap=\"YlGnBu\", mask=mask)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Unbelievable!!!\n\nNone of Features analysising seems to have any dang correlation to JobSatisfaction!!"},{"metadata":{},"cell_type":"markdown","source":"# 6. Final Verdict\n1. Key factors to Attrition.  \n\n * Age, DistanceFromHome, JobLevel,\n * MaritalStatus, MonthlyIncome, OverTime,\n * TotalWorkingYears, TrainingTimesLastYear, YearsWithCurrManager.\n\nThough there is a drawback: we just know they influence the Attrition, but how much?? T-test can not give the answer.\n\n2. Key factors to Job Satisfaction.\n\nMy procedure is unable to point out key factors influence the Job Satisfaction, but it indicates those does not:\n * Age, DistanceFromHome, Education,\n * JobLevel, MaritalStatus, MonthlyIncome,\n * MonthlyRate, NumCompaniesWorked, OverTime,\n * PercentSalaryHike, TotalWorkingYears, TrainingTimesLastYear, \n * YearsSinceLastPromotion, YearsWithCurrManager"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"markdown","source":"# 7. My potential mistakes\n1. ***Lacking of Assumptions checking***. T-test and ANOVA working based on concrete assumptions. If the data are not suitable for them, the testing could be incorrect.\n\n\n2. ***Problems with ordinal data.*** I ran ANOVA with assumption that Job Satisfaction is simply a integer, but it is not. Job Satisfaction is an ordinal, which by far different from a ninteger, so this assumption badly effects on ANOVA at certain level."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}