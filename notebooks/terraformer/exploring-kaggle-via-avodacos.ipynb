{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression, HuberRegressor, Ridge\nimport sklearn.metrics as metrics\nfrom sklearn.model_selection import cross_val_predict\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f0280fb85c7da6afa1d0f79bb77dab626e98d026"},"cell_type":"markdown","source":"**Exploring Data**\n\nNext, reading data in from avocados and visualizing it."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"raw_data = pd.read_csv('../input/avocado.csv', encoding='utf-8', index_col='Date')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"raw_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"78852b88ab7c2d75210dc2a1eaa7fd173257e104"},"cell_type":"code","source":"n_regions = raw_data.region.nunique()\nregions = raw_data.region.unique()\nprint(n_regions, regions, sep=\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d6b7bfa9968d9cb0de43f58a2e4f07e545f278f"},"cell_type":"code","source":"#x = regions[0]\nplace = 'Albany'\nregion = raw_data[raw_data.region == place]\nregion = region.sort_index()\nprice = region.AveragePrice\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c69d0aa6b9ad18cd40027f20c296322c72a79188"},"cell_type":"code","source":"x= range(0,len(region.index))\ny=price\nplt.plot(x,y)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d46796d9349a645895c9125f229ccb23abdf3897"},"cell_type":"markdown","source":"It seems that average price has varied a lot in Albany during nearly the first 3 years. After that it has become more easily trendable and therefor more predictable.  "},{"metadata":{"_uuid":"55da150e30bd2ddd430b6949d88b7440d34dc3f5"},"cell_type":"markdown","source":"**Testing Models**\n\nNext, I divide data into training and testing sets. Training and testing of models follow.  "},{"metadata":{"trusted":true,"_uuid":"e173c9e4742d4442b9f206d5ef2ec9c2cacddf10"},"cell_type":"code","source":"X = np.array(x)\nX = X.reshape(-1,1)\nX_train, y_train, X_test, y_test =  X[:150], y[:150], X[150:], y[150:] #division of training and test sets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9cf6f4551383994c810b7538f64040f81c3c6c89"},"cell_type":"code","source":"models = [LinearRegression(), HuberRegressor(), Ridge()]\nresults = []\nfor model in models:\n    predicted = cross_val_predict(model, X_train, y_train, cv= 5)\n    testing = {'model':model,'cross_validation_method_1':metrics.mean_squared_error(y_pred=predicted, y_true=y_train)}\n    model.fit(X_train, y_train)\n    testing['singular_testing_method'] = metrics.mean_squared_error((model.predict(X_test)),y_test)\n    testing['cross_validation_method_2'] = metrics.mean_squared_error(y_pred=cross_val_predict(model, X_test, y_test, cv= 5), y_true=y_test)\n    results.append(testing)\n    \nfor result in results:\n    print(\"Model: {0},\\n cross_validation_method_1: {1},\\n singular_testing_method:{2},\\n cross_validation_method_2: {3} \\n\".format(result['model'],result['cross_validation_method_1'],result['singular_testing_method'],result['cross_validation_method_2']))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"98e0e8da657b8ddde7e069ae9a2f766cd58cd0c4"},"cell_type":"markdown","source":"**Discussion**\n\nIn this notebook, I practiced basics of training models for value prediction. Dataset was avocado.csv. I tried to predict the AveragePrice of the Albany region based on just time series data.\n\n1.  cross_validation_method_1 used X_train and y_train to predict values. \n2. 'singular_testing_method' used X_train and y_train to learn and X_test values to predict.\n3. cross_validation_method_2  used X_test and y_test for predictions.\n\nIt seems that all methods of testing are giving very minimal mean squared error. Cross validation is larger, however. I'd say this is not a problem, because it must be that cross-validation method gives a more general answer compared to singular testing method.  I am/was a little baffled since I could not use cross_val_predict in the same way as model.predict. Therefor, I'd argue results of cross_validation_method_1 are not comparable with the other two methods and this is what leads to its mean squared error being noticeably big. More simply put; cross_validation_method_1 was not tested on the same data as singular_testing_method and cross_validation_method_2 and that's why there's a gap in prediction error.\n"},{"metadata":{"trusted":true,"_uuid":"2d9c51c13ca391c9b66c405f85bcf84fb5d06fae"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}