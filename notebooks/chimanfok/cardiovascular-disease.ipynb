{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n\n%matplotlib inline\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport os\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import normalize\nfrom sklearn.metrics import accuracy_score\n\nimport xgboost\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Reading data\ndata = pd.read_csv(\"/kaggle/input/cardiovascular-disease-dataset/cardio_train.csv\", sep=\";\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Know the dimension\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove the id\ndata.drop(\"id\",axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To find abnormal data\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fields of \"height\", \"weight\", \"ap_hi\", \"ap_lo\" may have outlier."},{"metadata":{"trusted":true},"cell_type":"code","source":"# To have a closer look to ap_hi\nplt.hist(data[\"ap_hi\"], bins = 200)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To have a closer look to ap_lo\nplt.hist(data[\"ap_lo\"], bins = 200)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove outliers\ndata = data[data[\"ap_lo\"] < 200]\ndata = data[data[\"ap_hi\"] < 200]\ndata = data[data[\"ap_lo\"] > 30]\ndata = data[data[\"ap_hi\"] > 30]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check if the target is balanced\ndata[\"cardio\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data after removing outliers\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature engineering\ndata[\"bmi\"] = data[\"weight\"]/ (data[\"height\"]/100)**2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data preprocessing - train test split and normalise\ny = data[\"cardio\"]\nX = data.drop([\"cardio\"], axis = 1)\nX = normalize(X)\nX_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=8017)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=8017)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training (baseline)\ndtc = DecisionTreeClassifier()\nrfc = RandomForestClassifier()\nknn = KNeighborsClassifier()\nsvc = SVC(random_state=1)\nlog = LogisticRegression(solver=\"liblinear\", max_iter=200)\n\nmodels = {\"Decision tree\" : dtc,\n          \"Random forest\" : rfc,\n          \"KNN\" : knn,\n          \"SVM\" : svc,\n          \"Logistic\" : log}\nscores= { }\n\nfor key, value in models.items():    \n    model = value\n    accuracies = cross_val_score(estimator=value, X=X_train_val, y=y_train_val, cv=4)\n    scores[key] = round(sum(accuracies)/len(accuracies), 4)\n    print(\"done. run {}\".format(key))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print score\nprint(scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tuning rfc\ngrid = {\"n_estimators\" : np.arange(70,200,20)}\nrfc_grid = GridSearchCV(rfc, grid, cv=4) \nrfc_grid.fit(X_train_val,y_train_val)\n\nprint(\"Best n_estimators: {}\".format(rfc_grid.best_params_)) \nprint(\"Best score: {}\".format(rfc_grid.best_score_))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tuning rfc\ngrid = {\"n_estimators\" : np.arange(115,150,5)}\nrfc_grid = GridSearchCV(rfc, grid, cv=4) \nrfc_grid.fit(X_train_val,y_train_val)\n\nprint(\"Best n_estimators: {}\".format(rfc_grid.best_params_)) \nprint(\"Best score: {}\".format(rfc_grid.best_score_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tuning knn\n\ngrid = {\"n_neighbors\" : np.arange(2,40,2)}\nknn_grid = GridSearchCV(knn, grid, cv=4)\nknn_grid.fit(X_train_val,y_train_val)# Fit)\n\nprint(\"Best n_neighbors: {}\".format(knn_grid.best_params_)) \nprint(\"Best score: {}\".format(knn_grid.best_score_))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tuning knn\n\ngrid = {\"n_neighbors\" : np.arange(38,50,2)}\nknn_grid = GridSearchCV(knn, grid, cv=4)\nknn_grid.fit(X_train_val,y_train_val)# Fit)\n\nprint(\"Best n_neighbors: {}\".format(knn_grid.best_params_)) \nprint(\"Best score: {}\".format(knn_grid.best_score_))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tuning svm\n\ngrid = {\"kernel\" : ['linear', 'poly', 'rbf', 'sigmoid']}\nsvc_grid = GridSearchCV(svc, grid, cv=4)\nsvc_grid.fit(X_train_val,y_train_val)# Fit)\n\nprint(\"Best n_estimators: {}\".format(svc_grid.best_params_)) \nprint(\"Best score: {}\".format(svc_grid.best_score_))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tuning log\n\ngrid = {\"penalty\" : [\"l1\", \"l2\"],\n         \"C\" : np.arange(60,80,2)} \nlog_grid = GridSearchCV(log, grid, cv=4)\nlog_grid.fit(X_train_val, y_train_val)\n\n# Print hyperparameter\nprint(\"Best grid: {}\".format(log_grid.best_params_)) \nprint(\"Best score: {}\".format(log_grid.best_score_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training (final)\nrfc_final = RandomForestClassifier(n_estimators= 130)\nknn_final = KNeighborsClassifier(n_neighbors= 38)\nsvc_final = SVC(random_state=1, kernel = 'linear')\nlog_final = LogisticRegression(solver=\"liblinear\", max_iter=200, C = 64, penalty= 'l1')\n\nmodels = {\"Random forest\" : rfc_final,\n          \"KNN\" : knn_final,\n          \"SVM\" : svc_final,\n          \"Logistic\" : log_final}\nscores_final = { }\n\nfor key, value in models.items():    \n    model = value\n    model.fit(X_train_val, y_train_val)\n    y_pred = model.predict(X_test)\n    scores_final[key] = accuracy_score(y_pred, y_test)\n    print(\"done. run {}\".format(key))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(scores_final)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}