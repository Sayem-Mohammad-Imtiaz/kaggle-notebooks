{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Importing packages","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport datetime as dt\nimport seaborn as sns\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import silhouette_samples, silhouette_score\nfrom scipy.cluster.hierarchy import dendrogram, linkage, cophenet, fcluster\nfrom scipy.spatial.distance import pdist\nimport scipy.cluster.hierarchy as shc\nfrom sklearn.cluster import AgglomerativeClustering","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Importing Data  ","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('../input/ecommerce-data/data.csv')\nprint(f'The shape of the data is {data.shape}')\ndata.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> *The dataset is a collection of details of products purchased in transactions(identified by invoice no.) by several customers in an e-commerce website. \nIt consist of 8 columns corresponding to eac product bought in the e-commerce website. For each invoice no.(transaction) , there are multiple rows identifing each product in that transaction. The stock code is the code no of the product, it will be used to identify the product. Description is the product description and quantity and unitPrice are the no. of units and price of each unit of that product. InvoiceDate consist of date and time of purchase and CustomerID will be used to identify each customer uniquely.*","metadata":{}},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isna().sum(axis=0).sort_values(ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.dropna(subset=['CustomerID','Description'],how = 'any', inplace = True)\nprint(f'The shape of the data is {data.shape}')\nprint(\"Null Values in each Column:\")\ndata.isna().sum(axis=0).sort_values(ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"The number of duplicates in the dataset is {data.duplicated(keep='first').sum(axis = 0)}\")\ndata.drop_duplicates(inplace=True)\nprint(f\"Duplicates Dropped...\\nThe number of duplicates in the dataset now is {data.duplicated(keep='first').sum(axis = 0)}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### In the above code all the rows missing the value of CustomerID and the description of the products are identified and dropped.\n#### Also the duplicates are searched among the data and only a single copy is backed.","metadata":{}},{"cell_type":"code","source":"data = data[data['Quantity'] > 0]\nprint(f'The shape of the data is {data.shape}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Number of transaction: ',data['InvoiceNo'].nunique())\nprint('Number of unique products: ',data['StockCode'].nunique())\nprint('Number of customers: ',data['CustomerID'].nunique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The given dataset consist of information which cannot be used as a feature for clustering customers based on the purchases.\nHence we do some feature engineering to generate some useful and direct features from the given dataset. Here are the features: \n1. Recency: One of the most important feature of customer segmentation is when the last transaction was done in the e-commerce website. This helps in targetting customers who have recently transacted in the e-commerce website and hence would segragate all the inactive customers, helping to market them differently. Recency is calculated by grouping all the transaction done by a customer and finding the difference between the current date and the date of latest transaction. For this the dataset's datetime format is made compatible for operation. Recency is measured by no. of days\n\n2. Frequency: Frequency is the number of times the customer has done transaction in the e-commerce website. This helps in separating regular customers from one-time customers and marketing them appropriately.\n\n3. Monetary: Monetary determines the amount spent altogether by the customers altogether on the transactions made in the website. This helps in identifying customers who are spend-thrift or have the capacity of spending a good amount on costly products in the future transaction from customers who have purchased goods of less amount from the e-commerce website and hence would help them market differently once segmented.\n\n4. AvgQuantity: AvgQuantity determines the average number of products(quantity-wise) purchased by the customer in each transaction. This helps in keeping track of customers who purchase goods in large quantities and marketing them appropriately.\n\n5. OldCust: OldCust determines since how long the customers has been purchasing from the e-commerce website. Using this feature would help identifying old customers from comparitively newer ones.","metadata":{}},{"cell_type":"code","source":"data['InvoiceDate'] = data['InvoiceDate'].astype('datetime64')\nprint(data['InvoiceDate'].max())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"now = dt.date(2011,12,9)\nprint(f'Date of Reference: {now}')\ndata['Date'] = data['InvoiceDate'].apply(lambda x: x.date())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"recency_df = data.groupby(by='CustomerID', as_index=False)['Date'].max()\nrecency_df.columns = ['CustomerID','LastPurshaceDate']\nrecency_df['Recency'] = recency_df['LastPurshaceDate'].apply(lambda x: (now - x).days)\nrecency_df.drop('LastPurshaceDate',axis=1,inplace=True)\nrecency_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp = data.copy()\ntemp.drop_duplicates(['InvoiceNo','CustomerID'],keep='first',inplace=True)\nfrequency_df = temp.groupby(by=['CustomerID'], as_index=False)['InvoiceNo'].count()\nfrequency_df.columns = ['CustomerID','Frequency']\nfrequency_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['TotalCost'] = data['Quantity'] * data['UnitPrice']\ndata.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"monetary_df = data.groupby(by='CustomerID',as_index=False).agg({'TotalCost': 'sum'})\nmonetary_df.columns = ['CustomerID','Monetary']\nmonetary_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"quantity_df = data.groupby(by='CustomerID',as_index=False)['Quantity'].mean()\nquantity_df.columns = ['CustomerID','AvgQuantity']\nquantity_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oldcust_df = data.groupby(by='CustomerID', as_index=False)['Date'].min()\noldcust_df.columns = ['CustomerID','FirstPurshaceDate']\noldcust_df['OldCust'] = oldcust_df['FirstPurshaceDate'].apply(lambda x: (now - x).days)\noldcust_df.drop('FirstPurshaceDate',axis=1,inplace=True)\noldcust_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"customer_data = recency_df.merge(frequency_df,on='CustomerID').merge(monetary_df,on='CustomerID').merge(quantity_df,on='CustomerID').merge(oldcust_df,on='CustomerID')\ncustomer_data.set_index('CustomerID',inplace=True)\ncustomer_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(customer_data,diag_kind='kde')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(customer_data.corr(),annot=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_cd = customer_data.mean()\nstd_cd = customer_data.std()\ncustomer_data = (customer_data - customer_data.mean())/customer_data.std()\ncustomer_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Hierarchical Clustering","metadata":{}},{"cell_type":"markdown","source":"### Single Aggromerative Clustering","metadata":{}},{"cell_type":"code","source":"X_sig = customer_data.copy()\nY_sig = X_sig.to_numpy()\nsig_agg = AgglomerativeClustering(linkage='single',affinity='euclidean', n_clusters=5)\nmodel_sig = sig_agg.fit(X_sig)\nZ_sig = linkage(X_sig,'single')\nfig_sig = plt.figure(figsize=(10, 7))\ndn_sig = dendrogram(Z_sig)\nX_sig['Label']=model_sig.labels_+1\nc_sig, coph_dists_sig = cophenet(Z_sig, pdist(Y_sig))\nprint(f'Cophenetic Correlation Value: {c_sig}')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Complete Aggromerative Clustering","metadata":{}},{"cell_type":"code","source":"X_comp = customer_data.copy()\nY_comp = X_comp.to_numpy()\ncomp_agg = AgglomerativeClustering(linkage='complete',affinity='euclidean', n_clusters=5)\nmodel_comp = comp_agg.fit(X_comp)\nZ_comp = linkage(X_comp,'complete')\nfig_comp = plt.figure(figsize=(10, 7))\ndn_comp = dendrogram(Z_comp)\nX_comp['Label']=model_comp.labels_+1\nc_comp, coph_dists_comp = cophenet(Z_comp, pdist(Y_comp))\nprint(f'Cophenetic Correlation Value: {c_comp}')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Average Aggromerative Clustering","metadata":{}},{"cell_type":"code","source":"X_avg = customer_data.copy()\nY_avg = X_avg.to_numpy()\navg_agg = AgglomerativeClustering(linkage='average',affinity='euclidean', n_clusters=5)\nmodel_avg = avg_agg.fit(X_avg)\nZ_avg = linkage(X_avg,'average')\nfig_avg = plt.figure(figsize=(10, 7))\ndn_avg = dendrogram(Z_avg)\nX_avg['Label']=model_avg.labels_+1\nc_avg, coph_dists_avg = cophenet(Z_avg, pdist(Y_avg))\nprint(f'Cophenetic Correlation Value: {c_avg}')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Ward Aggromerative Clustering","metadata":{}},{"cell_type":"code","source":"X_ward = customer_data.copy()\nY_ward = X_ward.to_numpy()\nward_agg = AgglomerativeClustering(linkage='ward',affinity='euclidean', n_clusters=5)\nmodel_ward = ward_agg.fit(X_ward)\nZ_ward = linkage(X_ward,'ward')\nfig_ward = plt.figure(figsize=(10, 7))\ndn_ward = dendrogram(Z_ward)\nX_ward['Label']=model_ward.labels_+1\nc_ward, coph_dists_ward = cophenet(Z_ward, pdist(Y_ward))\nprint(f'Cophenetic Correlation Value: {c_ward}')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## K-means clustering","metadata":{}},{"cell_type":"code","source":"X = customer_data.copy()\ncluster_range = range(1, 15)\ncluster_errors = []\ncluster_sil_scores = []\n\nfor num_clusters in cluster_range:\n    clusters = KMeans( num_clusters, n_init = 100,init='k-means++',random_state=0)\n    clusters.fit(X)\n    labels = clusters.labels_\n    centroids = clusters.cluster_centers_\n    cluster_errors.append(clusters.inertia_)\n    \nclusters_df = pd.DataFrame({ \"num_clusters\":cluster_range, \"cluster_errors\": cluster_errors} )\nclusters_df[0:10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,6))\nplt.plot(clusters_df['num_clusters'], clusters_df['cluster_errors'], marker = \"o\" )\nplt.xlabel('Number of Clusters')\nplt.ylabel('Cluster Errors')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for k in range(2,10):\n    cluster = KMeans(n_clusters=k, random_state=0)\n    labels = cluster.fit_predict(X)\n    \n    sil_avg = silhouette_score(X, labels)\n    print('For',k,'clusters, average silhoutte score =',sil_avg)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"customer_data = recency_df.merge(frequency_df,on='CustomerID').merge(monetary_df,on='CustomerID').merge(quantity_df,on='CustomerID').merge(oldcust_df,on='CustomerID')\ncustomer_data.set_index('CustomerID',inplace=True)\ncustomer_data.head()\nmean_cd = customer_data.mean()\nstd_cd = customer_data.std()\ncustomer_data = (customer_data - customer_data.mean())/customer_data.std()\ncustomer_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# With num_clusters = 5\nX = customer_data.copy()\nclusters = KMeans(5, n_init = 100,init='k-means++',random_state=42)\nclusters.fit(X)\nlabels = clusters.labels_\ncentroids = clusters.cluster_centers_\nX['Label'] = labels+1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"centroids","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_cd = mean_cd.values[:]\nstd_cd = std_cd.values[:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cent_vals = (centroids * std_cd) + mean_cd\ncent_vals = cent_vals.astype('int32')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cent_vals","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cluster_count = X['Label'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(1,6):\n    print(f\"Cluster {i}:\")\n    print(f\"The number of customers in this cluster is {cluster_count[i]}.\")\n    print(f\"Centroid(Mean) Features of Cluster {i}:\\n \")\n    print(f\"Recency = {cent_vals[i-1][0]} \\nFrequency = {cent_vals[i-1][1]} \\nMonetary = {cent_vals[i-1][2]} \\nAvgQuantity = {cent_vals[i-1][3]} \\nOldCust = {cent_vals[i-1][4]} \\n\\n\\n\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":">From the above output we can infer that, we can cluster our customers in 5 clusters:\n\n>Cluster 1: It includes recent customers(Based on recency) who have only purchased once with low amount of purchase. They don't on an average purchase in large quantities. The e-commerce website shall target them such that they come to the e-commerce website again. As they are recent customers they can be potential customers based on there experience of first purchase. ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}