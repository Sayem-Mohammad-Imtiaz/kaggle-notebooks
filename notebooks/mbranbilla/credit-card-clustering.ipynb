{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"## Credit Card Clustering\n"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing as pp\nfrom sklearn.cluster import KMeans\n\nsns.set()\n%matplotlib inline\n\n# Display Options\npd.options.mode.chained_assignment = None\npd.options.display.max_columns = None","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"537890ad22803bce6368de260dc29b5b78651ee0"},"cell_type":"markdown","source":"### Preparing data\n- View types;\n- Summarize / Overview dataset;\n- Fill NAs"},{"metadata":{"trusted":true,"_uuid":"5c9a2def6ca602b295a00321b3cce4f75f5178a4"},"cell_type":"code","source":"# Import data\ndata = pd.read_csv(\"../input/CC GENERAL.csv\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9c589d08ae605b3771f573fcf3da1ae9d00b6eee"},"cell_type":"code","source":"# Overview\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d4b4c0bffb605b63d53a136aaf4dc9efb7a3cce6"},"cell_type":"markdown","source":"Observing the table above, we can say that variables  `BALANCE`, `PURCHASES`, `ONEOFF_PURCHASES`, `INSTALLMENTS_PURCHASES`, `CASH_ADVANCE`, `CASH_ADVANCE_TRX`, `PURCHASE_TRX`, `CREDIT_LIMIT`, `PAYMENTS` and `MINIMUM_PAYMENTS` have outliers. Let's treat using log-transformation before standardizing."},{"metadata":{"trusted":true,"_uuid":"500d4f9989344275f7aca8fec9bf29fd97783418"},"cell_type":"code","source":"# View missing values (count)\ndata.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81b2d14deeaf32f61f292c758e588ca63435ac8f"},"cell_type":"code","source":"# Fill NAs by mean\ndata = data.fillna(data.mean())\n\ndata.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e28d0cabd8bc32c7a0bc0b37a5f02fc3277dd224"},"cell_type":"code","source":"# Remove CUST_ID (not usefull)\ndata.drop(\"CUST_ID\", axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"48c1d57cd1564fc09c4df59b0d08d3a4e43c76b7"},"cell_type":"markdown","source":"### Data exploration\n- View types;\n- Data visualization"},{"metadata":{"trusted":true,"_uuid":"0e0833984f4d2048e2ffe179e87472a5b4f797cf"},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e67df07e5aa7d4fa0c15672f01f78f0ffe577f06","scrolled":true},"cell_type":"code","source":"# Unique values for int64 types\ndata[['CASH_ADVANCE_TRX', 'PURCHASES_TRX', 'TENURE']].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"77febee4b2ebb269b0b36cdaad5b2f1b5c0e93bb"},"cell_type":"code","source":"# Correlation plot\nsns.heatmap(data.corr(),\n            xticklabels=data.columns,\n            yticklabels=data.columns\n           )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c356ccffffb7a91c01dc82d3eaee89ff6d2145f"},"cell_type":"code","source":"# Pairplot - dispersion between variables\nsns.pairplot(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5a67c09c91461bd74107274b3ddaac3fef6123d8"},"cell_type":"code","source":"# Distribution of int64 variables\nfig, axes = plt.subplots(nrows=3, ncols=1)\nax0, ax1, ax2 = axes.flatten()\n\nax0.hist(data['CASH_ADVANCE_TRX'], 65, histtype='bar', stacked=True)\nax0.set_title('CASH_ADVANCE_TRX')\n\nax1.hist(data['PURCHASES_TRX'], 173, histtype='bar', stacked=True)\nax1.set_title('PURCHASES_TRX')\n\nax2.hist(data['TENURE'], 7, histtype='bar', stacked=True)\nax2.set_title('TENURE')\n\nfig.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a6af4000ac4ad601c3af425f15e22ff687f8f587"},"cell_type":"markdown","source":" ## Feature generation\n ### Used technics:\n - Log transformation;\n - Standardization;\n - Statistics for some variables (like mean, median, first and third quartile and mode)"},{"metadata":{"trusted":true,"_uuid":"cf9b35a0d6182880675555d80ecf497ed07a2afe"},"cell_type":"code","source":"# Create a copy of data\nfeatures = data.copy()\nlist(features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1e6eb88090b6bcf82381a64b8901dc95ce847560"},"cell_type":"code","source":"# Log-transformation\n\ncols =  ['BALANCE',\n         'PURCHASES',\n         'ONEOFF_PURCHASES',\n         'INSTALLMENTS_PURCHASES',\n         'CASH_ADVANCE',\n         'CASH_ADVANCE_TRX',\n         'PURCHASES_TRX',\n         'CREDIT_LIMIT',\n         'PAYMENTS',\n         'MINIMUM_PAYMENTS',\n        ]\n\n# Note: Adding 1 for each value to avoid inf values\nfeatures[cols] = np.log(1 + features[cols])\n\nfeatures.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"45f184c93432e76bc2f6c4c624a1345848429706"},"cell_type":"code","source":"features.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7a061ad3a936e1b75e0164c56a9cdcae381cccfd"},"cell_type":"markdown","source":"#### Outliers\n\n\nAs this is a clustering, I decided to test first without _outlier\\`s_ replacement.  But is important know that information for comparision of clusterized values,  if we\\`ll see outliers inside the clusters.\n\nUsing _IRQ Score_ for identify _outliers_ values in  dataset. \n*_IRQ method_* is used in boxplot to identify possible outliers values. By Wikipedia definition:\n\n> The interquartile range (IQR), also called the midspread or middle 50%, or technically H-spread, is a measure of statistical dispersion, being equal to the difference between 75th and 25th percentiles, or between upper and lower quartiles, IQR = Q3 âˆ’ Q1.\nIn other words, the IQR is the first quartile subtracted from the third quartile; these quartiles can be clearly seen on a box plot on the data.\nIt is a measure of the dispersion similar to standard deviation or variance, but is much more robust against outliers.\n\n\n\n**For now, we\\`ll do nothing with outliers because this may harm the clustering.**\n"},{"metadata":{"trusted":true,"_uuid":"dcba244f8cd5df6f9bf7083859909a5de6c9f56e"},"cell_type":"code","source":"# Using boxplot for indentify possible outliers values after log-transform\n\nfeatures.boxplot(rot=90, figsize=(30,10))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"353f1b5e91b0ebb76ed0fced22809c475c030a91"},"cell_type":"markdown","source":"Applying IRQ methodology in our dataset:"},{"metadata":{"trusted":true,"_uuid":"61a891470884330f9fc293c854d764ad30404a42"},"cell_type":"code","source":"cols = list(features)\nirq_score = {}\n\nfor c in cols:\n    q1 = features[c].quantile(0.25)\n    q3 = features[c].quantile(0.75)\n    score = q3 - q1\n    outliers = features[(features[c] < q1 - 1.5 * score) | (features[c] > q3 + 1.5 * score)][c]\n    values = features[(features[c] >= q1 - 1.5 * score) | (features[c] <= q3 + 1.5 * score)][c]\n    \n    irq_score[c] = {\n        \"Q1\": q1,\n        \"Q3\": q3,\n        \"IRQ\": score,\n        \"n_outliers\": outliers.count(),\n        \"outliers_avg\": outliers.mean(),\n        \"outliers_stdev\": outliers.std(),\n        \"outliers_median\": outliers.median(),\n        \"values_avg:\": values.mean(),\n        \"values_stdev\": values.std(),\n        \"values_median\": values.median(),\n    }\n    \nirq_score = pd.DataFrame.from_dict(irq_score, orient='index')\n\nirq_score","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"345979d444b4856ad8bf534515960ae83d4eb457"},"cell_type":"markdown","source":"#### Feature Scaling\nHere we can use `scale` function of `sklearn.preprocessing`.  This function will put all variables at the same scale, with _mean zero_ and _standard deviation equals to one_."},{"metadata":{"trusted":true,"_uuid":"b8dba2d54a2b933bfd704580f38de9524a80bea5"},"cell_type":"code","source":"# Scale All features\n\nfor col in cols:\n    features[col] = pp.scale(np.array(features[col]))\n\nfeatures.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"35ea775b10c45d9d8197e755b489cd9720a97a92"},"cell_type":"markdown","source":"## Clustering using K-Means\n\n\nNow we\\`re ready to apply the clustering algorithm, using `KMeans` from `sklearn.cluster`.\n"},{"metadata":{"_uuid":"12d7185456479cf68c7c9b9cbf740b0aa9014e30"},"cell_type":"markdown","source":"Firstly, using Elbow\\`s method, we can find an adequate number of clusters"},{"metadata":{"trusted":true,"_uuid":"d99c9f5a73ecdf73b0898dab0bc05b8621963019"},"cell_type":"code","source":"X = np.array(features)\nSum_of_squared_distances = []\nK = range(1, 30)\n\nfor k in K:\n    km = KMeans(n_clusters=k, random_state=0)\n    km = km.fit(X)\n    Sum_of_squared_distances.append(km.inertia_)\n\nplt.plot(K, Sum_of_squared_distances, 'bx-')\nplt.xlabel('k')\nplt.ylabel('Sum_of_squared_distances')\nplt.title('Elbow Method For Optimal k')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ae67fb1f27c1a277ac6b2eb1258cd725c62e7a1b"},"cell_type":"markdown","source":"I choose `k = 10` for number of clusters, based in plot above. "},{"metadata":{"trusted":true,"_uuid":"0e977a727f86c4f3d93e76a2986ef84829a804f0"},"cell_type":"code","source":"# Custumers per cluster\n\nn_clusters = 10\n\nclustering = KMeans(n_clusters=n_clusters,\n                    random_state=0\n                   )\n\ncluster_labels = clustering.fit_predict(X)\n\n# plot cluster sizes\n\nplt.hist(cluster_labels, bins=range(n_clusters+1))\nplt.title('# Customers per Cluster')\nplt.xlabel('Cluster')\nplt.ylabel('# Customers')\nplt.show()\n\n# Assing cluster number to features and original dataframe\nfeatures['cluster_index'] = cluster_labels\ndata['cluster_index'] = cluster_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b2fc6336121d325c4212dadc4f016ea6fb3f2791"},"cell_type":"code","source":"# Dispersion between clusterized data\n# Pairplot - dispersion between variables\nsns.pairplot(features, hue='cluster_index')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"19700e4e77016ed25518a30d88382f294e73accc"},"cell_type":"code","source":"# View Features\nfeatures","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4f07f3a576715cefea2272c7c71e6d387b1aac12"},"cell_type":"code","source":"# View results\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d8bcf25d715795602e2864ffaa84dd677597677"},"cell_type":"markdown","source":"## To-Do:\n- [ ] Outlier analysis for any cluster;\n- [ ] Interpretation of clusters"},{"metadata":{"trusted":true,"_uuid":"d3b9f798d5137084f17be530efa7fdd861914eb6"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}