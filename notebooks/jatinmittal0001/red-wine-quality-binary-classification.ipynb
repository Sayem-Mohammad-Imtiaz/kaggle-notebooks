{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom keras.utils import np_utils\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom sklearn.model_selection import train_test_split,GridSearchCV      # import GridSearchCV\nfrom sklearn.pipeline import make_pipeline        # import pipeline\nfrom sklearn.preprocessing import StandardScaler \nfrom xgboost import XGBClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, roc_auc_score, accuracy_score\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/winequality-red.csv\")\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a23ab7d9008deb15d183b5f8fbb51bd8df86defa"},"cell_type":"code","source":"#shuffling the dataset\nnp.random.seed(123)\ndata = data.reindex(np.random.permutation(data.index))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3363043c79a4a1675316de979f2a8ac02ba8c12d"},"cell_type":"code","source":"#before dividing the dataset, we will run some preliminary analysis\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0947dd0ee332ceb9f8aeb087bb2973358161a258"},"cell_type":"code","source":"data_X = data.iloc[:,:-1]\ndata_y = data.iloc[:,-1]\n\ndata_y.value_counts(normalize=True)   #checking proportion of different ratings\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"567099d8f69f1662524dc563606363ee7bdee06c"},"cell_type":"markdown","source":"We don't have all quality ratings i.e. 1,2,9,10 are missing, so if we train our model it will not learn these ratings. Moreover, rating 3,4,8 are present in very less proportion with rating 3 just only 0.6%. Due to less data for these ratings, our model will train better on other ratings. We will convert these 6 ratings into 6 classes and turn this regression model into classification model."},{"metadata":{"trusted":true,"_uuid":"83b5e268b9fc48e09c3b0aae5c36b93998151836"},"cell_type":"code","source":"data_y  = data_y.astype('category')\ndata_y1 = np_utils.to_categorical(data_y)\ndata_y1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a5353f174b4d8d1c8bafdfda23507738731798ba"},"cell_type":"code","source":"data_X.isnull().sum()\n# No missing values found","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"97dc4e641620d1b5baba3f678767deb6bd1ebe4c"},"cell_type":"code","source":"data_X.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"10e34508564715d1e83e43eb6fe5ca38b1b42b49"},"cell_type":"code","source":"#correlation matrix\ncorrmat = data.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=.8, square=True);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4ea232e063bb92402a6240edb33807c260f2108d"},"cell_type":"markdown","source":"1. Total Sulfur dioxide and free sulfur dioxide have very high correlation, so we will remove total sulphur dioxide and instead create a new variable with non_free_sulfur_dioxide = Total Sulfur dioxide -  free sulfur dioxide\n2. Fixed acidity and citric acid are highly correlated becuase citric acid is not volatile. Three primary acids are found in wine grapes: tartaric, malic and citric acids. Other acids mights be fixed or volatile, so  removing a variable here might be dicey!! What we can do is to create a variable which sort of captures fixed acidity from citric acid: citric acid/ fixed acidity. \n3. Also, higher is the alcohol content better is the quality."},{"metadata":{"trusted":true,"_uuid":"4847256bd98ff755d0d3d1308d79ab6a4f1c027c"},"cell_type":"code","source":"data_X['non_free_sulfur_dioxide'] = data_X['total sulfur dioxide'] - data_X['free sulfur dioxide']\ndata_X = data_X.drop(['total sulfur dioxide'],axis=1)\ndata_X['fixed_acidity_proportion_citric'] = data_X['citric acid']/data_X['fixed acidity']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2358e440f39bf9240c95db3a5a5a39dc0787b59c"},"cell_type":"code","source":"data_X['non_free_sulfur_dioxide'].describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4d817ff11ae507004b03e96cbe2aec2a9f64c1fe"},"cell_type":"markdown","source":"**Outlier Treatment:**"},{"metadata":{"trusted":true,"_uuid":"e702bbe92b06e87b315de74fa06cbdead4f96b5a"},"cell_type":"code","source":"m=1\nplt.figure(figsize = (20,20))\nfor i in data_X.columns:\n    plt.subplot(3,4,m)\n    sns.boxplot(data_X[i])\n    m = m+1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"66858629f52200eef2dc7990f60ecf7925426402"},"cell_type":"markdown","source":"There are many outliers in each variable. Since our data set is very small, it is not recommended to remove these outiers. So we will do capping and flooring of these outliers."},{"metadata":{"trusted":true,"_uuid":"5be3976e2657916a2549db7223be15a1712891f3"},"cell_type":"code","source":"for col in data_X.columns:\n    percentiles = data_X[col].quantile([0.01,0.99]).values\n    data_X[col][data_X[col] <= percentiles[0]] = percentiles[0]\n    data_X[col][data_X[col] >= percentiles[1]] = percentiles[1]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"204c3cb6e001bb2c28f40cce57bd4be7653474ec"},"cell_type":"markdown","source":"Skewness:\nWe will not check skewness of variables."},{"metadata":{"trusted":true,"_uuid":"1e3402e03e241a4f230286dbbe83eceb3dc82ea1"},"cell_type":"code","source":"# plot histograms to see skewness\nm=1\nplt.figure(figsize = (15,15))\nfor i in data_X.columns:\n    plt.subplot(3,4,m)\n    sns.distplot(data_X[i],kde = True)\n    m = m+1\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4597f83825cd1e2d83ffea8313d26fdcf2a04eda"},"cell_type":"markdown","source":"Different variables have different scaling and are skewed left(mostly). We will apply log transformation. We wil apply transformation to variables having skewness > 0.75"},{"metadata":{"trusted":true,"_uuid":"b5be71ef5cdfa9770869d43827083a332b5a1323"},"cell_type":"code","source":"data_X.dtypes[data_X.dtypes != \"object\"].index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2e7b0d4a1dacf12116b9602a636c57110c9202cb"},"cell_type":"code","source":"from scipy.stats import skew\n\n#finding skewness of all variables\ncol = data_X.columns\nskewed_feats = data_X[col].apply(lambda x: skew(x.dropna()))\n#adjusting features having skewness >0.75\nskewed_feats = skewed_feats[skewed_feats > 0.75]\nskewed_feats = skewed_feats.index\ndata_X[skewed_feats] = np.log1p(data_X[skewed_feats])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"08dc5605ce4cef680999e64e2265c4fbe9aa1c6e"},"cell_type":"code","source":"data_X.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"deaf65d587bf1575d51bc9bf41923322f8ff561e"},"cell_type":"markdown","source":"We earlier saw that some of our target classes are under repessented i.e. their counts are low. We can't undersample ther classes since data is less. We will oversample few classes."},{"metadata":{"trusted":true,"_uuid":"a58a4e0fcc4b8a653dcd1086db49ea781de69ab4"},"cell_type":"code","source":"bins = (2, 6.5, 8)\ngroup_names = ['bad', 'good']\ndata_y= pd.cut(data_y, bins = bins, labels = group_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"98605fb6b9c17b55c778462ce913c78b622aae06"},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabel_quality = LabelEncoder()\n#Bad becomes 0 and good becomes 1 \ndata_y = label_quality.fit_transform(data_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3fb054aa84d1a0556cd512f44ffa3f39607871b7"},"cell_type":"code","source":"'''\nfrom imblearn.combine import SMOTETomek\n\nsmt = SMOTETomek(sampling_strategy = 0.3)\nX_smt, y_smt = smt.fit_sample(data_X, data_y)\n\nprint('Before applying oversampling: ', data_y.shape)\nunique, counts = np.unique(data_y, return_counts=True)   #y_smt is now ndarray, we can't apply value_counts()\nprint(np.asarray((unique, counts)).T)\n\nprint('After applying oversampling: ', y_smt.shape)\nunique, counts = np.unique(y_smt, return_counts=True)   #y_smt is now ndarray, we can't apply value_counts()\nprint(np.asarray((unique, counts)).T)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"25ad0640c6d4204010ff26f54b100879badbda24"},"cell_type":"code","source":"#we will divide data into train, test and validation data\n#since our data is shuffled we can select say top n rows for training\nntrain = int(data.shape[0]*0.9)\ntrain_data = data_X.iloc[:ntrain,:]            # 90% of total data\ntrain_data_y = data_y[:ntrain]\n\nvalidation_data = data_X.iloc[ntrain: ,:]             #10% of total data\nval_data_y = data_y[ntrain:]\n\nprint(train_data.shape[0])\nprint(validation_data.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8a49e205bacbe408f8ae7352f137f37528414754"},"cell_type":"markdown","source":"Modelling:"},{"metadata":{"trusted":true,"_uuid":"df7f9ebd6f625f57be29aae6fb11b35d79c8d54a"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n#  split X between training and testing set\nx_train, x_test, y_train, y_test = train_test_split(train_data,train_data_y, test_size=0.25, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4dfbcad1c326d57986ce51e0de0cefbcfea8f9c6"},"cell_type":"code","source":"ss = StandardScaler()\nss.fit(x_train)\nx_train = ss.transform(x_train)\nx_test = ss.transform(x_test)\nvalidation_data = ss.transform(validation_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7779475ac3dcc5bc7f660903709ade597b809047"},"cell_type":"code","source":"\ndef report(y_actuals,y_pred):\n    print(classification_report(y_actuals, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9c6e8d8254ba0b403fda5ae616258b408f9d1d8d"},"cell_type":"code","source":"# Using DecisionTreeClassifier\ndtc = DecisionTreeClassifier()\ndtc.fit(x_train, y_train)\ndtc_pred = dtc.predict(x_test)\nreport(y_test, dtc_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a6df8a17fddc0f3777449195d4e5fdbd1f3789c4"},"cell_type":"code","source":"# Using RandomForestClassifier\nrfc = RandomForestClassifier(n_estimators=400)\nrfc.fit(x_train, y_train)\nrfc_pred = rfc.predict(x_test)\nreport(y_test, rfc_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f0db52da27ca22bdd14135d43e0cf362b98414e"},"cell_type":"code","source":"features = data_X.columns\nimportances = rfc.feature_importances_\nindices = np.argsort(importances)\n\nplt.title('Feature Importances')\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), [features[i] for i in indices])\nplt.xlabel('Relative Importance')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8e19cf3ac8300d52ec6819369ed6070e59bb5874"},"cell_type":"code","source":"# Using XGBClassifier\nxgb = XGBClassifier(n_estimators=900)\nxgb.fit(x_train, y_train)\nxgb_pred = xgb.predict(x_test)\nreport(y_test, xgb_pred)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1248acdcb5357c0a8a197b0931c6bb680338e217"},"cell_type":"markdown","source":"From above three models weighted avg  f1 score is almost same, so we will use random forest classifier and tune it further. The precision for XGB model is less than random forest so we will notuse this"},{"metadata":{"trusted":true,"_uuid":"c6369a4e75c6637b46f3860b8625b3bdd2e225e0"},"cell_type":"code","source":"rfc = RandomForestClassifier(n_jobs =-1)\nparameters = {'n_estimators' : [200,400,600], 'criterion':['gini'], 'max_depth':[5,10,30,50,100]}\ngrid_rf = GridSearchCV(rfc, parameters , scoring='accuracy', cv=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8439b8ff72c7c2c832a54b5bbe972be287bb8509"},"cell_type":"code","source":"grid_rf.fit(x_train, y_train)\n#Best parameters for our svc model\ngrid_rf.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5068435971d6e49f6020fd1111dad5731c1fb644"},"cell_type":"code","source":"#Let's run our RFC again with the best parameters.\nrfc = RandomForestClassifier(n_estimators=400,max_depth =10, n_jobs =-1)\nrfc.fit(x_train, y_train)\nrfc_pred = rfc.predict(x_test)\nreport(y_test, rfc_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d390444cddf1ec696ab108edabb1aa95b8eded48"},"cell_type":"code","source":"rf_acc_score = accuracy_score(y_test, rfc_pred)\nrf_acc_score","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fa03f3adb54a77aa3079f1f225b3431b0f2db16f"},"cell_type":"markdown","source":"I also tried PCA, but the accuracy from it was 89.5%, so not showing that code here.\n\nSo, concluding this program by achieving accuracy of 90.8%."},{"metadata":{"trusted":true,"_uuid":"9cb7ffd206cb3a9bca80a7e57bc5e4459bd1a0e6"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}