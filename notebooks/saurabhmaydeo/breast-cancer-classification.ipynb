{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport seaborn as sns\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import f1_score,confusion_matrix\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ndata = pd.read_csv(\"/kaggle/input/breast-cancer-wisconsin-data/data.csv\")\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis "},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('float_format', '{:f}'.format)\ndata.describe().T\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Since Unnamed: 32 column doesn't have any value we are dropping it\ndata.drop(['Unnamed: 32', 'id'],axis = 1 ,inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_quality_report = pd.DataFrame(columns = ['feature','count', 'missing %','unique values' ,'mean', 'std', 'min', 'Q1', 'median', 'Q3', 'max', 'IQR'])\n\ni = 0\nfor f, ser in data._get_numeric_data().iteritems():\n    \n    Q1 = ser.quantile(0.25)\n    Q3 = ser.quantile(0.75)\n    \n    data_quality_report.at[i, :] = [f, ser.count(), (ser.isnull().sum()/ser.size)*100, ser.unique().size, ser.mean(), ser.std(), ser.min(), Q1, ser.median(), Q3, ser.max(), Q3 - Q1]\n    i = i + 1\ndata_quality_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Missing Values###"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**There are no missing values in the data set.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['diagnosis'].value_counts().plot(kind = 'bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = data.corr()\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\nf, ax = plt.subplots(figsize=(21, 19))\nsns.heatmap(corr, cmap=cmap, center=0,annot = True,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5});","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#It is taking a lot of time to execute this function as there are 30 features. If you are running this on TPU or something then uncomment and run\n\n#ns.pairplot(data);\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"class_mapping = {label:idx for idx,label in enumerate(np.unique(data['diagnosis']))}\ndata['diagnosis'] = data['diagnosis'].map(class_mapping)\ndata['diagnosis'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Selection###\nUsing chi2 test for selecting k best features from the data set to prevent the overfitting caused by the curse of dimensionality."},{"metadata":{"trusted":true},"cell_type":"code","source":"#data = data[selected_columns]\nlen(data.columns)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\n# find best scored k features\nselect_feature = SelectKBest(chi2, k=10).fit(data.drop('diagnosis',axis = 1 ), data['diagnosis'])\n\nprint('Score list:', select_feature.scores_)\nprint('Feature list:', data.columns)\nselect_feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"select_feature.transform(data.drop('diagnosis',axis = 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_columns = np.array(data.drop('diagnosis',axis = 1).columns)[select_feature.get_support()]\nselected_columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Analysis Base Table"},{"metadata":{"trusted":true},"cell_type":"code","source":"ABT = pd.DataFrame(select_feature.transform(data.drop('diagnosis',axis = 1)),columns=selected_columns)\ny = data.diagnosis","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ABT.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ABT.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelling\n1. **Information based learning** - Random Forest classifer\n2. **Error based learning** - SVM, Logistic Regression\n3. **Similarity based learning **- kNN classifier\n3. **Probability based learning** - Naive Bayes classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"compare = pd.DataFrame(index=['RandomForest', 'SVM', 'LogisticRegression', 'kNN', 'Naive Bayes'], \n                      columns=['Accuracy', 'f1 score', 'Precision', 'Recall'])\ncompare","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Information Based Learning ##\n### **Random Forest Classifier** ###\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(ABT, y, test_size=0.2, random_state=0)\nX_train, X_v, y_train, y_v = train_test_split(X_train, y_train, test_size=0.2, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(bootstrap= False, criterion='entropy', max_features = 'sqrt', min_samples_leaf =1, n_estimators= 300)      \nrf = rf.fit(X_train,y_train)\n\ny_pred = rf.predict(X_v)\nprint(f'Accuracy on validation set is {accuracy_score(y_v,y_pred)}')\nprint(f'f1 score on validation set is {f1_score(y_true=y_v, y_pred=y_pred)}')\nprint(f'Precision on validation set is {precision_score(y_true=y_v, y_pred=y_pred)}')\nprint(f'Recall on validation set is {recall_score(y_true=y_v, y_pred=y_pred)}')\nconfmat = confusion_matrix(y_v,y_pred)\nsns.heatmap(confmat,annot=True,fmt=\"d\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = rf.predict(X_test)\n\naccuracy = accuracy_score(y_test,y_pred)\nf1 = f1_score(y_true=y_test, y_pred=y_pred)\nprecision = precision_score(y_true=y_test, y_pred=y_pred)\nrecall = recall_score(y_true=y_test, y_pred=y_pred)\n\n\ncompare.at['RandomForest', :] = (accuracy, f1, precision, recall)\n\nprint(f'Accuracy on test set is {accuracy}')\nprint(f'f1 score on test set is {f1}')\nprint(f'Precision on test set is {precision}')\nprint(f'Recall on test set is {recall}')\n\n\nconfmat = confusion_matrix(y_test,y_pred)\nsns.heatmap(confmat,annot=True,fmt=\"d\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Error Based Learning ##\n> ### **1. SVM **###\n> ### **2. Logistic Regression**###\n"},{"metadata":{},"cell_type":"markdown","source":"### **Normalization** ### \nPerforming normalization for further models.<br /> \nRandomForest didn't require it.<br /> \n\nAfter normalization we will get NormalizedABT, so will split this into 3 sets for training, cross-validation and testing."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\n\nmin_max_scaler = preprocessing.MinMaxScaler()\nNormalizedABT = min_max_scaler.fit_transform(ABT)\nNormalizedABT=pd.DataFrame(NormalizedABT, columns=selected_columns)\nX_train, X_test, y_train, y_test = train_test_split(NormalizedABT, y, test_size=0.2, random_state=0)\nX_train, X_v, y_train, y_v = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\nNormalizedABT.describe().T\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### SVM - Support Vector Machine classifier\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import svm\n\nclf = svm.SVC().fit(X_train, y_train)\ny_pred = clf.predict(X_v)\n\nprint(f'Accuracy on validation set is {accuracy_score(y_v,y_pred)}')\nprint(f'f1 score on validation set is {f1_score(y_true=y_v, y_pred=y_pred)}')\nprint(f'Precision on validation set is {precision_score(y_true=y_v, y_pred=y_pred)}')\nprint(f'Recall on validation set is {recall_score(y_true=y_v, y_pred=y_pred)}')\n\nconfmat = confusion_matrix(y_v,y_pred)\nsns.heatmap(confmat,annot=True,fmt=\"d\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = clf.predict(X_test)\n\naccuracy = accuracy_score(y_test,y_pred)\nf1 = f1_score(y_true=y_test, y_pred=y_pred)\nprecision = precision_score(y_true=y_test, y_pred=y_pred)\nrecall = recall_score(y_true=y_test, y_pred=y_pred)\n\ncompare.at['SVM', :] = (accuracy, f1, precision, recall)\n\nprint(f'Accuracy on test set is {accuracy}')\nprint(f'f1 score on test set is {f1}')\nprint(f'Precision on test set is {precision}')\nprint(f'Recall on test set is {recall}')\n\nconfmat = confusion_matrix(y_test,y_pred)\nsns.heatmap(confmat,annot=True,fmt=\"d\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nclf = LogisticRegression(random_state=0).fit(X_train, y_train)\ny_pred = clf.predict(X_v)\n\nprint(f'Accuracy on validation set is {accuracy_score(y_v,y_pred)}')\nprint(f'f1 score on validation set is {f1_score(y_true=y_v, y_pred=y_pred)}')\nprint(f'Precision on validation set is {precision_score(y_true=y_v, y_pred=y_pred)}')\nprint(f'Recall on validation set is {recall_score(y_true=y_v, y_pred=y_pred)}')\n\nconfmat = confusion_matrix(y_v,y_pred)\nsns.heatmap(confmat,annot=True,fmt=\"d\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = clf.predict(X_test)\n\naccuracy = accuracy_score(y_test,y_pred)\nf1 = f1_score(y_true=y_test, y_pred=y_pred)\nprecision = precision_score(y_true=y_test, y_pred=y_pred)\nrecall = recall_score(y_true=y_test, y_pred=y_pred)\n\ncompare.at['LogisticRegression', :] = (accuracy, f1, precision, recall)\n\nprint(f'Accuracy on test set is {accuracy}')\nprint(f'f1 score on test set is {f1}')\nprint(f'Precision on test set is {precision}')\nprint(f'Recall on test set is {recall}')\n\n\nconfmat = confusion_matrix(y_test,y_pred)\nsns.heatmap(confmat,annot=True,fmt=\"d\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Similarity Based Learning ##\n### kNN classifier ###\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nclf = KNeighborsClassifier(n_neighbors=19).fit(X_train, y_train)\n\ny_pred = clf.predict(X_v)\n\nprint(f'Accuracy on validation set is {accuracy_score(y_v,y_pred)}')\nprint(f'f1 score on validation set is {f1_score(y_true=y_v, y_pred=y_pred)}')\nprint(f'Precision on validation set is {precision_score(y_true=y_v, y_pred=y_pred)}')\nprint(f'Recall on validation set is {recall_score(y_true=y_v, y_pred=y_pred)}')\n\nconfmat = confusion_matrix(y_v,y_pred)\nsns.heatmap(confmat,annot=True,fmt=\"d\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = clf.predict(X_test)\n\naccuracy = accuracy_score(y_test,y_pred)\nf1 = f1_score(y_true=y_test, y_pred=y_pred)\nprecision = precision_score(y_true=y_test, y_pred=y_pred)\nrecall = recall_score(y_true=y_test, y_pred=y_pred)\n\ncompare.at['kNN', :] = (accuracy, f1, precision, recall)\n\nprint(f'Accuracy on test set is {accuracy}')\nprint(f'f1 score on test set is {f1}')\nprint(f'Precision on test set is {precision}')\nprint(f'Recall on test set is {recall}')\n\nconfmat = confusion_matrix(y_test,y_pred)\nsns.heatmap(confmat,annot=True,fmt=\"d\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Probability Based Learning ##\n### Naive Bayes classifier ###\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\nclf = GaussianNB().fit(X_train, y_train)\n\ny_pred = clf.predict(X_v)\n\nprint(f'Accuracy on validation set is {accuracy_score(y_v,y_pred)}')\nprint(f'f1 score on validation set is {f1_score(y_true=y_v, y_pred=y_pred)}')\nprint(f'Precision on validation set is {precision_score(y_true=y_v, y_pred=y_pred)}')\nprint(f'Recall on validation set is {recall_score(y_true=y_v, y_pred=y_pred)}')\n\nconfmat = confusion_matrix(y_v,y_pred)\nsns.heatmap(confmat,annot=True,fmt=\"d\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = clf.predict(X_test)\n\naccuracy = accuracy_score(y_test,y_pred)\nf1 = f1_score(y_true=y_test, y_pred=y_pred)\nprecision = precision_score(y_true=y_test, y_pred=y_pred)\nrecall = recall_score(y_true=y_test, y_pred=y_pred)\n\ncompare.at['Naive Bayes', :] = (accuracy, f1, precision, recall)\n\nprint(f'Accuracy on test set is {accuracy}')\nprint(f'f1 score on test set is {f1}')\nprint(f'Precision on test set is {precision}')\nprint(f'Recall on test set is {recall}')\n\nconfmat = confusion_matrix(y_test,y_pred)\nsns.heatmap(confmat,annot=True,fmt=\"d\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"compare","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}