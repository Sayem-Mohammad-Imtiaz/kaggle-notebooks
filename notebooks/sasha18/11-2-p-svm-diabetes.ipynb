{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Support Vector Machines - SVM"},{"metadata":{},"cell_type":"markdown","source":"# Context\nThis dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the \ndataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in \nthe dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all \npatients here are females at least 21 years old of Pima Indian heritage."},{"metadata":{},"cell_type":"markdown","source":"# Content\nThe datasets consists of several medical predictor variables and one target variable, Outcome. Predictor variables includes the \nnumber of pregnancies the patient has had, their BMI, insulin level, age, and so on."},{"metadata":{},"cell_type":"markdown","source":"# Can you build a machine learning model to accurately predict whether or not the patients in the dataset have diabetes or not?"},{"metadata":{},"cell_type":"markdown","source":"# 1. Import Libraries and load the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import library\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diabetes = pd.read_csv('../input/pima-indians-diabetes-database/diabetes.csv')\nprint(diabetes.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diabetes.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Check dimension of dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"dimension of diabetes data: {}\".format(diabetes.shape))\n#The diabetes dataset consists of 768 data points, with 9 features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Check distribution of dependent variable, Outcome and plot it"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(diabetes.groupby('Outcome').size())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Out of 768 data points, 500 are labeled as 0 and 268 as 1.\nOutcome 0 means No diabetes, outcome 1 means diabetes, Give a countplot"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n\nsns.countplot(diabetes['Outcome'],label=\"Count\")\n#data has more No diabetic data as compared to diabetic data which would give a biased prediction towards no diabetic","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diabetes.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Check data distribution using summary statistics and provide your findings(Insights)"},{"metadata":{"trusted":true},"cell_type":"code","source":"diabetes.describe().transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Few Insights\n# Min blood pressure of 0 is invalid, so impute it with appropriate values. Same with few other variables like BMI\n# Mean and Median values of Insuline is very different\n# Insuline has very high Standard deviation\n# We will ignore all these issues for now to concentrate more on Model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. Do correlation analysis and bivariate viualization with Insights"},{"metadata":{"trusted":true},"cell_type":"code","source":"colormap = plt.cm.viridis # Color range to be used in heatmap\nplt.figure(figsize=(15,15))\nplt.title('Pearson Correlation of attributes', y=1.05, size=19)\nsns.heatmap(diabetes.corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)\n#There is no strong correlation between any two variables.\n#There is no strong correlation between any independent variable and class variable.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7. Plot a scatter Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"spd = pd.plotting.scatter_matrix(diabetes, figsize=(20,20), diagonal=\"kde\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 8. Do train and test split with stratify sampling on Outcome variable to maintain the distribution of dependent variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(diabetes.loc[:, diabetes.columns != 'Outcome'], diabetes['Outcome'], stratify=diabetes['Outcome'], random_state=11)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 9. Train Support Vector Machine Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\nsvc = SVC()\nsvc.fit(X_train, y_train)\n\nprint(\"Accuracy on training set: {:.2f}\".format(svc.score(X_train, y_train)))\nprint(\"Accuracy on test set: {:.2f}\".format(svc.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The model overfits substantially with a perfect score on the training set and only 65% accuracy on the test set.\n\n#SVM requires all the features to be on a similar scale. We will need to rescale our data that all the features are approximately\n#on the same scale and than see the performance","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 10. Scale the data points using MinMaxScaler"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.fit_transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 11. Fit SVM Model on Scale data and give your observation"},{"metadata":{"trusted":true},"cell_type":"code","source":"svc = SVC()\nsvc.fit(X_train_scaled, y_train)\n\nprint(\"Accuracy on training set: {:.2f}\".format(svc.score(X_train_scaled, y_train)))\nprint(\"Accuracy on test set: {:.2f}\".format(svc.score(X_test_scaled, y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Scaling the data made a huge difference.But now we are actually in an underfitting regime, where training and test set \nperformance are quite similar but less close to 100% accuracy.\nFrom here, we can try increasing either C or gamma to fit a more complex model."},{"metadata":{},"cell_type":"markdown","source":"# 12. Try improving the model accuracy using C=1000"},{"metadata":{"trusted":true},"cell_type":"code","source":"svc = SVC(C=1000)\nsvc.fit(X_train_scaled, y_train)\n\nprint(\"Accuracy on training set: {:.3f}\".format(\n    svc.score(X_train_scaled, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(svc.score(X_test_scaled, y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Here, increasing C allows us to improve the model, resulting in 81.2% train set accuracy."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}