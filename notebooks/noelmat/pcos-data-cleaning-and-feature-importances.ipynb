{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Introduction "},{"metadata":{},"cell_type":"markdown","source":"I have been working on **fastai** courses for quite sometime. This is a technique I came across in the fastai [Introduction to Machine Learning for coders](http://course18.fast.ai/ml)"},{"metadata":{},"cell_type":"markdown","source":"# Model Based EDA\n\nIn the course, Jeremy Howard took us through the following procedure for EDA. Rather than looking at the data and finding relationships and interactions  between the features, the course suggest fitting a model on the data and looking at the model importances and getting the intution from the model itself. \n\nUsing this approach helps us to not all prey to any biases that we form from the features. This approach helps to find:\n* Important Features.\n* Redundant Features.\n* Feature Interactions."},{"metadata":{},"cell_type":"markdown","source":"# Loading the data"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"PCOS_inf = pd.read_csv(\"../input/polycystic-ovary-syndrome-pcos/PCOS_infertility.csv\")\nPCOS_data = pd.read_csv(\"../input/polycystic-ovary-syndrome-pcos/data without infertility _final.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After loading the data, lets print the data to have a look at the data. Remember, We are not looking at the features in the data. We are just making sure that all the data has been loaded correctly"},{"metadata":{"trusted":true},"cell_type":"code","source":"PCOS_data.head().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks like the is some discrepancy in the data. We can see the last row (as transpose of the head is displayed) has `Unnamed:42`. Lets Check the data if we can correct it"},{"metadata":{"trusted":true},"cell_type":"code","source":"PCOS_data[~ PCOS_data['Unnamed: 42'].isna()].T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have extracted the two observations in the `Unnamed: 42` column. Looks like there was some mistake with entering the data. Lets look at the other columns to check if there are other mistake as well."},{"metadata":{"trusted":true},"cell_type":"code","source":"PCOS_data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see there is 1 null value in `Marraige Status (Yrs)`"},{"metadata":{"trusted":true},"cell_type":"code","source":"PCOS_data[PCOS_data['Marraige Status (Yrs)'].isnull()].T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets assign the median to the missing data\nPCOS_data['Marraige Status (Yrs)'].fillna(PCOS_data['Marraige Status (Yrs)'].median(),inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PCOS_data['Fast food (Y/N)'].fillna(PCOS_data['Fast food (Y/N)'].median(),inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks like we can just drop the last erroneous column and go ahead with the analysis"},{"metadata":{},"cell_type":"markdown","source":"## Dropping the column `Unnamed: 42`"},{"metadata":{"trusted":true},"cell_type":"code","source":"PCOS_data.drop('Unnamed: 42',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PCOS_inf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PCOS_inf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Merging the two dataframes"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.merge(PCOS_data,PCOS_inf, on='Patient File No.', suffixes={'','_y'},how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns = ['SNo', 'Patient_File_No.', 'PCOS_(Y/N)', 'Age_(yrs)', 'Weight_(Kg)',\n       'Height(Cm)', 'BMI', 'Blood_Group', 'Pulse_rate(bpm)',\n       'RR_(breaths/min)', 'Hb(g/dl)', 'Cycle(R/I)', 'Cycle_length(days)',\n       'Marriage_Status_(Yrs)', 'Pregnant(Y/N)', 'No_of_aborptions',\n       'FSH(mIU/mL)', 'LH(mIU/mL)', 'FSH/LH', 'Hip(inch)', 'Waist(inch)',\n       'Waist:Hip_Ratio', 'TSH_(mIU/L)', 'AMH(ng/mL)', 'PRL(ng/mL)',\n       'Vit_D3_(ng/mL)', 'PRG(ng/mL)', 'RBS(mg/dl)', 'Weight_gain(Y/N)',\n       'hair_growth(Y/N)', 'Skin_darkening (Y/N)', 'Hair_loss(Y/N)',\n       'Pimples(Y/N)', 'Fast_food_(Y/N)', 'Reg_Exercise(Y/N)',\n       'BP_Systolic(mmHg)', 'BP_Diastolic(mmHg)', 'Follicle_No.(L)',\n       'Follicle_No.(R)', 'Avg.Fsize(L)(mm)', 'Avg.Fsize(R)(mm)',\n       'Endometrium(mm)', 'Sl.No_y', 'PCOS(Y/N)_y',\n       'I_beta-HCG(mIU/mL)', 'II_beta-HCG(mIU/mL)', 'AMH(ng/mL)_y']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(['Sl.No_y', 'PCOS(Y/N)_y','AMH(ng/mL)_y'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have successfully loaded the data. "},{"metadata":{},"cell_type":"markdown","source":"# Fitting a Model"},{"metadata":{},"cell_type":"markdown","source":"Before fitting the model, we will have to split our data into **train**, **valid** and **test** sets. We can use sklearn's train_test_split function to split our data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\ntarget = data['PCOS_(Y/N)']\ndata.drop('PCOS_(Y/N)',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,7))\nsns.countplot(target)\nplt.title('Data imbalance')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test, y_train, y_test = train_test_split(data, target, test_size=0.15, random_state=1, stratify = target)\nX_train,X_valid, y_train, y_valid =  train_test_split(X_train, y_train, test_size=0.3, random_state=1, stratify=y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\ndef print_scores(m):\n    res = [roc_auc_score(y_train,m.predict_proba(X_train)[:,1]),roc_auc_score(y_valid,m.predict_proba(X_valid)[:,1])]\n    for r in res:\n        print(r)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(n_jobs=-1,n_estimators=150,max_features='sqrt',min_samples_leaf=10)\nrf.fit(X_train,y_train)\nprint_scores(rf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\ny_pred_proba = rf.predict_proba(X_valid)[:,1]\nfpr, tpr, thresholds = roc_curve(y_valid, y_pred_proba)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,7))\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr,tpr, label='Knn')\nplt.xlabel('fpr')\nplt.ylabel('tpr')\nplt.title('Knn(n_neighbors=11) ROC curve')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we are getting a high roc auc score, lets start with out Exploratory Data Analysis"},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_fi(m, df):\n    return pd.DataFrame({'col': df.columns, 'imp': m.feature_importances_}).sort_values('imp',ascending=False)\n\n#lets get the feature importances for training set\nfi = get_fi(rf,X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_fi(df):\n    df.plot('col','imp','barh',figsize=(10,10))\n    \nplot_fi(fi)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Observations\n* We can see that the top features are:\n    1. Follicle_No.(R)\n    2. Follicle_No.(L)\n    3. hair_growth(Y/N)\n    4. Skin_darkening (Y/N)\n    5. Weight_gain(Y/N)\n    6. Fast_food_(Y/N)\n    7. Cycle(R/I)\n    8. AMH(ng/mL)\n    9. Cycle_length(days)\n    10. Pimples(Y/N)"},{"metadata":{},"cell_type":"markdown","source":"Lets plot data important features and look if we can find some interesting relationships"},{"metadata":{},"cell_type":"markdown","source":"# To be continued..."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}