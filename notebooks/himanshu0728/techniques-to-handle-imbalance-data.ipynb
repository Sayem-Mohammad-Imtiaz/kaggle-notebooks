{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Techniques to handle imbalance data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#PIMA diabetes dataset\n#column_names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\ndata = pd.read_csv('../input/pima-indians-diabetes-database/diabetes.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data['Outcome'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# class count\nclass_count_0, class_count_1 = data['Outcome'].value_counts()\n\n# Separate class\nclass_0 = data[data['Outcome'] == 0]\nclass_1 = data[data['Outcome'] == 1]\n\n# print the shape of the class\nprint('class 0 : ', class_0.shape)\nprint('class 1 : ', class_1.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Techniques\n1. Random Under-Sampling\n2. Random Over-Sampling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Random Under-Smapling\nclass_0_under = class_0.sample(class_count_1)\n\n# print the shape of the class\nprint(\"class_0_under : \",class_0_under.shape)\nprint('class 1 : ', class_1.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Random Over-Smapling\nclass_1_over = class_1.sample(class_count_0,replace=True)\n\n# print the shape of the class\nprint('class 0 : ', class_0.shape)\nprint(\"class_1_over : \",class_1_over.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(class_0_under)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Balance data with the imbalanced-learn python module\nLetâ€™s apply some of these resampling techniques, using the Python library imbalanced-learn.\nIt is compatible with scikit-learn and is part of scikit-learn-contrib projects.\n\nInstall imblearn model\n\n1. Command : pip install -U imbalanced-learn\n\n2. Command : conda install -c conda-forge imbalanced-learn (I have used this.)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#import imblearn","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*RandomUnderSampler* is a fast and easy way to balance the data by randomly selecting a subset of data for the targeted classes. Under-sample the majority class(es) by randomly picking samples with or without replacement.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.under_sampling import RandomUnderSampler\nrus = RandomUnderSampler(random_state=10)\n\nX = data.drop(['Outcome'],axis=1)\ny = data[['Outcome']]\n\nX_rus, y_rus = rus.fit_resample(X,y)\n\n# plot\nsns.countplot(y_rus['Outcome'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y['Outcome'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import RandomOverSampler\nros = RandomOverSampler(random_state=10)\n\nX = data.drop(['Outcome'],axis=1)\ny = data[['Outcome']]\n\nX_ros, y_ros = ros.fit_resample(X,y)\n\n# plot\nsns.countplot(y_ros['Outcome'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Synthetic Minority Oversampling Technique (SMOTE)\nThis technique generates synthetic data for the minority class.\n\nSMOTE (Synthetic Minority Oversampling Technique) works by randomly picking a point from the minority class and computing the k-nearest neighbors for this point. The synthetic points are added between the chosen point and its neighbors.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nsmote = SMOTE(random_state=10)\n\nX = data.drop(['Outcome'],axis=1)\ny = data[['Outcome']]\n\nX_smote, y_smote = smote.fit_resample(X,y)\n\n# plot\nsns.countplot(y_smote['Outcome'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# NearMiss\nNearMiss is an under-sampling technique. Instead of resampling the Minority class, using a distance, this will make the majority class equal to the minority class.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.under_sampling import NearMiss\nnm = NearMiss()\n\nX = data.drop(['Outcome'],axis=1)\ny = data[['Outcome']]\n\nX_nm, y_nm = nm.fit_resample(X,y)\n\n# plot\nsns.countplot(y_nm['Outcome'])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}