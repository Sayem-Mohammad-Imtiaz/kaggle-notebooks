{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We want to predict \"pm\". So we load the data and we create the validation data set"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/pmsm_temperature_data.csv')\n\nprint(data.describe())\n\n#print(data.isnull().sum()) #non ci sono valori nulli\n\n#prendo la label\nlabel = data['pm']\n\n#prendo i dati\ndata.drop('pm', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('data number of rows is {}'.format(data.iloc[:,0].value_counts().sum()))\nprint('label number of rows is {}'.format(label.value_counts().sum()))\ndata.pop('profile_id')\nprint(plt.matshow(data.corr()))\n\n\nprint(data.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#divido in test set\n\ntrain_data, test_data, train_label, test_label = train_test_split(data, label, test_size=0.1)\n\n\nprint('train_data.size is {}'.format(train_data.iloc[:,1].value_counts().sum()))\nprint('train_label.size is {}'.format(train_label.value_counts().sum()))\n\nprint('test_data.size is {}'.format(test_data.iloc[:,1].value_counts().sum()))\nprint('test_label.size is {}'.format(test_label.value_counts().sum()))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We create a simple regression model with Tensorflow and Keras!!"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel = keras.models.Sequential()\n\nmodel.add(keras.layers.Dense(32, input_shape=([len(train_data.keys())])))\nmodel.add(keras.layers.BatchNormalization())\nmodel.add(keras.layers.Activation('relu'))\n\nmodel.add(keras.layers.Dense(256))\nmodel.add(keras.layers.BatchNormalization())\nmodel.add(keras.layers.Activation('relu'))\n\nmodel.add(keras.layers.Dense(512))\nmodel.add(keras.layers.BatchNormalization())\nmodel.add(keras.layers.Activation('relu'))\n\nmodel.add(keras.layers.Dense(2048))\nmodel.add(keras.layers.BatchNormalization())\nmodel.add(keras.layers.Activation('relu'))\n\nmodel.add(keras.layers.Dense(1024))\nmodel.add(keras.layers.BatchNormalization())\nmodel.add(keras.layers.Activation('relu'))\n\nmodel.add(keras.layers.Dense(512))\nmodel.add(keras.layers.BatchNormalization())\nmodel.add(keras.layers.Activation('relu'))\n\nmodel.add(keras.layers.Dense(256))\nmodel.add(keras.layers.BatchNormalization())\nmodel.add(keras.layers.Activation('relu'))\n\nmodel.add(keras.layers.Dense(128))\nmodel.add(keras.layers.BatchNormalization())\nmodel.add(keras.layers.Activation('relu'))\n\nmodel.add(keras.layers.Dense(64))\nmodel.add(keras.layers.BatchNormalization())\nmodel.add(keras.layers.Activation('relu'))\n\nmodel.add(keras.layers.Dense(32))\nmodel.add(keras.layers.BatchNormalization())\nmodel.add(keras.layers.Activation('relu'))\n\nmodel.add(keras.layers.Dense(1))\n\nmodel.summary()\n\nmodel.compile(optimizer='adam', loss='mean_absolute_error' , metrics=['mean_absolute_error'])\nhistory = model.fit(train_data, train_label, epochs=10)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We plot the accuracy with mean squared error and the various epochs!!"},{"metadata":{"trusted":true},"cell_type":"code","source":"# NOT OK ..... history = model.evaluate(test_data, test_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['mean_absolute_error']\nepochs_=range(0,10)  \n\nplt.plot(epochs_, acc, label='mean_absolute_error')\nplt.xlabel('no of epochs')\nplt.ylabel('mean_absolute_error')\n\n#acc_val = history.history['mean_absolute_error']\n#plt.plot(epochs_, acc_val, label=\"validation mean_squared_error\")\n\nplt.title(\"no of epochs vs accuracy\")\nplt.legend()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"and we avalueate the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport seaborn as sns\n\nax1 = sns.distplot(train_label, hist=False, color=\"r\", label=\"Actual Value\")\nsns.distplot(model.predict(train_data), hist=False, color=\"b\", label=\"Fitted Values\" , ax=ax1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(test_data, test_label)\n\nfor i in range(0,20):\n    print('target values is {} and the diff with the prediction is {}'.format(train_label.iloc[[i]],model.predict(train_data.iloc[[i]]) ))\n    #print('and prediction is {}'.format(model.predict(train_data.iloc[[i]])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"For any suggestion, please comment or if u like... upvote :)\n\nBye"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}