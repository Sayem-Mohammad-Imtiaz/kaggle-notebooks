{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-29T09:26:40.988646Z","iopub.execute_input":"2021-06-29T09:26:40.98916Z","iopub.status.idle":"2021-06-29T09:26:41.01122Z","shell.execute_reply.started":"2021-06-29T09:26:40.989053Z","shell.execute_reply":"2021-06-29T09:26:41.009988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Table of Contents\n* <a href=\"#intro\">Introduction</a>\n* <a href=\"#dataprep\">Data preparation</a>\n* <a href=\"#datavis\">Data visualization and exploration\n* <a href=\"#featureselection\">Feature selection\n* <a href=\"#hyptuning\">Hyperparameter tuning\n* <a href=\"#modelcomp\">Model Comparison and selection\n* <a href=\"#test\">Testing the final model\n* <a href=\"#intro\">Conclusion\n* <a href=\"#references\">References\n    ","metadata":{}},{"cell_type":"markdown","source":"# Introduction\n\nPlacements are very important in a college curricullum. Predicting which students have higher chances to be placed can help in filtering out students for specific companies. Thus saving time and increasing placement efficiency. \nAlthough this kind of work may give rise to some ethical issues. In this notebook we are not going to address or discuss those issues.\nThis is just an attempt to see how variuos model would work on this dataset and carry out data mining tasks on it.\nThe notebook prepares the data and creates visualization to understand effect of different factors on status of placement for a student. It also explains the feature selection procedure and how to test wether the selected features give us significantly improved results or not.\nIt also carry out hyperparameter tuning of models and selects the best model. The notebook demonstrates hyperparameter tuning of following models, Decision Tree, KNN, SVC, Random forest and Naive Bayes.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section1\"> </a>\n# **Importing the required packages and libraries**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.figure as figure\nfrom matplotlib.pyplot import gcf\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom scipy import stats\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import feature_selection as fs\nfrom sklearn.preprocessing import PowerTransformer\nfrom sklearn.ensemble import RandomForestClassifier","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:26:41.012707Z","iopub.execute_input":"2021-06-29T09:26:41.013041Z","iopub.status.idle":"2021-06-29T09:26:42.31528Z","shell.execute_reply.started":"2021-06-29T09:26:41.012997Z","shell.execute_reply":"2021-06-29T09:26:42.31433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"dataprep\"> </a>\n# **Date preparation**","metadata":{}},{"cell_type":"markdown","source":"# Importing the data and inspecting the dtypes","metadata":{}},{"cell_type":"code","source":"placement_data = pd.read_csv(\"../input/factors-affecting-campus-placement/Placement_Data_Full_Class.csv\")\nplacement_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:26:42.319172Z","iopub.execute_input":"2021-06-29T09:26:42.319496Z","iopub.status.idle":"2021-06-29T09:26:42.371827Z","shell.execute_reply.started":"2021-06-29T09:26:42.319465Z","shell.execute_reply":"2021-06-29T09:26:42.3708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#data preparation\nplacement_data.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:26:42.37306Z","iopub.execute_input":"2021-06-29T09:26:42.373399Z","iopub.status.idle":"2021-06-29T09:26:42.381048Z","shell.execute_reply.started":"2021-06-29T09:26:42.373372Z","shell.execute_reply":"2021-06-29T09:26:42.380091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#removing the unwanted columns\nfinal_df = placement_data.drop(columns=['sl_no', 'salary'])","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:26:42.382431Z","iopub.execute_input":"2021-06-29T09:26:42.382736Z","iopub.status.idle":"2021-06-29T09:26:42.394574Z","shell.execute_reply.started":"2021-06-29T09:26:42.382709Z","shell.execute_reply":"2021-06-29T09:26:42.393606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking the unique values for categorical columns\ncategorical_columns = final_df.columns[final_df.dtypes == object]\nfor col in categorical_columns:\n    print(\"Unique values for \", col ,\": \" ,final_df[col].unique())","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:26:42.395994Z","iopub.execute_input":"2021-06-29T09:26:42.396362Z","iopub.status.idle":"2021-06-29T09:26:42.415869Z","shell.execute_reply.started":"2021-06-29T09:26:42.396333Z","shell.execute_reply":"2021-06-29T09:26:42.414772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking the summary of descriptive features\ndescriptive_columns = final_df.columns[final_df.dtypes != object]\nfinal_df[descriptive_columns].describe()\n    ","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:26:42.419588Z","iopub.execute_input":"2021-06-29T09:26:42.419875Z","iopub.status.idle":"2021-06-29T09:26:42.453359Z","shell.execute_reply.started":"2021-06-29T09:26:42.419848Z","shell.execute_reply":"2021-06-29T09:26:42.452296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking if there are any NAs\nprint(final_df.isna().sum())\nprint(\"\\nNumber of records: \", final_df['gender'].count())","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:26:42.455562Z","iopub.execute_input":"2021-06-29T09:26:42.455895Z","iopub.status.idle":"2021-06-29T09:26:42.463963Z","shell.execute_reply.started":"2021-06-29T09:26:42.455867Z","shell.execute_reply":"2021-06-29T09:26:42.463145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"datavis\"> </a>\n# Data visualization and exploration","metadata":{}},{"cell_type":"code","source":"#exploring different types of descriptive features\nfigure, axes = plt.subplots(3,2,figsize=(11, 11))\nfigure.delaxes(axes[2,1])\ni = 0\n\nfigure.suptitle('Distribution of descriptive features')\n\nfor ax in axes:\n    for a in ax:\n        if(i == 5):\n            break\n        sns.histplot(ax = a, data = final_df, x = descriptive_columns[i],bins=30)\n        a.axvline(np.mean(final_df[descriptive_columns[i]]),color='red', linestyle='--', label=(\"Average = \" + str( round(np.mean(final_df[descriptive_columns[i]]),2) )) )\n        i = i + 1\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:26:42.465754Z","iopub.execute_input":"2021-06-29T09:26:42.466047Z","iopub.status.idle":"2021-06-29T09:26:43.664858Z","shell.execute_reply.started":"2021-06-29T09:26:42.466018Z","shell.execute_reply":"2021-06-29T09:26:43.663816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have data for 215 students. Observing the above figure and due to the central limit theorem we can conclude that the distribution of every descriptive feature is normal. ","metadata":{}},{"cell_type":"code","source":"#visualizing different categorical variables\nfigure, axes = plt.subplots(4,2,figsize=(10, 16))\ni = 0\nsns.set_theme(style=\"whitegrid\")\nfigure.suptitle('Distribution of categorical features')\n\nfor ax in axes:\n    for a in ax:\n        sns.countplot(ax = a, data = final_df, x = categorical_columns[i])\n        i = i + 1\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:26:43.666073Z","iopub.execute_input":"2021-06-29T09:26:43.666385Z","iopub.status.idle":"2021-06-29T09:26:44.448246Z","shell.execute_reply.started":"2021-06-29T09:26:43.666356Z","shell.execute_reply":"2021-06-29T09:26:44.447302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"An imbalance can be observed for status which is our target variable. Hence, we will be using stratified  cross validation.","metadata":{}},{"cell_type":"code","source":"#visualising effect of other features on 'status'\nfigure, axes = plt.subplots(4,2,figsize=(10, 16))\nfigure.delaxes(axes[3,1])\ni = 0\nsns.set_theme(style=\"whitegrid\")\nfigure.suptitle('Status vs other categorical features')\n\nfor ax in axes:\n    for a in ax:\n        if( i == 8 ):\n            break\n        if(categorical_columns[i] != 'status'):\n            sns.countplot(ax = a, x=\"status\", hue=categorical_columns[i], data=final_df, palette=['#432371',\"#FAAE7B\", \"#1082a8\"])\n        i = i + 1\n\nplt.show()\n\n# sns.set_theme(style=\"whitegrid\")\n# sns.countplot(x=\"status\", hue=\"specialisation\", data=final_df, palette=['#432371',\"#FAAE7B\", \"#1082a8\"])","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:26:44.449465Z","iopub.execute_input":"2021-06-29T09:26:44.449763Z","iopub.status.idle":"2021-06-29T09:26:45.458396Z","shell.execute_reply.started":"2021-06-29T09:26:44.449734Z","shell.execute_reply":"2021-06-29T09:26:45.457329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From above visualization, we can conlude that specialisation has an influence over the decision of placement.","metadata":{}},{"cell_type":"code","source":"#data vis and exploration\nfigure, axes = plt.subplots(3,2,figsize=(10, 17))\nfigure.delaxes(axes[2,1])\ni = 0\n\nfigure.suptitle('Status vs other descriptive feature')\n\nfor ax in axes:\n    for a in ax:\n        if(i == 5):\n            break\n        sns.boxplot(ax = a, x=\"status\", y=descriptive_columns[i], data=final_df)\n        i = i + 1\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:26:45.460553Z","iopub.execute_input":"2021-06-29T09:26:45.460832Z","iopub.status.idle":"2021-06-29T09:26:46.275055Z","shell.execute_reply.started":"2021-06-29T09:26:45.460805Z","shell.execute_reply":"2021-06-29T09:26:46.274141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can confirm that the scores matter alot during the placement decisions. Scores have more importance in student selection than work experience.","metadata":{}},{"cell_type":"markdown","source":" <a id=\"dataprepML\"> </a>\n # Preparing the data for machine learning tasks - Feature selection, hyper parameter tuning and model selection.","metadata":{}},{"cell_type":"code","source":"#one hot encoding on categorical variables\nfor col in categorical_columns:\n    if(len(final_df[col].unique()) == 2):\n        final_df[col] = pd.get_dummies(final_df[col], drop_first=True)\n\nfinal_df = pd.get_dummies(final_df)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:26:46.276458Z","iopub.execute_input":"2021-06-29T09:26:46.276752Z","iopub.status.idle":"2021-06-29T09:26:46.298332Z","shell.execute_reply.started":"2021-06-29T09:26:46.276715Z","shell.execute_reply":"2021-06-29T09:26:46.297171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#data standardization for descriptive features\nfor col in final_df.columns:\n    final_df[[col]] = preprocessing.MinMaxScaler().fit_transform(final_df[[col]])","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:26:46.300151Z","iopub.execute_input":"2021-06-29T09:26:46.300592Z","iopub.status.idle":"2021-06-29T09:26:46.394532Z","shell.execute_reply.started":"2021-06-29T09:26:46.300547Z","shell.execute_reply":"2021-06-29T09:26:46.393661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#observing the final dataframe created after data normalization\nfinal_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:26:46.395867Z","iopub.execute_input":"2021-06-29T09:26:46.396291Z","iopub.status.idle":"2021-06-29T09:26:46.432604Z","shell.execute_reply.started":"2021-06-29T09:26:46.396253Z","shell.execute_reply":"2021-06-29T09:26:46.43156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#seperating the target variable\ndata = final_df.drop(columns=['status'])\ntarget = final_df['status']","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:26:46.43385Z","iopub.execute_input":"2021-06-29T09:26:46.434156Z","iopub.status.idle":"2021-06-29T09:26:46.440164Z","shell.execute_reply.started":"2021-06-29T09:26:46.434125Z","shell.execute_reply":"2021-06-29T09:26:46.439226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"featureselection\"> </a>\n# **Feature selection**","metadata":{}},{"cell_type":"code","source":"#defining the global variables\n\n#we will be selecting top 5 features\nnum_features = 5\n\n#defining the cross validation method\ncross_validation = RepeatedStratifiedKFold(n_splits=5,\n                                          n_repeats=3,\n                                          random_state=999)\n#defning the scoring metric \nscoring_metric = 'accuracy'","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:26:46.441472Z","iopub.execute_input":"2021-06-29T09:26:46.441827Z","iopub.status.idle":"2021-06-29T09:26:46.452103Z","shell.execute_reply.started":"2021-06-29T09:26:46.441798Z","shell.execute_reply":"2021-06-29T09:26:46.451271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#training the decision tree algorithm on full set of features\ndt_clf = DecisionTreeClassifier()\n\n#generating the cross validation score\ncross_validation_full = cross_val_score(estimator=dt_clf,\n                             X=data,\n                             y=target, \n                             cv=cross_validation, \n                             scoring=scoring_metric)\n\n#printing the result\nprint(\"\\033[1m Accuracy on full set of features (DT classifier): \\033[0m\" + str(cross_validation_full.mean().round(3)))","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:26:46.453387Z","iopub.execute_input":"2021-06-29T09:26:46.453669Z","iopub.status.idle":"2021-06-29T09:26:46.556108Z","shell.execute_reply.started":"2021-06-29T09:26:46.453641Z","shell.execute_reply":"2021-06-29T09:26:46.555141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#mutual information\n#creating mutual info algorithm\nmutual_info = fs.SelectKBest(fs.mutual_info_classif, k=num_features)\n\n#fitting the data and getting the ranked features\nmutual_info.fit_transform(data, target)\n\n#getting the top 5 indices of the features by sorting them by their scores\nindices_mutual_info = np.argsort(mutual_info.scores_)[::-1][0:num_features]\n\n#printing the array of top 5 features\nbest_features_mi = data.columns[indices_mutual_info].values\nbest_features_mi","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:26:46.557319Z","iopub.execute_input":"2021-06-29T09:26:46.557594Z","iopub.status.idle":"2021-06-29T09:26:46.615132Z","shell.execute_reply.started":"2021-06-29T09:26:46.557567Z","shell.execute_reply":"2021-06-29T09:26:46.614184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plotting the importances of the features\nfeature_importances_mi = mutual_info.scores_[indices_mutual_info]\n\n#visualizing the top 5 features and their scores\nplt.bar(best_features_mi, feature_importances_mi, color='cadetblue')\nplt.xlabel(\"Features\")\nplt.xlabel(\"Importance score\")\nplt.title(\"Top 5 features selected by Mutual information\")\nplt.xticks(fontsize=8, rotation=45)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:26:46.616349Z","iopub.execute_input":"2021-06-29T09:26:46.616638Z","iopub.status.idle":"2021-06-29T09:26:46.782871Z","shell.execute_reply.started":"2021-06-29T09:26:46.616608Z","shell.execute_reply":"2021-06-29T09:26:46.782157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#calculating the cross validation result of recall on selected 5 features\ncv_results_mi = cross_val_score(estimator=dt_clf,\n                             X=data.iloc[:,indices_mutual_info],\n                             y=target, \n                             cv=cross_validation, \n                             scoring=scoring_metric)\n#printing the result\nprint(\"\\033[1m Cross validation accuracy score on features selected by mutual info (DT classifier): \\033[0m\" + str(cv_results_mi.mean().round(3)))","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:26:46.783884Z","iopub.execute_input":"2021-06-29T09:26:46.784283Z","iopub.status.idle":"2021-06-29T09:26:46.873909Z","shell.execute_reply.started":"2021-06-29T09:26:46.784254Z","shell.execute_reply":"2021-06-29T09:26:46.87326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating random forest classifier with 100 estimators\nrfi = RandomForestClassifier(n_estimators=100)\n\n#fitting the data\nrfi.fit(data, target)\n\n#getting the indices of top 5 features sorted by their importance\nindices_rfi = np.argsort(rfi.feature_importances_)[::-1][0:num_features]","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:26:46.874846Z","iopub.execute_input":"2021-06-29T09:26:46.875243Z","iopub.status.idle":"2021-06-29T09:26:47.074771Z","shell.execute_reply.started":"2021-06-29T09:26:46.875202Z","shell.execute_reply":"2021-06-29T09:26:47.074029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#printing the top 5 features selected by rfi\nbest_features_rfi = data.columns[indices_rfi].values\nbest_features_rfi","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:26:47.078124Z","iopub.execute_input":"2021-06-29T09:26:47.078556Z","iopub.status.idle":"2021-06-29T09:26:47.083201Z","shell.execute_reply.started":"2021-06-29T09:26:47.078527Z","shell.execute_reply":"2021-06-29T09:26:47.082486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plotting the importances of the features\nfeature_importances_rfi = rfi.feature_importances_[indices_rfi]\n\n#visualizing the top 5 features and their scores\nplt.bar(best_features_rfi, feature_importances_rfi, color='cadetblue')\nplt.xlabel(\"Features\")\nplt.xlabel(\"Importance score\")\nplt.title(\"Top 5 features selected by Random forest information\")\nplt.xticks(fontsize=8, rotation=45)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:26:47.084837Z","iopub.execute_input":"2021-06-29T09:26:47.085294Z","iopub.status.idle":"2021-06-29T09:26:47.264527Z","shell.execute_reply.started":"2021-06-29T09:26:47.085259Z","shell.execute_reply":"2021-06-29T09:26:47.26384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#calculating the cross validation result of recall on selected 5 features\ncv_results_rfi = cross_val_score(estimator=dt_clf,\n                             X=data.iloc[:, indices_rfi],\n                             y=target, \n                             cv=cross_validation, \n                             scoring=scoring_metric)\n#printing the result\nprint(\"\\033[1m Cross validation accuracy score on features selected by rfi (DT classifier): \\033[0m\" + str(cv_results_rfi.mean().round(3)))","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:26:47.265503Z","iopub.execute_input":"2021-06-29T09:26:47.265865Z","iopub.status.idle":"2021-06-29T09:26:47.351818Z","shell.execute_reply.started":"2021-06-29T09:26:47.265837Z","shell.execute_reply":"2021-06-29T09:26:47.351185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating the fscore algorithm\nfit_fscore = fs.SelectKBest(fs.f_classif, k=num_features)\n\n#fitting the algorithm\nfit_fscore.fit_transform(data, target)\n\n#getting the top 5 features \nindices_fscore = np.argsort(np.nan_to_num(fit_fscore.scores_))[::-1][0:num_features]\nbest_features_fscore = data.columns[indices_fscore].values\nbest_features_fscore","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:26:47.352771Z","iopub.execute_input":"2021-06-29T09:26:47.353148Z","iopub.status.idle":"2021-06-29T09:26:47.366279Z","shell.execute_reply.started":"2021-06-29T09:26:47.353112Z","shell.execute_reply":"2021-06-29T09:26:47.36538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plotting the importances of the features\nfeature_importances_fscore = fit_fscore.scores_[indices_fscore]\n\n#visualizing the top 5 features and their scores\nplt.bar(best_features_rfi, feature_importances_rfi, color='cadetblue')\nplt.xlabel(\"Features\")\nplt.xlabel(\"Importance score\")\nplt.title(\"Top 5 features selected by F-score\")\nplt.xticks(fontsize=8, rotation=45)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:26:47.367507Z","iopub.execute_input":"2021-06-29T09:26:47.367794Z","iopub.status.idle":"2021-06-29T09:26:47.529974Z","shell.execute_reply.started":"2021-06-29T09:26:47.367766Z","shell.execute_reply":"2021-06-29T09:26:47.528954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#calculating the cross validation result of recall on selected 5 features\ncv_results_fscore = cross_val_score(estimator=dt_clf,\n                             X=data.iloc[:, indices_fscore],\n                             y=target, \n                             cv=cross_validation, \n                             scoring=scoring_metric)\nprint(\"\\033[1m Cross validation accuracy score on features selected by  info (DT classifier): \\033[0m\" + str(cv_results_fscore.mean().round(3)))","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:26:47.531246Z","iopub.execute_input":"2021-06-29T09:26:47.531545Z","iopub.status.idle":"2021-06-29T09:26:47.617855Z","shell.execute_reply.started":"2021-06-29T09:26:47.531517Z","shell.execute_reply":"2021-06-29T09:26:47.616664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#comparing features cross validation accuracy\n#creating variables to compare scores of different feature selection methods\nset_of_feature_selection_method = ['Full Set of Features', 'F-Score', 'Mutual Information', 'RFI']\nset_of_scores = [cross_validation_full.mean().round(3), cv_results_fscore.mean().round(3), cv_results_mi.mean().round(3), cv_results_rfi.mean().round(3)]","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:26:47.618927Z","iopub.execute_input":"2021-06-29T09:26:47.619192Z","iopub.status.idle":"2021-06-29T09:26:47.623433Z","shell.execute_reply.started":"2021-06-29T09:26:47.619166Z","shell.execute_reply":"2021-06-29T09:26:47.622707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#visualizing the cross validation scores given by different feaure selection methods\nplt.bar(set_of_feature_selection_method, set_of_scores, color='cadetblue')\nplt.xlabel(\"Feature selection method\")\nplt.xlabel(\"Cross validation score\")\nplt.title(\"Comapring different feature selection methods\")\nplt.xticks(fontsize=8, rotation=45)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:26:47.62433Z","iopub.execute_input":"2021-06-29T09:26:47.624695Z","iopub.status.idle":"2021-06-29T09:26:47.796736Z","shell.execute_reply.started":"2021-06-29T09:26:47.624668Z","shell.execute_reply":"2021-06-29T09:26:47.795914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As it can observed, mutual information and f-score has better scores than others. But are the scores significantly more than others? We will now check this using paired T-test of significance.","metadata":{}},{"cell_type":"code","source":"#performing a two sided paired t-test\nprint(stats.ttest_rel(cross_validation_full, cv_results_fscore).pvalue.round(3))\nprint(stats.ttest_rel(cross_validation_full, cv_results_mi).pvalue.round(3))\nprint(stats.ttest_rel(cross_validation_full, cv_results_rfi).pvalue.round(3))","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:26:47.79773Z","iopub.execute_input":"2021-06-29T09:26:47.798121Z","iopub.status.idle":"2021-06-29T09:26:47.806834Z","shell.execute_reply.started":"2021-06-29T09:26:47.798083Z","shell.execute_reply":"2021-06-29T09:26:47.805817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All the p-values are greater than 0.05 (p > 0.05), the result is not statistically significant. Hence, we can say that modelling with top 5 features don't give us a better result.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"hyptuning\"> </a>\n# Hyperparameter tuning and model selection","metadata":{}},{"cell_type":"code","source":"#splitting the data into 75% train and 25% test\ntrain_data, test_data, train_target, test_target = train_test_split(data, target, test_size=0.20, random_state=999)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:26:47.807988Z","iopub.execute_input":"2021-06-29T09:26:47.808269Z","iopub.status.idle":"2021-06-29T09:26:47.818689Z","shell.execute_reply.started":"2021-06-29T09:26:47.808243Z","shell.execute_reply":"2021-06-29T09:26:47.817832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating the array for different values of var smoothing variable\nnp.logspace(0,-9, num=10)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:26:47.819729Z","iopub.execute_input":"2021-06-29T09:26:47.81999Z","iopub.status.idle":"2021-06-29T09:26:47.829245Z","shell.execute_reply.started":"2021-06-29T09:26:47.819966Z","shell.execute_reply":"2021-06-29T09:26:47.82836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#setting the random seed\nnp.random.seed(999)\n\n#creating default NB classifier\nnb_classifier = GaussianNB()\n\n#defining parameters to test\nparams_NB = {'var_smoothing': np.logspace(0,-9, num=100)}\n\n#creating the GridSearch algorithm on NB classifier\ngs_NB = GridSearchCV(estimator=nb_classifier, \n                     param_grid=params_NB, \n                     cv=cross_validation,\n                     verbose=1, \n                     scoring=scoring_metric)\n\n#NB expects data to be in normal distribution hence converting it using power transform\nData_transformed = PowerTransformer().fit_transform(train_data)\n\n#fitting the data\ngs_NB.fit(Data_transformed, train_target);\n","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:26:47.830268Z","iopub.execute_input":"2021-06-29T09:26:47.830533Z","iopub.status.idle":"2021-06-29T09:26:50.656581Z","shell.execute_reply.started":"2021-06-29T09:26:47.830507Z","shell.execute_reply":"2021-06-29T09:26:50.655602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#getting the best params\nnb_best_params = gs_NB.best_params_\nnb_best_params","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:26:50.658073Z","iopub.execute_input":"2021-06-29T09:26:50.658501Z","iopub.status.idle":"2021-06-29T09:26:50.664807Z","shell.execute_reply.started":"2021-06-29T09:26:50.658459Z","shell.execute_reply":"2021-06-29T09:26:50.663649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#getting the best score of NB\nnb_best_score = gs_NB.best_score_\nnb_best_score","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:26:50.666382Z","iopub.execute_input":"2021-06-29T09:26:50.666784Z","iopub.status.idle":"2021-06-29T09:26:50.677479Z","shell.execute_reply.started":"2021-06-29T09:26:50.666744Z","shell.execute_reply":"2021-06-29T09:26:50.676285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#defining parameters\nparameters={\"splitter\":[\"best\",\"random\"],\n            \"max_depth\" : [1,3,5,7,9,11,12],\n           \"min_samples_leaf\":[1,2,3,4,5,6,7,8,9,10],\n           \"min_weight_fraction_leaf\":[0.1,0.2,0.3,0.4,0.5],\n           \"max_features\":[\"auto\",\"log2\",\"sqrt\",None],\n           \"max_leaf_nodes\":[None,10,20,30,40,50,60,70,80,90] }\n\n#creating default DT classifier\ndt_clf = DecisionTreeClassifier()\n\n#creating the GridSearch algorithm on DT classifier\ndt_grid = GridSearchCV(estimator=dt_clf,\n                          param_grid=parameters,\n                          scoring=scoring_metric,\n                          cv=cross_validation,\n                          verbose=1)\n\ndt_grid.fit(train_data,train_target)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:26:50.678706Z","iopub.execute_input":"2021-06-29T09:26:50.679226Z","iopub.status.idle":"2021-06-29T10:03:36.588227Z","shell.execute_reply.started":"2021-06-29T09:26:50.679173Z","shell.execute_reply":"2021-06-29T10:03:36.586883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#getting the best params given by Grid search\ndt_best_params = dt_grid.best_params_\ndt_best_params","metadata":{"execution":{"iopub.status.busy":"2021-06-29T10:03:36.589832Z","iopub.execute_input":"2021-06-29T10:03:36.59049Z","iopub.status.idle":"2021-06-29T10:03:36.598755Z","shell.execute_reply.started":"2021-06-29T10:03:36.590336Z","shell.execute_reply":"2021-06-29T10:03:36.597511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#getting the best score of DT\ndt_best_score = dt_grid.best_score_\ndt_best_score","metadata":{"execution":{"iopub.status.busy":"2021-06-29T10:03:36.600425Z","iopub.execute_input":"2021-06-29T10:03:36.600926Z","iopub.status.idle":"2021-06-29T10:03:36.619151Z","shell.execute_reply.started":"2021-06-29T10:03:36.600877Z","shell.execute_reply":"2021-06-29T10:03:36.617927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#specifying params for SVC\nparam_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}\n\n#creating default SV classifier\nsvc_clf = SVC()\n\n#creating the GridSearch algorithm on SV classifier\nsvc_grid = GridSearchCV(estimator=svc_clf,\n                        param_grid=param_grid,\n                        refit=True,\n                        verbose=1, \n                        cv=cross_validation, \n                        scoring=scoring_metric)\n\nsvc_grid.fit(train_data,train_target)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T10:03:36.621254Z","iopub.execute_input":"2021-06-29T10:03:36.621719Z","iopub.status.idle":"2021-06-29T10:03:41.546312Z","shell.execute_reply.started":"2021-06-29T10:03:36.621672Z","shell.execute_reply":"2021-06-29T10:03:41.545464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#getting the best params\nsvc_best_params = svc_grid.best_params_\nsvc_best_params","metadata":{"execution":{"iopub.status.busy":"2021-06-29T10:03:41.54756Z","iopub.execute_input":"2021-06-29T10:03:41.547827Z","iopub.status.idle":"2021-06-29T10:03:41.554179Z","shell.execute_reply.started":"2021-06-29T10:03:41.5478Z","shell.execute_reply":"2021-06-29T10:03:41.553162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#getting the best score of SVC\nsvc_best_score = svc_grid.best_score_\nsvc_best_score","metadata":{"execution":{"iopub.status.busy":"2021-06-29T10:03:41.555495Z","iopub.execute_input":"2021-06-29T10:03:41.555833Z","iopub.status.idle":"2021-06-29T10:03:41.574921Z","shell.execute_reply.started":"2021-06-29T10:03:41.555802Z","shell.execute_reply":"2021-06-29T10:03:41.573691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#defining KNN's parameters\nparams_KNN = {'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8 , 9 , 10,11,12,13,14,15,16,17,18,19,20], \n              'p': [1, 2, 5]}\n\n#creating default KNN classifier\nknn_clf = KNeighborsClassifier()\n\n#creating the GridSearch algorithm on KNN classifier\ngs_KNN = GridSearchCV(estimator=knn_clf, \n                      param_grid=params_KNN,\n                      cv=cross_validation,\n                      verbose=1,  # verbose: the higher, the more messages\n                      scoring=scoring_metric, \n                      return_train_score=True)\n\ngs_KNN.fit(train_data, train_target)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T10:03:41.576741Z","iopub.execute_input":"2021-06-29T10:03:41.577303Z","iopub.status.idle":"2021-06-29T10:04:06.217153Z","shell.execute_reply.started":"2021-06-29T10:03:41.577255Z","shell.execute_reply":"2021-06-29T10:04:06.216035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#getting the best params of KNN\nknn_best_params = gs_KNN.best_params_\nknn_best_params","metadata":{"execution":{"iopub.status.busy":"2021-06-29T10:04:06.218551Z","iopub.execute_input":"2021-06-29T10:04:06.218963Z","iopub.status.idle":"2021-06-29T10:04:06.225861Z","shell.execute_reply.started":"2021-06-29T10:04:06.218919Z","shell.execute_reply":"2021-06-29T10:04:06.22463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#getting the best scores of KNN\nKNN_best_score = gs_KNN.best_score_\nKNN_best_score","metadata":{"execution":{"iopub.status.busy":"2021-06-29T10:04:06.227637Z","iopub.execute_input":"2021-06-29T10:04:06.228109Z","iopub.status.idle":"2021-06-29T10:04:06.241923Z","shell.execute_reply.started":"2021-06-29T10:04:06.228059Z","shell.execute_reply":"2021-06-29T10:04:06.24081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#defining random forest's parameters\nparam_rfc = {\n    'criterion' :['gini', 'entropy'],\n    'n_estimators': [100, 200, 500],\n    'max_depth' : [2,3,4,5,6,7,8],\n    'max_features': ['auto', 'sqrt', 'log2']\n}\n\n#creating default RandomForest classifier\nrfc_clf = RandomForestClassifier(random_state=999)\n\n#creating the GridSearch algorithm on RandomForest classifier\ncv_rfc = GridSearchCV(estimator=rfc_clf, \n                      param_grid=param_rfc,\n                      cv= cross_validation,\n                      scoring=scoring_metric,\n                      verbose=1)\n\ncv_rfc.fit(train_data, train_target)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T10:04:06.243431Z","iopub.execute_input":"2021-06-29T10:04:06.243864Z","iopub.status.idle":"2021-06-29T10:20:02.299261Z","shell.execute_reply.started":"2021-06-29T10:04:06.243827Z","shell.execute_reply":"2021-06-29T10:20:02.298333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Best parameters of random forest\nrfc_best_params = cv_rfc.best_params_\nrfc_best_params","metadata":{"execution":{"iopub.status.busy":"2021-06-29T10:20:02.300444Z","iopub.execute_input":"2021-06-29T10:20:02.300739Z","iopub.status.idle":"2021-06-29T10:20:02.306736Z","shell.execute_reply.started":"2021-06-29T10:20:02.300709Z","shell.execute_reply":"2021-06-29T10:20:02.305819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Best score of randomforest\nrfc_best_score = cv_rfc.best_score_\nrfc_best_score","metadata":{"execution":{"iopub.status.busy":"2021-06-29T10:20:02.307871Z","iopub.execute_input":"2021-06-29T10:20:02.308156Z","iopub.status.idle":"2021-06-29T10:20:02.327878Z","shell.execute_reply.started":"2021-06-29T10:20:02.308128Z","shell.execute_reply":"2021-06-29T10:20:02.326774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"modelcomp\"> </a>\n# Model comparison and selection","metadata":{}},{"cell_type":"code","source":"#model comparison by visualising the best scores\nmodels = ['Naive Bayes', 'Decision Tree', 'KNN', 'SVM', 'Random Forest']\nscores_bf = [nb_best_score, dt_best_score, KNN_best_score, svc_best_score, rfc_best_score]\n\ndf = pd.DataFrame({\"models\": models, \"scores\": scores_bf})\n\nsns.barplot(data = df, x = \"models\", y=\"scores\", order=df.sort_values('scores', ascending=False).models)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-29T10:30:20.727726Z","iopub.execute_input":"2021-06-29T10:30:20.728331Z","iopub.status.idle":"2021-06-29T10:30:20.921802Z","shell.execute_reply.started":"2021-06-29T10:30:20.728278Z","shell.execute_reply":"2021-06-29T10:30:20.921052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can observe from the above barplot, Random forest gives us the best accuracy. Hence, we can use this model to test out data and see how many correct prediction it can perform.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"test\"> </a>\n# Testing the model with the unseen data","metadata":{}},{"cell_type":"code","source":"#predicting the test data using the best random forest classifier\n\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\n\nbest_RF = RandomForestClassifier(criterion='entropy', max_depth=7, max_features='auto', n_estimators=200, random_state=999)\n\nmodel = best_RF.fit(train_data, train_target)\n\npredicted = model.predict(test_data)\n\nprint(confusion_matrix(test_target, predicted))\n","metadata":{"execution":{"iopub.status.busy":"2021-06-29T10:20:02.658648Z","iopub.execute_input":"2021-06-29T10:20:02.658911Z","iopub.status.idle":"2021-06-29T10:20:03.071873Z","shell.execute_reply.started":"2021-06-29T10:20:02.658884Z","shell.execute_reply":"2021-06-29T10:20:03.071128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking the classification report\nprint(classification_report(test_target, predicted))","metadata":{"execution":{"iopub.status.busy":"2021-06-29T10:20:03.073066Z","iopub.execute_input":"2021-06-29T10:20:03.073378Z","iopub.status.idle":"2021-06-29T10:20:03.083002Z","shell.execute_reply.started":"2021-06-29T10:20:03.073348Z","shell.execute_reply":"2021-06-29T10:20:03.081952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So we got an overall accuracy of 91% on test data. During training, we tested our model with 5-fold cross validaton and observed an accuracy of around 85%.\nSo, \nTrain accuracy: 85%\nTest accuracy: 91%\n\nTherefore, we can confirm that the model is not overfitting!","metadata":{}},{"cell_type":"markdown","source":"<a id=\"conclusion\"> </a>\n# Conclusion\n1. Status of placement is highly influenced by the scores(percentages scored) and type of specialisation to choose\n2. We cannot select any best features from the data as the t-test was not significant. Hence, every feature contributes in decision of your placement\n3. Decision tree takes time to run and fit\n4. Random forest performed best with following parameters: {'criterion': 'entropy','max_depth': 7, 'max_features': 'auto','n_estimators': 200}\n5. There is no overfitting observed","metadata":{}},{"cell_type":"markdown","source":"<a id=\"references\"> </a>\n# References","metadata":{}},{"cell_type":"markdown","source":"SK Part 2: Feature Selection and Ranking | www.featureranking.com SK Part 2: Feature Selection and Ranking | www.featureranking.com. (2021). Retrieved 29 May 2021, from https://www.featureranking.com/tutorials/machine-learning-tutorials/sk-part-2-feature-selection-and-ranking/\n\nSK Part 3: Cross-Validation and Hyperparameter Tuning | www.featureranking.com SK Part 3: Cross-Validation and Hyperparameter Tuning | www.featureranking.com. (2021). Retrieved 29 May 2021, from https://www.featureranking.com/tutorials/machine-learning-tutorials/sk-part-3-cross-validation-and-hyperparameter-tuning/\n\nGridSearchCV, S. GridSearchCV, S. (2020). SVM Hyperparameter Tuning using GridSearchCV - Velocity Business Solutions Limited. Retrieved 29 May 2021, from https://www.vebuso.com/2020/03/svm-hyperparameter-tuning-using-gridsearchcv/","metadata":{}}]}