{"cells":[{"metadata":{"id":"irttwTyW3riz"},"cell_type":"markdown","source":"**Package Install**"},{"metadata":{"id":"HatmQTViHJ7R","trusted":true},"cell_type":"code","source":"!apt-get -qq install -y graphviz && pip install -q pydot\n!pip install torchvision\n!pip install torchviz\n!pip install -q kaggle\n!pip install torchsummary","execution_count":null,"outputs":[]},{"metadata":{"id":"M9cLbMHA3u_Z"},"cell_type":"markdown","source":"**Package Import**"},{"metadata":{"id":"8t-WVdS4HZMJ","trusted":true},"cell_type":"code","source":"import numpy as np\nfrom matplotlib import pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torchvision.datasets as dests\nfrom torch.utils import data\nfrom torch.autograd import Variable\nfrom torchvision import models\nfrom torchsummary import summary\nfrom torchviz import make_dot\nimport pandas as pd\nimport os\nfrom shutil import copyfile\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image\nfrom numpy import asarray\nfrom sklearn.metrics import confusion_matrix, multilabel_confusion_matrix\nfrom datetime import datetime\nfrom sklearn.preprocessing import MinMaxScaler","execution_count":null,"outputs":[]},{"metadata":{"id":"XxJhqrJ53_qU"},"cell_type":"markdown","source":"**Set Parameters**"},{"metadata":{"id":"9xEIlxh-cTVK","trusted":true},"cell_type":"code","source":"dateparse = lambda x: datetime.strptime(x, \"%Y-%m-%d\")\ndateconvert = lambda x: datetime.utcfromtimestamp(x*(1e-9)).strftime('%Y-%m-%d')\nINPUT_PATH = \"/kaggle/input/daily-historical-stock-prices-1970-2018\"\nOUTPUT_PATH = \"stock\"\nfrom_year = '2000'\nsequence_dim = 6 # number of look back data to predict one forward","execution_count":null,"outputs":[]},{"metadata":{"id":"kTM-vOqT4Dca"},"cell_type":"markdown","source":"**Load Data**"},{"metadata":{"id":"KF8fxi8nIxgr","outputId":"ab1758c6-2c45-4061-8b40-b3d68dff424c","trusted":true},"cell_type":"code","source":"df = pd.read_csv(INPUT_PATH+\"/historical_stock_prices.csv\",parse_dates=['date'],date_parser=dateparse)","execution_count":null,"outputs":[]},{"metadata":{"id":"MbrPX_5U4Hb8"},"cell_type":"markdown","source":"**Filter Data**"},{"metadata":{"id":"66-DULhEax5h","trusted":true},"cell_type":"code","source":"df = df.loc[(df.date>from_year)]","execution_count":null,"outputs":[]},{"metadata":{"id":"MQqrGUqC4Lt_"},"cell_type":"markdown","source":"**Company and Date collect**"},{"metadata":{"id":"1k1zAKwuI6en","trusted":true},"cell_type":"code","source":"company_list = df['ticker'].unique().tolist()\ncompany_list.sort()\ndate_list = df['date'].unique().tolist()\ndate_list = [ dateconvert(x) for  x in date_list]\ndate_list.sort()","execution_count":null,"outputs":[]},{"metadata":{"id":"4QW1u1AK4K-w"},"cell_type":"markdown","source":"**Index set to faster search**"},{"metadata":{"id":"HxHzJGoikPJs","trusted":true},"cell_type":"code","source":"df.set_index(['ticker', 'date'], inplace=True)\ndf = df.sort_values(\"date\")","execution_count":null,"outputs":[]},{"metadata":{"id":"igz6kMWd4Uob"},"cell_type":"markdown","source":"**Count highest number of data point**"},{"metadata":{"id":"jXN2WxM2oPAA","outputId":"4645b7be-648d-495f-ac4a-87f19defefb0","trusted":true},"cell_type":"code","source":"highest_data = -1\nfor item in company_list:\n  if  len(df.loc[item]) >= highest_data:\n    highest_data = len(df.loc[item])","execution_count":null,"outputs":[]},{"metadata":{"id":"96Zx6yEm4a53"},"cell_type":"markdown","source":"**Collect highest data companies**"},{"metadata":{"id":"G3EWEd4wleRW","trusted":true},"cell_type":"code","source":"temp = []\nfor item in company_list:\n  if  len(df.loc[item]) >=highest_data:\n    temp.append(item)\ncompany_list = temp\ncompany_list.sort()","execution_count":null,"outputs":[]},{"metadata":{"id":"HO0z6N0i4kJ9"},"cell_type":"markdown","source":"**Collect highest data points**"},{"metadata":{"id":"cTJioxGVMi7b","trusted":true},"cell_type":"code","source":"row_list = []\ncolumn_to_be_predicted = \"open\"\ni = 0\nfor date in date_list:\n    row = [date]\n    for company in company_list:\n        try:\n          row.append(getattr(df.loc[company, date],column_to_be_predicted))\n        except KeyError:\n          print(company,date)\n          row.append(-1)\n\n    row_list.append(tuple(row))\n    i += 1\n    print((i/len(date_list))*100)","execution_count":null,"outputs":[]},{"metadata":{"id":"ZoLqvzDD4l3q"},"cell_type":"markdown","source":"**Create new csv**"},{"metadata":{"id":"BS8FHXOnRUE_","trusted":true},"cell_type":"code","source":"df = pd.DataFrame(data=row_list, columns=[\"Date\"] + company_list)\n# if not os.path.exists(\"/content/drive/My Drive\"+\"/sanitized.csv\"):\n#   df = pd.DataFrame(data=row_list, columns=[\"Date\"] + company_list)\n#   df.to_csv(path_or_buf=\"/content/drive/My Drive\"+\"/sanitized.csv\",index=False)\n#   df.to_csv(path_or_buf=OUTPUT_PATH+\"/sanitized.csv\",index=False)\n# else:\n#   df = pd.read_csv(\"/content/drive/My Drive\"+\"/sanitized.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"MCmafu5n4o33"},"cell_type":"markdown","source":"**Scale data**"},{"metadata":{"id":"vypTARfo8uqN","outputId":"76a83b4a-cf0d-469d-a8b2-004a753b7c24","trusted":true},"cell_type":"code","source":"number_of_company = 5\nfull_data = df.iloc[:, 1:number_of_company+2]\ntrain_data, test_data = full_data.iloc[:round(len(full_data)*0.8),1:], full_data.iloc[round(len(full_data)*0.8):,1:]\nscaler = MinMaxScaler(feature_range = (0, 1))\nscaled_train_data = scaler.fit_transform(train_data)\nscaled_test_data = scaler.transform(test_data)","execution_count":null,"outputs":[]},{"metadata":{"id":"eEMm4hjy4rjF"},"cell_type":"markdown","source":"**Create traindata**"},{"metadata":{"id":"jpBUCHv0LhJ9","outputId":"91dcd8a3-c7ea-4cb1-8382-221b96100eb0","trusted":true},"cell_type":"code","source":"x_train = []\ny_train = []\nfor i in range(sequence_dim, len(scaled_train_data)):\n    x_train.append(scaled_train_data[i-sequence_dim:i, :])\n    y_train.append(scaled_train_data[i, :])\nx_train, y_train = np.array(x_train).astype(float), np.array(y_train).astype(float)\nx_train[0][0].dtype","execution_count":null,"outputs":[]},{"metadata":{"id":"0cz9Gs_N4uP8"},"cell_type":"markdown","source":"**Create testdata**"},{"metadata":{"id":"D94HAIMXh1O-","trusted":true},"cell_type":"code","source":"x_test = []\ny_test = []\nfor i in range(sequence_dim, len(scaled_train_data)):\n    x_test.append([scaled_train_data[i-sequence_dim:i, :]])\n    y_test.append(scaled_train_data[i, :])\nx_test, y_test = np.array(x_train).astype(np.float64), np.array(y_train).astype(np.float64)","execution_count":null,"outputs":[]},{"metadata":{"id":"AzxtjWqu4w_X"},"cell_type":"markdown","source":"**Datset Class for batch**"},{"metadata":{"id":"umB09-AXgUPF","trusted":true},"cell_type":"code","source":"class StockDataset(data.Dataset):\n  'Characterizes a dataset for PyTorch'\n  def __init__(self, object_list, labels, transform=None):\n        'Initialization'\n        self.labels = labels\n        self.object_list = object_list\n        self.transform = transform\n\n  def __len__(self):\n        'Denotes the total number of samples'\n        return len(self.object_list)\n\n  def __getitem__(self, index):\n        'Generates one sample of data'\n        # Select sample\n        X = self.object_list[index]\n\n        if self.transform:\n            for transform_item in self.transform:\n                X = transform_item(X)\n        y = self.labels[index]\n\n        return X, y","execution_count":null,"outputs":[]},{"metadata":{"id":"Z56prfVp41Fc"},"cell_type":"markdown","source":"Datset initialize"},{"metadata":{"id":"0vyd_EyDNyBe","trusted":true},"cell_type":"code","source":"train_dataset = StockDataset(object_list=x_train, labels= y_train)\ntest_dataset = StockDataset(object_list=x_test, labels= y_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"Rs4BXQNM40sm"},"cell_type":"markdown","source":"**Epoch calculation**"},{"metadata":{"id":"HWuur5pDiS4l","trusted":true},"cell_type":"code","source":"batch_size = 800\nn_iters = 12000\nnum_epochs = int(n_iters / (len(train_dataset)/batch_size))","execution_count":null,"outputs":[]},{"metadata":{"id":"LDrgT1mf47xq"},"cell_type":"markdown","source":"**Data loader**"},{"metadata":{"id":"lbVdLxnviXiy","trusted":true},"cell_type":"code","source":"train_loader = torch.utils.data.DataLoader(dataset= train_dataset, batch_size= batch_size, shuffle=False)\ntest_loader = torch.utils.data.DataLoader(dataset= test_dataset, batch_size= batch_size, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"id":"oo7t7B1E496N"},"cell_type":"markdown","source":"**Model**"},{"metadata":{"id":"OOWZsO1tlA2f","trusted":true},"cell_type":"code","source":"class LSTMModel(nn.Module):\n    def __init__(self,input_dim, hidden_dim, layer_dim, output_dim):\n        super(LSTMModel, self).__init__()\n        self.layer_dim = layer_dim\n        self.hidden_dim = hidden_dim\n        self.lstm = nn.LSTM(input_dim,hidden_dim,layer_dim,batch_first=True)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n    def forward(self,x):\n        h0 = Variable(torch.zeros(self.layer_dim, x.size(0),self.hidden_dim))\n        c0 = Variable(torch.zeros(self.layer_dim, x.size(0),self.hidden_dim))\n        out,(hn,cn)= self.lstm(x,(h0,c0)) # hn shape layer_dim, batch_size, hidden_dim out, shape batch_size, seq_dim, hidden_dim\n        out = self.fc(out[:,-1,:])\n        return out","execution_count":null,"outputs":[]},{"metadata":{"id":"aiJnKijz5AEz"},"cell_type":"markdown","source":"**Parameters**"},{"metadata":{"id":"ZPUusKErlWF1","trusted":true},"cell_type":"code","source":"input_dim = number_of_company\nhidden_dim = 100\nlayer_dim = 2\noutput_dim = number_of_company\nmodel = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim).float()\ncriterion = nn.MSELoss()\nlearning_rate = 0.1\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)","execution_count":null,"outputs":[]},{"metadata":{"id":"cxceXWIq5FH-"},"cell_type":"markdown","source":"**Train**"},{"metadata":{"id":"ET-JCS3WltTe","outputId":"c95c6ad3-f11e-4207-fd6b-ad6bffb0782e","trusted":true},"cell_type":"code","source":"iter_counter = 0\nfor epoch in range(num_epochs):\n    for i, (images,labels) in enumerate(train_loader):\n        images= Variable(images)\n        labels = Variable(labels)\n        optimizer.zero_grad()\n        outputs = model(images.float())\n        loss = criterion(outputs,labels.float())\n        loss.backward()\n        optimizer.step()\n        iter_counter +=1\n        if iter_counter% 500 ==0:\n            error = 0\n            for images, labels in test_loader:\n                images = Variable(images.float())\n                outputs = model(images.float())\n                error += ((outputs.data - labels.data)**2).mean()\n            print(\"Iteration: {} Loss: {} Error: {}\".format(iter_counter, loss, error))\n                \n            ","execution_count":null,"outputs":[]},{"metadata":{"id":"QpJy8qqh5Hql"},"cell_type":"markdown","source":"**Test**"},{"metadata":{"id":"NNN3QnpSYaVg","trusted":true},"cell_type":"code","source":"Flag_first = True\nfor prices, labels in test_loader:\n    prices = Variable(prices.float())\n    outputs = model(images.float())\n    if Flag_first:\n      actual_data = scaler.inverse_transform(labels.data.numpy())\n    else:\n      np.concatenate(actual_data,scaler.inverse_transform(labels.data.numpy()))\n    if Flag_first:\n      predicted_data = scaler.inverse_transform(outputs.data.numpy())\n    else:\n      np.concatenate(actual_data,scaler.inverse_transform(outputs.data.numpy()))","execution_count":null,"outputs":[]},{"metadata":{"id":"wFQl145F5J3p"},"cell_type":"markdown","source":"**Plot**"},{"metadata":{"id":"62mECCC2j4PH","outputId":"055e53ec-e1ee-4776-aa60-9d10e1b8e3a5","trusted":true},"cell_type":"code","source":"for item in range(number_of_company):\n\n  plt.plot(actual_data.T[0], color = 'blue', label = 'Actual Stock Price')\n  plt.plot(predicted_data.T[0], color = 'red', label = 'Predicted Stock Price')\n  plt.title('Stock Price Prediction')\n  plt.xlabel('Time')\n  plt.ylabel('Stock Price')\n  plt.legend()\n  plt.show()","execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"RNN_Pytorch.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":4}