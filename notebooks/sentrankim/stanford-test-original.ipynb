{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install faiss-gpu","metadata":{"execution":{"iopub.status.busy":"2021-08-06T17:31:47.761915Z","iopub.execute_input":"2021-08-06T17:31:47.762315Z","iopub.status.idle":"2021-08-06T17:31:47.766272Z","shell.execute_reply.started":"2021-08-06T17:31:47.762283Z","shell.execute_reply":"2021-08-06T17:31:47.765184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.io import loadmat\nimport albumentations as A\nimport torch\nimport torchvision.models as models\nimport cv2\nfrom albumentations.pytorch import ToTensorV2\nfrom torch import nn\nimport math\nimport glob\nimport sys\nsys.path.append('../input/d/kozodoi/timm-pytorch-image-models/pytorch-image-models-master/')\nimport timm\nimport pandas as pd\nfrom torch.nn.parameter import Parameter\nfrom tqdm import tqdm\nimport torch.nn.functional as F\nfrom typing import Dict, List, Optional\n\n# import faiss\nimport torch\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-06T17:31:47.771636Z","iopub.execute_input":"2021-08-06T17:31:47.772517Z","iopub.status.idle":"2021-08-06T17:31:47.785551Z","shell.execute_reply.started":"2021-08-06T17:31:47.77242Z","shell.execute_reply":"2021-08-06T17:31:47.784302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    original = '../input/product/Stanford_Online_Products/'\n    pretrain_model = \"../input/resnet-50-adaptive-weighted/resnet50_adaptive_arcface_with_weighted_CosineAnnealingWarmRestarts_CrossEntropyLoss-Copy3.pt\"\n    path_test = \"../input/product/Stanford_Online_Products/Ebay_test.txt\"\n    path_train = \"../input/product-detail/train_info (1).csv\"\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    num_classes= 11318\n    input_size = 256\n    use_pretrained = True\n    ### model config\n    use_pretrained = True\n    model_name = \"resnet50\" #\"efficientnet_b3\" #\"densenet121\"#\"efficientnet_b3\"resnet50\n    embedding_size = 512\n    train = True\n    dropout = 0.5\n    lambda_=10\n    adaptive=True\n    metric = 'adaptive_arcface_with_weighted' #\"adaptive_arcface_with_weighted\" #'adaptive_arcface' # arcface, cosface , softmax \n    use_fc = True\n    s = 30\n    margin = 0.5\n    ls_eps = 0.0\n    theta_zero = 0.785\n    batch_size = 512\n    worker = 8\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2021-08-06T17:31:47.787739Z","iopub.execute_input":"2021-08-06T17:31:47.78831Z","iopub.status.idle":"2021-08-06T17:31:47.800874Z","shell.execute_reply.started":"2021-08-06T17:31:47.788263Z","shell.execute_reply":"2021-08-06T17:31:47.799655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AdaCos(nn.Module):\n    def __init__(self, in_features, out_features, m=0.50, ls_eps=0, theta_zero=math.pi/4):\n        super(AdaCos, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.theta_zero = theta_zero\n        self.s = math.log(out_features - 1) / math.cos(theta_zero)\n        self.m = m\n        self.ls_eps = ls_eps  # label smoothing\n        self.weight = Parameter(torch.FloatTensor(out_features, in_features))\n        nn.init.xavier_uniform_(self.weight)\n\n    def forward(self, input, label):\n        # normalize features\n        x = F.normalize(input)\n        # normalize weights\n        W = F.normalize(self.weight)\n        # dot product\n        logits = F.linear(x, W)\n        # add margin\n        theta = torch.acos(torch.clamp(logits, -1.0 + 1e-7, 1.0 - 1e-7))\n        target_logits = torch.cos(theta + self.m)\n        one_hot = torch.zeros_like(logits)\n        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n        if self.ls_eps > 0:\n            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.out_features\n        output = logits * (1 - one_hot) + target_logits * one_hot\n        # feature re-scale\n        with torch.no_grad():\n            B_avg = torch.where(one_hot < 1, torch.exp(self.s * logits), torch.zeros_like(logits))\n            B_avg = torch.sum(B_avg) / input.size(0)\n            theta_med = torch.median(theta)\n            self.s = torch.log(B_avg) / torch.cos(torch.min(self.theta_zero * torch.ones_like(theta_med), theta_med))\n        output *= self.s\n\n        return output\nclass ArcMarginProduct(nn.Module):\n    r\"\"\"Implement of large margin arc distance: :\n        Args:\n            in_features: size of each input sample\n            out_features: size of each output sample\n            s: norm of input feature\n            m: margin\n            cos(theta + m)\n        \"\"\"\n    def __init__(self, in_features, out_features, s=30.0, m=0.50, easy_margin=False, ls_eps=0.0):\n        super(ArcMarginProduct, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.s = s\n        self.m = m\n        self.ls_eps = ls_eps  # label smoothing\n        self.weight = Parameter(torch.FloatTensor(out_features, in_features))\n        nn.init.xavier_uniform_(self.weight)\n\n        self.easy_margin = easy_margin\n        self.cos_m = math.cos(m)\n        self.sin_m = math.sin(m)\n        self.th = math.cos(math.pi - m)\n        self.mm = math.sin(math.pi - m) * m\n\n    def forward(self, input, label):\n        # --------------------------- cos(theta) & phi(theta) ---------------------------\n        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n        phi = cosine * self.cos_m - sine * self.sin_m\n        if self.easy_margin:\n            phi = torch.where(cosine > 0, phi, cosine)\n        else:\n            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n        # --------------------------- convert label to one-hot ---------------------------\n        # one_hot = torch.zeros(cosine.size(), requires_grad=True, device='cuda')\n        one_hot = torch.zeros(cosine.size(), device='cuda')\n        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n        if self.ls_eps > 0:\n            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.out_features\n        # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\n        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n        output *= self.s\n\n        return output\nclass AddMarginProduct(nn.Module):\n    r\"\"\"Implement of large margin cosine distance: :\n    Args:\n        in_features: size of each input sample\n        out_features: size of each output sample\n        s: norm of input feature\n        m: margin\n        cos(theta) - m\n    \"\"\"\n\n    def __init__(self, in_features, out_features, s=30.0, m=0.40):\n        super(AddMarginProduct, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.s = s\n        self.m = m\n        self.weight = Parameter(torch.FloatTensor(out_features, in_features))\n        nn.init.xavier_uniform_(self.weight)\n\n    def forward(self, input, label):\n        # --------------------------- cos(theta) & phi(theta) ---------------------------\n        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n        phi = cosine - self.m\n        # --------------------------- convert label to one-hot ---------------------------\n        one_hot = torch.zeros(cosine.size(), device=CFG.device)\n        # one_hot = one_hot.cuda() if cosine.is_cuda else one_hot\n        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n        # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\n        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)  # you can use torch.where if your torch.__version__ is 0.4\n        output *= self.s\n        # print(output)\n\n        return output\n\nclass LiArcFace(nn.Module):\n    def __init__(self, in_features, out_features, m=0.4, s=64.0):\n        super().__init__()\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        nn.init.xavier_normal_(self.weight)\n        self.m = m\n        self.s = s\n\n    def forward(self, input, label):\n        W = F.normalize(self.weight)\n        input = F.normalize(input)\n        cosine = input @ W.t()\n        theta = torch.acos(cosine)\n        m = torch.zeros_like(theta)\n        m.scatter_(1, label.view(-1, 1), self.m)\n        scale = -2 * self.s / math.pi\n        return self.s + scale * (theta + m)\n\nclass Arcface_adaptive_margin(nn.Module):\n    r\"\"\"Implement of large margin arc distance: :\n        Args:\n            in_features: size of each input sample\n            out_features: size of each output sample\n            s: norm of input feature\n            m: List margin for each class\n            cos(theta + m)\n        \"\"\"\n\n    def __init__(self, in_features, out_features, s=30.0, m=0.50, device='cuda', easy_margin=False, ls_eps=0.0):\n        super(Arcface_adaptive_margin, self).__init__()\n        self.in_features = torch.tensor(in_features)\n        self.out_features = torch.tensor(out_features)\n        self.s = torch.tensor(s)\n        self.device = device\n        self.m = Parameter(torch.tensor([[m]] * out_features, requires_grad=True, device=self.device,\n                                        dtype=torch.double))  # automatic margin\n        self.m_update = 0\n        self.ls_eps = torch.tensor(ls_eps).type(dtype=torch.double)  # label smoothing\n        self.weight = Parameter(torch.FloatTensor(out_features, in_features))\n        nn.init.xavier_uniform_(self.weight)\n        self.easy_margin = easy_margin\n        self.torch_pi = torch.tensor(3.141592, dtype=torch.double, device=self.device)\n\n    def forward(self, input, label):\n        self.m_update += 1\n        m = self.m[label]\n        cos_m = torch.cos(m)\n        sin_m = torch.sin(m)\n        th = torch.cos(torch.sub(self.torch_pi, m))\n        mm = torch.mul(torch.sin(torch.sub(self.torch_pi, m)), m)\n\n        # --------------------------- cos(theta) & phi(theta) ---------------------------\n        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n        sine = torch.sqrt(torch.sub(1.0, torch.pow(cosine, 2)))\n        phi = torch.sub(torch.mul(cosine, cos_m), torch.mul(sine, sin_m))\n\n        if self.easy_margin:\n            phi = torch.where(cosine > 0, phi, cosine)\n        else:\n            phi = torch.where(cosine > th, phi, torch.sub(cosine, mm))\n\n        # --------------------------- convert label to one-hot ---------------------------\n        one_hot = torch.zeros(cosine.size(), device=self.device)\n        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n        if self.ls_eps > 0:\n            one_hot = torch.add(torch.mul(torch.sub(1, self.ls_eps), one_hot),\n                                torch.div(self.ls_eps, self.out_features))\n\n        # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\n        output = torch.add(torch.mul(one_hot, phi), torch.mul(torch.sub(1.0, one_hot), cosine))\n        output = torch.mul(output, self.s)\n\n        return output\n\nclass ArcModule(nn.Module):\n    def __init__(self, in_features, out_features, s = 10, m = CFG.margin):\n        super().__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.s = s\n        self.m = m\n        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n        nn.init.xavier_normal_(self.weight)\n\n        self.cos_m = math.cos(m)\n        self.sin_m = math.sin(m)\n        self.th = torch.tensor(math.cos(math.pi - m))\n        self.mm = torch.tensor(math.sin(math.pi - m) * m)\n\n    def forward(self, inputs, labels):\n        cos_th = F.linear(inputs, F.normalize(self.weight))\n        cos_th = cos_th.clamp(-1, 1)\n        sin_th = torch.sqrt(1.0 - torch.pow(cos_th, 2))\n        cos_th_m = cos_th * self.cos_m - sin_th * self.sin_m\n        # print(type(cos_th), type(self.th), type(cos_th_m), type(self.mm))\n        cos_th_m = torch.where(cos_th > self.th, cos_th_m, cos_th - self.mm)\n\n        cond_v = cos_th - self.th\n        cond = cond_v <= 0\n        cos_th_m[cond] = (cos_th - self.mm)[cond]\n\n        if labels.dim() == 1:\n            labels = labels.unsqueeze(-1)\n        onehot = torch.zeros(cos_th.size()).cuda()\n        labels = labels.type(torch.LongTensor).cuda()\n        onehot.scatter_(1, labels, 1.0)\n        outputs = onehot * cos_th_m + (1.0 - onehot) * cos_th\n        outputs = outputs * self.s\n        return outputs\n\nclass Arcface_adaptive_margin(nn.Module):\n    r\"\"\"Implement of large margin arc distance: :\n        Args:\n            in_features: size of each input sample\n            out_features: size of each output sample\n            s: norm of input feature\n            m: List margin for each class\n            cos(theta + m)\n        \"\"\"\n\n    def __init__(self, in_features, out_features, s=30.0, m=0.50, device='cuda', easy_margin=False, ls_eps=0.0,file_m=\"./auto_margin.dat\"):\n        super(Arcface_adaptive_margin, self).__init__()\n        self.in_features = torch.tensor(in_features)\n        self.out_features = torch.tensor(out_features)\n        self.s = torch.tensor(s)\n        self.file_m = file_m\n        self.device = device\n        self.m = Parameter(torch.tensor([[m]] * out_features, requires_grad=True, device=self.device,\n                                        dtype=torch.double))  # automatic margin\n\n        self.ls_eps = torch.tensor(ls_eps).type(dtype=torch.double)  # label smoothing\n        self.weight = Parameter(torch.FloatTensor(out_features, in_features))\n        nn.init.xavier_uniform_(self.weight)\n        self.easy_margin = easy_margin\n        self.torch_pi = torch.tensor(3.141592, dtype=torch.double, device=self.device)\n\n# class Arcface_update(nn.Module):\n\n#     def __init__(self, channel_size=CFG.embedding_size, out_feature=CFG.num_classes, dropout=0.5, backbone=CFG.model_name, pretrained=True):\n#         super(Arcface_update, self).__init__()\n#         self.backbone = timm.create_model(backbone, pretrained=True)\n# #         self.backbone.load_state_dict(torch.load(CFG.orginal_pretrain_model, map_location=CFG.device))\n#         self.channel_size = channel_size\n#         self.out_feature = out_feature\n#         self.in_features = self.backbone.classifier.in_features\n#         self.margin = ArcModule(in_features=self.channel_size, out_features = self.out_feature)\n#         self.bn1 = nn.BatchNorm2d(self.in_features)\n#         self.dropout = nn.Dropout2d(dropout, inplace=True)\n#         self.fc1 = nn.Linear(self.in_features * 8 * 8 , self.channel_size)\n#         self.bn2 = nn.BatchNorm1d(self.channel_size)\n        \n#     def forward(self, x, labels=None):\n#         features = self.backbone.features(x)\n#         features = self.bn1(features)\n#         features = self.dropout(features)\n#         features = features.view(features.size(0), -1)\n#         features = self.fc1(features)\n#         features = self.bn2(features)\n#         features = F.normalize(features)\n#         if labels is not None:\n#             return self.margin(features, labels)\n#         return features","metadata":{"execution":{"iopub.status.busy":"2021-08-06T17:31:48.020948Z","iopub.execute_input":"2021-08-06T17:31:48.021293Z","iopub.status.idle":"2021-08-06T17:31:48.083237Z","shell.execute_reply.started":"2021-08-06T17:31:48.021262Z","shell.execute_reply":"2021-08-06T17:31:48.081938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class Model(nn.Module):\n\n#     def __init__(self,\n#                  n_classes,\n#                  model_name='efficientnet_b3',\n#                  use_fc=False,\n#                  fc_dim=512,\n#                  dropout=0.0,\n#                  metric='softmax',\n#                  s=30.0,\n#                  margin=0.50,\n#                  ls_eps=0.0,\n#                  theta_zero=0.785,\n#                  pretrained=False):\n#         \"\"\"\n#         :param n_classes:\n#         :param model_name: name of model from pretrainedmodels\n#             e.g. resnet50, resnext101_32x4d, pnasnet5large\n#         :param pooling: One of ('SPoC', 'MAC', 'RMAC', 'GeM', 'Rpool', 'Flatten', 'CompactBilinearPooling')\n#         :param metric: One of ('arcface', 'cosface', 'softmax')\n#         \"\"\"\n#         super(Model, self).__init__()\n#         print('Building Model Backbone for {} model'.format(model_name))\n\n#         self.backbone = timm.create_model(model_name, pretrained=True)\n# #         self.backbone.load_state_dict(torch.load(CFG.orginal_pretrain_model, map_location=CFG.device))\n#         final_in_features = self.backbone.classifier.in_features\n        \n#         self.backbone.classifier = nn.Identity()\n#         self.backbone.global_pool = nn.Identity()\n        \n#         self.pooling =  nn.AdaptiveAvgPool2d(1)\n            \n#         self.use_fc = use_fc\n#         if use_fc:\n#             self.dropout = nn.Dropout(p=dropout)\n#             self.fc = nn.Linear(final_in_features, fc_dim)\n#             self.bn = nn.BatchNorm1d(fc_dim)\n#             self._init_params()\n#             final_in_features = fc_dim\n\n#         self.metric = metric\n#         if metric == 'arcface':\n#             self.final = ArcMarginProduct(final_in_features, n_classes,\n#                                           s=s, m=margin, easy_margin=False, ls_eps=ls_eps)\n#         elif metric == 'cosface':\n#             self.final = AddMarginProduct(final_in_features, n_classes, s=s, m=margin)\n#         elif metric == 'adacos':\n#             self.final = AdaCos(final_in_features, n_classes, m=margin, theta_zero=theta_zero)\n#         elif metric == 'LiArcFace':\n#             print(\"LiArcFace\")\n#             self.final = LiArcFace(final_in_features, n_classes)\n#         elif metric =='adaptive':\n#             self.final = Arcface_adaptive_margin(final_in_features, n_classes,\n#                                           s=s, m=margin, easy_margin=False, ls_eps=ls_eps)\n#         else:\n#             self.final = nn.Linear(final_in_features, n_classes)\n\n#     def _init_params(self):\n#         nn.init.xavier_normal_(self.fc.weight)\n#         nn.init.constant_(self.fc.bias, 0)\n#         nn.init.constant_(self.bn.weight, 1)\n#         nn.init.constant_(self.bn.bias, 0)\n\n#     def forward(self, x, label):\n#         feature = self.extract_feat(x)\n#         if self.metric in ('arcface', 'cosface', 'adacos','LiArcFace'):\n#             logits = self.final(feature, label)\n#         else:\n#             logits = self.final(feature)\n#         return logits\n\n#     def extract_feat(self, x):\n#         batch_size = x.shape[0]\n#         x = self.backbone(x)\n#         x = self.pooling(x).view(batch_size, -1)\n\n#         if self.use_fc:\n#             x = self.dropout(x)\n#             x = self.fc(x)\n#             x = self.bn(x)\n\n#         return x\n# class Arcface_adaptive_margin_with_weighted(nn.Module):\n#     r\"\"\"Implement of large margin arc distance: :\n#         Args:\n#             in_features: size of each input sample\n#             out_features: size of each output sample\n#             s: norm of input feature\n#             m: List margin for each class\n#             cos(theta + m)\n#         \"\"\"\n\n#     def __init__(self, in_features, out_features, s=30.0, m=0.50, device='cuda', easy_margin=False, ls_eps=0.0,file_m=\"./auto_margin.dat\"):\n#         super(Arcface_adaptive_margin_with_weighted, self).__init__()\n#         self.in_features = torch.tensor(in_features)\n#         self.out_features = torch.tensor(out_features)\n#         self.s = torch.tensor(s)\n#         self.file_m = file_m\n#         self.device = device\n#         self.m = Parameter(torch.tensor([[m]] * out_features, requires_grad=True, device=self.device,\n#                                         dtype=torch.double))  # automatic margin\n\n#         self.ls_eps = torch.tensor(ls_eps).type(dtype=torch.double)  # label smoothing\n#         self.weight = Parameter(torch.FloatTensor(out_features, in_features))\n#         nn.init.xavier_uniform_(self.weight)\n#         self.easy_margin = easy_margin\n#         self.torch_pi = torch.tensor(3.141592, dtype=torch.double, device=self.device)\n\n#     def forward(self, input, label):\n#         file_m = open(self.file_m, 'ab')\n#         np.savetxt(file_m, self.m.detach().cpu().numpy().reshape(1, -1))\n#         file_m.close()\n#         m = self.m[label]      # list margin m \n#         cos_m = torch.cos(m)   # cos list margin m \n#         sin_m = torch.sin(m)   # cos(m+theta) =  cos(m) * cos(theta) - sin(m)*sin(theta)\n#         th = torch.cos(torch.sub(self.torch_pi, m)) # th =  threshold = Pi-m -> check m+theta < Pi <=> cos(theta) < cos(Pi-m) \n#         mm = torch.mul(torch.sin(torch.sub(self.torch_pi, m)), m)  \n\n#         # --------------------------- cos(theta) & phi(theta) ---------------------------\n#         cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n#         sine = torch.sqrt(torch.sub(1.0, torch.pow(cosine, 2)))\n#         phi = torch.sub(torch.mul(cosine, cos_m), torch.mul(sine, sin_m))\n        \n#         if self.easy_margin:\n#             phi = torch.where(cosine > 0, phi, cosine)\n#         else:\n#             phi = torch.where(cosine > th, phi, torch.sub(cosine, mm))\n\n#         # --------------------------- convert label to one-hot ---------------------------\n#         one_hot = torch.zeros(cosine.size(), device=self.device)\n#         one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n#         if self.ls_eps > 0:\n#             one_hot = torch.add(torch.mul(torch.sub(1, self.ls_eps), one_hot),\n#                                 torch.div(self.ls_eps, self.out_features))\n\n#         # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\n#         output = torch.add(torch.mul(one_hot, phi)*m, torch.mul(torch.sub(1.0, one_hot), cosine))\n#         output = self.s*output\n\n#         return output\n# explain https://github.com/siriusdemon/Build-Your-Own-Face-Model/blob/master/recognition/model/metric.py\nclass Arcface_adaptive_margin_with_weighted(nn.Module):\n    r\"\"\"Implement of large margin arc distance: :\n        Args:\n            in_features: size of each input sample\n            out_features: size of each output sample\n            s: norm of input feature\n            m: List margin for each class\n            cos(theta + m)\n        \"\"\"\n\n    def __init__(self, in_features, out_features, s=30.0, m=0.50, device='cuda', easy_margin=False, ls_eps=0.0,file_m=\"./auto_margin.dat\"):\n        super(Arcface_adaptive_margin_with_weighted, self).__init__()\n        self.in_features = torch.tensor(in_features)\n        self.out_features = torch.tensor(out_features)\n        self.s = torch.tensor(s)\n        self.file_m = file_m\n        self.device = device\n        self.m = Parameter(torch.tensor([[m]] * out_features, requires_grad=True, device=self.device,\n                                        dtype=torch.double))  # automatic margin\n\n        self.ls_eps = torch.tensor(ls_eps).type(dtype=torch.double)  # label smoothing\n        self.weight = Parameter(torch.FloatTensor(out_features, in_features))\n        nn.init.xavier_uniform_(self.weight)\n        self.easy_margin = easy_margin\n        self.torch_pi = torch.tensor(3.141592, dtype=torch.double, device=self.device)\n\n    def forward(self, input, label):\n        file_m = open(self.file_m, 'ab')\n        np.savetxt(file_m, self.m.detach().cpu().numpy().reshape(1, -1))\n        file_m.close()\n        m = self.m[label]      # list margin m\n        tensor_index =  torch.arange(11318).to(self.device)\n#         another_m = torch.tensor([value for value in tensor_index if value not in label])\n#         another_m = another_m.unsqueeze(1).to(self.device)\n#         another_m = self.m[tensor_index[tensor_index!=label]]\n        cos_m = torch.cos(m)   # cos list margin m \n        sin_m = torch.sin(m)   # cos(m+theta) =  cos(m) * cos(theta) - sin(m)*sin(theta)\n        th = torch.cos(torch.sub(self.torch_pi, m)) # th =  threshold = Pi-m -> check m+theta < Pi <=> cos(theta) < cos(Pi-m) \n        mm = torch.mul(torch.sin(torch.sub(self.torch_pi, m)), m)  \n\n        # --------------------------- cos(theta) & phi(theta) ---------------------------\n        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n        sine = torch.sqrt(torch.sub(1.0, torch.pow(cosine, 2)))\n        phi = torch.sub(torch.mul(cosine, cos_m), torch.mul(sine, sin_m))\n        \n        if self.easy_margin:\n            phi = torch.where(cosine > 0, phi, cosine)\n        else:\n            phi = torch.where(cosine > th, phi, torch.sub(cosine, mm))\n\n        # --------------------------- convert label to one-hot ---------------------------\n        one_hot = torch.zeros(cosine.size(), device=self.device)\n        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n        if self.ls_eps > 0:\n            one_hot = torch.add(torch.mul(torch.sub(1, self.ls_eps), one_hot),\n                                torch.div(self.ls_eps, self.out_features))\n\n        # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\n        output = torch.add(torch.mul(one_hot, phi)*m, torch.mul(torch.sub(1.0, one_hot), cosine))\n        output = output*self.s\n\n        return output","metadata":{"execution":{"iopub.status.busy":"2021-08-06T17:31:48.085875Z","iopub.execute_input":"2021-08-06T17:31:48.086394Z","iopub.status.idle":"2021-08-06T17:31:48.111427Z","shell.execute_reply.started":"2021-08-06T17:31:48.08635Z","shell.execute_reply":"2021-08-06T17:31:48.110177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n\n    def __init__(self, n_classes, model_name='efficientnet_b3', use_fc=False, fc_dim=512,\\\n                 dropout=0.0, metric='softmax', s=30.0, margin=0.50, ls_eps=0.0,\\\n                 theta_zero=0.785, pretrained=False):\n        \"\"\"\n        :param n_classes:\n        :param model_name: name of model from pretrainedmodels\n            e.g. resnet50, resnext101_32x4d, pnasnet5large\n        :param pooling: One of ('SPoC', 'MAC', 'RMAC', 'GeM', 'Rpool', 'Flatten', 'CompactBilinearPooling')\n        :param metric: One of ('arcface', 'cosface', 'softmax')\n        \"\"\"\n        super(Model, self).__init__()\n        print('Building Model Backbone for {} model'.format(model_name))\n\n        self.backbone = timm.create_model(model_name, pretrained=False)\n#         self.backbone.load_state_dict(torch.load(CFG.orginal_pretrain_model, map_location=CFG.device))\n        \n        if CFG.model_name==\"resnet50\":\n            final_in_features = self.backbone.fc.in_features\n            self.backbone.fc = nn.Identity()\n        else:\n            final_in_features = self.backbone.classifier.in_features\n            self.backbone.classifier = nn.Identity()\n        self.backbone.global_pool = nn.Identity()\n\n        self.pooling = nn.AdaptiveAvgPool2d(1)\n\n        self.use_fc = use_fc\n        if use_fc:\n            self.dropout = nn.Dropout(p=dropout)\n            self.fc = nn.Linear(final_in_features, fc_dim)\n            self.bn = nn.BatchNorm1d(fc_dim)\n            self._init_params()\n            final_in_features = fc_dim\n\n        self.metric = metric\n        if metric == 'arcface':\n            self.final = ArcMarginProduct(final_in_features, n_classes,\n                                          s=s, m=margin, easy_margin=False, ls_eps=ls_eps)\n        elif metric == 'cosface':\n            self.final = AddMarginProduct(final_in_features, n_classes, s=s, m=margin, device=CFG.device)\n        elif metric == 'adacos':\n            self.final = AdaCos(final_in_features, n_classes, m=margin, theta_zero=theta_zero)\n        elif metric == 'adaptive_arcface':\n            self.final = Arcface_adaptive_margin(final_in_features, n_classes, s=s, m=margin,\\\n                                                 device=CFG.device, easy_margin=False, ls_eps=ls_eps)\n        elif metric == 'adaptive_arcface_with_weighted':\n            self.final = Arcface_adaptive_margin_with_weighted(final_in_features, n_classes, s=s, m=margin,\\\n                                                 device=CFG.device, easy_margin=False, ls_eps=ls_eps)\n        else:\n            self.final = nn.Linear(final_in_features, n_classes)\n\n    def _init_params(self):\n        nn.init.xavier_normal_(self.fc.weight)\n        nn.init.constant_(self.fc.bias, 0)\n        nn.init.constant_(self.bn.weight, 1)\n        nn.init.constant_(self.bn.bias, 0)\n\n    def forward(self, x, label):\n        feature = self.extract_feat(x)\n        if self.metric in ('arcface', 'cosface', 'adacos','adaptive_arcface','adaptive_arcface_with_weighted'):\n            logits = self.final(feature, label)\n        else:\n            logits = self.final(feature)\n        return logits\n\n    def extract_feat(self, x):\n        batch_size = x.shape[0]\n        x = self.backbone(x)\n        x = self.pooling(x).view(batch_size, -1)\n\n        if self.use_fc:\n            x = self.dropout(x)\n            x = self.fc(x)\n            x = self.bn(x)\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-08-06T17:31:48.114802Z","iopub.execute_input":"2021-08-06T17:31:48.11525Z","iopub.status.idle":"2021-08-06T17:31:48.137663Z","shell.execute_reply.started":"2021-08-06T17:31:48.115207Z","shell.execute_reply":"2021-08-06T17:31:48.136471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FocalLoss(torch.nn.Module):\n\n    def __init__(self, gamma=0, eps=1e-7):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.eps = eps\n        self.ce = torch.nn.CrossEntropyLoss()\n\n    def forward(self, input, target):\n        logp = self.ce(input, target)\n        p = torch.exp(-logp)\n        loss = (1 - p) ** self.gamma * logp\n        return loss.mean()","metadata":{"execution":{"iopub.status.busy":"2021-08-06T17:31:48.140102Z","iopub.execute_input":"2021-08-06T17:31:48.140808Z","iopub.status.idle":"2021-08-06T17:31:48.156504Z","shell.execute_reply.started":"2021-08-06T17:31:48.140749Z","shell.execute_reply":"2021-08-06T17:31:48.155372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Custom_dataset():\n    \n    def __init__(self, df, transform = None):\n        \n        self.df = df.reset_index()\n        self.transform = transform\n                \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self,index):\n        \n        img_path, class_id = self.df.loc[index, 'path'], self.df.loc[index,'class_id']\n        \n        sample = cv2.imread(img_path)\n        sample = cv2.cvtColor(sample, cv2.COLOR_BGR2RGB)\n        \n        if self.transform is not None:\n            sample = self.transform(image=sample)[\"image\"]\n\n        return sample, torch.tensor(class_id)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T17:31:48.158775Z","iopub.execute_input":"2021-08-06T17:31:48.159536Z","iopub.status.idle":"2021-08-06T17:31:48.169577Z","shell.execute_reply.started":"2021-08-06T17:31:48.15949Z","shell.execute_reply":"2021-08-06T17:31:48.168385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = Model(**{'n_classes':CFG.num_classes,\n#             'model_name':CFG.model_name,\n#             'use_fc':CFG.use_fc,\n#             'fc_dim':CFG.embedding_size,\n#             'dropout':CFG.dropout,\n#             'metric':CFG.metric,\n#             's':CFG.s,\n#             'margin':CFG.margin,\n#             'ls_eps':CFG.ls_eps,\n#             'theta_zero':CFG.theta_zero,\n#             'pretrained':True\n#         }\n# )\n# model = Arcface_update()\nmodel = Model(**{\n                'n_classes':CFG.num_classes,\n                'model_name':CFG.model_name,\n                'use_fc':CFG.use_fc,\n                'fc_dim':CFG.embedding_size,\n                'dropout':CFG.dropout,\n                'metric':CFG.metric,\n                's':CFG.s,\n                'margin':CFG.margin,\n                'ls_eps':CFG.ls_eps,\n                'theta_zero':CFG.theta_zero,\n                'pretrained':False\n            }\n    )\n\nif CFG.pretrain_model is not None:\n    print(\"load pretrain\")\n    checkpoint = torch.load(CFG.pretrain_model,map_location=torch.device('cpu'))\n    model.load_state_dict(checkpoint['model_state_dict'])    \n\ntrans = A.Compose([\n        A.Resize(CFG.input_size, CFG.input_size),\n        A.Normalize(),\n        A.pytorch.transforms.ToTensorV2()\n])\n\ntrans = A.Compose([\n    A.LongestMaxSize(max_size = CFG.input_size ),\n    A.PadIfNeeded(min_height=CFG.input_size, min_width=CFG.input_size, p=1),\n    A.Resize(CFG.input_size, CFG.input_size),\n    A.Normalize(),\n    ToTensorV2()\n])","metadata":{"execution":{"iopub.status.busy":"2021-08-06T17:31:48.171475Z","iopub.execute_input":"2021-08-06T17:31:48.172175Z","iopub.status.idle":"2021-08-06T17:31:49.126378Z","shell.execute_reply.started":"2021-08-06T17:31:48.172129Z","shell.execute_reply":"2021-08-06T17:31:49.125172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv(CFG.path_test,delimiter = \" \",index_col=None)\ndf_test['path'] = CFG.original + df_test['path']\ndf_test['class_id']-=1\n\n# df_train = pd.read_csv(CFG.path_train,index_col=None)\n# df_train['path'] = CFG.original + df_train['path']\n# df_train['class_id']-=1\n\ntest = Custom_dataset(df_test, transform = trans)\ntest_loader = DataLoader(dataset=test, num_workers=CFG.worker, batch_size=CFG.batch_size, shuffle=False, pin_memory = False)\n\n# train = Custom_dataset(df_train[df_train['phase']=='train'], transform = trans)\n# train_loader = DataLoader(dataset=train, num_workers=CFG.worker, batch_size=CFG.batch_size, shuffle=False, pin_memory = False)\n\n\nmodel.to(CFG.device)\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2021-08-06T17:31:49.128077Z","iopub.execute_input":"2021-08-06T17:31:49.128477Z","iopub.status.idle":"2021-08-06T17:31:49.258379Z","shell.execute_reply.started":"2021-08-06T17:31:49.128433Z","shell.execute_reply":"2021-08-06T17:31:49.257093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_test = pd.read_csv(CFG.path_test,delimiter = \" \",index_col=None)\n# df_test","metadata":{"execution":{"iopub.status.busy":"2021-08-06T17:31:49.262047Z","iopub.execute_input":"2021-08-06T17:31:49.26249Z","iopub.status.idle":"2021-08-06T17:31:49.277803Z","shell.execute_reply.started":"2021-08-06T17:31:49.262448Z","shell.execute_reply":"2021-08-06T17:31:49.273294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calc_recall_at_k(T, Y, k):\n    \"\"\"\n    T : [nb_samples] (target labels)\n    Y : [nb_samples x k] (k predicted labels/neighbours)\n    \"\"\"\n\n    s = 0\n    for t,y in zip(T,Y):\n        if t in torch.Tensor(y).long()[:k]:\n            s += 1\n    return s / (1. * len(T))\ndef l2_norm(input):\n    input_size = input.size()\n    buffer = torch.pow(input, 2)\n    normp = torch.sum(buffer, 1).add_(1e-12)\n    norm = torch.sqrt(normp)\n    _output = torch.div(input, norm.view(-1, 1).expand_as(input))\n    output = _output.view(input_size)\n\n    return output\ndef predict_batchwise(model, dataloader):\n    device = \"cuda\"\n    model_is_training = model.training\n    model.eval()\n    \n    ds = dataloader.dataset\n    A = [[] for i in range(len(ds[0]))]\n    with torch.no_grad():\n        # extract batches (A becomes list of samples)\n        for batch in tqdm(dataloader):\n            for i, J in enumerate(batch):\n                # i = 0: sz_batch * images\n                # i = 1: sz_batch * labels\n                # i = 2: sz_batch * indices\n                if i == 0:\n                    # move images to device of model (approximate device)\n#                     J = model(J.cuda())\n                    J = model.extract_feat(J.cuda())\n                for j in J:\n                    A[i].append(j)\n           \n    model.train()\n    model.train(model_is_training) # revert to previous training state\n    \n    return [torch.stack(A[i]) for i in range(len(A))]\ndef evaluate_cos_SOP(model, dataloader):\n    nb_classes = 11316\n    \n    # calculate embeddings with model and get targets\n    X, T = predict_batchwise(model, dataloader)\n    X = l2_norm(X)\n    \n    # get predictions by assigning nearest 8 neighbors with cosine\n    K = 1000\n    Y = []\n    xs = []\n    for x in X:\n        if len(xs)<10000:\n            xs.append(x)\n        else:\n            xs.append(x)            \n            xs = torch.stack(xs,dim=0)\n            cos_sim = F.linear(xs,X)\n            y = T[cos_sim.topk(1 + K)[1][:,1:]]\n            Y.append(y.float().cpu())\n            xs = []\n            \n    # Last Loop\n    xs = torch.stack(xs,dim=0)\n    cos_sim = F.linear(xs,X)\n    y = T[cos_sim.topk(1 + K)[1][:,1:]]\n    Y.append(y.float().cpu())\n    Y = torch.cat(Y, dim=0)\n\n    # calculate recall @ 1, 2, 4, 8\n    recall = []\n    for k in [1, 2,3,4,5,10, 100, 1000]:\n        r_at_k = calc_recall_at_k(T, Y, k)\n        recall.append(r_at_k)\n        print(\"R@{} : {:.3f}\".format(k, 100 * r_at_k))\n    return recall","metadata":{"execution":{"iopub.status.busy":"2021-08-06T17:31:49.282143Z","iopub.execute_input":"2021-08-06T17:31:49.284188Z","iopub.status.idle":"2021-08-06T17:31:49.308242Z","shell.execute_reply.started":"2021-08-06T17:31:49.284131Z","shell.execute_reply":"2021-08-06T17:31:49.307092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"recall = evaluate_cos_SOP(model, test_loader)\nprint(recall)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T17:31:49.310169Z","iopub.execute_input":"2021-08-06T17:31:49.310911Z","iopub.status.idle":"2021-08-06T17:36:47.312992Z","shell.execute_reply.started":"2021-08-06T17:31:49.31085Z","shell.execute_reply":"2021-08-06T17:36:47.311807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gg","metadata":{"execution":{"iopub.status.busy":"2021-08-06T17:36:47.314919Z","iopub.execute_input":"2021-08-06T17:36:47.315408Z","iopub.status.idle":"2021-08-06T17:36:47.340324Z","shell.execute_reply.started":"2021-08-06T17:36:47.315359Z","shell.execute_reply":"2021-08-06T17:36:47.338483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gallery_features = []\ngallery_label = []\ndem=0\nwith torch.no_grad():\n    for bi,d in tqdm(enumerate(train_loader), total=len(train_loader)):\n        batch_size = d[0].size()[0]\n\n        image = d[0]\n        targets = d[1]\n\n        image = image.to(CFG.device)\n        targets = targets.to(CFG.device)\n\n#         output = model.extract_feat(image)\n        output = model(image)\n#         logist = model(image,targets)\n        gallery_features.append(output)\n        gallery_label.append(targets)\ngallery_features = torch.cat(gallery_features, dim=0)\ngallery_label = torch.cat(gallery_label,dim=0)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T17:36:47.341774Z","iopub.status.idle":"2021-08-06T17:36:47.342276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"query_features = []\nquery_labels = []\ndem=0\nwith torch.no_grad():\n    for bi,d in tqdm(enumerate(test_loader), total=len(test_loader)):\n        batch_size = d[0].size()[0]\n\n        image = d[0]\n        targets = d[1]\n\n        image = image.to(CFG.device)\n        targets = targets.to(CFG.device)\n\n#         output = model.extract_feat(image)\n        output = model(image)\n        query_features.append(output)\n        query_labels.append(targets)\nquery_features = torch.cat(query_features,dim=0)\nquery_labels = torch.cat(query_labels, dim = 0)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T17:36:47.344085Z","iopub.status.idle":"2021-08-06T17:36:47.344859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef recall_at_ks(query_features: torch.Tensor,\n                 query_labels: torch.LongTensor,\n                 ks: List[int],\n                 gallery_features: Optional[torch.Tensor] = None,\n                 gallery_labels: Optional[torch.Tensor] = None,\n                 cosine: bool = False) -> Dict[int, float]:\n    \"\"\"\n    Compute the recall between samples at each k. This function uses about 8GB of memory.\n    Parameters\n    ----------\n    query_features : torch.Tensor\n        Features for each query sample. shape: (num_queries, num_features)\n    query_labels : torch.LongTensor\n        Labels corresponding to the query features. shape: (num_queries,)\n    ks : List[int]\n        Values at which to compute the recall.\n    gallery_features : torch.Tensor\n        Features for each gallery sample. shape: (num_queries, num_features)\n    gallery_labels : torch.LongTensor\n        Labels corresponding to the gallery features. shape: (num_queries,)\n    cosine : bool\n        Use cosine distance between samples instead of euclidean distance.\n    Returns\n    -------\n    recalls : Dict[int, float]\n        Values of the recall at each k.\n    \"\"\"\n    offset = 0\n    if gallery_features is None and gallery_labels is None:\n        offset = 1\n        gallery_features = query_features\n        gallery_labels = query_labels\n    elif gallery_features is None or gallery_labels is None:\n        raise ValueError('gallery_features and gallery_labels needs to be both None or both Tensors.')\n\n    if cosine:\n        print(\"cosine\")\n        pass\n        query_features = F.normalize(query_features, p=2, dim=1)\n        gallery_features = F.normalize(gallery_features, p=2, dim=1)\n    to_cpu_numpy = lambda x: x.cpu().numpy()\n    q_f, q_l, g_f, g_l = map(to_cpu_numpy, [query_features, query_labels, gallery_features, gallery_labels])\n\n    res = faiss.StandardGpuResources()\n    flat_config = faiss.GpuIndexFlatConfig()\n    flat_config.device = 0\n\n    max_k = max(ks)\n    index_function = faiss.GpuIndexFlatIP if cosine else faiss.GpuIndexFlatL2\n    index = index_function(res, g_f.shape[1], flat_config)\n    index.add(g_f)\n    closest_indices = index.search(q_f, max_k + offset)[1]\n\n    recalls = {}\n    for k in ks:\n        indices = closest_indices[:, offset:k + offset]\n        recalls[k] = (q_l[:, None] == g_l[indices]).any(1).mean()\n    return {k: round(v * 100, 2) for k, v in recalls.items()}","metadata":{"execution":{"iopub.status.busy":"2021-08-06T17:36:47.347211Z","iopub.status.idle":"2021-08-06T17:36:47.348055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"recall_at_ks(query_features,query_labels,[1,10,20,30,40,50],gallery_features,gallery_label,cosine=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T17:36:47.349949Z","iopub.status.idle":"2021-08-06T17:36:47.350792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}