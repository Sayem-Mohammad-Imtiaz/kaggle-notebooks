{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import LabelEncoder\n\ndataset = pd.read_csv(\"/kaggle/input/churn-modelling/Churn_Modelling.csv\")\ndataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_data = dataset\n\nle = LabelEncoder()\ndummy_columns = [] #array for multiple value columns\n\nfor column in df_data.columns:\n    if df_data[column].dtype == object and column != 'customerID' and column != 'RowNumber' and column != 'Surname':\n        if df_data[column].nunique() == 2:\n            #apply Label Encoder for binary ones\n            df_data[column] = le.fit_transform(df_data[column]) \n        else:\n            dummy_columns.append(column)\n#apply get dummies for selected columns\ndf_data = pd.get_dummies(data = df_data,columns = dummy_columns, drop_first=True)\n\nX = df_data.drop([\"RowNumber\",\"CustomerId\",\"Surname\",\"Exited\"], axis=1)\ny = df_data.Exited\n\n#Splitting into test set and training set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n\n#Use stratified KFold as cross-validation strategy\nkfold = StratifiedKFold(n_splits=10, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Logistic Regression Model\n\n#feature scaling\nfrom sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nX_train_scaled = sc_X.fit_transform(X_train)\nX_test_scaled = sc_X.transform(X_test)\n\n#Fitting Logistic Regression to the Training set\nfrom sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state = 0)\nfit_1 = classifier.fit(X_train_scaled,y_train)\n\n#Predicting the Test set results\ny_pred = classifier.predict(X_test_scaled)\n\n#applying k-Fold Cross Validation\naccuracies_log = cross_val_score(estimator=classifier, X=X_train_scaled, y=y_train, cv=kfold)\n\n#confusion matrix\ncm_log = confusion_matrix(y_test, y_pred)\n\n#classification report\ncr_log = classification_report(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#KNN model\n\n#Fitting classifier to the Training set\nfrom sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors=5,metric='minkowski',p=2)\nclassifier.fit(X_train_scaled,y_train)\n\n#Predicting the test set value\ny_pred = classifier.predict(X_test_scaled)\n\n#applying k-Fold Cross Validation\naccuracies_knn = cross_val_score(estimator=classifier, X=X_train_scaled, y=y_train, cv=kfold)\n\n#confusion matrix\ncm_knn = confusion_matrix(y_test, y_pred)\n\n#classification report\ncr_knn = classification_report(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Support Vector Machine Model\n\n#Fitting classifier to the Training set\nfrom sklearn.svm import SVC\n\n#Fitting classifier to the Training set\nclassifier = SVC(kernel='rbf', random_state=0)\nclassifier.fit(X_train_scaled,y_train)\n\n#Predicting the test set value\ny_pred = classifier.predict(X_test_scaled)\n\n#applying k-Fold Cross Validation\naccuracies_svm_gaussian = cross_val_score(estimator=classifier, X=X_train_scaled, y=y_train, cv=kfold)\n\n#confusion matrix\ncm_svm_gaussian = confusion_matrix(y_test, y_pred)\n\n#classification report\ncr_svm_gaussian = classification_report(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Naive Bayes Model\n\n#Fitting classifier to the Training set\nfrom sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\nclassifier.fit(X_train_scaled,y_train)\n\n#Predicting the test set value\ny_pred = classifier.predict(X_test_scaled)\n\n#applying k-Fold Cross Validation\naccuracies_naivebayes = cross_val_score(estimator=classifier, X=X_train_scaled, y=y_train, cv=kfold)\n\n#confusion matrix\ncm_naivebayes = confusion_matrix(y_test, y_pred)\n\n#classification report\ncr_naivebayes = classification_report(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Decision Tree Model\n\n#Fitting classifier to the Training set\nfrom sklearn.tree import DecisionTreeClassifier\nclassifier = DecisionTreeClassifier(criterion='entropy', random_state=0)\nclassifier.fit(X_train_scaled,y_train)\n\n#Predicting the test set value\ny_pred = classifier.predict(X_test_scaled)\n\n#applying k-Fold Cross Validation\naccuracies_dectree = cross_val_score(estimator=classifier, X=X_train_scaled, y=y_train, cv=kfold)\n\n#confusion matrix\ncm_dectree = confusion_matrix(y_test, y_pred)\n\n#classification report\ncr_dectree = classification_report(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Random Forest Model\n\n#Fitting classifier to the Training set\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators=10, random_state=0, criterion='entropy')\nclassifier.fit(X_train_scaled,y_train)\n\n#Predicting the test set value\ny_pred = classifier.predict(X_test_scaled)\n\n#applying k-Fold Cross Validation\naccuracies_randfor = cross_val_score(estimator=classifier, X=X_train_scaled, y=y_train, cv=kfold)\n\n#confusion matrix\ncm_randfor = confusion_matrix(y_test, y_pred)\n\n#classification report\ncr_randfor = classification_report(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#XGBoost Model\n\n#Fitting XGBoost to the training set\nfrom xgboost import XGBClassifier\nxgbmodel = XGBClassifier()\nxgbmodel.fit(X_train, y_train)\n\n#Predicting the test set value\ny_pred = xgbmodel.predict(X_test)\n\n#applying k-Fold Cross Validation\naccuracies_xgboost = cross_val_score(estimator=xgbmodel, X=X_train, y=y_train, cv=kfold)\n\n#confusion matrix\ncm_xgboost = confusion_matrix(y_test, y_pred)\n\n#classification report\ncr_xgboost = classification_report(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Comparing K-Fold means on training set\n\nrow_list = []\ndict_1 = {\"Logistic\":accuracies_log.mean(), \"KNN\":accuracies_knn.mean(), \n         \"SVM_Gaussian\":accuracies_svm_gaussian.mean(), \"Naive Bayes\":accuracies_naivebayes.mean(),\n         \"Decision Tree\":accuracies_dectree.mean(), \"Random Forest\":accuracies_randfor.mean(),\n         \"XGBoost\":accuracies_xgboost.mean()}\nrow_list.append(dict_1)\ndict_2 = {\"Logistic\":accuracies_log.std(),\"KNN\":accuracies_knn.std(), \n         \"SVM_Gaussian\":accuracies_svm_gaussian.std(), \"Naive Bayes\":accuracies_naivebayes.std(),\n         \"Decision Tree\":accuracies_dectree.std(), \"Random Forest\":accuracies_randfor.std(),\n         \"XGBoost\":accuracies_xgboost.std()}\nrow_list.append(dict_2)\nacc_df = pd.DataFrame(row_list)\nacc_df = acc_df.transpose()\nacc_df = acc_df.rename(columns={0:\"skfold_mean\",1:\"skfold_std\"})\nacc_df = acc_df.sort_values(by=\"skfold_mean\",ascending=False)\nacc_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cla_report(matrix,name):\n    TP=matrix[0,0]\n    FP=matrix[0,1]\n    FN=matrix[1,0]\n    TN=matrix[1,1]\n    precision_class_1 = TN/(TN+FP)\n    recall_class_1 = TN/(TN+FN)\n    precision_class_0 = TP/(TP+FN)\n    recall_class_0 = TP/(TP+FP)\n    accuracy = (TP+TN)/(TP+FP+FN+TN)\n    return {\"Model\":name,\"Precision Stay\":precision_class_0, \"Precision Leave\":precision_class_1, \n            \"Recall Stay\":recall_class_0, \"Recall Leave\":recall_class_1, \"Accuracy\":accuracy}\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Comparing Confusion Matrix metrics on test set\n\ncml = []\ncml.append(cla_report(cm_svm_gaussian,\"SVM Gaussian\"))\ncml.append(cla_report(cm_log,\"Logistic\"))\ncml.append(cla_report(cm_randfor,\"Random Forest\"))\ncml.append(cla_report(cm_xgboost,\"XGBoost\"))\ncml.append(cla_report(cm_knn,\"KNN\"))\ncml.append(cla_report(cm_naivebayes,\"Naive Bayes\"))\ncml.append(cla_report(cm_dectree,\"Decision Tree\"))\ncml_df = pd.DataFrame(cml)\ncml_df = cml_df.sort_values(by=[\"Recall Leave\",\"Precision Leave\"],ascending=False)\ncml_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Important features of XGBoost model\n\nimport matplotlib.pyplot as plt\nfrom xgboost import plot_importance\n\nfig, ax = plt.subplots(figsize=(10,8))\np = plot_importance(xgbmodel, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_data['ChurnProb'] = xgbmodel.predict_proba(df_data[X_train.columns])[:,1]\ndf_data[['CustomerId','ChurnProb']].head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}