{"cells":[{"metadata":{},"cell_type":"markdown","source":"## TUGAS 1 DATA SCIENCE & ANALYTICS"},{"metadata":{},"cell_type":"markdown","source":"Petunjuk:\n1. Gunakanlah Jupyter Notebook, Google Collab, Kaggle, ataupun platform lainnya dalam pengerjaan tugas.\n2. Lakukanlah pengolahan data dan perhitungan menggunakan bahasa pemrograman Python.\n3. Mahasiswa diberikan kebebasan dalam penggunaan library.\n4. Sertakan penjelasan singkat mengenai setiap jawaban maupun code yang diberikan,beserta sumber code (jika ada).\n5. Sertakan nama kolaborator jika tugas dikerjakan secara peer. Tugas yang dikerjakan secara peer tanpa nama kolaborator akan diindikasikan sebagai PLAGIARISME.\n6. Simpan file dengan nama: Kls_T1_NPM.zip yang berisi penjelasan dalam bentuk PPT dan file ipynb.\n7. Kumpulkan file pada slot yang telah disediakan di scele. Deadline: 16 Februari 2020 pukul 21.00 WIB.\n8. Terdapat 3 dataset yang digunakan dalam tugas ini. Mahasiswa hanya perlu menggunakan satu dataset saja, yaitu Dataset x dimana x = digit terakhir NPM Anda di mod dengan 3.\n\n\nDataset yang digunakan adalah mengenai Birdsâ€™ Bones and Living Habits. Data dapat dilihat pada https://www.kaggle.com/zhangjuefei/birds-bones-and-living-habits"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Import Library\n\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Mengambil data, kode disesuaikan dengan platform (Kaggle)\n\ndata = pd.read_csv('../input/birds-bones-and-living-habits/bird.csv', index_col='id')\ndisplay(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## NOMOR 1"},{"metadata":{},"cell_type":"markdown","source":"### [30] Deskripsikan secara singkat tentang dataset Anda (jumlah atribut, jumlah data, jumlah data tak valid, contoh histogram minimal 5 atribut yang Anda anggap menarik, contoh scatterplot minimal 5 pasang atribut yang Anda anggap menarik, dll)"},{"metadata":{},"cell_type":"markdown","source":"#### Deskripsi data\nData terdiri atas 11 fitur dan 420 entry data. Terdapat satu fitur kategori dan sisanya adalah numerikal. Data tidak bersih sepenuhnya, terdapat beberapa baris dengan nilai Null pada satu atau lebih fiturnya. \n\nFitur dataset :\n* id : Sequential id\n* huml : Length of Humerus (mm)\n* humw : Diameter of Humerus (mm)\n* ulnal : Length of Ulna (mm)\n* ulnaw : Diameter of Ulna (mm)\n* feml : Length of Femur (mm)\n* femw : Diameter of Femur (mm)\n* tibl : Length of Tibiotarsus (mm)\n* tibw : Diameter of Tibiotarsus (mm)\n* tarl : Length of Tarsometatarsus (mm)\n* tarw : Diameter of Tarsometatarsus (mm)\n* type : Ecological Group"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Pada fitur-fitur numerikal, terdapat perbandingan scale data yang besar antara fitur yang mendeskripsikan \"length\" dan \"diameter\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Deskripsi statistik data\n\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Membersihkan data yang Null\n\ncleaned = data.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cleaned_y = cleaned['type']\ncleaned_x = cleaned.drop(['type'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting boxplot. Terdapat beberapa entry yang terdeteksi sebagai outlier, dengan definisi outlier adalah data yang keluuar dari boxplot\n\nfor feature in cleaned_x.columns:\n    sns.boxplot(x=\"type\", y=feature, data=cleaned)\n    sns.swarmplot(x=\"type\", y=feature, data=cleaned, color=\"0.3\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Type adalah fitur \"utama\" yang paling menarik, karena paling mungkin untuk dilakukan prediksi padanya.\n\nplt.title(\"Bird Type Data Count\")\nsns.countplot(x=\"type\", data=cleaned)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Menghitung Covariance Matrix\n\ncov_matrix = np.cov(cleaned_x.T)\ncov_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting Covariance Matrix\n\nplt.figure(figsize=(15,15))\n\nsns.heatmap(cov_matrix.T, \n        annot=True,\n        cbar = False,\n        fmt=\"0.2f\",\n        cmap=\"YlGnBu\",\n        xticklabels=cleaned_x.columns,\n        yticklabels=cleaned_x.columns)\nplt.title(\"Covariance matrix\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting Covariance Matrix\n\nplt.figure(figsize=(15,15))\n\nsns.heatmap(cleaned_x.corr(), \n        annot=True,\n        cbar = False,\n        fmt=\"0.2f\",\n        cmap=\"YlGnBu\",\n        xticklabels=cleaned_x.columns,\n        yticklabels=cleaned_x.columns)\nplt.title(\"Correlation matrix\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in df_special_l.columns:\n    for typ in cleaned_y.unique():\n        df = cleaned[cleaned['type'] == typ]\n        sns.distplot(a=df[feature], label=typ)\n    plt.title(feature)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in df_special_w.columns:\n    for typ in cleaned_y.unique():\n        df = cleaned[cleaned['type'] == typ]\n        sns.distplot(a=df[feature], label=typ)\n    plt.title(feature)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(cleaned, hue='type')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dari heatmap di atas, didapatkan 5 buah fitur dengan nilai covariance matrix yang tinggi yaitu \"huml\", \"ulnal\", \"feml\", \"tibl\", \"tarl\". Hal ini dikarenakan scale fitur data yang memang tinggi. Sedangkan terdapat 5 buat fitur dengan nilai covariance yang relatif rendah \"humw\", \"ulnaw\", \"femw\", \"tibw\", \"tarw\". Dari sini, ingin dilihat distribusi fitur dari kategorinya."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Kategori fitur \"Length\"\n\ndf_special_l = data.drop(['tarw','tibw','femw','ulnaw','humw', 'type'], axis=1)\ndf_special_l","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting distribusi data pada fitur-fitur kategori \"length\"\n\nplt.figure(figsize=(15,10))\n\nfor feature in df_special_l.columns:\n    sns.distplot(a=df_special_l[feature], label=feature)\nplt.legend()\nplt.title(\"Distribution of 'Length' features\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Kategori fitur \"Diameter\"\n\ndf_special_w = data.drop(['tarl','tibl','feml','ulnal','huml','type'], axis=1)\ndf_special_w","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting distribusi data pada fitur-fitur kategori \"length\"\n\nplt.figure(figsize=(15,10))\n\nfor feature in df_special_w.columns:\n    sns.distplot(a=df_special_w[feature], label=feature)\nplt.title(\"Distribution of 'Diameter' features\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Selain distribusi setiap kategori, antar pasang fitur \"Length\" dan \"Diameter\" dapat divisualisasikan dengan scatter plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scatter plot \n\nfor i in range(len(df_special_l.columns)):\n    sns.scatterplot(x=df_special_l.columns[i], y=df_special_w.columns[i], data=cleaned, hue='type')\n    plt.title(\"%s vs %s\" % (df_special_l.columns[i],df_special_w.columns[i]))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## NOMOR 2"},{"metadata":{},"cell_type":"markdown","source":"### [10] Menurut Anda, apakah sebaiknya perlu dilakukan normalisasi terhadap data sebelum pemrosesan lebih lanjut, atau cukup menggunakan data asli? Berikan contoh ekstrimnya"},{"metadata":{},"cell_type":"markdown","source":"Ya, normalisasi perlu dilakukan. Seperti yang telah dieksplor pada nomor 1, bahwa scale data antara \"length\" dan \"diamater\" relatif tinggi. Pada perhitungan Covariance Matrix pun terlihat anomali pada hasilnya, karena data yang tidak discale dalam ukuran yang sama. Oleh karena itu juga, saya belajar bahwa Covariance Matrix digunakan untuk data yang sudah memiliki scale yang sama antar fiturnya. Sedangkan untuk data yang tidak discale, lebih baik menggunakan Correlation Matrix. Hasil dari kedua metode tersebut akan tetap sama.\n\nCara untuk melakukan scale ada banyak, di sini saya akan menunjukkan perbedaan antara 2 scale paling terkenal dan simple yang digunakan dalam Data Mining."},{"metadata":{"trusted":true},"cell_type":"code","source":"def normalisasi(data, scaler):\n    data_norm = scaler.fit_transform(data)\n    return data_norm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### MINMAX SCALER"},{"metadata":{"trusted":true},"cell_type":"code","source":"min_max_scale = MinMaxScaler()\nmin_max = normalisasi(cleaned_x, min_max_scale)\nnew_min_max = pd.DataFrame(min_max, columns=cleaned_x.columns)\nnew_min_max['type'] = cleaned_y\nnew_min_max","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_min_max.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting Covariance Matrix\n\nplt.figure(figsize=(15,15))\n\nsns.heatmap(np.cov(min_max.T), \n        annot=True,\n        cbar = False,\n        fmt=\"0.3f\",\n        cmap=\"YlGnBu\",\n        xticklabels=cleaned_x.columns,\n        yticklabels=cleaned_x.columns)\nplt.title(\"Covariance matrix\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### STANDARD SCALER"},{"metadata":{"trusted":true},"cell_type":"code","source":"standard_scale = StandardScaler()\nstandard = normalisasi(cleaned_x, standard_scale)\nnew_standard = pd.DataFrame(standard, columns=cleaned_x.columns)\nnew_standard['type'] = cleaned_y\nnew_standard","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_standard.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting Covariance Matrix\n\nplt.figure(figsize=(15,15))\n\nsns.heatmap(np.cov(standard.T), \n        annot=True,\n        cbar = False,\n        fmt=\"0.2f\",\n        cmap=\"YlGnBu\",\n        xticklabels=cleaned_x.columns,\n        yticklabels=cleaned_x.columns)\nplt.title(\"Covariance matrix\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Bagaimana jika kita menyimpulkan decision dari insight yang anomali karena data belum dinormalisasi?? Kasusnya akan sangat berbahaya. Apalagi insight mining merupakan salah satu hal yang krusial di Data Science.\n\nDari contoh sebelumnya merupakan hanya sedikit gambaran dampak yang dapat terjadi pada tahap insight mining, di mana hal ini masih dalam tahap awal dalam Data Science Lifecycle. Dampak lebih buruk dan ekstrim dapat terjadi pada proses setelahnya. Pada proses prediksi, normalisasi dapat berpengaruh besar (kecuali pada Tree-based model) pada peningkatan akurasi. \n"},{"metadata":{},"cell_type":"markdown","source":"## NOMOR 3"},{"metadata":{},"cell_type":"markdown","source":"### [60] Carilah eigenvector dan eigenvalue dari dataset Anda. Rekomendasikan berapa jumlah principle component yang sebaiknya digunakan untuk dataset Anda, jika Anda menginginkan dimensi sekecil mungkin namun hasil plot kelas dapat terpisahkan dengan baik secara visual. Berikan analisis singkat mengapa Anda merekomendasikan hal tersebut."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Mencari eigenvector dan eigenvalue dari covariance matrix\n\neig_values, eig_vectors = np.linalg.eig(cov_matrix)\nprint(\"Eigen Values of dataset: \", eig_values)\nprint()\nprint(\"Eigen vector of dataset: \", eig_vectors)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Untuk menentukan N fitur minimal yang dapat menggambarkan X% variance, dapat dilakukan dengan melihat frekuensi kumulatif dari eigenvalues dan melihat signifikasinya. Perlu direduksi fitur di data sehingga dengan N fitur minimal kita sudah bisa mendapatkan frekuensi kumulatif >= X."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Melihat signifikansi masing-masing eigen dengan frekuensi kumulatif\n\neig_sum = np.sum(eig_values)\ndata_eig = [(i / eig_sum)*100 for i in sorted(eig_values, reverse=True)]\ndata_fr = np.cumsum(data_eig)\ndata_fr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lineplot(y=data_fr, x=range(len(data_fr)))\nsns.lineplot(y=99, x=range(len(data_fr)))\nplt.title(\"Cummulative frequency of Eigenvalue\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Maka dengan asumsi kita ingin mengcover 99% variance dari data, kita hanya perlu mereduksi dimensi dataset hingga menjadi hanya 4 dimensi/fitur karena cukup dengan 4 fitur kita sudah bisa mendapatkan persentase variance yang diharapkan"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dengan library\nfrom sklearn.decomposition import PCA\n\npca = PCA(0.99)\nskl_pca = pca.fit_transform(cleaned_x).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Top eigen values of reduced dimention\n\neig_selected = pca.explained_variance_\nprint(\"Numer of dimension: \", len(eig_selected))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skl_pca = skl_pca.T\nskl_pca = pd.DataFrame(skl_pca)\nskl_pca","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skl_pca['type'] = cleaned_y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(skl_pca, hue='type')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}