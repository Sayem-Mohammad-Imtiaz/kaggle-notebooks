{"cells":[{"metadata":{"id":"mo9Nsua3V955"},"cell_type":"markdown","source":"# Avacado Price Prediction Regression Models","execution_count":null},{"metadata":{"id":"FDZ02EraWSop"},"cell_type":"markdown","source":"## Table of Contents\n\n1. Problem Statement\n2. Importing Libraries\n3. Data\n  - Loading data\n  - Description of data columns\n  - Understanding data - Pre-Profiling\n4. Exploratory Data Analysis\n  - Pre processing data\n      - Handling missing values\n      - Type conversions\n      - Feature engineering\n      - Transforming exploratory variable\n  - Post profiling\n5. Modelling using sklearn\n  - Data Preparation\n    - Splitting data as train and test\n    - Scaling and encoding\n  - Building Models\n  - Model Predictions\n6. Model Evaluations\n7. Model Plotting\n    - Comparing models\n8. Conclusions\n    - Analyzing and finalizing best-fit model\n  \n","execution_count":null},{"metadata":{"id":"uiw5L2uddpHg"},"cell_type":"markdown","source":"## 1. Problem Statement\n---","execution_count":null},{"metadata":{"id":"UgQT3H1MT6L-"},"cell_type":"markdown","source":"Given historical data on avocado prices and sales volume in multiple US markets and various other factors like Date, AveragePrice,Total Volume, Total Bags,Year,Type etc.\n\nThe goal is to predict average price of avocado using best regression model among Linear Regression, Decision Tree Regressor and Randon Forest Regressor.","execution_count":null},{"metadata":{"id":"INIu22pZdxCd"},"cell_type":"markdown","source":"## 2. Importing Libraries\n---","execution_count":null},{"metadata":{"executionInfo":{"elapsed":1919,"status":"ok","timestamp":1599390947861,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"FSsaPA1I0o3z","outputId":"b0ec00d4-d2dc-4551-d31c-30dc40cccb5f","trusted":true},"cell_type":"code","source":"# Importing required libraries\nimport numpy as np\nimport pandas as pd\nfrom pandas_profiling import ProfileReport\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\n\n# Setting options\nnp.set_printoptions(precision=4)                 # To display values upto Four decimal places. \nplt.style.use('seaborn-whitegrid')               # To apply seaborn whitegrid style to the plots.\nplt.rc('figure', figsize=(20, 12))               # Set the default figure size of plots.\nsns.set(style='whitegrid')                       # To apply whitegrid style to the plots.\nwarnings.filterwarnings('ignore')                # To ignore warnings, if any","execution_count":null,"outputs":[]},{"metadata":{"id":"JeP3jy0qepya"},"cell_type":"markdown","source":"## 3. Data\n---","execution_count":null},{"metadata":{"id":"imL31_q7ez-b"},"cell_type":"markdown","source":"### Loading data...","execution_count":null},{"metadata":{"executionInfo":{"elapsed":2637,"status":"ok","timestamp":1599390948601,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"2_GNcHCUzweW","outputId":"624b22c6-0e04-4f8c-88ea-ad2e0e212314","trusted":true},"cell_type":"code","source":"# Importing the dataset as data\ndata = pd.read_csv('../input/avocado-prices/avocado.csv', index_col=0)\ndata.sample(8)    # Preview of random 8 rows ","execution_count":null,"outputs":[]},{"metadata":{"id":"rlYROcn9fEso"},"cell_type":"markdown","source":"### Description of data columns","execution_count":null},{"metadata":{"id":"-FbaqS1IfZqE"},"cell_type":"markdown","source":"\n<p>\nThe dataset consists of the information about HASS Avocado. \n\nHistorical data on avocado prices and sales volume in multiple US markets. Various variables present in the dataset includes Date, AveragePrice,Total Volume, Total Bags,Year,Type etc.\n\nThe dataset comprises of 18249 observations of 14 columns. Below is a table showing names of all the columns and their description.\n</p>\n\n|Column|Description|\n|--:|:--|\n|**Date**|The date of the observation|\n|**AveragePrice**|Average price of a single avocado - ***Target Variable***|\n|**Total Volume**|Total number of avocados sold|\n|**4046**|Total avocados with PLU 4046 - *Small/Medium Hass Avocado (\\~3-5oz avocado)* sold|\n|**4225**|Total number of avocados with PLU 4225 - *Large Hass Avocado (\\~8-10oz avocado)* sold|\n|**4770**|Total number of avocados with PLU 4770 - *Extra Large Hass Avocado (\\~10-15oz avocado)* sold|\n|**type**|Conventional or Organic|\n|**year**|Year of observation|\n|**Region**|City or region of the observation|\n\n\n\n","execution_count":null},{"metadata":{"executionInfo":{"elapsed":2621,"status":"ok","timestamp":1599390948602,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"cr2BXP3zhanq","outputId":"78bbb1e3-7780-4207-9c49-fe1e101ceb80","trusted":true},"cell_type":"code","source":"data.shape       # Number of (records, features) of data","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":2602,"status":"ok","timestamp":1599390948603,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"jrYaFkPGi7Az","outputId":"8a051fa6-1b6c-4b3d-c50e-6c59a203ecca","trusted":true},"cell_type":"code","source":"data.info()      # Info of data","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":2580,"status":"ok","timestamp":1599390948604,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"xyIsz1UChbUQ","outputId":"1cc6ccbf-4baa-4a84-e4cb-5c8b520dd8c6","trusted":true},"cell_type":"code","source":"data.describe()     # Descriptive statistics of data","execution_count":null,"outputs":[]},{"metadata":{"id":"9rUbp0_AhcNo"},"cell_type":"markdown","source":"* There are total of 18249 and 13 columns \n* From `info`, we can infer that there are no missing values.\n* Target Variable 'Average Price' looks normally distribured as mean and median(50 percentile value) are almost similar, but TV seems to be right skewed\n\n","execution_count":null},{"metadata":{"id":"FoznfQZFhPKu"},"cell_type":"markdown","source":"### Understanding data - Pre-Profiling","execution_count":null},{"metadata":{"executionInfo":{"elapsed":2565,"status":"ok","timestamp":1599390948605,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"TpkY2l7mhSOU","trusted":true},"cell_type":"code","source":"pre_profile = data.profile_report(title='Avacado Pre-Profiling')   # Performing Pre Profiling on data.","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":38597,"status":"ok","timestamp":1599390984652,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"cB3XPX4UM5xr","outputId":"e07e228d-9925-42f2-9de3-586a3f93b8ff","trusted":true},"cell_type":"code","source":"pre_profile.to_file('pre-profiling.html')                          # Saving report to pre-profiling.html","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":44275,"status":"ok","timestamp":1599390990352,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"Qbae76G3L22h","outputId":"793dffe2-60b7-49d7-e8a0-328c2170f6e4","trusted":true},"cell_type":"code","source":"# pre_profile.to_notebook_iframe()                                 # Displaying the profiling report inline. ","execution_count":null,"outputs":[]},{"metadata":{"id":"6ZLBbRZ1Lmoh"},"cell_type":"markdown","source":"**Profiling before Data Processing** <br><br>\n__Dataset info__:\n- Number of variables: 13\n- Number of observations: 18249\n- Missing cells: 0\n\n\n__Variables types__: \n- Numeric: 10\n- Categorical: 3\n\n__Observations__: \n* There seems to be some problem with __index__, as there are only 53 unique values and total records are 18000+\n* __Target variable__ in normally distributed but wiht slight skewedness at right\n* There is equal distribution of __conventional__ and __organic__ avacado types\n* __Region__ and __Date__ are uniformly distributed and have high cardinality\n* Most of variables like _4046, 4225, Total Bags, Small Bags, Large Bags_ are highly corellated with **Total Volume**","execution_count":null},{"metadata":{"id":"n0eTR-_XTcye"},"cell_type":"markdown","source":"## 4. Exploratory Data Analysis\n---","execution_count":null},{"metadata":{"id":"Tic4ueZOTly-"},"cell_type":"markdown","source":"###  Pre processing data\n\n* __Handling issues found in pre-profiling__\n* __Preparing data for modelling__\n      - Handling missing values\n      - Type conversions\n      - Feature engineering\n      - Transforming exploratory variable\n      \n---\n\nFrom the above observations we will:\n- Reset_index\n- Rename features as per conveniance\n- Altering the type of features\n- Feature engineer some columns\n- Drop ineffective features\n- Drop highly correlated features\n- Drop records with right skewed target variable","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Fixing issues with index","execution_count":null},{"metadata":{"executionInfo":{"elapsed":44261,"status":"ok","timestamp":1599390990354,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"MVYsQhVKVyrP","outputId":"c4b1a15c-d5ac-46a7-e1f0-7ff3abb5dbb3","trusted":true},"cell_type":"code","source":"# Unique values in data index - doing this as profiling shows there are zeros in index\nprint('No. of unique index values:', data.index.nunique())                          ","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":44261,"status":"ok","timestamp":1599390990354,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"MVYsQhVKVyrP","outputId":"c4b1a15c-d5ac-46a7-e1f0-7ff3abb5dbb3","trusted":true},"cell_type":"code","source":"data.reset_index(drop=True, inplace=True)    # reseting index as index values seems to be incorrect\n\n# Unique values in data index after ressetting\nprint('No. of unique index values after resetting index: ', data.index.nunique())   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Rename columns as per conveniance","execution_count":null},{"metadata":{"executionInfo":{"elapsed":44245,"status":"ok","timestamp":1599390990356,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"8GLfMJwXXH2i","outputId":"8910c092-2d36-468a-e2b8-6c85d2f67c70","trusted":true},"cell_type":"code","source":"# Renaming column names\ndata.rename(columns={'4046':'PLU_4046','4225':'PLU_4225','4770':'PLU_4770'}, inplace=True) # Renaming size as per description\n# Renaming columns to remove spaces and capitalize first letter\ndata.columns = data.columns.str.replace(' ','').map(lambda x : x[0].upper() + x[1:]) \ndata.head(2)  # Preview of column header","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Working with type of features...","execution_count":null},{"metadata":{"executionInfo":{"elapsed":44227,"status":"ok","timestamp":1599390990357,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"NJUsEZQeRU93","outputId":"997bf894-55fe-4d88-fbe6-578dbd2e2d38","scrolled":true,"trusted":true},"cell_type":"code","source":"data.dtypes # Looking for data types","execution_count":null,"outputs":[]},{"metadata":{"id":"cbZszhPXiqRx"},"cell_type":"markdown","source":"There are 3 categorical columns\n* __Type__ has on two values and distriburted uniformly\n* __Date__ and __Region__ are highly cardinal, so we will work on how to proceed further...","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Converting `Date` to `datetime` from `object`","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Converting `Year` to `object` from `numeric`","execution_count":null},{"metadata":{"executionInfo":{"elapsed":44229,"status":"ok","timestamp":1599390990376,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"CZG0rYOCRVuY","trusted":true},"cell_type":"code","source":"data['Date'] = pd.to_datetime(data['Date'])    # Converting date to datetime type\ndata['Year'] = data['Year'].astype('object')   # Converting Year to object from numeric","execution_count":null,"outputs":[]},{"metadata":{"id":"g9abJqRlO_H0"},"cell_type":"markdown","source":"Deriving some insightful columns from __Date__ - like 'Season', 'Month', 'Quarter'","execution_count":null},{"metadata":{"executionInfo":{"elapsed":44217,"status":"ok","timestamp":1599390990377,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"GN_a_GWzJEvD","trusted":true},"cell_type":"code","source":"# Utility / Helper Function - To categorize season based on date\n\ndef categorizing_seasons(date):\n    month = date.month\n\n    # Source - https://en.wikipedia.org/wiki/Season#Meteorological\n    winter, spring, summer, autumn = ([12, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10, 11])\n    if month in winter:\n        return 'Winter'\n    elif month in spring:\n        return 'Spring'\n    elif month in summer:\n        return 'Summer'\n    else:\n        return 'Autumn'","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":44210,"status":"ok","timestamp":1599390990382,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"iw6gMzwuIFL4","trusted":true},"cell_type":"code","source":"data['Month'] = data['Date'].dt.month_name()             # Deriving Month from Date\ndata['Quarter'] = data['Date'].dt.quarter                # Deriving Qurter from Date\ndata['Season'] = data['Date'].map(categorizing_seasons)  # Deriving Season from Date","execution_count":null,"outputs":[]},{"metadata":{"id":"gqcss7K6OgWN"},"cell_type":"markdown","source":"Analyzing how `AveragePrice` varies w.r.t `Month`, `Quarter`, `Season`. ","execution_count":null},{"metadata":{"executionInfo":{"elapsed":44198,"status":"ok","timestamp":1599390990383,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"rjppbD-NlUV6","trusted":true},"cell_type":"code","source":"# Utility / Helper Function - To update the variables as per data\n\ndef get_variables_from_data():\n    # Target Variables\n    y_column = 'AveragePrice'                                          \n     \n    # Categorical Feature variables \n    X_columns_cat = list(data.dtypes[data.dtypes.values == 'object'].index)  \n\n    # Numeric Feature variables\n    X_columns_num = list(data.dtypes[(data.dtypes.values != 'object') & (data.dtypes.index != y_column)].index)    \n\n    # Feature variables\n    X_columns = X_columns_num + X_columns_cat\n    \n    print('y_column:', y_column)\n    print('X_columns: ',X_columns) \n    print('X_columns_num: ',X_columns_num) \n    print('X_columns_cat: ',X_columns_cat) \n    \n    # Returning as a tuple\n    return y_column, X_columns, X_columns_num, X_columns_cat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Updating Variables\ny_column, X_columns, X_columns_num, X_columns_cat = get_variables_from_data()","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":44182,"status":"ok","timestamp":1599390990384,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"nFqe40x9PJ5a","outputId":"c1529df6-2edd-4235-9339-65e3e4053cc6","trusted":true},"cell_type":"code","source":"data.groupby('Month')[y_column].agg(['max', 'mean', 'min'])   # Understanding TV w.r.t 'Month'","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":44166,"status":"ok","timestamp":1599390990386,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"m54-pSilP-2D","outputId":"a5bf4f1c-8d51-4b51-d397-895dd4ef55c3","trusted":true},"cell_type":"code","source":"data.groupby('Quarter')[y_column].agg(['max', 'mean', 'min'])  # Understanding TV w.r.t 'Quarter'","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":44141,"status":"ok","timestamp":1599390990387,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"mYWiIx4FQBO-","outputId":"5ac2cdc2-3f72-4e6d-fc25-793957001d32","trusted":true},"cell_type":"code","source":"data.groupby('Season')[y_column].agg(['max', 'mean', 'min'])  # Understanding TV w.r.t 'Season'","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":44125,"status":"ok","timestamp":1599390990390,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"ElJSyqugPIYl","outputId":"0cf3eb12-2dd2-439f-93ae-3d5b39580696","trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(1, 3, figsize=(15,5))\nf.suptitle('Spread of mean AveragePrice Over Season, Quarter and Month', fontsize=16)\ndata.groupby('Season')[y_column].mean().plot(kind='bar',ax=ax[0])\ndata.groupby('Quarter')[y_column].mean().plot(kind='bar',ax=ax[1])\ndata.groupby('Month')[y_column].mean().plot(kind='bar',ax=ax[2])","execution_count":null,"outputs":[]},{"metadata":{"id":"6LitOH62PJBL"},"cell_type":"markdown","source":"__Observations__\n\n*   Average price drops in the months of December, January, February, May, June, July\n*   No much varience in price w.r.t Quarter - So we can drop this column. \n*   In winters Avacado prices drops more than any other seasons - as seasons are correlated and gives more info we can drop `Season`, `Date` and have `Month` column as an important feature.\n\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_columns          # Preview of existing Feature columns ","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":44110,"status":"ok","timestamp":1599390990391,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"NHpRotErqEaa","trusted":true},"cell_type":"code","source":"# Replacing date with less cordinal column month\ndata.drop(columns=['Date', 'Season', 'Quarter'], inplace=True)   # Droping Data, Quarter and Season columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Updating Variables\ny_column, X_columns, X_columns_num, X_columns_cat = get_variables_from_data()","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":44098,"status":"ok","timestamp":1599390990392,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"X21ewGmaPMjN","outputId":"a01b1ca6-5c3f-4f04-aba8-b5a05a26d5ab","trusted":true},"cell_type":"code","source":"f, ax =  plt.subplots(1, 2, figsize=(15, 8))\nf.suptitle('Box plot on Target Variable and Target Variable Distribution - Before', fontsize=16)\nsns.boxplot(y=y_column, data=data, ax=ax[0]) # Box plot on TV before droping extreme values\nsns.distplot(data[y_column], ax=ax[1])       # Distribution of Target Vaiable","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking mean|median and limiting data to 2 * (mean|median) - To eliminate extreme right values\ndata[y_column].describe()                  ","execution_count":null,"outputs":[]},{"metadata":{"id":"MvMQ3IY0PNI5"},"cell_type":"markdown","source":"We will remove extreme values above avg price 2.8, this makes our TV symetric","execution_count":null},{"metadata":{"executionInfo":{"elapsed":44081,"status":"ok","timestamp":1599390990394,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"cOzriiEdI63F","outputId":"bc087edb-f1e0-42e1-afbd-1374b2977af3","trusted":true},"cell_type":"code","source":"data.drop(data[data[y_column] > 2.8].index, inplace=True) # Droping records where price > 3\nprint(data.shape)                                         # Shape of data after droping few records\ndata.sample(5)                                            # Preview of data after droping few records","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax =  plt.subplots(1, 2, figsize=(15, 8))\nf.suptitle('Box plot on Target Variable and Target Variable Distribution - After', fontsize=16)\nsns.boxplot(y=y_column, data=data, ax=ax[0]) # Box plot on TV after droping extreme values\nsns.distplot(data[y_column], ax=ax[1])       # Distribution of Target Vaiable","execution_count":null,"outputs":[]},{"metadata":{"id":"gg8mXT0Xq0zW"},"cell_type":"markdown","source":"EDA\nHow Price are varying wrt to Region\n\nPrice and Type relation\n\n\nSeperate X and y \n  - Do correlation and drop few columns\n  - Joint plot\n  - Dist Plot\n  - Linear relation amoing x and y","execution_count":null},{"metadata":{"executionInfo":{"elapsed":44063,"status":"ok","timestamp":1599390990395,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"-6C6k7ie5RAR","outputId":"3025faa6-7738-4d56-9657-9e2128f09001","trusted":true},"cell_type":"code","source":"data.head()   # Preview of data","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":3153,"status":"ok","timestamp":1599396552689,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"5T1H-5U64kFC","outputId":"535e263c-65ce-4735-dfac-d5b748538edf","scrolled":false,"trusted":true},"cell_type":"code","source":"# Density of mean price w.r.t categorical columns\nf, ax = plt.subplots(2,2)\nfor x_var, subplot in zip(X_columns_cat, ax.flatten()):\n    subplot.set_xlabel(x_var)\n    data.groupby(x_var)[y_column].mean().plot(kind='kde', ax=subplot, label='Test')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Mean price w.r.t categorical columns\nf, ax = plt.subplots(2,2)\nplt.subplots_adjust(hspace=0.5)\nfor x_var, subplot in zip(X_columns_cat, ax.flatten()):\n    subplot.set_xlabel(x_var)\n    subplot.set_ylabel('Mean Avg price')\n    data.groupby(x_var)[y_column].mean().plot(kind='bar', ax=subplot, label='Test')","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":3997,"status":"ok","timestamp":1599396553754,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"MfNFTJCnAD9V","outputId":"54f2ab5a-a1fe-43a9-b300-198813210de3","trusted":true},"cell_type":"code","source":"# Bot plot to check outliers in categorical columns\n\nf, ax = plt.subplots(1,2, figsize=(15,5))\nfor x_var, subplot in zip(X_columns_cat[0:2], ax.flatten()):\n    sns.boxplot(data = data, x=x_var, y=y_column, ax=subplot)\n\nf, ax = plt.subplots(1, figsize=(15,5))\nsns.boxplot(data = data, x=X_columns_cat[-1], y=y_column, ax=ax)\n\nf, ax = plt.subplots(1, figsize=(15,5))\nsns.boxplot(data = data, x=X_columns_cat[2], y=y_column, ax=ax)\nax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"id":"Si27XuvOBGOb"},"cell_type":"markdown","source":"There are some outliers present but these are not too extreme so we do not drop any records","execution_count":null},{"metadata":{"executionInfo":{"elapsed":9689,"status":"ok","timestamp":1599396559794,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"Ah_QP8VpDICo","outputId":"cf2520fe-1d8b-4de8-9083-9f0b77c61438","trusted":true},"cell_type":"code","source":"# Checking for relation of numeric columns w.r.t Target Variable\nf, ax = plt.subplots(1, len(X_columns_num), figsize=(20, 5))\n\nfor x_var, sp in zip(X_columns_num, ax.flatten()):\n    sns.regplot(x=data[x_var], y=data[y_column], ax=sp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Assumptions - Checking for No Multicollinearity","execution_count":null},{"metadata":{"executionInfo":{"elapsed":9524,"status":"ok","timestamp":1599396559795,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"z96ah_EbEcfF","outputId":"a3216257-8b64-40f6-f1eb-847548a47917","trusted":true},"cell_type":"code","source":"# Heatmap to check correlation\nplt.figure(figsize=(10,8))\nsns.heatmap(data[X_columns_num].corr(), annot=True, cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So droping 'PLU_4046', 'PLU_4225', 'TotalBags', 'SmallBags' which has very high Correlation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Droping highly correlated columns\ndata.drop(columns=['PLU_4046', 'PLU_4225', 'TotalBags', 'SmallBags'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data.head(2)   # Preview after droping columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Updating Variables\ny_column, X_columns, X_columns_num, X_columns_cat = get_variables_from_data()","execution_count":null,"outputs":[]},{"metadata":{"id":"-XPoKlvo_4sb"},"cell_type":"markdown","source":"#### Assumptions - Target Variable is Normally Distributed","execution_count":null},{"metadata":{"executionInfo":{"elapsed":9943,"status":"ok","timestamp":1599396560457,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"GKH3OF4YJE1w","outputId":"e4061190-731f-4bd6-fd30-d5b5d7b4d75e","trusted":true},"cell_type":"code","source":"sns.distplot(data[y_column]) # Normal Distribution of Target Vaiable","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":8640,"status":"ok","timestamp":1599396718576,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"l87TC8sGHRGt","outputId":"4686b552-71a7-4ae9-ad44-0d0a6258c2c5","trusted":true},"cell_type":"code","source":"# Pair Plot of data\nsns.pairplot(data, size = 2, aspect = 1.5)","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":6052,"status":"ok","timestamp":1599397718147,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"6JHqd3TpHhlv","outputId":"ae288fb6-552d-4071-f587-bd8c170c77af","trusted":true},"cell_type":"code","source":"# Checking for relation of Numeric Features with Target Variable\nsns.pairplot(data, x_vars=X_columns_num, y_vars=y_column, size=5, aspect=1, kind='reg') ","execution_count":null,"outputs":[]},{"metadata":{"id":"3HgnUuoLTxOI"},"cell_type":"markdown","source":"### Post profiling","execution_count":null},{"metadata":{"executionInfo":{"elapsed":8518,"status":"aborted","timestamp":1599396560461,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"OfWhwh-AV1l-","trusted":true},"cell_type":"code","source":"post_profile = data.profile_report(title='Avacado Post-Profiling')   # Performing Post Profiling on data.","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":8333,"status":"aborted","timestamp":1599396560462,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"mpq1xJlKV1QK","trusted":true},"cell_type":"code","source":"post_profile.to_file('post-profiling.html')                          # Saving report to post-profiling.html","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":8244,"status":"aborted","timestamp":1599396560462,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"LejfTi7PhWRc","trusted":true},"cell_type":"code","source":"# post_profile.to_notebook_iframe()                                    # View report inline here","execution_count":null,"outputs":[]},{"metadata":{"id":"fQNvHtbwUPiZ"},"cell_type":"markdown","source":"## 5. Modelling using sklearn\n---","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Preparing X and y","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(2) # Preview of data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_columns   # Preview of feature columns","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":4202,"status":"ok","timestamp":1599396718578,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"8r2Wiu_5MKnU","trusted":true},"cell_type":"code","source":"X = data[X_columns]           # Features data\ny = data[y_column]            # TV data","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":3754,"status":"ok","timestamp":1599396718581,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"CxoyLqwsMMk5","outputId":"2fb57e9d-5f66-4675-f176-650898e664aa","trusted":true},"cell_type":"code","source":"print(X.shape)\nX.head()                      # Preview of X","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":3233,"status":"ok","timestamp":1599396718583,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"EASqkdcdMVG1","outputId":"b5305275-961c-4da1-b25b-a13ad1167f5b","trusted":true},"cell_type":"code","source":"print(y.shape)\ny.head()                     # Preview of y","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":2622,"status":"ok","timestamp":1599396718585,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"J87LD-VYKvb3","trusted":true},"cell_type":"code","source":"# Splitting the dataset into training and test sets 80-20 split.\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":1165,"status":"ok","timestamp":1599397407307,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"dUPaCrwggvK2","trusted":true},"cell_type":"code","source":"# Reset index of split data sets\nX_train.reset_index(drop=True, inplace=True)\nX_test.reset_index(drop=True, inplace=True)\ny_train.reset_index(drop=True, inplace=True)\ny_test.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":1120,"status":"ok","timestamp":1599397410814,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"zn0lyXCQKwGa","outputId":"2fbb0a56-8ec3-49bb-d6ca-99f99560010d","trusted":true},"cell_type":"code","source":"print(X_train.shape)\nX_train.head()        # Preview of X_train","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":1156,"status":"ok","timestamp":1599397422920,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"MGMdb1bkKwhj","outputId":"aabfb860-72dd-44d6-db9c-016846a78978","trusted":true},"cell_type":"code","source":"print(X_test.shape)\nX_test.head()         # Preview of X_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Scaling numerical fields using StandardScaler","execution_count":null},{"metadata":{"executionInfo":{"elapsed":1330,"status":"ok","timestamp":1599397433970,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"Y3Quqq5pNiI6","trusted":true},"cell_type":"code","source":"X_train_num = X_train[X_columns_num]       # Numeric X_train \nX_test_num = X_test[X_columns_num]         # Numeric X_test","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":851,"status":"ok","timestamp":1599397433971,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"NzoxrmbMKwBh","trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler         # Importing Standard Scalar\nscaler = StandardScaler().fit(X_train_num)               # Fitting with train data","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":813,"status":"ok","timestamp":1599397435161,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"464ZnQtCKu-w","trusted":true},"cell_type":"code","source":"X_train_s = pd.DataFrame(scaler.transform(X_train_num), columns=X_columns_num)  # Transforming train data\nX_test_s = pd.DataFrame(scaler.transform(X_test_num), columns=X_columns_num)    # Transforming test data","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":842,"status":"ok","timestamp":1599397436379,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"NyXIovGNQ7-Z","outputId":"4d082785-8b62-488b-9f16-978849027f23","trusted":true},"cell_type":"code","source":"print(X_train_s.shape)\nX_train_s.head()            # Scaled train data - Numeric","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":1379,"status":"ok","timestamp":1599397439826,"user":{"displayName":"Raghava Joijode","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPP9eqwZmwzH-YNoXEYtCh3iE8FKq4jYPS6WH9kW4=s64","userId":"16384523256113436747"},"user_tz":-330},"id":"iW3wcUYteYFI","outputId":"cd243689-a8d8-4481-ec42-2c6321c50967","trusted":true},"cell_type":"code","source":"print(X_test_s.shape)\nX_test_s.head()             # Scaled test data - Numeric","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Scaling numerical fields using StandardScaler","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train[X_columns_cat].head()         # Preview of categorical features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 4 categorical features and as per below table we will perform encoding on each feature.\n\n|Column|Type of Encoding|\n|--:|:--|\n|Type|**OneHot** - As there are only 2 unique values|\n|Year|**Label** - To keep the ordinal importance|\n|Region|**Target** - As it has high cardinality we can use TargetEncoding to have effect of each Region on AveragePrice|\n|Month|**Target** - As it has high cardinality we can use TargetEncoding to have effect of each Month on AveragePrice|","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# One Hot Encoding on Type for Train set.\nX_train_type_dummies = pd.get_dummies(X_train['Type'], prefix='Type', drop_first=True)\nprint(X_train_type_dummies.shape)       # Shape of Dummies\nX_train_type_dummies.head()             # Preview of Type Dummies               ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_s = pd.concat([X_train_s, X_train_type_dummies], 1) # Merging type dummies to Scaled Train set\nprint(X_train_s.shape)                                      # Shape of merged train set\nX_train_s.head()                                            # Preview of merged train set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One Hot Encoding on Type for Test set.\nX_test_type_dummies = pd.get_dummies(X_test['Type'], prefix='Type', drop_first=True)\nprint(X_test_type_dummies.shape)       # Shape of Dummies\nX_test_type_dummies.head()             # Preview of Type Dummies               ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_s = pd.concat([X_test_s, X_test_type_dummies], 1)   # Merging type dummies to Scaled test set\nprint(X_test_s.shape)                                      # Shape of merged test set\nX_test_s.head()                                            # Preview of merged test set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Label Encoding on Year for Train set.\nfrom sklearn.preprocessing import LabelEncoder         # Importing Label Encoder\nlabel_encoder = LabelEncoder().fit(X_train['Year'])    # Fitting on train set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_year_dummies = pd.DataFrame(label_encoder.transform(X_train['Year']), columns=['Year'])\nprint(X_train_year_dummies.shape)       # Shape of Transformed Year\nX_train_year_dummies.head()             # Preview of Transformed Year ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_s = pd.concat([X_train_s, X_train_year_dummies], 1)   # Merging type dummies to Scaled train set\nprint(X_train_s.shape)                                        # Shape of merged train set\nX_train_s.head()                                              # Preview of merged train set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_year_dummies = pd.DataFrame(label_encoder.transform(X_test['Year']), columns=['Year'])\nprint(X_test_year_dummies.shape)       # Shape of Transformed Year\nX_test_year_dummies.head()             # Preview of Transformed Year ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_s = pd.concat([X_test_s, X_test_year_dummies], 1)   # Merging type dummies to Scaled test set\nprint(X_test_s.shape)                                      # Shape of merged test set\nX_test_s.head()                                            # Preview of merged test set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Installing category_encoders to import TargetEncoder\n# !pip install category_encoders","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Label Encoding on Year for Train set.\nfrom category_encoders import TargetEncoder                                # Importing Target Encoder\ntarget_encoder_region = TargetEncoder().fit(X_train['Region'], y_train)    # Fitting on train set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_region_dummies = target_encoder_region.transform(X_train['Region'])\nprint(X_train_region_dummies.shape)       # Shape of Transformed region\nX_train_region_dummies.head()             # Preview of Transformed region ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_s = pd.concat([X_train_s, X_train_region_dummies], 1)   # Merging region dummies to Scaled train set\nprint(X_train_s.shape)                                          # Shape of merged train set\nX_train_s.head()                                                # Preview of merged train set","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"X_test_region_dummies = target_encoder_region.transform(X_test['Region'])\nprint(X_test_region_dummies.shape)       # Shape of Transformed region\nX_test_region_dummies.head()             # Preview of Transformed region ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_s = pd.concat([X_test_s, X_test_region_dummies], 1)     # Merging region dummies to Scaled train set\nprint(X_test_s.shape)                                          # Shape of merged train set\nX_test_s.head()                                                # Preview of merged train set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_encoder_month = TargetEncoder().fit(X_train['Month'], y_train)    # Fitting on train set for Month","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_month_dummies = target_encoder_month.transform(X_train['Month'])\nprint(X_train_month_dummies.shape)       # Shape of Transformed region\nX_train_month_dummies.head()             # Preview of Transformed region ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_s = pd.concat([X_train_s, X_train_month_dummies], 1)    # Merging region dummies to Scaled train set\nprint(X_train_s.shape)                                          # Shape of merged train set\nX_train_s.head()                                                # Preview of merged train set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_month_dummies = target_encoder_month.transform(X_test['Month'])\nprint(X_test_month_dummies.shape)       # Shape of Transformed region\nX_test_month_dummies.head()             # Preview of Transformed region ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_s = pd.concat([X_test_s, X_test_month_dummies], 1)      # Merging month dummies to Scaled train set\nprint(X_test_s.shape)                                          # Shape of merged train set\nX_test_s.head()                                                # Preview of merged train set","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Final data after Scalings and Encodings","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train_s.shape)\nX_train_s.head()                    # Preview of X_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_train.shape)\ny_train.head()                    # Preview of y_train","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print(X_test_s.shape)\nX_test_s.head()                    # Preview of X_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_test.shape)\ny_test.head()                    # Preview of y_test","execution_count":null,"outputs":[]},{"metadata":{"id":"-0l_G3bkiv7a"},"cell_type":"markdown","source":"### Building Models","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing Models\nfrom sklearn.linear_model import LinearRegression              # Importing LinearRegression Algo\nfrom sklearn.tree import DecisionTreeRegressor                 # Importing DecisionTreeRegressor Algo\nfrom sklearn.ensemble import RandomForestRegressor             # Importing RandomForestRegressor Algo","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating our LinearRegression model and fitting the data into it.\nlinreg_model = LinearRegression()\nlinreg_model.fit(X_train_s, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating our DecisionTreeRegressor model and fitting the data into it.\ndt_model = DecisionTreeRegressor()\ndt_model.fit(X_train_s, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating our RandomForestRegressor model and fitting the data into it.\nrf_model=RandomForestRegressor()\nrf_model.fit(X_train_s,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Hyper Parameter Tuning \n    - To find best RandomForestRegressor Using GridSearchCV and RandomizedSearchCV","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preparations for Hyper Parameter Tuning\n\nfrom sklearn.model_selection import GridSearchCV          # Importing GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV    # Importing RandomizedSearchCV\n\nn_estimators = [10,50,100,200,300,500]                    # Number of trees in random forest\nmax_features = ['auto', 'log2',2,4,8,12]                  # Number of features to consider at every split\nmax_depth = [2,4,8,16,25]                                 # Maximum number of levels in tree=\n\n# Creating param_grid for hyper-parameter tuning.\nrandom_grid = {'n_estimators': n_estimators, 'max_features': max_features, 'max_depth': max_depth,}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating our RandomForestRegressor model from GridSearchCV and fitting the data into it.\nrf_model_grid = GridSearchCV(estimator = rf_model, param_grid=random_grid, cv = 3, n_jobs = -1 )\nrf_model_grid.fit(X_train_s,y_train)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Creating our RandomForestRegressor model from RandomizedSearchCV and fitting the data into it.\nrf_model_random = RandomizedSearchCV(estimator = rf_model, param_distributions = random_grid, \n                                     n_iter = 10, cv = 3, verbose=2, random_state=100, n_jobs = -1)\nrf_model_random.fit(X_train_s, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model Predictions","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### 1. Predictions from LinearRegression Model - linreg_model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictions from `linreg_model` - TRAIN Set\ny_train_pred_lr = linreg_model.predict(X_train_s)     # Predicted Target Values for TRAIN set.\nprint(y_train_pred_lr.shape)                          # Shape of Predicted Target Value - TRAIN set.\ny_train_pred_lr[:10]                                  # Top 10 Predicted Target Values for TRAIN set.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictions from `linreg_model` - TEST Set\ny_test_pred_lr = linreg_model.predict(X_test_s)     # Predicted Target Values for TEST set.\nprint(y_test_pred_lr.shape)                         # Shape of Predicted Target Value - TEST set.\ny_test_pred_lr[:10]                                 # Top 10 Predicted Target Values for TEST set.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2. Predictions from DecisionTreeRegressor Model - dt_model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictions from `dt_model` - TRAIN Set\ny_train_pred_dt = dt_model.predict(X_train_s)         # Predicted Target Values for TRAIN set.\nprint(y_train_pred_dt.shape)                          # Shape of Predicted Target Value - TRAIN set.\ny_train_pred_dt[:10]                                  # Top 10 Predicted Target Values for TRAIN set.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictions from `dt_model` - TEST Set\ny_test_pred_dt = dt_model.predict(X_test_s)          # Predicted Target Values for TEST set.\nprint(y_test_pred_dt.shape)                          # Shape of Predicted Target Value - TEST set.\ny_test_pred_dt[:10]                                  # Top 10 Predicted Target Values for TEST set.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3. Predictions from RandomForestRegressor Model - rf_model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictions from `rf_model` - TRAIN Set\ny_train_pred_rf = rf_model.predict(X_train_s)         # Predicted Target Values for TRAIN set.\nprint(y_train_pred_rf.shape)                          # Shape of Predicted Target Value - TRAIN set.\ny_train_pred_rf[:10]                                  # Top 10 Predicted Target Values for TRAIN set.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictions from `rf_model` - TEST Set\ny_test_pred_rf = rf_model.predict(X_test_s)          # Predicted Target Values for TEST set.\nprint(y_test_pred_rf.shape)                          # Shape of Predicted Target Value - TEST set.\ny_test_pred_rf[:10]                                  # Top 10 Predicted Target Values for TEST set.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 4. Predictions from RandomForestRegressor - GridSearchCV  - rf_model_grid","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictions from `rf_model_grid` - TRAIN Set\ny_train_pred_rf_grid = rf_model_grid.predict(X_train_s)    # Predicted Target Values for TRAIN set.\nprint(y_train_pred_rf_grid.shape)                          # Shape of Predicted Target Value - TRAIN set.\ny_train_pred_rf_grid[:10]                                  # Top 10 Predicted Target Values for TRAIN set.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictions from `rf_model_grid` - TEST Set\ny_test_pred_rf_grid = rf_model_grid.predict(X_test_s)     # Predicted Target Values for TEST set.\nprint(y_test_pred_rf_grid.shape)                          # Shape of Predicted Target Value - TEST set.\ny_test_pred_rf_grid[:10]                                  # Top 10 Predicted Target Values for TEST set.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 5. Predictions from RandomForestRegressor - RandomizedSearchCV  - rf_model_random","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictions from `rf_model_random` - TRAIN Set\ny_train_pred_rf_random = rf_model_random.predict(X_train_s)  # Predicted Target Values for TRAIN set.\nprint(y_train_pred_rf_random.shape)                          # Shape of Predicted Target Value - TRAIN set.\ny_train_pred_rf_random[:10]                                  # Top 10 Predicted Target Values for TRAIN set.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictions from `rf_model_random` - TEST Set\ny_test_pred_rf_random = rf_model_random.predict(X_test_s)     # Predicted Target Values for TEST set.\nprint(y_test_pred_rf_random.shape)                          # Shape of Predicted Target Value - TEST set.\ny_test_pred_rf_random[:10]                                  # Top 10 Predicted Target Values for TEST set.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6. Model Evaluations\n\n\n---\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Utility / Helper Function - Regression Model Evaluation\n\ndef regression_model_evaluation(y, y_pred, set_type='', features_count=None):\n    '''\n    Utility/Helper method to calulate the Evaluation parameters for a regression model\n    '''\n    from sklearn import metrics # Importing metrics from SK-Learn\n    result = {}\n    \n    if set_type != '':\n        set_type = '_'+set_type\n        \n    # Mean Absolute Error on train set.\n    result['MAE'] = metrics.mean_absolute_error(y, y_pred) \n    # Mean Squared Error on train set.\n    result['MSE'] = metrics.mean_squared_error(y, y_pred)  \n    # Root Mean Squared Error on train set.\n    result['RMSE'] = np.sqrt(result['MSE'])                      \n    # R_squared on train set.\n    result['R_squared'] = metrics.r2_score(y, y_pred)      \n    \n    # Adj r2 = 1-(1-R2)*(n-1)/(n-p-1)\n    if features_count:\n        # Adjusted R_squared on train set.\n        result['Adj_R_squared'] = 1 - (((1 - result['R_squared']) * (len(y)-features_count))/(len(y)-features_count-1))\n    # Returning with appending type to key and rounding value \n    return {f'{k}'+set_type: round(v, 4) for k, v in result.items()} ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 1. Evaluation Parameters for - linreg_model","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Evaluation metrics for LinearRegression - TRAIN set\nmetrics_lr_train = regression_model_evaluation(y_train, y_train_pred_lr, features_count=8)\nmetrics_lr_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluation metrics for LinearRegression - TEST set\nmetrics_lr_test = regression_model_evaluation(y_test, y_test_pred_lr, features_count=8)\nmetrics_lr_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting metrics map to DataFrame\nLR_Train_mertrics = pd.DataFrame(metrics_lr_train.items(), columns=['Metrics', 'LR_Train'])\nLR_Test_mertrics = pd.DataFrame(metrics_lr_test.items(), columns=['Metrics', 'LR_Test'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To get the intercept of the model.\nlinreg_model.intercept_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To get the coefficients of the model.\ncoefs = linreg_model.coef_\nfeatures = X_train_s.columns\n\nlist(zip(features,coefs))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2. Evaluation Parameters for - dt_model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluation metrics for DecisionTreeRegressor - TRAIN set\nmetrics_dt_train = regression_model_evaluation(y_train, y_train_pred_dt, features_count=8)\nmetrics_dt_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluation metrics for DecisionTreeRegressor - TEST set\nmetrics_dt_test = regression_model_evaluation(y_test, y_test_pred_dt, features_count=8)\nmetrics_dt_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting metrics map to DataFrame\nDT_Train_mertrics = pd.DataFrame(metrics_dt_train.items(), columns=['Metrics', 'DT_Train'])\nDT_Test_mertrics = pd.DataFrame(metrics_dt_test.items(), columns=['Metrics', 'DT_Test'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# DecisionTreeRegressor Score; Same as R-Squared from X and y; So it internally calculates r-squared of y and y_pred (-from X)\nprint('Train set: ',dt_model.score(X_train_s,y_train))\nprint('Test set: ',dt_model.score(X_test_s,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3. Evaluation Parameters for - rf_model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluation metrics for RandomForestRegressor - TRAIN set\nmetrics_rf_train = regression_model_evaluation(y_train, y_train_pred_rf, features_count=8)\nmetrics_rf_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluation metrics for RandomForestRegressor - TEST set\nmetrics_rf_test = regression_model_evaluation(y_test, y_test_pred_rf, features_count=8)\nmetrics_rf_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting metrics map to DataFrame\nRF_Train_mertrics = pd.DataFrame(metrics_rf_train.items(), columns=['Metrics', 'RF_Train'])\nRF_Test_mertrics = pd.DataFrame(metrics_rf_test.items(), columns=['Metrics', 'RF_Test'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# RandomForestRegressor Score; Same as R-Squared from X and y; So it internally calculates r-squared of y and y_pred (-from X)\nprint('Train set: ',rf_model.score(X_train_s,y_train))\nprint('Test set: ',rf_model.score(X_test_s,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 4. Evaluation Parameters for - rf_model_grid","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluation metrics for RandomForestRegressor with GridSearchCV - TRAIN set\nmetrics_rf_grid_train = regression_model_evaluation(y_train, y_train_pred_rf_grid, features_count=8)\nmetrics_rf_grid_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluation metrics for RandomForestRegressor with GridSearchCV - TEST set\nmetrics_rf_grid_test = regression_model_evaluation(y_test, y_test_pred_rf_grid, features_count=8)\nmetrics_rf_grid_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting metrics map to DataFrame\nRF_Grid_Train_mertrics = pd.DataFrame(metrics_rf_grid_train.items(), columns=['Metrics', 'RF_Grid_Train'])\nRF_Grid_Test_mertrics = pd.DataFrame(metrics_rf_grid_test.items(), columns=['Metrics', 'RF_Grid_Test'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 5. Evaluation Parameters for - rf_model_random","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluation metrics for RandomForestRegressor with RandomizedSearchCV - TRAIN set\nmetrics_rf_random_train = regression_model_evaluation(y_train, y_train_pred_rf_random, features_count=8)\nmetrics_rf_random_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluation metrics for RandomForestRegressor with RandomizedSearchCV - TEST set\nmetrics_rf_random_test = regression_model_evaluation(y_test, y_test_pred_rf_random, features_count=8)\nmetrics_rf_random_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting metrics map to DataFrame\nRF_Random_Train_mertrics = pd.DataFrame(metrics_rf_random_train.items(), columns=['Metrics', 'RF_Random_Train'])\nRF_Random_Test_mertrics = pd.DataFrame(metrics_rf_random_test.items(), columns=['Metrics', 'RF_Random_Test'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating DataFrames of Metrics for 5 Models","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Converting Train metrics df\nTrain_mertrics = LR_Train_mertrics.merge(\n                    DT_Train_mertrics, on='Metrics').merge(\n                    RF_Train_mertrics, on='Metrics').merge(\n                    RF_Grid_Train_mertrics, on='Metrics').merge(\n                    RF_Random_Train_mertrics, on='Metrics').set_index(keys='Metrics')\nTrain_mertrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting Train metrics df\nTest_mertrics = LR_Test_mertrics.merge(DT_Test_mertrics, on='Metrics').merge(\n                    RF_Test_mertrics, on='Metrics').merge(\n                    RF_Grid_Test_mertrics, on='Metrics').merge(\n                    RF_Random_Test_mertrics, on='Metrics').set_index(keys='Metrics')\nTest_mertrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_mertrics = Train_mertrics.merge(Test_mertrics, on='Metrics')\nmodel_mertrics = model_mertrics.reindex(\n    columns=['LR_Train', 'LR_Test', 'DT_Train', 'DT_Test', 'RF_Train', 'RF_Test', 'RF_Grid_Train', 'RF_Grid_Test', 'RF_Random_Train', 'RF_Random_Test'])\n\nmodel_mertrics","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 7. Model Plotings","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### 1. LinearRegression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_diff = pd.DataFrame({'Y_ACT':y_train , 'Y_Pred':y_train_pred_lr},columns=['Y_ACT','Y_Pred']) \ntrain_diff.head()    # Preview of DF - y_train and y_train_pred","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"test_diff = pd.DataFrame({'Y_ACT':y_test , 'Y_Pred':y_test_pred_lr},columns=['Y_ACT','Y_Pred'])\ntest_diff.head()    # Preview of DF - y_test and y_test_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, (ax1, ax2) = plt.subplots(1,2, figsize=(16,8))\nf.suptitle('Y-Actual VS Y-Predicted - LinearRegression')\nax1.set_title('Train Set', fontsize=14)\nsns.regplot(x='Y_ACT',y='Y_Pred',data=train_diff, ax=ax1)\nax2.set_title('Test Set', fontsize=14)\nsns.regplot(x='Y_ACT',y='Y_Pred',data=test_diff, ax=ax2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2. DecisionTreeRegressor","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_diff = pd.DataFrame({'Y_ACT':y_train , 'Y_Pred':y_train_pred_dt},columns=['Y_ACT','Y_Pred'])\ntrain_diff.head() # Preview of DF - y_train and y_train_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_diff = pd.DataFrame({'Y_ACT':y_test , 'Y_Pred':y_test_pred_dt},columns=['Y_ACT','Y_Pred'])\ntest_diff.head()   # Preview of DF - y_test and y_test_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, (ax1, ax2) = plt.subplots(1,2, figsize=(16,8))\nf.suptitle('Y-Actual VS Y-Predicted - DecisionTreeRegressor')\nax1.set_title('Train Set', fontsize=14)\nsns.regplot(x='Y_ACT',y='Y_Pred',data=train_diff, ax=ax1)\nax2.set_title('Test Set', fontsize=14)\nsns.regplot(x='Y_ACT',y='Y_Pred',data=test_diff, ax=ax2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3. RandomForestRegressor","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_diff = pd.DataFrame({'Y_ACT':y_train , 'Y_Pred':y_train_pred_rf},columns=['Y_ACT','Y_Pred'])\ntrain_diff.head() # Preview of DF - y_train and y_train_pred","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"test_diff = pd.DataFrame({'Y_ACT':y_test , 'Y_Pred':y_test_pred_rf},columns=['Y_ACT','Y_Pred'])\ntest_diff.head()   # Preview of DF - y_test and y_test_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, (ax1, ax2) = plt.subplots(1,2, figsize=(16,8))\nf.suptitle('Y-Actual VS Y-Predicted - RandomForestRegressor')\nax1.set_title('Train Set', fontsize=14)\nsns.regplot(x='Y_ACT',y='Y_Pred',data=train_diff, ax=ax1)\nax2.set_title('Test Set', fontsize=14)\nsns.regplot(x='Y_ACT',y='Y_Pred',data=test_diff, ax=ax2)","execution_count":null,"outputs":[]},{"metadata":{"id":"TUT7QpPNjdrO"},"cell_type":"markdown","source":"#### 4. RandomForestRegressor - GridSearchCV","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_diff = pd.DataFrame({'Y_ACT':y_train , 'Y_Pred':y_train_pred_rf_grid},columns=['Y_ACT','Y_Pred'])\ntrain_diff.head() # Preview of DF - y_train and y_train_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_diff = pd.DataFrame({'Y_ACT':y_test , 'Y_Pred':y_test_pred_rf_grid},columns=['Y_ACT','Y_Pred'])\ntest_diff.head()  # Preview of DF - y_test and y_test_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, (ax1, ax2) = plt.subplots(1,2, figsize=(16,8))\nf.suptitle('Y-Actual VS Y-Predicted - RandomForestRegressor With GridSearchCV')\nax1.set_title('Train Set', fontsize=14)\nsns.regplot(x='Y_ACT',y='Y_Pred',data=train_diff, ax=ax1)\nax2.set_title('Test Set', fontsize=14)\nsns.regplot(x='Y_ACT',y='Y_Pred',data=test_diff, ax=ax2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 5. RandomForestRegressor - RandomizedSearchCV","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_diff = pd.DataFrame({'Y_ACT':y_train , 'Y_Pred':y_train_pred_rf_random},columns=['Y_ACT','Y_Pred'])\ntrain_diff.head() # Preview of DF - y_train and y_train_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_diff = pd.DataFrame({'Y_ACT':y_test , 'Y_Pred':y_test_pred_rf_random},columns=['Y_ACT','Y_Pred'])\ntest_diff.head() # Preview of DF - y_test and y_test_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, (ax1, ax2) = plt.subplots(1,2, figsize=(16,8))\nf.suptitle('Y-Actual VS Y-Predicted - RandomForestRegressor With RandomizedSearchCV')\nax1.set_title('Train Set', fontsize=14)\nsns.regplot(x='Y_ACT',y='Y_Pred',data=train_diff, ax=ax1)\nax2.set_title('Test Set', fontsize=14)\nsns.regplot(x='Y_ACT',y='Y_Pred',data=test_diff, ax=ax2)","execution_count":null,"outputs":[]},{"metadata":{"id":"ClHqqx7-UfHI"},"cell_type":"markdown","source":"## 8. Conclusions\n\n---\n\n\n  - Analyzing and finalizing best-fit model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model_mertrics # Preview of Model Evaluation Metrics","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above table we can observe,\n1. LinearRegression Model has lease R-Squared Value - **UnderFit Model**\n2. DecisionTreeRegressor Model has maximum R-Squared Value for train data and less R-Squared Value for test data - **OverFit Model**\n3. RandomForestRegressor Model has better R-Squared Value for test data\n4. We can best version of RandomForestRegressor by *hyper parameter tuning* with GridSearchCV or RandomizedSearchCV","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}