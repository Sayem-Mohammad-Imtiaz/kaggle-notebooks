{"cells":[{"metadata":{},"cell_type":"markdown","source":"<b>This dataset contains information about used cars listed on www.cardekho.com\nThis data can be used for a lot of purposes such as price prediction to exemplify the use of linear regression in Machine Learning.</b> \n\nThe columns in the given dataset is as follows:\n<ol>\n    <li> Car_Name </li>\n    <li> Year </li>\n    <li> Selling_Price </li>\n    <li> Present_Price </li>\n    <li> Kms_Driven </li>\n    <li> Fuel_Type </li>\n    <li> Seller_Type </li>\n    <li> Transmission </li>\n    <li> Owner </li>\n</ol>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Importing Dependencies ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Importing Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/vehicle-dataset-from-cardekho/car data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,12))\nsns.heatmap(df.corr(), cmap='Blues', annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploring Categorical Features ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_features = [col for col in df.columns if df[col].dtypes == 'O']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in categorical_features:\n    print(col, df[col].nunique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_values = []\nfor col in categorical_features:\n    unique_values.append(df[col].nunique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_style(\"white\")\nsns.barplot(unique_values, categorical_features, orient='h')\nplt.title('Unique values of each Categorical values')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=3.7 color='#1b6ca8'>Here, Car_Name feature has **98** unique values so converting them into one hot encoding is not a very good idea. And also Car_Name is not much beneficial for predictions. So, we are dropping that column.</font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['Car_Name'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_features = [col for col in df.columns if df[col].dtypes == 'O']\ncategorical_features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=4>Splitting the data into independent and dependent features.\n</font>\n\nHere,\n\n**Dependent Feature** - <font color='#ff9234'>'Selling_Price'</font>\n\n**Independent Features** - <font color='#ff9234'>'Year', 'Present_Price', 'Kms_Driven', 'Fuel_Type','Seller_Type', 'Transmission', 'Owner'</font> ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop(['Selling_Price'], axis=1)\ny = df['Selling_Price']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X.shape)\nprint(y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=3.7 color='#1b6ca8'>Exploring Unique values of each Categorical values</font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in categorical_features:\n    print(col, X[col].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## OneHotEncoding ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pd.get_dummies(X, drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=3.7 color='#1b6ca8'>Converting Year column into (How Old the Car is?) by subtracting Year column from Current Year</font> ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X['Current_Year'] = 2020\nX['Number_of_years'] = X['Current_Year'] - X['Year']\nX.drop(['Current_Year', 'Year'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating Models ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"###  1. RandomForestRegressor","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.ensemble import RandomForestRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = RandomForestRegressor()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=3.7 color='#1b6ca8'>Performing RandomizedSearchCV</font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n\nmax_features = ['auto', 'sqrt']\n\nmax_depth = [int(x) for x in np.linspace(5, 30, num = 6)]\n\nmin_samples_split = [2, 5, 10, 15, 100]\n\nmin_samples_leaf = [1, 2, 5, 10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomizedSearchCV(estimator = model, \n                               param_distributions = random_grid,\n                               scoring='neg_mean_squared_error', \n                               n_iter = 10, cv = 5, verbose=2, \n                               random_state=42, n_jobs = 1)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fitting the Training data ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rf.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = rf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\n\nprint('MAE:',round(metrics.mean_absolute_error(y_test, predictions),2))\nprint('MSE:',round(metrics.mean_squared_error(y_test, predictions),2))\nprint('RMSE:',round(np.sqrt(metrics.mean_squared_error(y_test, predictions)),2))\nprint('R2_score',round(metrics.r2_score(y_test, predictions),2))\nRandom_Forest_Regressor = { 'MAE': round(metrics.mean_absolute_error(y_test, predictions),2), 'MSE': round(metrics.mean_squared_error(y_test, predictions),2), \n                      'RMSE': round(np.sqrt(metrics.mean_squared_error(y_test, predictions)),2) , 'R2_score':round(metrics.r2_score(y_test, predictions),2)}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nsns.scatterplot(y_test, predictions)\nplt.xlabel('y_test')\nplt.ylabel('Predictions')\nplt.title('y_test vs Predictions (RandomForestRegressor)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. DecisionTreeRegressor","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree = DecisionTreeRegressor()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = tree.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('MAE:',round(metrics.mean_absolute_error(y_test, predictions),2))\nprint('MSE:',round(metrics.mean_squared_error(y_test, predictions),2))\nprint('RMSE:',round(np.sqrt(metrics.mean_squared_error(y_test, predictions)),2))\nprint('R2_score',round(metrics.r2_score(y_test, predictions),2))\n\nDecision_Tree_Regressor = { 'MAE': round(metrics.mean_absolute_error(y_test, predictions),2), 'MSE': round(metrics.mean_squared_error(y_test, predictions),2), \n                      'RMSE': round(np.sqrt(metrics.mean_squared_error(y_test, predictions)),2) , 'R2_score':round(metrics.r2_score(y_test, predictions),2)}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nsns.scatterplot(y_test, predictions)\nplt.xlabel('y_test')\nplt.ylabel('Predictions')\nplt.title('y_test vs Predictions (DecisionTreeRegressor)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. LinearRegression ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LR = LinearRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LR.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = tree.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('MAE:',round(metrics.mean_absolute_error(y_test, predictions),2))\nprint('MSE:',round(metrics.mean_squared_error(y_test, predictions),2))\nprint('RMSE:',round(np.sqrt(metrics.mean_squared_error(y_test, predictions)),2))\nprint('R2_score',round(metrics.r2_score(y_test, predictions),2))\n\nLinear_Regression = { 'MAE': round(metrics.mean_absolute_error(y_test, predictions),2), 'MSE': round(metrics.mean_squared_error(y_test, predictions),2), \n                      'RMSE': round(np.sqrt(metrics.mean_squared_error(y_test, predictions)),2) , 'R2_score':round(metrics.r2_score(y_test, predictions),2)}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nsns.scatterplot(y_test, predictions)\n\nplt.xlabel('y_test')\nplt.ylabel('Predictions')\nplt.title('y_test vs Predictions (LinearRegression)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tomark import Tomark\n\ndata = [Random_Forest_Regressor, Decision_Tree_Regressor, Linear_Regression]\n\nmarkdown = Tomark.table(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Final Result ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"|Model| MAE | MSE | RMSE | R2_score |\n|-----|-----|-----|-----|-----|\n|RandomForestRegressor| 0.83 | 2.92 | 1.71 | 0.89 |\n|DecisionTreeRegressor| 0.74 | 1.24 | 1.11 | 0.95 |\n|LinearRegression| 0.74 | 1.24 | 1.11 | 0.95 |\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}