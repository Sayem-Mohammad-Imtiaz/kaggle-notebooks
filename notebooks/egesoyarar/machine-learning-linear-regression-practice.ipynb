{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/biomechanical-features-of-orthopedic-patients/column_2C_weka.csv\")\n\nanormality = data[data[\"class\"] == \"Abnormal\"]\n\nx = np.array(anormality.loc[:,'pelvic_incidence']).reshape(-1,1)\ny = np.array(anormality.loc[:,'sacral_slope']).reshape(-1,1)\n\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reading data from target file and naming as data.\nNaming the data which are called \"Abnormal\" in anormality and, x and y stand for our features. "},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If we take a look to our output, we can observe that we have 210 range and float64 datatyped data."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Describe function helps us to make our data meaningful. Without plotting, we can understand the data thanks to those significant numbers."},{"metadata":{"trusted":true},"cell_type":"code","source":"color_list = ['red' if i=='Abnormal' else 'green' for i in data.loc[:,'class']]\npd.plotting.scatter_matrix(data.loc[:, data.columns != 'class'],\n                                       c=color_list,\n                                       figsize= [15,15],\n                                       diagonal='hist',\n                                       alpha=0.5,\n                                       s = 200,\n                                       marker = '*',\n                                       edgecolor= \"black\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"red stars show \"Abnormal\" patients and greens show \"Normal\" ones.\npd.plotting.scatter_matrix:\n\n* green: normal and red: abnormal\n* c: color\n* figsize: figure size\n* diagonal: histohram of each features\n* alpha: opacity\n* s: size of marker\n* marker: marker type"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=\"class\", data=data)\ndata.loc[:,'class'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Countplot function design a bar chart for illustrating \"class\" which is included in seaborn library.\nvalue_counts, show the numeric value of \"class\" data."},{"metadata":{},"cell_type":"markdown","source":"**REGRESSION**\n* Supervised learning\n* We will use linear regression and polynomial regression.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=[10,10])\nplt.scatter(x=x,y=y)\nplt.xlabel('pelvic_incidence')\nplt.ylabel('sacral_slope')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Linear Regression**\nAfter visualizing our data in a plot, we can move on to make linear regression."},{"metadata":{},"cell_type":"markdown","source":"Score: Score uses R^2 method that is ((y_pred - y_mean)^2 )/(y_actual - y_mean)^2"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\nlinear_reg = LinearRegression()\n\nlinear_reg.fit(x,y)\n\npredict_space = np.linspace(min(x), max(x)).reshape(-1,1)\n\nprediction = linear_reg.predict(x)\n\nprint('R^2 score: ',linear_reg.score(x, y))\n# Plot regression line and scatter\nplt.plot(x, prediction, color='black', linewidth=3)\nplt.scatter(x,y)\nplt.xlabel('pelvic_incidence')\nplt.ylabel('sacral_slope')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Polynomial Regression**\n* To make our regression polynomial we demand help from PolynomialFeatures in sklearn.preprocessing.\n* In this method, our most crucial parameter is degree (n). Polynomial functions are formulized as y =b0 + b1*x + b2*x^2 + .. +bn*x^n . When n increases, we will get more complicated function. To be more obvious, it has both advantages and disadvantages. It does not mean that more degree, more reliable."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import PolynomialFeatures\npolynomial_regression = PolynomialFeatures(degree = 3) #degree increases reliability\n\nx_poly = polynomial_regression.fit_transform(x) \n\nlinear_regression2 = LinearRegression()\nlinear_regression2.fit(x_poly,y)\n\n\nprediction_poly = linear_regression2.predict(x_poly)\nplt.scatter(x,y)\nplt.plot(x,prediction_poly,color=\"green\",label = \"poly\")\nplt.legend()\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see, our 3rd degree polynom is not appropriately fitted. That means we cannot find a correlation between x_poly and prediction_poly in polynomial regression."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}