{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-23T11:33:10.315122Z","iopub.execute_input":"2021-09-23T11:33:10.316399Z","iopub.status.idle":"2021-09-23T11:33:10.359103Z","shell.execute_reply.started":"2021-09-23T11:33:10.316259Z","shell.execute_reply":"2021-09-23T11:33:10.357872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import the necessary library\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport re\nimport string\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom collections import Counter\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nimport pickle\nfrom sklearn.model_selection import validation_curve\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import ShuffleSplit\nfrom itertools import chain","metadata":{"execution":{"iopub.status.busy":"2021-09-23T11:34:16.941531Z","iopub.execute_input":"2021-09-23T11:34:16.942604Z","iopub.status.idle":"2021-09-23T11:34:19.114211Z","shell.execute_reply.started":"2021-09-23T11:34:16.942563Z","shell.execute_reply":"2021-09-23T11:34:19.113113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_review = pd.read_csv('/kaggle/input/amazon-music-reviews/Musical_instruments_reviews.csv')\ndf_review.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T11:35:38.595278Z","iopub.execute_input":"2021-09-23T11:35:38.595645Z","iopub.status.idle":"2021-09-23T11:35:38.845298Z","shell.execute_reply.started":"2021-09-23T11:35:38.595606Z","shell.execute_reply":"2021-09-23T11:35:38.844401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* You have to categorise opinions expressed in feedback forums","metadata":{}},{"cell_type":"code","source":"# review the head of dataset\ndf_review.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T11:36:21.171325Z","iopub.execute_input":"2021-09-23T11:36:21.172184Z","iopub.status.idle":"2021-09-23T11:36:21.189596Z","shell.execute_reply.started":"2021-09-23T11:36:21.172141Z","shell.execute_reply":"2021-09-23T11:36:21.189004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking the scale of overall rating\nprint('Maximum rating scale of overall rating {}'.format(df_review.overall.max()))\nprint('Minimum rating scale of overall rating {}'.format(df_review.overall.min()))","metadata":{"execution":{"iopub.status.busy":"2021-09-23T11:36:33.063355Z","iopub.execute_input":"2021-09-23T11:36:33.064236Z","iopub.status.idle":"2021-09-23T11:36:33.074621Z","shell.execute_reply.started":"2021-09-23T11:36:33.06419Z","shell.execute_reply":"2021-09-23T11:36:33.073888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **NOTE:We should the categorize the opnion of the feedback based on the overall rating because overall rating indicate that how much customers are satisfied from that product. <br>**\n\n* Rating and there General Meaning are follows <br>\n<pre>\n    Rating            General Meaning\n    1.0               I hate it.\n    2.0               I don't like it.\n    3.0               It's okey.\n    4.0               I like it.\n    5.0               I love it.\n</pre>\n\n","metadata":{}},{"cell_type":"code","source":"# defing the function for adding the category for the feedback\ndef add_category(df):\n\n  if df['overall']==1.0:\n    return \"I hate it\"\n  elif df['overall']==2.0:\n    return \"I don't like it\"\n  elif df['overall'] == 3.0:\n    return \"It's okey\"\n  elif df['overall'] == 4.0:\n    return \"I like it\"\n  elif df['overall'] == 5.0:\n    return \"I love it\"\n  else:\n    return -1\n","metadata":{"execution":{"iopub.status.busy":"2021-09-23T11:37:19.179564Z","iopub.execute_input":"2021-09-23T11:37:19.180673Z","iopub.status.idle":"2021-09-23T11:37:19.186371Z","shell.execute_reply.started":"2021-09-23T11:37:19.180631Z","shell.execute_reply":"2021-09-23T11:37:19.185733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# adding the category in dataframe\ndf_review['category'] = df_review.apply(add_category, axis=1)\nplt.figure(figsize=(6,6))\nplt.title('Percentage of category')\nax = sns.countplot(y = 'category', data = df_review)\ntotal = len(df_review)\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()/2\n        ax.annotate(percentage, (x, y))\n","metadata":{"execution":{"iopub.status.busy":"2021-09-23T11:37:30.691361Z","iopub.execute_input":"2021-09-23T11:37:30.692404Z","iopub.status.idle":"2021-09-23T11:37:31.306235Z","shell.execute_reply.started":"2021-09-23T11:37:30.692359Z","shell.execute_reply":"2021-09-23T11:37:31.305132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"+ **We can see the above graph**<br>\n<pre>\n  67.6% customers love the product.\n  7.5% customers it's okey.\n  20.3% customers like the product.\n  2.4% customres don't like the product.\n  2.1% customers hate the product.\n</pre>","metadata":{}},{"cell_type":"markdown","source":"+ You have to classify individual comments/reviews and you have to determine overall rating based on individual comments/reviews.","metadata":{}},{"cell_type":"code","source":"df_review.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T11:38:25.123505Z","iopub.execute_input":"2021-09-23T11:38:25.124529Z","iopub.status.idle":"2021-09-23T11:38:25.14598Z","shell.execute_reply.started":"2021-09-23T11:38:25.124475Z","shell.execute_reply":"2021-09-23T11:38:25.144847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking the total number of nan values of each features\ndf_review.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T11:38:38.139104Z","iopub.execute_input":"2021-09-23T11:38:38.139997Z","iopub.status.idle":"2021-09-23T11:38:38.161497Z","shell.execute_reply.started":"2021-09-23T11:38:38.139936Z","shell.execute_reply":"2021-09-23T11:38:38.160411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"+ We can see the above only to two features has nan values reviewerName and reviewText respectively.\n+ we can reviewText row whose values is nan because this is an important features. Curruently imput with missing string.","metadata":{}},{"cell_type":"code","source":"# imputing the reviewText features with missing \ndf_review['reviewText'] = df_review.reviewText.fillna('missing')\n\n# concating the reviewText and summary features\ndf_review['review']= df_review['reviewText'] +\" \"+ df_review['summary']\n\n# deleting the summary column\ndf_review.drop(['summary','reviewText'], inplace=True, axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-23T11:39:06.495575Z","iopub.execute_input":"2021-09-23T11:39:06.495877Z","iopub.status.idle":"2021-09-23T11:39:06.522655Z","shell.execute_reply.started":"2021-09-23T11:39:06.495849Z","shell.execute_reply":"2021-09-23T11:39:06.521782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_review.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T11:39:17.651411Z","iopub.execute_input":"2021-09-23T11:39:17.651785Z","iopub.status.idle":"2021-09-23T11:39:17.670237Z","shell.execute_reply.started":"2021-09-23T11:39:17.651749Z","shell.execute_reply":"2021-09-23T11:39:17.669205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Our goal is predict the overall rating based on the comment/ review\n* so review/comment is input feature and overall rating is the label\n* This problem is mutliclass classification problem","metadata":{}},{"cell_type":"code","source":"# create a dataframe that has only reviewText and overall rating\ndf = df_review[['review', 'overall']].copy()\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T11:39:54.275703Z","iopub.execute_input":"2021-09-23T11:39:54.276059Z","iopub.status.idle":"2021-09-23T11:39:54.291479Z","shell.execute_reply.started":"2021-09-23T11:39:54.276029Z","shell.execute_reply":"2021-09-23T11:39:54.290426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Text Preprocessing","metadata":{}},{"cell_type":"code","source":"# defing the funtion for remoing the punctuation\ndef clean(text):\n\n  # converting the all the text into lowercase\n  text = str(text).lower()\n  text = re.sub('\\[.*?\\]', '', text)\n  text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n  text = re.sub('<.*?>+', '', text)\n  text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n  text = re.sub('\\n', '', text)\n  text = re.sub('\\w*\\d\\w*', '', text)\n  return text","metadata":{"execution":{"iopub.status.busy":"2021-09-23T11:40:24.967841Z","iopub.execute_input":"2021-09-23T11:40:24.968124Z","iopub.status.idle":"2021-09-23T11:40:24.976339Z","shell.execute_reply.started":"2021-09-23T11:40:24.968096Z","shell.execute_reply":"2021-09-23T11:40:24.975596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# apply the clean function on dataframe\ndf['review'] = df.review.apply(lambda x: clean(x))\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T11:40:35.875635Z","iopub.execute_input":"2021-09-23T11:40:35.876559Z","iopub.status.idle":"2021-09-23T11:40:37.339931Z","shell.execute_reply.started":"2021-09-23T11:40:35.876516Z","shell.execute_reply":"2021-09-23T11:40:37.339061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nltk.download('stopwords')","metadata":{"execution":{"iopub.status.busy":"2021-09-23T11:40:46.411356Z","iopub.execute_input":"2021-09-23T11:40:46.411987Z","iopub.status.idle":"2021-09-23T11:40:46.690176Z","shell.execute_reply.started":"2021-09-23T11:40:46.411937Z","shell.execute_reply":"2021-09-23T11:40:46.689156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove the stop_words from the reivew\ndf['review']= df.review.apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords.words('english')]))\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T11:40:58.146938Z","iopub.execute_input":"2021-09-23T11:40:58.14781Z","iopub.status.idle":"2021-09-23T11:42:56.724497Z","shell.execute_reply.started":"2021-09-23T11:40:58.147764Z","shell.execute_reply":"2021-09-23T11:42:56.723656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nltk.download('wordnet')","metadata":{"execution":{"iopub.status.busy":"2021-09-23T11:42:56.726104Z","iopub.execute_input":"2021-09-23T11:42:56.726351Z","iopub.status.idle":"2021-09-23T11:42:56.802942Z","shell.execute_reply.started":"2021-09-23T11:42:56.726323Z","shell.execute_reply":"2021-09-23T11:42:56.802348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# conveting the words into the root words using the WordNetLemmatizer\nlemmatizer = WordNetLemmatizer()\ndf['review'] = df.review.apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T11:42:56.804086Z","iopub.execute_input":"2021-09-23T11:42:56.804452Z","iopub.status.idle":"2021-09-23T11:43:01.750619Z","shell.execute_reply.started":"2021-09-23T11:42:56.804408Z","shell.execute_reply":"2021-09-23T11:43:01.749937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# converting the words into base words using stemming method\nps = PorterStemmer()\ndf['review']= df.review.apply(lambda x: ' '.join([ps.stem(word) for word in x.split()]))\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T11:43:01.752528Z","iopub.execute_input":"2021-09-23T11:43:01.75293Z","iopub.status.idle":"2021-09-23T11:43:16.702503Z","shell.execute_reply.started":"2021-09-23T11:43:01.752882Z","shell.execute_reply":"2021-09-23T11:43:16.701612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# featuers extraction most 5000 best features from the all featues with 1 to 3 gram using TF-IDF\ntfidf = TfidfVectorizer(max_features=5000, ngram_range=(1,3))\nx = tfidf.fit_transform(df['review'])","metadata":{"execution":{"iopub.status.busy":"2021-09-23T11:43:16.70382Z","iopub.execute_input":"2021-09-23T11:43:16.704241Z","iopub.status.idle":"2021-09-23T11:43:22.109635Z","shell.execute_reply.started":"2021-09-23T11:43:16.704206Z","shell.execute_reply":"2021-09-23T11:43:22.108867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# label of featuere\ny = df['overall']\nprint('Origonal no samples of each ratting {}'.format(Counter(y)))\nprint('original shape of the input features {}'.format(x.shape))\nprint('origonal shape of the output features {}'.format(y.shape))","metadata":{"execution":{"iopub.status.busy":"2021-09-23T11:43:22.111185Z","iopub.execute_input":"2021-09-23T11:43:22.111423Z","iopub.status.idle":"2021-09-23T11:43:22.121038Z","shell.execute_reply.started":"2021-09-23T11:43:22.111399Z","shell.execute_reply":"2021-09-23T11:43:22.120023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"+ we can easly see that five classess has different number of samples so we need to handle this\n+ we are using the over_sampling technique to handle the imbalance dataset","metadata":{}},{"cell_type":"code","source":"# create the SMOTE over_sampling technique object and fit_resample the features\nsm = SMOTE()\nx_res, y_res = sm.fit_resample(x, y)\nprint('Before sampling the  shape of dataset {}'.format(Counter(y)))\nprint('After sampling the shape of dataset {}'.format(Counter(y_res)))","metadata":{"execution":{"iopub.status.busy":"2021-09-23T11:43:22.122528Z","iopub.execute_input":"2021-09-23T11:43:22.123199Z","iopub.status.idle":"2021-09-23T11:43:22.608428Z","shell.execute_reply.started":"2021-09-23T11:43:22.123164Z","shell.execute_reply":"2021-09-23T11:43:22.607312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create the test and train set\nx_train, x_test, y_train, y_test = train_test_split(x_res, y_res, random_state=0, test_size=0.25)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T11:43:22.610017Z","iopub.execute_input":"2021-09-23T11:43:22.610293Z","iopub.status.idle":"2021-09-23T11:43:22.637363Z","shell.execute_reply.started":"2021-09-23T11:43:22.610262Z","shell.execute_reply":"2021-09-23T11:43:22.636431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model selection\n# cross validation score\ndef cross_validation(model,x,y):\n\n  cross_value_scored = []\n  for model in models:\n      model_name = model.__class__.__name__\n      accuracies= cross_val_score(model, x, y, scoring = 'accuracy', cv = 5)\n      for accuracy in accuracies:\n          cross_value_scored.append((model_name, accuracy))\n  df_cv = pd.DataFrame(cross_value_scored, columns =['model_name', 'accuracy'])\n  acc = pd.concat([df_cv.groupby('model_name').accuracy.mean(),df_cv.groupby('model_name').accuracy.std()], axis= 1,ignore_index=True)\n  acc.columns = ['Mean Accuracy', 'Standard deviation']\n  return acc","metadata":{"execution":{"iopub.status.busy":"2021-09-23T11:43:22.638979Z","iopub.execute_input":"2021-09-23T11:43:22.63922Z","iopub.status.idle":"2021-09-23T11:43:22.649935Z","shell.execute_reply.started":"2021-09-23T11:43:22.639193Z","shell.execute_reply":"2021-09-23T11:43:22.648789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define all the models\nmodels = [\n    RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0),\n    XGBClassifier(),\n    LinearSVC(),\n    BernoulliNB(),\n    KNeighborsClassifier()\n    \n]\n# calling the cross_validation function\ncross_validation(models, x_res, y_res)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T11:43:22.653122Z","iopub.execute_input":"2021-09-23T11:43:22.653393Z","iopub.status.idle":"2021-09-23T12:03:40.57598Z","shell.execute_reply.started":"2021-09-23T11:43:22.653364Z","shell.execute_reply":"2021-09-23T12:03:40.574849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training the model and predict \ndef train_predict_final_model(x_train, y_train, x_test):\n  svc = LinearSVC(C=100.0, random_state=0)\n  svc.fit(x_train, y_train)\n  return svc, svc.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T12:03:40.577641Z","iopub.execute_input":"2021-09-23T12:03:40.577968Z","iopub.status.idle":"2021-09-23T12:03:40.583432Z","shell.execute_reply.started":"2021-09-23T12:03:40.577938Z","shell.execute_reply":"2021-09-23T12:03:40.582462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# call the train_predict_final_model\nmodel, y_pred = train_predict_final_model(x_train, y_train, x_test)\nprint('Accuracy of the model {}'.format(accuracy_score(y_test, y_pred)))","metadata":{"execution":{"iopub.status.busy":"2021-09-23T12:03:40.586144Z","iopub.execute_input":"2021-09-23T12:03:40.586625Z","iopub.status.idle":"2021-09-23T12:04:03.322019Z","shell.execute_reply.started":"2021-09-23T12:03:40.586585Z","shell.execute_reply":"2021-09-23T12:04:03.321415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"+ Validate your build model, use any of your choice of validation matrices","metadata":{}},{"cell_type":"code","source":"# plot the confusion matrix\ndef confusion_matrix_plot(y_test, y_pred):\n  cm = confusion_matrix(y_test, y_pred)\n  fig, ax = plt.subplots(figsize=(8,8))\n  sns.heatmap(cm, annot=True, cmap = 'Reds',square = True,xticklabels = [1,2,3,4,5],yticklabels=[1,2,3,4,5])\n  plt.ylabel('Actual')\n  plt.xlabel('Predicted')\n  plt.title('Confusion Matrix.')\n\n# calling the confusion_matrix_plot function\nconfusion_matrix_plot(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T12:04:03.323193Z","iopub.execute_input":"2021-09-23T12:04:03.323538Z","iopub.status.idle":"2021-09-23T12:04:03.738672Z","shell.execute_reply.started":"2021-09-23T12:04:03.323509Z","shell.execute_reply":"2021-09-23T12:04:03.737763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Accuracy of the model {}'.format(accuracy_score(y_test, y_pred)))","metadata":{"execution":{"iopub.status.busy":"2021-09-23T12:04:03.739969Z","iopub.execute_input":"2021-09-23T12:04:03.740217Z","iopub.status.idle":"2021-09-23T12:04:03.746752Z","shell.execute_reply.started":"2021-09-23T12:04:03.740181Z","shell.execute_reply":"2021-09-23T12:04:03.745837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# report of the model\nprint('Report of the model {}'.format(classification_report(y_test, y_pred)))","metadata":{"execution":{"iopub.status.busy":"2021-09-23T12:04:03.748085Z","iopub.execute_input":"2021-09-23T12:04:03.748378Z","iopub.status.idle":"2021-09-23T12:04:03.787254Z","shell.execute_reply.started":"2021-09-23T12:04:03.748349Z","shell.execute_reply":"2021-09-23T12:04:03.786389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ploting the learning curver\ndef plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None,n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n   \n       \n    if axes is None:\n        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n\n    axes[0].set_title(title)\n    if ylim is not None:\n        axes[0].set_ylim(*ylim)\n    axes[0].set_xlabel(\"Training examples\")\n    axes[0].set_ylabel(\"Score\")\n\n    train_sizes, train_scores, test_scores, fit_times, _ = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,train_sizes=train_sizes,return_times=True)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    fit_times_mean = np.mean(fit_times, axis=1)\n    fit_times_std = np.std(fit_times, axis=1)\n\n    # Plot learning curve\n    axes[0].grid()\n    axes[0].fill_between(train_sizes, train_scores_mean - train_scores_std,train_scores_mean + train_scores_std, alpha=0.1,color=\"r\")\n    axes[0].fill_between(train_sizes, test_scores_mean - test_scores_std,test_scores_mean + test_scores_std, alpha=0.1,color=\"g\")\n    axes[0].plot(train_sizes, train_scores_mean, 'o-', color=\"r\",label=\"Training score\")\n    axes[0].plot(train_sizes, test_scores_mean, 'o-', color=\"g\",label=\"Cross-validation score\")\n    axes[0].legend(loc=\"best\")\n\n    # Plot n_samples vs fit_times\n    axes[1].grid()\n    axes[1].plot(train_sizes, fit_times_mean, 'o-')\n    axes[1].fill_between(train_sizes, fit_times_mean - fit_times_std,fit_times_mean + fit_times_std, alpha=0.1)\n    axes[1].set_xlabel(\"Training examples\")\n    axes[1].set_ylabel(\"fit_times\")\n    axes[1].set_title(\"Scalability of the model\")\n\n    # Plot fit_time vs score\n    axes[2].grid()\n    axes[2].plot(fit_times_mean, test_scores_mean, 'o-')\n    axes[2].fill_between(fit_times_mean, test_scores_mean - test_scores_std,test_scores_mean + test_scores_std, alpha=0.1)\n    axes[2].set_xlabel(\"fit_times\")\n    axes[2].set_ylabel(\"Score\")\n    axes[2].set_title(\"Performance of the model\")\n\n    return plt","metadata":{"execution":{"iopub.status.busy":"2021-09-23T12:04:03.788364Z","iopub.execute_input":"2021-09-23T12:04:03.788595Z","iopub.status.idle":"2021-09-23T12:04:03.807171Z","shell.execute_reply.started":"2021-09-23T12:04:03.788568Z","shell.execute_reply":"2021-09-23T12:04:03.80578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"title = 'Learning curve of LinearSVC'\ncv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\nestimator = LinearSVC(C=100.0)\nplot_learning_curve(estimator, title, x_res, y_res,  ylim=(0.7, 1.01),cv=cv, n_jobs=4)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T12:04:03.809815Z","iopub.execute_input":"2021-09-23T12:04:03.810085Z","iopub.status.idle":"2021-09-23T12:45:13.277671Z","shell.execute_reply.started":"2021-09-23T12:04:03.810056Z","shell.execute_reply":"2021-09-23T12:45:13.276559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Perform an Exploratory Data Analysis for the Text Data (Reviews) and help the organisation to understand better about their customer feedbacks.","metadata":{}},{"cell_type":"code","source":"# rating of the insturiments\nplt.figure(figsize=(6,6))\nplt.title('Rating of the Musical Instruments')\nax = sns.countplot(y = 'overall', data = df_review)\ntotal = len(df_review)\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()/2\n        ax.annotate(percentage, (x, y))","metadata":{"execution":{"iopub.status.busy":"2021-09-23T12:45:13.279601Z","iopub.execute_input":"2021-09-23T12:45:13.279914Z","iopub.status.idle":"2021-09-23T12:45:13.548883Z","shell.execute_reply.started":"2021-09-23T12:45:13.279878Z","shell.execute_reply":"2021-09-23T12:45:13.547679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_words = df.review.values\nnegtive_words= df[df.overall <= 2.0]['review'].values\npositive_words = df[df.overall >= 4.0]['review'].values","metadata":{"execution":{"iopub.status.busy":"2021-09-23T12:45:13.55087Z","iopub.execute_input":"2021-09-23T12:45:13.551158Z","iopub.status.idle":"2021-09-23T12:45:13.56496Z","shell.execute_reply.started":"2021-09-23T12:45:13.551128Z","shell.execute_reply":"2021-09-23T12:45:13.563812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# conert string of list to word of list\ndef string_to_word(words):\n  word = []\n  for w in words:\n    word.append(w.split())\n  return word","metadata":{"execution":{"iopub.status.busy":"2021-09-23T12:45:13.566698Z","iopub.execute_input":"2021-09-23T12:45:13.567675Z","iopub.status.idle":"2021-09-23T12:45:13.577157Z","shell.execute_reply.started":"2021-09-23T12:45:13.567623Z","shell.execute_reply":"2021-09-23T12:45:13.576061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 10 most frequnt words\ndef most_frequent(word, title):\n  word = string_to_word(word)\n  word = list(chain.from_iterable(word))\n  word = Counter(word)\n  freq_words = word.most_common(10)\n\n  y = [x[0] for x in freq_words]\n  x = [x[1] for x in freq_words]\n  plt.title(title)\n  plt.bar(y, x)\n  plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T12:45:13.580263Z","iopub.execute_input":"2021-09-23T12:45:13.580534Z","iopub.status.idle":"2021-09-23T12:45:13.591729Z","shell.execute_reply.started":"2021-09-23T12:45:13.580506Z","shell.execute_reply":"2021-09-23T12:45:13.59054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"most_frequent(all_words, '10 Most frequent words')","metadata":{"execution":{"iopub.status.busy":"2021-09-23T12:45:13.593346Z","iopub.execute_input":"2021-09-23T12:45:13.593683Z","iopub.status.idle":"2021-09-23T12:45:14.01578Z","shell.execute_reply.started":"2021-09-23T12:45:13.593641Z","shell.execute_reply":"2021-09-23T12:45:14.014917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"most_frequent(negtive_words, '10 Most Negative words')","metadata":{"execution":{"iopub.status.busy":"2021-09-23T12:45:14.017116Z","iopub.execute_input":"2021-09-23T12:45:14.017488Z","iopub.status.idle":"2021-09-23T12:45:14.251226Z","shell.execute_reply.started":"2021-09-23T12:45:14.017456Z","shell.execute_reply":"2021-09-23T12:45:14.250191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"most_frequent(positive_words, '10 most positive words')","metadata":{"execution":{"iopub.status.busy":"2021-09-23T12:45:14.252925Z","iopub.execute_input":"2021-09-23T12:45:14.253192Z","iopub.status.idle":"2021-09-23T12:45:14.607781Z","shell.execute_reply.started":"2021-09-23T12:45:14.253162Z","shell.execute_reply":"2021-09-23T12:45:14.606664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}