{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.display.float_format = '{:.4f}'.format","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Import Data**","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/mushroom-classification/mushrooms.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check null values\ndata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#e: edible == 1\n#p: poison == 0\ndata['class'] = np.where(data['class']=='e',1,0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Information Value**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp_data = data.fillna('NULL')\nsummary = pd.DataFrame(columns=['Input','Total','Target','Non-Target','%Target','%Non-Target','WOE','IV','Features','Total_IV'])\n\nfor i in range(1,tmp_data.shape[1]):\n\n    tmp_features = tmp_data.columns[i]\n    \n    tmp_info = pd.DataFrame(tmp_data[[tmp_features]+['class']].groupby(tmp_features).agg(['count','sum'])).reset_index()\n    tmp_info = pd.concat([tmp_info[tmp_features],tmp_info['class']],axis=1).rename(columns={tmp_features:'Input','count':'Total','sum':'Target'})\n    tmp_info['Non-Target'] = tmp_info['Total']-tmp_info['Target']\n    tmp_info['%Target']= tmp_info['Target']/tmp_data.groupby('class').size()[1]\n    tmp_info['%Non-Target'] = tmp_info['Non-Target']/tmp_data.groupby('class').size()[0]\n    tmp_info['WOE'] = np.log(tmp_info['%Target']/tmp_info['%Non-Target'])\n    tmp_info['IV'] = ((tmp_info['%Target']-tmp_info['%Non-Target']).sum())*(tmp_info['WOE'])\n\n    #Edit some bins\n    edit_bins_tmp = tmp_info[(tmp_info['WOE']==np.inf)|(tmp_info['WOE']==-np.inf)].reset_index(drop=True)\n    \n    if len(edit_bins_tmp)==1:\n        edit_bins_tmp['WOE'] = 0\n        edit_bins_tmp['IV'] = 0\n    else:\n        for i in range(0,len(edit_bins_tmp)-1):\n            edit_bins_tmp['Input'][i] = edit_bins_tmp['Input'][i]+','\n        edit_bins_tmp = pd.DataFrame(edit_bins_tmp[['Input','Total','Target','Non-Target']].sum()).transpose()\n        edit_bins_tmp['%Target']= edit_bins_tmp['Target']/tmp_data.groupby('class').size()[1]\n        edit_bins_tmp['%Non-Target'] = edit_bins_tmp['Non-Target']/tmp_data.groupby('class').size()[0]\n        try:\n            edit_bins_tmp['WOE'] = np.log((edit_bins_tmp['%Target']/edit_bins_tmp['%Non-Target'])[0])\n        except:\n            edit_bins_tmp['WOE'] = 0\n\n        try:\n            edit_bins_tmp['IV'] = ((edit_bins_tmp['%Target']-edit_bins_tmp['%Non-Target']).sum())*(edit_bins_tmp['WOE'])\n        except:\n            edit_bins_tmp['IV'] = 0\n    #Final bins table\n    tmp_info = tmp_info[(tmp_info['WOE']!=np.inf)&(tmp_info['WOE']!=-np.inf)].reset_index(drop=True)\n\n    tmp_info = (tmp_info.append(edit_bins_tmp)).reset_index(drop=True)\n    tmp_info['Features'] = tmp_features\n    tmp_info['Total_IV'] = tmp_info['IV'].sum()\n    \n    summary = summary.append(tmp_info)\n    summary = summary[summary['Input']!=0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"summary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"important_feat = summary[['Features','Total_IV']].groupby('Features').max().reset_index()\nimportant_feat = important_feat.sort_values('Total_IV',ascending=False)\nimportant_feat","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Apply WOE to data**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp_woe = pd.DataFrame(columns=['Features','Input','WOE'])\nfor i in range(0,len(important_feat)):\n        tmp_woe_features = summary[summary['Features']==important_feat['Features'][i]]\n        for k in range(0,len(tmp_woe_features)):\n            tmp_woe_features_comma = tmp_woe_features.iloc[k:k+1]\n            if len(tmp_woe_features_comma['Input'][k].split(','))==1:\n                tmp_woe = tmp_woe.append(tmp_woe_features_comma[['Features','Input','WOE']])\n            else:\n                edit_bins_woe = pd.DataFrame(tmp_woe_features_comma['Input'][k].split(',')).rename(columns={0:'Input'})\n                edit_bins_woe['Features'] = important_feat['Features'][i]\n                edit_bins_woe['WOE'] = tmp_woe_features_comma['WOE'][k]\n                edit_bins_woe = edit_bins_woe[['Features','Input','WOE']]\n                \n                tmp_woe = tmp_woe.append(edit_bins_woe)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[[important_feat['Features'][1]]].merge(tmp_woe[tmp_woe['Features']==important_feat['Features'][1]][['Input','WOE']].rename(columns={'Input':important_feat['Features'][1]}),how='left',on=important_feat['Features'][1])['WOE']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"important_feat.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_woe = data[['class']]\nfor i in range(0,important_feat.shape[0]):\n    tmp_feat_nm = data.columns[i]+'_woe'\n    data_woe[tmp_feat_nm] = data[[important_feat['Features'][i]]].merge(tmp_woe[tmp_woe['Features']==important_feat['Features'][i]][['Input','WOE']].rename(columns={'Input':important_feat['Features'][i]}),how='left',on=important_feat['Features'][i])['WOE']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_woe","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Traditional Logistic Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nfrom matplotlib import pyplot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data_woe.iloc[:,1:]\ny = data_woe.iloc[:,0:1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split into train/test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression(random_state=0).fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ns_probs = [0 for _ in range(len(y))]\nlr_train_probs = lr.predict_proba(X_train)[:, 1]\nlr_test_probs = lr.predict_proba(X_test)[:, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ns_auc = roc_auc_score(y, ns_probs)\nlr_train_auc = roc_auc_score(y_train, lr_train_probs)\nlr_test_auc = roc_auc_score(y_test, lr_test_probs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# summarize scores\nprint('No Skill: ROC AUC=%.3f' % (ns_auc))\nprint('Trainning Logistic: ROC AUC=%.3f' % (lr_train_auc))\nprint('Testing Logistic: ROC AUC=%.3f' % (lr_test_auc))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}