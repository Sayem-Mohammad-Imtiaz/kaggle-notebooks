{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":79,"outputs":[{"output_type":"stream","text":"['mnist_train.csv', 'mnist_test.csv']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom IPython.display import clear_output\nimport pandas as pd\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import accuracy_score","execution_count":80,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/mnist_train.csv\")\ntest = pd.read_csv(\"../input/mnist_test.csv\")","execution_count":81,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)\nprint(train.columns)\nprint(train[:2])\nprint(test[:2])\nprint(train[:10][\"label\"])\nprint(test[:10][\"label\"])","execution_count":82,"outputs":[{"output_type":"stream","text":"(60000, 785)\n(10000, 785)\nIndex(['label', '1x1', '1x2', '1x3', '1x4', '1x5', '1x6', '1x7', '1x8', '1x9',\n       ...\n       '28x19', '28x20', '28x21', '28x22', '28x23', '28x24', '28x25', '28x26',\n       '28x27', '28x28'],\n      dtype='object', length=785)\n   label  1x1  1x2  1x3  1x4  ...    28x24  28x25  28x26  28x27  28x28\n0      5    0    0    0    0  ...        0      0      0      0      0\n1      0    0    0    0    0  ...        0      0      0      0      0\n\n[2 rows x 785 columns]\n   label  1x1  1x2  1x3  1x4  ...    28x24  28x25  28x26  28x27  28x28\n0      7    0    0    0    0  ...        0      0      0      0      0\n1      2    0    0    0    0  ...        0      0      0      0      0\n\n[2 rows x 785 columns]\n0    5\n1    0\n2    4\n3    1\n4    9\n5    2\n6    1\n7    3\n8    1\n9    4\nName: label, dtype: int64\n0    7\n1    2\n2    1\n3    0\n4    4\n5    1\n6    4\n7    9\n8    5\n9    9\nName: label, dtype: int64\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = np.array(train)\ntest = np.array(test)","execution_count":83,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train[10:15])\nprint(test[10:15])","execution_count":84,"outputs":[{"output_type":"stream","text":"[[3 0 0 ... 0 0 0]\n [5 0 0 ... 0 0 0]\n [3 0 0 ... 0 0 0]\n [6 0 0 ... 0 0 0]\n [1 0 0 ... 0 0 0]]\n[[0 0 0 ... 0 0 0]\n [6 0 0 ... 0 0 0]\n [9 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [1 0 0 ... 0 0 0]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x = train[:,1:]\ntrain_y = pd.get_dummies(train[:,0])\ntest_x = test[:,1:]\ntest_y = pd.get_dummies(test[:,0])","execution_count":85,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_x.shape)\nprint(train_y.shape)\nprint(test_x.shape)\nprint(test_y.shape)\nprint(train_x[10:12])\nprint(train_y[10:12])\nprint(test_x[10:12])\nprint(test_y[10:12])","execution_count":86,"outputs":[{"output_type":"stream","text":"(60000, 784)\n(60000, 10)\n(10000, 784)\n(10000, 10)\n[[0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]]\n    0  1  2  3  4  5  6  7  8  9\n10  0  0  0  1  0  0  0  0  0  0\n11  0  0  0  0  0  1  0  0  0  0\n[[0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]]\n    0  1  2  3  4  5  6  7  8  9\n10  1  0  0  0  0  0  0  0  0  0\n11  0  0  0  0  0  0  1  0  0  0\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"#### We will treat each image as a sequence of 28 rows of 28 pixels each (since each MNIST image is 28 Ã— 28 pixels). We will use cells of 150 recurrent neurons, plus a fully connected layer containing 10 neurons (one per class) connected to the output of the last time step, followed by a softmax layer"},{"metadata":{"trusted":true},"cell_type":"code","source":"#NETWORK PARAMETERS\nn_steps = 28\nn_inputs = 28\nn_neurons = 150\nn_outputs = 10","execution_count":87,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x = train_x.reshape(-1,n_steps,n_inputs)\ntest_x = test_x.reshape(-1,n_steps,n_inputs)","execution_count":88,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_x.shape)\nprint(test_x.shape)\nprint(train_x[0:1])\nprint(test_x[0:1])","execution_count":89,"outputs":[{"output_type":"stream","text":"(60000, 28, 28)\n(10000, 28, 28)\n[[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n     0   0   0   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n     0   0   0   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n     0   0   0   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n     0   0   0   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n     0   0   0   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126\n   136 175  26 166 255 247 127   0   0   0   0]\n  [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253\n   253 225 172 253 242 195  64   0   0   0   0]\n  [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253\n   251  93  82  82  56  39   0   0   0   0   0]\n  [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247\n   241   0   0   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43\n   154   0   0   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0\n     0   0   0   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0\n     0   0   0   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0\n     0   0   0   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108\n     1   0   0   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253\n   119  25   0   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253\n   253 150  27   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93\n   252 253 187   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   249 253 249  64   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183\n   253 253 207   2   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253\n   253 250 182   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253\n   201  78   0   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81\n     2   0   0   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0\n     0   0   0   0   0   0   0   0   0   0   0]\n  [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0\n     0   0   0   0   0   0   0   0   0   0   0]\n  [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0\n     0   0   0   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n     0   0   0   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n     0   0   0   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n     0   0   0   0   0   0   0   0   0   0   0]]]\n[[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n     0   0   0   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n     0   0   0   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n     0   0   0   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n     0   0   0   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n     0   0   0   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n     0   0   0   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n     0   0   0   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0  84 185 159 151  60  36   0   0   0   0   0\n     0   0   0   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0 222 254 254 254 254 241 198 198 198 198 198\n   198 198 198 170  52   0   0   0   0   0   0]\n  [  0   0   0   0   0   0  67 114  72 114 163 227 254 225 254 254 254\n   250 229 254 254 140   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0   0  17  66  14  67  67  67\n    59  21 236 254 106   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n     0  83 253 209  18   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    22 233 255  83   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   129 254 238  44   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  59\n   249 254  62   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 133\n   254 187   5   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   9 205\n   248  58   0   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 126 254\n   182   0   0   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  75 251 240\n    57   0   0   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0   0   0   0  19 221 254 166\n     0   0   0   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0   0   0   3 203 254 219  35\n     0   0   0   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0   0   0  38 254 254  77   0\n     0   0   0   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0   0  31 224 254 115   1   0\n     0   0   0   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0   0 133 254 254  52   0   0\n     0   0   0   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0  61 242 254 254  52   0   0\n     0   0   0   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0 121 254 254 219  40   0   0\n     0   0   0   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0 121 254 207  18   0   0   0\n     0   0   0   0   0   0   0   0   0   0   0]\n  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n     0   0   0   0   0   0   0   0   0   0   0]]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X , train_y = shuffle(train_x , train_y)\ntest_X , test_y = shuffle(test_x , test_y)","execution_count":90,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.reset_default_graph()","execution_count":91,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training Parameters\nlearning_rate = 0.001\ntraining_iters = 100\nbatch_size = 150\ndisplay_step = 200","execution_count":92,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = tf.placeholder(tf.float32,[None,n_steps,n_inputs])\ny = tf.placeholder(tf.float32,[None,n_outputs])","execution_count":93,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def RNN(X):\n    basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n    outputs , states = tf.nn.dynamic_rnn(basic_cell,X,dtype=tf.float32)\n    out = tf.layers.dense(states, n_outputs)\n    out = tf.nn.softmax(out)\n    return out\n    ","execution_count":94,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = RNN(X)","execution_count":95,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define loss and optimizer\nloss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=prediction, labels=y))\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\ntrain_op = optimizer.minimize(loss_op)","execution_count":96,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate model (with test logits, for dropout to be disabled)\ncorrect_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()","execution_count":97,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sess = tf.Session()\nsess.run(init) \n\nfor i in range(training_iters):\n    for batch in range(len(train_X)//batch_size):\n        batch_x = train_X[batch*batch_size:min((batch+1)*batch_size,len(train_X))]\n        batch_y = train_y[batch*batch_size:min((batch+1)*batch_size,len(train_y))]    \n\n        sess.run(train_op, feed_dict={X: batch_x, y: batch_y})\n            # Calculate batch loss and accuracy\n        loss = sess.run([loss_op], feed_dict={X: batch_x, y: batch_y})\n    \n    predTest = sess.run(prediction , feed_dict={X:test_X})\n\n    p = np.argmax(predTest,1)\n    t = np.argmax(np.array(test_y),1)\n\n    acc = accuracy_score(p,t)\n    print(\"Iter \"+str(i)+\" Out of\",training_iters , \" Loss= \",loss, \"acc=\",acc )\n            \n#     acc = sess.run([accuracy], feed_dict={X: batch_x, y: batch_y})\n        \n#     print(\"Step \" + str(i) + \",        Batch Loss= \",loss, \",       Training Accuracy= \",acc)\n    \nprint(\"Optimization Finished!\")","execution_count":99,"outputs":[{"output_type":"stream","text":"Iter 0 Out of 100  Loss=  [1.8855386] acc= 0.5067\nIter 1 Out of 100  Loss=  [1.8827469] acc= 0.5075\nIter 2 Out of 100  Loss=  [1.8734704] acc= 0.5131\nIter 3 Out of 100  Loss=  [1.8806031] acc= 0.5146\nIter 4 Out of 100  Loss=  [1.8724397] acc= 0.5199\nIter 5 Out of 100  Loss=  [1.8630449] acc= 0.5186\nIter 6 Out of 100  Loss=  [1.8721691] acc= 0.5211\nIter 7 Out of 100  Loss=  [1.8643327] acc= 0.5175\nIter 8 Out of 100  Loss=  [1.8711295] acc= 0.5181\nIter 9 Out of 100  Loss=  [1.8555135] acc= 0.5238\nIter 10 Out of 100  Loss=  [1.8639575] acc= 0.5242\nIter 11 Out of 100  Loss=  [1.8654317] acc= 0.5234\nIter 12 Out of 100  Loss=  [1.8529726] acc= 0.5316\nIter 13 Out of 100  Loss=  [1.8765159] acc= 0.5278\nIter 14 Out of 100  Loss=  [1.8703305] acc= 0.5263\nIter 15 Out of 100  Loss=  [1.8799516] acc= 0.5287\nIter 16 Out of 100  Loss=  [1.8528666] acc= 0.5309\nIter 17 Out of 100  Loss=  [1.8494303] acc= 0.5318\nIter 18 Out of 100  Loss=  [1.8484768] acc= 0.5335\nIter 19 Out of 100  Loss=  [1.861479] acc= 0.5332\nIter 20 Out of 100  Loss=  [1.8422475] acc= 0.5336\nIter 21 Out of 100  Loss=  [1.8492352] acc= 0.5378\nIter 22 Out of 100  Loss=  [1.8539768] acc= 0.5385\nIter 23 Out of 100  Loss=  [1.8629171] acc= 0.5346\nIter 24 Out of 100  Loss=  [1.8228021] acc= 0.535\nIter 25 Out of 100  Loss=  [1.8368683] acc= 0.5393\nIter 26 Out of 100  Loss=  [1.8624117] acc= 0.5305\nIter 27 Out of 100  Loss=  [1.8467759] acc= 0.536\nIter 28 Out of 100  Loss=  [1.8595439] acc= 0.5365\nIter 29 Out of 100  Loss=  [1.8745857] acc= 0.5322\nIter 30 Out of 100  Loss=  [1.8811927] acc= 0.542\nIter 31 Out of 100  Loss=  [1.8508801] acc= 0.5403\nIter 32 Out of 100  Loss=  [1.8549747] acc= 0.5439\nIter 33 Out of 100  Loss=  [1.8403695] acc= 0.539\nIter 34 Out of 100  Loss=  [1.8406905] acc= 0.5481\nIter 35 Out of 100  Loss=  [1.8442212] acc= 0.5443\nIter 36 Out of 100  Loss=  [1.8601979] acc= 0.5457\nIter 37 Out of 100  Loss=  [1.841465] acc= 0.5371\nIter 38 Out of 100  Loss=  [1.8671671] acc= 0.5435\nIter 39 Out of 100  Loss=  [1.8523663] acc= 0.5402\nIter 40 Out of 100  Loss=  [1.8780777] acc= 0.5432\nIter 41 Out of 100  Loss=  [1.835721] acc= 0.5441\nIter 42 Out of 100  Loss=  [1.8706884] acc= 0.545\nIter 43 Out of 100  Loss=  [1.8536011] acc= 0.5412\nIter 44 Out of 100  Loss=  [1.8403039] acc= 0.5379\nIter 45 Out of 100  Loss=  [1.8441545] acc= 0.5431\nIter 46 Out of 100  Loss=  [1.8334475] acc= 0.5443\nIter 47 Out of 100  Loss=  [1.8449336] acc= 0.5464\nIter 48 Out of 100  Loss=  [1.8519043] acc= 0.5459\nIter 49 Out of 100  Loss=  [1.8149619] acc= 0.5435\nIter 50 Out of 100  Loss=  [1.8295674] acc= 0.5448\nIter 51 Out of 100  Loss=  [1.8138431] acc= 0.5488\nIter 52 Out of 100  Loss=  [1.8331891] acc= 0.5496\nIter 53 Out of 100  Loss=  [1.8364469] acc= 0.542\nIter 54 Out of 100  Loss=  [1.8057296] acc= 0.5476\nIter 55 Out of 100  Loss=  [1.8503937] acc= 0.5441\nIter 56 Out of 100  Loss=  [1.8341436] acc= 0.5415\nIter 57 Out of 100  Loss=  [1.8395196] acc= 0.5492\nIter 58 Out of 100  Loss=  [1.8304838] acc= 0.5416\nIter 59 Out of 100  Loss=  [1.8423681] acc= 0.5425\nIter 60 Out of 100  Loss=  [1.8623507] acc= 0.5404\nIter 61 Out of 100  Loss=  [1.8593479] acc= 0.5474\nIter 62 Out of 100  Loss=  [1.8339571] acc= 0.5522\nIter 63 Out of 100  Loss=  [1.8650795] acc= 0.5429\nIter 64 Out of 100  Loss=  [1.8637022] acc= 0.5469\nIter 65 Out of 100  Loss=  [1.8514873] acc= 0.5385\nIter 66 Out of 100  Loss=  [1.8248149] acc= 0.5466\nIter 67 Out of 100  Loss=  [1.8333994] acc= 0.5486\nIter 68 Out of 100  Loss=  [1.8588794] acc= 0.5488\nIter 69 Out of 100  Loss=  [1.8336775] acc= 0.5468\nIter 70 Out of 100  Loss=  [1.8326066] acc= 0.5378\nIter 71 Out of 100  Loss=  [1.8369393] acc= 0.5482\nIter 72 Out of 100  Loss=  [1.8039435] acc= 0.5487\nIter 73 Out of 100  Loss=  [1.8384414] acc= 0.5488\nIter 74 Out of 100  Loss=  [1.8218602] acc= 0.5494\nIter 75 Out of 100  Loss=  [1.8154161] acc= 0.5539\nIter 76 Out of 100  Loss=  [1.8231852] acc= 0.5504\nIter 77 Out of 100  Loss=  [1.8183749] acc= 0.5454\nIter 78 Out of 100  Loss=  [1.8256326] acc= 0.549\nIter 79 Out of 100  Loss=  [1.8276365] acc= 0.5524\nIter 80 Out of 100  Loss=  [1.8079526] acc= 0.5471\nIter 81 Out of 100  Loss=  [1.8541173] acc= 0.5423\nIter 82 Out of 100  Loss=  [1.8422229] acc= 0.5416\nIter 83 Out of 100  Loss=  [1.8636959] acc= 0.5465\nIter 84 Out of 100  Loss=  [1.8380982] acc= 0.5496\nIter 85 Out of 100  Loss=  [1.8601106] acc= 0.5508\nIter 86 Out of 100  Loss=  [1.8263173] acc= 0.5508\nIter 87 Out of 100  Loss=  [1.8080231] acc= 0.5524\nIter 88 Out of 100  Loss=  [1.8508387] acc= 0.5503\nIter 89 Out of 100  Loss=  [1.8424754] acc= 0.5463\nIter 90 Out of 100  Loss=  [1.8420966] acc= 0.5507\nIter 91 Out of 100  Loss=  [1.8289846] acc= 0.5428\nIter 92 Out of 100  Loss=  [1.8367627] acc= 0.5495\nIter 93 Out of 100  Loss=  [1.8233501] acc= 0.5556\nIter 94 Out of 100  Loss=  [1.8343298] acc= 0.5501\nIter 95 Out of 100  Loss=  [1.8268116] acc= 0.5492\nIter 96 Out of 100  Loss=  [1.8396269] acc= 0.5487\nIter 97 Out of 100  Loss=  [1.8505493] acc= 0.5471\nIter 98 Out of 100  Loss=  [1.8459247] acc= 0.5488\nIter 99 Out of 100  Loss=  [1.8474147] acc= 0.5502\nOptimization Finished!\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"while(True):\n    r = np.random.randint(9000)\n    test_img = np.reshape(test_X[r], (28,28))\n    plt.imshow(test_img, cmap=\"gray\")\n    test_pred = sess.run(prediction, feed_dict = {X:[test_X[r]]})\n    print(\"Model : I think it is :    \",np.argmax(test_pred))\n    plt.show()\n    \n    if input(\"Enter n to exit\")=='n':\n        break\nclear_output();","execution_count":100,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wrong = test_X[t!=p]\nwrong.shape","execution_count":101,"outputs":[{"output_type":"execute_result","execution_count":101,"data":{"text/plain":"(4498, 28, 28)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"a,b,c = wrong.shape","execution_count":102,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"while(True):\n    r=np.random.randint(a)\n    plt.imshow(wrong[r].reshape((28,28)),cmap=\"gray\")\n    test_pred_1=sess.run(prediction, feed_dict = {X:[wrong[r]]})\n    print(\"Model : I think it is :    \",np.argmax(test_pred_1))\n    plt.show()\n    \n    if input(\"Enter n to exit\")=='n':\n        break\nclear_output();","execution_count":104,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p = np.argmax(predTest,1)\nprint(p)\nt = np.argmax(np.array(test_y),1)\nprint(t)\nacc = accuracy_score(p,t)\nprint(acc*100)","execution_count":106,"outputs":[{"output_type":"stream","text":"[6 6 1 ... 2 4 8]\n[6 6 4 ... 2 8 2]\n55.02\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Saving Weights\")\nsaver = tf.train.Saver()\nsaver.save(sess,\"weights_\"+str(i)+\"/weights.ckpt\")\nprint(\"Weights Saved\")","execution_count":107,"outputs":[{"output_type":"stream","text":"Saving Weights\nWeights Saved\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}