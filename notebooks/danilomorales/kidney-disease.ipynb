{"cells":[{"metadata":{},"cell_type":"markdown","source":"Importing fundamental libraries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reading the dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dados = pd.read_csv('../input/ckdisease/kidney_disease.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Showing the first five lines","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dados.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Removing id column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dados = dados.drop('id',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dados.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Showing initial statistcs from the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dados.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It looks like there are lines with NaNs","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dados.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are several NaNs in the columns rbc, wc, rc for example. I will drop them all since most of them are categorical columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dados = dados.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dados.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dados.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dados = dados.reset_index().drop('index',axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking the distribution of each class","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(dados['classification'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking how each categorical variable affects the diagnostic","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(2,5,figsize=(12,7))\nsns.countplot(dados['ane'],ax=ax[0][0],hue=dados['classification'])\nsns.countplot(dados['pe'],ax=ax[0][1],hue=dados['classification'])\nsns.countplot(dados['appet'],ax=ax[0][2],hue=dados['classification'])\nsns.countplot(dados['cad'],ax=ax[0][3],hue=dados['classification'])\nsns.countplot(dados['dm'],ax=ax[0][4],hue=dados['classification'])\nsns.countplot(dados['htn'],ax=ax[1][0],hue=dados['classification'])\nsns.countplot(dados['rbc'],ax=ax[1][1],hue=dados['classification'])\nsns.countplot(dados['pc'],ax=ax[1][2],hue=dados['classification'])\nsns.countplot(dados['pcc'],ax=ax[1][3],hue=dados['classification'])\nsns.countplot(dados['ba'],ax=ax[1][4],hue=dados['classification'])\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For patients without the disease the categorical variables have a very specific behavior","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dados['pcv'] = dados['pcv'].astype(int)\ndados['wc'] = dados['wc'].astype(int)\ndados['rc'] = dados['rc'].astype(float)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking the distributions of the continuous variables","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(4,3,figsize=(12,7))\nax[0][0].hist(dados['bgr'])\nax[0][0].set_title('bgr')\nax[0][1].hist(dados['bu'])\nax[0][1].set_title('bu')\nax[0][2].hist(dados['sc'])\nax[0][2].set_title('sc')\n\nax[1][0].hist(dados['sod'])\nax[1][0].set_title('sod')\nax[1][1].hist(dados['pot'])\nax[1][1].set_title('pot')\nax[1][2].hist(dados['hemo'])\nax[1][2].set_title('hemo')\n\nax[2][0].hist(dados['pcv'])\nax[2][0].set_title('pcv')\nax[2][1].hist(dados['wc'])\nax[2][1].set_title('wc')\nax[2][2].hist(dados['rc'])\nax[2][2].set_title('rc')\n\nax[3][0].hist(dados['age'])\nax[3][0].set_title('age')\nax[3][1].hist(dados['sg'])\nax[3][1].set_title('sg')\nax[3][2].hist(dados['bp'])\nax[3][2].set_title('bp')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These distributions tell us that all of these continuous variables must be normalized in order to get the maximum accuracies","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"colunas_normalizar = ['bgr','bu','sc','sod','pot','hemo','pcv','wc','rc','age','bp']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Continuous features will be normalized with MinMaxScaler","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in colunas_normalizar:\n    scaler = MinMaxScaler(feature_range=(0,1))\n    dados[col] = scaler.fit_transform(dados[col].values.reshape(-1,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dados.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Categorical features will be converted to numerical values using OneHot Enconder","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"colunas_onehot = ['rbc','pc','ba','pcc','pe','appet','cad','dm','htn','ane']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder, LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in colunas_onehot:\n    enc = OneHotEncoder()\n    dados[col] = enc.fit_transform(dados[col].values.reshape(-1,1)).toarray()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The output feature (classification) will be converted to numerical using Label Enconder","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"enc = LabelEncoder()\ndados['classification'] = enc.fit_transform(dados['classification'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dados.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking the correlation of each variable\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = dados.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(figsize=(10,8))\nsns.heatmap(corr,ax=ax)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Features with strong correlation have a negative correlation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, cross_val_score,KFold,StratifiedKFold, GridSearchCV\nfrom sklearn.metrics import confusion_matrix,accuracy_score,f1_score,average_precision_score,recall_score,roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Defining the X and Y variables\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"colunas_X = dados.columns.drop('classification')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = dados.drop('classification',axis=1).values\nY = dados['classification'].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Spliting into train and test samples using 30% for test size","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30,random_state=42,stratify=Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = []\nprecision =[]\nrecall = []\nf1 = []\nroc = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In order to find the best solution for each model, GridSearchCV will be used with a cross-validation of 10 samples","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Logistic Regression\")\nlog_reg_params = {\"penalty\": ['None','l1', 'l2','elasticnet'], 'C': [1, 10, 100], \n                  'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\ngrid_log_reg = GridSearchCV(LogisticRegression(max_iter=10000), log_reg_params,n_jobs=8,cv=10,scoring='roc_auc_ovo')\ngrid_log_reg.fit(X_train, y_train)\nlogreg = grid_log_reg.best_estimator_\nlog_reg_score = cross_val_score(logreg, X_train, y_train, cv=10,scoring='roc_auc_ovo')\nlog_reg_score_teste = cross_val_score(logreg, X_test, y_test, cv=10,scoring='roc_auc_ovo')\nprint(\"Best Estimator\")\nprint(logreg)\nprint('Score Regressao Logistica Train: ', round(log_reg_score.mean() * 100, 2).astype(str) + '%')\nprint('Score Regressao Logistica Test: ', round(log_reg_score_teste.mean() * 100, 2).astype(str) + '%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred_logreg = logreg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm_logreg = confusion_matrix(y_test,Y_pred_logreg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_score_logreg = accuracy_score(y_test,Y_pred_logreg)\nf1_score_logreg = f1_score(y_test,Y_pred_logreg)\nprecisao_logreg = average_precision_score(y_test,Y_pred_logreg)\nrecall_logreg = recall_score(y_test,Y_pred_logreg)\nroc_logreg = roc_auc_score(y_test,Y_pred_logreg,multi_class='ovo')\nprint('Accuracy Logistic Regression ',round(acc_score_logreg*100,2).astype(str)+'%')\nprint('Precision Logistic Regression ',round(precisao_logreg*100,2).astype(str)+'%')\nprint('F1 Logistic Regression ',round(f1_score_logreg*100,2).astype(str)+'%')\nprint('Recall Logistic Regression ',round(recall_logreg*100,2).astype(str)+'%')\nprint('ROC Logistic Regression ',round(roc_logreg*100,2).astype(str)+'%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy.append(acc_score_logreg)\nprecision.append(precisao_logreg)\nrecall.append(recall_logreg)\nf1.append(f1_score_logreg)\nroc.append(roc_logreg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,6))\nsns.heatmap(cm_logreg, ax=ax, annot=True, cmap=plt.cm.copper)\nax.set_title(\"Logistic Regression \\n Confusion Matrix\", fontsize=14)\nax.set_xticklabels(['ckd', 'notckd'], fontsize=14, rotation=0)\nax.set_yticklabels(['ckd', 'notckd'], fontsize=14, rotation=360)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Logistic regression has only made one mistake with demonstrate that it is an excellent model for predicting kidney disease","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"importance_logreg = logreg.coef_[0]\nfeature_series_logreg = pd.Series(data=importance_logreg,index=colunas_X)\nfeature_series_logreg.plot.bar()\nplt.title('Feature Importance Logistic Regression')\nplt.xlabel('Features')\nplt.ylabel('Importance')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The feature importance plot shows that only the columns al, htn, dm and appet are important for the problem","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"KNN\")\nknears_params = {\"n_neighbors\": list(range(5,30,1)),'leaf_size' : list(range(3,11,1)), 'weights': ['uniform', 'distance']}\ngrid_knears = GridSearchCV(KNeighborsClassifier(), knears_params,n_jobs=8,cv=10,scoring='roc_auc_ovo')\ngrid_knears.fit(X_train, y_train)\nknn = grid_knears.best_estimator_\nknears_score = cross_val_score(knn, X_train, y_train, cv=10,scoring='roc_auc_ovo')\nknears_score_teste = cross_val_score(knn, X_test, y_test, cv=10,scoring='roc_auc_ovo')\nprint(\"Best Estimator\")\nprint(knn)\nprint('Score KNN Train: ', round(knears_score.mean() * 100, 2).astype(str) + '%')\nprint('Score KNN Test: ', round(knears_score_teste.mean() * 100, 2).astype(str) + '%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred_knn = knn.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm_knn = confusion_matrix(y_test,Y_pred_knn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_score_knn = accuracy_score(y_test,Y_pred_knn)\nf1_score_knn = f1_score(y_test,Y_pred_knn)\nprecisao_knn = average_precision_score(y_test,Y_pred_knn)\nrecall_knn = recall_score(y_test,Y_pred_knn)\nroc_knn = roc_auc_score(y_test,Y_pred_knn,multi_class='ovo')\nprint('Accuracy KNN ',round(acc_score_knn*100,2).astype(str)+'%')\nprint('Precision KNN ',round(precisao_knn*100,2).astype(str)+'%')\nprint('F1 KNN ',round(f1_score_knn*100,2).astype(str)+'%')\nprint('Recall KNN ',round(recall_knn*100,2).astype(str)+'%')\nprint('ROC KNN ',round(roc_knn*100,2).astype(str)+'%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy.append(acc_score_knn)\nprecision.append(precisao_knn)\nrecall.append(recall_knn)\nf1.append(f1_score_knn)\nroc.append(roc_knn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,6))\nsns.heatmap(cm_knn, ax=ax, annot=True, cmap=plt.cm.copper)\nax.set_title(\"KNN \\n Confusion Matrix\", fontsize=14)\nax.set_xticklabels(['ckd', 'notckd'], fontsize=14, rotation=0)\nax.set_yticklabels(['ckd', 'notckd'], fontsize=14, rotation=360)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Compared to logistic regression KNN had a worse performance","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Ada Boost Classifier\")\nada_params = {'n_estimators' : list(range(5,200))}\ngrid_ada = GridSearchCV(AdaBoostClassifier(), ada_params,n_jobs=8,cv=10,scoring='roc_auc_ovo')\ngrid_ada.fit(X_train, y_train)\nada = grid_ada.best_estimator_\nprint(\"Best Estimator\")\nprint(ada)\nada_score = cross_val_score(ada, X_train, y_train, cv=10,scoring='roc_auc_ovo')\nada_score_teste = cross_val_score(ada, X_test, y_test, cv=10,scoring='roc_auc_ovo')\nprint('Score AdaBoost Train: ', round(ada_score.mean() * 100, 2).astype(str) + '%')\nprint('Score AdaBoost Test: ', round(ada_score_teste.mean() * 100, 2).astype(str) + '%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ada.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred_ada = ada.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm_ada = confusion_matrix(y_test,Y_pred_ada)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_score_ada = accuracy_score(y_test,Y_pred_ada)\nf1_score_ada = f1_score(y_test,Y_pred_ada)\nprecisao_ada = average_precision_score(y_test,Y_pred_ada)\nrecall_ada = recall_score(y_test,Y_pred_ada)\nroc_ada = roc_auc_score(y_test,Y_pred_ada,multi_class='ovo')\nprint('Accuracy ADA Boost ',round(acc_score_ada*100,2).astype(str)+'%')\nprint('Precision Ada Boost ',round(precisao_ada*100,2).astype(str)+'%')\nprint('F1 Ada Boost ',round(f1_score_ada*100,2).astype(str)+'%')\nprint('Recall Ada Boost ',round(recall_ada*100,2).astype(str)+'%')\nprint('ROC Ada Boost ',round(roc_ada*100,2).astype(str)+'%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy.append(acc_score_ada)\nprecision.append(precisao_ada)\nrecall.append(recall_ada)\nf1.append(f1_score_ada)\nroc.append(roc_ada)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,6))\nsns.heatmap(cm_ada, ax=ax, annot=True, cmap=plt.cm.copper)\nax.set_title(\"Ada Boost \\n Confusion matrix\", fontsize=14)\nax.set_xticklabels(['ckd', 'notckd'], fontsize=14, rotation=0)\nax.set_yticklabels(['ckd', 'notckd'], fontsize=14, rotation=360)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ada Boost had a very similar performance compared to Logistic Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"importance_ada = ada.feature_importances_\nfeature_series_ada = pd.Series(data=importance_ada,index=colunas_X)\nfeature_series_ada.plot.bar()\nplt.title('Feature Importance Ada Boost')\nplt.xlabel('Features')\nplt.ylabel('Importance')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Accoring to Ada Boost only the column al is important for the problem","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Random Forest Classifier\")\nforest_params = {\"max_depth\": list(range(5,10,1)),\"n_estimators\" : list(range(5,10,1))}\nforest = GridSearchCV(RandomForestClassifier(), forest_params,n_jobs=8,cv=10,scoring='roc_auc_ovo')\nforest.fit(X_train, y_train)\nrandom_forest = forest.best_estimator_\nprint(\"Best Estimator\")\nprint(random_forest)\nforest_score = cross_val_score(random_forest, X_train, y_train, cv=10,scoring='roc_auc_ovo')\nforest_score_teste = cross_val_score(random_forest, X_test, y_test, cv=10,scoring='roc_auc_ovo')\nprint('Score RFC Train: ', round(forest_score.mean() * 100, 2).astype(str) + '%')\nprint('Score RFC Test: ', round(forest_score_teste.mean() * 100, 2).astype(str) + '%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_forest.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred_rf = random_forest.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm_rf = confusion_matrix(y_test,Y_pred_rf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_score_rf = accuracy_score(y_test,Y_pred_rf)\nf1_score_rf = f1_score(y_test,Y_pred_rf)\nprecisao_rf = average_precision_score(y_test,Y_pred_rf)\nrecall_rf = recall_score(y_test,Y_pred_rf)\nroc_rf = roc_auc_score(y_test,Y_pred_rf,multi_class='ovo')\nprint('Accuracy Random Forest ',round(acc_score_rf*100,2).astype(str)+'%')\nprint('Precision Random Forest ',round(precisao_rf*100,2).astype(str)+'%')\nprint('F1 Random Forest ',round(f1_score_rf*100,2).astype(str)+'%')\nprint('Recall Random Forest ',round(recall_rf*100,2).astype(str)+'%')\nprint('ROC Random Forest ',round(roc_rf*100,2).astype(str)+'%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy.append(acc_score_rf)\nprecision.append(precisao_rf)\nrecall.append(recall_rf)\nf1.append(f1_score_rf)\nroc.append(roc_rf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,6))\nsns.heatmap(cm_rf, ax=ax, annot=True, cmap=plt.cm.copper)\nax.set_title(\"Random Forest \\n Confusion matrix\", fontsize=14)\nax.set_xticklabels(['ckd', 'notckd'], fontsize=14, rotation=0)\nax.set_yticklabels(['ckd', 'notckd'], fontsize=14, rotation=360)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random forest had a very similiar result compared to Logistic regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"importance_rfc = random_forest.feature_importances_\nfeature_series_rfc = pd.Series(data=importance_rfc,index=colunas_X)\nfeature_series_rfc.plot.bar()\nplt.title('Feature Importance Random Forest')\nplt.xlabel('Features')\nplt.ylabel('Importance')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For random forest classifier only the columns al, ba, sod, hemo, rc and dm are important where the column rc is the most important","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Gradient Boost Classifier\")\ngrad_params = {'n_estimators' : list(range(4,21,1)),'max_depth' : list(range(5,21,1))}\ngrad = GridSearchCV(GradientBoostingClassifier(), grad_params,n_jobs=8,cv=10,scoring='roc_auc_ovo')\ngrad.fit(X_train, y_train)\ngrad_boost = grad.best_estimator_\nprint(\"Best Estimator\")\nprint(grad_boost)\ngrad_score = cross_val_score(grad_boost, X_train, y_train, cv=10,scoring='roc_auc_ovo')\ngrad_score_teste = cross_val_score(grad_boost, X_test, y_test, cv=10,scoring='roc_auc_ovo')\nprint('Score GradBoost Train: ', round(grad_score.mean() * 100, 2).astype(str) + '%')\nprint('Score GradBoost Test: ', round(grad_score_teste.mean() * 100, 2).astype(str) + '%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grad_boost.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred_gb = grad_boost.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm_gb = confusion_matrix(y_test,Y_pred_gb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_score_gb = accuracy_score(y_test,Y_pred_gb)\nf1_score_gb = f1_score(y_test,Y_pred_gb)\nprecisao_gb = average_precision_score(y_test,Y_pred_gb)\nrecall_gb = recall_score(y_test,Y_pred_gb)\nroc_gb = roc_auc_score(y_test,Y_pred_gb,multi_class='ovo')\nprint('Accuracy Gradient Boosting ',round(acc_score_gb*100,2).astype(str)+'%')\nprint('Precision Gradient Boosting  ',round(precisao_gb*100,2).astype(str)+'%')\nprint('F1 Gradient Boosting  ',round(f1_score_gb*100,2).astype(str)+'%')\nprint('Recall Gradient Boosting  ',round(recall_gb*100,2).astype(str)+'%')\nprint('ROC Gradient Boosting ',round(roc_gb*100,2).astype(str)+'%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy.append(acc_score_gb)\nprecision.append(precisao_gb)\nrecall.append(recall_gb)\nf1.append(f1_score_gb)\nroc.append(roc_gb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,6))\nsns.heatmap(cm_gb, ax=ax, annot=True, cmap=plt.cm.copper)\nax.set_title(\"Gradient Boosting  \\n Confusion matrix\", fontsize=14)\nax.set_xticklabels(['ckd', 'notckd'], fontsize=14, rotation=0)\nax.set_yticklabels(['ckd', 'notckd'], fontsize=14, rotation=360)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Gradient boost also had a very similar performance compared to the logistic regression and ada boost models","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"importance_gradboost = grad_boost.feature_importances_\nfeature_series_gradboost = pd.Series(data=importance_gradboost,index=colunas_X)\nfeature_series_gradboost.plot.bar()\nplt.title('Feature Importance Gradient Boosting')\nplt.xlabel('Features')\nplt.ylabel('Importance')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For Gradient Boosting only the column al is important","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Build a deep learning model with Keras. I will use Batch Normalization since this has a very imporant effect in the model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"n_inputs = X_train.shape[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Activation,BatchNormalization\nfrom keras.layers.core import Dense,Dropout\nfrom keras.optimizers import Adam\nfrom keras.metrics import categorical_crossentropy\nfrom keras.callbacks import ReduceLROnPlateau,EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelo = Sequential()\nmodelo.add(Dense(128, input_shape=(n_inputs, ), activation='relu', kernel_initializer='glorot_uniform',bias_initializer='zeros'))\nmodelo.add(BatchNormalization())\nmodelo.add(Dense(256, activation='relu', kernel_initializer='glorot_uniform',bias_initializer='zeros'))\nmodelo.add(BatchNormalization())\nmodelo.add(Dropout(0.5))\nmodelo.add(Dense(512, activation='relu', kernel_initializer='glorot_uniform',bias_initializer='zeros'))\nmodelo.add(BatchNormalization())\nmodelo.add(Dense(512, activation='relu', kernel_initializer='glorot_uniform',bias_initializer='zeros'))\nmodelo.add(BatchNormalization())\nmodelo.add(Dropout(0.5))\nmodelo.add(Dense(256, activation='relu', kernel_initializer='glorot_uniform',bias_initializer='zeros'))\nmodelo.add(BatchNormalization())\nmodelo.add(Dense(128, activation='relu', kernel_initializer='glorot_uniform',bias_initializer='zeros'))\nmodelo.add(BatchNormalization())\nmodelo.add(Dropout(0.5))\nmodelo.add(Dense(2, activation='softmax', kernel_initializer='glorot_uniform',bias_initializer='zeros'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=0.5, mode='auto', min_delta=0.0001)\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\ncallbacks_list = [reduce_lr,es]\nbsize = 50","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelo.compile(Adam(lr=0.01), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodelo.fit(X_train, y_train, batch_size=bsize, epochs=200, verbose=2, validation_data=(X_test,y_test),callbacks=callbacks_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred_keras = modelo.predict_classes(X_test, batch_size=bsize, verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm_keras = confusion_matrix(y_test,Y_pred_keras)\nacc_score_keras = accuracy_score(y_test,Y_pred_keras)\nf1_score_keras = f1_score(y_test,Y_pred_keras)\nprecisao_keras = average_precision_score(y_test,Y_pred_keras)\nrecall_keras = recall_score(y_test,Y_pred_keras)\nroc_keras = roc_auc_score(y_test,Y_pred_keras,multi_class='ovo')\nprint('Accuracy Keras ',round(acc_score_keras*100,2).astype(str)+'%')\nprint('Precision Keras  ',round(precisao_keras*100,2).astype(str)+'%')\nprint('F1 Keras  ',round(f1_score_keras*100,2).astype(str)+'%')\nprint('Recall Keras  ',round(recall_keras*100,2).astype(str)+'%')\nprint('ROC Keras ',round(roc_keras*100,2).astype(str)+'%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy.append(acc_score_keras)\nprecision.append(precisao_keras)\nrecall.append(recall_keras)\nf1.append(f1_score_keras)\nroc.append(roc_keras)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,6))\nsns.heatmap(cm_keras, ax=ax, annot=True, cmap=plt.cm.copper)\nax.set_title(\"Keras  \\n Matriz de Confusão\", fontsize=14)\nax.set_xticklabels(['ckd', 'notckd'], fontsize=14, rotation=0)\nax.set_yticklabels(['ckd', 'notckd'], fontsize=14, rotation=360)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The deep learning model has proven to be the best one compared to the machine learning models used here","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"nome_modelo = [\"Logistic Regression\",\"KNN\",\"AdaBoost\",\"RFC\",\"GradBoost\",\"Keras\"]\ndic_metrics = {'Model' : nome_modelo, 'Accuracy' : accuracy, 'Precision' : precision, 'Recall' : recall, 'F1' : f1, 'ROC' : roc}\ndataframe = pd.DataFrame(dic_metrics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframe_sorted =  dataframe.sort_values(by=['ROC','Accuracy','Recall','F1','Precision'],ascending=False).reset_index().drop('index',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframe_sorted","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Keras was able to find the right solution for all test sample","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}