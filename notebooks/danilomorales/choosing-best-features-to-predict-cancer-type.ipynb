{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Importing fundamental libraries for data science\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Reading CSV file with Pandas Library\ndados = pd.read_csv('../input/breast-cancer-wisconsin-data/data.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking the first five lines"},{"metadata":{"trusted":true},"cell_type":"code","source":"dados.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dropping columns id and Unnamed: 32 sicne they are unimportant"},{"metadata":{"trusted":true},"cell_type":"code","source":"dados = dados.drop(['id','Unnamed: 32'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dados.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_colunas = dados.shape[1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Countplot to check the amount of each type of cancer"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='diagnosis',data=dados)\nplt.xlabel('Diagnóstico')\nplt.ylabel('Count')\nplt.title('Kind of diagnostic')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finding the correlation among each of the variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = dados.corr()\nf,ax = plt.subplots(figsize=(20, 20))\nsns.heatmap(corr, annot=True, linewidths=.5, fmt= '.1f',ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are features like Compactness_mean, concavity_mean and concave points_mean that are correlated with each other"},{"metadata":{"trusted":true},"cell_type":"code","source":"colunas = dados.columns\nprint(\"Number of columns = {}\".format(len(colunas)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Boxplots to check the distribution of each variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots(6,5,figsize=(12,15))\nsns.boxplot(y=dados[colunas[1]],x=dados['diagnosis'],ax=ax[0][0])\nsns.boxplot(y=dados[colunas[2]],x=dados['diagnosis'],ax=ax[0][1])\nsns.boxplot(y=dados[colunas[3]],x=dados['diagnosis'],ax=ax[0][2])\nsns.boxplot(y=dados[colunas[4]],x=dados['diagnosis'],ax=ax[0][3])\nsns.boxplot(y=dados[colunas[5]],x=dados['diagnosis'],ax=ax[0][4])\n\nsns.boxplot(y=dados[colunas[6]],x=dados['diagnosis'],ax=ax[1][0])\nsns.boxplot(y=dados[colunas[7]],x=dados['diagnosis'],ax=ax[1][1])\nsns.boxplot(y=dados[colunas[8]],x=dados['diagnosis'],ax=ax[1][2])\nsns.boxplot(y=dados[colunas[9]],x=dados['diagnosis'],ax=ax[1][3])\nsns.boxplot(y=dados[colunas[10]],x=dados['diagnosis'],ax=ax[1][4])\n\nsns.boxplot(y=dados[colunas[11]],x=dados['diagnosis'],ax=ax[2][0])\nsns.boxplot(y=dados[colunas[12]],x=dados['diagnosis'],ax=ax[2][1])\nsns.boxplot(y=dados[colunas[13]],x=dados['diagnosis'],ax=ax[2][2])\nsns.boxplot(y=dados[colunas[14]],x=dados['diagnosis'],ax=ax[2][3])\nsns.boxplot(y=dados[colunas[15]],x=dados['diagnosis'],ax=ax[2][4])\n\nsns.boxplot(y=dados[colunas[16]],x=dados['diagnosis'],ax=ax[3][0])\nsns.boxplot(y=dados[colunas[17]],x=dados['diagnosis'],ax=ax[3][1])\nsns.boxplot(y=dados[colunas[18]],x=dados['diagnosis'],ax=ax[3][2])\nsns.boxplot(y=dados[colunas[19]],x=dados['diagnosis'],ax=ax[3][3])\nsns.boxplot(y=dados[colunas[20]],x=dados['diagnosis'],ax=ax[3][4])\n\nsns.boxplot(y=dados[colunas[21]],x=dados['diagnosis'],ax=ax[4][0])\nsns.boxplot(y=dados[colunas[22]],x=dados['diagnosis'],ax=ax[4][1])\nsns.boxplot(y=dados[colunas[23]],x=dados['diagnosis'],ax=ax[4][2])\nsns.boxplot(y=dados[colunas[24]],x=dados['diagnosis'],ax=ax[4][3])\nsns.boxplot(y=dados[colunas[25]],x=dados['diagnosis'],ax=ax[4][4])\n\nsns.boxplot(y=dados[colunas[26]],x=dados['diagnosis'],ax=ax[5][0])\nsns.boxplot(y=dados[colunas[27]],x=dados['diagnosis'],ax=ax[5][1])\nsns.boxplot(y=dados[colunas[28]],x=dados['diagnosis'],ax=ax[5][2])\nsns.boxplot(y=dados[colunas[29]],x=dados['diagnosis'],ax=ax[5][3])\nsns.boxplot(y=dados[colunas[30]],x=dados['diagnosis'],ax=ax[5][4])\n\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Each feature has a good distribuition with few outliers that will not be removed up to this point"},{"metadata":{},"cell_type":"markdown","source":"Normalization usually improves model performance. With expection of the column diagnosis, all remaining columns will be normalized"},{"metadata":{"trusted":true},"cell_type":"code","source":"colunas_normalizar = colunas.drop('diagnosis')\ndados_norm = dados.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importing libraries to normalize the data and split into train and test samples"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, cross_val_score,KFold,StratifiedKFold\nfrom sklearn.preprocessing import RobustScaler,StandardScaler,LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Converting categorical variable diagnosis to numeric"},{"metadata":{"trusted":true},"cell_type":"code","source":"enconder = LabelEncoder()\ndados_norm['diagnosis'] = enconder.fit_transform(dados_norm['diagnosis'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dados_norm.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Normalizing columns with RobustScaler to take into account the effects due to outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = RobustScaler()\nfor col in colunas_normalizar:\n    dados_norm[col] = scaler.fit_transform(dados_norm[col].values.reshape(-1,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dados.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Splitting into X and Y variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = dados_norm.drop(['diagnosis'],axis=1)\nY = dados_norm['diagnosis']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Splitting sample into training and testing"},{"metadata":{"trusted":true},"cell_type":"code","source":"strat_kfold = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n\nfor indice_treino, indice_teste in strat_kfold.split(X, Y):\n    #print(\"Treino:\", indice_treino, \"Teste:\", indice_teste)\n    X_treino, X_teste = X.iloc[indice_treino], X.iloc[indice_teste]\n    Y_treino, Y_teste = Y.iloc[indice_treino], Y.iloc[indice_teste]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importing libraries to compute metrics"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix,accuracy_score,f1_score,average_precision_score,classification_report,recall_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using GridSearchCV to find the best inputs for Logistic Regression, KNN, SVC, Decision Tree, Random Forest, Ada Boost and Gradient Boosting"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nome_modelo = []\nresultados = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = []\nprecision =[]\nrecall = []\nf1 = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Logistic Regression\")\nlog_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.0001,0.001, 0.01, 0.1, 1, 10, 100, 1000,10000,100000], \n                  'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\ngrid_log_reg = GridSearchCV(LogisticRegression(max_iter=2000), log_reg_params,n_jobs=8,cv=10,scoring=['recall','f1'],refit='recall')\ngrid_log_reg.fit(X_treino, Y_treino)\nlogreg = grid_log_reg.best_estimator_\nlog_reg_score = cross_val_score(logreg, X_treino, Y_treino, cv=10,scoring='recall')\nprint(\"Best Estimator\")\nprint(logreg)\nprint('Score Regressao Logistica Validacao Cruzada: ', round(log_reg_score.mean() * 100, 2).astype(str) + '%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nome_modelo.append(\"Logistic Regression\")\nresultados.append(log_reg_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg.fit(X_treino,Y_treino)\nY_pred_logreg = logreg.predict(X_teste)\ncm_logreg = confusion_matrix(Y_teste,Y_pred_logreg)\nacc_score_logreg = accuracy_score(Y_teste,Y_pred_logreg)\nf1_score_logreg = f1_score(Y_teste,Y_pred_logreg)\nprecisao_logreg = average_precision_score(Y_teste,Y_pred_logreg)\nrecall_logreg = recall_score(Y_teste,Y_pred_logreg)\nprint('Acuracia Regressão Logistica ',round(acc_score_logreg*100,2).astype(str)+'%')\nprint('Precião média Regressão Logistica ',round(precisao_logreg*100,2).astype(str)+'%')\nprint('F1 Regressão Logistica ',round(f1_score_logreg*100,2).astype(str)+'%')\nprint('Recall Regressão Logistica ',round(recall_logreg*100,2).astype(str)+'%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy.append(acc_score_logreg)\nprecision.append(precisao_logreg)\nrecall.append(recall_logreg)\nf1.append(f1_score_logreg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,6))\nsns.heatmap(cm_logreg, ax=ax, annot=True, cmap=plt.cm.copper)\nax.set_title(\"Regressão Logistica \\n Matriz de Confusão\", fontsize=14)\nax.set_xticklabels(['B', 'M'], fontsize=14, rotation=0)\nax.set_yticklabels(['B', 'M'], fontsize=14, rotation=360)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"KNN\")\nknears_params = {\"n_neighbors\": list(range(5,40,1)), 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n                'leaf_size' : list(range(3,40,1))}\ngrid_knears = GridSearchCV(KNeighborsClassifier(), knears_params,n_jobs=8,cv=10,scoring=['recall','f1'],refit='recall')\ngrid_knears.fit(X_treino, Y_treino)\nknn = grid_knears.best_estimator_\nknears_score = cross_val_score(knn, X_treino, Y_treino, cv=10,scoring='recall')\nprint(\"Best Estimator\")\nprint(knn)\nprint('Score KNN Validacao Cruzada: ', round(knears_score.mean() * 100, 2).astype(str) + '%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nome_modelo.append(\"KNN\")\nresultados.append(knears_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn.fit(X_treino,Y_treino)\nY_pred_knn = knn.predict(X_teste)\ncm_knn = confusion_matrix(Y_teste,Y_pred_knn)\nacc_score_knn = accuracy_score(Y_teste,Y_pred_knn)\nf1_score_knn = f1_score(Y_teste,Y_pred_knn)\nprecisao_knn = average_precision_score(Y_teste,Y_pred_knn)\nrecall_knn = recall_score(Y_teste,Y_pred_knn)\nprint('Acuracia KNN ',round(acc_score_knn*100,2).astype(str)+'%')\nprint('Precião média KNN ',round(precisao_knn*100,2).astype(str)+'%')\nprint('F1 KNN ',round(f1_score_knn*100,2).astype(str)+'%')\nprint('Recall KNN ',round(recall_knn*100,2).astype(str)+'%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy.append(acc_score_knn)\nprecision.append(precisao_knn)\nrecall.append(recall_knn)\nf1.append(f1_score_knn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,6))\nsns.heatmap(cm_knn, ax=ax, annot=True, cmap=plt.cm.copper)\nax.set_title(\"KNN \\n Matriz de Confusão\", fontsize=14)\nax.set_xticklabels(['B', 'M'], fontsize=14, rotation=0)\nax.set_yticklabels(['B', 'M'], fontsize=14, rotation=360)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Ada Boost Classifier\")\nada_params = {'n_estimators' : [5,10,15,20,25,30,35,40,45,50,55,60,65,70,75,80], 'learning_rate' : [0.001,0.01,0.1,1.0], 'algorithm' : ['SAMME','SAMME.R']}\ngrid_ada = GridSearchCV(AdaBoostClassifier(), ada_params,n_jobs=8,cv=10,scoring=['recall','f1'],refit='recall')\ngrid_ada.fit(X_treino, Y_treino)\nada = grid_ada.best_estimator_\nprint(\"Best Estimator\")\nprint(ada)\nada_score = cross_val_score(ada, X_treino, Y_treino, cv=10,scoring='recall')\nprint('Score AdaBoost Validacao Cruzada: ', round(ada_score.mean() * 100, 2).astype(str) + '%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nome_modelo.append(\"AdaBoost\")\nresultados.append(ada_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ada.fit(X_treino,Y_treino)\nY_pred_ada = ada.predict(X_teste)\ncm_ada = confusion_matrix(Y_teste,Y_pred_ada)\nacc_score_ada = accuracy_score(Y_teste,Y_pred_ada)\nf1_score_ada = f1_score(Y_teste,Y_pred_ada)\nprecisao_ada = average_precision_score(Y_teste,Y_pred_ada)\nrecall_ada = recall_score(Y_teste,Y_pred_ada)\nprint('Acuracia ADA Boost ',round(acc_score_ada*100,2).astype(str)+'%')\nprint('Precião média Ada Boost ',round(precisao_ada*100,2).astype(str)+'%')\nprint('F1 Ada Boost ',round(f1_score_ada*100,2).astype(str)+'%')\nprint('Recall Ada Boost ',round(recall_ada*100,2).astype(str)+'%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy.append(acc_score_ada)\nprecision.append(precisao_ada)\nrecall.append(recall_ada)\nf1.append(f1_score_ada)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,6))\nsns.heatmap(cm_ada, ax=ax, annot=True, cmap=plt.cm.copper)\nax.set_title(\"Ada Boost \\n Matriz de Confusão\", fontsize=14)\nax.set_xticklabels(['B', 'M'], fontsize=14, rotation=0)\nax.set_yticklabels(['B', 'M'], fontsize=14, rotation=360)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Random Forest Classifier\")\nforest_params = {\"criterion\": [\"gini\", \"entropy\"], \"max_depth\": list(range(2,20,1)), \n              \"min_samples_leaf\": list(range(3,20,1)), 'max_features' : ['auto','sqrt','log2']}\nforest = GridSearchCV(RandomForestClassifier(), forest_params,n_jobs=8,cv=10,scoring=['recall','f1'],refit='recall')\nforest.fit(X_treino, Y_treino)\nrandom_forest = forest.best_estimator_\nprint(\"Best Estimator\")\nprint(random_forest)\nforest_score = cross_val_score(random_forest, X_treino, Y_treino, cv=10,scoring='recall')\nprint('Score RFC Validacao Cruzada: ', round(forest_score.mean() * 100, 2).astype(str) + '%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nome_modelo.append(\"RFC\")\nresultados.append(forest_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_forest.fit(X_treino,Y_treino)\nY_pred_rf = random_forest.predict(X_teste)\ncm_rf = confusion_matrix(Y_teste,Y_pred_rf)\nacc_score_rf = accuracy_score(Y_teste,Y_pred_rf)\nf1_score_rf = f1_score(Y_teste,Y_pred_rf)\nprecisao_rf = average_precision_score(Y_teste,Y_pred_rf)\nrecall_rf = recall_score(Y_teste,Y_pred_rf)\nprint('Acuracia Random Forest ',round(acc_score_rf*100,2).astype(str)+'%')\nprint('Precião média Random Forest ',round(precisao_rf*100,2).astype(str)+'%')\nprint('F1 Random Forest ',round(f1_score_rf*100,2).astype(str)+'%')\nprint('Recall Random Forest ',round(recall_rf*100,2).astype(str)+'%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy.append(acc_score_rf)\nprecision.append(precisao_rf)\nrecall.append(recall_rf)\nf1.append(f1_score_rf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,6))\nsns.heatmap(cm_rf, ax=ax, annot=True, cmap=plt.cm.copper)\nax.set_title(\"Random Forest \\n Matriz de Confusão\", fontsize=14)\nax.set_xticklabels(['B', 'M'], fontsize=14, rotation=0)\nax.set_yticklabels(['B', 'M'], fontsize=14, rotation=360)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Gradient Boost Classifier\")\ngrad_params = {'n_estimators' : [30,35,40,45,50,55,60,65,70], 'learning_rate' : [0.001,0.01,0.1,1.0], 'loss' : ['deviance','exponential'],\n              'max_depth' : [3,4,5,6,7], 'max_features' : ['auto','sqrt','log2'], 'min_samples_leaf' : [2,3,4,5,6]}\ngrad = GridSearchCV(GradientBoostingClassifier(), grad_params,n_jobs=8,cv=10,scoring=['recall','f1'],refit='recall')\ngrad.fit(X_treino, Y_treino)\ngrad_boost = grad.best_estimator_\nprint(\"Best Estimator\")\nprint(grad_boost)\ngrad_score = cross_val_score(grad_boost, X_treino, Y_treino, cv=10,scoring='recall')\nprint('Score GradBoost Validacao Cruzada: ', round(grad_score.mean() * 100, 2).astype(str) + '%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nome_modelo.append(\"GradBoost\")\nresultados.append(grad_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grad_boost.fit(X_treino,Y_treino)\nY_pred_gb = grad_boost.predict(X_teste)\ncm_gb = confusion_matrix(Y_teste,Y_pred_gb)\nacc_score_gb = accuracy_score(Y_teste,Y_pred_gb)\nf1_score_gb = f1_score(Y_teste,Y_pred_gb)\nprecisao_gb = average_precision_score(Y_teste,Y_pred_gb)\nrecall_gb = recall_score(Y_teste,Y_pred_gb)\nprint('Acuracia Gradient Boosting ',round(acc_score_gb*100,2).astype(str)+'%')\nprint('Precião média Gradient Boosting  ',round(precisao_gb*100,2).astype(str)+'%')\nprint('F1 Gradient Boosting  ',round(f1_score_gb*100,2).astype(str)+'%')\nprint('Recall Gradient Boosting  ',round(recall_gb*100,2).astype(str)+'%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy.append(acc_score_gb)\nprecision.append(precisao_gb)\nrecall.append(recall_gb)\nf1.append(f1_score_gb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,6))\nsns.heatmap(cm_gb, ax=ax, annot=True, cmap=plt.cm.copper)\nax.set_title(\"Gradient Boosting  \\n Matriz de Confusão\", fontsize=14)\nax.set_xticklabels(['B', 'M'], fontsize=14, rotation=0)\nax.set_yticklabels(['B', 'M'], fontsize=14, rotation=360)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Boxplot of the average score of each model"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots(figsize=(10,7))\nplt.boxplot(resultados)\nax.set_xticklabels(nome_modelo)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Up to this point logistic regression and AdaBoost are the best models"},{"metadata":{},"cell_type":"markdown","source":"Up to this point logistic regression and AdaBoost are the best models"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Activation\nfrom keras.layers.core import Dense,Dropout\nfrom keras.optimizers import Adam\nfrom keras.metrics import categorical_crossentropy\nfrom keras.callbacks import ReduceLROnPlateau,EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_inputs = X_treino.shape[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelo = Sequential()\nmodelo.add(Dense(32, input_shape=(n_inputs, ), activation='relu', kernel_initializer='glorot_uniform',bias_initializer='zeros'))\nmodelo.add(Dense(64, activation='relu', kernel_initializer='glorot_uniform',bias_initializer='zeros'))\nmodelo.add(Dropout(0.5))\nmodelo.add(Dense(64, activation='relu', kernel_initializer='glorot_uniform',bias_initializer='zeros'))\nmodelo.add(Dense(32, activation='relu', kernel_initializer='glorot_uniform',bias_initializer='zeros'))\nmodelo.add(Dropout(0.5))\nmodelo.add(Dense(2, activation='softmax', kernel_initializer='glorot_uniform',bias_initializer='zeros'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=0.5, mode='auto', min_delta=0.0001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"callbacks_list = [reduce_lr,es]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelo.compile(Adam(lr=0.01), loss='sparse_categorical_crossentropy', metrics=['top_k_categorical_accuracy'])\nmodelo.fit(X_treino, Y_treino, batch_size=20, epochs=200, verbose=2, validation_data=(X_teste,Y_teste),callbacks=callbacks_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred_keras = modelo.predict_classes(X_teste, batch_size=50, verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm_keras = confusion_matrix(Y_teste,Y_pred_keras)\nacc_score_keras = accuracy_score(Y_teste,Y_pred_keras)\nf1_score_keras = f1_score(Y_teste,Y_pred_keras)\nprecisao_keras = average_precision_score(Y_teste,Y_pred_keras)\nrecall_keras = recall_score(Y_teste,Y_pred_keras)\nprint('Acuracia Keras ',round(acc_score_keras*100,2).astype(str)+'%')\nprint('Precião média Keras  ',round(precisao_keras*100,2).astype(str)+'%')\nprint('F1 Gradient Boosting  ',round(f1_score_keras*100,2).astype(str)+'%')\nprint('Recall Keras  ',round(recall_keras*100,2).astype(str)+'%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nome_modelo.append(\"Keras\")\naccuracy.append(acc_score_keras)\nprecision.append(precisao_keras)\nrecall.append(recall_keras)\nf1.append(f1_score_keras)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,6))\nsns.heatmap(cm_keras, ax=ax, annot=True, cmap=plt.cm.copper)\nax.set_title(\"Keras  \\n Matriz de Confusão\", fontsize=14)\nax.set_xticklabels(['B', 'M'], fontsize=14, rotation=0)\nax.set_yticklabels(['B', 'M'], fontsize=14, rotation=360)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Keras had similar behavior compared to the other models. Deep learning models are not required up to this point to categorize the cancer type"},{"metadata":{},"cell_type":"markdown","source":"Choosing the K best features in order to best the performance of each model and remove features that are causing troubles to the models to get the best result"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest,chi2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dados['diagnosis'] = enconder.fit_transform(dados['diagnosis'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = dados.drop(['diagnosis'],axis=1)\nY = dados['diagnosis']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_params(model):\n    if(model == 'logistic_regression'):\n        modelo = LogisticRegression(max_iter=2000)\n        modelo_params = {\"penalty\": ['l1', 'l2'], 'C': [0.0001,0.001, 0.01, 0.1, 1, 10, 100, 1000,10000,100000], \n                  'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n    \n    elif(model == 'KNN'):\n        modelo = KNeighborsClassifier()\n        modelo_params = {\"n_neighbors\": list(range(5,40,1)), 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n                'leaf_size' : list(range(2,40,1))}\n    \n    elif(model == 'AdaBoost'):\n        modelo = AdaBoostClassifier()\n        modelo_params = {'n_estimators' : list(range(5,81)), 'learning_rate' : [0.001,0.01,0.1,1.0], 'algorithm' : ['SAMME','SAMME.R']}\n        \n    elif(model == 'RFC'):\n        modelo = RandomForestClassifier()\n        modelo_params = {\"criterion\": [\"gini\", \"entropy\"], \"max_depth\": list(range(2,20,1)), \n              \"min_samples_leaf\": list(range(3,20,1)), 'max_features' : ['auto','sqrt','log2']}\n        \n    elif(model == 'GradBoost'):\n        modelo = GradientBoostingClassifier()\n        modelo_params = {'n_estimators' : [30,35,40,45,50,55,60,65,70], 'learning_rate' : [0.001,0.01,0.1,1.0], 'loss' : ['deviance','exponential'],\n              'max_depth' : [3,4,5,6,7], 'max_features' : ['auto','sqrt','log2'], 'min_samples_leaf' : [2,3,4,5,6]}\n    \n    return modelo,modelo_params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_best_features(modelo,X,Y,n):\n    X_treino, X_teste, Y_treino, Y_teste = train_test_split(X, Y, test_size=0.3, random_state=42)\n    best_features = SelectKBest(chi2, k=n).fit(X_treino, Y_treino)\n    X_treino = best_features.transform(X_treino)\n    X_teste = best_features.transform(X_teste)\n    acc,precision,recall,f1 = best_model(modelo,X_treino,Y_treino,X_teste,Y_teste)\n    \n    return acc, precision, recall, f1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def best_model(model,X_treino_best,Y_treino_best,X_teste,Y_teste):\n    \n    modelo, parametros = model_params(model)\n    grid_log_reg = GridSearchCV(modelo, parametros,n_jobs=8,cv=10,scoring=['recall','f1'],refit='f1')\n    grid_log_reg.fit(X_treino_best, Y_treino_best)\n    logreg = grid_log_reg.best_estimator_\n    logreg.fit(X_treino_best,Y_treino_best)\n    Y_pred_Kbest = logreg.predict(X_teste)\n    acc_kest = accuracy_score(Y_teste,Y_pred_Kbest)\n    f1_kbest = f1_score(Y_teste,Y_pred_Kbest)\n    precisao_kbest = average_precision_score(Y_teste,Y_pred_Kbest)\n    recall_kbest = recall_score(Y_teste,Y_pred_Kbest)\n    \n    return acc_kest,precisao_kbest,recall_kbest,f1_kbest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_bestn(modelo,X,Y,number):\n\n    acc_findbest = []\n    rec_findbest = []\n    prec_findbest = []\n    f1s_findbest= []\n    n_idex = []\n\n    for n in range(5,number):\n        acuraciax,precisaox,recallx,f1x = find_best_features(modelo,X,Y,n)\n        acc_findbest.append(acuraciax)\n        rec_findbest.append(recallx)\n        prec_findbest.append(precisaox)\n        f1s_findbest.append(f1x)\n        n_idex.append(n)\n        print(\"N = \",n,\"Acc = \",acuraciax, \"Prec = \",precisaox, \"Rec = \",recallx, \"F1 = \",f1x)\n    \n    dic_kbest = {\"N\" : n_idex, \"Acuracia\" : acc_findbest, \"Recall\" : rec_findbest, \"Precision\" : prec_findbest, \"F1\" : f1s_findbest}\n\n    dataframe_kbest = pd.DataFrame(dic_kbest)\n    \n    dataframe_kbest = dataframe_kbest.sort_values(by=['Acuracia','Recall','F1','Precision'],ascending=False).reset_index()\n    \n    best_n = int(dataframe_kbest.iloc[0]['N'])\n    \n    return best_n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelos = ['logistic_regression']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dic_bestn = {}\n\nfor models in modelos:\n    bestn = find_bestn(models,X,Y,num_colunas-1)\n    dic_bestn[models] = bestn\n    print(\"Modelo = \",models,\" \",\"N = \",bestn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_treino_best, X_teste_best, Y_treino_best, Y_teste_best = train_test_split(X, Y, test_size=0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_n = dic_bestn['logistic_regression']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the 30 features from this dataset only 12 of them are really important. We will from this point choose only these 14 features and see how the models are improved"},{"metadata":{"trusted":true},"cell_type":"code","source":"modelo_kbest = SelectKBest(chi2, k=int(best_n)).fit(X_treino_best, Y_treino_best)\nX_treino_best = modelo_kbest.transform(X_treino_best)#.values\nX_teste_best = modelo_kbest.transform(X_teste_best)#.values\nY_treino_best = Y_treino_best.values\nY_teste_best = Y_teste_best.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_kbest = []\nprecison_kbest =[]\nrecall_kbest = []\nf1_kbest = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.0001,0.001, 0.01, 0.1, 1, 10, 100, 1e3,1e4], \n                  'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\ngrid_log_reg = GridSearchCV(LogisticRegression(max_iter=2000), log_reg_params,n_jobs=8,cv=10,scoring=['recall','f1'],refit='f1')\ngrid_log_reg.fit(X_treino_best, Y_treino_best)\nlogreg = grid_log_reg.best_estimator_\nlogreg.fit(X_treino_best,Y_treino_best)\nY_pred_best = logreg.predict(X_teste_best)\ncm_best = confusion_matrix(Y_teste_best,Y_pred_best)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,6))\nsns.heatmap(cm_best, ax=ax, annot=True, cmap=plt.cm.copper)\nax.set_title(\"Regressão logistica  \\n Matriz de Confusão\", fontsize=14)\nax.set_xticklabels(['B', 'M'], fontsize=14, rotation=0)\nax.set_yticklabels(['B', 'M'], fontsize=14, rotation=360)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_score_logreg_best = accuracy_score(Y_teste_best,Y_pred_best)\nf1_score_logreg_best = f1_score(Y_teste_best,Y_pred_best)\nprecisao_logreg_best = average_precision_score(Y_teste_best,Y_pred_best)\nrecall_logreg_best = recall_score(Y_teste_best,Y_pred_best)\nprint('Acuracia Regressão Logistica ',round(acc_score_logreg_best*100,2).astype(str)+'%')\nprint('Precião média Regressão Logistica ',round(precisao_logreg_best*100,2).astype(str)+'%')\nprint('F1 Regressão Logistica ',round(f1_score_logreg_best*100,2).astype(str)+'%')\nprint('Recall Regressão Logistica ',round(recall_logreg_best*100,2).astype(str)+'%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_kbest.append(acc_score_logreg_best)\nprecison_kbest.append(precisao_logreg_best)\nrecall_kbest.append(recall_logreg_best)\nf1_kbest.append(f1_score_logreg_best)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knears_params = {\"n_neighbors\": list(range(5,40,1)), 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n                'leaf_size' : list(range(2,40,1))}\ngrid_knears = GridSearchCV(KNeighborsClassifier(), knears_params,n_jobs=8,cv=10,scoring=['recall','f1'],refit='recall')\ngrid_knears.fit(X_treino_best, Y_treino_best)\nknn = grid_knears.best_estimator_\nknn.fit(X_treino_best,Y_treino_best)\nY_pred_best_knn = knn.predict(X_teste_best)\ncm_best_knn = confusion_matrix(Y_teste_best,Y_pred_best_knn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,6))\nsns.heatmap(cm_best_knn, ax=ax, annot=True, cmap=plt.cm.copper)\nax.set_title(\"KNN  \\n Matriz de Confusão\", fontsize=14)\nax.set_xticklabels(['B', 'M'], fontsize=14, rotation=0)\nax.set_yticklabels(['B', 'M'], fontsize=14, rotation=360)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_score_knn = accuracy_score(Y_teste_best,Y_pred_best_knn)\nf1_score_knn = f1_score(Y_teste_best,Y_pred_best_knn)\nprecisao_knn = average_precision_score(Y_teste_best,Y_pred_best_knn)\nrecall_knn = recall_score(Y_teste_best,Y_pred_best_knn)\nprint('Acuracia KNN ',round(acc_score_knn*100,2).astype(str)+'%')\nprint('Precião média KNN ',round(precisao_knn*100,2).astype(str)+'%')\nprint('F1 KNN ',round(f1_score_knn*100,2).astype(str)+'%')\nprint('Recall KNN ',round(recall_knn*100,2).astype(str)+'%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_kbest.append(acc_score_knn)\nprecison_kbest.append(precisao_knn)\nrecall_kbest.append(recall_knn)\nf1_kbest.append(f1_score_knn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ada_params = {'n_estimators' : list(range(5,81)), 'learning_rate' : [0.001,0.01,0.1,1.0], 'algorithm' : ['SAMME','SAMME.R']}\ngrid_ada = GridSearchCV(AdaBoostClassifier(), ada_params,n_jobs=8,cv=10,scoring=['recall','f1'],refit='f1')\ngrid_ada.fit(X_treino_best, Y_treino_best)\nada = grid_ada.best_estimator_\nada.fit(X_treino_best,Y_treino_best)\nY_pred_best_ada = ada.predict(X_teste_best)\ncm_best_ada = confusion_matrix(Y_teste_best,Y_pred_best_ada)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,6))\nsns.heatmap(cm_best_ada, ax=ax, annot=True, cmap=plt.cm.copper)\nax.set_title(\"Ada Boost  \\n Matriz de Confusão\", fontsize=14)\nax.set_xticklabels(['B', 'M'], fontsize=14, rotation=0)\nax.set_yticklabels(['B', 'M'], fontsize=14, rotation=360)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_score_ada_best = accuracy_score(Y_teste_best,Y_pred_best_ada)\nf1_score_ada_best = f1_score(Y_teste_best,Y_pred_best_ada)\nprecisao_ada_best = average_precision_score(Y_teste_best,Y_pred_best_ada)\nrecall_ada_best = recall_score(Y_teste_best,Y_pred_best_ada)\nprint('Acuracia Ada Boost ',round(acc_score_ada_best*100,2).astype(str)+'%')\nprint('Precião média Ada Boost ',round(precisao_ada_best*100,2).astype(str)+'%')\nprint('F1 Ada Boost ',round(f1_score_ada_best*100,2).astype(str)+'%')\nprint('Recall Ada Boost ',round(recall_ada_best*100,2).astype(str)+'%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_kbest.append(acc_score_ada_best)\nprecison_kbest.append(precisao_ada_best)\nrecall_kbest.append(recall_ada_best)\nf1_kbest.append(f1_score_ada_best)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forest_params = {\"criterion\": [\"gini\", \"entropy\"], \"max_depth\": list(range(2,20,1)), \n              \"min_samples_leaf\": list(range(3,20,1)), 'max_features' : ['auto','sqrt','log2']}\nforest = GridSearchCV(RandomForestClassifier(), forest_params,n_jobs=8,cv=10,scoring=['recall','f1'],refit='recall')\nforest.fit(X_treino_best, Y_treino_best)\nrandom_forest = forest.best_estimator_\nrandom_forest.fit(X_treino_best,Y_treino_best)\nY_pred_best_rf = random_forest.predict(X_teste_best)\ncm_best_rf = confusion_matrix(Y_teste_best,Y_pred_best_rf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,6))\nsns.heatmap(cm_best_rf, ax=ax, annot=True, cmap=plt.cm.copper)\nax.set_title(\"Random Forest  \\n Matriz de Confusão\", fontsize=14)\nax.set_xticklabels(['B', 'M'], fontsize=14, rotation=0)\nax.set_yticklabels(['B', 'M'], fontsize=14, rotation=360)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_score_rf_best = accuracy_score(Y_teste_best,Y_pred_best_rf)\nf1_score_rf_best = f1_score(Y_teste_best,Y_pred_best_rf)\nprecisao_rf_best = average_precision_score(Y_teste_best,Y_pred_best_rf)\nrecall_rf_best = recall_score(Y_teste_best,Y_pred_best_rf)\nprint('Acuracia Random Forest ',round(acc_score_rf_best*100,2).astype(str)+'%')\nprint('Precião média Random Forest ',round(precisao_rf_best*100,2).astype(str)+'%')\nprint('F1 Random Forest ',round(f1_score_rf_best*100,2).astype(str)+'%')\nprint('Recall Random Forest ',round(recall_rf_best*100,2).astype(str)+'%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_kbest.append(acc_score_rf_best)\nprecison_kbest.append(precisao_rf_best)\nrecall_kbest.append(recall_rf_best)\nf1_kbest.append(f1_score_rf_best)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grad_params = {'n_estimators' : [30,35,40,45,50,55,60,65,70], 'learning_rate' : [0.001,0.01,0.1,1.0], 'loss' : ['deviance','exponential'],\n              'max_depth' : [3,4,5,6,7], 'max_features' : ['auto','sqrt','log2'], 'min_samples_leaf' : [2,3,4,5,6]}\ngrad = GridSearchCV(GradientBoostingClassifier(), grad_params,n_jobs=8,cv=10,scoring=['recall','f1'],refit='recall')\ngrad.fit(X_treino_best, Y_treino_best)\ngrad_boost = grad.best_estimator_\ngrad_boost.fit(X_treino_best,Y_treino_best)\nY_pred_best_grad = grad_boost.predict(X_teste_best)\ncm_best_grad = confusion_matrix(Y_teste_best,Y_pred_best_grad)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,6))\nsns.heatmap(cm_best_grad, ax=ax, annot=True, cmap=plt.cm.copper)\nax.set_title(\"Gradient Boosting  \\n Matriz de Confusão\", fontsize=14)\nax.set_xticklabels(['B', 'M'], fontsize=14, rotation=0)\nax.set_yticklabels(['B', 'M'], fontsize=14, rotation=360)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_score_grad_best = accuracy_score(Y_teste_best,Y_pred_best_grad)\nf1_score_grad_best = f1_score(Y_teste_best,Y_pred_best_grad)\nprecisao_grad_best = average_precision_score(Y_teste_best,Y_pred_best_grad)\nrecall_grad_best = recall_score(Y_teste_best,Y_pred_best_grad)\nprint('Acuracia Random Forest ',round(acc_score_grad_best*100,2).astype(str)+'%')\nprint('Precião média Random Forest ',round(precisao_grad_best*100,2).astype(str)+'%')\nprint('F1 Random Forest ',round(f1_score_grad_best*100,2).astype(str)+'%')\nprint('Recall Random Forest ',round(recall_grad_best*100,2).astype(str)+'%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_kbest.append(acc_score_grad_best)\nprecison_kbest.append(precisao_grad_best)\nrecall_kbest.append(recall_grad_best)\nf1_kbest.append(f1_score_grad_best)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_inputs = X_treino_best.shape[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelo2 = Sequential()\nmodelo2.add(Dense(32, input_shape=(n_inputs, ), activation='relu', kernel_initializer='glorot_uniform',bias_initializer='zeros'))\nmodelo2.add(Dense(64, activation='relu', kernel_initializer='glorot_uniform',bias_initializer='zeros'))\nmodelo2.add(Dropout(0.5))\nmodelo2.add(Dense(64, activation='relu', kernel_initializer='glorot_uniform',bias_initializer='zeros'))\nmodelo2.add(Dense(32, activation='relu', kernel_initializer='glorot_uniform',bias_initializer='zeros'))\nmodelo2.add(Dropout(0.5))\nmodelo2.add(Dense(2, activation='softmax', kernel_initializer='glorot_uniform',bias_initializer='zeros'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelo2.compile(Adam(lr=0.01), loss='sparse_categorical_crossentropy', metrics=['top_k_categorical_accuracy'])\nmodelo2.fit(X_treino_best, Y_treino_best, batch_size=20, epochs=200, verbose=2, validation_data=(X_teste_best,Y_teste_best),callbacks=callbacks_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred_keras = modelo2.predict_classes(X_teste_best, batch_size=50, verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm_keras = confusion_matrix(Y_teste_best,Y_pred_keras)\nacc_score_keras = accuracy_score(Y_teste_best,Y_pred_keras)\nf1_score_keras = f1_score(Y_teste_best,Y_pred_keras)\nprecisao_keras = average_precision_score(Y_teste_best,Y_pred_keras)\nrecall_keras = recall_score(Y_teste_best,Y_pred_keras)\nprint('Acuracia Keras ',round(acc_score_keras*100,2).astype(str)+'%')\nprint('Precião média Keras  ',round(precisao_keras*100,2).astype(str)+'%')\nprint('F1 Gradient Boosting  ',round(f1_score_keras*100,2).astype(str)+'%')\nprint('Recall Keras  ',round(recall_keras*100,2).astype(str)+'%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_kbest.append(acc_score_keras)\nprecison_kbest.append(precisao_keras)\nrecall_kbest.append(recall_keras)\nf1_kbest.append(f1_score_keras)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dic_metrics = {'Model' : nome_modelo, 'Accuracy' : accuracy, 'Precision' : precision, 'Recall' : recall, 'F1' : f1, \n              'Accuracy_Kbest' : acc_kbest, 'Precision_Kbest' : precison_kbest, 'Recall_Kbest' : recall_kbest,\n              'F1_Kbest' : f1_kbest}\n\ndataframe = pd.DataFrame(dic_metrics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframe","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Except Keras, all other models have reached better accuracies demonstranting that remove the not necessary features plays an important role in my models"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}