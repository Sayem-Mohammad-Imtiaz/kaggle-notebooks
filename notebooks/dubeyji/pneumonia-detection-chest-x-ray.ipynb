{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.densenet import DenseNet121\nfrom keras.layers import Dense, GlobalAveragePooling2D, Conv2D, MaxPooling2D, Flatten, Activation, Dropout, BatchNormalization\nfrom keras.models import Sequential\nfrom keras.models import Model\nfrom keras import backend as K\n\nfrom keras.models import load_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = ['Pneumonia', 'Normal']\nbatch_size = 16\n\n# this is the augmentation configuration we will use for testing:\n# only rescaling\ntrain_datagen = ImageDataGenerator(\n        rotation_range = 0.2,\n        shear_range=0.2)\ntest_datagen = ImageDataGenerator()\n# this is a generator that will read pictures found in\n# subfolers of 'data/train', and indefinitely generate\n# batches of augmented image data\ntrain_generator = train_datagen.flow_from_directory(\n        '/kaggle/input/chest-xray-pneumonia/chest_xray/train',  # this is the target directory\n        target_size=(320, 320),  \n        batch_size=batch_size,\n        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n\n# this is a similar generator, for validation data\nvalidation_generator = test_datagen.flow_from_directory(\n        '/kaggle/input/chest-xray-pneumonia/chest_xray/val',\n        target_size=(320, 320),\n        batch_size=batch_size,\n        class_mode='binary')\n\n# this is a similar generator, for validation data\ntest_generator = test_datagen.flow_from_directory(\n        '/kaggle/input/chest-xray-pneumonia/chest_xray/test',\n        target_size=(320, 320),\n        batch_size=batch_size,\n        class_mode='binary')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plots(ims, figsize=(32,32), rows=1, interp=False, titles=None):\n    if type(ims[0]) is np.ndarray:\n        ims = np.array(ims).astype(np.uint8)\n        \n    f = plt.figure(figsize=figsize)\n    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n\n    for i in range(len(ims)):\n        sp = f.add_subplot(cols, rows, i+1)\n        sp.axis('Off')\n        if titles is not None:\n            sp.set_title(titles[i], fontsize=12)\n        plt.imshow(ims[i], interpolation=None if interp else 'none')\n\n#########################################################################\n\n#Check the training set (with batch of 10 as defined above\nimgs, labels = next(train_generator)\n\n#Images are shown in the output\nplots(imgs, titles=labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = train_generator.labels\nN = labels.shape[0]\n\npositive_frequencies = np.sum(labels, axis=0) / N\nnegative_frequencies = 1 - positive_frequencies","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pos_weights = negative_frequencies\nneg_weights = positive_frequencies\npos_contribution = positive_frequencies * pos_weights \nneg_contribution = negative_frequencies * neg_weights","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dense_net = DenseNet121(weights = '../input/densenet/densenet.hdf5', include_top=False, input_shape=(320,320,3))\nfor layer in dense_net.layers:\n    layer.trainable = False\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model 1:Baseline(No pretrained model used)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=(320,320,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(2, 2))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(2, 2))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(2, 2))\nmodel.add(Dropout(0.2))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation=\"relu\"))\n\nmodel.add(Dense(1))\nmodel.add(Activation(\"sigmoid\"))\n\nmodel.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(train_generator, \n                              validation_data=validation_generator,\n                              steps_per_epoch = len(train_generator.labels)/batch_size,\n                              validation_steps= len(validation_generator.labels)/batch_size,\n                              epochs=10,\n                             verbose=1,\n                             class_weight = {0:neg_weights, 1:pos_weights})\n\nplt.plot(history.history['loss'])\nplt.ylabel(\"loss\")\nplt.xlabel(\"epoch\")\nplt.title(\"Training Loss Curve\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Accuracy \nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Training set', 'Validation set'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Accuracy \nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Training set', 'Validation set'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_vals = model.predict_generator(test_generator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ntick_labels = ['Normal', 'Pneumonia']\n\ncm = confusion_matrix(test_generator.labels, predicted_vals> 0.5)\nax = sns.heatmap(cm, annot=True, fmt=\"d\")\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nax.set_xticklabels(tick_labels)\nax.set_yticklabels(tick_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve, roc_auc_score\nfp, tp, _ = roc_curve(test_generator.labels, predicted_vals)\n\nplt.plot(fp, tp, label='ROC', linewidth=3)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.plot(\n  [0, 1], [0, 1], \n  linestyle='--', \n  linewidth=2, \n  color='r',\n  label='Chance', \n  alpha=.8\n)\nplt.grid(True)\nax = plt.gca()\nax.set_aspect('equal')\nplt.legend(loc=\"lower right\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve, auc\nprecision, recall, threshold = precision_recall_curve(test_generator.labels, predicted_vals)\n# plot the model precision-recall curve\nplt.plot(recall, precision, label='PR')\n# axis labels\nplt.xlabel('Recall')\nplt.ylabel('Precision')\n# show the legend\nplt.legend()\n# show the plot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc_score = auc(recall, precision)\nauc_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Same model with Dense added on top","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(dense_net)\nmodel.add(Conv2D(32, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(2, 2))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(2, 2))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(2, 2))\nmodel.add(Dropout(0.2))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation=\"relu\"))\n\nmodel.add(Dense(1))\nmodel.add(Activation(\"sigmoid\"))\n\nmodel.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(train_generator, \n                              validation_data=validation_generator,\n                              steps_per_epoch = len(train_generator.labels)/batch_size,\n                              validation_steps= len(validation_generator.labels)/batch_size,\n                              epochs=10,\n                             verbose=1,\n                             class_weight = {0:neg_weights, 1:pos_weights})\n\nplt.plot(history.history['loss'])\nplt.ylabel(\"loss\")\nplt.xlabel(\"epoch\")\nplt.title(\"Training Loss Curve\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Accuracy \nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Training set', 'Validation set'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Accuracy \nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Training set', 'Validation set'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_vals = model.predict_generator(test_generator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ntick_labels = ['Normal', 'Pneumonia']\n\ncm = confusion_matrix(test_generator.labels, predicted_vals> 0.5)\nax = sns.heatmap(cm, annot=True, fmt=\"d\")\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nax.set_xticklabels(tick_labels)\nax.set_yticklabels(tick_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve, roc_auc_score\nfp, tp, _ = roc_curve(test_generator.labels, predicted_vals)\n\nplt.plot(fp, tp, label='ROC', linewidth=3)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.plot(\n  [0, 1], [0, 1], \n  linestyle='--', \n  linewidth=2, \n  color='r',\n  label='Chance', \n  alpha=.8\n)\nplt.grid(True)\nax = plt.gca()\nax.set_aspect('equal')\nplt.legend(loc=\"lower right\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve, auc\nprecision, recall, threshold = precision_recall_curve(test_generator.labels, predicted_vals)\n# plot the model precision-recall curve\nplt.plot(recall, precision, label='PR')\n# axis labels\nplt.xlabel('Recall')\nplt.ylabel('Precision')\n# show the legend\nplt.legend()\n# show the plot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc_score = auc(recall, precision)\nauc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}