{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2761273b-4d69-6745-ce12-c4ef117a28ed"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d1a78884-239d-84a8-11b2-9a59abfded40"},"outputs":[],"source":"#Import the files you want to work with\n#dfchat = pd.read_csv('../input/chat.csv')\n#dfhn = pd.read_csv('../input/hero_names.csv')\ndfmatch = pd.read_csv('../input/match.csv')\n#dfobjectives = pd.read_csv('../input/objectives.csv')\n#dfplt = pd.read_csv('../input/player_time.csv')\n#dfpl = pd.read_csv('../input/players.csv')\n#dftf = pd.read_csv('../input/teamfights.csv')\n#dftfp = pd.read_csv('../input/teamfights_players.csv')\n#dftl = pd.read_csv('../input/test_labels.csv')\n#dftp = pd.read_csv('../input/test_player.csv')\ndfpurl = pd.read_csv('../input/purchase_log.csv')\n#dfabil = pd.read_csv('../input/ability_upgrades.csv')\n#dfabilid = pd.read_csv('../input/ability_ids.csv')\n\nprint(\"ok\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"e7c82738-f96e-fc45-966d-61ed9f0b32a4"},"source":"Here, concatenate the files into one. tried 6 files and kernel kept crashing for exceeding memory limit.  So really can only concatenate 2 -3 files for analysis. Change the choices as desired by un-commenting the imports and listing your choices in the concatenate code line"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"654d2277-f5dc-79c5-ef61-b2a33168aea8"},"outputs":[],"source":"dfpurl.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c6a49420-dc95-ec44-1af5-2a262b7a44cc"},"outputs":[],"source":"dfmatch.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3f7a8af5-43a8-d6a4-f9e3-f6dda4cf66e5"},"outputs":[],"source":"dftf.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"70aac253-26c6-4efa-2108-e6de36026fe2"},"outputs":[],"source":"dftfp.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ae39fb99-48f5-26c9-2e1b-9e581b773802"},"outputs":[],"source":"total = pd.concat([dfmatch,dfpurl], axis=0)\nprint(\"done\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ffea4ba9-62cb-bcf4-f50c-2d7341d2b490"},"outputs":[],"source":"print (\"The new total dataset has {} data points with {} variables each.\" .format(*total.shape))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ce07d47a-2006-de36-939c-5494f41f5684"},"outputs":[],"source":"total.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"43ae2552-fedb-e462-bac0-50c690dd1a78"},"outputs":[],"source":"total.shape"},{"cell_type":"markdown","metadata":{"_cell_guid":"068b84bd-57f8-37e9-5f45-d9be0a35d7a1"},"source":"Show all columns by name with NaN values as a Boolean true or false"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"99632819-6cc3-95fa-8edd-a5a1027bbf01"},"outputs":[],"source":"pd.isnull(total).sum() > 0"},{"cell_type":"markdown","metadata":{"_cell_guid":"b60f1207-777d-cb03-cca1-8ef84ce6ccc0"},"source":"Now get rid of NaNs below"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4bceac42-4455-a6ee-af33-abeac31df01e"},"outputs":[],"source":"total.fillna(0)\n#total = total.fillna(total.mean()) use this if you want to fill the NaN columns with mean of column not zero"},{"cell_type":"markdown","metadata":{"_cell_guid":"14e61ba3-d7f2-6c44-5423-2af83fe55719"},"source":"Let's change the Boolean True and False in radiant_win to 1 and 0's and make existing zeros to 3 to avaoid confusion with them being Falses"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"452c1283-3327-a230-f93d-9daa569b346f"},"outputs":[],"source":"total.loc[total[\"radiant_win\"] == \"False\", \"radiant_win\"] = 0\ntotal.loc[total[\"radiant_win\"] == \"True\", \"radiant_win\"] = 1\ntotal[\"radiant_win\"] = total[\"radiant_win\"].fillna(\"3\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"56d7b426-2ba8-bcd6-33dc-a3b8a793c6a9"},"outputs":[],"source":"print(total[\"radiant_win\"].unique())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3d55b3bc-9518-2386-43cb-403463e3b49c"},"outputs":[],"source":"import colorsys\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nfrom sklearn.ensemble import (RandomForestClassifier, ExtraTreesClassifier,\n                              AdaBoostClassifier)\nfrom sklearn.externals.six.moves import xrange\nfrom sklearn.tree import DecisionTreeClassifier\n%matplotlib inline\nprint(\"done\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"64597c9c-bd31-2aef-7262-547f8b6f5d27"},"outputs":[],"source":"fig,ax = plt.subplots(figsize=(8,5))\ntotal['deaths'].value_counts(sort=False).plot(kind='bar',ax=ax,rot =90)\nplt.title('deaths Distribution',fontsize=15)\nplt.xlabel('deaths',fontsize=15)\nplt.ylabel('negative_votes',fontsize=15)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"db68a17e-abd4-6098-8aa6-b4150c2f02ef"},"outputs":[],"source":"duration = Counter(total['duration'].dropna().tolist()).most_common(10)\nduration_name = [name[0] for name in duration]\nduration_counts = [name[1] for name in duration]\n\nfig,ax = plt.subplots(figsize=(8,5))\nsns.barplot(x=duration_name,y=duration_counts,ax=ax)\nplt.title('Top ten duration',fontsize=15)\nplt.xlabel('duration',fontsize=15)\nplt.ylabel('first_blood_time',fontsize=15)\nticks = plt.setp(ax.get_xticklabels(),fontsize=15,rotation=60)"},{"cell_type":"markdown","metadata":{"_cell_guid":"efff0166-df6d-dcd9-b78e-3c43d80a2182"},"source":"Let's see if buybacks correlates with any of the other columns. 1.0 = correlation and -1 is a negative correlation"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6ae49073-5977-c322-0ed5-1641f7761835"},"outputs":[],"source":"total.corr()['buybacks']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fedb5b61-1ce8-98fc-5649-615264c5dae0"},"outputs":[],"source":"total.corr()['gold_delta']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1773d140-921d-aba4-b9c4-491df1b17372"},"outputs":[],"source":"total.corr()['game_mode']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4f559f16-722e-a65d-0e6e-abb64d5b3825"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nfrom sklearn import cross_validation\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.cross_validation import ShuffleSplit\nfrom IPython.display import display\n%matplotlib inline\nprint(\"ok\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d516b79a-aa16-ba49-f965-67cce9e419d7"},"outputs":[],"source":"#this code crashed the kernel for timing out\n#pd.scatter_matrix(total, alpha = 0.3,figsize = (20,20), diagonal = 'kde');"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b5c62a61-0ec9-64f0-8c99-6469d1dcb732"},"outputs":[],"source":"#this code crashed the kernal for exceeding memory\n#total.plot.box()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b73a51b0-5d42-f64e-47db-62c34da5e268"},"outputs":[],"source":"from matplotlib.colors import ListedColormap\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import make_moons, make_circles, make_classification\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"84885e85-c668-fcd4-f8c7-0ec4a4ad8440"},"outputs":[],"source":"h = .02  # step size in the mesh\n\nnames = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n         \"Naive Bayes\", \"QDA\"]\n\nclassifiers = [\n    KNeighborsClassifier(3),\n    SVC(kernel=\"linear\", C=0.025),\n    SVC(gamma=2, C=1),\n    GaussianProcessClassifier(1.0 * RBF(1.0), warm_start=True),\n    DecisionTreeClassifier(max_depth=5),\n    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n    MLPClassifier(alpha=1),\n    AdaBoostClassifier(),\n    GaussianNB(),\n    QuadraticDiscriminantAnalysis()]\n\nX, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n                           random_state=1, n_clusters_per_class=1)\nrng = np.random.RandomState(2)\nX += 2 * rng.uniform(size=X.shape)\nlinearly_separable = (X, y)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c3e3ce43-7aae-90b6-b58d-f96687e88147"},"outputs":[],"source":"datasets = [make_moons(noise=0.3, random_state=0),\n            make_circles(noise=0.2, factor=0.5, random_state=1),\n            linearly_separable\n            ]\n\nfigure = plt.figure(figsize=(27, 9))\ni = 1\n# iterate over datasets\nfor ds_cnt, ds in enumerate(datasets):\n    # preprocess dataset, split into training and test part\n    X, y = ds\n    X = StandardScaler().fit_transform(X)\n    X_train, X_test, y_train, y_test = \\\n        train_test_split(X, y, test_size=.4, random_state=42)\n\n    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                         np.arange(y_min, y_max, h))\n\n    # just plot the dataset first\n    cm = plt.cm.RdBu\n    cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n    ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n    if ds_cnt == 0:\n        ax.set_title(\"Input data\")\n    # Plot the training points\n    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright)\n    # and testing points\n    ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6)\n    ax.set_xlim(xx.min(), xx.max())\n    ax.set_ylim(yy.min(), yy.max())\n    ax.set_xticks(())\n    ax.set_yticks(())\n    i += 1"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}