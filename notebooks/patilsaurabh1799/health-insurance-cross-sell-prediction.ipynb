{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Health Insurance Cross Sell Prediction üè† üè•\n\nPredict Health Insurance Owner's who wil be interested in Vehicle Insurance"},{"metadata":{},"cell_type":"markdown","source":"# Workflow stages\n\nThe competition solution workflow goes through following stages:\n1. Acquire training and testing data\n2. Wrangle, prepare, and cleanse the data\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport sys\nimport random as rnd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Acquire Data\nWe will use Python Pandas package to load the data. We will store the data in train_df and test_df. We will combine the datato run certain operations on both datasets together."},{"metadata":{"trusted":false},"cell_type":"code","source":"train_df = pd.read_csv(\"D:\\Learning\\ML_projects\\Health_Insurance_cross_sell_prediction/train.csv\")\ntest_df = pd.read_csv(\"D:\\Learning\\ML_projects\\Health_Insurance_cross_sell_prediction/test.csv\")\ncombine = [train_df, test_df]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Getting quick insights of data\n\nWe will try to get a quick insights of data. We will print the top five and bottom five rows of both the datasets. Also, we will print the names of all columns to check which features are available for us."},{"metadata":{"trusted":false},"cell_type":"code","source":"print(train_df.columns.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_df.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Which features are categorical (Nominal or Ordinal) and numerical (Continuous or Discrete) ?\n\n* Nominal : **Gender, Driving_license, Previously_Insured, Vehicle_Damage, Response**\n\n* Ordinal : **Vehicle_Age**\n\n* Continuous : **Age, Annual_Premium.** \n"},{"metadata":{"trusted":false},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_df.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Are there any blank, null or empty values?\n\nSo, there are no null values in dataset. We will move to next stage."},{"metadata":{"trusted":false},"cell_type":"code","source":"train_df.info()\nprint(\"=\"*100)\ntest_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Corelate the data.\n\nWe plot a heatmap and check the corelation. As Region code show' no relation we wil drop it. Also, we don't need id column so, we will drop it.\n\nAfter that we will change the gender, vehicle age, and vehicle damage into categorical data."},{"metadata":{"trusted":false},"cell_type":"code","source":"def health_in(data):\n    correlation = data.corr()\n    sns.heatmap(correlation, annot =True, cbar = True, cmap=\"RdYlGn\")\n    \nhealth_in(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_df = train_df.drop(['id'], axis=1)\ntest_df = test_df.drop(['id'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_df = train_df.drop(['Region_Code'], axis=1)\ntest_df = test_df.drop(['Region_Code'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_df.loc[train_df['Gender'] == 'Male', 'Gender'] = 0\ntrain_df.loc[train_df['Gender'] == 'Female', 'Gender'] = 1\ntest_df.loc[test_df['Gender'] == 'Male', 'Gender'] = 0\ntest_df.loc[test_df['Gender'] == 'Female', 'Gender'] = 1\n\ntrain_df.loc[train_df['Vehicle_Age'] == '< 1 Year', 'Vehicle_Age'] = 0\ntrain_df.loc[train_df['Vehicle_Age'] == '1-2 Year', 'Vehicle_Age'] = 1\ntrain_df.loc[train_df['Vehicle_Age'] == '> 2 Years', 'Vehicle_Age'] = 2\ntest_df.loc[test_df['Vehicle_Age'] == '< 1 Year', 'Vehicle_Age'] = 0\ntest_df.loc[test_df['Vehicle_Age'] == '1-2 Year', 'Vehicle_Age'] = 1\ntest_df.loc[test_df['Vehicle_Age'] == '> 2 Years', 'Vehicle_Age'] = 2\n\n\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_df.loc[train_df['Vehicle_Damage'] == 'Yes', 'Vehicle_Damage'] = 1\ntrain_df.loc[train_df['Vehicle_Damage'] == 'No', 'Vehicle_Damage'] = 0\ntest_df.loc[test_df['Vehicle_Damage'] == 'Yes', 'Vehicle_Damage'] = 1\ntest_df.loc[test_df['Vehicle_Damage'] == 'No', 'Vehicle_Damage'] = 0\n\ntest_df.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train = train_df.drop(['Response'], axis =1)\nY_train = train_df['Response']\n\nX_test = test_df\nX_train.shape, Y_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fitting and predictions\n\nWe will now fit the data using different classifiers. Firstly, we will import it and then we will predict and then store them.\nIf we see the result then we get the accuracy of 99.7 percent for both random forest and decision tree classifiers.\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"logreg = LogisticRegression()\nlogreg.fit(X_train, Y_train)\nY_pred = logreg.predict(X_test)\nacc_log = round(logreg.score(X_train, Y_train) * 100, 2)\nacc_log","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"gaussian = GaussianNB()\ngaussian.fit(X_train, Y_train)\nY_pred = gaussian.predict(X_test)\nacc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\nacc_gaussian","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\nY_pred = knn.predict(X_test)\nacc_knn = round(knn.score(X_train, Y_train) * 100, 2)\nacc_knn \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"linear_svc = LinearSVC()\nlinear_svc.fit(X_train, Y_train)\nY_pred = linear_svc.predict(X_test)\nacc_linear_svc = round(linear_svc.score(X_train, Y_train) * 100, 2)\nacc_linear_svc","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sgd = SGDClassifier()\nsgd.fit(X_train, Y_train)\nY_pred = sgd.predict(X_test)\nacc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\nacc_sgd","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"decision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\nacc_decision_tree","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"random_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"models = pd.DataFrame({\n    'Model': ['KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', \n              'Stochastic Gradient Decent', 'Linear SVC', \n              'Decision Tree'],\n    'Score': [ acc_knn, acc_log, \n              acc_random_forest, acc_gaussian, \n              acc_sgd, acc_linear_svc, acc_decision_tree]})\nmodels.sort_values(by='Score', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_sf = pd.read_csv(\"D:\\Learning\\ML_projects\\Health_Insurance_cross_sell_prediction/test.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"submission = pd.DataFrame({\n        \"Id\": test_sf[\"id\"],\n        \"Response\": Y_pred\n    })\nsubmission.to_csv('D:\\Learning\\ML_projects\\Health_Insurance_cross_sell_prediction/submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}