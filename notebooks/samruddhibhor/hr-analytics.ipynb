{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n# to suppress warnings \nfrom warnings import filterwarnings\nfilterwarnings('ignore')\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load The Dataset","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/hr-analytics-job-change-of-data-scientists/aug_train.csv')\nprint('Shape is',df_train.shape)\ndf_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/hr-analytics-job-change-of-data-scientists/aug_test.csv')\nprint('Shape is',df_test.shape)\ndf_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Let us combine both train and test set and then clean the data together","metadata":{}},{"cell_type":"code","source":"df_comb = pd.concat([df_train, df_test])\nprint('shape:',df_comb.shape)\ndf_comb.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_comb.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Null Values","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = [15,8]\nsns.heatmap(df_comb.isnull())\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the percentage of null values in each column\n((df_comb.isnull().sum()/df_comb.shape[0])*100).sort_values(ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inference\n* As we can see there are many missing values in the data.\n* We will have to treat these using apropriate methods.","metadata":{}},{"cell_type":"markdown","source":"## Univariate Analysis","metadata":{}},{"cell_type":"markdown","source":"##### Company Type","metadata":{}},{"cell_type":"code","source":"df_comb['company_type'].value_counts(dropna=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(df_comb['company_type']);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inference\n* We have most of the data pf private companies.\n* Comparatively we have less data of all other types of companies like Funded start up, NGO, etc.","metadata":{}},{"cell_type":"markdown","source":"##### Company Size","metadata":{}},{"cell_type":"code","source":"df_comb['company_size'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Engineering","metadata":{}},{"cell_type":"code","source":"## Let's bin these values\n\ndf_comb['company_size'].replace({'<10': 'Very_small_size', '10/49':'Very_small_size', '50-99':'Very_small_size',\n'100-500': 'Small_Org', '500-999':'Small_Org',\n'1000-4999':'Medium_Org', '5000-9999': 'Medium_Org',\n'10000+': 'Large_Org'},inplace = True)\n\ndf_comb['company_size'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Checking the relationship between company size and company type","metadata":{}},{"cell_type":"code","source":"pd.crosstab(df_comb['company_type'],df_comb['company_size']).plot(kind = 'bar');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inference\n* There is definte relationship between company type and company size.","metadata":{}},{"cell_type":"markdown","source":"##### City Column","metadata":{}},{"cell_type":"code","source":"df_comb['city'].value_counts().sort_values(ascending = False).head(8).plot(kind = 'barh', color = 'red')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inference\n\n* Most of the data scientists are from city_103.\n","metadata":{}},{"cell_type":"markdown","source":"##### city_development_index","metadata":{}},{"cell_type":"code","source":"df_comb['city_development_index'].plot(kind = 'kde');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Gender","metadata":{}},{"cell_type":"code","source":"df_comb[\"gender\"].value_counts(dropna = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_unk=df_comb[['gender','target']].fillna(value= 'Unknown')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_unk.groupby(by = 'gender')['target'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Column : Experience","metadata":{}},{"cell_type":"code","source":"df_comb[\"experience\"].value_counts(dropna = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Let's make the column numerical by replacing the strings in the values.","metadata":{}},{"cell_type":"code","source":"df_comb[\"experience\"].replace({'>20': 21, '<1':0},inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### enrolled_university","metadata":{}},{"cell_type":"code","source":"df_comb['enrolled_university'].value_counts().plot(kind = 'bar');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inference\n* We have more data of the people who have not enrolled in any university.\n* And the least data of the people who have enrolled in part time course.","metadata":{}},{"cell_type":"markdown","source":"##### education_level","metadata":{}},{"cell_type":"code","source":"sns.countplot(df_comb['education_level']);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inference\n* We have more data of the graduate students.","metadata":{}},{"cell_type":"markdown","source":"##### major_discipline","metadata":{}},{"cell_type":"code","source":"df_comb['major_discipline'].value_counts().plot(kind = 'barh');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inference\n* In the major discipline section, we have more data of STEM.","metadata":{}},{"cell_type":"markdown","source":"#### Last new JOB","metadata":{}},{"cell_type":"code","source":"df_comb['last_new_job'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* We will replace the strings into numbers to make the column numerical","metadata":{}},{"cell_type":"code","source":"def replace(last_new_job):\n    if last_new_job == '>4':\n        return 5\n    elif last_new_job == 'never':\n        return 0\n\n    else:\n        return last_new_job\n\ndf_comb.last_new_job = df_comb.last_new_job.map(replace)\ndf_comb['last_new_job'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Training hours","metadata":{}},{"cell_type":"code","source":"df_comb['training_hours'].plot(kind = 'kde');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Filling missing values\n* We will fill all the missing values except the target column by Forward fill method","metadata":{}},{"cell_type":"code","source":"df_comb[\"enrolled_university\"]=df_comb[\"enrolled_university\"].fillna(method = 'ffill')\ndf_comb[\"education_level\"]=df_comb[\"education_level\"].fillna(method = 'ffill')\ndf_comb[\"major_discipline\"]=df_comb[\"major_discipline\"].fillna(method = 'ffill')\ndf_comb[\"last_new_job\"]=df_comb[\"last_new_job\"].fillna(method = 'ffill')\ndf_comb[\"company_type\"]=df_comb[\"company_type\"].fillna(method = 'ffill')\ndf_comb[\"company_type\"]=df_comb[\"company_type\"].fillna(method = 'bfill')\ndf_comb[\"company_size\"]=df_comb[\"company_size\"].fillna(method = 'ffill')\ndf_comb[\"company_size\"]=df_comb[\"company_size\"].fillna(method = 'bfill')\ndf_comb[\"experience\"]=df_comb[\"experience\"].fillna(method = 'ffill')\ndf_comb[\"gender\"]=df_comb[\"gender\"].fillna(method = 'ffill')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_comb.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* The missing values have been treated well now.","metadata":{}},{"cell_type":"code","source":"df_comb.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Let us change the data type of the column experience as it is a numerical column","metadata":{}},{"cell_type":"code","source":"df_comb['experience'] = df_comb['experience'].astype('int64')\ndf_comb['last_new_job'] = df_comb['last_new_job'].astype('int64')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Correlation plot","metadata":{}},{"cell_type":"code","source":"sns.heatmap(df_comb.corr(), annot = True);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inference\n* last new job is moderately correlated with the experience column.\n* experience is also positively correlated with the city_development index column.\n* No other numerical columns are very highly correlated with each other.","metadata":{}},{"cell_type":"markdown","source":"#### Let us drop the unnecessary columns in the data\n* As we do not need enrollee_id. We will delete this column\n* City has many unique values and is also not interpretable as it is i codes. any of the cities are not significant when used in logistic regression.\n* City development index is having high multicollinearity when checked with VIF","metadata":{}},{"cell_type":"code","source":"df_comb.drop(['enrollee_id', 'city', 'city_development_index'], axis = 1, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Let's check the outliers ","metadata":{}},{"cell_type":"code","source":"df_comb.boxplot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### We will now separate the train set and the test set again","metadata":{}},{"cell_type":"code","source":"df_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = df_comb.iloc[:19158]\ntest = df_comb.iloc[19158:]\n\nprint('Shape of train set:', train.shape)\nprint('Shape of test set:', test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['target'].value_counts(dropna = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['target'].value_counts(dropna = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.drop('target', axis = 1, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Let's summarize relationships among variables   ","metadata":{}},{"cell_type":"code","source":"# Let's take all categorical columns in another dataframe\n\ndf_cat = train.select_dtypes(include = [np.object])\ndf_cat.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (10,8)\ndef bar_(column):\n    sns.countplot(train[i], hue = train['target'])\n    plt.show()\n    \nfor i in df_cat:\n    print('Effect of', i , 'on target column')\n    bar_(i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inference\n* We have more data of males and less of females.","metadata":{}},{"cell_type":"code","source":"# Let's check the relationship of numerical features with target\n\ncorr = train.corr()\ncorr['target'].plot.barh()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inference\n\n* All the numeric components are negatively correlated with our target column","metadata":{}},{"cell_type":"markdown","source":"### Let us check if there is imbalance in the data","metadata":{}},{"cell_type":"code","source":"sns.countplot(train['target']);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['target'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### We can clearly see that there is imbalance in the target column\n* We will treat the imbalance using SMOTE ANALYSIS\n\n### SMOTE ANALYSIS","metadata":{}},{"cell_type":"code","source":"X_sm = train.drop(['target'], axis = 1)\nX_sm = pd.get_dummies(X_sm, drop_first= True)\ny_sm = train.target","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Before Resampling Target 1', sum(y_sm == 1))\nprint('Before Resampling Target 0', sum(y_sm == 0))\nfrom imblearn.over_sampling import SMOTE\nsmo = SMOTE(random_state = 5)\nX_sm,y_sm = smo.fit_resample(X_sm,y_sm.ravel())\nprint('X shape', X_sm.shape)\nprint('y shape', y_sm.shape)\nprint('After Resampling Target 1', sum(y_sm == 1))\nprint('After Resampling Target 0', sum(y_sm == 0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### As we can see in the above output that our data has become balanced now. We can proceed further.","metadata":{}},{"cell_type":"markdown","source":"# Basemodel on the normal data","metadata":{}},{"cell_type":"code","source":"import statsmodels.api as sm\nX = train.drop(['target'], axis = 1)\nX = sm.add_constant(X)\nX = pd.get_dummies(X, drop_first= True)\ny = train.target\n\n\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test =  train_test_split(X, y, test_size = 0.2, random_state = 10)\n\nprint('X_train', X_train.shape)\nprint('y_train', y_train.shape)\n\n\nprint('X_test', X_test.shape)\nprint('y_test', y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import statsmodels.api as sm\n\nlogreg = sm.Logit(y_train, X_train).fit()\n\n# print the summary of the model\nprint(logreg.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inference\n* The pseudo R squared for base model is 0.05 which is very less. \n* We can say that it is not a good model at all.","metadata":{}},{"cell_type":"code","source":"sig_feat = logreg.pvalues[1:][logreg.pvalues[1:]<0.05].index\nsig_feat","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logit_y_pred_prob = logreg.predict(X_test)\nlogit_y_pred = [1 if x > 0.5 else 0 for x in logit_y_pred_prob]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score \nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import RocCurveDisplay\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import f1_score\n\nprint('accuracy score', accuracy_score(y_test, logit_y_pred))\nprint('precision_score', precision_score(y_test, logit_y_pred))\nprint('recall_score', recall_score(y_test, logit_y_pred))\nprint('f1_score', f1_score(y_test, logit_y_pred))\nprint('roc_auc score', roc_auc_score(y_test, logit_y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, logit_y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(y_test, logit_y_pred)\nconf_matrix = pd.DataFrame(data = cm, columns = ['Predicted:No', 'Predicted:Yes'], index = ['Actual:No', 'Actual:Yes'])\nsns.heatmap(conf_matrix, annot = True, fmt = 'd', \n            cbar = False, cmap = 'OrRd', linewidth = 0.3, linecolor = 'black', annot_kws = {'size':25})\nplt.xticks(fontsize = 20)\nplt.yticks(fontsize = 20)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.abs(logreg.params[1:]).sort_values().plot(kind = 'barh');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inference\n* From all the above scores we can say that even if accuracy score is 0.75, all other scores are less than expected. \n* It must be beacuse of the imbalance in our target column.","metadata":{}},{"cell_type":"markdown","source":"\n#### Cohen's Kappa Score\n* It is a measure of inter-rater reliability. For logistic regression the actual and predicted values of the target variables are the raters","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import cohen_kappa_score\n\ncohen_kappa_score(y_test, logit_y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* The Cohen Kappa score of a good model is more than 0.5. \n* In our model there is no substantial agreement between the actual and predicted values. \n\n\n## We will try to improve overall efficiency of the model \n\n### Let us build one more Logistic model using the data with SMOTE","metadata":{}},{"cell_type":"code","source":"print('X Shape', X_sm.shape)\nprint('y Shape', y_sm.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting the SMOTE data in train and test set\n\nX_train_sm, X_test_sm, y_train_sm, y_test_sm = train_test_split(X_sm, y_sm, test_size = 0.3, random_state = 10)\n\nprint('Shape of X_train_sm ', X_train_sm.shape)\nprint('Shape of X_test_sm ', X_test_sm.shape)\nprint('Shape of y_train_sm ', y_train_sm.shape)\nprint('Shape of y_test_sm ', y_test_sm.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logit_model_smote = sm.Logit(y_train_sm, X_train_sm).fit()\nlogit_model_smote.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logit_sm_y_pred_prob = logit_model_smote.predict(X_test_sm)\nlogit_sm_y_pred = [1 if x > 0.5 else 0 for x in logit_sm_y_pred_prob]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('accuracy score', accuracy_score(y_test_sm, logit_sm_y_pred))\nprint('precision_score', precision_score(y_test_sm, logit_sm_y_pred))\nprint('recall_score', recall_score(y_test_sm, logit_sm_y_pred))\nprint('f1_score', f1_score(y_test_sm, logit_sm_y_pred))\nprint('roc_auc score', roc_auc_score(y_test_sm, logit_sm_y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cohen_kappa_score(y_test_sm, logit_sm_y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Inference\n* We can see that there is high change in metrics on using SMOTE but this may have created an error in the data \n* When we didn't use SMOTE the accuracy was better but precision, recall and F1 scores were very low.\n* There is gradual change in these scores here.\n* We can say that using SMOTE has really affected the model.\n\n\n***We will use different models and check the accuracy scores***","metadata":{}},{"cell_type":"markdown","source":"#### Let us Define a Function for Confusion Matrix so than it can be used in every model","metadata":{}},{"cell_type":"code","source":"def plot_confusion_matrix(model,X_test,y_test):\n    y_pred = model.predict(X_test)\n    cm = confusion_matrix(y_test, y_pred)\n    conf_matrix = pd.DataFrame(data = cm, columns = ['Predicted:0', 'Predicted:1'], index = ['Actual:0', 'Actual:1'])\n    sns.heatmap(conf_matrix, annot = True, fmt = 'd', \n                cbar = False, cmap = 'plasma', linewidth = 0.1, annot_kws = {'size':25})\n    plt.xticks(fontsize = 20)\n    plt.yticks(fontsize = 20)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Create a generalised function to check the metrics for the train and the test set","metadata":{}},{"cell_type":"code","source":"def get_train_report(model,X_train,y_train):\n    train_pred = model.predict(X_train)\n    print('Accuracy Score for train is ', accuracy_score(y_train, train_pred))\n    print('Recall Score for train is ', recall_score(y_train, train_pred))\n    print('Precision Score for train is ', precision_score(y_train, train_pred))\n    print('F1 Score for train is ', f1_score(y_train, train_pred))\n    return(classification_report(y_train, train_pred))\n\ndef get_test_report(model,X_test,y_test):\n    test_pred = model.predict(X_test)\n    print('Accuracy Score for test is ', accuracy_score(y_test, test_pred))\n    print('Recall Score for test is ', recall_score(y_test, test_pred))\n    print('Precision Score for test is ', precision_score(y_test, test_pred))\n    print('F1 Score for test is ', f1_score(y_test, test_pred))\n    return(classification_report(y_test, test_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Decision Tree Model","metadata":{}},{"cell_type":"markdown","source":"### Normal Data","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier()\ndt_model = dt.fit(X_train, y_train)\ndt_pred = dt_model.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(get_train_report(dt_model,X_train, y_train))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(get_test_report(dt_model,X_train, y_train))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inference\n* Decision tree model tends to overfit on train as well as test data.\n* Let us tune our hyperparameters using Gridsearch CCV\n\n## GridSearchCV for Decision Tree model","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\ntuned_params = [{'criterion': ['entropy', 'gini'],\n                'max_depth' : range(2, 6),\n                'max_features': ['sqrt', 'log2']}]\n\ndecision_tree_classification = DecisionTreeClassifier(random_state = 10)\ntree_grid = GridSearchCV(estimator = decision_tree_classification, param_grid = tuned_params, \n                        cv = 5)\n\ntree_grid_model = tree_grid.fit(X_train, y_train)\n\ntree_grid_model.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndt_CV = DecisionTreeClassifier(criterion = 'entropy', max_depth = 2, max_features = 'sqrt')\ndt_model_CV = dt_CV.fit(X_train, y_train)\ndt_pred_CV = dt_model_CV.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(get_train_report(dt_model_CV,X_train, y_train))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(get_test_report(dt_model_CV,X_test, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inference\n* All the scores for 1 i.e. the person will leave the bank are 0.00. which clearly means that the results are predicted wrong.\n* We can see that the given data is not working well in Logistic as well as Random forest model.\n* So, henceforth we will use the data after applying SMOTE ANALYSIS to build the further models.\n","metadata":{}},{"cell_type":"markdown","source":"## DecisionTree on SMOTE DATA","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndtc = DecisionTreeClassifier()\ndt_model_sm = dtc.fit(X_train_sm, y_train_sm)\ndt_pred_sm = dt_model_sm.predict(X_test_sm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(get_train_report(dt_model_sm,X_train_sm,y_train_sm))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(get_test_report(dt_model_sm,X_test_sm,y_test_sm))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tune the Hyperparameters of the Decision tree","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\ntuned_params = [{'criterion': ['entropy', 'gini'],\n                'max_depth' : range(2, 6),\n                'max_features': ['sqrt', 'log2']}]\n\ndecision_tree_classification = DecisionTreeClassifier(random_state = 10)\ntree_grid = GridSearchCV(estimator = decision_tree_classification, param_grid = tuned_params, \n                        cv = 5)\n\ntree_grid_model = tree_grid.fit(X_train_sm, y_train_sm)\n\ntree_grid_model.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndt_CV_sm = DecisionTreeClassifier(criterion = 'gini', max_depth = 5, max_features = 'log2')\ndt_model_CV_sm = dt_CV_sm.fit(X_train_sm, y_train_sm)\ndt_pred_CV_sm = dt_model_CV_sm.predict(X_test_sm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(get_train_report(dt_model_CV_sm,X_train_sm, y_train_sm))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(get_test_report(dt_model_CV_sm,X_test_sm, y_test_sm))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inference\n* After tuning the hyperparameters, we can see that the data is consistent in both train and test set.\n* The accuracy score is 0.66 which is a fine model","metadata":{}},{"cell_type":"markdown","source":"## KNN Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn_sm = KNeighborsClassifier()\nknn_model_sm = knn_sm.fit(X_train_sm, y_train_sm)\nknn_pred_sm = knn_model_sm.predict(X_test_sm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(get_train_report(knn_model_sm, X_train_sm,y_train_sm))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(get_test_report(knn_model_sm, X_test_sm,y_test_sm))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Random Forest Model","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf_sm = RandomForestClassifier()\nrf_model_sm = rf_sm.fit(X_train_sm, y_train_sm)\nrf_pred_sm = rf_model_sm.predict(X_test_sm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(get_train_report(rf_model_sm, X_train_sm, y_train_sm))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(get_test_report(rf_model_sm, X_test_sm, y_test_sm))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tune the Hyperparameters using GridSearchCV (Random Forest)","metadata":{}},{"cell_type":"code","source":"# create a dictionary with hyperparameters and its values\n# pass the criteria 'entropy' and 'gini' to the parameter, 'criterion' \n# pass a list of values to 'n_estimators' to build the different number of trees in the random forest\n# pass a list of values to 'max_depth' that assigns maximum depth of the tree\n# 'max_features' assigns maximum number of features to consider for the best split. We pass the string 'sqrt' and 'log2'\n# 'sqrt' considers maximum number of features equal to the square root of total features\n# 'log2' considers maximum number of features equal to the log of total features with base 2\n# pass a list of values to 'min_samples_split' that assigns minimum number of samples to split an internal node\n# pass a list of values to 'min_samples_leaf' that assigns minimum number of samples required at the terminal/leaf node\n# pass a list of values to 'max_leaf_nodes' that assigns maximum number of leaf nodes in the tree\ntuned_paramaters = [{'criterion': ['entropy', 'gini'],\n                     'n_estimators': [10, 30, 50, 70],\n                     'max_depth': [10, 15],\n                     'max_features': ['sqrt', 'log2'],\n                     }]\n \n# instantiate the 'RandomForestClassifier' \n# pass the 'random_state' to obtain the same samples for each time you run the code\nrandom_forest_classification = RandomForestClassifier(random_state = 10)\n\n# use GridSearchCV() to find the optimal value of the hyperparameters\n# estimator: pass the random forest classifier model\n# param_grid: pass the list 'tuned_parameters'\n# cv: number of folds in k-fold i.e. here cv = 5\nrf_grid = GridSearchCV(estimator = random_forest_classification, \n                       param_grid = tuned_paramaters, \n                       cv = 5)\n\n# use fit() to fit the model on the train set\nrf_grid_model = rf_grid.fit(X_train_sm, y_train_sm)\n\n# get the best parameters\nprint('Best parameters for random forest classifier: ', rf_grid_model.best_params_, '\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf_sm_CV = RandomForestClassifier(criterion ='gini',max_depth= 15, max_features = 'sqrt', n_estimators = 50 )\nrf_model_sm_CV = rf_sm_CV.fit(X_train_sm, y_train_sm)\nrf_pred_sm_CV = rf_model_sm_CV.predict(X_test_sm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(get_train_report(rf_model_sm_CV, X_train_sm, y_train_sm))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(get_test_report(rf_model_sm_CV, X_test_sm, y_test_sm))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Ada Boost ","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\n\n# instantiate the 'AdaBoostClassifier'\n# n_estimators: number of estimators at which boosting is terminated\n# pass the 'random_state' to obtain the same results for each code implementation\nada_model = AdaBoostClassifier(n_estimators = 40, random_state = 10)\n\n# fit the model using fit() on train data\nada_model_sm = ada_model.fit(X_train_sm, y_train_sm)\nada_pred_sm = ada_model_sm.predict(X_test_sm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(get_train_report(ada_model_sm, X_train_sm, y_train_sm))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(get_test_report(ada_model_sm, X_test_sm, y_test_sm))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Gradient Boost","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\n\n# instantiate the 'GradientBoostingClassifier' \n# n_estimators: number of estimators to consider\n# 'max_depth': assigns maximum depth of the tree\n# pass the 'random_state' to obtain the same results for each code implementation\ngboost_model = GradientBoostingClassifier(n_estimators = 150, max_depth = 10, random_state = 10)\n\n# fit the model using fit() on train data\ngboost_model_sm = gboost_model.fit(X_train_sm, y_train_sm)\ngboost_pred_sm = gboost_model_sm.predict(X_test_sm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(get_train_report(gboost_model_sm, X_train_sm, y_train_sm))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(get_test_report(gboost_model_sm, X_test_sm, y_test_sm))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tune Hyperparameters (Gradient Boost)","metadata":{}},{"cell_type":"code","source":"# create a dictionary with hyperparameters and its values\n# learning_rate: pass the list of boosting learning rates\n# max_depth: pass the range of values as the maximum tree depth for base learners\ntuning_parameters = {'n_estimators': [i for i in range(10,15,2)],\n                     'learning_rate': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6],\n                     'max_depth': [i for i in range(3,6,2)],\n                     'max_features': [20,25,30],\n                     'min_samples_leaf' : [i for i in range(500,2500,1000)]}\n\n# instantiate the 'GradientBoostingClassifier' \ngboost_model = GradientBoostingClassifier()\n\n# use GridSearchCV() to find the optimal value of the hyperparameters\n# estimator: pass the Gradient Boost classifier model\n# param_grid: pass the list 'tuned_parameters'\n# cv: number of folds in k-fold i.e. here cv = 3\n# scoring: pass a measure to evaluate the model on test set\ngboost_grid = GridSearchCV(estimator = gboost_model, param_grid = tuning_parameters, cv = 3, scoring = 'roc_auc')\n\n# fit the model on X_train and y_train using fit()\ngboost_grid.fit(X_train_sm, y_train_sm)\n\n# get the best parameters\nprint('Best parameters for GradientBoosting classifier: ', gboost_grid.best_params_, '\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gboost_model_CV = GradientBoostingClassifier(n_estimators = 14, max_depth = 5, learning_rate = 0.5, max_features = 25, min_samples_leaf = 500, random_state = 10)\n\n# fit the model using fit() on train data\ngboost_model_sm_CV = gboost_model_CV.fit(X_train_sm, y_train_sm)\ngboost_pred_sm_CV = gboost_model_sm_CV.predict(X_test_sm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(get_train_report(gboost_model_sm_CV, X_train_sm, y_train_sm))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(get_test_report(gboost_model_sm_CV, X_test_sm, y_test_sm))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### XG Boost","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\n# instantiate the 'XGBClassifier'\n# set the maximum depth of the tree using the parameter, 'max_depth'\n# pass the value of minimum loss reduction required for partition of the leaf node to the parameter, 'gamma'\nxgb_model = XGBClassifier(max_depth = 10, gamma = 1)\n\n# fit the model using fit() on train data\nxgb_model_sm = xgb_model.fit(X_train_sm, y_train_sm)\nxgb_pred_sm = xgb_model_sm.predict(X_test_sm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(get_train_report(xgb_model_sm, X_train_sm, y_train_sm))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(get_test_report(xgb_model_sm, X_test_sm, y_test_sm))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tune the Hyperparameters (GridSearchCV) for XGBoost","metadata":{}},{"cell_type":"code","source":"# to suppress warnings \nfrom warnings import filterwarnings\nfilterwarnings('ignore')\n\n# create a dictionary with hyperparameters and its values\n# learning_rate: pass the list of boosting learning rates\n# max_depth: pass the range of values as the maximum tree depth for base learners\n# gamma: pass the list of minimum loss reduction values required to make a further partition on a leaf node of the tree\ntuning_parameters = {'learning_rate': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6],\n                     'max_depth': range(3,10),\n                     'gamma': [0, 1, 2, 3, 4]}\n\n# instantiate the 'XGBClassifier' \nxgb_model = XGBClassifier()\n\n# use GridSearchCV() to find the optimal value of the hyperparameters\n# estimator: pass the XGBoost classifier model\n# param_grid: pass the list 'tuned_parameters'\n# cv: number of folds in k-fold i.e. here cv = 3\n# scoring: pass a measure to evaluate the model on test set\nxgb_grid = GridSearchCV(estimator = xgb_model, param_grid = tuning_parameters, cv = 3, scoring = 'roc_auc')\n\n# fit the model on X_train and y_train using fit()\nxgb_grid.fit(X_train_sm, y_train_sm)\n\n# get the best parameters\nprint('Best parameters for XGBoost classifier: ', xgb_grid.best_params_, '\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_model_CV = XGBClassifier(max_depth = 9, gamma = 0, learning_rate = 0.3)\n\n# fit the model using fit() on train data\nxgb_model_CV_sm = xgb_model_CV .fit(X_train_sm, y_train_sm)\nxgb_pred_CV_sm = xgb_model_CV_sm.predict(X_test_sm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(get_train_report(xgb_model_CV_sm, X_train_sm, y_train_sm))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(get_test_report(xgb_model_CV_sm, X_test_sm, y_test_sm))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Comparative Study of the models","metadata":{}},{"cell_type":"code","source":"score_card = pd.DataFrame({'Log_Reg_Normal_Data': {'Accuracy': accuracy_score(y_test, logit_y_pred)*100 , 'Precision_score': precision_score(y_test, logit_y_pred)*100, 'recall_score': recall_score(y_test, logit_y_pred)*100, 'f1_score': f1_score(y_test, logit_y_pred)*100, 'roc_auc_score': roc_auc_score(y_test, logit_y_pred)*100},\n                           'Log_Reg_SMOTE_Data': {'Accuracy': accuracy_score(y_test_sm, logit_sm_y_pred)*100 , 'Precision_score': precision_score(y_test_sm, logit_sm_y_pred)*100, 'recall_score': recall_score(y_test_sm, logit_sm_y_pred)*100 , 'f1_score': f1_score(y_test_sm, logit_sm_y_pred)*100, 'roc_auc_score': roc_auc_score(y_test_sm, logit_sm_y_pred)*100}, \n                           'DT_Normal_Data': {'Accuracy': accuracy_score(y_test, dt_pred)*100 , 'Precision_score': precision_score(y_test, dt_pred)*100, 'recall_score': recall_score(y_test, dt_pred)*100 , 'f1_score': f1_score(y_test, dt_pred)*100, 'roc_auc_score': roc_auc_score(y_test, dt_pred)*100},\n                           'DT_CV_Normal Data': {'Accuracy': accuracy_score(y_test, dt_pred_CV)*100 , 'Precision_score': precision_score(y_test, dt_pred_CV)*100, 'recall_score': recall_score(y_test, dt_pred_CV)*100 , 'f1_score': f1_score(y_test, dt_pred)*100, 'roc_auc_score': roc_auc_score(y_test, dt_pred_CV)*100},\n                           'DT_SMOTE_Data': {'Accuracy': accuracy_score(y_test_sm, dt_pred_sm)*100 , 'Precision_score': precision_score(y_test_sm, dt_pred_sm)*100, 'recall_score': recall_score(y_test_sm, dt_pred_sm)*100 , 'f1_score': f1_score(y_test_sm, dt_pred_sm)*100, 'roc_auc_score': roc_auc_score(y_test_sm, dt_pred_sm)*100},\n                           'DT_CV_SMOTE Data': {'Accuracy': accuracy_score(y_test_sm, dt_pred_CV_sm)*100 , 'Precision_score': precision_score(y_test_sm, dt_pred_CV_sm)*100, 'recall_score': recall_score(y_test_sm, dt_pred_CV_sm)*100 , 'f1_score': f1_score(y_test_sm, dt_pred_CV_sm)*100, 'roc_auc_score': roc_auc_score(y_test_sm, dt_pred_CV_sm)*100},\n                           'KNN': {'Accuracy': accuracy_score(y_test_sm, knn_pred_sm)*100 , 'Precision_score': precision_score(y_test_sm, knn_pred_sm)*100, 'recall_score': recall_score(y_test_sm, knn_pred_sm)*100 , 'f1_score': f1_score(y_test_sm, knn_pred_sm)*100, 'roc_auc_score': roc_auc_score(y_test_sm, knn_pred_sm)*100},\n                           'Random_Forest': {'Accuracy': accuracy_score(y_test_sm, rf_pred_sm)*100 , 'Precision_score': precision_score(y_test_sm, rf_pred_sm)*100, 'recall_score': recall_score(y_test_sm, rf_pred_sm)*100 , 'f1_score': f1_score(y_test_sm, rf_pred_sm)*100, 'roc_auc_score': roc_auc_score(y_test_sm, rf_pred_sm)*100},\n                           'RF_CV': {'Accuracy': accuracy_score(y_test_sm, rf_pred_sm_CV)*100 , 'Precision_score': precision_score(y_test_sm, rf_pred_sm_CV)*100, 'recall_score': recall_score(y_test_sm, rf_pred_sm_CV)*100 , 'f1_score': f1_score(y_test_sm, rf_pred_sm_CV)*100, 'roc_auc_score': roc_auc_score(y_test_sm, rf_pred_sm_CV)*100},\n                           'Ada_Boost': {'Accuracy': accuracy_score(y_test_sm, ada_pred_sm)*100 , 'Precision_score': precision_score(y_test_sm, ada_pred_sm)*100, 'recall_score': recall_score(y_test_sm, ada_pred_sm)*100 , 'f1_score': f1_score(y_test_sm, ada_pred_sm)*100, 'roc_auc_score': roc_auc_score(y_test_sm, ada_pred_sm)*100},\n                           'Gradient_Boost': {'Accuracy': accuracy_score(y_test_sm, gboost_pred_sm)*100 , 'Precision_score': precision_score(y_test_sm, gboost_pred_sm)*100, 'recall_score': recall_score(y_test_sm, gboost_pred_sm)*100 , 'f1_score': f1_score(y_test_sm, gboost_pred_sm)*100, 'roc_auc_score': roc_auc_score(y_test_sm, gboost_pred_sm)*100},\n                           'Gradient_Boost_CV': {'Accuracy': accuracy_score(y_test_sm, gboost_pred_sm_CV)*100 , 'Precision_score': precision_score(y_test_sm, gboost_pred_sm_CV)*100, 'recall_score': recall_score(y_test_sm, gboost_pred_sm_CV)*100 , 'f1_score': f1_score(y_test_sm, gboost_pred_sm_CV)*100, 'roc_auc_score': roc_auc_score(y_test_sm, gboost_pred_sm_CV)*100},\n                           'XG_Boost': {'Accuracy': accuracy_score(y_test_sm, xgb_pred_sm)*100 , 'Precision_score': precision_score(y_test_sm, xgb_pred_sm)*100, 'recall_score': recall_score(y_test_sm, xgb_pred_sm)*100 , 'f1_score': f1_score(y_test_sm, xgb_pred_sm)*100, 'roc_auc_score': roc_auc_score(y_test_sm, xgb_pred_sm)*100},\n                           'XG_Boost_CV': {'Accuracy': accuracy_score(y_test_sm, xgb_pred_CV_sm)*100 , 'Precision_score': precision_score(y_test_sm, xgb_pred_CV_sm)*100, 'recall_score': recall_score(y_test_sm, xgb_pred_CV_sm)*100 , 'f1_score': f1_score(y_test_sm, xgb_pred_CV_sm)*100, 'roc_auc_score': roc_auc_score(y_test_sm, xgb_pred_CV_sm)*100}})\n                      \n                \nscore_card.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inference\n\n* Based on above table, we can observe that Gradient Boosting has the highest ROC value as well as all other values and hence, we will select Gradient Boosting as our model for prediction.\n\n\n### Inferences for Gradient Boosting model","metadata":{}},{"cell_type":"markdown","source":"#### Confusion_matrix","metadata":{}},{"cell_type":"code","source":"plot_confusion_matrix(gboost_model_sm,X_test_sm,y_test_sm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### ROC-AUC-Curve","metadata":{}},{"cell_type":"code","source":"y_pred_prob = gboost_model_sm.predict_proba(X_test_sm)[:,1]\n\n# the roc_curve() returns the values for false positive rate, true positive rate and threshold\n# pass the actual target values and predicted probabilities to the function\nfpr, tpr, thresholds = roc_curve(y_test_sm, y_pred_prob)\n\n# plot the ROC curve\nplt.plot(fpr, tpr)\n\n# set limits for x and y axes\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\n\n# plot the straight line showing worst prediction for the model\nplt.plot([0, 1], [0, 1],'r--')\n\n# add plot and axes labels\n# set text size using 'fontsize'\nplt.title('ROC curve for Admission Prediction Classifier', fontsize = 15)\nplt.xlabel('False positive rate (1-Specificity)', fontsize = 15)\nplt.ylabel('True positive rate (Sensitivity)', fontsize = 15)\n\n# add the AUC score to the plot\n# 'x' and 'y' gives position of the text\n# 's' is the text \n# use round() to round-off the AUC score upto 4 digits\nplt.text(x = 0.82, y = 0.3, s = ('AUC Score:',round(roc_auc_score(y_test_sm, y_pred_prob),4)))\n\n# plot the grid\nplt.grid(True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Important Features","metadata":{}},{"cell_type":"code","source":"# create a dataframe that stores the feature names and their importance\n# 'feature_importances_' returns the features based on the average gain \nimportant_features = pd.DataFrame({'Features': X_train_sm.columns, \n                                   'Importance': gboost_model_sm.feature_importances_})\n\n# sort the dataframe in the descending order according to the feature importance\nimportant_features = important_features.sort_values('Importance', ascending = False)\n\n# create a barplot to visualize the features based on their importance\nsns.barplot(x = 'Importance', y = 'Features', data = important_features)\n\n# add plot and axes labels\n# set text size using 'fontsize'\nplt.title('Feature Importance', fontsize = 15)\nplt.xlabel('Importance', fontsize = 15)\nplt.ylabel('Features', fontsize = 15)\n\n# display the plot\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}