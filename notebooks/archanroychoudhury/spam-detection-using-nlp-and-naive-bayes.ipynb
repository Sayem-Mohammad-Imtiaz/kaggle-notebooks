{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The dataset contains one message per line. Each line is composed by two columns: v1 contains the label (ham or spam) and v2 contains the raw messages. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Impotant Imports\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"#### Get the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/spam.csv\", encoding='latin-1')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Let's check our dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns = ['label', 'message', 'line1', 'line2', 'line3']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### As we can see, the last three columns has huge number of null values. It'll better if I drop them."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(['line1','line2', 'line3'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Exploring the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby('label').describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### As we can see there are many same messages are there."},{"metadata":{},"cell_type":"markdown","source":"#### I will add a feature of length of each message"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['length'] = data['message'].apply(len)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['length'].plot(bins=50, kind='hist', cmap='coolwarm')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### From here we can see that there are some really long messages"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.length.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Max message character is 910. Let's try to see that message"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data['length'] == 910]['message'].iloc[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### This is not a Spam message. Looks like a love letter sort of"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.hist(column='length', by='label', bins=50,figsize=(12,4))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Through this we can understand the trend that Spam messages tend to have more characters."},{"metadata":{},"cell_type":"markdown","source":"### Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"#### First I'll remove the common words, ('the', 'a', etc..) as they have very less importance for prediction. I will use NLTK library to do this. \n#### And then I will convert the raw messages (sequence of characters) into vectors (sequences of numbers)."},{"metadata":{},"cell_type":"markdown","source":"#### Let's see some stopwords."},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nimport string\nfrom nltk.corpus import stopwords\nstopwords.words('english')[0:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_stopword(mess):\n    # Checking characters if they are in punctuation\n    message = [char for char in mess if char not in string.punctuation]\n\n    # Joining the characters \n    message = ''.join(message)\n    \n    # Removing any stopwords\n    return [word for word in message.split() if word.lower() not in stopwords.words('english')]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Checking how it's working"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['message'].head(5).apply(remove_stopword)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train Test split"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nmsg_train, msg_test, label_train, label_test = train_test_split(data['message'], data['label'], test_size=0.3, random_state=101)\n\nprint(len(msg_train), len(msg_test), len(msg_train) + len(msg_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Creating a Pipeline"},{"metadata":{},"cell_type":"markdown","source":"#### This will allow us to set up all the transformations that we will do to the data for future use. I am using Bag of Words (CountVectorizer), Tfidf (Term Frequency - Inverse Document Frequency) and Naive Bayes classifier. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB\n\npipeline = Pipeline([\n    ('vector', CountVectorizer(analyzer=remove_stopword)),  # strings to tokenized vectors\n    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n    ('classifier', MultinomialNB()),  # train on TF-IDF vectors with Naive Bayes classifier\n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Now I can pass the data through Pipeline and it will do all the preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline.fit(msg_train,label_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prediction and Evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = pipeline.predict(msg_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix\n\nprint(confusion_matrix(label_test,predictions))\nprint(\"\\n\")\nprint(classification_report(label_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\naccuracy = accuracy_score(label_test,predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}