{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\nimport warnings\nwarnings.simplefilter(action='ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '/kaggle/input/vehicle-dataset-from-cardekho/Car details v3.csv'\ndf = pd.read_csv(path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.duplicated().any()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop_duplicates()\ndf.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(['torque'], axis=1, inplace=True)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check missing values\ndf.isnull().any()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Missing values in Percentage of the Total Sample\ndf.isnull().sum() / df.shape[0] * 100","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Having more than 6000 samples, only 3% data is missing at max hence dropping such rows\ndf.dropna(axis=0, inplace=True)\ndf.isnull().any()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Removing Units**","metadata":{}},{"cell_type":"code","source":"#Removing units to handle the column as float columns\n#Meethod-1\ndef remove_unit(df,colum_name) :\n    t = []\n    for i in df[colum_name]:\n        number = str(i).split(' ')[0]\n        t.append(number)\n    return t\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['engine'] = remove_unit(df,'engine')\ndf['mileage'] = remove_unit(df,'mileage')\ndf['max_power'] = remove_unit(df,'max_power')\n\ndf['engine'] = pd.to_numeric(df['engine'])\ndf['mileage'] = pd.to_numeric(df['mileage'])\ndf['max_power'] = pd.to_numeric(df['max_power'])\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(df['engine'][0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Adding 'age' feature to know how old the car is and dropping 'year' feature as it is useless now\ndf['age'] = 2021 - df['year']\ndf.drop(['year'],axis = 1,inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df['fuel'].unique())\nprint(df['seller_type'].unique())\nprint(df['transmission'].unique())\nprint(df['owner'].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Ordinal encoding\ndf['owner'] = df['owner'].replace({'First Owner': 1, 'Second Owner': 2, 'Third Owner': 3, 'Fourth & Above Owner': 4, 'Test Drive Car': 5})\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['seats'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converting the datatype of 'seats' to string object since it is a categorical data\ndf['seats'] = df['seats'].astype(str)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **EDA**","metadata":{}},{"cell_type":"markdown","source":"## **Univariate Analysis**","metadata":{}},{"cell_type":"code","source":"fig = make_subplots(rows=3, cols=2,subplot_titles=(\"Selling Price in Rupee\", \"Total KM Driven\", \"Fuel Efficiency in KM per litre\",\n                                                   \"Engine CC\", \"Brake Horse Power(BHP)\", \"Age of Car\",\"Number of Seats\"))\n\nfig.add_trace(go.Histogram(x=df['selling_price'], name=\"Rupee\"), row=1, col=1)\n\nfig.add_trace(go.Histogram(x=df['km_driven'], name=\"KM\"), row=1, col=2)\n\nfig.add_trace(go.Histogram(x=df['mileage'], name=\"KM/L\"), row=2, col=1)\n\nfig.add_trace(go.Histogram(x=df['engine'], name=\"CC\"), row=2, col=2)\n\nfig.add_trace(go.Histogram(x=df['max_power'], name=\"BHP\"), row=3, col=1)\n\nfig.add_trace(go.Histogram(x=df['age'], name=\"Years\"), row=3, col=2)\n\nfig.update_layout(height=1400, width=800, title_text=\"Distribution of numerical data\")\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = make_subplots(rows=3, cols=2,subplot_titles=(\"Selling Price in Rupee\", \"Total KM Driven\", \"Fuel Efficiency in KM per litre\",\n                                                   \"Engine CC\", \"Brake Horse Power(BHP)\", \"Age of Car\",\"Number of Seats\"))\n\nfig.add_trace(go.Box(x=df['selling_price'], name=\"Rupee\"), row=1, col=1)\n\nfig.add_trace(go.Box(x=df['km_driven'], name=\"KM\"), row=1, col=2)\n\nfig.add_trace(go.Box(x=df['mileage'], name=\"KM/L\"), row=2, col=1)\n\nfig.add_trace(go.Box(x=df['engine'], name=\"CC\"), row=2, col=2)\n\nfig.add_trace(go.Box(x=df['max_power'], name=\"BHP\"), row=3, col=1)\n\nfig.add_trace(go.Box(x=df['age'], name=\"Years\"), row=3, col=2)\n\nfig.update_layout(height=1400, width=800, title_text=\"Distribution of numerical data\")\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_fuel = df['fuel'].value_counts().reset_index()\ncount_fuel = count_fuel.rename(columns = {'index':'fuel','fuel':'count'})\n\ncount_seller = df['seller_type'].value_counts().reset_index()\ncount_seller = count_seller.rename(columns = {'index':'seller_type','seller_type':'count'})\n\ncount_transmission = df['transmission'].value_counts().reset_index()\ncount_transmission = count_transmission.rename(columns = {'index':'transmission','transmission':'count'})\n\ncount_owner = df['owner'].value_counts().reset_index()\ncount_owner = count_owner.rename(columns = {'index':'owner','owner':'count'})\n\ncount_seats = df['seats'].value_counts().reset_index()\ncount_seats = count_seats.rename(columns = {'index':'seats','seats':'count'})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Bivariate/Multivariate Analysis**","metadata":{}},{"cell_type":"code","source":"sns.heatmap(df.corr(), annot=True, cmap=\"RdBu\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Feature Selection, Feature Engineering and Data Preparation for Modelling**","metadata":{}},{"cell_type":"code","source":"# Make a copy of the data for modelling\ndf_model = df.copy()\n\n# Create the 'brand' column by splitting the 'name' column\ndf_model['brand'] = df_model['name'].str.split(' ').str.get(0)\ndf_model.drop(['name'],axis=1,inplace=True)\n\n# Filter the outlier and log-transform the target variable('selling_price')\ndf_model = df_model[df_model['selling_price'] < 2500000]\ndf_model['selling_price'] = np.log(df_model['selling_price'])\n\n# Filter the outlier in 'km_driven' feature\ndf_model = df_model[df_model['km_driven'] < 300000]\n\n# Filter the unwanted rows in 'fuel' feature\ndf_model = df_model[~df_model['fuel'].isin(['CNG','LPG'])]\n\n# Filter the outliers in 'mileage' feature\ndf_model = df_model[(df_model['mileage'] > 5) & (df_model['mileage'] < 35)]\n\n# Filter the outlier in 'max_power' feature and log-transform the data.\ndf_model = df_model[df_model['max_power'] < 300]\ndf_model['max_power'] = np.log(df_model['max_power'])\n\n# Log-transform the 'age' feature data.\ndf_model['age'] = np.log(df_model['age'])\n\ndf_model.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df_model['brand'].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_model = pd.get_dummies(data = df_model, drop_first=True)\ndf_model.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_model.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df_model.drop(['selling_price'],axis=1)\ny = df_model['selling_price']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)\nprint(\"x train: \",X_train.shape)\nprint(\"x test: \",X_test.shape)\nprint(\"y train: \",y_train.shape)\nprint(\"y test: \",y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nnum_var = ['km_driven', 'mileage', 'engine', 'max_power', 'age']\nX_train[num_var] = scaler.fit_transform(X_train[num_var])\nX_test[num_var] = scaler.transform(X_test[num_var])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_selection import RFE\nfrom sklearn.ensemble import RandomForestRegressor\nselect = RFE(RandomForestRegressor(n_estimators=100, random_state=42), n_features_to_select=40)\nselect.fit(X_train, y_train)\nX_train_rfe= select.transform(X_train)\nX_test_rfe= select.transform(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import r2_score\nfrom sklearn.model_selection import cross_val_score\n\nr2_train_scores = []\nr2_test_scores = []\ncv_mean = []\n\ndef car_price_prediction_model(model):\n    model.fit(X_train, y_train)\n    \n    #R2 score of training set\n    y_train_pred = model.predict(X_train)\n    r2_train = r2_score(y_train, y_train_pred)\n    r2_train_scores.append(round(r2_train,2))\n    \n    #R2 score of test set\n    y_test_pred = model.predict(X_test)\n    r2_test = r2_score(y_test, y_test_pred)\n    r2_test_scores.append(round(r2_test,2))\n    \n    # CV score of training set\n    cv_training = cross_val_score(model, X_train, y_train, cv=5)\n    cv_mean_training = cv_training.mean()\n    cv_mean.append(round(cv_mean_training,2))\n    \n    # Printing each score\n    print(\"Training set R2 scores: \",round(r2_train,2))\n    print(\"Test set R2 scores: \",round(r2_test,2))\n    print(\"Training cross validation score: \", cv_training)\n    print(\"Training cross validation mean score: \",round(cv_mean_training,2))\n    \n    fig, ax = plt.subplots(1,2,figsize = (10,4))\n    ax[0].set_title('Residual Plot of Train samples')\n    sns.distplot((y_train-y_train_pred),hist = False,ax = ax[0])\n    ax[0].set_xlabel('y_pred')\n    \n    # Y_test vs Y_train scatter plot\n    ax[1].set_title('y_test vs y_pred_test')\n    ax[1].scatter(x = y_test, y = y_test_pred)\n    ax[1].set_xlabel('y_test')\n    ax[1].set_ylabel('y_pred_test')\n    \n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import r2_score\nfrom sklearn.model_selection import cross_val_score\n\nr2_train_scores_rfe = []\nr2_test_scores_rfe = []\ncv_mean_rfe = []\n\ndef car_price_prediction_model_rfe(model):\n    model.fit(X_train_rfe, y_train)\n    \n    \n    #R2 score of RFE training set\n    y_train_pred_rfe = model.predict(X_train_rfe)\n    r2_train_rfe = r2_score(y_train, y_train_pred_rfe)\n    r2_train_scores_rfe.append(round(r2_train_rfe,2))\n    \n    #R2 score of RFE test set\n    y_test_pred_rfe = model.predict(X_test_rfe)\n    r2_test_rfe = r2_score(y_test, y_test_pred_rfe)\n    r2_test_scores_rfe.append(round(r2_test_rfe,2))\n\n    # CV score of RFE training set\n    cv_training_rfe = cross_val_score(model, X_train_rfe, y_train, cv=5)\n    cv_mean_training_rfe = cv_training_rfe.mean()\n    cv_mean_rfe.append(round(cv_mean_training_rfe,2))\n    \n    # Printing each score\n    print(\"Training set R2 scores: \",round(r2_train_rfe,2))\n    print(\"Test set R2 scores: \",round(r2_test_rfe,2))\n    print(\"Training cross validation score: \", cv_training_rfe)\n    print(\"Training cross validation mean score: \",round(cv_mean_training_rfe,2))\n    \n    fig, ax = plt.subplots(1,2,figsize = (10,4))\n    ax[0].set_title('Residual Plot of RFE-Train samples')\n    sns.distplot((y_train-y_train_pred_rfe),hist = False,ax = ax[0])\n    ax[0].set_xlabel('residual')\n    \n    # Y_test vs Y_train scatter plot\n    ax[1].set_title('y_test vs y_pred_test_rfe')\n    ax[1].scatter(x = y_test, y = y_test_pred_rfe)\n    ax[1].set_xlabel('y_test')\n    ax[1].set_ylabel('y_pred_test_rfe')\n    \n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Regression Modelling and Evaluation**","metadata":{}},{"cell_type":"markdown","source":"### **1. Linear Regression(Ordinary Least Square)**","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlm = LinearRegression()\ncar_price_prediction_model(lm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"car_price_prediction_model_rfe(lm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **2. Linear Regression(Ridge)**","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import Ridge\nfrom sklearn.model_selection import RandomizedSearchCV\n\nrg = Ridge()\nalpha = np.logspace(-3,3,num=14)\nrg_rs = RandomizedSearchCV(estimator=rg, param_distributions=dict(alpha=alpha))\ncar_price_prediction_model(rg_rs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"car_price_prediction_model_rfe(rg_rs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **3. Linear Regression(Lasso)**","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import Lasso\nfrom sklearn.model_selection import RandomizedSearchCV\n\nls = Lasso()\nalpha = np.logspace(-3,3,num=14)\nls_rs = RandomizedSearchCV(estimator=ls, param_distributions=dict(alpha=alpha))\ncar_price_prediction_model(ls_rs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"car_price_prediction_model_rfe(ls_rs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **4. Extreme Gradient Boosting Regressor**","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBRegressor\nxg = XGBRegressor(verbosity= 0)\n\nn_estimators = [100, 500, 900, 1100, 1500]\nmax_depth = [2, 3, 5, 10, 15]\nbooster=['gbtree','gblinear']\nlearning_rate=[0.05,0.1,0.15,0.20]\nmin_child_weight=[1,2,3,4]\nbase_score=[0.25,0.5,0.75,1]\n\nparameter_grid = {\n    'n_estimators': n_estimators,\n    'max_depth':max_depth,\n    'learning_rate':learning_rate,\n    'min_child_weight':min_child_weight,\n    'booster':booster,\n    'base_score':base_score\n    }\n\nxg_rs = RandomizedSearchCV(estimator=xg, param_distributions=parameter_grid)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"car_price_prediction_model(xg_rs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"car_price_prediction_model_rfe(xg_rs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **5. Random Forest Regressor**","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import RandomizedSearchCV\n\nrf = RandomForestRegressor()\n\n# Number of trees in Random forest\nn_estimators=list(range(500,1000,100))\n# Maximum number of levels in a tree\nmax_depth=list(range(4,9,4))\n# Minimum number of samples required to split an internal node\nmin_samples_split=list(range(4,9,2))\n# Minimum number of samples required to be at a leaf node.\nmin_samples_leaf=[1,2,5,7]\n# Number of fearures to be considered at each split\nmax_features=['auto','sqrt']\n\n# Hyperparameters dict\nparam_grid = {\"n_estimators\":n_estimators,\n              \"max_depth\":max_depth,\n              \"min_samples_split\":min_samples_split,\n              \"min_samples_leaf\":min_samples_leaf,\n              \"max_features\":max_features}\n\nrf_rs = RandomizedSearchCV(estimator = rf, param_distributions = param_grid, scoring='neg_mean_squared_error', n_iter=10, cv=5, verbose=2, random_state=42, n_jobs=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"car_price_prediction_model(rf_rs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"car_price_prediction_model_rfe(rf_rs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **6. Gradient Boosting Regressor**","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import RandomizedSearchCV\n\ngb = GradientBoostingRegressor()\n\n# Rate at which correcting is being made\nlearning_rate = [0.001, 0.01, 0.1, 0.2]\n# Number of trees in Gradient boosting\nn_estimators=list(range(500,1000,100))\n# Maximum number of levels in a tree\nmax_depth=list(range(4,9,4))\n# Minimum number of samples required to split an internal node\nmin_samples_split=list(range(4,9,2))\n# Minimum number of samples required to be at a leaf node.\nmin_samples_leaf=[1,2,5,7]\n# Number of fearures to be considered at each split\nmax_features=['auto','sqrt']\n\n# Hyperparameters dict\nparam_grid = {\"learning_rate\":learning_rate,\n              \"n_estimators\":n_estimators,\n              \"max_depth\":max_depth,\n              \"min_samples_split\":min_samples_split,\n              \"min_samples_leaf\":min_samples_leaf,\n              \"max_features\":max_features}\n\ngb_rs = RandomizedSearchCV(estimator = gb, param_distributions = param_grid, scoring='neg_mean_squared_error', n_iter=10, cv=5, verbose=2, random_state=42, n_jobs=1)\n#n_jobs = Number of Cores of the laptop used","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"car_price_prediction_model(gb_rs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"car_price_prediction_model_rfe(gb_rs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Model Evaluation**","metadata":{}},{"cell_type":"code","source":"algo = [\"LinearRegression(OLS)\",\"LinearRegression(Ridge)\",\"LinearRegression(Lasso)\", \"ExtremeGradientBoostingRegressor\",\"RandomForestRegressor\",\"GradientBoostingRegressor\"]\n\nmodel_eval = pd.DataFrame({'Model': algo,'R Squared(Train)': r2_train_scores,'R Squared(Test)': r2_test_scores, 'CV score mean(Train)': cv_mean})\ndisplay(model_eval)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_eval_RFE = pd.DataFrame({'Model': algo,'R Squared(Train)': r2_train_scores_rfe,'R Squared(Test)': r2_test_scores_rfe,'CV score mean(Train)': cv_mean_rfe})\ndisplay(model_eval_RFE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Conclusion**","metadata":{}},{"cell_type":"markdown","source":"**1. Gradient Boosting Regressor is the model I will choose since it has the highest CV score(91%) which mean it generalize better than other models.**","metadata":{}},{"cell_type":"markdown","source":"**2. Linear model is also a great model choice if we have computational power constraint since the non-linear model are quite computational expensive.**","metadata":{}},{"cell_type":"markdown","source":"**3. The automatic feature selection(RFE) did not make significant improvement on all of the models. Hence we do not need it unless computational time is of concern.**","metadata":{}},{"cell_type":"code","source":"gb_rs.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = gb_rs.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.distplot(y_test-predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(y_test, predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import pickle\n# #open the file where you want to store the data\n# file = open('gradient_boosting_regressor_model.pkl', 'wb')\n# #dump information to the file\n# pickle.dump(gb_rs, file)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}