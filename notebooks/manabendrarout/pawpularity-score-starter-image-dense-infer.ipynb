{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# About This Notebook\n\nThis implementation is based on a vanilla Efficientnet_B0 in Pytorch for the Pawpularity Competition.  \nThis model uses **both images and dense features** for score prediction.  \nThis scores around [insert here].\n\nTraining Params: -\n1. **Dataset**: - 3-channel RGB Images (256x256) with separate dense features\n2. **Augmentations**: - Resize, Normalize, HorizontalFlip, VerticalFlip, RandomBrightness, RandomResizedCrop, HueSaturationValue, RandomBrightnessContrast\n3. **Optimizer**: - AdamW\n4. **Scheduler**: - CosineAnnealingLR\n5. **Model**: - Efficientnet-B0\n6. **Initial Weights**: - Imagenet\n5. **Max Epochs**: - 20 (~1 min per epoch on Tesla T4 GPU)\n6. **Saved Weights**: - 5-fold ensemble. Weights having highest OOF score on RMSE metric were saved.\n\n**If you find this notebook useful and use parts of it in your work, please don't forget to show your appreciation by upvoting this kernel. That keeps me motivated and inspires me to write and share these public kernels. ðŸ˜Š**","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"# Get GPU Info","metadata":{}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2021-09-24T05:11:07.49567Z","iopub.execute_input":"2021-09-24T05:11:07.496048Z","iopub.status.idle":"2021-09-24T05:11:08.599486Z","shell.execute_reply.started":"2021-09-24T05:11:07.49597Z","shell.execute_reply":"2021-09-24T05:11:08.598352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append('../input/pytorch-image-models/pytorch-image-models-master')","metadata":{"execution":{"iopub.status.busy":"2021-09-24T05:11:08.603436Z","iopub.execute_input":"2021-09-24T05:11:08.607495Z","iopub.status.idle":"2021-09-24T05:11:08.614324Z","shell.execute_reply.started":"2021-09-24T05:11:08.607449Z","shell.execute_reply":"2021-09-24T05:11:08.613337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Asthetics\nimport warnings\nimport sklearn.exceptions\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\nwarnings.filterwarnings('ignore', category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n\n# General\nfrom tqdm.auto import tqdm\nimport pandas as pd\nimport numpy as np\nimport os\nimport glob\nimport random\nimport cv2\npd.set_option('display.max_columns', None)\n\n# Image Aug\nimport albumentations\nfrom albumentations.pytorch.transforms import ToTensorV2\n\n# Deep Learning\nimport torch\nimport torchvision\nimport timm\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\n# Random Seed Initialize\nRANDOM_SEED = 42\n\ndef seed_everything(seed=RANDOM_SEED):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    \nseed_everything()\n\n# Device Optimization\nif torch.cuda.is_available():\n    device = torch.device('cuda')\nelse:\n    device = torch.device('cpu')\n    \nprint(f'Using device: {device}')","metadata":{"execution":{"iopub.status.busy":"2021-09-24T05:11:08.615987Z","iopub.execute_input":"2021-09-24T05:11:08.619405Z","iopub.status.idle":"2021-09-24T05:11:16.522821Z","shell.execute_reply.started":"2021-09-24T05:11:08.619362Z","shell.execute_reply":"2021-09-24T05:11:16.521692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"csv_dir = '../input/petfinder-pawpularity-score'\ntest_dir = '../input/petfinder-pawpularity-score/test'\nmodels_dir = '../input/pawpularity-contest-models/efficientnet_b0'\n\ntest_file_path = os.path.join(csv_dir, 'test.csv')\nsample_sub_file_path = os.path.join(csv_dir, 'sample_submission.csv')\nprint(f'Test file: {test_file_path}')\nprint(f'Models path: {models_dir}')","metadata":{"execution":{"iopub.status.busy":"2021-09-24T05:11:16.525119Z","iopub.execute_input":"2021-09-24T05:11:16.525805Z","iopub.status.idle":"2021-09-24T05:11:16.536345Z","shell.execute_reply.started":"2021-09-24T05:11:16.525762Z","shell.execute_reply":"2021-09-24T05:11:16.535181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(test_file_path)\nsample_df = pd.read_csv(sample_sub_file_path)","metadata":{"execution":{"iopub.status.busy":"2021-09-24T05:11:16.54046Z","iopub.execute_input":"2021-09-24T05:11:16.540835Z","iopub.status.idle":"2021-09-24T05:11:16.567364Z","shell.execute_reply.started":"2021-09-24T05:11:16.540791Z","shell.execute_reply":"2021-09-24T05:11:16.56634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def return_filpath(name, folder):\n    path = os.path.join(folder, f'{name}.jpg')\n    return path","metadata":{"execution":{"iopub.status.busy":"2021-09-24T05:11:16.570148Z","iopub.execute_input":"2021-09-24T05:11:16.570391Z","iopub.status.idle":"2021-09-24T05:11:16.577465Z","shell.execute_reply.started":"2021-09-24T05:11:16.570356Z","shell.execute_reply":"2021-09-24T05:11:16.576236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['image_path'] = test_df['Id'].apply(lambda x: return_filpath(x, folder=test_dir))","metadata":{"execution":{"iopub.status.busy":"2021-09-24T05:11:16.580096Z","iopub.execute_input":"2021-09-24T05:11:16.580436Z","iopub.status.idle":"2021-09-24T05:11:16.593544Z","shell.execute_reply.started":"2021-09-24T05:11:16.580402Z","shell.execute_reply":"2021-09-24T05:11:16.592337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-24T05:11:16.598053Z","iopub.execute_input":"2021-09-24T05:11:16.598408Z","iopub.status.idle":"2021-09-24T05:11:16.626968Z","shell.execute_reply.started":"2021-09-24T05:11:16.598373Z","shell.execute_reply":"2021-09-24T05:11:16.625943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CFG","metadata":{}},{"cell_type":"code","source":"params = {\n    'model': 'efficientnet_b0',\n    'dense_features': ['Subject Focus', 'Eyes', 'Face', 'Near',\n                       'Action', 'Accessory', 'Group', 'Collage',\n                       'Human', 'Occlusion', 'Info', 'Blur'],\n    'pretrained': False,\n    'inp_channels': 3,\n    'im_size': 256,\n    'device': device,\n    'batch_size': 32,\n    'num_workers' : 2,\n    'out_features': 1,\n    'debug': False\n}","metadata":{"execution":{"iopub.status.busy":"2021-09-24T05:11:16.62832Z","iopub.execute_input":"2021-09-24T05:11:16.628694Z","iopub.status.idle":"2021-09-24T05:11:16.635462Z","shell.execute_reply.started":"2021-09-24T05:11:16.628642Z","shell.execute_reply":"2021-09-24T05:11:16.634298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if params['debug']:\n    test_df = test_df.sample(frac=0.1)","metadata":{"execution":{"iopub.status.busy":"2021-09-24T05:11:16.637163Z","iopub.execute_input":"2021-09-24T05:11:16.637802Z","iopub.status.idle":"2021-09-24T05:11:16.649825Z","shell.execute_reply.started":"2021-09-24T05:11:16.637761Z","shell.execute_reply":"2021-09-24T05:11:16.648786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Augmentations","metadata":{}},{"cell_type":"code","source":"def get_test_transforms(DIM = params['im_size']):\n    return albumentations.Compose(\n        [\n          albumentations.Resize(DIM,DIM),\n          albumentations.Normalize(\n              mean=[0.485, 0.456, 0.406],\n              std=[0.229, 0.224, 0.225],\n              ),\n          ToTensorV2(p=1.0)\n        ]\n    )","metadata":{"execution":{"iopub.status.busy":"2021-09-24T05:11:16.651855Z","iopub.execute_input":"2021-09-24T05:11:16.652662Z","iopub.status.idle":"2021-09-24T05:11:16.660366Z","shell.execute_reply.started":"2021-09-24T05:11:16.65262Z","shell.execute_reply":"2021-09-24T05:11:16.659228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class CuteDataset(Dataset):\n    def __init__(self, images_filepaths, dense_features, targets, transform=None):\n        self.images_filepaths = images_filepaths\n        self.dense_features = dense_features\n        self.targets = targets\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.images_filepaths)\n\n    def __getitem__(self, idx):\n        image_filepath = self.images_filepaths[idx]\n        image = cv2.imread(image_filepath)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        if self.transform is not None:\n            image = self.transform(image=image)['image']\n        \n        dense = self.dense_features[idx, :]\n        label = torch.tensor(self.targets[idx]).float()\n        return image, dense, label","metadata":{"execution":{"iopub.status.busy":"2021-09-24T05:11:16.662202Z","iopub.execute_input":"2021-09-24T05:11:16.662575Z","iopub.status.idle":"2021-09-24T05:11:16.672572Z","shell.execute_reply.started":"2021-09-24T05:11:16.662532Z","shell.execute_reply":"2021-09-24T05:11:16.671444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CNN Model","metadata":{}},{"cell_type":"code","source":"class PetNet(nn.Module):\n    def __init__(self, model_name=params['model'], out_features=params['out_features'], inp_channels=params['inp_channels'],\n                 pretrained=params['pretrained'], num_dense=len(params['dense_features'])):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=inp_channels)\n        if model_name.split('_')[0] == 'efficientnet':\n            out_channels = self.model.conv_stem.out_channels\n            kernel_size = self.model.conv_stem.kernel_size\n            stride = self.model.conv_stem.stride\n            padding = self.model.conv_stem.padding\n            bias = self.model.conv_stem.bias\n            self.model.conv_stem = nn.Conv2d(inp_channels, out_channels,\n                                             kernel_size=kernel_size, stride=stride,\n                                             padding=padding, bias=bias)\n            n_features = self.model.classifier.in_features\n            self.model.classifier = nn.Identity()\n        elif model_name.split('_')[0] == 'nfnet':\n            n_features = self.model.head.fc.in_features\n            self.model.head.fc = nn.Identity()\n        elif model_name in ['resnet18d', 'resnet50d', 'resnet152d',\n                            'seresnet50', 'seresnext26d_32x4d', 'seresnext50_32x4d',\n                            'resnetblur18', 'resnetblur50']:\n            n_features = self.model.fc.in_features\n            self.model.fc = nn.Identity()\n\n        self.dropout = nn.Dropout(0.1)\n        self.fc = nn.Linear(n_features + num_dense, out_features)\n    \n    def forward(self, image, dense):\n        embeddings = self.model(image)\n        x = self.dropout(embeddings)\n        x = torch.cat([x, dense], dim=1)\n        output = self.fc(x)\n        return output","metadata":{"execution":{"iopub.status.busy":"2021-09-24T05:11:16.674472Z","iopub.execute_input":"2021-09-24T05:11:16.67521Z","iopub.status.idle":"2021-09-24T05:11:16.690646Z","shell.execute_reply.started":"2021-09-24T05:11:16.675165Z","shell.execute_reply":"2021-09-24T05:11:16.689218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction","metadata":{}},{"cell_type":"code","source":"predicted_labels = None\nfor model_name in glob.glob(models_dir + '/*.pth'):\n    model = PetNet()\n    model.load_state_dict(torch.load(model_name))\n    model = model.to(params['device'])\n    model.eval()\n\n    test_dataset = CuteDataset(\n        images_filepaths = test_df['image_path'].values,\n        dense_features = test_df[params['dense_features']].values,\n        targets = sample_df['Pawpularity'].values,\n        transform = get_test_transforms()\n    )\n    test_loader = DataLoader(\n        test_dataset, batch_size=params['batch_size'],\n        shuffle=False, num_workers=params['num_workers'],\n        pin_memory=True\n    )\n\n    temp_preds = None\n    with torch.no_grad():\n        for (images, dense, target) in tqdm(test_loader, desc=f'Predicting. '):\n            images = images.to(params['device'], non_blocking=True)\n            dense = dense.to(params['device'], non_blocking=True)\n            predictions = model(images, dense).to('cpu').numpy()\n            \n            if temp_preds is None:\n                temp_preds = predictions\n            else:\n                temp_preds = np.vstack((temp_preds, predictions))\n\n    if predicted_labels is None:\n        predicted_labels = temp_preds\n    else:\n        predicted_labels += temp_preds\n        \npredicted_labels /= (len(glob.glob(models_dir + '/*.pth')))","metadata":{"execution":{"iopub.status.busy":"2021-09-24T05:11:16.695501Z","iopub.execute_input":"2021-09-24T05:11:16.695866Z","iopub.status.idle":"2021-09-24T05:11:28.177832Z","shell.execute_reply.started":"2021-09-24T05:11:16.695838Z","shell.execute_reply":"2021-09-24T05:11:28.176577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = pd.DataFrame()\nsub_df['Id'] = test_df['Id']\nsub_df['Pawpularity'] = predicted_labels","metadata":{"execution":{"iopub.status.busy":"2021-09-24T05:11:28.180251Z","iopub.execute_input":"2021-09-24T05:11:28.181056Z","iopub.status.idle":"2021-09-24T05:11:28.193082Z","shell.execute_reply.started":"2021-09-24T05:11:28.180996Z","shell.execute_reply":"2021-09-24T05:11:28.191285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-24T05:11:28.195065Z","iopub.execute_input":"2021-09-24T05:11:28.196458Z","iopub.status.idle":"2021-09-24T05:11:28.216347Z","shell.execute_reply.started":"2021-09-24T05:11:28.196406Z","shell.execute_reply":"2021-09-24T05:11:28.215196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-24T05:11:28.218027Z","iopub.execute_input":"2021-09-24T05:11:28.219309Z","iopub.status.idle":"2021-09-24T05:11:28.230889Z","shell.execute_reply.started":"2021-09-24T05:11:28.219248Z","shell.execute_reply":"2021-09-24T05:11:28.229694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**If you find this notebook useful and use parts of it in your work, please don't forget to show your appreciation by upvoting this kernel. That keeps me motivated and inspires me to write and share these public kernels. ðŸ˜Š**","metadata":{}}]}