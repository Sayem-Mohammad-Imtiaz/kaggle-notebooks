{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![SETI](https://earthsky.org/upl/2020/02/Earth-transit-zone-Breakthrough-Listen.jpg)\n\n# About This Notebook\n\nThis is simply the Inference Notebook for models I have trained separately.\n* Training Notebook:- [SETI : EDA and Pytorch Starter](https://www.kaggle.com/manabendrarout/nfnet-pytorch-starter-lb-0-95)\n\n**If you found this notebook useful and use parts of it in your work, please don't forget to show your appreciation by upvoting this kernel. That keeps me motivated and inspires me to write and share these public kernels.** ðŸ˜Š","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import sys\nsys.path.append('../input/pytorch-image-models/pytorch-image-models-master')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Asthetics\nimport warnings\nimport sklearn.exceptions\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\nwarnings.filterwarnings('ignore', category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n\n# General\nfrom tqdm import tqdm\nimport pandas as pd\nimport numpy as np\nimport os\nimport random\nimport glob\npd.set_option('display.max_columns', None)\n\n# Image Aug\nimport albumentations\nfrom albumentations.pytorch.transforms import ToTensorV2\n\n# Deep Learning\nimport torch\nimport torchvision\nimport timm\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\n\n# Random Seed Initialize\nRANDOM_SEED = 42\n\ndef seed_everything(seed=RANDOM_SEED):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    \nseed_everything()\n\n# Device Optimization\nif torch.cuda.is_available():\n    device = torch.device('cuda')\nelse:\n    device = torch.device('cpu')\n    \nprint(f'Using device: {device}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"csv_dir = '../input/seti-breakthrough-listen'\ntest_dir = '../input/seti-breakthrough-listen/test'\n\nsample_sub_file_path = os.path.join(csv_dir, 'sample_submission.csv')\nprint(f'Train file: {sample_sub_file_path}')\n\ntest_df = pd.read_csv(sample_sub_file_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def return_filpath(name, folder=test_dir):\n    path = os.path.join(folder, name[0], f'{name}.npy')\n    return path","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['image_path'] = test_df['id'].apply(lambda x: return_filpath(x))\ntest_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"params = {\n    'model': 'nfnet_l0',\n    'inp_channels': 1,\n    'device': device,\n    'batch_size': 32,\n    'num_workers' : 0,\n    'out_features': 1,\n    'path': '../input/seti-pytorch-models/nfnet_l0_6_epoch_0.98_roc_auc.pth',\n    'TTA': 3\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Image Augmentations","metadata":{}},{"cell_type":"code","source":"def get_test_transforms(TTA):\n    '''\n    Returns an augmented Image if the TTA count is > 1 otherwise\n    returns the resized image only.\n    '''\n    if TTA > 1:\n        return albumentations.Compose(\n            [\n                albumentations.Resize(256,256),\n                albumentations.HorizontalFlip(p=0.5),\n                albumentations.VerticalFlip(p=0.5),\n                albumentations.Rotate(limit=180, p=0.7),\n                albumentations.RandomBrightness(limit=0.6, p=0.5),\n                albumentations.ShiftScaleRotate(\n                    shift_limit=0.25, scale_limit=0.1, rotate_limit=0\n                ),\n                ToTensorV2(p=1.0),\n            ]\n        )\n    \n    else:\n        return albumentations.Compose(\n            [\n                albumentations.Resize(256,256),\n                ToTensorV2(p=1.0)\n            ]\n        )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset Class","metadata":{}},{"cell_type":"code","source":"class SETIDataset(Dataset):\n    def __init__(self, images_filepaths, targets, transform=None):\n        self.images_filepaths = images_filepaths\n        self.targets = targets\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.images_filepaths)\n\n    def __getitem__(self, idx):\n        image_filepath = self.images_filepaths[idx]\n        image = np.load(image_filepath)\n        image = image.astype(np.float32)\n        image = np.vstack(image).transpose((1, 0))\n            \n        if self.transform is not None:\n            image = self.transform(image=image)[\"image\"]\n        else:\n            image = image[np.newaxis,:,:]\n            image = torch.from_numpy(image).float()\n        \n        label = torch.tensor(self.targets[idx]).float()\n        return image, label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CNN Model","metadata":{}},{"cell_type":"code","source":"class AlienNet(nn.Module):\n    def __init__(self, model_name=params['model'], out_features=params['out_features'],\n                 inp_channels=params['inp_channels'], pretrained=True):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained,\n                                       in_chans=inp_channels)\n        if model_name.split('_')[0] == 'efficientnet':\n            n_features = self.model.classifier.in_features\n            self.model.conv_stem = nn.Conv2d(inp_channels, 40, kernel_size=(3, 3),\n                                             stride=(2, 2), padding=(1, 1), bias=False)\n            self.model.classifier = nn.Linear(n_features, out_features)\n        \n        elif model_name.split('_')[0] == 'nfnet':\n            n_features = self.model.head.fc.in_features\n            self.model.head.fc = nn.Linear(n_features, out_features)\n    \n    def forward(self, x):\n        x = self.model(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AlienNet()\nmodel.load_state_dict(torch.load(params['path'], map_location=device))\nmodel = model.to(params['device'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prediction","metadata":{}},{"cell_type":"code","source":"model.eval()\npredicted_labels = None\nfor i in range(params['TTA']):\n    test_dataset = SETIDataset(\n        images_filepaths = test_df['image_path'].values,\n        targets = test_df['target'].values,\n        transform=get_test_transforms(params['TTA'])\n    )\n    test_loader = DataLoader(\n        test_dataset, batch_size=params['batch_size'],\n        shuffle=False, num_workers=params['num_workers']\n    )\n    \n    temp_preds = None\n    with torch.no_grad():\n        for (images, target) in tqdm(test_loader):\n            images = images.to(params['device'], non_blocking=True)\n            output = model(images)\n            predictions = torch.sigmoid(output).cpu().numpy()\n            if temp_preds is None:\n                temp_preds = predictions\n            else:\n                temp_preds = np.vstack((temp_preds, predictions))\n    \n    if predicted_labels is None:\n        predicted_labels = temp_preds\n    else:\n        predicted_labels += temp_preds\n        \npredicted_labels /= params['TTA']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = pd.DataFrame()\nsub_df['id'] = test_df['id']\nsub_df['target'] = predicted_labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is a simple starter kernel on implementation of Transfer Learning using Pytorch for this problem. Pytorch has many SOTA Image models which you can try out using the guidelines in this notebook.\n\nI hope you have learnt something from this notebook. I have created this notebook as a baseline model, which you can easily fork and paly-around with to get much better results. I might update parts of it down the line when I get more GPU hours and some interesting ideas.\n\n**If you liked this notebook and use parts of it in you code, please show some support by upvoting this kernel. It keeps me inspired to come-up with such starter kernels and share it with the community.**\n\nThanks and happy kaggling!","metadata":{}}]}