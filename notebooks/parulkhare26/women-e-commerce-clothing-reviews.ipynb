{"cells":[{"metadata":{},"cell_type":"markdown","source":"import the libraries","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas_profiling\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix\nimport sklearn.metrics as mt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Read dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/womens-ecommerce-clothing-reviews/Womens Clothing E-Commerce Reviews.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"here the maximum null values are in the title and second most in the review text.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# group by the ratings as per the recommended id.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(['Rating', 'Recommended IND'])['Recommended IND'].count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we can drop some colums as they are not meaningfull for our data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df1=df.drop(['Unnamed: 0','Division Name','Department Name',],axis=1)\ndf1.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"check the null values in the reviews columns and drop them from the column.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df1[df1['Review Text'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"dropping the null values for review text from the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df1[~df1['Review Text'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.head(77)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Visualization","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's find the how much clothes are recommendable in our data ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.offline as py\nimport plotly.graph_objs as go\nx=df1['Recommended IND'].value_counts()\ncolors = ['#FEBFB3', '#E1396C']\n\ntrace=go.Pie(labels=x.index,values=x,textinfo=\"value\",\n            marker=dict(colors=colors, \n                           line=dict(color='#000000', width=2)))\nlayout=go.Layout(title=\"Cloths are Recommended or not\",width=500,height=500)\nfig=go.Figure(data=[trace],layout=layout)\npy.iplot(fig, filename='pie_chart_subplots')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"check the ratio of ratings in the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\nfig = px.histogram(df1, x=df1['Rating'], nbins=10)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"check the count of the class name of clothes in the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfig = px.histogram(df1, x = df1['Class Name'])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['review_len'] = df1['Review Text'].astype(str).apply(len)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"px.histogram(df1, x = 'review_len')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['token_count'] = df1['Review Text'].apply(lambda x: len(str(x).split()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"px.histogram(df1, x = 'token_count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install TextBlob\nfrom textblob import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['polarity'] = df1['Review Text'].map(lambda text: TextBlob(text).sentiment.polarity)\ndf1['polarity']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.histogram(df1, x = df1['polarity'])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reviews with Positive Polarity","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pop = df1.loc[df1.polarity == 1,['Review Text']].sample(3).values\nfor i in pop:\n    print(i[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reviews with Neutral Polarity","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pop = df1.loc[df1.polarity == 0.5,['Review Text']].sample(3).values\nfor i in pop:\n    print(i[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reviews with Negative Polarity","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pop = df1.loc[df1.polarity < 0,['Review Text']].sample(3).values\nfor i in pop:\n    print(i[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"negative = (len(df1.loc[df1.polarity <0,['Review Text']].values)/len(df1))*100\npositive = (len(df1.loc[df1.polarity >0.5,['Review Text']].values)/len(df1))*100\nneutral  = len(df1.loc[df1.polarity >0 ,['Review Text']].values) - len(df1.loc[df1.polarity >0.5 ,['Review Text']].values)\nneutral = neutral/len(df1)*100 \nplt.figure(figsize =(10, 7)) \nplt.pie([positive,negative,neutral], labels = ['Positive','Negative','Neutral'],colors = [ 'blue','#E1396C','#FEBFB3'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ratings with respect to the age of a customer","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\nAge = df1['Age']\nfx=sns.boxplot(x='Rating',y='Age',data=df1)\nplt.title(\"Distribution of age with respect to rating\")\nplt.xlabel(\"Rating\")\nplt.ylabel(\"Age\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df1['Recommended IND']\nX = df1.drop(columns = 'Recommended IND')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Correlation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,7))\nsns.heatmap(df1.corr(method='kendall'), annot=True )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Handling Multi-Colinearity","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"set1 =set()\ncor = df1.corr()\nfor i in cor.columns:\n    for j in cor.columns:\n        if cor[i][j]>0.8 and i!=j:\n            set1.add(i)\nprint(set1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = X.drop(labels = ['token_count'],axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Building","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"import some more libraries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.corpus import stopwords\nstop=stopwords.words('english')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let's see positive and negative words by using WordCloud.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud\npositivedata = df1[ df1['Recommended IND'] == 1]\npositivedata =positivedata['Review Text']\nnegdata = df1[df1['Recommended IND'] == 0]\nnegdata= negdata['Review Text']\n\ndef wordcloud_draw(df1, color = 'white'):\n    words = ' '.join(df1)\n    cleaned_word = \" \".join([word for word in words.split()\n                              if(word!='clothes' and word!='shop')\n                            ])\n    wordcloud = WordCloud(stopwords=stop,\n                      background_color=color,\n                      width=2500,\n                      height=2000\n                     ).generate(cleaned_word)\n    plt.figure(1,figsize=(10, 7))\n    plt.imshow(wordcloud)\n    plt.axis('off')\n    plt.show()\n    \nprint(\"Positive words are as follows\")\nwordcloud_draw(positivedata,'white')\nprint(\"Negative words are as follows\")\nwordcloud_draw(negdata)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corpus =[]\nX.index = np.arange(len(X))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(X)):\n    review = re.sub('[^a-zA-z]',' ',X['Review Text'][i])\n    review = review.lower()\n    review = review.split()\n    ps = PorterStemmer()\n    review =[ps.stem(i) for i in review if not i in set(stopwords.words('english'))]\n    review =' '.join(review)\n    corpus.append(review)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CountVectorizer ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer as CV\ncv  = CV(max_features = 3000,ngram_range=(1,1))\nX_cv = cv.fit_transform(corpus).toarray()\ny = y.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_cv, y, test_size = 0.20, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Bernoulli Naive Bayes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import BernoulliNB\nclassifier = BernoulliNB()\nclassifier.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifier.predict(X_test)\nfrom sklearn.metrics import accuracy_score\nacc = accuracy_score(y_test, y_pred)\nprint('accuracy:',acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Tf-Idf Vectorizer","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer as TV\ntv  = TV(ngram_range =(1,1),max_features = 3000)\nX_tv = tv.fit_transform(corpus).toarray()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Mulinomial Naive Bayes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_tv, y, test_size = 0.20, random_state = 0)\nfrom sklearn.naive_bayes import MultinomialNB\nclassifier = MultinomialNB()\nclassifier.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifier.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\nprint(\"accuracy:\" , acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forrest Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier()\nclassifier.fit(X_train,y_train)\npreds=classifier.predict(X_test)\nrf_accuracy=accuracy_score(preds,y_test)\nprint(\"Random Forest Model accuracy\",rf_accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# XGBoost Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nxgb=xgb.XGBClassifier()\nxgb.fit(X_train,y_train)\npreds2=xgb.predict(X_test)\nxgb_accuracy=accuracy_score(preds2,y_test)\nprint(\"XGBoost Model accuracy\",xgb_accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegressionCV\nclassifier=LogisticRegressionCV(cv=6,scoring='accuracy',random_state=0,n_jobs=-1,verbose=3,max_iter=500).fit(X_train,y_train)\ny_pred1 = classifier.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nprint(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test, y_pred1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Deep Learning Model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Creating a ANN structure","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\ntokenizer = Tokenizer(num_words = 3000)\ntokenizer.fit_on_texts(corpus)\nsequences = tokenizer.texts_to_sequences(corpus)\npadded = pad_sequences(sequences, padding='post')\nword_index = tokenizer.word_index\ncount = 0\nfor i,j in word_index.items():\n    if count == 11:\n        break\n    print(i,j)\n    count = count+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_dim = 64\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Embedding(3000, embedding_dim),\n    tf.keras.layers.GlobalAveragePooling1D(),\n    tf.keras.layers.Dense(6, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 10\n\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nmodel.fit(padded,y,epochs= num_epochs,validation_split= 0.39)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualising Model history","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = model.history.history\nloss = pd.DataFrame(loss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\nt = f.suptitle('Basic ANN Performance', fontsize=12)\nf.subplots_adjust(top=0.85, wspace=0.3)\n\nepoch_list = range(1,11)\nax1.plot(epoch_list, loss['accuracy'], label='Train Accuracy')\nax1.plot(epoch_list, loss['val_accuracy'], label='Validation Accuracy')\nax1.set_xticks(np.arange(0, 11, 1))\nax1.set_ylabel('Accuracy Value')\nax1.set_xlabel('Epoch')\nax1.set_title('Accuracy')\nl1 = ax1.legend(loc=\"best\")\n\nax2.plot(epoch_list, loss['loss'], label='Train Loss')\nax2.plot(epoch_list, loss['val_loss'], label='Validation Loss')\nax2.set_xticks(np.arange(0, 11, 1))\nax2.set_ylabel('Loss Value')\nax2.set_xlabel('Epoch')\nax2.set_title('Loss')\nl2 = ax2.legend(loc=\"best\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Checking the model on a random example","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_string = \"I hate this dress\"\nsample = tokenizer.texts_to_sequences(sample_string)\npadded_sample = pad_sequences(sample, padding='post')\nprint(\"Padded sample\", padded_sample.T)\nprint(\"Probabilty of a person recommending :\",model.predict(padded_sample.T)[0][0]*100,\"%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_string = \"i love the fabric\"\nsample = tokenizer.texts_to_sequences(sample_string)\npadded_sample = pad_sequences(sample, padding='post')\nprint(\"Padded sample\", padded_sample.T)\nprint(\"Probabilty of a person recommending :\",model.predict(padded_sample.T)[0][0]*100,\"%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}