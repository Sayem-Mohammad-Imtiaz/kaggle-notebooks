{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"d215 = pd.read_csv(\"/kaggle/input/world-happiness/2015.csv\")\nd216 = pd.read_csv(\"/kaggle/input/world-happiness/2016.csv\")\nd217 = pd.read_csv(\"/kaggle/input/world-happiness/2017.csv\")\nd218 = pd.read_csv(\"/kaggle/input/world-happiness/2018.csv\")\nd219 = pd.read_csv(\"/kaggle/input/world-happiness/2019.csv\")\n\ndlist = [d215, d216, d217, d218, d219]\nyears = [2015, 2016, 2017, 2018, 2019]\n\nfor x, y in zip(years,dlist):\n    print(\"Shape of data from \", x, \": \", y.shape, \"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for x in dlist:\n    print(x.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d217","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data is very different. For example data from 2019 has 9 columns and data from 2015 has 12 columns. We will need to figure out what data is missing in 2019. In order to be able to quickly compare two dataframes with one another, we write a compare_columns function."},{"metadata":{"trusted":true},"cell_type":"code","source":"def compare_columns(df1, df2):\n    \"\"\" \n    Takes two lists or tuples as arguments and compares them\n    \n    We can use this function to compare two lists and get the values that are in one list and not in the other\n    \"\"\"\n    \n    c1 = df1.columns\n    c2 = df2.columns\n    \n    rl1 = list()\n    \n    for value in c1:\n        if value not in c2:\n            rl1.append(value)\n            \n    print(\"Comparing Values\")        \n            \n    for x in rl1:\n        print(x, \"not in second dataframe\")\n        \ncompare_columns(d215,d218)\n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After some closer inspection of the columns, we can notice that some columns just have different names in different dataframes. For exmaple, in years 2015, 2016, 2017 we have the columns \"Country\" and \"Region\" seperately, whereas in years 2018 and 2019 we have the column \"Country or Region\" as one column. In order to be able to work with our data, we need to make sure that it's consistent. So we rename the columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Renaming Columns due to data inconsistency\nd215_1 = d215.rename(columns = {\"Happiness Rank\":\"Rank\", \"Happiness Score\":\"Score\", \"Economy (GDP per Capita)\":\"GDP\",\n                             \"Health (Life Expectancy)\":\"Life Expectancy\", \"Trust (Government Corruption)\":\"Trust\"})\nd216_1 = d216.rename(columns = {\"Happiness Rank\": \"Rank\", \"Happiness Score\": \"Score\", \"Lower Confidence Interval\":\"Lower\",\n                             \"Upper Confidence Interval\":\"Upper\", \"Economy (GDP per Capita)\":\"GDP\", \n                              \"Health (Life Expectancy)\":\"Life Expectancy\", \"Trust (Government Corruption)\":\"Trust\"})\nd217_1 = d217.rename(columns = {\"Happines.Rank\":\"Rank\", \"Happiness.Score\":\"Score\", \"Happiness.Rank\":\"Happiness\", \n                              \"Whisker.high\":\"High\", \"Whisker.low\":\"Low\", \"Economy..GDP.per.Capita.\":\"GDP\", \n                              \"Health..Life.Expectancy.\":\"Life Expectancy\", \"Trust..Government.Corruption.\":\"Trust\",\n                             \"Dystopia.Residual\":\"Dystopia Residual\"})\nd218_1 = d218.rename(columns = {\"Country or region\":\"Country\", \n                              \"Freedom to make life choices\":\"Freedom\", \n                              \"GDP per capita\":\"GDP\", \n                              \"Overall rank\":\"Rank\", \n                              \"Social support\":\"Social Support\", \n                              \"Perceptions of corruption\":\"Trust\",\n                             \"Healthy life expectancy\":\"Life Expectancy\"})\nd219_1 = d219_1.rename(columns = {\"Overall rank\":\"Rank\", \"Country or region\": \"Country\", \"GDP per capita\":\"GDP\", \"Social support\":\"Social Support\",\n                             \"Healthy life expectancy\":\"Life Expectancy\", \"Freedom to make life choices\":\"Freedom\", \"Perceptions of corruption\":\"Trust\"})\n\n\n# d215 = d215.drop(\"Standard Error\", axis = 1)\n\ndlist = [d215_1, d216_1,d217_1,d218_1,d219_1]\n\nd219_1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I want to compare the averages of all countries of each value and see if there is any correlation on a global scale. Instead of manually taking the averages, I will make a function to do it for me. In the end, I will plot the averages of each value throught the years to see if we can find a pattern."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creting a function that averages that values of a column in a table\n\ndef get_yearly_averages(value, dataframes):\n    \"\"\"\n    Gets averages for certain values from each year\n    \n    Value - the Value as a string of the column that should be averaged for each year\n    Dataframes - takes a list of dataframes\n    \"\"\"\n    averages = list()\n    \n    for x in dataframes:\n        averages.append(x[value].mean())\n        \n    averages = list(zip(years,averages))                                  # Years referenced in earlier cell\n    averages = pd.DataFrame(averages, columns = [\"Year\", value])\n    averages = averages.set_index(\"Year\")                                 # Making sure we index by year, not 1,2,3,..\n    \n    return averages\n\n# Average Happiness score Dataframe (Global)\navg_score = get_yearly_averages(\"Score\", dlist)\n\n# Average GDP (Global)\navg_gdp = get_yearly_averages(\"GDP\", dlist)\n\n# Average Life Expectancy (Global)\navg_le = get_yearly_averages(\"Life Expectancy\", dlist)\n\n\nyearly_averages = pd.concat([avg_score, avg_gdp, avg_le], sort=True, axis = 1)\n\navg_le.plot(kind=\"bar\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nhap_15_avg = d215[\"Score\"].mean()\nhap_16_avg = d216[\"Score\"].mean()\nhap_17_avg = d217[\"Score\"].mean()\nhap_18_avg = d218[\"Score\"].mean()\nhap_19_avg = d219[\"Score\"].mean()\n\ndata = [[2015, hap_15_avg], [2016, hap_16_avg], [2017, hap_17_avg], [2018, hap_18_avg], [2019, hap_19_avg]]\navg_hap = pd.DataFrame(data, columns = [\"Year\", \"Happiness\"])\navg_hap.astype({\"Year\":\"int\"})\navg_hap = avg_hap.set_index(\"Year\")\navg_hap.plot(kind=\"line\", alpha = 0.5)\nplt.xticks(range(2015,2020))\nplt.title(\"Average Happiness over the years\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Syria Happines Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"d215_2 = d215_1.set_index(\"Country\")\nd216_2 = d216_1.set_index(\"Country\")\nd217_2 = d217_1.set_index(\"Country\")\nd218_2 = d218_1.set_index(\"Country\")\nd219_2 = d218_1.set_index(\"Country\")\n\ns16 = d216_2.loc[\"Syria\"]\ns17 = d217_2.loc[\"Syria\"]\ns18 = d218_2.loc[\"Syria\"]\ns19 = d219_2.loc[\"Syria\"]\n\ns16","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}