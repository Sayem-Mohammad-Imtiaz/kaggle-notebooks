{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Iris Dataset\n\n**Context**\n\nThe Iris flower data set is a multivariate data set introduced by the British statistician and biologist Ronald Fisher in his 1936 paper The use of multiple measurements in taxonomic problems. It is sometimes called Anderson's Iris data set because Edgar Anderson collected the data to quantify the morphologic variation of Iris flowers of three related species. The data set consists of 50 samples from each of three species of Iris (Iris Setosa, Iris virginica, and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters.\n\nThis dataset became a typical test case for many statistical classification techniques in machine learning such as support vector machines\n\nContent\nThe dataset contains a set of 150 records under 5 attributes - Petal Length, Petal Width, Sepal Length, Sepal width and Class(Species)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# required libraries\n\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nnp.seterr(divide='ignore', invalid='ignore')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# read the dataset\niris_data = pd.read_csv('../input/iris-flower-dataset/IRIS.csv')\niris_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"iris_data.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"iris_data.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Fixing the the headings**"},{"metadata":{"trusted":true},"cell_type":"code","source":"iris_data.columns = iris_data.columns.str.title()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"iris_data.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**label encode the target variable**"},{"metadata":{"trusted":true},"cell_type":"code","source":"encode = LabelEncoder()\niris_data.Species = encode.fit_transform(iris_data.Species)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"iris_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis\n\nLet's create some simple plots to check out the data!"},{"metadata":{"trusted":true},"cell_type":"code","source":"iris_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"iris_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_style(\"whitegrid\")\nsns.pairplot(iris_data, hue=\"Species\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(iris_data.corr(), cmap=\"magma\",annot=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train Test Split\nlet's split the data into a training set and a testing set. We will train out model on the training set and then use the test set to evaluate the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = iris_data.drop('Species', axis=1)\ny = iris_data['Species']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train-test-split   \n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('shape of training data : ',X_train.shape)\nprint('shape of testing data',X_test.shape)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create the object of the model\nmodel = LogisticRegression(solver='newton-cg', multi_class='auto')\n\nmodel.fit(X_train,y_train)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = model.predict(X_test)\npredict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Evaluation\nLet's evaluate the model by checking out it's coefficients and how we can interpret them."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Summary of the predictions made by the classifier\nprint(classification_report(y_test, predict))\nprint(confusion_matrix(y_test, predict))\n\n# Accuracy score\nprint('\\n\\nAccuracy Score on test data : \\n\\n')\nprint(accuracy_score(y_test,predict))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Using KNN\nImport KNeighborsClassifier from scikit learn"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Create a KNN model instance with n_neighbors=1**"},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Fit this KNN model to the training data.**\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"knn.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = knn.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predictions and Evaluations\n\nLet's evaluate our KNN model!"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_test,pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Choosing a K Value\n\nLet's go ahead and use the elbow method to pick a good K Value:"},{"metadata":{"trusted":true},"cell_type":"code","source":"error_rate = []\n\n# Will take some time\nfor i in range(1,40):\n    \n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train,y_train)\n    pred_i = knn.predict(X_test)\n    error_rate.append(np.mean(pred_i != y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',\n         markerfacecolor='red', markersize=10)\nplt.title('Error Rate vs. K Value')\nplt.xlabel('K')\nplt.ylabel('Error Rate')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we can see that that after arouns K>1 the error rate just tends to hover around 0.06-0.05 Let's retrain the model with that and check the classification report!"},{"metadata":{"trusted":true},"cell_type":"code","source":"# NOW WITH K=23\nknn = KNeighborsClassifier(n_neighbors=1)\n\nknn.fit(X_train,y_train)\npred = knn.predict(X_test)\n\nprint('WITH K=23')\nprint('\\n')\nprint(confusion_matrix(y_test,pred))\nprint('\\n')\nprint(classification_report(y_test,pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train a (SVM) Support Vector Machine Model\n\nNow its time to train a Support Vector Machine Classifier. \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svc_model = SVC()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svc_model.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true},"cell_type":"markdown","source":"## Model Evaluation\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = svc_model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Wow! You should have noticed that your model was pretty good! Let's see if we can tune the parameters to try to get even better (unlikely, and you probably would be satisfied with these results in real like because the data set is quite small, but I just want to practice using GridSearch."},{"metadata":{},"cell_type":"markdown","source":"## Gridsearch Practice\n\n** Import GridsearchCV from SciKit Learn.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Create a dictionary called param_grid and fill out some parameters for C and gamma.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001]} ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Create a GridSearchCV object and fit it to the training data.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=2)\ngrid.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Now take that grid model and create some predictions using the test set and create classification reports and confusion matrices for them."},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_predictions = grid.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_test,grid_predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,grid_predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You should have done about the same or exactly the same, this makes sense, there is basically just one point that is too noisey to grab, which makes sense, we don't want to have an overfit model that would be able to grab that."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}