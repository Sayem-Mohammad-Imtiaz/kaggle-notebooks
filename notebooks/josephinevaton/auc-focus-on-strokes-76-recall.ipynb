{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1- EXPLORATORY DATA ANALYSE","metadata":{}},{"cell_type":"markdown","source":"## INTRODUCTION","metadata":{}},{"cell_type":"markdown","source":"## Objectif : \n- Comprendre au maximum les données dont on dispose pour définir une stratégie de modélisation\n\n- Dévolopper une première stratégie de modélisation\n\n#### ANALYSE DE LA FORME : \n\n- **Identification de la target** : stroke\n\n- **Nombre de lignes et de colonnes** : 5110 lignes et 12 colonnes\n\n- **Types de variables** : qualitatives : 9, quantitatives : 3\n\n- **Identification des valeurs manquantes** : peu de NaN, seulement sur la variable bmi (indice de masse corporelle), il y a 4% de valeurs manquantes\n\n","metadata":{}},{"cell_type":"markdown","source":"#### ANALYSE DE LA FORME","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\ndata = pd.read_csv('../input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv', delimiter = ',', encoding = 'utf-8')\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = data.copy()\ndf.dtypes\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dtypes.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Identification des valeurs manquantes :\n\nimport seaborn as sns \nplt.figure(figsize =  (20,10))\nsns.heatmap(df.isna(), cbar = False)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum()/df.shape[0]\n(df.isna().sum()/df.shape[0]).sort_values(ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### ANALYSE DE FOND : \n\n- **Visualisation de la target (Histogramme si c’est une valeur continue / Boxplot si c’est une valeur discrète** : \n    - Seulement 4% de positifs\n\n- **Signification des différentes variables** :\n    - Variables continues : non-standardisées, asymétriques\n    - Variables age : age varie de 0 à 80 ans, on pourra créer une variable pour les catégories d'age plus tard\n    - Variables qualitatives : plus de femmes, plus de mariés, plus de personnes travaillant dans le privé. Peu de malades hypertension, et maladie du coeur. Une inconnu sur les fumeurs'unknow'\n\n- **Relations features – target (Histogramme / Boxplot)** :\n    - target / catégorie : Pour l'instant on ne peut rien tirer de ces graphs \n    - target / age : très peu d'accident vasculaire avant 40 ans, cela augmente avec l'age. La'ge pourrait etre une variable interessante\n    - target / viral : l'age et le glucose pourrait être des facteurs => à tester","metadata":{}},{"cell_type":"code","source":"df['stroke'].value_counts(normalize = True)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in df.select_dtypes('float'):\n    print(col)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in df.select_dtypes('float'):\n    plt.figure()\n    sns.distplot(df[col])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in df.select_dtypes('object'):\n    plt.figure()\n    df[col].value_counts().plot.pie()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['hypertension'].value_counts().plot.pie()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['heart_disease'].value_counts().plot.pie()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# création des sous-ensemble \n\nnegative_df = df[df['stroke'] == 0]\n\npositive_df = df[df['stroke'] == 1]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"positive_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_columns = df[['hypertension','heart_disease','gender','ever_married','work_type','Residence_type','smoking_status']].columns.to_list()\n\nnum_columns = df[['age','avg_glucose_level','bmi' ]].columns.to_list()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Relation catégorie / target \n\nfor col in cat_columns : \n    plt.figure()\n    sns.heatmap(pd.crosstab(df['stroke'], df[col]), annot = True, fmt = 'd')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#target / age\n\nplt.figure(figsize = (20,8))\nsns.countplot(x = 'age', hue = 'stroke', data = df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (12,8))\nplt.scatter(df['age'], df['bmi'], c = df['stroke'], alpha = 0.4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#target /numé \n\nfor i in num_columns: \n    plt.figure()\n    sns.distplot(positive_df[i], label= 'positive')\n    sns.distplot(negative_df[i], label= 'negative')\n    plt.legend()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### ANALYSE DETAILLEE : \n\n- ** Relations variables / Variables ** :\n    - Numérique / Numérique : pas de relation linéaire\n    - Numérique / age : Pas de relation linéaire\n    - Catégorielles / Catégorielles : \n    - Catégorielles / Age : \n\n- **Sous-Ensemble** :\n    - est malade (hypertension et maladie cardiaque) : on une IMC plus élévé, un age plus élevé aussi \n\n- **Test hypothèses ** : ","metadata":{}},{"cell_type":"code","source":"sns.pairplot(df[num_columns])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(df[num_columns].corr())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.corr()['age'\n         ].sort_values()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.crosstab(df['hypertension'], df['heart_disease'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['smoking_status'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['est malade'] = np.sum(df[['hypertension','heart_disease' ]] == 1, axis = 1) >=1\n\nmalade_df = df[df['est malade'] == True]\nnon_malade_df = df[df['est malade'] == False]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in num_columns : \n    plt.figure()\n    sns.distplot(malade_df[i], label= 'malade')\n    sns.distplot(non_malade_df[i], label= 'non malade')\n    plt.legend()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.stats import ttest_ind\n\npositive_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"negative_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"balanced_neg = negative_df.sample(positive_df.shape[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"balanced_neg.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def t_test (col) : \n    alpha = 0.2\n    stat, p = ttest_ind(balanced_neg[col].dropna(), positive_df[col].dropna())\n    if p < alpha : \n        return 'H0 Rejectée'\n    else : \n        return 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in cat_columns : \n    print(f'{col}{t_test(col)}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in num_columns : \n    print(f'{col}{t_test(col)}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2- PRE TRAITEMENT DES DONNÉES","metadata":{}},{"cell_type":"code","source":"df = df.drop('id', axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Autres visualisation","metadata":{}},{"cell_type":"code","source":"%matplotlib\nfrom mpl_toolkits.mplot3d import Axes3D\nax = plt.axes(projection = '3d')\nax.scatter(df['hypertension'], df['age'], df['heart_disease'], c=df['stroke'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Encodage ","metadata":{}},{"cell_type":"code","source":"# Colonne Gender : \n\ndf.loc[df['gender'] == 'Male','gender'] = 0\ndf.loc[df[\"gender\"] == \"Female\",\"gender\"] = 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Colonne Ever Married :\n\ndf.loc[df['ever_married'] == \"Yes\", 'ever_married'] = 1\ndf.loc[df['ever_married'] == \"No\", 'ever_married'] = 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Colonne Residence\n\n\ndf.loc[df['Residence_type'] == \"Urban\", 'Residence_type'] = 1\ndf.loc[df['Residence_type'] == \"Rural\", 'Residence_type'] = 0\n\ndf = df.rename(columns = {'Residence_type': 'Urban_residence'}) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_columns = ['hypertension','heart_disease','gender','ever_married','work_type','Urban_residence','smoking_status']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Colonne Work Type et Smoking Status\n\ndf2 = pd.get_dummies(df[['work_type', 'smoking_status']], prefix=['work_type', 'smoking_status'])\n\ndf = df.join(df2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Suppression des colonnes 'work_type','smoking_status','smoking_status_Unknown','smoking_status_never smoked'\n\ndf = df.drop(['work_type','smoking_status','smoking_status_Unknown','smoking_status_never smoked'], axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Suppression de la colonne work type children\n\ndf = df.drop('work_type_children', axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.loc[df['est malade'] == True, 'est malade'] = 1\ndf.loc[df['est malade'] == False, 'est malade'] = 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fonctions de preprocessing","metadata":{}},{"cell_type":"code","source":"# On supprime la ligne Gender = Other\nindexNames = df[df['gender'] == 'Other'].index\nindexNames\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop(index = indexNames)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# On remet les bons types aux colonnes\n\ndf[['age', 'avg_glucose_level','bmi']] = df[['age', 'avg_glucose_level','bmi']].astype(float)\ndf[['gender','ever_married','Urban_residence','est malade' ]] = df[['gender','ever_married','Urban_residence','est malade' ]].astype(int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[['work_type_Govt_job', 'work_type_Never_worked','work_type_Private','work_type_Self-employed',\n   'smoking_status_formerly smoked','smoking_status_smokes']] = df[['work_type_Govt_job', 'work_type_Never_worked','work_type_Private','work_type_Self-employed',\n   'smoking_status_formerly smoked','smoking_status_smokes']].astype(int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def imputation(df): \n    return df.dropna(axis =0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" def feature_engineering (df) : \n        df['est malade'] = np.sum(df[['hypertension','heart_disease' ]] == 1, axis = 1) >=1\n        df = df.drop(['hypertension','heart_disease'], axis = 1)\n        \n        df['a fumé'] = np.sum(df[['smoking_status_formerly smoked','smoking_status_smokes']] == 1, axis = 1) >=1\n        df = df.drop(['smoking_status_formerly smoked','smoking_status_smokes'], axis = 1)\n        \n        df['vieux'] = df.loc[df['age'] >= 55, 'age']\n        df.loc[df['vieux'] >= 50, 'vieux'] = 1\n        df['vieux'] = df['vieux'].fillna(0)\n        \n        return df\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocessing (df) : \n    \n    df = imputation(df)\n    df = feature_engineering(df)\n    \n    X = df.drop('stroke', axis = 1)\n    y = df['stroke']\n    \n    print(y.value_counts(normalize = True))\n    \n    return X,y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainset, testset = train_test_split(df, test_size = 0.2, random_state = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, y_train = preprocessing(trainset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test, y_test = preprocessing(testset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Sur echantillonnage","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE \n\nsmote = SMOTE(sampling_strategy = 0.1)\nX_train, y_train = smote.fit_resample(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from imblearn.under_sampling import RandomUnderSampler \n\nrUs = RandomUnderSampler(sampling_strategy=0.9)\nX_train, y_train = rUs.fit_resample(X_train, y_train)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.value_counts(normalize = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Modelling","metadata":{}},{"cell_type":"code","source":"# On entraine un arbre de décision \n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.feature_selection import SelectKBest, f_classif, chi2\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.decomposition import PCA\n\nmodel = make_pipeline(PolynomialFeatures(2),SelectKBest(score_func=chi2, k=12),\n                      DecisionTreeClassifier(random_state = 0))\n\n#model = make_pipeline(PolynomialFeatures(2),PCA (n_components = 3),\n                      #DecisionTreeClassifier(random_state = 0))\n\n\n\n#model = DecisionTreeClassifier(random_state = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluation","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import f1_score,  confusion_matrix, classification_report\nfrom sklearn.model_selection import learning_curve \n\ndef evaluation(model):\n    model.fit(X_train,y_train)\n    y_pred = model.predict (X_test)\n    \n    print(confusion_matrix(y_test,y_pred))\n    print(classification_report(y_test, y_pred))\n    \n    N, train_score, val_score = learning_curve(model, X_train,y_train, \n                                              cv = 4, scoring = 'f1',\n                                               train_sizes = np.linspace(0.1,1,10))\n    \n    plt.figure(figsize = (12,8))\n    plt.plot(N,train_score.mean(axis = 1), label = 'train score')\n    plt.plot(N,val_score.mean(axis = 1), label = 'validation score')\n    plt.legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluation(model)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pd.DataFrame(model.feature_importances_, index = X_train.columns).plot.bar()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3- MODELISATION","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier \nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler\nfrom sklearn.decomposition import PCA","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocessor = make_pipeline(PolynomialFeatures(2, include_bias = False), SelectKBest(chi2, k=12))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RandomForest = make_pipeline(preprocessor, RandomForestClassifier(random_state = 0))\n\nAdaBoost = make_pipeline(preprocessor, AdaBoostClassifier(random_state = 0))\n\nSVM = make_pipeline(preprocessor, StandardScaler(), SVC(random_state = 0))\n\nKNN = make_pipeline(preprocessor, StandardScaler(), KNeighborsClassifier())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_of_models = [RandomForest,AdaBoost, SVM, KNN ]\ndict_of_models = {'RandomForest' :RandomForest ,\n                 'Adaboost' : AdaBoost ,\n                 'SVM' :SVM ,\n                 'KNN':KNN }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for name,model in dict_of_models.items() : \n    print(name)\n    evaluation(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## OPTIMISATION","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hyper_params = {'svc__gamma' : [1e-3, 1e-4],\n                'svc__C' : [1,10,100,1000]}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nSVM = make_pipeline(preprocessor, StandardScaler(), SVC(random_state = 0))\n\ngrid = GridSearchCV(SVM,hyper_params, scoring = \"recall\", cv =4)\n\ngrid.fit(X_train,y_train)\n\nprint(grid.best_params_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = grid.predict(X_test)\nprint(classification_report (y_test,y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluation(grid.best_estimator_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hyper_params = {'svc__gamma' : [1e-3, 1e-4],\n                'svc__C' : [1,10,100,1000],\n               'svc__kernel':['rbf', 'linear', 'poly', 'rbf', 'sigmoid'],\n               'pipeline__polynomialfeatures__degree' : [2,3],\n               'pipeline__selectkbest__k' : range(40,80)}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n\nSVM = make_pipeline(preprocessor, StandardScaler(), SVC(random_state = 0))\n\ngrid = RandomizedSearchCV(SVM,hyper_params, scoring = \"recall\", cv =4, n_iter = 40)\n\ngrid.fit(X_train,y_train)\n\nprint(grid.best_params_)\n\ny_pred = grid.predict(X_test)\nprint(classification_report (y_test,y_pred))\n\nevaluation(grid.best_estimator_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SVM = make_pipeline(preprocessor, StandardScaler(), SVC(random_state = 0))\n\nevaluation(SVM)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## PRECISION RECALL CURVE","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"precision, recall, threshold = precision_recall_curve(y_test, SVM.decision_function(X_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(threshold, precision[:-1], label = 'precision')\nplt.plot(threshold, recall[:-1], label = 'recall')\nplt.legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_final(model,X, threshold = 0.8) : \n    return model.decision_function(X) > threshold","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model_final(SVM, X_test,threshold = 0.1)\n\nprint(confusion_matrix(y_test,y_pred))\nprint(classification_report(y_test, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}