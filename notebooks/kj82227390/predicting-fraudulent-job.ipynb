{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Interesting Problem\n#### -How to predict whether a job posting is Fraudulent\n#### -Which classifier (RandomForest, Logistic Regression or KNeighbours) is best for predicting if a job posting is fraudulent","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sb\nimport matplotlib.pyplot as plt # we only need pyplot\nsb.set() # set the default Seaborn style for graphics\n\nimport os\nfor dirname, _, filenames in os.walk('../input/real-or-fake-fake-jobposting-prediction'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#importing the csv data into jobData\njobData = pd.read_csv('/kaggle/input/real-or-fake-fake-jobposting-prediction/fake_job_postings.csv')\n\njobData.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#info about the variables\njobData.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Finding out the num of rows and columns\nprint(\"Data dims is: \",jobData.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check for duplicate datas\njobData.duplicated().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check for null values\njobData.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#replace null values with \"NULL\"\njobData.fillna(\"NULL\",inplace=True)\n\n#checking for any null values\njobData.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# num of fake jobs in the Dataset\nprint(\"Number of real (label as 0) and fake jobs (label as 1) in the dataset :\")\n\n\nprint(jobData[\"fraudulent\"].value_counts())\nsb.catplot(x=\"fraudulent\", data = jobData, kind = \"count\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# unique elements in different variables in the Dataset\nprint(\"NUMBERS OF UNIQUE ELEMENTS IN EACH VARIABLES:\")\nprint(\"title:\", len(jobData[\"title\"].unique()))\nprint(\"location:\", len(jobData[\"location\"].unique()))\nprint(\"department:\", len(jobData[\"department\"].unique()))\nprint(\"salary range:\", len(jobData[\"salary_range\"].unique()))\nprint(\"company profile:\", len(jobData[\"company_profile\"].unique()))\nprint(\"description:\", len(jobData[\"description\"].unique()))\nprint(\"requirements:\", len(jobData[\"requirements\"].unique()))\nprint(\"benefits:\", len(jobData[\"benefits\"].unique()))\nprint(\"telecommuting:\", len(jobData[\"telecommuting\"].unique()))\nprint(\"has company logo:\", len(jobData[\"has_company_logo\"].unique()))\nprint(\"has questions:\", len(jobData[\"has_questions\"].unique()))\nprint(\"employment type:\", len(jobData[\"employment_type\"].unique()))\nprint(\"required experience:\", len(jobData[\"required_experience\"].unique()))\nprint(\"required education:\", len(jobData[\"required_education\"].unique()))\nprint(\"industry:\", len(jobData[\"industry\"].unique()))\nprint(\"function:\", len(jobData[\"function\"].unique()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analysis of Data\n","metadata":{}},{"cell_type":"markdown","source":"We decided to not use the variables title, location, department as there are over 1000 category in them making it non ideal and hard to work with","metadata":{}},{"cell_type":"markdown","source":"-------------------------------------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"## Salary Range","metadata":{}},{"cell_type":"code","source":"#Extracting the data of the variables salary_range and fraudulent\nsalaryrange = pd.DataFrame(jobData[['salary_range','fraudulent']])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since there is 875 unique elements in the variable, we would like to know if this variable will be useful to us by seeing how many null and non - null values there are","metadata":{}},{"cell_type":"code","source":"#if there is a value in the variable salary_range replace it with \"NOT NULL\"\nsalaryrange.loc[(salaryrange.salary_range !='NULL'),'salary_range']='NOT NULL'\n\n#print the num of Null and Non Null \nprint(salaryrange[\"salary_range\"].value_counts())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,15))\n\n#Plotting a countplot\nax=sb.countplot(x =\"salary_range\",hue=\"fraudulent\", data= salaryrange)\n\n#Print title on top of the countplot fig\nax.set_title(\"Number of null and non-null data in the variable salary range \", fontsize = 20)\n\n#changing the font size of the y axis label, 'count'\nplt.ylabel(\"count\", fontsize=20)\n\n#To Display the count values on top of the countplot\nfor p in ax.patches:\n  ax.annotate(f'\\n{p.get_height()}', (p.get_x()+.2, p.get_height()), ha='center', va='bottom', color='black', size=24)\n\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since the number of NULL value is 15012 and NON NULL value is 2868, the variable salary_range will not be useful to us","metadata":{}},{"cell_type":"markdown","source":"-------------------------------------------------------------------------------\n\n\nFor the variable company profile, description, requirements and benefits. We would like to compare the num of characters between the real and the fake job postings","metadata":{}},{"cell_type":"markdown","source":"## Company Profile","metadata":{}},{"cell_type":"code","source":"\nfig,(ax1,ax2)= plt.subplots(ncols=2, figsize=(17, 5), dpi=100)\n\n#counting the number of characters for frauduelent data\nlength=jobData[jobData[\"fraudulent\"]==1]['company_profile'].str.len()\n\n#plotting the histogram\nax1.hist(length,bins = 20,color='orangered')\nax1.set_title('Fake Post')\n\n#counting the number of characters for non frauduelent data\nlength=jobData[jobData[\"fraudulent\"]==0]['company_profile'].str.len()\n\n#plotting the histogram\nax2.hist(length, bins = 20)\nax2.set_title('Real Post')\nfig.suptitle('Characters in Company Profile')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"we can see that fake postings in the variable company profile has lesser characaters and that if there is more that 1500 characters the post is likely to be a real post.","metadata":{}},{"cell_type":"markdown","source":"## Description","metadata":{}},{"cell_type":"code","source":"fig,(ax1,ax2)= plt.subplots(ncols=2, figsize=(17, 5), dpi=100)\n\n#counting the number of characters for frauduelent data\nlength=jobData[jobData[\"fraudulent\"]==1]['description'].str.len()\n\n#plotting the histogram\nax1.hist(length,bins = 20,color='orangered')\nax1.set_title('Fake Post')\n\n#counting the number of characters for non frauduelent data\nlength=jobData[jobData[\"fraudulent\"]==0]['description'].str.len()\n\n#plotting the histogram\nax2.hist(length, bins = 20)\nax2.set_title('Real Post')\nfig.suptitle('Characters in Description')\n\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The distribution of characters in both the Fake and Real job postings are similar but some fake post can reach up to 6000 to 6500 character","metadata":{}},{"cell_type":"markdown","source":"## Requirements","metadata":{}},{"cell_type":"code","source":"fig,(ax1,ax2)= plt.subplots(ncols=2, figsize=(17, 5), dpi=100)\n\n#counting the number of characters for frauduelent data\nlength=jobData[jobData[\"fraudulent\"]==1]['requirements'].str.len()\n\n#plotting the histogram\nax1.hist(length,bins = 20,color='orangered')\nax1.set_title('Fake Post')\n\n#counting the number of characters for non frauduelent data\nlength=jobData[jobData[\"fraudulent\"]==0]['requirements'].str.len()\n\n#plotting the histogram\nax2.hist(length, bins = 20)\nax2.set_title('Real Post')\nfig.suptitle('Characters in Requirements')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The distribution for both real and fake job postings is similar","metadata":{}},{"cell_type":"markdown","source":"## Benefits","metadata":{}},{"cell_type":"code","source":"fig,(ax1,ax2)= plt.subplots(ncols=2, figsize=(17, 5), dpi=100)\n\n#counting the number of characters for frauduelent data\nlength=jobData[jobData[\"fraudulent\"]==1]['benefits'].str.len()\n\n#plotting the histogram\nax1.hist(length,bins = 20,color='orangered')\nax1.set_title('Fake Post')\n\n#counting the number of characters for Non frauduelent data\nlength=jobData[jobData[\"fraudulent\"]==0]['benefits'].str.len()\n\n#plotting the histogram\nax2.hist(length, bins = 20)\nax2.set_title('Real Post')\nfig.suptitle('Characters in Benefits')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"-------------------------------------------------------------------------------\n\n\nFor the variables telecommuting, has company logo, has questions, employment type, required experience and required education we would like to know the ratio of real vs fake job postings for each unique element.","metadata":{}},{"cell_type":"markdown","source":"## Telecommuting","metadata":{}},{"cell_type":"code","source":"#Plotting the countplot\nplt.figure(figsize=(15,15))\nax=sb.countplot(x =\"telecommuting\", hue=\"fraudulent\", data=jobData)\nax.set_title(\"Number of Real and Fake job posts in the variable telecommuting \", fontsize = 20)\n\n#setting the title and fontsize of the x and y axis label of the count plot\nplt.xlabel(\"Telecommuting\",fontsize=20)\nplt.ylabel(\"count\", fontsize=20)\n\n#To Display the count values on top of the countplot\nfor p in ax.patches:\n  ax.annotate(f'\\n{p.get_height()}', (p.get_x()+0.2, p.get_height()), ha='center', va='bottom', color='black', size=24)\n\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Has Company Logo","metadata":{}},{"cell_type":"code","source":"#Plotting the countplot\nplt.figure(figsize=(15,15))\nax=sb.countplot(x =\"has_company_logo\", hue=\"fraudulent\", data=jobData)\n\n#setting the title and fontsize of the x and y axis label of the count plot\nax.set_title(\"Number of Real and Fake job posts in the variable has company logo \", fontsize = 20)\nplt.xlabel(\"has company logo\",fontsize=20)\nplt.ylabel(\"count\", fontsize=20)\n\n#To Display the count values on top of the countplot\nfor p in ax.patches:\n  ax.annotate(f'\\n{p.get_height()}', (p.get_x()+0.2, p.get_height()), ha='center', va='bottom', color='black', size=24)\n\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Has Questions","metadata":{}},{"cell_type":"code","source":"#Plotting the countplot\nplt.figure(figsize=(15,15))\nax=sb.countplot(x =\"has_questions\", hue=\"fraudulent\", data=jobData)\n\n#setting the title and fontsize of the x and y axis label of the count plot\nax.set_title(\"Number of Real and Fake job posts in the variable has questions \", fontsize = 20)\nplt.xlabel(\"has questions\",fontsize=20)\nplt.ylabel(\"count\", fontsize=20)\n\n#To Display the count values on top of the countplot\nfor p in ax.patches:\n  ax.annotate(f'\\n{p.get_height()}', (p.get_x()+0.2, p.get_height()), ha='center', va='bottom', color='black', size=24)\n\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the variable telecommuting, has company logo and has questions we can observe that there is more category '0' in these variables for fake job postings","metadata":{}},{"cell_type":"markdown","source":"## Employment Type","metadata":{}},{"cell_type":"code","source":"#Plotting the countplot\nplt.figure(figsize=(15,15))\nax=sb.countplot(x =\"employment_type\", hue=\"fraudulent\", data=jobData)\n\n#setting the title and fontsize of the x and y axis label of the count plot\nax.set_title(\"Number of Real and Fake job posts in the variable employment type \", fontsize = 20)\nplt.xlabel(\"employment type\",fontsize=20)\nplt.ylabel(\"count\", fontsize=20)\n\n#To Display the count values on top of the countplot\nfor p in ax.patches:\n  ax.annotate(f'\\n{p.get_height()}', (p.get_x()+.2, p.get_height()), ha='center', va='bottom', color='black', size=24)\n\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can observe that most Fake job postings are in the elements Full-time and NULL","metadata":{}},{"cell_type":"markdown","source":"## Required Experience","metadata":{}},{"cell_type":"code","source":"#Plotting the countplot\nplt.figure(figsize=(15,15))\nax=sb.countplot(y =\"required_experience\", hue=\"fraudulent\", data=jobData)\n\n#setting the title and fontsize of the x and y axis label of the count plot\nax.set_title(\"Number of Real and Fake job posts in the variable required experience \", fontsize = 20)\nplt.xlabel(\"count\",fontsize=20)\nplt.ylabel(\"required experience\", fontsize=20)\n\n#setting the font size for the Y axis elements \nax.set_yticklabels(ax.get_yticklabels(),  fontsize=15)\n\n#To Display the count values on top of the countplot\nfor p in ax.patches:\n    width = p.get_width()\n    height = p.get_height()\n    x, y = p.get_xy()\n    ax.annotate(int(width),\n                ((x + width), y), \n                xytext = (40, -25),\n                fontsize = 18, \n                color = '#000000',\n                textcoords = 'offset points',\n                ha = 'right',\n                va = 'center')\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Most of the Fake job postings are in the elements NULL, Mid-senior level and Entry Level","metadata":{}},{"cell_type":"markdown","source":"## Required Education","metadata":{}},{"cell_type":"code","source":"#Plotting the countplot\nplt.figure(figsize=(10,15))\nax=sb.countplot(y =\"required_education\", hue=\"fraudulent\", data=jobData)\n\n#setting the title and fontsize of the x and y axis label of the count plot\nax.set_title(\"Number of Real and Fake job posts in the variable required education \", fontsize = 20)\nplt.xlabel(\"count\",fontsize=20)\nplt.ylabel(\"required education\", fontsize=20)\n\n# Put the legend out of the figure\nplt.legend(bbox_to_anchor=(1, 1.1),title='Fraudulent', loc=2, borderaxespad=0.)\n\n\n#setting the font size for the Y axis elements \nax.set_yticklabels(ax.get_yticklabels(),  fontsize=15)\n\n#To Display the count values on top of the countplot\nfor p in ax.patches:\n    width = p.get_width()\n    x, y = p.get_xy()\n    ax.annotate(float(width),\n                ((x + width), y), \n                xytext = (40, -15),\n                fontsize = 16,\n                color = '#000000',\n                textcoords = 'offset points',\n                ha = 'center',\n                va = 'center')\n    \n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Most of the fake job postings are in the elements NULL, Bachelor's degree and High school or equivalent.","metadata":{}},{"cell_type":"markdown","source":"-------------------------------------------------------------------------------\n\nFor the variable, industry we would like to know where most of the fake job postings are at.","metadata":{}},{"cell_type":"markdown","source":"## Industry","metadata":{}},{"cell_type":"code","source":"#Extracting the fake job postings data\njobData_industry = jobData[jobData['fraudulent']== 1]\n\n#Able to print all the elements and count\npd.set_option('display.max_rows', jobData.shape[0]+1)\n\n#Print the count of fraudulent data of the elements in 'industry'\nprint(\"The number of fake job postings in the following elements are:\\n\")\nprint(jobData_industry['industry'].value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" \n \n Most of the fake job postings in industry lies in the element NULL, Oil and energy","metadata":{}},{"cell_type":"code","source":"#Extracting the fake job postings data\njobData_function = jobData[jobData['fraudulent']== 1]\n\n#Able to print all the elements and count\npd.set_option('display.max_rows', jobData.shape[0]+1)\n\n#Print the count of fraudulent data of the elements in 'function'\nprint(\"The number of fake job postings in the following elements are:\\n\")\nprint(jobData_industry['function'].value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Most of the fake job postings lies in the elements NULL, administrative and Engineering.","metadata":{}},{"cell_type":"markdown","source":"# Prediction","metadata":{}},{"cell_type":"markdown","source":"From the analysis of the data we feel that the following variables is useful in helping us in the prediction","metadata":{}},{"cell_type":"code","source":"#Putting the useful 'variables' in predictionData\npredictionData = pd.DataFrame(jobData[['telecommuting','has_company_logo','has_questions','employment_type','required_experience','required_education','industry','function','fraudulent']])\npredictionData.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preparing of data","metadata":{}},{"cell_type":"code","source":"#importing label enconder to convert the elements in each variable to a number\nfrom sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\n\n#converting each variable's elements into a number \nfor i in predictionData:\n    if predictionData[i].dtype=='object':\n        predictionData[i]=le.fit_transform(predictionData[i])\n        \npredictionData.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx = pd.DataFrame(predictionData[['telecommuting','has_company_logo','has_questions','employment_type','required_experience','required_education','industry','function']])\ny = pd.DataFrame(predictionData['fraudulent'])\n\n# Split the Dataset into Train and Test\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25)\n\n# Check the sample sizes\nprint(\"Train Set :\", y_train.shape, x_train.shape)\nprint(\"Test Set  :\", y_test.shape, x_test.shape)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Balancing our dataset with SMOTE()","metadata":{}},{"cell_type":"code","source":"#SMOTE(oversampling of minority data[fake job postings] )\n#to install new library imblearn\n#!pip install imblearn \n\n#importing libraries needed for SMOTE\nfrom sklearn.utils import resample\nimport imblearn\nfrom imblearn.over_sampling import SMOTE\nsm = SMOTE()\n\n#fitting the train datas into the SMOTE model for oversampling of minority data\nX , Y= sm.fit_resample(x_train,y_train)\n\n# new Dataset after smote\nprint(\"Number of real (label as 0) and fake jobs (label as 1) in the new dataset :\")\nprint(Y[\"fraudulent\"].value_counts())\n\n#Count of the new dataset in X train\nsb.catplot(x=\"fraudulent\", data = Y, kind = \"count\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prediction with Random Forest Classifier","metadata":{}},{"cell_type":"markdown","source":"### Fitting train data into random forest model","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrfc=RandomForestClassifier()\nrfc.fit(X,Y.values.ravel())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predicting train datas","metadata":{}},{"cell_type":"code","source":"#prediciting frauduelent with x_train\ny_train_predrfc=rfc.predict(X)\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\n\n#Displaying the accuracy score\nprint(\"The accuracy score for Random Forest classifier for the train set is:\" )\nprint(accuracy_score(Y,y_train_predrfc))\n\nfrom sklearn.metrics import classification_report\n#Displaying the classification_report\nprint(classification_report(Y,y_train_predrfc))\n\n# Plot the Confusion Matrix for Train \nsb.heatmap(confusion_matrix(Y, y_train_predrfc), \n           annot = True, fmt=\".0f\", annot_kws={\"size\": 18})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predicting test datas","metadata":{}},{"cell_type":"code","source":"#prediciting frauduelent with x_test\ny_test_predrfc=rfc.predict(x_test)\n\n#Displaying the accuracy score\nprint(\"The accuracy score for Random Forest classifier for the test set is:\" )\nprint(accuracy_score(y_test,y_test_predrfc))\n\n#Displaying the classification_report\nprint(classification_report(y_test,y_test_predrfc))\n\nsb.heatmap(confusion_matrix(y_test, y_test_predrfc), \n           annot = True, fmt=\".0f\", annot_kws={\"size\": 18})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction with Logistic Regression","metadata":{}},{"cell_type":"code","source":"#importing logistic regression and setting its iteration to 10000\nfrom sklearn.linear_model import LogisticRegression\nlr=LogisticRegression(solver='lbfgs', max_iter=10000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#fitting the train data into the logistic regression model\nlr.fit(X,Y.values.ravel())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predicting train datas","metadata":{}},{"cell_type":"code","source":"y_train_predlr=lr.predict(X)\n\n#Displaying the accuracy score\nprint(\"The accuracy score for logistic regression for the train set is:\" )\nprint(accuracy_score(Y,y_train_predlr))\n\n#Displaying the classification_report\nprint(classification_report(Y,y_train_predlr))\n\nsb.heatmap(confusion_matrix(Y, y_train_predlr), \n           annot = True, fmt=\".0f\", annot_kws={\"size\": 18})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predicting test datas","metadata":{}},{"cell_type":"code","source":"y_test_predlr=lr.predict(x_test)\n\n#Displaying the accuracy score\nprint(\"The accuracy score for logistic regression for the test set is:\" )\nprint(accuracy_score(y_test,y_test_predlr))\n\n#Displaying the classification_report\nprint(classification_report(y_test,y_test_predlr))\n\nsb.heatmap(confusion_matrix(y_test, y_test_predlr), \n           annot = True, fmt=\".0f\", annot_kws={\"size\": 18})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prediction with KNeighbours Classifier","metadata":{}},{"cell_type":"code","source":"#importing and fitting the model for the KNeighbours Classifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier()\nknn.fit(X,np.ravel(Y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predicting train datas","metadata":{}},{"cell_type":"code","source":"y_train_predknn=knn.predict(X)\n#Displaying the accuracy score\nprint(\"The accuracy score for KNeighbours classifier for the train set is:\" )\nprint(accuracy_score(Y,y_train_predknn))\n\n#Displaying the classification_report\nprint(classification_report(Y,y_train_predknn))\n\nsb.heatmap(confusion_matrix(Y, y_train_predknn), \n           annot = True, fmt=\".0f\", annot_kws={\"size\": 18})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predicting test datas","metadata":{}},{"cell_type":"code","source":"y_test_predknn=knn.predict(x_test)\nprint(\"The accuracy score for KNeighbours classifier for the test set is:\" )\nprint(accuracy_score(y_test,y_test_predknn))\n\n#Displaying the classification_report\nprint(classification_report(y_test,y_test_predknn))\n\nsb.heatmap(confusion_matrix(y_test, y_test_predknn), \n           annot = True, fmt=\".0f\", annot_kws={\"size\": 18})","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Which Classfier is best to predict if a job postings is fraudulent or not.","metadata":{}},{"cell_type":"markdown","source":"From the f1 score, The Random Forest Classifier gives us the best score of 0.76. It also has the highest accuracy of 93%  Thus, it is the better classifier out of the other 2. ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}