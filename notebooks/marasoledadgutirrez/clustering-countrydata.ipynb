{"cells":[{"metadata":{},"cell_type":"markdown","source":"# CLUSTERING PROBLEM\n\nPurpose: The goal is to categorise the countries using socio-economic and health factors that determine the overall development of the country.\n\nModel Class: *Unsupervised*\n\nModel Type: *Clustering*\n\nEdit Date: 7/6/2020\n\nCluster Model: K-Means\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# DEPENDENCIES\n\nLoad the dependencies for model development. Current package requirements include:\n* Sklearn\n* Pandas\n* Numpy\n* Matplotlib","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# data\nimport pandas as pd\n\n# visualizations\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport pycountry\nimport plotly.express as px\n\n# preprocessing\nimport numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler,FunctionTransformer\n\n# clusters models\nfrom sklearn.cluster import KMeans, AgglomerativeClustering, SpectralClustering, DBSCAN\nfrom sklearn import metrics\nfrom sklearn.metrics import silhouette_score, silhouette_samples\n#from sklearn.metrics.pairwise import cosine_similarity\n#from scipy.cluster.hierarchy import dendrogram, linkage","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Get Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"info = pd.read_csv('../input/unsupervised-learning-on-country-data/data-dictionary.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"for i, row in info.iterrows():\n  print(row['Column Name'],' ---> ', row.Description)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CountryData = pd.read_csv('../input/unsupervised-learning-on-country-data/Country-data.csv')\nCountryData.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"CountryData.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CountryData.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see in the first two columns the presence of upper outliers. To deal with them, we will apply a logarithm type transformation.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"features = CountryData.columns[1:]\n\nfeatures_group1 = ['child_mort','exports']\nfeatures_group2 = list(set(features)-set(features_group1))\n\ng1_transformer = Pipeline(steps=[\n    ('log', FunctionTransformer(np.log1p)),\n    ('scaler', StandardScaler())\n    ])\n\ng2_transformer = Pipeline(steps=[\n    ('scaler', StandardScaler())\n    ])\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('group1', g1_transformer, features_group1),\n        ('group2', g2_transformer, features_group2),\n        ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocessor.fit(CountryData) \nnp_data = preprocessor.transform(CountryData) \ndf_data = pd.DataFrame(np_data, columns=features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using Pearson Correlation\nplt.figure(figsize=(12,10))\ncorr_m = CountryData.drop(['country'],axis=1).corr()\nsns.heatmap(corr_m, annot=True, cmap=plt.cm.Reds).set_title('Correlation Matrix')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see a strong correlation between:\n- gdpp and income\n- total_fer and child_mort","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Feature selection:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = df_data.loc[:, features].values\n\n\n# created a covariance matrix on the standardized data. \nmatrix_cov = np.cov(data.T)\n\n# eigendecomposition on covariance matrix\neig_vals, eig_vecs = np.linalg.eig(matrix_cov)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, we need to select the pricipal components. For that, we will see in which features the variance is concentrated. The eigenvectors with the lowest eigenvalues describe the least amount of variation within the dataset. Therefore, these values can be dropped. So, we can follow the Kaiser criterion. With this approach, we retain component with an eigenvalue greater than 1.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(eig_vals)):\n    print(eig_vals[i], eig_vals[i]/np.sum(eig_vals))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Explained variance\npca = PCA().fit(data)\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.xlabel('number of components')\nplt.ylabel('cumulative explained variance')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**CONCLUSION:** take 3 principal components","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components=3)\nprincipalComponents = pca.fit_transform(data)\nprincipalDf = pd.DataFrame(data = principalComponents)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Functions for visualization on a map:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def ISO_Code(df):\n    # Countries that are not in the ISO Code\n    df['RightCountry'] = [item.replace('Cape Verde', 'Cabo Verde')\n                              .replace('Congo, Dem. Rep.', 'Congo, The Democratic Republic of the')\n                              .replace('Congo, Rep.', 'Republic of the Congo')\n                              .replace('Macedonia, FYR', 'North Macedonia')\n                              .replace('Micronesia, Fed. Sts.', 'Micronesia, Federated States of')\n                              .replace('South Korea', 'Korea, Republic of')\n                              .replace('St. Vincent and the Grenadines', 'Saint Vincent and the Grenadines') for item in df.country]\n\n    list_countries = df['RightCountry'].unique().tolist()\n\n    d_country_code = {}  # To hold the country names and their ISO\n    for country in list_countries:\n        try:\n            country_data = pycountry.countries.search_fuzzy(country)\n            country_code = country_data[0].alpha_3\n            d_country_code.update({country: country_code})\n        except:\n            print('could not add ISO 3 code for ->', country)\n            # If could not find country, make ISO code ' '\n            d_country_code.update({country: ' '})\n\n    for k, v in d_country_code.items():\n        df.loc[(df.RightCountry == k), 'iso_alpha'] = v \n\n    df.loc[df.country.tolist().index('Niger'),'iso_alpha']='NER'\n    return df\n\ndef get_map(df):\n    df = ISO_Code(df)\n    fig = px.choropleth(data_frame = df,\n                        locations= \"iso_alpha\",\n                        color= \"cluster\",  # value in column 'Confirmed' determines color\n                        hover_name= \"country\",\n                        color_continuous_scale= 'RdYlGn_r',  #  color scale red, yellow green\n                        )\n\n    fig.show()\n\ndef get_datavisual(df,np_data):\n    # Create PCA for data visualization / Dimensionality reduction to 2D graph\n    from sklearn.decomposition import PCA\n\n    pca = PCA(n_components=2)\n    pca_model = pca.fit_transform(np_data)\n    data_transform = pd.DataFrame(data = pca_model, columns = ['PCA1', 'PCA2'])\n    data_transform['Cluster'] = df.cluster\n\n    plt.figure()\n    g = sns.scatterplot(data=data_transform, x='PCA1', y='PCA2', palette=sns.color_palette()[:int(df.cluster.nunique())], hue='Cluster')\n    title = plt.title('Countries Clusters with PCA')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MODEL: K-Means","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_model(n_c, np_data):\n  # Create and fit model\n  kmeans = KMeans(n_clusters=n_c,\n                  init='k-means++',\n                  max_iter=400, \n                  n_init=80, \n                  random_state=0)\n  model = kmeans.fit(np_data)\n\n  df = CountryData.copy()\n  df['cluster'] = model.labels_\n\n  return df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**NÂ°Clusters for K-means: Elbow Method**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"np_data = principalDf\nSum_of_squared_distances = []\nfor k in range(1, 10):\n    km = KMeans(n_clusters=k, \n                init='k-means++',\n                max_iter=400, \n                n_init=80, \n                random_state=0\n                ).fit(np_data)\n    Sum_of_squared_distances.append(km.inertia_)\n\n#plt.figure(figsize=(10,10))\nplt.plot(range(1, 10), Sum_of_squared_distances, 'bx-')\nplt.xlabel('k')\nplt.ylabel('Sum_of_squared_distances')\nplt.title('Elbow Method For Optimal k')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can conclude that 3 clusters is a good choice.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_km3PCA = run_model(3, principalDf)\ndf_km3PCA.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_km3PCA.cluster.value_counts())\ndf_km3PCA.cluster.hist()\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Interpretation of clusters","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"get_datavisual(df_km3PCA, np_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_map(df_km3PCA)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_km3PCA.groupby(['cluster']).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pylab import *\n\ncols = df_km3PCA.columns[1:-1]\nfor col in cols:\n    y0 = sorted(df_km3PCA[df_km3PCA.cluster==0][col].tolist())\n    y1 = sorted(df_km3PCA[df_km3PCA.cluster==1][col].tolist())\n    y2 = sorted(df_km3PCA[df_km3PCA.cluster==2][col].tolist())\n\n    plt.plot(range(len(y0)),y0,'.', linewidth=4, color='b')\n    plt.plot(range(len(y1)),y1, '.', linewidth=4,color='r')\n    plt.plot(range(len(y2)),y2,'.', linewidth=4, color='g')\n    plt.title(col)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Cluster 0:* Poor countries\n\n*Cluster 1:* Rich countries\n\n*Cluster 2:* medium countries","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}