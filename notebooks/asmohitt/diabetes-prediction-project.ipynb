{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### This project is basically an overview of how we can train a machine learning model on the diabeties data set and predict with the conditions given whether the person is diabetic or not.\n\n\n\n\n","metadata":{}},{"cell_type":"markdown","source":"## SVM\n### We use svm classification for this project\nSupport vector machine used to classify a data point based on a maximum margin hyperplane created by the supporting points known as support vectors (vectors - as in higher dimension it is tough to call them points, supporting - since these points are enough than all the other data points together as this marks the boundary to. help classify the point) which seperate the data points.","metadata":{}},{"cell_type":"markdown","source":"Let's Start!","metadata":{}},{"cell_type":"markdown","source":"About the libraries\n\n1.   numpy - for numpy arrays, useful for processing and scientific computing \n2.   pandas - helpful for creating dataframes and storing data\n3.   StandardScalar - in this project we're using support vector machine classification and this class cannot process the data given to it unless the data is standardized. \n4.   svm - the suport vector machine class in the sklearn package\n5.   accuracy_score - to check the accuracy of our model\n6.   train_test_split - to split the data into training and test set\n\n\n","metadata":{}},{"cell_type":"markdown","source":"Importing the libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import svm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n#from sklearn.linear_model import LogisticRegression\n#from sklearn.neighbors import KNeighborsClassifier\n#from sklearn.naive_bayes import GaussianNB\n#from sklearn.tree import DecisionTreeClassifier\n#from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n","metadata":{"execution":{"iopub.status.busy":"2021-08-25T04:20:41.694924Z","iopub.execute_input":"2021-08-25T04:20:41.695468Z","iopub.status.idle":"2021-08-25T04:20:41.70156Z","shell.execute_reply.started":"2021-08-25T04:20:41.695432Z","shell.execute_reply":"2021-08-25T04:20:41.700696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Data Collecting and Analysis\n\n\n*   dataset - PIMA Indians diabetes dataset (Kaggle) \n    this data set contains data about females \n\n","metadata":{}},{"cell_type":"code","source":"diabetes_dataset = pd.read_csv(\"../input/pima-indians-diabetes-database/diabetes.csv\")\ndiabetes_dataset.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-25T04:20:41.732706Z","iopub.execute_input":"2021-08-25T04:20:41.733055Z","iopub.status.idle":"2021-08-25T04:20:41.758251Z","shell.execute_reply.started":"2021-08-25T04:20:41.733025Z","shell.execute_reply":"2021-08-25T04:20:41.757274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"diabetes_dataset.describe()","metadata":{"execution":{"iopub.status.busy":"2021-08-25T04:20:41.770218Z","iopub.execute_input":"2021-08-25T04:20:41.77059Z","iopub.status.idle":"2021-08-25T04:20:41.810329Z","shell.execute_reply.started":"2021-08-25T04:20:41.770559Z","shell.execute_reply":"2021-08-25T04:20:41.809397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"diabetes_dataset.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-25T04:20:41.812065Z","iopub.execute_input":"2021-08-25T04:20:41.812428Z","iopub.status.idle":"2021-08-25T04:20:41.818299Z","shell.execute_reply.started":"2021-08-25T04:20:41.812388Z","shell.execute_reply":"2021-08-25T04:20:41.817335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's visualize the number of\n\n* 0 --> Not diabetic\n* 1 --> Diabetic","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(8,5))\nsns.countplot(x=diabetes_dataset['Outcome'])\nplt.title('Outcome vs count',fontsize=20)\nplt.xlabel('Outcome',fontsize=15)\nplt.ylabel('Count',fontsize=15);","metadata":{"execution":{"iopub.status.busy":"2021-08-25T04:20:41.820573Z","iopub.execute_input":"2021-08-25T04:20:41.821188Z","iopub.status.idle":"2021-08-25T04:20:41.962755Z","shell.execute_reply.started":"2021-08-25T04:20:41.82114Z","shell.execute_reply":"2021-08-25T04:20:41.961592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"diabetes_dataset[\"Outcome\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-08-25T04:20:41.964723Z","iopub.execute_input":"2021-08-25T04:20:41.965022Z","iopub.status.idle":"2021-08-25T04:20:41.972847Z","shell.execute_reply.started":"2021-08-25T04:20:41.964992Z","shell.execute_reply":"2021-08-25T04:20:41.971879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"diabetes_dataset.groupby('Outcome').mean()","metadata":{"execution":{"iopub.status.busy":"2021-08-25T04:20:41.974531Z","iopub.execute_input":"2021-08-25T04:20:41.974936Z","iopub.status.idle":"2021-08-25T04:20:42.001693Z","shell.execute_reply.started":"2021-08-25T04:20:41.974895Z","shell.execute_reply":"2021-08-25T04:20:42.000733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = diabetes_dataset.iloc[:,:-1].values\ny = diabetes_dataset.iloc[:,-1].values","metadata":{"execution":{"iopub.status.busy":"2021-08-25T04:20:42.002976Z","iopub.execute_input":"2021-08-25T04:20:42.00325Z","iopub.status.idle":"2021-08-25T04:20:42.009613Z","shell.execute_reply.started":"2021-08-25T04:20:42.003222Z","shell.execute_reply":"2021-08-25T04:20:42.008547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"execution":{"iopub.status.busy":"2021-08-25T04:20:42.011928Z","iopub.execute_input":"2021-08-25T04:20:42.012299Z","iopub.status.idle":"2021-08-25T04:20:42.025977Z","shell.execute_reply.started":"2021-08-25T04:20:42.012264Z","shell.execute_reply":"2021-08-25T04:20:42.024817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y","metadata":{"execution":{"iopub.status.busy":"2021-08-25T04:20:42.027753Z","iopub.execute_input":"2021-08-25T04:20:42.028091Z","iopub.status.idle":"2021-08-25T04:20:42.03878Z","shell.execute_reply.started":"2021-08-25T04:20:42.02806Z","shell.execute_reply":"2021-08-25T04:20:42.037758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Data Standardization\n","metadata":{}},{"cell_type":"code","source":"scalar = StandardScaler()\nX = scalar.fit_transform(X)\nprint(X)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T04:20:42.040469Z","iopub.execute_input":"2021-08-25T04:20:42.04114Z","iopub.status.idle":"2021-08-25T04:20:42.049817Z","shell.execute_reply.started":"2021-08-25T04:20:42.041092Z","shell.execute_reply":"2021-08-25T04:20:42.04875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train Test Split","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, stratify = y)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T04:20:42.051329Z","iopub.execute_input":"2021-08-25T04:20:42.051779Z","iopub.status.idle":"2021-08-25T04:20:42.061459Z","shell.execute_reply.started":"2021-08-25T04:20:42.051735Z","shell.execute_reply":"2021-08-25T04:20:42.060453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape\ny_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-25T04:20:42.062681Z","iopub.execute_input":"2021-08-25T04:20:42.063249Z","iopub.status.idle":"2021-08-25T04:20:42.074057Z","shell.execute_reply.started":"2021-08-25T04:20:42.063213Z","shell.execute_reply":"2021-08-25T04:20:42.072907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Training the model","metadata":{}},{"cell_type":"code","source":"classifier = svm.SVC(C=0.5, kernel='linear')\n#classifier = LogisticRegression()\n#classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski' , p=2)\n#classifier = svm.SVC(kernel = 'rbf')\n#classifier = GaussianNB()\n#classifier = DecisionTreeClassifier(criterion='entropy')\n#classifier = RandomForestClassifier(n_estimators=10,criterion = 'entropy')\nclassifier.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T04:20:42.075511Z","iopub.execute_input":"2021-08-25T04:20:42.07613Z","iopub.status.idle":"2021-08-25T04:20:42.095827Z","shell.execute_reply.started":"2021-08-25T04:20:42.076085Z","shell.execute_reply":"2021-08-25T04:20:42.094737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Model Evaluation\nAccuracy Score","metadata":{}},{"cell_type":"code","source":"y_pred = classifier.predict(X_test)\ncm = confusion_matrix(y_pred,y_test)\naccuracy = accuracy_score(y_pred, y_test)\nprint(cm)\ncf_matrix = cm\nprint(\"Accuracy of the model is:\", accuracy)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T04:20:53.738481Z","iopub.execute_input":"2021-08-25T04:20:53.738844Z","iopub.status.idle":"2021-08-25T04:20:53.748013Z","shell.execute_reply.started":"2021-08-25T04:20:53.738814Z","shell.execute_reply":"2021-08-25T04:20:53.746929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using K-Fold cross validation to check if we didn't get lucky on the test set!","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = classifier,X = X_train,y= y_train , cv = 10)\nprint(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\nprint(\"Standard Deviation: {:.2f}\".format(accuracies.std()*100))","metadata":{"execution":{"iopub.status.busy":"2021-08-25T04:20:55.179532Z","iopub.execute_input":"2021-08-25T04:20:55.180024Z","iopub.status.idle":"2021-08-25T04:20:55.271943Z","shell.execute_reply.started":"2021-08-25T04:20:55.179981Z","shell.execute_reply":"2021-08-25T04:20:55.270858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#.  visualizing the confusion matrix!\nsns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n            fmt='.2%', cmap='Reds')","metadata":{"execution":{"iopub.status.busy":"2021-08-25T04:21:10.45611Z","iopub.execute_input":"2021-08-25T04:21:10.456496Z","iopub.status.idle":"2021-08-25T04:21:10.717636Z","shell.execute_reply.started":"2021-08-25T04:21:10.456461Z","shell.execute_reply":"2021-08-25T04:21:10.716563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualzing. with labels!\nlabels = ['True Neg','False Pos','False Neg','True Pos']\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Reds')","metadata":{"execution":{"iopub.status.busy":"2021-08-25T04:21:33.570739Z","iopub.execute_input":"2021-08-25T04:21:33.571126Z","iopub.status.idle":"2021-08-25T04:21:33.796788Z","shell.execute_reply.started":"2021-08-25T04:21:33.57109Z","shell.execute_reply":"2021-08-25T04:21:33.796015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we have to check if there is a better hyperparameter we can tune to improve over all accuracy.\nWe use **Grid Search** here","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nparameters = [{'C':[0.25,0.5,0.75,1], 'kernel' : ['linear']},\n              {'C':[0.25,0.5,0.75,1], 'kernel' : ['rbf'], 'gamma' : [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]}]\ngrid_search = GridSearchCV(estimator=classifier,\n                          param_grid=parameters,\n                          scoring='accuracy',\n                          cv=10)\ngrid_search.fit(X_train,y_train)\nprint(\"Best Accuracy: {:.2f} %\".format(grid_search.best_score_*100))\nprint(\"Best Parameters: \", grid_search.best_params_)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T04:21:35.147034Z","iopub.execute_input":"2021-08-25T04:21:35.147618Z","iopub.status.idle":"2021-08-25T04:21:40.40358Z","shell.execute_reply.started":"2021-08-25T04:21:35.147561Z","shell.execute_reply":"2021-08-25T04:21:40.402606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy comparision of all classifier methods\n\n1.   SVM - using svm we get a accuracy of 78% and as we can see the best hyperparameters to use is c=0.5 and linear kernel\n2.   Logistic Regression - accuracy of 78%\n3.   KNN - accuracy of 74%\n4.   Kernel SVM - accuracy of 77%\n5.   Naive Bayes - accuracy of 74%\n6.   Decision Tree - accuracy of 71%\n7.   Random Forest - accuracy of 78% though random forest has good accuracy it performs too good in train set and is over fitted\n\n","metadata":{}},{"cell_type":"markdown","source":"Making a predictive system","metadata":{}},{"cell_type":"code","source":"input_data = np.array([1,85,66,29,0,26.6,0.351,31])\ninput_data = input_data.reshape(1,-1)\nstanderdized_input_data = scalar.transform(input_data)\nprediction = classifier.predict(standerdized_input_data)\nif(prediction[0] == 0):\n  print(\"Person is not diabetic\")\nelse:\n  print(\"The Person is diabetic\")","metadata":{"execution":{"iopub.status.busy":"2021-08-25T04:21:40.405059Z","iopub.execute_input":"2021-08-25T04:21:40.405373Z","iopub.status.idle":"2021-08-25T04:21:40.41251Z","shell.execute_reply.started":"2021-08-25T04:21:40.405327Z","shell.execute_reply":"2021-08-25T04:21:40.41172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}