{"nbformat":4,"cells":[{"execution_count":null,"cell_type":"code","outputs":[],"source":"from pandas import read_csv\nraw_data = read_csv(\"../input/Dataset_spine.csv\")","metadata":{"_execution_state":"idle","_uuid":"7c40898a753ce4ed7f119a2c3c0a5a44afedbf91","_cell_guid":"4fb3b136-4769-4193-99a7-5ebe9feeccc6","trusted":false}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"# === Rename The Columns === #\n\ncolumn_names = (\"pelvic_incidence\",\n\"pelvic_tilt\",\n\"lumbar_lordosis_angle\",\n\"sacral_slope\",\n\"pelvic_radius\",\n\"degree_spondylolisthesis\",\n\"pelvic_slope\",\n\"Direct_tilt\",\n\"thoracic_slope\",\n\"cervical_tilt\",\n\"sacrum_angle\",\n\"scoliosis_slope\")\n\n# === Rename === #\n\nrename = {}\nfor i in range(0,12):\n    temp = \"Col\" + str(i+1)\n    rename[temp] = column_names[i]\n\nrenamed_data = raw_data.rename(columns = rename)","metadata":{"_execution_state":"idle","_uuid":"c9cb843290a9c699bae74ca132c753041b6518de","_cell_guid":"1507f990-8c94-4ec0-a098-c8bbc3022c89","collapsed":false,"trusted":false}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"data = renamed_data.drop(\"Unnamed: 13\",1)\ntarget = \"Class_att\"\nfeatures = [feature for feature in data.columns if feature != target]","metadata":{"_execution_state":"idle","_uuid":"1e55df1b2e0dad01526e3e3e8af3dfa709431668","_cell_guid":"901cf31a-83ca-4182-80bd-3c3866e51a57","collapsed":false,"trusted":false}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"def get_score(actuals, predictions):\n    \n    # === Prepare dictionary for accuracy score for each unique label === #\n    \n    score_dictionary = {}\n    \n    # === Set count to 0 for all labels === #\n    \n    for value in actuals.unique():\n        score_dictionary[value] = 0\n        \n    # === Get total counts of each label in actual series === #\n    \n    actuals_counts = actuals.value_counts()\n    \n    # === Convert actuals series into list === #\n    \n    actuals = actuals.tolist()\n    \n    # === For every matched item by index in actuals and predictions list, add +1 to their counts === #\n    \n    for i in range(0,len(actuals)):\n        \n        if actuals[i] == predictions[i]:\n            \n            value = actuals[i]\n            \n            score_dictionary[value] += 1\n            \n    # === Divide label counts correctly guessed by total actual counts in actuals === #\n            \n    for key in score_dictionary.keys():\n        score_dictionary[key] /= actuals_counts[key]\n        \n    # === Mean Accuracy === #\n        \n    score_dictionary[\"Mean Accuracy\"] = Series(score_dictionary).mean()\n        \n    # === Return a score dictionary for this instance of classification predictions === #\n                \n    return score_dictionary","metadata":{"_execution_state":"idle","_uuid":"670573da09d996825ca73c95852bfb23a4698e7f","_cell_guid":"6700d560-0d71-422e-b6cc-9b40b8297049","collapsed":false,"trusted":false}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"from pandas import DataFrame, Series\nfrom IPython.display import display\nfrom sklearn.model_selection import StratifiedKFold\n\ndef get_cross_validation_mean_score(full_data,category,model,folds):\n    \n    # === KFold Object === #\n    \n    splitter = StratifiedKFold(n_splits=folds)\n    \n    # === Keep Model Template === #\n    \n    model_copy = model\n    \n    # === Split full data as feature and label data === #\n    \n    feature_data = full_data.drop(category,1)\n    label_data = full_data[category]\n    \n    # === Set Up List for Scores === #\n    \n    scores = []\n    \n    # === For Every Split, Add Accuracy Score by Label Dictionary to Scores List === #\n    \n    for train_indices, test_indices in splitter.split(feature_data, label_data):\n        \n        # === Test Data. Actual Label for Index === #\n        \n        actuals = full_data.iloc[test_indices][category]\n        \n        # === Reset to Unfitted Model === #\n        \n        model = model_copy\n        \n        # === Prepare Input Data for Fitting === #\n        \n        feature_data = full_data.iloc[train_indices].drop(category,1)\n        label_data = full_data.iloc[train_indices][category]\n        \n        # === Fit the Data === #\n        \n        model.fit(feature_data,label_data)\n        \n        # === Obtain predictions from fitted model === #\n        \n        predictions = model.predict(full_data.iloc[test_indices].drop(category,1))\n        \n        # === Get accuracy score by label dictionary, then add to scores list === #\n        \n        scores += [get_score(actuals,predictions)]\n        \n    # === Return a mean score by label dictionary === #\n        \n    mean_score = DataFrame(scores).mean().to_dict()\n        \n    return mean_score","metadata":{"_execution_state":"idle","_uuid":"4c08d5cf28816bd22f998503fab7ced3b043b591","_cell_guid":"3a297670-b85e-4e4f-9d9e-db47404bed85","collapsed":false,"trusted":false}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"def display_classifier_results(full_data,category,models,folds):\n\n    output = {}\n\n    for m in models:\n        try:\n            model_name = type(m).__name__\n            row = get_cross_validation_mean_score(full_data,category,m,folds)\n            output[model_name] = row\n        except:\n            pass\n\n    from pandas import DataFrame\n    from IPython.display import display\n\n    display(DataFrame(data=output, index = [\"Abnormal\",\"Normal\",\"Mean Accuracy\"]).T.round(2).sort_values(\"Mean Accuracy\", ascending=False))","metadata":{"_execution_state":"idle","_uuid":"d5873b79ae1658b010385117f70807685ceea2e8","_cell_guid":"7409aadb-a1c0-48e6-8e71-1dca2037c5f4","collapsed":false,"trusted":false}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"models = []\n\nfrom sklearn.neighbors import KNeighborsClassifier\nmodels = [KNeighborsClassifier()]\n\nfrom sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\nmodels += [GaussianNB(), MultinomialNB(), BernoulliNB()]\n\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier#, VotingClassifier\nmodels += [RandomForestClassifier(), AdaBoostClassifier(), GradientBoostingClassifier(), ExtraTreesClassifier()]\n\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\nmodels += [LinearDiscriminantAnalysis(), QuadraticDiscriminantAnalysis()]\n\nfrom sklearn.svm import SVC, LinearSVC\nmodels += [SVC(),LinearSVC()]\n\nfrom sklearn.neighbors.nearest_centroid import NearestCentroid\nmodels += [NearestCentroid()]\n\nfrom xgboost import XGBClassifier\nmodels += [XGBClassifier()]","metadata":{"_execution_state":"idle","_uuid":"dcb24ddec2cfedc503159660c19e5d6510dee4e7","_cell_guid":"e563ca58-645f-4af4-9f58-4381ce64dd70","collapsed":false,"trusted":false}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"display_classifier_results(data, target, models, 10)","metadata":{"_execution_state":"idle","_uuid":"2b0509e8d88c6ba146240c5148de94376c9f66ff","_cell_guid":"40f8839a-a41c-46b5-9958-ea8eadfc1376","collapsed":false,"trusted":false}}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","file_extension":".py","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.1","pygments_lexer":"ipython3","nbconvert_exporter":"python"}},"nbformat_minor":0}