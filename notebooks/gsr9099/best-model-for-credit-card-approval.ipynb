{"cells":[{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"95e73493-5a61-4dfe-8a42-a7d7672f1e3e"}},"cell_type":"markdown","source":"Best Model for Credit Card Approval Project"},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fea64d26-cbfc-42da-8362-ae39bfbcca36"}},"cell_type":"markdown","source":"-- by **Gurnoordeep Singh Randhawa** "},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"819af90c-0ed5-46d4-9ef7-a6fab9e9f301"}},"cell_type":"markdown","source":"This Project is based on a hypothetical situation which follows - <br>\nThe Bank provides us with a really small fraction of data from there database and wants us to -\n* Clean the datasets and join them.\n* Visualize on that data to make it presentablle and understandable to the board of directores.\n* Find the fastest and the most accurate Model to find the features that are needed to be accessed and in which order while approoving a Credit for a new customer."},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"54637945-d8b6-4aa8-b521-3004b553acf1"}},"cell_type":"markdown","source":"##Importing all the Libraries required."},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"45550598-5ed8-4cbd-8390-98055ed8b78f"},"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3581297c-95cc-4643-8ac2-0d2567070f14"}},"cell_type":"markdown","source":"##Understanding Datasets"},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"77dc9d62-49a4-4501-a533-79f69334e24b"}},"cell_type":"markdown","source":"Firstly we will go ahead and access our data that we are using.\nFrom pre assessment of the data we found that - \n* Both the files are in CSV format.\n* The fields are seperated by the ',' deliminater."},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"40c235d3-ed66-4b75-ad96-f207676bb794"}},"cell_type":"markdown","source":"###Application Records (df1)"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1fc5c162-c050-45e5-88f0-eb4e5871d453"}},"cell_type":"markdown","source":"This data set is the Application records. It contains all the information on all the clients and these clients are unique.<br>"},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d7233082-a89c-4cbc-9b3c-4a85faf857b4"},"trusted":true},"cell_type":"code","source":"df1 = pd.read_csv('/kaggle/input/credit-card-approval-prediction/application_record.csv', delimiter=',', index_col=False)\ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"82ad221d-6894-4c06-af11-4671c2bf58cc"},"trusted":true},"cell_type":"code","source":"print('The shape of Application Record dataset is ' + str(df1.shape) +'.')\nprint('There are ' + str(df1['ID'].nunique()) + ' unique IDs in this dataset.')","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"83ef2606-427a-4e20-8422-802a76042264"},"trusted":true},"cell_type":"code","source":"df1.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9083475c-3440-4a73-ba79-ca178ee5a141"}},"cell_type":"markdown","source":"To get the further info on our dataset we can see below."},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"48ba5583-7e9a-4384-b8fe-4289168f08ee"},"trusted":true},"cell_type":"code","source":"df1.head().T","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9c4c6ddd-a6ce-4423-850c-a517fe7d0e99"}},"cell_type":"markdown","source":"###Credit Records (df2)"},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"09aa3a48-9b50-4679-ae07-fa8e5d4a6b92"}},"cell_type":"markdown","source":"This dataset is called the Credit Records. <br>\nIt contains the status of each customers credit status and the count of months for."},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c1120d66-2315-446a-9d54-e236e69ac18b"},"trusted":true},"cell_type":"code","source":"df2 = pd.read_csv('/kaggle/input/credit-card-approval-prediction/credit_record.csv', delimiter=',', index_col=False)\ndf2.head()","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"07666ff9-bf87-4724-ac1b-18a9db7c7a06"},"trusted":true},"cell_type":"code","source":"print('The shape of Credit Record dataset is ' + str(df2.shape) +'.')\nprint('There are ' + str(df2['ID'].nunique()) + ' unique IDs in this dataset, which is much less than the parent dataset.')","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ec0b5fb1-bce9-456e-97bc-7619357022b6"}},"cell_type":"markdown","source":"##Merging and Cleaning the datasets"},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d99fe4e4-2d6e-48c7-88e0-d96c3869550c"}},"cell_type":"markdown","source":"###Merging"},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b9fbb51f-0875-438d-8dbf-7b5d8a1d1b12"}},"cell_type":"markdown","source":"Now we are going to merge the two datasets on the common column i.e. ID."},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ed6869b1-5b9a-4725-9406-b4a29fb34488"},"trusted":true},"cell_type":"code","source":"df3 = pd.merge(df1, df2, on='ID')\ndf3.head()","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3bf5a2a3-7724-4392-a918-4c8bc050a846"},"trusted":true},"cell_type":"code","source":"print('The shape of the merged dataset is ' + str(df3.shape) +'.')","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f1e7a93e-ebed-45a3-92b2-b64f13f9bb21"}},"cell_type":"markdown","source":"###Cleaning the dataset"},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"555cfc06-af89-4259-8c79-7c2fc03599d8"}},"cell_type":"markdown","source":"But this is not our final dataset as this dataset contains a lot of dupluicates for every time the customer missed a transaction. So -\n* We are going to drop all the rows with the missing values.\n* Drop all the duplicate rows and keep the first entry of the customer.\n* We will do this on a copy of our merged dataset so that the original stays intact for further use."},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3e4ab359-ca3c-4675-b587-56f4625f0c4c"},"trusted":true},"cell_type":"code","source":"df4 = df3.dropna().drop_duplicates(subset='ID', keep='first')\ndf4.head()","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8b6b19ae-7794-4938-a911-56903e8c8a33"}},"cell_type":"markdown","source":"Now this is the data set that we will do our visualization on."},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"caf7bf3b-795a-4ed4-ac8d-565b20be1eed"},"trusted":true},"cell_type":"code","source":"print('The shape of the cleaned data set is ' + str(df4.shape) +'.')","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4d00d8c4-8d8a-4271-9f49-d17af717a831"}},"cell_type":"markdown","source":"##Visualization on the cleaned dataset."},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0aae2edc-1f8f-4dd8-9b14-f021fb3a1ef0"}},"cell_type":"markdown","source":"Now we are going to do a bit of visualization of the datt that we have so that our dataset is presentable to the board of directors."},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"34aa582c-85b0-4a5d-84f7-02af856a74d1"}},"cell_type":"markdown","source":"###Age VS Customer Frequency"},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1cb93995-40ba-4223-9099-cff6599e0d33"}},"cell_type":"markdown","source":"The age of the customers are given in a format which is little complicated. It is given as the amount of days from birth till today and the -ve sign indicated that the time is in past.<br>\nSo, we are going to convert this into the years and then map a histogram chart that tells us to]he amount of customer and which age bracket they are in."},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c8d4aeda-ac72-44bf-b96d-0482af571085"},"trusted":true},"cell_type":"code","source":"# Converting the Days of Birth field to Age in years.\ndf4['Age']=-(df4['DAYS_BIRTH'])//365\t\nprint(df4['Age'].value_counts(bins=10,normalize=False,sort=False))\ndf4['Age'].plot(kind='hist',bins=20,density=False)","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3fa8579d-4574-46fb-90fe-36eceb778edc"}},"cell_type":"markdown","source":"###Employment time VS Customer Frequency"},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"23bf036b-783e-4440-b53e-c4ed2ab9a556"}},"cell_type":"markdown","source":"Employment column is represented in the same format and we are going to covvert it the same way we did for the age.<br>\nThen, we map a histogram representing the data of amount of customers vs the years they have been employed."},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"39bc9ec5-e9fd-4f4e-8c37-e5398901ee3d"},"trusted":true},"cell_type":"code","source":"# Converting the Days_Employed field from days to Years and the visualising.\ndf4['Employed']=-(df4['DAYS_EMPLOYED'])//365\t\ndf4[df4['Employed']<0] = np.nan # replace by na\ndf4['DAYS_EMPLOYED']\ndf4['Employed'].fillna(df4['Employed'].mean(),inplace=False) #replace na by mean\ndf4['Employed'].plot(kind='hist',bins=20,density=False)","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d19ad4d8-9f2e-4b2c-95f8-7fde81d72796"}},"cell_type":"markdown","source":"###Various Occupation Classifications"},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"71f4419b-e7fa-4e6a-82f0-b73ec25f3f01"}},"cell_type":"markdown","source":"Taking a rough look on the Occupation field brfore visualising"},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e6755234-4488-40bd-8063-4bc911323a68"},"trusted":true},"cell_type":"code","source":"df4['OCCUPATION_TYPE'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"679f22b4-031b-4f77-a87c-dba7f0ce0250"},"trusted":true},"cell_type":"code","source":"df4['OCCUPATION_TYPE'].value_counts().sort_values().plot(kind='barh', figsize=(9,12))","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"61dd83f8-8ebf-4b51-8f70-5b3b339cabc5"},"trusted":true},"cell_type":"code","source":"PNoLoan = (df4.loc[df4['STATUS'] == 'X'].shape[0]/df4.shape[0]) * 100\nprint(str(round(PNoLoan, 2)) + \"% of people have no loans.\")","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0142ee4f-bafe-4cdd-b766-f334a34bdc46"},"trusted":true},"cell_type":"code","source":"PPaidOf = (df4.loc[df4['STATUS'] == 'C'].shape[0]/df4.shape[0]) * 100\nprint(str(round(PPaidOf, 2)) + \"% of customers have paid off there dues.\")","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0aff64e0-2ee0-4c81-b86c-3144fe34259c"}},"cell_type":"markdown","source":"Now we will declare the people who have not paid there dues as the defaulters. These are represented by numbers in the Status field of the Credit Records dataset."},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1f7a3e9b-d3ae-4145-813b-acb0e981d1a7"},"trusted":true},"cell_type":"code","source":"defaulters= ['0','1','2','3','4','5']","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"216a6a89-e41a-4df3-be58-e4fbb84e5a19"},"trusted":true},"cell_type":"code","source":"df4['OverDues'] = np.where(df4.STATUS.isin(defaulters), 1, 0)\ndf4.head()","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"625fe99f-2338-4b63-a185-a72abaaf5257"},"trusted":true},"cell_type":"code","source":"df4.groupby('OCCUPATION_TYPE')","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"81459d50-3a1f-4a10-aa9a-1318879bc5b1"}},"cell_type":"markdown","source":"###Defaulters VS PaidOff"},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"453252fa-0eb1-48cc-b93c-29f31cf994ec"}},"cell_type":"markdown","source":"This chart will represent the amount of money made by People who have paid of vs the Defaulters."},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"df51f367-4629-4059-aa11-dc716b3e221f"},"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\ndf4[df4['OverDues']==1]['AMT_INCOME_TOTAL'].hist(alpha=0.7,color='Red', bins=6,label='Defaulters')\ndf4[df4['OverDues']==0]['AMT_INCOME_TOTAL'].hist(alpha=0.3,color='Blue', bins=6,label='PaidOff')\n                                                    \nplt.title('Customers around the income groups')                                                    \nplt.legend()\nplt.xlabel('Annual Income')\nplt.ylabel('Number of Customers')","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c564830f-61ed-4647-b2b1-04eab634dfbc"},"trusted":true},"cell_type":"code","source":"df4['OverDues'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a7c7c5b7-9c72-47a0-a580-dc6560df887d"}},"cell_type":"markdown","source":"###Female VS Male"},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"21654351-e0f0-4d93-93bd-61d46612ccfe"}},"cell_type":"markdown","source":"This chart tell us the Male and Female numbers in eeach category."},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f9d902e8-a0b3-49de-8d39-9c7553700886"},"trusted":true},"cell_type":"code","source":"pd.crosstab(df4.CODE_GENDER,df4.OverDues).plot(kind='bar')\nplt.title('Gender vs Defaulters')\nplt.xlabel('Gender')\nplt.ylabel('Number of Customers')\nplt.legend(labels = [\"PaidOff\", \"Defaulters\"])\nplt.xticks(np.linspace(0, 1, 2), ['Female','Male'])","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c9c524a8-bb03-4b1b-a49b-efccbe00d341"}},"cell_type":"markdown","source":"###Income types VS Customer Frequency"},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2813f9f3-6293-4111-aad9-e39663a1f872"}},"cell_type":"markdown","source":"This chart tells us the income types of the people in both categories."},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"38ca085b-cc2f-44b2-9a5f-26cbdf511b5c"},"trusted":true},"cell_type":"code","source":"pd.crosstab(df4.NAME_INCOME_TYPE, df4.OverDues).plot(kind='bar', figsize=(12,6))\nplt.title('Customers across various Income Types')\nplt.xlabel('Income Type')\nplt.ylabel('Number of Customers')\nplt.legend(labels = [\"PaidOff\", \"Defaulters\"])","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c6151c73-0835-497a-8ecd-da4fb7c836be"}},"cell_type":"markdown","source":"## Correlations"},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3e970b17-67ac-4bb2-a43e-56deed64d7f5"}},"cell_type":"markdown","source":"Now we will find the feature correlation by mapping them."},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"446ea3ae-c255-42ba-add5-ee2322d7ca66"}},"cell_type":"markdown","source":"###Heat Mapping"},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e7ebc543-ef3b-4b27-a016-cef9c84d9c19"}},"cell_type":"markdown","source":"Now we are going to find the corelation between features for more in-depth review of how features work.<br>\nThe lesser they are correlated the better this is."},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"51b828be-60e8-4bce-b414-81ace3ee552a"},"trusted":true},"cell_type":"code","source":"# Put in the columns that we want to make the dummie variable of...\ndf7 = pd.get_dummies(df3, columns=['CODE_GENDER','FLAG_OWN_CAR','FLAG_OWN_REALTY','NAME_INCOME_TYPE','NAME_EDUCATION_TYPE','NAME_FAMILY_STATUS','NAME_HOUSING_TYPE'], drop_first = False)\ndf7['OverDues'] = np.where(df7.STATUS.isin(defaulters), 1, 0)","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d17828fa-478e-4026-929a-8b91ac638c84"},"trusted":true},"cell_type":"code","source":"#Using Pearson Correlation\nplt.figure(figsize=(12,10))\n\ncorr = df7[['OverDues', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'AMT_INCOME_TOTAL', 'FLAG_PHONE', 'CNT_FAM_MEMBERS']].corr()\nsns.heatmap(corr, \n        xticklabels=corr.columns,\n        yticklabels=corr.columns,\n        annot=True, cmap=plt.cm.Reds)","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fceb2bbf-8ae6-4afd-a585-79426c5a379a"}},"cell_type":"markdown","source":"###Pairplotting"},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"522aa160-0c8f-4bf4-9d03-a1d4862947f8"}},"cell_type":"markdown","source":"Now we will do a bit of Pairplottin which is better to see the distribution of the single variable and its relation with other variable.<br>\nThis will help us identify trends for follow-up analysis."},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d3897bcb-7362-489e-a709-5fd6a3011dde"},"trusted":true},"cell_type":"code","source":"sns.pairplot(df7[['CNT_CHILDREN', 'AMT_INCOME_TOTAL', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'CNT_FAM_MEMBERS', 'OverDues']])","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1b958992-1254-43a5-8a5f-ee67da58215d"}},"cell_type":"markdown","source":"##Prediction Modelling"},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6d7cd66d-7f69-4e6e-aebc-cd568fb019b7"},"trusted":true},"cell_type":"code","source":"#Making a copy of this df just in case we want to retry from the start\ndf5 = df4.copy()","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7e4cd66f-fbcd-4ea5-a23b-eec977011103"}},"cell_type":"markdown","source":"Now we have columns with more than one catagorical values and there are many of them. <br>\nIf we go on converting each and every one of them into different columns with two categories it will take a lot of time. <br>\nSo, to simplify this we will use **get_dummies** cmd and mention the colmumns that we want to make dummie vaiables of.<br>\nWe do this to make as many features as possible for our prediction model as we cannot use string for analysis."},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ae541496-e3ed-4c8a-a9c5-456cc3d67810"}},"cell_type":"markdown","source":"###Creating Dummie Variables"},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"27b0ecb1-7de3-41d8-b42b-a36ebc2570d3"},"trusted":true},"cell_type":"code","source":"df7.head()","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ad983892-2707-4e17-b217-28bd67675e4b"}},"cell_type":"markdown","source":"###Declaring Features"},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"25d74625-7f62-4173-bf87-1a1ab4ad9265"},"trusted":true},"cell_type":"code","source":"df7.columns","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d2916cf3-d795-41e7-81a3-ac72d6a12ba3"},"trusted":true},"cell_type":"code","source":"#Mentioning our Features\nFeatures = ['CNT_CHILDREN', 'AMT_INCOME_TOTAL',\n       'DAYS_BIRTH', 'DAYS_EMPLOYED', 'FLAG_MOBIL', 'FLAG_WORK_PHONE',\n       'FLAG_PHONE', 'FLAG_EMAIL', 'CNT_FAM_MEMBERS',\n       'CODE_GENDER_F', 'CODE_GENDER_M', 'FLAG_OWN_CAR_N', 'FLAG_OWN_CAR_Y',\n       'FLAG_OWN_REALTY_N', 'FLAG_OWN_REALTY_Y',\n       'NAME_INCOME_TYPE_Commercial associate', 'NAME_INCOME_TYPE_Pensioner',\n       'NAME_INCOME_TYPE_State servant', 'NAME_INCOME_TYPE_Student',\n       'NAME_INCOME_TYPE_Working', 'NAME_EDUCATION_TYPE_Academic degree',\n       'NAME_EDUCATION_TYPE_Higher education',\n       'NAME_EDUCATION_TYPE_Incomplete higher',\n       'NAME_EDUCATION_TYPE_Lower secondary',\n       'NAME_EDUCATION_TYPE_Secondary / secondary special',\n       'NAME_FAMILY_STATUS_Civil marriage', 'NAME_FAMILY_STATUS_Married',\n       'NAME_FAMILY_STATUS_Separated',\n       'NAME_FAMILY_STATUS_Single / not married', 'NAME_FAMILY_STATUS_Widow',\n       'NAME_HOUSING_TYPE_Co-op apartment',\n       'NAME_HOUSING_TYPE_House / apartment',\n       'NAME_HOUSING_TYPE_Municipal apartment',\n       'NAME_HOUSING_TYPE_Office apartment',\n       'NAME_HOUSING_TYPE_Rented apartment', 'NAME_HOUSING_TYPE_With parents']","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5b9370bf-2cd1-4d34-a0cd-9c41203973da"}},"cell_type":"markdown","source":"###Train Test split"},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1da87f09-1585-4e6d-ae12-ac5bf04a189b"},"trusted":true},"cell_type":"code","source":"from sklearn import model_selection\nfrom sklearn.model_selection import train_test_split\n\ntrain, test = train_test_split(df7, test_size = 0.3, random_state=21)\ntrain = train.reset_index(drop=True)\ntest = test.reset_index(drop=True)\n\nfeatures_train = train[Features]\nlabel_train = train['OverDues']\nfeatures_test = test[Features]\nlabel_test = test['OverDues']","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4c2b78d3-5e7e-46aa-b2b7-1994d81760aa"},"trusted":true},"cell_type":"code","source":"#df7.drop('OCCUPATION_TYPE', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"20474698-436e-4949-9deb-3ec3f48b0844"}},"cell_type":"markdown","source":"As our Employer wants us to find the most important feature for them to approove the credit for there customers, we have these two predictive models that we are going to put to test."},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0ad1d1a2-1fe1-4cb0-9c20-c8d61750db5f"}},"cell_type":"markdown","source":"## Random Forest Classifier"},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5906d36e-fbd2-42aa-82ad-65bbbe96d9fe"}},"cell_type":"markdown","source":"This Model test all the features in multiple times in different orders. This is the reason that it is the slowest one but in theory oit should be the most accurate one as well."},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"34470d83-e37e-4d63-9af9-8b83eabbcf1d"},"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier()\n\nclf.fit(features_train,label_train)\n\npred_train = clf.predict(features_train)\npred_test = clf.predict(features_test)\n\nfrom sklearn.metrics import accuracy_score\nRFCaccuracy_train = (accuracy_score(pred_train,label_train)) * 100\nRFCaccuracy_test = (accuracy_score(pred_test,label_test)) * 100","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8f398066-92da-4b73-8313-98d969a13ea3"},"trusted":true},"cell_type":"code","source":"print('Training Accuracy is ' + str(round(RFCaccuracy_train, 4)) + '%')\nprint('Test Accuracy is ' +  str(round(RFCaccuracy_test, 4)) + '%')","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c165b81b-aaf5-489a-ba3f-012cef0846d8"}},"cell_type":"markdown","source":"Here is the confusion mattrix for this model."},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e748c1ef-53cf-4610-be09-9fb93b1d8ab5"},"trusted":true},"cell_type":"code","source":"pd.crosstab(label_test,pd.Series(pred_test),rownames=['ACTUAL'],colnames=['PRED'])","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"45129d3a-7a00-4191-b779-bf3fc41377c5"},"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n\nprint('Accuracy Score')\nprint(accuracy_score(label_test, pred_test),'\\n')\n\nprint('Precision Score')\nprint(precision_score(label_test, pred_test,average = None),'\\n')\n\nprint('Confusion Matrix')\narray = confusion_matrix(label_test, pred_test)\ncolumns = ['Non Defaulter','Defaulter'] \nprint(pd.DataFrame(array,columns = columns, index = columns),'\\n')\n\nprint('Classification Report')\nprint(classification_report(label_test, pred_test),'\\n')","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"66e7ee39-16aa-45f8-9fee-1828e1beb62c"}},"cell_type":"markdown","source":"## Decision Tree Classifier"},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d20f0476-2cef-42a6-9ff4-ec721da64af2"}},"cell_type":"markdown","source":"This Model is faster but not that accurate as it only test the features one time."},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"88a8e344-3cba-4ac2-82ef-cf61d026c48a"},"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ntree = DecisionTreeClassifier(random_state=0)\ntree.fit(features_train, label_train)\n\n# predict train set\npred_train=tree.predict(features_train)\n# predict test set\npred_test=tree.predict(features_test)\n\nfrom sklearn.metrics import accuracy_score\nDTCaccuracy_train = (accuracy_score(pred_train,label_train)) * 100\nDTCaccuracy_test = (accuracy_score(pred_test,label_test)) * 100","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"249d2be3-1387-4359-b86f-335f682c4493"},"trusted":true},"cell_type":"code","source":"print('Training Accuracy is ' + str(round(DTCaccuracy_train, 4)) + '%')\nprint('Test Accuracy is ' +  str(round(DTCaccuracy_test, 4)) + '%')","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bd431776-f3ba-40c0-9b43-d2b3d54d62c6"},"trusted":true},"cell_type":"code","source":"pd.crosstab(label_test,pd.Series(pred_test),rownames=['ACTUAL'],colnames=['PRED'])","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b590a161-16f3-4110-9dc5-2930897c362c"},"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n\nprint('Accuracy Score')\nprint(accuracy_score(label_test, pred_test),'\\n')\n\nprint('Precision Score')\nprint(precision_score(label_test, pred_test,average = None),'\\n')\n\nprint('Confusion Matrix')\narray = confusion_matrix(label_test, pred_test)\ncolumns = ['Non Defaulter','Defaulter']  \nprint(pd.DataFrame(array,columns = columns, index = columns),'\\n')\n\nprint('Classification Report')\nprint(classification_report(label_test, pred_test),'\\n')","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8da97a77-b334-4184-979e-29faa2cec3f3"},"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"31b101c2-37c5-4ca5-a721-bb2b751c243c"}},"cell_type":"markdown","source":"## Feature Importance"},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3329d2b7-6ec6-41eb-98ee-743df0758422"},"trusted":true},"cell_type":"code","source":"dfz=pd.DataFrame({'features':features_train.columns,'importances':tree.feature_importances_})\ndfz.sort_values('importances',inplace=True)\ndfz.plot(kind='barh', title = 'Decision Tree Classifier\\nFeature Importances', y='importances',x='features',color='brown', figsize=(12,22))","execution_count":null,"outputs":[]},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2dda2bda-b8b8-40c1-94f2-cdf30d27f7ee"}},"cell_type":"markdown","source":"## Conclusion...."},{"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"01679a93-7786-412d-87cf-20457aa1af6d"}},"cell_type":"markdown","source":"* From the model testing done above we can see that the Decision Tree Classifier is better faster and has almost the same accuracy as compared to the Random Forest Classifier. \n* This tells us that on per our employers demand the best fit for there work would be the Decision tree classifier and We did the feature importance chart on them.<br> \n* The most important features that are at the top of the chart gives the bank a slight insight on what to test for while approving a credit based on there previous customer data."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}