{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\ncolor = sns.color_palette()\nsns.set_style('darkgrid')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import stats\nfrom scipy.stats import skew,norm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\ndef ignore_warn(*args,**kwargs):\n    pass\nwarnings.warn = ignore_warn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/brasilian-houses-to-rent/houses_to_rent_v2.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corrmat = data.corr()\n#print(corrmat)\nf,ax = plt.subplots(figsize=(6,6))\nsns.heatmap(corrmat,square=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As it is seen from the correlation map, fire insurance and rent amount show very high correlation. Also, rent amount(or fire insurance) shows good coorelation with bathrooms and rooms. Also, hoa is highly correlated  to total amount, as expected.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking for missing data\ndata_missing = (data.isnull().sum()/len(data)) * 100\ndata_missing = data_missing.drop(data_missing[data_missing==0].index).sort_values(ascending=False)\nmissing_data = pd.DataFrame({'Missing Percentage':data_missing})\nmissing_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, there is no missing data, so we do not need to eliminate any columns or rows.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data[['floor']] = data[['floor']].replace(['-'], ['0'])\n#replacing - values in floor with 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_col = ['city','animal','furniture']\nfor col in cat_col:\n    sns.set()\n    cols = ['city','area','rooms','bathroom','parking spaces','floor','animal','furniture','hoa (R$)','rent amount (R$)','property tax (R$)','fire insurance (R$)','total (R$)']\n    plt.figure()\n    sns.pairplot(data[cols],size=5.0,hue=col)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"From here, we can observe the relations between the features. The plots are colored on the basis of city, furnished or not and animal accepted or not. As we see, in the plots, the cities are mostly in clusters, which means city and features can be well correlated. Also, in case of animals or not, we see that if for example, rent is less, animals are not allowed.  ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['floor'] = data['floor'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data3 = data[data['city'] == 'Porto Alegre']\ndata1 = data[data['city'] == 'Rio de Janeiro']\ndata2 = data[data['city'] == 'Campinas']\ndata4 = data[data['city'] == 'SÃ£o Paulo']\ndata5 = data[data['city'] == 'Belo Horizonte']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = data.city\nax = sns.countplot(y,label=\"Count\") \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"average1 = data1.mean(axis=0)\naverage2 = data2.mean(axis=0)\naverage3 = data3.mean(axis=0)\naverage4 = data4.mean(axis=0)\naverage5 = data5.mean(axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"average1.plot(figsize=(10,10))\naverage2.plot(figsize=(10,10))\naverage3.plot(figsize=(10,10))\naverage4.plot(figsize=(10,10))\naverage5.plot(figsize=(10,10))\nplt.show()\n#Plot of averages city wise","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean1 = average1.to_frame() \nmean1 =mean1.rename(columns={0: 'Rio de Janeiro'})\nmean2 = average2.to_frame() \nmean2 = mean2.rename(columns={0: 'Campinas'})\nmean3 = average3.to_frame()\nmean3 = mean3.rename(columns={0: 'Porto Alegre'}) \nmean4 = average4.to_frame() \nmean4 = mean4.rename(columns={0: 'Sao Paulo'}) \nmean5 = average5.to_frame()\nmean5 = mean5.rename(columns={0: 'Belo Horizonte'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = pd.concat([mean1, mean2,mean3,mean4,mean5], axis=1, sort=False)\nresult\n#averages table","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = result.plot.bar(rot=0,logy=True,figsize=(15,7))\n#scaled y axis for better comparison\n#comparison of averages through a bar graph","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mode1 = data1.mode(axis=0).T\nmode1 = mode1.rename(columns={0: 'Rio de Janeiro'})\nmode2 = data2.mode(axis=0).T\nmode2 = mode2.rename(columns={0: 'Campinas'})\nmode3 = data3.mode(axis=0).T\nmode3 = mode3.rename(columns={0: 'Porto Alegre'})\nmode4 = data4.mode(axis=0).T\nmode4 = mode4.rename(columns={0: 'Sao Paulo'})\nmode5 = data5.mode(axis=0).T\nmode5 = mode5.rename(columns={0: 'Belo Horizonte'})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = result.plot.bar(rot=0,logy=True,figsize=(15,7))\n#scaled y axis for better comparison\n#comparison of modes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = result.plot(rot=0,figsize=(15,15))\n#comparison of mode values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# label encoding the data \nfrom sklearn.preprocessing import LabelEncoder \n  \nle = LabelEncoder() \n  \ndata['city']= le.fit_transform(data['city']) \ndata['furniture']= le.fit_transform(data['furniture']) \ndata['animal']= le.fit_transform(data['animal']) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = data[\"rent amount (R$)\"]\nX = data[['city','area','rooms','bathroom','parking spaces','floor','animal','fire insurance (R$)','furniture','hoa (R$)','property tax (R$)','total (R$)']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dia = y.copy()\ndata = X[['city']]\ndata_n_2 = (data - data.mean()) / (data.std())              # standardization\ndata = pd.concat([y,data_n_2.iloc[:,0:1000]],axis=1)\ndata = pd.melt(data,id_vars=\"city\",\n                    var_name=\"features\",\n                    value_name='value')\nplt.figure(figsize=(10,10))\nsns.violinplot(x=\"features\", y=\"value\", hue=\"city\", data=data, inner=\"quart\")\nplt.xticks(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X[0:10000]\ny_train = y[0:10000]\nX_test = X[10000:]\ny_test = y[10000:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split \nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"regressor = LinearRegression()  \nregressor.fit(X_train, y_train) #training the algorithm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = regressor.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df.head(25)\ndf1.plot(kind='bar',figsize=(16,10))\nplt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\nplt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Coefficients: \\n', regressor.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm # import statsmodels \n\nX = X_train \ny = y_train \nX = sm.add_constant(X) \nmodel = sm.OLS(y, X).fit() \npredictions = model.predict(X)\n\n# Print out the statistics\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that the coefficients obtained through stats model and sklearn match almost exactly, which is good for our model.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}