{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import IPython.display as ipd \nimport librosa\nimport librosa.display","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport os\naudio_dataset_path = '../input/urbansound8k/'\nmetadata = pd.read_csv('../input/urbansound8k/UrbanSound8K.csv')\nmetadata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def feature_extractor(file):\n    audio,sample_rate = librosa.load(file_name,res_type='kaiser_fast')\n    mfccs_feature = librosa.feature.mfcc(y=audio,sr=sample_rate,n_mfcc=40)\n    mfccs_scaled_feature = np.mean(mfccs_feature.T,axis=0)\n    return mfccs_scaled_feature","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom tqdm import tqdm\nextracted_features = []\nfor index_num,row in tqdm(metadata.iterrows()):\n    file_name = os.path.join(os.path.abspath(audio_dataset_path),'fold'+str(row[\"fold\"])+'/',str(row['slice_file_name']))\n    final_class_labels = row['class']\n    data= feature_extractor(file_name)\n    extracted_features.append([data,final_class_labels])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"extracted_features_df = pd.DataFrame(extracted_features,columns=['feature','class'])\nextracted_features_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = np.array(extracted_features_df['feature'].tolist())\ny = np.array(extracted_features_df['class'].tolist())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.utils import to_categorical","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"le = LabelEncoder()\nyy = to_categorical(le.fit_transform(y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split the dataset \nfrom sklearn.model_selection import train_test_split \n\nx_train, x_test, y_train, y_test = train_test_split(x, yy, test_size=0.2, random_state = 42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense , Activation , Dropout\nfrom sklearn import metrics","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_labels = yy.shape[1]\nfilter_size = 2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Construct model \nmodel = Sequential()\n\nmodel.add(Dense(256, input_shape=(40,)))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(256))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(num_labels))\nmodel.add(Activation('softmax'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile the model\nmodel.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate pre-training accuracy \nscore = model.evaluate(x_test, y_test, verbose=0)\naccuracy = 100*score[1]\n\nprint(\"Pre-training accuracy: %.4f%%\" % accuracy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint \nfrom datetime import datetime \n\nnum_epochs = 100\nnum_batch_size = 32\n\ncheckpointer = ModelCheckpoint(filepath='saved_models/weights.best.basic_mlp.hdf5', \n                               verbose=1, save_best_only=True)\nstart = datetime.now()\n\nmodel.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), callbacks=[checkpointer], verbose=1)\n\n\nduration = datetime.now() - start\nprint(\"Training completed in time: \", duration)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluating the model on the training and testing set\nscore = model.evaluate(x_train, y_train, verbose=0)\nprint(\"Training Accuracy: \", score[1])\n\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint(\"Testing Accuracy: \", score[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport librosa \nimport numpy as np \n\ndef extract_feature(file_name):\n   \n    try:\n        audio_data, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)\n        mfccsscaled = np.mean(mfccs.T,axis=0)\n        \n    except Exception as e:\n        print(\"Error encountered while parsing file: \", file)\n        return None, None\n\n    return np.array([mfccsscaled])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def print_prediction(file_name):\n    prediction_feature = extract_feature(file_name) \n\n    predicted_vector = model.predict_classes(prediction_feature)\n    predicted_class = le.inverse_transform(predicted_vector) \n    print(\"The predicted class is:\", predicted_class[0], '\\n') \n\n    predicted_proba_vector = model.predict_proba(prediction_feature) \n    predicted_proba = predicted_proba_vector[0]\n    for i in range(len(predicted_proba)): \n        category = le.inverse_transform(np.array([i]))\n        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import IPython.display as ipd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fname = '../input/urbansound8k/fold5/100263-2-0-121.wav'\nprint_prediction(fname)\nipd.Audio(fname)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t = '../input/urbansound8k/fold8/106905-5-0-0.wav'\nprint_prediction(t)\nipd.Audio(t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nprint_prediction('../input/urbansound8k/fold7/101848-9-0-2.wav')\nipd.Audio('../input/urbansound8k/fold7/101848-9-0-2.wav')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print_prediction('../input/urbansound8k/fold6/101281-3-0-14.wav')\nipd.Audio('../input/urbansound8k/fold6/101281-3-0-14.wav')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f='../input/urbansound8k/fold7/102853-8-0-0.wav'\nprint_prediction(f)\nipd.Audio(f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}