{"cells":[{"metadata":{"collapsed":true,"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"# Netflix Movies and TV Shows Analysis\n\n## Description\n\nThis dataset contains information concerning TV Shows and Movies added to the Netflix catalog, including:\n- General information: id, title, type (TV Show or Movie), director, cast and a brief description.\n- Date fields: When the show was released and when it was added to the catalog.\n- Categorization: Rating and category in which the show is listed.\n\nIn the present notebook I go through some wrangling, and some exploratory analysis as well, gaining insight of the kind of\ncontent available in the Netflix and how the nature of the content has changed (if it changed at all) through the years.\n\n## Loading the data"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.offline as pyo\nfrom plotly.subplots import make_subplots\nfrom wordcloud import (\n    STOPWORDS,\n    WordCloud\n)\npyo.init_notebook_mode()","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/netflix-shows/netflix_titles.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"### Basic Information"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"Given that `describe` doesn't calculate the number of unique values for numerical columns, we can print this count ourselves:"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"df.nunique()","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"## Data Transformation\n### Missing Data Analysis\n\nWe begin our analysis by determining the number of rows with holes for each column:"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"As we can see, we have missing values for:\n* `director`: we won't be using it, so we'll discard it.\n* `cast`: we won't be using it, so we'll discard it.\n* `country`: we'll fill missing values here with the `mode`.\n* `date_added`: if you look closely, you'll notice that it's safe to do a `ffill`. Plus, the rows with missing values for\nthis column are the last in the dataset.\n* `rating`: given that there are only 10 empty values. I decided to google the corresponding ratings and fill in the holes with the appropriate values.\n\nFirst, I delete the columns I don't need."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"df.drop(['director', 'cast'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"I fill the missing values for `country` with the `mode`."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"df['country'].fillna(df['country'].mode()[0], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"I forward fill the holes in `date_added`, which are the last records in the dataset."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"df['date_added'] = df['date_added'].ffill()","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"To solve the issue of the missing ratings, I create a dictionary where the key is the `show_id` of the affected records,\nand the values are the corresponding ratings I found after googling the shows. Then, I iterate this `dict`\nfilling in the values."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"replacements = {\n    211: 'TV-MA',\n    2411: 'PG-13',\n    3288: 'TV-MA',\n    4056: 'TV-MA',\n    4402: 'TV-G',\n    4403: 'TV-G',\n    4706: 'TV-14',\n    5015: 'TV-MA',\n    5234: 'TV-MA',\n    6231: 'TV-Y'\n}\n\nfor show_id, rating in replacements.items():\n    df.iloc[show_id, 6] = rating","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"At this point, the missing data issue should be resolved. We can check for missing data once more to confirm we no longer have empty values."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"### Dropping additional columns\n\nWe now proceed to drop some other columns that we are not going to need for our process. I decided to drop `listed_in`,\ngiven that it contains 461 unique values, which makes it kind of useless for any analysis. I removed `description` given\nthat I don't plan on any information out of it."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"df.drop(['listed_in', 'description'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"### Using `show_id` as index\n\nAs the `show_id` column doesn't include duplicates, we can well use it as the index of the `DataFrame`."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"df.set_index('show_id', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Duplicated Data Analysis\n\nLet's check for duplicated rows:"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"df[df.duplicated()]","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"As we can see, there's a duplicated record. We can print the duplicates just to corroborate that nothing\nodd is going on:"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"df[df['title'] == 'Sarkar']","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"Having checked that both rows are actually identical (except for the `show_id`, obviously), we can delete\nthe duplicated row."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"df.drop_duplicates(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"### Enforcing data types\n\nChecking the data types, we can see that there's some work to do:\n- `date_added` is not a proper `datetime`.\n- `type` can be coverted to a `Categorical` type."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"#### Converting values for `date_added` to Dates\n\nIf you take a look at the content of the `date_added` column you'll see that it contains dates in a variety\nof formats. Lucky for us, `Pandas` can deal create Datetime objects out of all of them:"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"df['date_added'] = pd.to_datetime(df['date_added'])","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"#### Converting `type` into a Categorical type\n\nThis column contains two possible values. Although it's not really needed for our analysis, we can transform this column\ninto a categorical one."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"df['type'] = pd.Categorical(df['type'])","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"### Working with `country` (segregating american content)\n\nIf we explore the `country` column, we'll see that it has 544 different values:"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"df['country'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"We will also notice that roughly half of the rows contain the string \"United States\" in `country`."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"len(df[df['country'].str.contains('United States')].index)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"Therefore, we can add a column, called `american`, to flag content produced, at least partially, by America."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"df['american'] = df.apply(lambda row: 'United States' in row['country'], axis=1).replace({True: 'Yes', False: 'No'})","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"### Extracting `month` and `year` from `date_added`\n\nHaving parsed `date_added` to Datetime, we can create additional columns for the `month` and `year` to allow for additional\nanalysis in a convenient way."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"df['month_added'] = pd.DatetimeIndex(df['date_added']).month\ndf['year_added'] = pd.DatetimeIndex(df['date_added']).year","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"### Working with `rating`\n\nIf we take a look at the `ratings` column, we'll see that it contains 14 different values. They are:"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"df['rating'].unique()","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"As you may know, these _maturity ratings_ are earned based on the kind of content of the show, and they stipulate the recommended age for viewers.\nBased on the information found on the [Amazon's Help & Customer Service](https://www.amazon.com/gp/help/customer/display.html?nodeId=G2C2CPZWGZWHZ42J) site,\nwe can map ratings like this:\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Rating</th>\n      <th>Age Restriction</th>\n    </tr>\n  </thead>\n  <tbody>\n<tr><td>TV-PG</td><td>7</td></tr>\n<tr><td>TV-MA</td><td>18</td></tr>\n<tr><td>TV-Y7-FV</td><td>7</td></tr>\n<tr><td>TV-Y7</td><td>7</td></tr>\n<tr><td>TV-14</td><td>16</td></tr>\n<tr><td>R</td><td>18</td></tr>\n<tr><td>TV-Y</td><td>0</td></tr>\n<tr><td>NR</td><td>18</td></tr>\n<tr><td>PG-13</td><td>13</td></tr>\n<tr><td>TV-G</td><td>0</td></tr>\n<tr><td>PG</td><td>7</td></tr>\n<tr><td>G</td><td>0</td></tr>\n<tr><td>UR</td><td>18</td></tr>\n<tr><td>NC-17</td><td>18</td></tr>\n  </tbody>\n</table>\n</div>\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Name</th>\n      <th>Age Restriction</th>\n    </tr>\n  </thead>\n  <tbody>\n<tr><td>Kids</td><td>0</td></tr>\n<tr><td>Older Kids</td><td>7</td></tr>\n<tr><td>Teens</td><td>13</td></tr>\n<tr><td>Young Adults</td><td>16</td></tr>\n<tr><td>Adults</td><td>18</td></tr>\n  </tbody>\n</table>\n</div>\n\nThus, we can create additional `Series` for this information."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"ratings_data = { 'TV-PG': 7,'TV-MA': 18,'TV-Y7-FV': 7,'TV-Y7': 7,\n            'TV-14': 16,'R': 18,'TV-Y': 0,'NR': 18,'PG-13': 13,\n            'TV-G': 0,'PG': 7,'G': 0,'UR': 18,'NC-17': 18}\n\nratings = pd.Series(ratings_data, name='age')\nratings","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"ages_data = {0: 'Kids', 7: 'Older Kids', 13: 'Teens', 16: 'Young Adults', 18: 'Adults'}\nages = pd.Series(ages_data, name='description')\nages","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"We can now proceed to join both `Series` to put together a temporary `DataFrame` -- that I will eventually merge into\nthe main `DataFrame`. I also convert the columns to Categorical\nbecause why not."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"ratings_df = pd.merge(ratings, ages, left_on='age', right_index=True)\nage_bins = [-1, 17, 19]\nratings_df['18+'] = pd.cut(ratings_df['age'], age_bins, labels=['No', 'Yes'])\n\nratings_df['description'] = pd.Categorical(ratings_df['description'],\n                                           categories=['Kids', 'Older Kids', 'Teens', 'Young Adults', 'Adults'],\n                                           ordered=True)\nratings_df['age'] = pd.Categorical(ratings_df['age'], ordered=True)\n\nratings_df","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"You probably noticed that I created one extra column: `18+`. The idea is to flag the content for adults.\n\nWe now merge the additional data we generated for ratings into the main `DataFrame`. I will also rename the new columns with more appropriate names."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"df = pd.merge(df, ratings_df, left_on='rating', right_index=True)\ndf.rename(columns={'age': 'recommended_age', 'description': 'rating_description'}, inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"## Descriptive Statistics\n\nHaving dropped columns we don't need, added some extra columns, enforced data types and removed duplicates,\nour data is finally ready to start our analysis. Let's begin by printing some descriptive analytics."},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"### Statistics for Numerical Variables"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"df.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Statistic for Categorical Variables"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"df.describe(include=[object, 'category']).T","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"### Types"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"def group_and_count_by(data, column_names:list, reset_index:bool = True) -> pd.DataFrame:\n    _df = data.filter(column_names).reset_index().groupby(column_names).count().rename(columns={'show_id': 'count'})\n    if reset_index:\n        _df = _df.reset_index()\n    return _df.sort_values(by=['count'], ascending=False)\n\n\ndef plot_pie(data, fig, row, col, top:int = -1):\n    labels = data['labels']\n    values = data['values']\n    if top > 0:\n        labels = data['labels'][:top]\n        labels.loc[labels.index.max() + 1] = \"Others\"\n        values = data['values'][:top]\n        values.loc[values.index.max() + 1] = data['values'][top:].sum()\n    fig.add_trace(\n        go.Pie(labels=labels,\n               values=values,\n               name=data['name']),\n        row, col\n    )\n\ndef plot_pie_pair(data_a, data_b, title, top:int = -1):\n    fig = make_subplots(rows=1, cols=2, specs=[[{\"type\": \"domain\"}, {\"type\": \"domain\"}]])\n    plot_pie(data_a, fig, 1, 1, top)\n    plot_pie(data_b, fig, 1, 2, top)\n    fig.update_traces(hole=.4, hoverinfo=\"label+percent+name\")\n    fig.update_layout(\n        title_text=title,\n        annotations=[\n            dict(text=data_a['name'], x=0.16\n                 , y=0.5, font_size=12, showarrow=False),\n            dict(text=data_b['name'], x=0.82, y=0.5, font_size=12, showarrow=False)\n        ])\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"## Releases by type throughout the years\n\nI plot a bar char showing the number of releases through the years. This allows us to see how recent the\ncontent is."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"releases_by_year = group_and_count_by(df, (['release_year', 'type']))\n\nfig = px.bar(releases_by_year, x='release_year', y='count', color='type')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"As we can see, almost all the content was released in the last 10 years. We can support this plot by\nlooking at the quartiles printed before. There, we can see that only 25% of the content was release before 2013. We\ncan also note that 25% of the content is less than 2-year old (released on 2018 or later).\n\nAnother takeaway from this plot is that the number of TV-Shows has increased significantly, accounting for roughly\n30% ~ 40% of the content released the last 3 years. Moreover, we can plot a line chart showing this:"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"fig = px.line(releases_by_year.sort_values(by=['release_year']), x=\"release_year\", y=\"count\", color='type')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"## Shows by Rating\n\nLet's now study how the TV Shows and Movies are spread across different ratings. Now, working with the `rating` column is\nnot really that practical for most visualizations, given that it has 14 different values. Instead, we can use the\nrating categories I created before. Thus, we can see how content is divided among age ranges.\n"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"shows_by_rating = group_and_count_by(df, ['rating_description', 'type'])\nfig = px.bar(shows_by_rating, x='rating_description', y='count', color='type', barmode='group')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"From the chart we can see that content is more oriented toward adult audiences. This is specially true for movies. In the\nfollowing pie charts this proportion is made even clearer."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"ratings_tv_shows = shows_by_rating[shows_by_rating['type'] == 'TV Show']\nratings_movies = shows_by_rating[shows_by_rating['type'] == 'Movie']\ndata_a = {\n    'labels': ratings_tv_shows['rating_description'],\n    'values': ratings_tv_shows['count'],\n    'name': \"TV Shows\"\n}\n\ndata_b = {\n    'labels': ratings_movies['rating_description'],\n    'values': ratings_movies['count'],\n    'name': \"Movies\"\n}\n\nplot_pie_pair(data_a, data_b, 'TV Shows and Movies')","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"We can plot the same data aggregated by the true `rating`. However, this produces a bunch of small sectors that don't\nadd much meaning to the visualization. Therefore, it's best to establish a number of representative ratings and group the\nrest under \"Others\"."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"shows_by_rating = group_and_count_by(df, ['rating', 'type'])\nratings_tv_shows = shows_by_rating[shows_by_rating['type'] == 'TV Show']\nratings_movies = shows_by_rating[shows_by_rating['type'] == 'Movie']\n\ndata_a = {\n    'labels': ratings_tv_shows['rating'],\n    'values': ratings_tv_shows['count'],\n    'name': \"TV Shows\"\n}\n\ndata_b = {\n    'labels': ratings_movies['rating'],\n    'values': ratings_movies['count'],\n    'name': \"Movies\"\n}\n\nplot_pie_pair(data_a, data_b, 'TV Shows and Movies', 5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Analyzing the previous chart, we can see that the two predominant ratings are [TV-MA](https://rating-system.fandom.com/wiki/TV-MA)\nand [TV-14](https://rating-system.fandom.com/wiki/TV-14), which are assigned to shows with strong language and sexual content.\n\nLet's wrap up the study of ratings by focusing exclusively on content for adults. For this, I create a pivot table as a\n quick and easy way to get this information. Then, as an alternative to bar charts, I use a heatmap for plotting the data."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"shows_18 = group_and_count_by(df, ['type', '18+'])\npivot_18 = pd.pivot_table(shows_18, values='count', index=['type'], columns=['18+'])\npivot_18","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"This table gives us valuable information: the number of movies for adults only is almost half of the total. On the other\nhand, there number of TV Shows for adults is about a third of the total."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"fig = px.imshow(pivot_18, color_continuous_scale='Agsunset')\n# fig = px.bar(shows_18, x='18+', y='count', color='type', barmode='group')\nfig.show()\n","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"## Catalog updates through the years\n\nWe can also study how the catalog has been updated. I use line charts throughout this section, given that is simple and\neasy to understand.\n\n### TV Shows and Movies\n\nI start by plotting two series showing the number of shows added by type through the years. In both cases we can see that\nstarting on 2016 the amount of content added has increased drastically. Another takeaway is that the number of shows added\nthe last years seems to be half the number of movies added."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"catalog_updates_by_type = group_and_count_by(df, ['year_added', 'type'])\nfig = px.line(catalog_updates_by_type.sort_values(by=['year_added']), x=\"year_added\", y=\"count\", color='type')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"### American vs International content\n\nI now plot the rate Netflix has been added american content and content filmed abroad. From this chart we learn that the\ncontent seems to be evenly split and added at about the same rate."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"catalog_updates_by_american = group_and_count_by(df, ['year_added', 'american'])\nfig = px.line(catalog_updates_by_american.sort_values(by=['year_added']), x=\"year_added\", y=\"count\", color='american')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"### 18+ content\n\nI apply the same criterion to compare content for adults only against those for kids and teenagers."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"catalog_updates_by_type = group_and_count_by(df, ['year_added', '18+'])\nfig = px.line(catalog_updates_by_type.sort_values(by=['year_added']), x=\"year_added\", y=\"count\", color='18+')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"### Totals by month\n\nBy aggregating the number of shows added each month, we can determine if there are any months that see more content added\nthan other."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"shows_by_month = group_and_count_by(df[df['year_added'] < 2020], ['month_added', 'type'])\nfig = px.bar(shows_by_month, x='month_added', y='count', color='type', barmode='group')\nfig.show()\n","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"In fact, we see that the last three have the highest numbers of shows added. This is to be expected, given that in the\nwinter months people spend more time at home. So, it makes sense for Netflix to update the catalog in the months before the\nholidays.\n\n## Word Cloud for `title`\n\nUsing `WordCloud` we can obtain the words most frequently used in titles."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"wordcloud = WordCloud(\n    height = 1000,\n    width = 1500,\n    background_color = 'black',\n    stopwords = STOPWORDS).generate(str(' '.join(df['title'].values)))\nfig = plt.figure(\n    figsize = (30, 20),\n    facecolor = 'k',\n    edgecolor = 'k')\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"## Movies duration\n\nLastly, I'll study the duration of the american and foreign movies. First, I generate a box plot.\n"},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"movies_duration = df[df['type'] == 'Movie'].filter(['american', 'duration'])\nmovies_duration['duration'] = movies_duration['duration'].map(lambda x: x.replace(' min', ''))\nmovies_duration['duration'] = pd.to_numeric(movies_duration['duration'])\n\nfig = px.box(movies_duration, y=\"duration\", color='american')\nfig.show()\n","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"This tells us that,\nin general, foreign movies are longer than american productions. Also, the american movies seem to be more concentrated around\nthe median than the foreign. We can further cement this insight by means of a violin plot."},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"fig = px.violin(movies_duration, y=\"duration\", color=\"american\", box=True, hover_data=movies_duration.columns)\nfig.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}