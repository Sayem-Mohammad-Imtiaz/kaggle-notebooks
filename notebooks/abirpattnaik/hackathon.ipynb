{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport pprint as pp\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nmaster_data = pd.read_csv('../input/Suicides in India 2001-2012.csv')\nmaster_data.head()\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"master_data.isnull().sum()\n#no null values present in the dataset\n\nobj_type_variables = [column for column in master_data.columns if master_data[column].dtype in ['object']]\nprint(obj_type_variables)\nfor column in obj_type_variables:\n    master_data[column] = master_data[column].astype('category')\nmaster_data.info()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import sklearn\n#from sklearn.cluster import KMeans\n#kmeans=KMeans(n_clusters=5)\n#kmeans.fit(master_data)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#labels = kmeans.predict(master_data)\n#print(labels)\n#centroids = kmeans.cluster_centers_\n#print(centroids)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from kmodes.kmodes import KModes\n#Cleaning data as required\nsuicides_data=master_data\nsuicides_data = suicides_data.drop(suicides_data[suicides_data.Total == 0].index)\n\nsuicides_data=suicides_data.drop(['Type'], axis=1)\nsuicides_data=suicides_data.drop(['Type_code'], axis=1)\n\nsuicides_data.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Selecting values with Age Group as 0-100+ only\nsuicides_data_selected_by_age=suicides_data.loc[suicides_data['Age_group']==\"0-100+\"]\n\nsuicides_data_selected_by_age = suicides_data_selected_by_age.drop(suicides_data_selected_by_age[suicides_data_selected_by_age.State.isin(\n                                                                                                            ['Total (Uts)', \n                                                                                                             'Total (States)',\n                                                                                                             'Total (All India)'])].index)\nsuicides_data_selected_by_age.head(20)\nsuicide_list = suicides_data_selected_by_age.values.tolist()\nsuicide_list = sorted(suicide_list, key=lambda x: x[0])\nsuicide_list = sorted(suicide_list, key=lambda x: x[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#State VS Gender Data\ncount = 0\nfinal_list = list()\ntotal_sum = 0 \nfor i in range(len(suicide_list)):\n    if i!=0:\n        if suicide_list[i-1][0] == suicide_list[i][0] and suicide_list[i-1][2] == suicide_list[i][2] and i != len(suicide_list)-1:\n            total_sum+=suicide_list[i][4] \n        elif suicide_list[i-1][0] == suicide_list[i][0] and suicide_list[i-1][2] == suicide_list[i][2] and i == len(suicide_list)-1:\n            total_sum+=suicide_list[i][4]\n            final_list.append([suicide_list[i][0], suicide_list[i][2], total_sum])    \n        else:\n            final_list.append([suicide_list[i-1][0], suicide_list[i-1][2], total_sum])\n            total_sum = 0\n    \n    else:\n        total_sum+=suicide_list[i][4]          \nfinal_list = sorted(final_list, key=lambda x: x[0])\n#pp.pprint(final_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#calculating percentage and finding top 10 states vs genders based on percentage suicide\ntotal_sum=master_data[master_data['State'] == 'Total (All India)'].Total.sum()\nprint(\"Total Number of Suicides:\", total_sum)\nfinal_list1 = list()\nfor row in final_list:\n    if row[-1]!=((row[2]/total_sum)*100):\n        row.append((row[2]/total_sum)*100)\n    final_list1.append(row)\nprint(\"Top Regions w.r.t. Gender for Suicide Numbers\")    \ntop_ten = sorted(final_list1, key = lambda x:x[3], reverse=True)[:11]\npp.pprint(top_ten)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###Since we have identified top states --> we are planning to drill down more to find out what are the core causes of this state and how \n### can we go about it.\nStates=['Maharashtra','Andhra Pradesh','Tamil Nadu','West Bengal','Karnataka','Kerala','Madhya Pradesh']\nsuicide_by_state = master_data\nsuicide_by_state = suicide_by_state.drop(suicide_by_state[suicide_by_state.Total == 0].index)\n#print(suicide_by_state['State'])\nsuicide_by_state = suicide_by_state[suicide_by_state['State'].isin(States)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#States vs Causes\n\nsuicide_by_state_causes = suicide_by_state[suicide_by_state['Type_code']==\"Causes\"]\nsuicide_by_state_causes = suicide_by_state_causes.drop(['Type_code', 'Age_group'], axis=1)\nsuicide_by_state_causes.head(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating 2 different data frames 1. on the basis of year\n#2.On the basis of Type\n\nsuicide_list = suicide_by_state_causes.values.tolist()\nsuicide_list = sorted(suicide_list, key=lambda x: x[0])\nsuicide_list = sorted(suicide_list, key=lambda x: x[2])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count = 0\nfinal_list = list()\ntotal_sum = 0 \nfor i in range(len(suicide_list)):\n    if i!=0:\n        if suicide_list[i-1][0] == suicide_list[i][0] and suicide_list[i-1][2] == suicide_list[i][2] and i != len(suicide_list)-1:\n            total_sum+=suicide_list[i][4] \n        elif suicide_list[i-1][0] == suicide_list[i][0] and suicide_list[i-1][2] == suicide_list[i][2] and i == len(suicide_list)-1:\n            total_sum+=suicide_list[i][4]\n            final_list.append([suicide_list[i][0], suicide_list[i][2], total_sum])    \n        else:\n            final_list.append([suicide_list[i-1][0], suicide_list[i-1][2], total_sum])\n            total_sum = 0\n    \n    else:\n        total_sum+=suicide_list[i][4]  \n        \n        \nfinal_list = sorted(final_list, key=lambda x: x[0])\npp.pprint(final_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calculating Totals, state wise\ndef calculate_total_suicide_per_state(my_list, state):\n    total_sum = 0\n    for i in range(len(my_list)):\n        if my_list[i][0] == state:\n            total_sum+=my_list[i][2]\n    return total_sum\n\npop_dict = dict()\n\nfor state in States:\n    value = calculate_total_suicide_per_state(final_list, state)\n    pop_dict[state] = value\nprint(pop_dict)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_list1 = list()\nfor row in final_list:\n    total_sum = pop_dict[row[0]]\n    if row[-1]!=((row[2]/total_sum)*100):\n        row.append((row[2]/total_sum)*100)\n    final_list1.append(row)\nprint(\"Top Causes w.r.t. Selected Regions for Suicide Numbers\")    \npp.pprint(final_list1)\nfrom pandas import DataFrame\nstate_cause_df=DataFrame.from_records(final_list1)\n#state_cause_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reason_by_state = sorted(final_list1, key = lambda x:x[0])\nstate_wise_dict = dict()\n\nfor state in States:\n    state_wise_dict[state] = list()\n    for row in final_list1:\n        if row[0] == state:\n            state_wise_dict[state].append(row)\n\npp.pprint(state_wise_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Top 3 Reasons per State\n\ndef top_three_reasons(my_list):\n    top_three = sorted(my_list, key = lambda x:x[3], reverse=True)[:3]\n    return top_three\n\nfor state in States:\n    pp.pprint(top_three_reasons(state_wise_dict[state]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#State vs Gender Unsupervised Learning\nkm = KModes(n_clusters=7, init='Huang', n_init=5, verbose=1)\n#\nclusters = km.fit_predict(suicides_data)\n\n#Print the cluster centroids\nprint(km.cluster_centroids_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#State vs Gender Unsupervised Learning\nkm1 = KModes(n_clusters=10, init='Huang', n_init=10, verbose=1)\n#\n\nclusters = km1.fit_predict(suicide_by_state_causes)\n\n#Print the cluster centroids\nprint(km1.cluster_centroids_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#State vs Gender Unsupervised Learning\nkm1 = KModes(n_clusters=10, init='Huang', n_init=10, verbose=1)\n#\n\nclusters = km1.fit_predict(state_cause_df)\n\n#Print the cluster centroids\nprint(km1.cluster_centroids_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_sum=master_data[master_data['State'] == 'Total (All India)'].Total.sum()\nprint(total_sum)\nmaster_data['Chance %']=(master_data.Total/total_sum)*100\nmaster_data.describe()\n\n\n#total_data.head()\n#list(master_data.groupby(['State'],as_index=False))\n#suicides_data = suicides_data.drop(suicides_data[suicides_data.Total == 0].index)\n\n#master_data['Chance']=master_data.Total/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Top 3 reasons for Selected States\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.decomposition import FactorAnalysis\n##X, _ = load_digits(return_X_y=True)\n#transformer = FactorAnalysis(n_components=7, random_state=0)\n#X_transformed = transformer.fit_transform(master_data[['Total','Chance %']])\n#X_transformed.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n# Label ncoder\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nclassifier = Sequential()\n\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = 8))\n# Adding the second hidden layer\nclassifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu'))\n# Adding the output layer\nclassifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n\n# Compiling Neural Network\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\ny_train=master_data['Total']\nx_train=master_data.drop(['Total'],axis=1)\n#df.drop(['B', 'C'], axis=1)\nclassifier.fit(x_train, y_train, batch_size = 10, epochs = 100)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}