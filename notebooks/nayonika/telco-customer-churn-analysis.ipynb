{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Some of the code in this notebook was inspired by notebooks from fellow Kaggle users- Gabriel Atkin and Audrey Guillot\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, learning_curve\nfrom sklearn.metrics import f1_score, recall_score, confusion_matrix, classification_report, precision_recall_curve\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier \nfrom sklearn.ensemble import AdaBoostClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.svm import SVC\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-20T19:55:15.00058Z","iopub.execute_input":"2021-05-20T19:55:15.001041Z","iopub.status.idle":"2021-05-20T19:55:16.652809Z","shell.execute_reply.started":"2021-05-20T19:55:15.000964Z","shell.execute_reply":"2021-05-20T19:55:16.651083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import the data\ntelco_data = pd.read_csv('../input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n\n#Let's begin by looking at the data\ntelco_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-20T19:55:16.654418Z","iopub.execute_input":"2021-05-20T19:55:16.654726Z","iopub.status.idle":"2021-05-20T19:55:16.737011Z","shell.execute_reply.started":"2021-05-20T19:55:16.654702Z","shell.execute_reply":"2021-05-20T19:55:16.736513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Now let's look at the all the columns we have and their data types \ntelco_data.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-20T19:55:16.737815Z","iopub.execute_input":"2021-05-20T19:55:16.738088Z","iopub.status.idle":"2021-05-20T19:55:16.756327Z","shell.execute_reply.started":"2021-05-20T19:55:16.738066Z","shell.execute_reply":"2021-05-20T19:55:16.755773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"CustomerID isn't a field that could really predict the churn so we can get rid of it. We also notice that the TotalCharges column is of Object type, let's convert it into float since it's numeric similar to MonthlyCharges.","metadata":{}},{"cell_type":"code","source":"#Let do some data preprocessing\ntelco_data = telco_data.drop('customerID', axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T19:55:16.757186Z","iopub.execute_input":"2021-05-20T19:55:16.757506Z","iopub.status.idle":"2021-05-20T19:55:16.764356Z","shell.execute_reply.started":"2021-05-20T19:55:16.757484Z","shell.execute_reply":"2021-05-20T19:55:16.763454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"When we try to convert the TotalCharges field we noticed that there were some blanks, so we need to handle it and then convert it into float. To fill in these blanks let's use the Mean value.","metadata":{}},{"cell_type":"code","source":"telco_data['TotalCharges']= telco_data['TotalCharges'].replace(' ',np.NaN)\ntelco_data['TotalCharges']= telco_data['TotalCharges'].astype(np.float)\ntelco_data['TotalCharges']= telco_data['TotalCharges'].fillna(telco_data['TotalCharges'].mean())","metadata":{"execution":{"iopub.status.busy":"2021-05-20T19:55:16.766584Z","iopub.execute_input":"2021-05-20T19:55:16.76688Z","iopub.status.idle":"2021-05-20T19:55:16.781973Z","shell.execute_reply.started":"2021-05-20T19:55:16.766857Z","shell.execute_reply":"2021-05-20T19:55:16.781339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looking at the data above we noticed that most of the columns could be converted into categories, let's see what are the different categories we have for each of the columns.","metadata":{}},{"cell_type":"code","source":"def get_uniques(df, columns):\n    return {column: list(df[column].unique()) for column in columns}\n\ndef get_categorical_columns(df):\n    return [column for column in df.columns if df.dtypes[column] == 'object']\n\nget_uniques(telco_data, get_categorical_columns(telco_data))","metadata":{"execution":{"iopub.status.busy":"2021-05-20T19:55:16.783473Z","iopub.execute_input":"2021-05-20T19:55:16.783846Z","iopub.status.idle":"2021-05-20T19:55:16.808143Z","shell.execute_reply.started":"2021-05-20T19:55:16.783822Z","shell.execute_reply":"2021-05-20T19:55:16.80758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Most of the columns are binary with a simple Yes or No option or even 'Gender' which has just Male or Female. We also see columns like 'MultipleLines', 'OnlineSecurity' and so on which could be converted into Yes and No. Let's converge them so that we get a cleaner dataset and better analysis.","metadata":{}},{"cell_type":"code","source":"telco_data['MultipleLines'] = telco_data['MultipleLines'].replace('No phone service', 'No')\n\ntelco_data[['OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n      'TechSupport', 'StreamingTV', 'StreamingMovies']] = telco_data[['OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n                                                                'TechSupport', 'StreamingTV', 'StreamingMovies']].replace('No internet service', 'No')","metadata":{"execution":{"iopub.status.busy":"2021-05-20T19:55:16.809324Z","iopub.execute_input":"2021-05-20T19:55:16.809726Z","iopub.status.idle":"2021-05-20T19:55:16.82228Z","shell.execute_reply.started":"2021-05-20T19:55:16.809692Z","shell.execute_reply":"2021-05-20T19:55:16.821172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_uniques(telco_data, get_categorical_columns(telco_data))","metadata":{"execution":{"iopub.status.busy":"2021-05-20T19:55:16.823451Z","iopub.execute_input":"2021-05-20T19:55:16.823744Z","iopub.status.idle":"2021-05-20T19:55:16.854345Z","shell.execute_reply.started":"2021-05-20T19:55:16.823713Z","shell.execute_reply":"2021-05-20T19:55:16.853626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our columns look in a much better shape now. Next we have columns like 'InternetService' and 'Contract' which could be converted to ordinal features since the data can be seen as continuous.","metadata":{}},{"cell_type":"code","source":"internet_order = ['No', 'DSL', 'Fiber optic']\ncontract_order = ['Month-to-month', 'One year', 'Two year']","metadata":{"execution":{"iopub.status.busy":"2021-05-20T19:55:16.855158Z","iopub.execute_input":"2021-05-20T19:55:16.855558Z","iopub.status.idle":"2021-05-20T19:55:16.861941Z","shell.execute_reply.started":"2021-05-20T19:55:16.855534Z","shell.execute_reply":"2021-05-20T19:55:16.860878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To summarize, we have all the columns grouped into these categories and this will help us in feature engineering:\n* binary_features: Gender, Partner, Dependents, PhoneService, MultipleLines, OnlineSecurity, OnlineBackup, DeviceProtection, TechSupport, StreamingTV, StreamingMovies, PaperlessBilling\n* ordinal_features: InternetService, Contract\n* nominal_features: PaymentMethod","metadata":{}},{"cell_type":"code","source":"def binary_encode(df, column, positive_value):\n    df = df.copy()\n    df[column] = df[column].apply(lambda x: 1 if x == positive_value else 0)\n    return df\n\ndef ordinal_encode(df, column, ordering):\n    df = df.copy()\n    df[column] = df[column].apply(lambda x: ordering.index(x))\n    return df\n    \ndef onehot_encode(df, column):\n    df = df.copy()\n    dummies = pd.get_dummies(df[column])\n    df = pd.concat([df, dummies], axis=1)\n    df = df.drop(column, axis=1)\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-05-20T19:55:16.862957Z","iopub.execute_input":"2021-05-20T19:55:16.863156Z","iopub.status.idle":"2021-05-20T19:55:16.879735Z","shell.execute_reply.started":"2021-05-20T19:55:16.863137Z","shell.execute_reply":"2021-05-20T19:55:16.878718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"telco_data = binary_encode(telco_data, 'gender', 'Male')\n\nbinary_features = ['Partner', 'Dependents', 'PhoneService', 'MultipleLines',\n                'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n                'StreamingTV', 'StreamingMovies', 'PaperlessBilling']\n\nfor feature in binary_features:\n    telco_data = binary_encode(telco_data, feature, 'Yes')\n\n\ntelco_data = ordinal_encode(telco_data, 'InternetService', internet_order)\ntelco_data = ordinal_encode(telco_data, 'Contract', contract_order)\n\n\ntelco_data = onehot_encode(telco_data, 'PaymentMethod')\n\ntelco_data = binary_encode(telco_data, 'Churn', 'Yes')","metadata":{"execution":{"iopub.status.busy":"2021-05-20T19:55:16.880759Z","iopub.execute_input":"2021-05-20T19:55:16.881061Z","iopub.status.idle":"2021-05-20T19:55:16.958628Z","shell.execute_reply.started":"2021-05-20T19:55:16.881037Z","shell.execute_reply":"2021-05-20T19:55:16.957662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"telco_data","metadata":{"execution":{"iopub.status.busy":"2021-05-20T19:55:16.960143Z","iopub.execute_input":"2021-05-20T19:55:16.960453Z","iopub.status.idle":"2021-05-20T19:55:16.991913Z","shell.execute_reply.started":"2021-05-20T19:55:16.960427Z","shell.execute_reply":"2021-05-20T19:55:16.990582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we see that all the columnar data is converted to numbers, binaries are converted to 1s and 0s and ordinals/nominals are converted to a series of 0, 1, 2s. ","metadata":{}},{"cell_type":"markdown","source":"**Machine Learning Algorithms**\n\nWe will use these models for this dataset and compare which model predicts accurately\n\n* Logistic Regression\n* Random Forest\n* AdaBoost\n* XGBoost\n* Support Vector Machines","metadata":{}},{"cell_type":"code","source":"#Let's begin with splitting the model into Test and Train datasets\n\ny = telco_data['Churn']\nX = telco_data.drop('Churn', axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T19:55:16.994397Z","iopub.execute_input":"2021-05-20T19:55:16.994697Z","iopub.status.idle":"2021-05-20T19:55:17.003837Z","shell.execute_reply.started":"2021-05-20T19:55:16.994669Z","shell.execute_reply":"2021-05-20T19:55:17.002314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Using scaler function we can normalize our dataset to improve the performance of our algorithms\n\nscaler = StandardScaler()\n\nX = scaler.fit_transform(X)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T19:55:17.005149Z","iopub.execute_input":"2021-05-20T19:55:17.005408Z","iopub.status.idle":"2021-05-20T19:55:17.025863Z","shell.execute_reply.started":"2021-05-20T19:55:17.005385Z","shell.execute_reply":"2021-05-20T19:55:17.025086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T19:55:17.026943Z","iopub.execute_input":"2021-05-20T19:55:17.027236Z","iopub.status.idle":"2021-05-20T19:55:17.040821Z","shell.execute_reply.started":"2021-05-20T19:55:17.027203Z","shell.execute_reply":"2021-05-20T19:55:17.039572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Logistic Regression\n\nclf_log = LogisticRegression(random_state=0)\nclf_log.fit(X_train, y_train)\ny_pred  = clf_log.predict(X_test)\n\n#Print the accuracy of our model\nprint(\"Score:\", clf_log.score(X_test, y_test))\ny_pred = clf_log.predict(X_test)\nprint(classification_report(y_test, y_pred))\nN, train_score, val_score = learning_curve(clf_log, X_train, y_train, cv=4, scoring='f1', train_sizes=np.linspace(0.1,1,10))\n\n#Plot the training and validation score for the model\nplt.figure(figsize=(12,8))\nplt.title('Logistic Regression')\nplt.plot(N,train_score.mean(axis=1), label='training score')\nplt.plot(N,val_score.mean(axis=1), label='validation score')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-20T19:55:17.04215Z","iopub.execute_input":"2021-05-20T19:55:17.042458Z","iopub.status.idle":"2021-05-20T19:55:17.982313Z","shell.execute_reply.started":"2021-05-20T19:55:17.042434Z","shell.execute_reply":"2021-05-20T19:55:17.980971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Random Forest \n\nclf_rf = RandomForestClassifier(random_state=0)\nclf_rf.fit(X_train, y_train)\ny_pred  = clf_rf.predict(X_test)\n\n#Print the accuracy of our model\n\nprint(\"Score:\", clf_rf.score(X_test, y_test))\ny_pred = clf_rf.predict(X_test)\nprint(classification_report(y_test, y_pred))\nN, train_score, val_score = learning_curve(clf_rf, X_train, y_train, cv=4, scoring='f1',train_sizes=np.linspace(0.1,1,10))\n\n#Plot the training and validation score for the model\nplt.figure(figsize=(12,8))\nplt.title('Random Forest')\nplt.plot(N,train_score.mean(axis=1), label='training score')\nplt.plot(N,val_score.mean(axis=1), label='validation score')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-20T19:55:17.983676Z","iopub.execute_input":"2021-05-20T19:55:17.983976Z","iopub.status.idle":"2021-05-20T19:55:32.190057Z","shell.execute_reply.started":"2021-05-20T19:55:17.983946Z","shell.execute_reply":"2021-05-20T19:55:32.188559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#AdaBoost\n\nclf_ab = AdaBoostClassifier(random_state=0)\nclf_ab.fit(X_train, y_train)\ny_pred  = clf_ab.predict(X_test)\n\n#Print the accuracy of our model\n\nprint(\"Score:\", clf_ab.score(X_test, y_test))\ny_pred = clf_ab.predict(X_test)\nprint(classification_report(y_test, y_pred))\nN, train_score, val_score = learning_curve(clf_ab, X_train, y_train, cv=4, scoring='f1',train_sizes=np.linspace(0.1,1,10))\n\n#Plot the training and validation score for the model\nplt.figure(figsize=(12,8))\nplt.title('AdaBoost')\nplt.plot(N,train_score.mean(axis=1), label='training score')\nplt.plot(N,val_score.mean(axis=1), label='validation score')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-20T19:55:32.191178Z","iopub.execute_input":"2021-05-20T19:55:32.191495Z","iopub.status.idle":"2021-05-20T19:55:42.195678Z","shell.execute_reply.started":"2021-05-20T19:55:32.191468Z","shell.execute_reply":"2021-05-20T19:55:42.194104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#XGBoost\n\nclf_xg = XGBClassifier(random_state=0)\nclf_xg.fit(X_train, y_train)\ny_pred  = clf_xg.predict(X_test)\n\n#Print the accuracy of our model\n\nprint(\"Score:\", clf_xg.score(X_test, y_test))\ny_pred = clf_xg.predict(X_test)\nprint(classification_report(y_test, y_pred))\nN, train_score, val_score = learning_curve(clf_xg, X_train, y_train, cv=4, scoring='f1',train_sizes=np.linspace(0.1,1,10))\n\n#Plot the training and validation score for the model\nplt.figure(figsize=(12,8))\nplt.title('XGBoost')\nplt.plot(N,train_score.mean(axis=1), label='training score')\nplt.plot(N,val_score.mean(axis=1), label='validation score')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-20T19:55:42.197024Z","iopub.execute_input":"2021-05-20T19:55:42.197327Z","iopub.status.idle":"2021-05-20T19:55:50.458699Z","shell.execute_reply.started":"2021-05-20T19:55:42.197298Z","shell.execute_reply":"2021-05-20T19:55:50.457842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Support Vector Machine SVM\n\nclf_svc = SVC(random_state=0)\nclf_svc.fit(X_train, y_train)\ny_pred  = clf_svc.predict(X_test)\n\n#Print the accuracy % of our model\n\nprint(\"Scores:\", clf_svc.score(X_test, y_test))\ny_pred = clf_svc.predict(X_test)\nprint(classification_report(y_test, y_pred))\nN, train_score, val_score = learning_curve(clf_svc, X_train, y_train, cv=4, scoring='f1',train_sizes=np.linspace(0.1,1,10))\n\n#Plot the training and validation score for the model\nplt.figure(figsize=(12,8))\nplt.title('SVM')\nplt.plot(N,train_score.mean(axis=1), label='training score')\nplt.plot(N,val_score.mean(axis=1), label='validation score')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-20T19:55:50.459695Z","iopub.execute_input":"2021-05-20T19:55:50.459908Z","iopub.status.idle":"2021-05-20T19:56:09.557049Z","shell.execute_reply.started":"2021-05-20T19:55:50.459885Z","shell.execute_reply":"2021-05-20T19:56:09.555526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looking at all the models, we notice that Random Forest is not a good fit for this data. The other models such as Logistic Regression, AdaBoost and SVM are performing the best. Let's dive further into the Logistic Regression model and perform Hyperparameter tuning to see if we can improve the score.","metadata":{}},{"cell_type":"code","source":"#Create a parameter grid\nparam_grid = {'penalty' : ['l1', 'l2'],\n              'C' : np.logspace(-4, 4, 20),'solver' : ['liblinear']}\nlr = LogisticRegression()\ngrid_log = GridSearchCV(param_grid = param_grid, cv = 6, verbose=True, n_jobs=-1, estimator=lr)\n\ngrid_log.fit(X_train, y_train)\n\n#Printing the best score and the best parameters for the model\nprint(\"Best Score:\", grid_log.best_score_)\nprint('Best Params: ', grid_log.best_params_) \n","metadata":{"execution":{"iopub.status.busy":"2021-05-20T19:56:09.558324Z","iopub.execute_input":"2021-05-20T19:56:09.558596Z","iopub.status.idle":"2021-05-20T19:56:22.277925Z","shell.execute_reply.started":"2021-05-20T19:56:09.558569Z","shell.execute_reply":"2021-05-20T19:56:22.276979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's look at the final classification report for our model\ny_pred = grid_log.predict(X_test)\nprint(\"Score:\", grid_log.score(X_test, y_test))\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-05-20T19:56:22.27921Z","iopub.execute_input":"2021-05-20T19:56:22.279521Z","iopub.status.idle":"2021-05-20T19:56:22.294596Z","shell.execute_reply.started":"2021-05-20T19:56:22.279493Z","shell.execute_reply":"2021-05-20T19:56:22.294062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We noticed that with the Hyperparameter tuning we were able to achieve a slightly better accuracy.","metadata":{}}]}