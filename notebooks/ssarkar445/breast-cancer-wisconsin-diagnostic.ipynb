{"cells":[{"metadata":{"trusted":false},"cell_type":"code","source":"# Importing the required packages\nimport warnings\nwarnings.filterwarnings('ignore')\nimport sys\nimport os\nimport time\n\nimport numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Importing the CSV file\nb_cancer = pd.read_csv('../input/data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Checking the number of rows and columns\nb_cancer.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Checking the table information\nb_cancer.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Checking the values for different quantiles\nb_cancer.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Checking the column present\nb_cancer.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Checking the random data\nb_cancer.head()\nb_cancer.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Dropping the upwanted columns\n#loans_df.dropna(axis=1,how='all')\nb_cancer = b_cancer.drop(['id','Unnamed: 32'],axis = 1)\n#b_cancer.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# def remove_outliers(df):\n#     df_new = []\n#     for i in df.columns:\n#         Q1 = pd.DataFrame(df[i]).quantile(0.25)\n#         Q3 = pd.DataFrame(df[i]).quantile(0.75)\n#         IQR = Q3 - Q1\n#         df_new = pd.DataFrame(df[(pd.DataFrame(df[i]) >= Q1 - 1.5*IQR) & (pd.DataFrame(df[i]) <= Q3 + 1.5*IQR)])\n#     return pd.DataFrame(df_new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Checking for the outliers for the metric columns\nb_cancer[['radius_mean','texture_mean', 'perimeter_mean', 'area_mean','smoothness_mean','compactness_mean','concavity_mean','concave points_mean','symmetry_mean']].describe([0.25,0.50,0.75,0.99])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Removing outliers\nplt.figure(figsize=(20,5))\nplt.subplot(1,5,1)\nsns.boxplot(y = b_cancer.area_mean)\n\nplt.subplot(1,5,2)\nsns.boxplot(y = b_cancer.compactness_mean)\n\nplt.subplot(1,5,3)\nsns.boxplot(y = b_cancer.concavity_mean)\n\nplt.subplot(1,5,4)\nsns.boxplot(y = b_cancer.symmetry_mean)\n\nplt.subplot(1,5,5)\nsns.boxplot(y = b_cancer['concave points_mean'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Removing Outliers\nQ1 = b_cancer.area_mean.quantile(0.25)\nQ3 = b_cancer.area_mean.quantile(0.75)\nIQR = Q3 - Q1\nb_cancer = b_cancer[(b_cancer.area_mean >= Q1 - 1.5*IQR) & (b_cancer.area_mean <= Q3 + 1.5*IQR)]\n\n\nQ1 = b_cancer.compactness_mean.quantile(0.25)\nQ3 = b_cancer.compactness_mean.quantile(0.75)\nIQR = Q3 - Q1\nb_cancer = b_cancer[(b_cancer.compactness_mean >= Q1 - 1.5*IQR) & (b_cancer.compactness_mean <= Q3 + 1.5*IQR)]\n\n\nQ1 = b_cancer.concavity_mean.quantile(0.25)\nQ3 = b_cancer.concavity_mean.quantile(0.75)\nIQR = Q3 - Q1\nb_cancer = b_cancer[(b_cancer.concavity_mean >= Q1 - 1.5*IQR) & (b_cancer.concavity_mean <= Q3 + 1.5*IQR)]\n\nQ1 = b_cancer.symmetry_mean.quantile(0.25)\nQ3 = b_cancer.symmetry_mean.quantile(0.75)\nIQR = Q3 - Q1\nb_cancer = b_cancer[(b_cancer.symmetry_mean >= Q1 - 1.5*IQR) & (b_cancer.symmetry_mean <= Q3 + 1.5*IQR)]\n\n\nQ1 = b_cancer['concave points_mean'].quantile(0.25)\nQ3 = b_cancer['concave points_mean'].quantile(0.75)\nIQR = Q3 - Q1\nb_cancer = b_cancer[(b_cancer['concave points_mean'] >= Q1 - 1.5*IQR) & (b_cancer['concave points_mean'] <= Q3 + 1.5*IQR)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"b_cancer.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"b_cancer[['fractal_dimension_mean','radius_se','texture_se','perimeter_se','area_se','smoothness_se','compactness_se','concavity_se','concave points_se','symmetry_se']].describe([0.25,0.50,0.75,0.99])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Removing  outliers\nplt.figure(figsize=(20,5))\nplt.subplot(1,4,1)\nsns.boxplot(y = b_cancer.texture_se)\n\nplt.subplot(1,4,2)\nsns.boxplot(y = b_cancer.area_se)\n\nplt.subplot(1,4,3)\nsns.boxplot(y = b_cancer.compactness_se)\n\nplt.subplot(1,4,4)\nsns.boxplot(y = b_cancer.concavity_se)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Removing Outliers\nQ1 = b_cancer.texture_se.quantile(0.25)\nQ3 = b_cancer.texture_se.quantile(0.75)\nIQR = Q3 - Q1\nb_cancer = b_cancer[(b_cancer.texture_se >= Q1 - 1.5*IQR) & (b_cancer.texture_se <= Q3 + 1.5*IQR)]\n\n\nQ1 = b_cancer.area_se.quantile(0.25)\nQ3 = b_cancer.area_se.quantile(0.75)\nIQR = Q3 - Q1\nb_cancer = b_cancer[(b_cancer.area_se >= Q1 - 1.5*IQR) & (b_cancer.area_se <= Q3 + 1.5*IQR)]\n\n\nQ1 = b_cancer.compactness_se.quantile(0.25)\nQ3 = b_cancer.compactness_se.quantile(0.75)\nIQR = Q3 - Q1\nb_cancer = b_cancer[(b_cancer.compactness_se >= Q1 - 1.5*IQR) & (b_cancer.compactness_se <= Q3 + 1.5*IQR)]\n\nQ1 = b_cancer.concavity_se.quantile(0.25)\nQ3 = b_cancer.concavity_se.quantile(0.75)\nIQR = Q3 - Q1\nb_cancer = b_cancer[(b_cancer.concavity_se >= Q1 - 1.5*IQR) & (b_cancer.concavity_se <= Q3 + 1.5*IQR)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Checking the numbers of rows after removing outliers\nb_cancer.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Describing again to check the effect after outliers removal\nb_cancer[['fractal_dimension_se','radius_worst','texture_worst','perimeter_worst','area_worst','smoothness_worst','compactness_worst','concavity_worst','concave points_worst']].describe([0.25,0.50,0.75,0.99])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.boxplot(y = b_cancer.compactness_worst)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"Q1 = b_cancer.compactness_worst.quantile(0.25)\nQ3 = b_cancer.compactness_worst.quantile(0.75)\nIQR = Q3 - Q1\n\nb_cancer = b_cancer[(b_cancer.compactness_worst >= Q1 - 1.5*IQR) & (b_cancer.compactness_worst<=Q3 + 1.5*IQR)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"b_cancer.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"b_cancer[['symmetry_worst', 'fractal_dimension_worst']].describe([0.99])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_cancer = b_cancer","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Replacing the dependent variable with binary value for prediction\ndf_cancer.diagnosis = df_cancer.diagnosis.map({'M':1,'B':0})","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Checking for the outliers using pair plot\nplt.figure(figsize = (10,10))\nsns.pairplot(df_cancer.corr())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Checking the correlation using heatmap\nplt.figure(figsize=(20,20))\nsns.heatmap(df_cancer.corr(),annot = True,cmap='winter')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.scatter(x = 'radius_worst',y = 'diagnosis',data = df_cancer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Spliting the dependent and independent variable\ny = df_cancer.pop('diagnosis')\nX = df_cancer","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Spliting the dataset for training and testing purpose\nX_train,X_test,y_train,y_test = train_test_split(X,y,train_size= 0.7,test_size=0.3,random_state=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Scaling the dataset for bringing all the columns to a single scale\nX_train = pd.DataFrame(scaler.fit_transform(pd.DataFrame(X_train)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train.columns = ['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean',\n       'smoothness_mean', 'compactness_mean', 'concavity_mean',\n       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n       'perimeter_worst', 'area_worst', 'smoothness_worst',\n       'compactness_worst', 'concavity_worst', 'concave points_worst',\n       'symmetry_worst', 'fractal_dimension_worst']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Describe the dataset after standerdScaling the mean should near to 0 and the SD should be 1\nX_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Using the automated technique for feature selection\nrfe = RFE(logreg,15)\nrfe = rfe.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"list(zip(X_train.columns,rfe.support_,rfe.ranking_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cols = X_train.columns[rfe.support_]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import statsmodels.api as sm","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Model 1\nX_train_new1 = sm.add_constant(X_train[cols])\nlm1 = sm.GLM(list(y_train),X_train_new1,family = sm.families.Binomial()).fit()\nprint(lm1.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Model 2\nX_train_new2 = X_train_new1.drop('concave points_mean',axis='columns')\nX_train_new2 = sm.add_constant(X_train_new2)\nlm2 = sm.GLM(list(y_train),X_train_new2,family = sm.families.Binomial()).fit()\nlm2.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Model 3\nX_train_new3 = X_train_new2.drop('area_worst',axis='columns')\nX_train_new3 = sm.add_constant(X_train_new3)\nlm3 = sm.GLM(list(y_train),X_train_new3,family=sm.families.Binomial()).fit()\nlm3.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Model 4\nX_train_new4 = X_train_new3.drop('smoothness_worst',axis='columns')\nX_train_new4 = sm.add_constant(X_train_new4)\nlm4 = sm.GLM(list(y_train),X_train_new4,family=sm.families.Binomial()).fit()\nlm4.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Model 5\nX_train_new5 = X_train_new4.drop('area_se',axis='columns')\nX_train_new5 = sm.add_constant(X_train_new5)\nlm5 = sm.GLM(list(y_train),X_train_new5,family=sm.families.Binomial()).fit()\nlm5.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Model 6\nX_train_new6 = X_train_new5.drop('concavity_worst',axis='columns')\nX_train_new6 = sm.add_constant(X_train_new6)\nlm6 = sm.GLM(list(y_train),X_train_new6,family=sm.families.Binomial()).fit()\nlm6.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Model 7\nX_train_new7 = X_train_new6.drop('compactness_mean',axis='columns')\nX_train_new7 = sm.add_constant(X_train_new7)\nlm7 = sm.GLM(list(y_train),X_train_new7,family=sm.families.Binomial()).fit()\nlm7.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Model 8\nX_train_new8 = X_train_new7.drop('perimeter_worst',axis='columns')\nX_train_new8 = sm.add_constant(X_train_new8)\nlm8 = sm.GLM(list(y_train),X_train_new8,family=sm.families.Binomial()).fit()\nlm8.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Creating fucntion to check the multicolenearity between the independent variables\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\ndef calculate_vif(df):\n    vif = pd.DataFrame()\n    vif['Feature'] = df.columns\n    vif['VIF'] = [variance_inflation_factor(df.values,i) for i in range(df.shape[1])]\n    vif['VIF'] = round(vif['VIF'],2)\n    vif = vif.sort_values(by = 'VIF',ascending=False)\n    return vif","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"calculate_vif(X_train_new8.drop('const',axis='columns'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Model 9\nX_train_new9 = X_train_new8.drop('concavity_mean',axis='columns')\nX_train_new9 = sm.add_constant(X_train_new9)\nlm9 = sm.GLM(list(y_train),X_train_new9,family=sm.families.Binomial()).fit()\nprint(lm9.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Model 10\nX_train_new10 = X_train_new9.drop('compactness_se',axis = 'columns')\nX_train_new10 = sm.add_constant(X_train_new10)\nlm10 = sm.GLM(list(y_train),X_train_new10,family=sm.families.Binomial()).fit()\nprint(lm10.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"calculate_vif(X_train_new10.drop('const',axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Model 10 is our final model based on that we will check the different metric now\ny_train_pred = lm10.predict(X_train_new10)\nprint(y_train_pred[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_train_pred = y_train_pred.values.reshape(-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Creating data frame with actual value and predicted probability\n\ny_train_pred_final = pd.DataFrame({'cancer':y_train, 'cancer_prob':y_train_pred})\ny_train_pred_final['ID'] = y_train.index","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_train_pred_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_train_pred_final['predicted'] = y_train_pred_final.cancer_prob.map(lambda x : 1 if x>0.5 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_train_pred_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nconfusion = confusion_matrix(y_train_pred_final.cancer,y_train_pred_final.predicted)\nprint(confusion)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Predicted     not_cancer  cancer\n# Actual\n# not_cancer        208       7\n# cancer            6       56  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nprint(accuracy_score(y_train_pred_final.cancer,y_train_pred_final.predicted))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"TP = confusion[1,1]\nTN = confusion[0,0]\nFN = confusion[1,0]\nFP = confusion[0,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# sensitivity\nprint(TP/float(TP+FN))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#specificity\nprint(TN/float(TN+FP))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# False positive rate\nprint(FP/float(FP+TN))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.metrics import roc_curve,roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def draw_roc(actual,prob):\n    fpr,tpr,thresholds = roc_curve(actual,prob,drop_intermediate=True)\n    accuracy_score = roc_auc_score(actual,prob)\n    plt.figure(figsize=(5,5))\n    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)'  %accuracy_score )\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC Curve')\n    plt.show()\n    return None","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"draw_roc(y_train_pred_final.cancer,y_train_pred_final.predicted)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Checking for the more accurate cutoff value\nnumbers = [float(x/10) for x in range(10)]\n\nfor i in numbers:\n    y_train_pred_final[i] = y_train_pred_final.cancer_prob.map(lambda x : 1 if x>i else 0)\ny_train_pred_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\ncutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\nfrom sklearn.metrics import confusion_matrix\n\n# TP = confusion[1,1] # true positive \n# TN = confusion[0,0] # true negatives\n# FP = confusion[0,1] # false positives\n# FN = confusion[1,0] # false negatives\n\nnum = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\nfor i in num:\n    cm1 = confusion_matrix(y_train_pred_final.cancer, y_train_pred_final[i] )\n    total1=sum(sum(cm1))\n    accuracy = (cm1[0,0]+cm1[1,1])/total1\n    \n    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\nprint(cutoff_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Let's plot accuracy sensitivity and specificity for various probabilities.\ncutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_train_pred_final['final_predicted'] = y_train_pred_final.cancer_prob.map( lambda x: 1 if x > 0.2 else 0)\ny_train_pred_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"accuracy_score(y_train_pred_final.cancer,y_train_pred_final.final_predicted)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"confusion = confusion_matrix(y_train_pred_final.cancer,y_train_pred_final.final_predicted)\nconfusion","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"TP = confusion[1,1]\nTN = confusion[0,0]\nFN = confusion[1,0]\nFP = confusion[0,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Sensitivity\nprint(TP/float(TP + FN))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Specificity\nprint(TN/float(TN+FP))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train_new10.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Now we will make prediction on the test data\nX_test = pd.DataFrame(scaler.transform(pd.DataFrame(X_test)))\nX_test.columns = ['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean',\n       'smoothness_mean', 'compactness_mean', 'concavity_mean',\n       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n       'perimeter_worst', 'area_worst', 'smoothness_worst',\n       'compactness_worst', 'concavity_worst', 'concave points_worst',\n       'symmetry_worst', 'fractal_dimension_worst']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cols = X_train_new10.columns[X_train_new10.columns !='const']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_test = X_test[cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_test_sm = sm.add_constant(X_test)\ny_test_pred = lm10.predict(X_test_sm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_pred_1 = pd.DataFrame(y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_pred_1.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_test_df = pd.DataFrame(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Removing index for both dataframes to append them side by side \ny_pred_1.reset_index(drop=True, inplace=True)\ny_test_df.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_pred_final = pd.concat([y_test_df,y_pred_1],axis='columns')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_pred_final.columns = ['cancer','pred_prob']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_pred_final['Prediction'] = y_pred_final.pred_prob.map(lambda x : 1 if x>0.2 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_pred_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"accuracy_score(y_pred_final.cancer,y_pred_final.Prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"confusion = confusion_matrix(y_pred_final.cancer,y_pred_final.Prediction)\nconfusion","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"TP = confusion[1,1]\nTN = confusion[0,0]\nFN = confusion[1,0]\nFP = confusion[0,1]\nprint(TP,TN,FP,FN)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Sensitivity\nprint(TP/float(TP+FN))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Specificity\nprint(TN/float(TN+FP))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}