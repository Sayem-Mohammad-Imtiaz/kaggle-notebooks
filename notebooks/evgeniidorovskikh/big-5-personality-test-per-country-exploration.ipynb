{"cells":[{"metadata":{},"cell_type":"markdown","source":"    **Big 5 Personality Test per Country Exploration **\nThe goal of this notebook was to find prevalent pesonality traits for different countries.\n\nI used some code from \"Big Five Personality Traits\" notebook by Petar Luketina. (used it to change country names and to map question as \"positive/negative\")"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sb\nimport pycountry","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"path = r'../input/big-five-personality-test/IPIP-FFM-data-8Nov2018/data-final.csv'\ndf_full = pd.read_csv(path, sep='\\t')\ndf_full.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I'm deleting rows with data where IP of respondent repeted several times (potential repeat of the test) and I filtered those who were answering too fast and too slow."},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf = df_full.loc[~(df_full[df_full.columns[:-1]] == 0).any(axis=1)] #removing nulls\ndf1 = df[(df['IPC'] == 1)] #cleaning repeaters (same IP)\ndf1 = df1[((df1['testelapse'] >= 150) & (df1['testelapse'] <= 2000))] # time filter\ndf1 = df1.drop(columns = ['screenw','screenh','lat_appx_lots_of_err','long_appx_lots_of_err']) # I'm not using that data\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To \"calculate\" the traits of a person we needed to divide answers into positive and negative (for the trait)."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Petar Luketina code\n#Changing country names for more readability\ncountry_dict = {i.alpha_2: i.alpha_3 for i in pycountry.countries}\ndf1['country'] = df1.country.map(country_dict)\n\n# Dividing questions into positive and negative and then replace answers accordingly\npos_questions = [ # positive questions adding to the trait.\n    'EXT1','EXT3','EXT5','EXT7','EXT9',                       # 5 Extroversion\n    'EST1','EST3','EST5','EST6','EST7','EST8','EST9','EST10', # 8 Neuroticism\n    'AGR2','AGR4','AGR6','AGR8','AGR9','AGR10',               # 6 Agreeableness\n    'CSN1','CSN3','CSN5','CSN7','CSN9','CSN10',               # 6 Conscientiousness\n    'OPN1','OPN3','OPN5','OPN7','OPN8','OPN9','OPN10',        # 7 Openness\n]\nneg_questions = [ # negative (negating) questions subtracting from the trait.\n    'EXT2','EXT4','EXT6','EXT8','EXT10', # 5 Extroversion\n    'EST2','EST4',                       # 2 Neuroticism\n    'AGR1','AGR3','AGR5','AGR7',         # 4 Agreeableness\n    'CSN2','CSN4','CSN6','CSN8',         # 4 Conscientiousness\n    'OPN2','OPN4','OPN6',                # 3 Openness\n]\ndf2 = df1.copy()\ndf2[pos_questions] = df2[pos_questions].replace({1:-2, 2:-1, 3:0, 4:1, 5:2})\ndf2[neg_questions] = df2[neg_questions].replace({1:2, 2:1, 3:0, 4:-1, 5:-2})\ndf2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create new columns in DF which represent sum of answers in each category (trait)\ntraits = ['EXT', 'EST', 'AGR', 'CSN', 'OPN']\ntrait_labels = ['Extroversion', 'Neuroticism', 'Agreeableness', 'Conscientiousness', 'Openness']\nfor trait in traits:\n    new_col = str(trait+'_s')\n    cols = [col for col in df2.columns if (trait in col) and ('_E' not in col)]\n    df2[new_col] = df2[cols].sum(axis=1)\n\n#Creating new DF which rows are top 50 countries (by number of respondents) and columns are means (of responces) for each trait.\ncount50 = list(df2['country'].value_counts().iloc[0:50].index)\ntraits_cols = list(df2.iloc[:,-5:].columns)\nmeans_traits = pd.DataFrame(columns = traits_cols)\nfor country in count50:    \n    means = {}\n    for trait in traits_cols:\n        means[trait] = (df2[df2['country'] == country])[trait].mean()\n    means_traits.loc[country] = means","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's visualise normalized traits for several countries and see which traits prevail."},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"df_norm_col=(means_traits-means_traits.mean())/means_traits.std() #Normalization\n\nfor i in range(0,40,10):\n    plt.subplots(figsize=(10,10)) \n    hmap = sb.heatmap(df_norm_col.iloc[i:i+10], cmap='viridis',annot=True)\n    hmap.set_xticklabels(trait_labels)\n    plt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}