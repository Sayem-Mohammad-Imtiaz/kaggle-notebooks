{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom sklearn.externals.six import StringIO\nfrom IPython.display import Image\nfrom sklearn.tree import export_graphviz\nfrom scipy.cluster.hierarchy import linkage, dendrogram","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Importing & Inspecting"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/students-performance-in-exams/StudentsPerformance.csv')\ndf.columns = ['Gender', 'Race', 'EducationLevel', 'Lunch', 'PreparationCourse',\n              'MathScore', 'ReadingScore', 'WritingScore']\ndf['AvgScore'] = round((df.MathScore + df.ReadingScore + df.WritingScore) / 3, 2)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe(include = 'O').T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['EducationLevel'] = pd.Categorical(df.EducationLevel,\n                                      categories = [\"some high school\", \"high school\", \"associate's degree\", \\\n                                                    \"some college\", \"bachelor's degree\", \"master's degree\"],\n                                      ordered = True)\n\nprint('Lunch Options\\n ', df.Lunch.unique())\nprint('Preparation Courses\\n', df.PreparationCourse.unique())\nprint('Races/Ethinicities\\n', df.Race.unique())\nprint('Education Levels\\n', df.EducationLevel.unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_list = ['Gender', 'Lunch', 'PreparationCourse', 'Race',  'EducationLevel']\n\nfor i in feature_list:\n    grouped = df[[i, 'MathScore', 'WritingScore', \\\n                'ReadingScore', 'AvgScore']].groupby(i).mean().sort_values(\n                by = 'AvgScore', ascending = False).round(2).reset_index()\n    print('---- {} Average Score Summary ----'.format(i))\n    display(grouped)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Visualization\n#### Categorical Variables Size Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('seaborn')\nfig, axes = plt.subplots(2, 3, figsize = (15, 8))\n\nfor ax, feature in zip(axes.flatten(), feature_list):\n    sns.countplot(df[feature], ax = ax, palette = 'Blues')\n    ax.set_xlabel('')\n    ax.tick_params(labelrotation = 30)\n    ax.set_title('Size on {}'.format(feature))\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Categorical Variables Detailed Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"#general overview on the dataset\nsns.pairplot(df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scores & Education Level seperated by Sex\ndf_sex = df[['MathScore', 'WritingScore', 'ReadingScore', 'EducationLevel', 'Gender']].groupby(\n            ['EducationLevel', 'Gender']).mean().reset_index()\n\nfig, axes = plt.subplots(1, 2, figsize = (15, 4), sharex = 'all', sharey = 'all')\ndf_sex[df_sex.Gender == 'female'].plot(kind = 'bar', x = 'EducationLevel', stacked = True, ax = axes[0])\naxes[0].set_title('Female Total Score by Education Level')\naxes[0].tick_params(labelrotation = 30)\naxes[0].set_xlabel('')\naxes[0].set_ylim(0, 300)\n\ndf_sex[df_sex.Gender == 'male'].plot(kind = 'bar', x = 'EducationLevel', stacked = True, ax = axes[1])\naxes[1].set_title('Male Total Score by Education Level')\naxes[1].tick_params(labelrotation = 30)\naxes[1].set_xlabel('')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scores & Test Preparation Course seperated by sex\nscores = ['AvgScore', 'MathScore', 'ReadingScore', 'WritingScore']\n\nfig, axes = plt.subplots(1, 4, figsize = (15, 3))\nfor ax, score in zip(axes.flatten(), scores):\n    sns.barplot('PreparationCourse', score, data = df, hue = 'Gender', ax = ax)\n    ax.set_ylim(0, 90)\n    ax.set_xlabel('')\n    ax.set_title('{} for Test Preparation Course'.format(score))\n    ax.legend(loc = 2)\n\nplt.tight_layout()\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scores & Lunch Options seperated by Sex\nfig, axes = plt.subplots(1, 4, figsize = (15, 4))\nfor ax, score in zip(axes.flatten(), scores):\n    sns.boxenplot('Lunch', score, data = df, hue = 'Gender', ax = ax)\n    ax.set_ylim(0, 110)\n    ax.set_xlabel('')\n    ax.set_title('{} for Lunch Options'.format(score))\n    ax.legend(loc = 3)\n\nplt.tight_layout()\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scores & Race seperated by Sex\nfig, axes = plt.subplots(2, 2, figsize = (15, 7))\nfor ax, score in zip(axes.flatten(), scores):\n    sns.boxplot('Race', score, data = df, hue = 'Gender', ax = ax)\n    ax.set_ylim(0, 110)\n    ax.set_xlabel('')\n    ax.set_title('{} for Race/Ethinicity'.format(score))\n    ax.legend(loc = 4)\n\nplt.tight_layout()\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scores & Education Level seperated by Sex\nfig, axes = plt.subplots(2, 2, figsize = (15, 8))\nfor ax, score in zip(axes.flatten(), scores):\n    sns.violinplot('EducationLevel', score, data = df, hue = 'Gender', ax = ax)\n    ax.set_xlabel('')\n    ax.set_title('{} for Education Level'.format(score))\n    ax.legend(loc = 4)\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Machine Learning\n#### Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting AvgScore intervals\ndf['AvgScore_int'] = pd.cut(df.AvgScore, bins = pd.interval_range(0, 100, 10))\nfeature_list.append('AvgScore_int')\n\n# setting up LabelEncoder\ncoded_list = []\nle = LabelEncoder()\n\n# encoding all variables\nfor col in feature_list:\n    df['{}_le'.format(col)] = le.fit_transform(df['{}'.format(col)])\n    coded_list.append('{}_le'.format(col))\n\nprint('Encoded Feature List\\n', coded_list)\ndisplay(df[coded_list].head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# setting up model & hyperparameters for GridSearch - get the best score\nX = df[coded_list].drop('AvgScore_int_le', axis = 1)\ny = df['AvgScore_int_le']\n\nhp_params = {'max_depth': range(3, 6, 1),\n             'n_estimators': range(150, 350, 50),\n             'criterion': ['gini', 'entropy']}\n\nrf_sg = GridSearchCV(estimator = RandomForestClassifier(oob_score = True, random_state = 0), \n                     param_grid = hp_params, cv = 5)\nrf_sg.fit(X, y)\n\nprint('Best Params: {}'.format(rf_sg.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# selecting the best params to find the feature importance\nrf_sg.best_estimator_.fit(X, y)\ndf_features = pd.DataFrame({'Feature': X.columns.values,\n                           'Importance': rf_sg.best_estimator_.feature_importances_})\n\nplt.figure(figsize = (10, 3))\nsns.barplot(x = 'Importance', y = 'Feature', \n            data = df_features.sort_values('Importance', ascending = False), palette = 'Blues_d')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# randomly selecting one of the forest to visualize\nestimator = rf_sg.best_estimator_.estimators_[np.random.randint(0, rf_sg.best_estimator_.n_estimators + 1)]\n\ndot_data = StringIO()\nexport_graphviz(estimator, out_file = dot_data, filled = True, rounded = True, special_characters = True,\n                feature_names = list(X.columns), class_names = [str(i) for i in set(y)])\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \nImage(graph.create_png())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}