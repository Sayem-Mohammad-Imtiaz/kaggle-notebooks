{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Diyabet\nBu veri seti aslen Ulusal Diyabet ve Sindirim ve Böbrek Hastalıkları Enstitüsü'nden alınmıştır. Amaç, bir hastanın diyabetli olup olmadığını tanısal ölçümlere dayanarak tahmin etmektir.\n\n## İçerik\nBu örneklerin daha büyük bir veritabanından seçilmesine çeşitli kısıtlamalar getirildi. Özellikle, buradaki tüm hastalar, Pima Kızılderili mirasına sahip en az 21 yaşında kadınlardır.\n\n- Pregnancies: Hamile kalma sayısı\n- Glucose:  Plazma glikoz konsantrasyonu, bir oral glikoz tolerans testinde 2 saat\n- BloodPressure: Diyastolik kan basıncı (mm Hg)\n- SkinThickness: Triceps deri kıvrım kalınlığı (mm)\n- Insulin: 2 saatlik serum insülini (mu U/ml)\n- BMI: Vücut kitle indeksi (kg cinsinden ağırlık/(m cinsinden boy)^2)\n- DiabetesPedigreeFunction: Diyabet soyağacı işlevi\n- Age: Yaş (yıl)\n- Outcome: Sınıf değişkeni (0 veya 1)\n\nİlgili bilgiler:\n  Bu örneklerin seçimine çeşitli kısıtlamalar getirildi. \n  Özellikle, buradaki tüm hastalar kadındır.\n  \n- Örnek Sayısı: 768\n- Nitelik Sayısı: 8 artı sınıf\n\nHer Nitelik için: (tümü sayısal değerli)\n- Hamile kalma sayısı\n- Plazma glikoz konsantrasyonu, bir oral glikoz tolerans testinde 2 saat\n- Diyastolik kan basıncı (mm Hg)\n- Triceps deri kıvrım kalınlığı (mm)\n- 2 saatlik serum insülini (mu U/ml)\n- Vücut kitle indeksi (kg cinsinden ağırlık/(m cinsinden boy)^2)\n- Diyabet soyağacı işlevi Yaşam yılları)\n- Sınıf değişkeni (0 veya 1)\n\n## Missing Values (Eksik Özellik Değerleri): Evet\n## Sınıf Dağılımı: (sınıf değeri 1, \" için şeker hastalığı pozitif test edildi\" olarak yorumlanır\")","metadata":{}},{"cell_type":"markdown","source":"## 1. Installing","metadata":{}},{"cell_type":"code","source":"# Bu Python 3 ortamı, yüklü birçok yardımcı analiz kitaplığı ile birlikte gelir\n# Kaggle/python Docker görüntüsü ile tanımlanır: https://github.com/kaggle/docker-python\n# Örneğin, yüklenecek birkaç yardımcı paket var\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Giriş verileri dosyaları salt okunur \"../input/\" dizininde bulunur\n# Örneğin, bunu çalıştırmak (çalıştır'ı tıklatarak veya Shift+Enter tuşlarına basarak) giriş dizini altındaki tüm dosyaları listeleyecektir.\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# \"Save & Run All\" seçeneğini kullanarak bir sürüm oluşturduğunuzda çıktı olarak korunan geçerli dizine (/kaggle/working/) 5GB'a kadar yazabilirsiniz.\n# /kaggle/temp/ dizinine geçici dosyalar da yazabilirsiniz, ancak bunlar geçerli oturumun dışında kaydedilmez\n\nimport statsmodels.api as sm\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import scale, StandardScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.metrics import confusion_matrix, accuracy_score, mean_squared_error, r2_score, roc_auc_score, roc_curve, classification_report\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import KFold\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) \nwarnings.filterwarnings(\"ignore\", category=FutureWarning) \nwarnings.filterwarnings(\"ignore\", category=UserWarning) \n\n%config InlineBackend.figure_format = 'retina'\n\n# tüm sütunları ve satırları görüntülemek için:\npd.set_option('display.max_columns', None); pd.set_option('display.max_rows', None);  # to display all columns and rows\npd.set_option('display.float_format', lambda x: '%.2f' % x) # The number of numbers that will be shown after the comma.\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. EDA (Exploratory of Data Analysis) (Veri Analizinin Keşfi)\n\n### 2.1. Data Preperation (Veri Hazırlama)","metadata":{}},{"cell_type":"code","source":"#Veri setini okuma\ndf = pd.read_csv(\"../input/diabetes-data-set/diabetes.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Veri Setinin boyutu\ndf.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#belirtilen değerlere göre veri setiyle ilgili istatistiki veriler\ndf.describe([0.10,0.25,0.50,0.75,0.90,0.95,0.99]).T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Veri setinin yüzde kaçı diabet hastası(1) yüzde kaçı diabet hastası değil(0)\ndf[\"Outcome\"].value_counts()*100/len(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Diabet olan ve diabet olmayanların sayısını öğrendik. 268 kişi diabet hastası ve 500 kişi diabet hastası değil\ndf.Outcome.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Yaş aralığına göre dağılım\ndf[\"Age\"].hist(edgecolor = \"black\");","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Missing Value Analysis ((Eksik Değer Analizi)","metadata":{}},{"cell_type":"code","source":"#Burda her kolonda kaç boş değer var bunun kontrolünü yaptık. Hiç boş değer görünmüyor.\ndf.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Burda ise verdiğimiz sütunlarda değeri 0 olan alanları NaN olarak değiştirdik.\ndf[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = df[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0, np.NaN)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Her kolondaki boş değerlerin toplamı\ndf.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Her sütun için dolu ve eksik değerleri gösteren dağılım grafiği\nimport missingno as msno\nmsno.bar(df);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def carp(x,y):\n    \n    z = x*y\n    \n    return z\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"carp(4,5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Eksik değerler bu fonksiyon ile her bir değişkenin medyan değerleri ile doldurulacaktır.\n\ndef median_target(var):   \n    \n    temp = df[df[var].notnull()]\n    \n    temp = temp[[var, 'Outcome']].groupby(['Outcome'])[[var]].median().reset_index()\n    \n    return temp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns = df.columns\n\ncolumns = columns.drop(\"Outcome\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# median_target fonksiyonu ile eksik değerlere dolu değerlerin medyanını atadık ve outcome'a göre grupladık.\nmedian_target('Glucose')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Eksik gözlemler için verilecek değerlere hasta olmayanların ortanca değeri ve hasta olanların ortanca değerleri verilir.\ncolumns = df.columns\n\ncolumns = columns.drop(\"Outcome\")\n\nfor col in columns:\n    \n    df.loc[(df['Outcome'] == 0 ) & (df[col].isnull()), col] = median_target(col)[col][0]\n    df.loc[(df['Outcome'] == 1 ) & (df[col].isnull()), col] = median_target(col)[col][1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Hasta olmayanların(0) Pregnancies(Gebelik) değeri boş olanları gösteriyor. Yokmuş.\ndf.loc[(df['Outcome'] == 0 ) & (df[\"Pregnancies\"].isnull()), \"Pregnancies\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Hasta olmayanların(0) BloodPressure(diyastolik kan basıncı) değeri boş olanları gösteriyor.\ndf[(df['Outcome'] == 0 ) & (df[\"BloodPressure\"].isnull())]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Outliers Analysis","metadata":{}},{"cell_type":"code","source":"Q1 = df[\"BloodPressure\"].quantile(0.25) #İstenen sütunda verilen nicelikteki değerleri döndürür yani BloodPressure alanı 0.25 olanları döndürecek.\nQ3 = df[\"BloodPressure\"].quantile(0.75) #Burdada BloodPressure alanı 0.75 olanları döndürecek.\nIQR = Q3-Q1 #0.75 değerlerin sayısı - 0.25 değerler\nlower = Q1 - 1.5*IQR #0.25 değerler - 1.5*aradaki fark(IQR)\nupper = Q3 + 1.5*IQR #0.75 değerler - 1.5*aradaki fark(IQR)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lower","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"upper","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Burda .any ile 104.0 değerinden daha büyük değerler var mı yok mu onu kontrol ettik ve True döndürdü yani daha büyük değer var. \ndf[(df[\"BloodPressure\"] > upper)].any(axis=None) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature in df:\n    print(feature)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature in df:\n    \n    Q1 = df[feature].quantile(0.05)\n    Q3 = df[feature].quantile(0.95)\n    IQR = Q3 - Q1\n    lower = Q1 - 1.5*IQR\n    upper = Q3 + 1.5*IQR\n    \n    if df[(df[feature] > upper)].any(axis=None):\n        print(feature,\"yes\")\n    else:\n        print(feature, \"no\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Feature Engineering","metadata":{}},{"cell_type":"code","source":"# BMI'ye göre bazı aralıklar belirlendi ve kategorik değişkenler atandı.\nNewBMI = pd.Series([\"Underweight\", \"Normal\", \"Overweight\", \"Obesity 1\", \"Obesity 2\", \"Obesity 3\"], dtype = \"category\")\n#Yukarda kategoriler belirlendi ve aşağıdaki kodlarla hangi aralığa hangi kategori geleceği belirlendi.\ndf[\"NewBMI\"] = NewBMI\n\ndf.loc[df[\"BMI\"] < 18.5, \"NewBMI\"] = NewBMI[0]\n\ndf.loc[(df[\"BMI\"] > 18.5) & (df[\"BMI\"] <= 24.9), \"NewBMI\"] = NewBMI[1]\ndf.loc[(df[\"BMI\"] > 24.9) & (df[\"BMI\"] <= 29.9), \"NewBMI\"] = NewBMI[2]\ndf.loc[(df[\"BMI\"] > 29.9) & (df[\"BMI\"] <= 34.9), \"NewBMI\"] = NewBMI[3]\ndf.loc[(df[\"BMI\"] > 34.9) & (df[\"BMI\"] <= 39.9), \"NewBMI\"] = NewBMI[4]\ndf.loc[df[\"BMI\"] > 39.9 ,\"NewBMI\"] = NewBMI[5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_insulin(row):\n    if row[\"Insulin\"] >= 16 and row[\"Insulin\"] <= 166: #df insulin değeri 16 dan büyükeşit ve 166 dan küçükeşitse Normal yazdır değilse Abnormal yazdır.\n        return \"Normal\"\n    else:\n        return \"Abnormal\"     ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#NewInsulinScore adında yeni bir sütunda insülini normal ve abnormal olanların değerlerini gösterdik.\ndf[\"NewInsulinScore\"] = df.apply(set_insulin, axis=1) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df.drop(\"NewInsulinScore\", inplace = True, axis = 1)\n#df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Glikoz değişkenine göre bazı aralıklar belirlenmiş ve bunlara kategorik değişkenler atanmıştır.\nNewGlucose = pd.Series([\"Low\", \"Normal\", \"Overweight\", \"Secret\", \"High\"], dtype = \"category\")\n\ndf[\"NewGlucose\"] = NewGlucose\n\ndf.loc[df[\"Glucose\"] <= 70, \"NewGlucose\"] = NewGlucose[0]\n\ndf.loc[(df[\"Glucose\"] > 70) & (df[\"Glucose\"] <= 99), \"NewGlucose\"] = NewGlucose[1]\n\ndf.loc[(df[\"Glucose\"] > 99) & (df[\"Glucose\"] <= 126), \"NewGlucose\"] = NewGlucose[2]\n\ndf.loc[df[\"Glucose\"] > 126 ,\"NewGlucose\"] = NewGlucose[3]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. One-hot Encoding","metadata":{}},{"cell_type":"code","source":"df = pd.get_dummies(df, columns =[\"NewBMI\",\"NewInsulinScore\", \"NewGlucose\"], drop_first = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorical_df = df[['NewBMI_Obesity 1','NewBMI_Obesity 2', 'NewBMI_Obesity 3', 'NewBMI_Overweight','NewBMI_Underweight',\n                     'NewInsulinScore_Normal','NewGlucose_Low','NewGlucose_Normal', 'NewGlucose_Overweight', 'NewGlucose_Secret']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7. Feature Standartization","metadata":{}},{"cell_type":"code","source":"y = df[\"Outcome\"]\nX = df.drop([\"Outcome\",'NewBMI_Obesity 1','NewBMI_Obesity 2', 'NewBMI_Obesity 3', 'NewBMI_Overweight','NewBMI_Underweight',\n                     'NewInsulinScore_Normal','NewGlucose_Low','NewGlucose_Normal', 'NewGlucose_Overweight', 'NewGlucose_Secret'], axis = 1)\ncols = X.columns\nindex = X.index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import RobustScaler\ntransformer = RobustScaler().fit(X)\nX = transformer.transform(X)\nX = pd.DataFrame(X, columns = cols, index = index)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = pd.concat([X, categorical_df], axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 8. Model","metadata":{}},{"cell_type":"code","source":"models = []\nmodels.append(('LR', LogisticRegression(random_state = 12345)))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier(random_state = 12345)))\nmodels.append(('RF', RandomForestClassifier(random_state = 12345)))\nmodels.append(('SVM', SVC(gamma='auto', random_state = 12345)))\nmodels.append(('XGB', GradientBoostingClassifier(random_state = 12345)))\nmodels.append((\"LightGBM\", LGBMClassifier(random_state = 12345)))\n\n# sırayla her modeli değerlendirin\nresults = []\nnames = []\n\nfor name, model in models:\n    \n        kfold = KFold(n_splits = 10, random_state = 12345)\n        \n        cv_results = cross_val_score(model, X, y, cv = 10, scoring= \"accuracy\")\n        results.append(cv_results)\n        names.append(name)\n        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n        print(msg)\n        \n# boxplot algorithm comparison\nfig = plt.figure(figsize=(15,10))\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 9. Model Optimizasyonu (Model Tunning)","metadata":{}},{"cell_type":"markdown","source":"### 9.1. Random Forests Tuning","metadata":{}},{"cell_type":"code","source":"rf_params = {\"n_estimators\" :[100,200,500,1000], \n             \"max_features\": [3,5,7], \n             \"min_samples_split\": [2,5,10,30],\n            \"max_depth\": [3,5,8,None]}\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_model = RandomForestClassifier(random_state = 12345)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gs_cv = GridSearchCV(rf_model, \n                    rf_params,\n                    cv = 10,\n                    n_jobs = -1,\n                    verbose = 2).fit(X, y)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gs_cv.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 9.1.1. RF Final Model","metadata":{}},{"cell_type":"code","source":"rf_tuned = RandomForestClassifier(**gs_cv.best_params_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_tuned = rf_tuned.fit(X,y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cross_val_score(rf_tuned, X, y, cv = 10).mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_imp = pd.Series(rf_tuned.feature_importances_,\n                        index=X.columns).sort_values(ascending=False)\n\nsns.barplot(x=feature_imp, y=feature_imp.index)\nplt.xlabel('Significance Score Of Variables')\nplt.ylabel('Variables')\nplt.title(\"Variable Severity Levels\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 9.2. LightGBM Model Tuning","metadata":{}},{"cell_type":"code","source":"lgbm = LGBMClassifier(random_state = 12345)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgbm_params = {\"learning_rate\": [0.01, 0.03, 0.05, 0.1, 0.5],\n              \"n_estimators\": [500, 1000, 1500],\n              \"max_depth\":[3,5,8]}\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gs_cv = GridSearchCV(lgbm, \n                     lgbm_params, \n                     cv = 10, \n                     n_jobs = -1, \n                     verbose = 2).fit(X, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gs_cv.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 9.2.1 LightGBM Final Model","metadata":{}},{"cell_type":"code","source":"lgbm_tuned = LGBMClassifier(**gs_cv.best_params_).fit(X,y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cross_val_score(lgbm_tuned, X, y, cv = 10).mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_imp = pd.Series(lgbm_tuned.feature_importances_,\n                        index=X.columns).sort_values(ascending=False)\n\nsns.barplot(x=feature_imp, y=feature_imp.index)\nplt.xlabel('Significance Score Of Variables')\nplt.ylabel('Variables')\nplt.title(\"Variable Severity Levels\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 9.3. XGBoost Model Tuning","metadata":{}},{"cell_type":"code","source":"xgb = GradientBoostingClassifier(random_state = 12345)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_params = {\n    \"learning_rate\": [0.01, 0.1, 0.2, 1],\n    \"min_samples_split\": np.linspace(0.1, 0.5, 10),\n    \"max_depth\":[3,5,8],\n    \"subsample\":[0.5, 0.9, 1.0],\n    \"n_estimators\": [100,1000]}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_cv_model  = GridSearchCV(xgb,xgb_params, cv = 10, n_jobs = -1, verbose = 2).fit(X, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_cv_model.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 9.3.1. XGBoost Final Model","metadata":{}},{"cell_type":"code","source":"xgb_tuned = GradientBoostingClassifier(**xgb_cv_model.best_params_).fit(X,y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cross_val_score(xgb_tuned, X, y, cv = 10).mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_imp = pd.Series(xgb_tuned.feature_importances_,\n                        index=X.columns).sort_values(ascending=False)\n\nsns.barplot(x=feature_imp, y=feature_imp.index)\nplt.xlabel('Significance Score Of Variables')\nplt.ylabel('Variables')\nplt.title(\"Variable Severity Levels\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 10. Comparison of Final Models","metadata":{"toc-hr-collapsed":true,"toc-nb-collapsed":true}},{"cell_type":"code","source":"models = []\n\nmodels.append(('RF', RandomForestClassifier(random_state = 12345, max_depth = 8, max_features = 7, min_samples_split = 2, n_estimators = 500)))\nmodels.append(('XGB', GradientBoostingClassifier(random_state = 12345, learning_rate = 0.1, max_depth = 5, min_samples_split = 0.1, n_estimators = 100, subsample = 1.0)))\nmodels.append((\"LightGBM\", LGBMClassifier(random_state = 12345, learning_rate = 0.01,  max_depth = 3, n_estimators = 1000)))\n\n# sırayla her modeli değerlendirin\nresults = []\nnames = []","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for name, model in models:\n    \n        kfold = KFold(n_splits = 10, random_state = 12345)\n        cv_results = cross_val_score(model, X, y, cv = 10, scoring= \"accuracy\")\n        results.append(cv_results)\n        names.append(name)\n        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n        print(msg)\n        \n# kutu grafiği algoritması karşılaştırması\nfig = plt.figure(figsize=(15,10))\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 11. Sonuç\n\nBu çalışmanın amacı, diyabet veri seti için sınıflandırma modelleri oluşturmak ve modeller kurarak bir kişinin hasta olup olmadığını tahmin etmek ve kurulan modellerde maksimum validasyon puanlarını elde etmektir. Yapılan iş aşağıdaki gibidir:\n\n1) Diyabet Veri Seti okundu.\n\n2) Keşfedici Veri Analizi ile; \nVeri setinin yapısal verileri kontrol edildi. Veri setindeki değişken türleri incelenmiştir. Veri setinin boyut bilgilerine ulaşıldı. Veri setindeki 0 değerleri eksik değerlerdir. Öncelikle bu 0 değerleri NaN değerleri ile değiştirildi. Veri setinin tanımlayıcı istatistikleri incelendi.\n\n3) Veri Ön İşleme bölümü; \ndf for: NaN değerleri eksik gözlemler, her bir değişkenin hasta olup olmadığına ilişkin medyan değerlerle dolduruldu. Aykırı değerler LOF tarafından belirlendi ve düşürüldü. X değişkenleri rubost yöntemi ile standardize edilmiştir.\n\n4) Model Oluşturma Sırasında; \nLojistik Regresyon, KNN, SVM, CART, Random Forests, XGBoost, LightGBM gibi makine öğrenme modelleri kullanılarak Çapraz Doğrulama Puanı hesaplanmıştır. Daha sonra Rastgele Ormanlar, XGBoost, LightGBM hiperparametre optimizasyonları Çapraz Doğrulama değerini artırmak için optimize edildi.\n\n5) Sonuç; \nLightBM hiperparametre optimizasyonu sonucunda oluşturulan model, Çapraz Doğrulama Puanı değeri en yüksek model olmuştur. (0.89)\n\n","metadata":{"toc-hr-collapsed":true,"toc-nb-collapsed":true}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}