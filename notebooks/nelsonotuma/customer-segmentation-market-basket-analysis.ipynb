{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Customer Segmentation Project.\n# Market Basket Analysis."},{"metadata":{},"cell_type":"markdown","source":"# Case Study"},{"metadata":{},"cell_type":"markdown","source":"It has always been important for businesses to understand customer behaviours in order to ensure that products or services are tailored towards maximum profitability. For this case study, we will refer to a dataset with customer shopping data on customer’s gender, city, customer‘s annual income, credit score, and spending score found here. This data was obtained on several cities in India as will be seen in the dataset. Data visualization will be done (in Python) to make comparisons between the different features of the dataset.  "},{"metadata":{},"cell_type":"markdown","source":"#  1. Defining the Goal of Customer Segmentation"},{"metadata":{},"cell_type":"markdown","source":"Customer Segmentation is the process of division of customer base into several groups of individuals that share a similarity in different ways that are relevant to marketing. Behaviour leads to Customer Segmentation, why Using clustering, companies, Malls, supermarkets and Restaurants can identify segments of customers to target the potential user base. We will divide customers into groups according to common characteristics like gender, city, customer‘s annual income, credit score, and spending score. Through this we get deeper understanding of the customer preferences as well as the requirements for discovering valuable segments that would help us gain maximum profit for the company.\nsecondly we strategize the marketing techniques more efficiently and reduce the risk of investment."},{"metadata":{},"cell_type":"markdown","source":"#  2. Get the Data"},{"metadata":{},"cell_type":"markdown","source":"We need to understand the data set in detail. We develop a brief understanding of the data set of which we will be working with. For example how many features are there in the data set , how many unique labels, How are they distributed or how are the labels distributed."},{"metadata":{"trusted":true},"cell_type":"code","source":"#We import the libraries for performing basic mathmatical operations and tabular Dataset that we intend to use in developing our model project.\nimport pandas as pd #data processing, CSV file I/O (e.g. pd.read_csv\nimport numpy as np #linear algebra\nfrom pandas import plotting\nimport seaborn as sns #Python library for Visualization\nimport matplotlib.pyplot as plt #Data Visualization\nimport plotly as py # Data plotting","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  Load the Data set."},{"metadata":{"trusted":true},"cell_type":"code","source":"#We now load the data set.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Data = pd.read_csv('../input/customer-segmentation-tutorial-in-python/Mall_Customers.csv')# we now read the data.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Data.head()# we explore the headers on the datasets to understand the features.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Data.tail()# we explore the tail on the datasets to understand it. Shows the bottom Data in the set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Data.tail().T# We explore the data sets to check on the headers conformity and understand it.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Data.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Data.T# we visualize the data set in tabular form","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Clean the Data."},{"metadata":{"trusted":true},"cell_type":"code","source":"Data.isnull().sum()#Check if there are any missing values.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This shows our data set does not have any missing values which means its clean.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(Data)#Shows how much data the Dataset contains:","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Data.info() #This displays all columns and their data types,","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Data.describe()# This shows you some basic descriptive statistics for all numeric columns in the data set.which includes the count,mean,standard deviation,min and max","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Enrich the data set to obtain reports."},{"metadata":{"trusted":true},"cell_type":"code","source":"#We now check for the data types in the data set.\nData.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We now visualize the columns in the data set.\nData.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We now rename the columns in the data set.\n\nData.rename(columns={'Annual Income (k$)':'AnnualIncome','Spending Score (1-100)':'SpendingScore'},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We use the concept of for loop in our data set  to understatand for data's columns\nfor i,col in enumerate(Data.columns):\n    print((i+1),'. columns is :',col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets Perform the row and columns count in our data set.\nData.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check for null values count  in our data set.\nData.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets check for every feature control  null value in this data # False mean our data is clean.\nprint(list(Data.isnull().any()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lWe check for data control null values in our data sets.\nData.isnull().values.any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking for data correlation in our data set.\nData.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Data.iloc[:,1:].corr()# we check for data correlation in our features as headers.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5.Find Insights and Visualize Data set."},{"metadata":{},"cell_type":"markdown","source":"We intend to drop the customer id from our data set since the customer id does not have the insights or does not draw any correlationship or unique feature with the rest of features in the data set. Hence we end up having Age,AnnualIncome,Spending Score and Gender in our data set.\nTherefore we will use this to visualize the data set."},{"metadata":{"trusted":true},"cell_type":"code","source":"#del Data['CustomerID']\nData.drop('CustomerID', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Data# we now check if we have dropped successfully the CustomerId column  in our data set.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We now check for Correlation between the different attributes of the Mall Customer Segementation Dataset,\nplt.rcParams['figure.figsize'] = (15, 8)\nsns.heatmap(Data.corr(), cmap = 'Wistia', annot = True)\nplt.title('Heatmap for the Data', fontsize = 20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above graph shows the correlation between the different attributes of the Mall Customer Segementation Dataset, \nThis Heat map reflects the most correlated features with Orange Color and least correlated features with yellow color"},{"metadata":{},"cell_type":"markdown","source":"# 5.1 Customer Gender Visualization"},{"metadata":{},"cell_type":"markdown","source":"We now create a bar graph and pie chart to check on customer Gender(Male and Female) distribution on our customer mall data set."},{"metadata":{"trusted":true},"cell_type":"code","source":"#We now check for the data Gender Unique\nData.Gender.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets now check on Data Gender counts for our data set.\nData.Gender.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## What gender is higher in density to the customer population?"},{"metadata":{},"cell_type":"markdown","source":"We can only answer this question by plotting the unique count for our mall customers. which counts the unique number of entries for each Gender within the data set in Mall."},{"metadata":{"trusted":true},"cell_type":"code","source":"#We plot a graph on data gender count for women and men for our data set.\nsns.countplot(Data.Gender)\nplt.title('Gender Count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. 2 We Visualize the Ratio of Male: Female by use of Pie Chart."},{"metadata":{},"cell_type":"markdown","source":"From the above barplot, we observe that the number of females is higher than the males. Now, let us visualize a pie chart to observe the ratio of male and female distribution."},{"metadata":{"trusted":true},"cell_type":"code","source":"# we now match label on data set gender..assign blue to male and red to female\nlabels=Data.Gender.unique()\ncolors=['blue','red']\nexplode=[0,0.1]\nvalues=Data.Gender.value_counts().values\n\n#We now carry out the visualization\nplt.figure(figsize=(7,7))\nplt.pie(values,explode=explode,labels=labels,colors=colors,autopct='%1.1f%%')\nplt.title('Male and Female Chart Distribution',color='black',fontsize=10)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now From the above piechart, we conclude that the percentage of females is 56%, whereas the percentage of male in the customer dataset is 44%"},{"metadata":{"trusted":true},"cell_type":"code","source":"# We now visualize the data in histogram distribution \nData.hist(figsize=(18,12))\nplt.title('All Data Show Histogram System')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6.Iteration of Mall Customer Data.\n\n## 6.1 Customer's distribution based on age."},{"metadata":{},"cell_type":"markdown","source":"We now check the customer distribution based on the age. our obejctive is to identify which age group visits the Mall mostly.\nTherefore we now plot the customer's distribution based on the age."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Customer's distribution based on age\nplt.figure(figsize=(20,5))\nsns.countplot(Data['Age'])\nplt.xticks(rotation=90)\nplt.title('Age Distribution')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We note that people who are of  age between 25 to 40 are mostly visiting mall than other age groups.\n\nPeople at Age 32 are the Most Frequent Visitors in the Mall.\nPeople of Age 55, 56, 64, 69 are very less frequent in the Malls (older age,above 50s groups are lesser frequent in comparison).\nAges from 19 and 31 are very much frequent."},{"metadata":{"trusted":true},"cell_type":"code","source":"#We now check for Male Age Distribution\nprint('Max  :',max(Data[Data['Gender']=='Male'].Age))\nprint('Min  :',min(Data[Data['Gender']=='Male'].Age))\nprint('Mean :',np.mean(Data[Data['Gender']=='Male'].Age))\nprint('Std  :',np.std(Data[Data['Gender']=='Male'].Age))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The maximum Age is 70, minimum 18 average age 39 for Male Gender in our data set."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets Check for Female Age Distribution in our Data Set.\nprint('Max  :',max(Data[Data['Gender']=='Female'].Age))\nprint('Min  :',min(Data[Data['Gender']=='Female'].Age))\nprint('Mean :',np.mean(Data[Data['Gender']=='Female'].Age))\nprint('Std  :',np.std(Data[Data['Gender']=='Female'].Age))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The maximum Age is 68, minimum 18 average age 38 for Female Gender in our data set with a standard diaviation of 12.5"},{"metadata":{},"cell_type":"markdown","source":"# 6.2 Customer Annuallncome Per Gender."},{"metadata":{},"cell_type":"markdown","source":"We now check on the customer annual income using the, our objective is to determine the maximum, minimum, mean and the standard deviation for our Male customers in the mall."},{"metadata":{"trusted":true},"cell_type":"code","source":"#check for the Male AnnualIncome \nprint('Max  :',max(Data[Data['Gender']=='Male'].AnnualIncome))\nprint('Min  :',min(Data[Data['Gender']=='Male'].AnnualIncome))\nprint('Mean :',np.mean(Data[Data['Gender']=='Male'].AnnualIncome))\nprint('Std  :',np.std(Data[Data['Gender']=='Male'].AnnualIncome))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We note that our maximum is, 137, minimum, 15, mean, 62.2, with standard variation of 26.4 anuallcome. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#check for the Female AnnualIncome \nprint('Max  :',max(Data[Data['Gender']=='Female'].AnnualIncome))\nprint('Min  :',min(Data[Data['Gender']=='Female'].AnnualIncome))\nprint('Mean :',np.mean(Data[Data['Gender']=='Female'].AnnualIncome))\nprint('Std  :',np.std(Data[Data['Gender']=='Female'].AnnualIncome))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We note that our maximum is, 126, minimum, 16, mean, 59.25, with standard variation of 25.8 anuallcome."},{"metadata":{"trusted":true},"cell_type":"code","source":"#We now visualize the Distribution of Annual Income of the Mall Customers.\nplt.figure(figsize=(20,5))\nsns.countplot(Data['AnnualIncome'])\nplt.xticks(rotation=90)\nplt.title('Distribution of AnnualIncome')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We note that the A wide veriety of income is visible ranging from 15k$ to 137k$ we can visualize the range on our bar plot.\n\nCustomers above 100k$ are 12\n\nCustomers below 25k$ are 22\n\nSo 166 customers have income between 25k$ and 100k$(ie.,83%)"},{"metadata":{},"cell_type":"markdown","source":"# 6.3 Analyzing Spending Score of the Customers."},{"metadata":{},"cell_type":"markdown","source":"We need to determine the minimum, average and the maximum spending score for our Mall Customers."},{"metadata":{"trusted":true},"cell_type":"code","source":"#We now check for the male customers spending score.\nprint('Max  :',max(Data[Data['Gender']=='Male'].SpendingScore))\nprint('Min  :',min(Data[Data['Gender']=='Male'].SpendingScore))\nprint('Mean :',np.mean(Data[Data['Gender']=='Male'].SpendingScore))\nprint('Std  :',np.std(Data[Data['Gender']=='Male'].SpendingScore))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We now check for the female customers spending score.\nprint('Max  :',max(Data[Data['Gender']=='Female'].SpendingScore))\nprint('Min  :',min(Data[Data['Gender']=='Female'].SpendingScore))\nprint('Mean :',np.mean(Data[Data['Gender']=='Female'].SpendingScore))\nprint('Std  :',np.std(Data[Data['Gender']=='Female'].SpendingScore))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We now visualize the Spending Score for our Mall Customers.\n#plt.figure(figsize=(18,8))\n#sns.countplot(Data['SpendingScore'])\n#plt.xticks(rotation=90)\n#plt.title('Distribution of SpendingScore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We now visualize our data using Histogram to show Spending Score Distribution\n\nplt.title('Distribution of SpendingScore')\nsns.distplot(Data[\"SpendingScore\"])\nplt.figure(figsize=(18,8))\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From our Data set we note that there are customers having 1 as spending score also, and 99 Spending score,\nWhich shows that the mall caters to the variety of Customers with Varying needs and requirements available in the Mall.\nMost of the Customers have their Spending Score in the range of 30-70."},{"metadata":{},"cell_type":"markdown","source":"# 6.4  More Comparisons on Spending Score vs Gender and Annual Income Vs Gender."},{"metadata":{"trusted":true},"cell_type":"code","source":"#We now map our data y label with Spending Score vs x label with Gender.\nsns.violinplot(y=Data['SpendingScore'],x=Data['Gender'])\nplt.title('SpendingScore & Gender')\nplt.show()\n\n#We now map our data y label with AnnualIncome vs x label with Gender.\nsns.violinplot(y=Data['AnnualIncome'],x=Data['Gender'])\nplt.title('AnnualIncome & Gender')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##  Based on Spending Score.\nFrom the above we note that Regarding Spending Score\nThe Male customers  have a Spending Score estimate of  25 to 70 and the female customers depict a spending score estimate  of  35 to 75\nTherefore we can Conclude that the female customers are ranked as the most shopping customers at the mall.\n\n## Based on Annuallncome.\nfrom the above the male most of the males have a spending annual income between 45k$ to 75K$ and female customers have a annual income of 35k$ to 75k$.\n"},{"metadata":{},"cell_type":"markdown","source":"# 7.0 K Means Clustering."},{"metadata":{},"cell_type":"markdown","source":"K-means clustering is a clustering algorithm that aims to partition n observations into k clusters.\nInitialisation – K initial “means” (centroids) are generated at random\nAssignment – K clusters are created by associating each observation with the nearest centroid\nUpdate – The centroid of the clusters becomes the new mean,\nAssignment and Update are repeated iteratively until convergence\nThe end result is that the sum of squared errors is minimised between points and their respective centroids.\nWe will use KMeans Clustering. At first we will find the optimal clusters based on inertia and using elbow method. The distance between the centroids and the data points should be less."},{"metadata":{"trusted":true},"cell_type":"code","source":"# We recheck for the missing value computation.\nData.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets perform  feature sleection for the model.\n#Lets consider only the two features  (Annual income and Spending Score)\nx = Data.iloc[:, [2, 3]].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 8.0 Building the Model"},{"metadata":{},"cell_type":"markdown","source":"We use the  elbow method  to determine the optimal number of clusters in k-means clustering.The elbow method plots the value of the cost function produced by different values of k. As you know, if k increases, average distortion will decrease, each cluster will have fewer constituent instances, and the instances will be closer to their respective centroids."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Building the Model\n#We use KMeans Algorithm to decide the optimum cluster number , KMeans++ using Elbow Mmethod\n#to figure out K for KMeans, I will use ELBOW Method on KMEANS++ Calculation\n#We always assume the max number of clusters would be 10\n# We  can judge the number of clusters by doing averaging\nfrom sklearn.cluster import KMeans\nwcss=[]\n\n# We use the below static code to get max number of clusters\n\nfor i in range(1,11):\n    kmeans = KMeans(n_clusters= i, init='k-means++', random_state=0)\n    kmeans.fit(x)\n    wcss.append(kmeans.inertia_)\n    \n#inertia_ is the formula used to segregate the data points into clusters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualize the ELBOW method to get the optimal value of K \nplt.plot(range(1,11), wcss)\nplt.title('The Elbow Method')\nplt.xlabel('no of clusters')\nplt.ylabel('wcss')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is clear from the figure that we should take the number of clusters equal to 5, as the slope of the curve is not steep enough after it.\nwhen we zoom out this curve then you will see that last elbow comes at k=5, it would be difficult to visualize the elbow if we choose the higher range. This why its usually recommended to pick a range of 1 to 11\nTherefore our k=5\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model Build\n#our data set is for  unsupervised learning therefore we will use \"fit_predict()\"\n#suppose we were working with  supervised learning data set we would use \"fit_tranform()\"\n#y_kmeans is our final model.\nkmeansmodel = KMeans(n_clusters= 5, init='k-means++', random_state=0)\ny_kmeans= kmeansmodel.fit_predict(x)\n\n#Visualizing all our the clusters \n\nplt.scatter(x[y_kmeans == 0, 0], x[y_kmeans == 0, 1], s = 100, c = 'red', label = 'Cluster 1')# Repeat for the same for the rest of the clusters.\nplt.scatter(x[y_kmeans == 1, 0], x[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')\nplt.scatter(x[y_kmeans == 2, 0], x[y_kmeans == 2, 1], s = 100, c = 'green', label = 'Cluster 3')\nplt.scatter(x[y_kmeans == 3, 0], x[y_kmeans == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4')\nplt.scatter(x[y_kmeans == 4, 0], x[y_kmeans == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5')\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 300, c = 'yellow', label = 'Centroids')\nplt.title('Clusters of customers', fontsize = 20)\nplt.xlabel('Annual Income (k$)')\nplt.ylabel('Spending Score (1-100)')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 8.1  K Means Model Interpretation and Analysis."},{"metadata":{},"cell_type":"markdown","source":"The model is divided in clusters,( Cluster 1 to Cluster 5)\nSo we have 5 clusters divided based on Annual Income and Spending Score\n\nCluster 1 (Red Color) -Normal Customer \n\nCustomers are average in terms of earning and spending\nAn Average consumer in terms of spending and Annual Income\nwe see that people have average income and an average spending score, these people again will not be the prime targets of the shops or mall, but again they will be considered and other data analysis techniques may be used to increase their spending score.\n\nCluster 2 (Blue Colr) -Spender \n\nThis type of customers earns less but spends more\nAnnual Income is less but spending high, so can also be treated as potential target customer\nwe can see that people have low income but higher spending scores, these are those people who for some reason love to buy products more often even though they have a low income. \nMaybe it’s because these people are more than satisfied with the mall services. \nThe shops/malls might not target these people that effectively but still will not lose them.\n\nCluster 3 (Green Color) -Target Customers\n\nEarning high and also spending high Target Customers.\nAnnual Income High as well as Spending Score is high, so a target consumer.\nwe see that people have high income and high spending scores, this is the ideal case for the mall or shops as these people are the prime sources of profit. These people might be the regular customers of the mall and are convinced by the mall’s facilities.\n\nCluster 4 (cyan Color)- Balanced Customers\n\nThe earn less and spend less too.\nwe can see people have low annual income and low spending scores, this is quite reasonable as people having low salaries prefer to buy less, \nin fact, these are the wise people who know how to spend and save money. \nThe shops/mall will be least interested in people belonging to this cluster.\n\nCluster 5 (magenta Color) - Pinch Penny Customers\n\nEarning high and spending less.- \nwe see that people have high income but low spending scores, this is interesting. Maybe these are the people who are unsatisfied or unhappy by the mall’s services. These can be the prime targets of the mall, as they have the potential to spend money. So, the mall authorities will try to add new facilities so that they can attract these people and can meet their needs.\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"# 9.0 Conclusion and Report\n"},{"metadata":{},"cell_type":"markdown","source":"We have explored the five segments based customers  Annual Income and Spending Score which are reportedly the best factors/attributes to determine the segments of a customer in a Mall. They include; Pinch Penny Customers,Balanced Customers,Target Customers,Spender and the normal customer.\nWe can put Cluster 3 into some alerting system where sms and emails can be send to them on daily basis regarding the offers and discounts that they can get at the Mall; while the rest we can set once per week in a month for blast sms to notify them about our products.\n\nSimilarly \nNow we know customers behaviour depending upon their Annual Income and Spending Score. \nThere can be many marketing strategies applied for Customers on these Cluster Analysis.\nHigh income and High spending score customers are our target customers and we would always want to retain them\nas they give the most profit margin to our organization. \nHigh Income and Less spending score customers can be \nattracted with wide range of products in their life style demands and it might attract them towards the Mall Supermarket.\nLess Income Less Spending Score can be given extra offers and constantly sending them the offers\nand discounts will attract them towards spending.\nWe can also have a cluster anaysis done on what kind of products customers tend to buy and can make other marketing strategies accordingly. The data set did not have enough data to carry out more analytics on the same."},{"metadata":{},"cell_type":"markdown","source":"# 10. Recommendation."},{"metadata":{},"cell_type":"markdown","source":"Companies, Malls, super markets on Small Business Enterprises should carry out Market Basket Analysis for their business. This will enable companies to target specific groups of customers, a customer segmentation model allows for the effective allocation of marketing resources and the maximization of cross- and up-selling opportunities.\nWhen a group of customers is sent personalized messages as part of a marketing mix that is designed around their needs, it's easier for companies to send those customers special offers meant to encourage them to buy more products. Customer segmentation can also improve customer service and assist in customer loyalty and retention.\nAs a by-product of its personalized nature, marketing materials sent out using customer segmentation tend to be more valued and appreciated by the customer who receives them as opposed to impersonal brand messaging that doesn't acknowledge purchase history or any kind of customer relationship\nFinally with customer segmentation Companies will stay a step ahead of competitors in specific sections of the market and identify new products that exist or potential customers could be interested in or improving products to meet customer expectations."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}