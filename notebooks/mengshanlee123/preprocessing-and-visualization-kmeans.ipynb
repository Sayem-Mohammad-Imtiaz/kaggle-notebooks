{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **Objective**\nDevelop a credit card customer segmentation to define marketing strategy.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **Outline**\n\n[**1. Dataset Features**](#Dataset-Features)\n\n\n[**2. Preprocessing**](#Preprocessing)\n\n> [* Missing Values Treatment](#Missing-Values-Treatment)\n\n> [* Feature Distribution - KDE plot](#Feature-Distribution)\n\n> [* Outliers Treatment](#Outliers-Treatment)\n\n> [* Correlation Matrix](#Correlation-Matrix)\n\n> [* Create Interaction Features](#Create-Interaction-Features)\n\n> [* Feature Digitization](#Feature-Digitization)\n\n\n[**3. Modeling**](#Modeling)\n\n> [* Evaluation Metric - Silhouette Score](#Evaluation-Metric---Silhouette-Score)\n\n> [* Model - KMeans](#Model---KMeans)\n\n\n[**4. Visualization**](#Visualization)\n\n> [* Line Plot - Silhouette Score under Various Number of Cluster](#Line-Plot---Silhouette-Score-under-Various-Number-of-Cluster)\n\n> [* Scatter Plot - Cluster Results](#Scatter-Plot---Cluster-Results)\n\n> [* Histogram - Features Value of Each Cluster](#Histogram---Features-Value-of-Each-Cluster)\n\n> [* Render Plot - Features Value of Each Cluster](#Render-Plot---Features-Value-of-Each-Cluster)\n\n\n[**5. Features of customers in each group**](#Features-of-customers-in-each-group)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **Dataset Features**<a></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**1. Balance**\n* BALANCE: Balance amount left in their account to make purchases (\n* BALANCEFREQUENCY: How frequently the Balance is updated, score between 0 and 1 (1 = frequently updated, 0 = not frequently updated)\n\n**2. Purchases**\n* PURCHASES: Amount of purchases made from account\n* ONEOFFPURCHASES: Maximum purchase amount done in one-go\n* INSTALLMENTSPURCHASES: Amount of purchase done in installment\n\n**3. Purchases Frequency**\n* PURCHASESFREQUENCY: How frequently the Purchases are being made, score between 0 and 1 (1 = frequently purchased, 0 = not frequently purchased)\n* ONEOFFPURCHASESFREQUENCY: How frequently Purchases are happening in one-go (1 = frequently purchased, 0 = not frequently purchased)\n* PURCHASESINSTALLMENTSFREQUENCY: How frequently purchases in installments are being done (1 = frequently done, 0 = not frequently done)\n* PURCHASESTRX: Number of purchase transactions made\n\n**4. Cash Advance**\n* CASHADVANCE: Cash in advance given by the user\n* CASHADVANCEFREQUENCY: How frequently the cash in advance being paid\n* CASHADVANCETRX: Number of Transactions made with \"Cash in Advanced\"\n\n**5. Payments**\n* PAYMENTS: Amount of Payment done by user\n* MINIMUM_PAYMENTS: Minimum amount of payments made by user\n* PRCFULLPAYMENT: Percent of full payment paid by user\n\n**6. Others**\n* CUSTID: Identification of Credit Card holder (Categorical)\n* CREDITLIMIT: Limit of Credit Card for user\n* TENURE: Tenure of credit card service for user","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndata = pd.read_csv('../input/ccdata/CC GENERAL.csv')\ndata_raw=data.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Preprocessing**<a></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Check out feature types","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Missing-Values-Treatment\"></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Missing Values Treatment**<a></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.isnull(data).sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"'CREDIT_LIMIT': Drop that row directly since it only has 1 missing value","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_index=data[data['CREDIT_LIMIT'].isnull()].index.to_list()\ndata=data.drop(index=missing_index[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"'MINIMUM_PAYMENTS': \n1. Kernel Density Estimation Plot shows positively skewed distribution, which means there are outliers\n2. Fill missing values with median value ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.kdeplot(data['MINIMUM_PAYMENTS'], shade=True) \nplt.title('Kernel Density Estimation Plot') \ndata['MINIMUM_PAYMENTS']=data['MINIMUM_PAYMENTS'].fillna(data['MINIMUM_PAYMENTS'].median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.isnull(data).sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Feature-Distribution\"></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Feature Distribution**<a></a>\n\nKDE (Kernel Density Estimation) plot for each feature","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dist=data.iloc[:,1:17]\ndata_columns=data_dist.columns\n\nr,c=0,0\nfig, axes=plt.subplots(4,4, figsize=(20,16))\n#plt.tight_layout()\nfor i in data_columns:\n    sns.distplot(data[i], ax=axes[r,c])\n    c += 1\n    if c == 4: \n        r += 1\n        c=0\n    if r == 4: break\nplt.suptitle('Kernel Density Estimation Plot', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Outliers-Treatment\"></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Outliers Treatment**<a></a>\n\nThere are 2 ways:\n1. Remove: If the observations are wrongly recorded (e.g., credit limit is not in accordance with bank's regulation), we directly remove the observations. \n2. Keep: Replace that features with their square root value or log value to downsize outliers impact.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"What we do:\n1. Since there is no evidence shows there are observations wrongly recorded, we do not remove outliers.\n2. Z-score is used to identify which features with more than 2% outliers (absolute z-score >3) in themselves, and replace them with thier square root value.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import stats\ndata1=data.drop(columns=['CUST_ID', 'TENURE']) # drop string feature and features with meaningful range\nz_score=pd.DataFrame(np.abs(stats.zscore(data1)), columns=data1.columns) # calculate z-score\n\n# Find out features with more than 2% outliers (absolute z-score >3)\nz_score3=[]\nover3_index=[] \nfor i in z_score.columns:\n    indexs=z_score.index[z_score[i] > 3].tolist()\n    ans=i, \"{:.3f}\".format(len(indexs)/len(z_score)), indexs\n    z_score3.append(ans) \n    if len(indexs)/len(z_score) > 0.02:\n        over3_index.append(i)  \n\n# remove 'BALANCE' and 'CASH_ADVANCE' since thay are regarded as high discriminative features\ndel over3_index[0]\ndel over3_index[1]\n\n# replace 'BALANCE_FREQUENCY','CASH_ADVANCE_FREQUENCY', and 'PURCHASES_TRX' with their square root value\nfor i in over3_index:\n    data1['sqrt_%s' % i]=data1[i].apply(np.sqrt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('feature: ', list(data1.columns))\nprint('data shape: ', data1.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Correlation-Matrix\"></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Correlation Matrix**<a></a>\n\nNote:\nTo avoid the top and bottom boxes are cut off, we need to downgrade matplotlib (conda install -c conda-forge matplotlib=3.1.2)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_coef=data[1:].corr()\n\n# Heatmap\nplt.figure(figsize=(25, 25))\nsns.heatmap(corr_coef, cmap='Greens', annot=True, annot_kws={'size':14},\n            xticklabels=corr_coef.columns,\n            yticklabels=corr_coef.columns)\nplt.title('Correlation Matrix')\n\n# Find out feature pairs whose coefficient >= 0.7\ncorr_cols=corr_coef.columns.to_list() \nsignif_corr=[]\nfor i in range(len(corr_cols)):\n    col=corr_cols[i]\n    signif_corr.append(abs(corr_coef[col])[abs(corr_coef[col]) >= 0.7])\nsignif_corr_df=pd.DataFrame(signif_corr)\n#signif_corr_df['PURCHASES']['ONEOFF_PURCHASES'] ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"High Correlation Coefficient Pairs Analysis:\n\n* PURCHASES & ONEOFFPURCHASES: 0.92\n\nWhen people use one-off purchases, purchase amount is higher than using installment purchases.\n\n* PURCHASESFREQUENCY & PURCHASESINSTALLMENTSFREQUENCY: 0.86\n\nMore people use installment purchases.\n\n* CASHADVANCEFREQUENCY & CASHADVANCETRX: 0.80\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.kdeplot(data1['INSTALLMENTS_PURCHASES'], shade=True)\nsns.kdeplot(data1['ONEOFF_PURCHASES'], shade=True)\nsns.kdeplot(data1['PURCHASES'], shade=True)\nplt.title('Kernel Density Estimation Plot')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.kdeplot(data1['PURCHASES_INSTALLMENTS_FREQUENCY'], shade=True)\nsns.kdeplot(data1['ONEOFF_PURCHASES_FREQUENCY'], shade=True)\nsns.kdeplot(data1['PURCHASES_FREQUENCY'], shade=True)\nplt.title('Kernel Density Estimation Plot')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Create-Interaction-Features\"></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Create Interaction Features**<a></a>\n\nWe can understand clients' purchase level or preference by knowing their average purchase amount, however we only got frequency for one-off and installment purchase or cash advance form this dataset.\n\nFrequency data is reagarded as metric of number of transaction since number of transaction divided by some value will be frequency. (The higher frequency is, the less average purchase amount is)\n\nBelow are the formulas:\n1. Average one-off purchase amount = 'ONEOFF_PURCHASES'/'ONEOFF_PURCHASES_FREQUENCY'\n2. Average installment purchase amount = 'INSTALLMENTS_PURCHASES'/'PURCHASES_INSTALLMENTS_FREQUENCY'\n3. Average can advance amount = 'CASH_ADVANCE'/'CASH_ADVANCE_TRX'","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data1['avg_oneoff_purchases']=data1['ONEOFF_PURCHASES']/data1['ONEOFF_PURCHASES_FREQUENCY']\ndata1['avg_oneoff_purchases']=data1['avg_oneoff_purchases'].fillna(0)\n\ndata1['avg_installment_purchases']=data1['INSTALLMENTS_PURCHASES']/data1['PURCHASES_INSTALLMENTS_FREQUENCY']\ndata1['avg_installment_purchases']=data1['avg_installment_purchases'].fillna(0)\n\ndata1['avg_cash_advance']=data1['CASH_ADVANCE']/data1['CASH_ADVANCE_TRX']\ndata1['avg_cash_advance']=data1['avg_cash_advance'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Feature-Digitization\"></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Feature Digitization**<a></a>\n\nDigitize features into 8 ranges except 'TENURE' (due to its meaningful own range)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\ndigit_index=list(data1.columns)\n\nfor i in digit_index:\n    max_v=math.ceil(data1[i].describe()['max'])\n    min_v=math.floor(data1[i].describe()['min'])\n    bins_range=np.arange(min_v, max_v, (max_v-min_v)/8)    \n    data1['digit_%s' % i]=np.digitize(data1[i], bins=bins_range)\n    #print(np.unique(data1['digit_%s' % i], return_counts=True))\n\ndata1['CUST_ID']=data['CUST_ID']\ndata1['TENURE']=data['TENURE']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('data shape: ', data1.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Modeling**<a></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import Normalizer, RobustScaler, OneHotEncoder\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.decomposition import PCA, TruncatedSVD\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Design pipelines to select numerical and categorical features\n\nNote: Since sklearn cannot directly handle DataFrames, we need to define a function to transform it into numpy\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\nclass DataFrameSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, attribute_names):\n        self.attribute_names = attribute_names\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X):\n        return X[self.attribute_names] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categ=list(data1.columns)[22:44]\ncateg1=np.delete(categ,[1, 9, 11]).tolist()\nnumer=['TENURE']\n\nprint('Categorical Features: ', categ1)\nprint('Numerical Feature: ', numer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_pipeline=Pipeline([('selector', DataFrameSelector(numer)),\n                             ('RobustScaler', RobustScaler())])\n\ncategorical_pipeline=Pipeline([('selector', DataFrameSelector(categ1)),\n                             ('OneHotEncoder', OneHotEncoder())])\n\nselector_pipeline=FeatureUnion([('numerical_pipeline', numerical_pipeline),\n                                ('categorical_pipeline', categorical_pipeline)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Evaluation-Metric---Silhouette-Score\"></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Evaluation Metric - Silhouette Score**<a></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def silhouette_score_cal(estimator,data):       \n    preprocess=FeatureUnion([('selector_pipeline', selector_pipeline), \n                             ('Normalizer', Normalizer(norm='l2')),\n                             ('pca', PCA(n_components=15))])            \n    trans_results=preprocess.fit_transform(data)          \n    clusters=estimator.fit_predict(data)\n    score=silhouette_score(trans_results, clusters)\n    return score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Model---KMeans\"></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Model - KMeans**<a></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"categ_copy=categ1.copy()\ncateg_copy.append('TENURE')\ndata_model=data1[categ_copy]\n\npreprocess=FeatureUnion([('selector_pipeline', selector_pipeline), \n                             ('Normalizer', Normalizer(norm='l2')),\n                             ('pca', PCA(n_components=15))])\n\ntrans_results=preprocess.fit_transform(data_model)  # for visualization    \nkmeans=Pipeline([('preprocess', preprocess), ('kmeans', KMeans())])     \nsearch_space=[{'kmeans__n_clusters':np.arange(3,10)}] # test various(3-9) n_clusters\ncv = [(slice(None), slice(None))]\n\ngs=GridSearchCV(estimator=kmeans,param_grid=search_space, \n                scoring=silhouette_score_cal,cv=cv, n_jobs=-1)\n\nbest_model=gs.fit(data_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Best Model Results**\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('best model - number of cluster: ', best_model.best_params_)\nprint('best model - Silhouette Score: ', best_model.best_score_)\ngrid_predict=best_model.predict(data_model)\ndata1['cluster']=grid_predict\ngrid_results=best_model.cv_results_\nprint('number of observations in each cluster: ', list(np.unique(grid_predict, return_counts=True)[1])) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Visualization**<a></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Line-Plot---Silhouette-Score-under-Various-Number-of-Cluster\"></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Line Plot - Silhouette Score under Various Number of Cluster<a></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_scores=grid_results['mean_test_score']\nplt.plot(range(3,10), grid_results['mean_test_score'])\nplt.title('Silhouette Score under Various Number of Cluster')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Scatter-Plot---Cluster-Results\"></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Scatter Plot - Cluster Results <a></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_visual=pd.DataFrame(TruncatedSVD(n_components=2).fit_transform(trans_results), columns=['p1','p2'])\n\nplt.figure(figsize=(10,8))\nplt.scatter(df_visual['p1'], df_visual['p2'], c=grid_predict, cmap=plt.cm.summer)\nplt.title('Clustering Results Visualization')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Histogram---Features-Value-of-Each-Cluster\"></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Histogram - Features Value of Each Cluster<a></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in list(data.columns[1:]):\n    g=sns.FacetGrid(data1, col='cluster')\n    g=g.map(plt.hist, feature)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Feature Value (Mean Value) of Each Cluster","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data1.insert(0, 'TENURE', data1['TENURE'], allow_duplicates=True) # just for convience\neach_cluster=data1.groupby('cluster').mean().iloc[:, :23]\neach_cluster","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Render-Plot---Features-Value-of-Each-Cluster\"></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Render Plot - Features Value of Each Cluster<a></a>\n\nSplit features into 3 parts based on value reange (low, high, top)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"high=['BALANCE', 'ONEOFF_PURCHASES', 'INSTALLMENTS_PURCHASES', 'CASH_ADVANCE',\n      'MINIMUM_PAYMENTS']\nlow=['BALANCE_FREQUENCY', 'PURCHASES_FREQUENCY', 'ONEOFF_PURCHASES_FREQUENCY', \n     'PURCHASES_INSTALLMENTS_FREQUENCY', 'CASH_ADVANCE_FREQUENCY', 'CASH_ADVANCE_TRX', \n     'PURCHASES_TRX','PRC_FULL_PAYMENT', 'TENURE']\ntop=['CREDIT_LIMIT', 'PURCHASES', 'PAYMENTS']\n\neach_cluster_high=each_cluster[high].T\neach_cluster_low=each_cluster[low].T\neach_cluster_top=each_cluster[top].T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def render_plot(data, dataLenth, labels, color, facecolor):    \n    angles = np.linspace(0, 2*np.pi, dataLenth, endpoint=False)\n    data, angles = np.concatenate((data, [data[0]])), np.concatenate((angles, [angles[0]])) # for visualize circle\n        \n    ax = fig.add_subplot(121, polar=True)# polar: drawing circle\n    ax.plot(angles, data, color, linewidth=1)\n    ax.fill(angles, data, facecolor=facecolor, alpha=0.1)# fill color\n    ax.set_thetagrids(angles * 180/np.pi, labels, fontproperties=\"SimHei\")\n    ax.set_title(\"Feature Value of Each Cluster\", va='baseline', fontproperties=\"SimHei\")\n    ax.grid(True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(15,15))\nlabels = np.array(list(each_cluster_top.index))\nrender_plot(each_cluster_top.iloc[:,0], len(each_cluster_top.iloc[:,0]), labels,'go-', 'g')\nrender_plot(each_cluster_top.iloc[:,1], len(each_cluster_top.iloc[:,0]), labels,'bo-', 'b')\nrender_plot(each_cluster_top.iloc[:,2], len(each_cluster_top.iloc[:,0]), labels,'ro-', 'r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=plt.figure()\nfig = plt.figure(figsize=(15,15))\nlabels = np.array(list(each_cluster_high.index))\nrender_plot(each_cluster_high.iloc[:,0], len(each_cluster_high.iloc[:,0]), labels,'go-', 'g')\nrender_plot(each_cluster_high.iloc[:,1], len(each_cluster_high.iloc[:,0]), labels,'bo-', 'b')\nrender_plot(each_cluster_high.iloc[:,2], len(each_cluster_high.iloc[:,0]), labels,'ro-', 'r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(15,15))\nlabels = np.array(list(each_cluster_low.index))\nrender_plot(each_cluster_low.iloc[:,0], len(each_cluster_low.iloc[:,0]), labels,'go-', 'g')\nrender_plot(each_cluster_low.iloc[:,1], len(each_cluster_low.iloc[:,0]), labels,'bo-', 'b')\nrender_plot(each_cluster_low.iloc[:,2], len(each_cluster_low.iloc[:,0]), labels,'ro-', 'r')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Features of customers in each group**<a></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Group Red**: Big spender with high balance, credit limit, and payments who mostly take one-off purchases.\n\n**Group Green**: Medium spender with low balance who take less cash advance and purchase mostly in installments.\n\n**Group Blue**: Small spender with medium balance who take more cash advance and seldom purchase in installments.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}