{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Get the Data","metadata":{}},{"cell_type":"code","source":"happines_data_2015 = pd.read_csv('../input/world-happiness/2015.csv', parse_dates=True, encoding = \"cp1252\")\nhappines_data_2016 = pd.read_csv('../input/world-happiness/2016.csv', parse_dates=True, encoding = \"cp1252\")\nhappines_data_2017 = pd.read_csv('../input/world-happiness/2017.csv', parse_dates=True, encoding = \"cp1252\")\nhappines_data_2018 = pd.read_csv('../input/world-happiness/2018.csv', parse_dates=True, encoding = \"cp1252\")\nhappines_data_2019 = pd.read_csv('../input/world-happiness/2019.csv', parse_dates=True, encoding = \"cp1252\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"happines_data_2015.drop(['Region', 'Standard Error', 'Dystopia Residual'], axis=1, inplace=True)\nhappines_data_2015.rename({'Happiness Rank':'Overall rank', \n                           'Country':'Country or region', \n                           'Happiness Score': 'Score', \n                           'Economy (GDP per Capita)': 'GDP per capita', \n                           'Family':'Social support', \n                           'Health (Life Expectancy)':'Healthy life expectancy', \n                           'Freedom':'Freedom to make life choices', \n                           'Trust (Government Corruption)':'Perceptions of corruption'}, axis=1, inplace=True)\nhappines_data_2015.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"happines_data_2016.drop(['Region', 'Lower Confidence Interval', 'Upper Confidence Interval', 'Dystopia Residual'], axis=1, inplace=True)\nhappines_data_2016.rename({'Happiness Rank':'Overall rank', \n                           'Country':'Country or region', \n                           'Happiness Score': 'Score', \n                           'Economy (GDP per Capita)': 'GDP per capita', \n                           'Family':'Social support', \n                           'Health (Life Expectancy)':'Healthy life expectancy', \n                           'Freedom':'Freedom to make life choices', \n                           'Trust (Government Corruption)':'Perceptions of corruption'}, axis=1, inplace=True)\nhappines_data_2016.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"happines_data_2017.drop(['Whisker.high', 'Whisker.low', 'Dystopia.Residual'], axis=1, inplace=True)\nhappines_data_2017.rename({'Happiness.Rank':'Overall rank', \n                           'Country':'Country or region', \n                           'Happiness.Score': 'Score', \n                           'Economy..GDP.per.Capita.': 'GDP per capita', \n                           'Family':'Social support', \n                           'Health..Life.Expectancy.':'Healthy life expectancy', \n                           'Freedom':'Freedom to make life choices', \n                           'Trust..Government.Corruption.':'Perceptions of corruption'}, axis=1, inplace=True)\nhappines_data_2017.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"happines_data = pd.concat([happines_data_2019, happines_data_2018, happines_data_2017, happines_data_2016, happines_data_2015])\nhappines_data.drop(['Overall rank', 'Country or region'], axis=1, inplace=True)\nhappines_data.head(800)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"happines_data.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"happines_data['Perceptions of corruption'].isnull().values.any()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"happines_data['Perceptions of corruption'].isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"happines_data['Perceptions of corruption'] = happines_data['Perceptions of corruption'].fillna(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Split up the data to training set and test set","metadata":{}},{"cell_type":"code","source":"X = happines_data[['GDP per capita',\n                   'Social support', \n                   'Healthy life expectancy',\n                   'Freedom to make life choices',\n                   'Generosity',\n                   'Perceptions of corruption']]\n\ny = happines_data['Score']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor, RandomForestRegressor, ExtraTreesRegressor\nfrom sklearn.linear_model import SGDRegressor, LinearRegression, Ridge, Lasso, ElasticNet\nfrom sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\n\nfrom sklearn.model_selection import cross_validate, cross_val_score\nfrom sklearn.metrics import explained_variance_score, max_error, mean_absolute_error, r2_score, explained_variance_score\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, mean_squared_error, mean_squared_log_error\nfrom sklearn.metrics import median_absolute_error, mean_poisson_deviance, mean_gamma_deviance\nfrom sklearn.model_selection import KFold\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models=[(\"Linear Regression\", LinearRegression()),\n        (\"Ridge Regression\", Ridge()),\n        (\"Lasso Regression\", Lasso()),\n        (\"Elastic-Net Regression\", ElasticNet()),\n        (\"Stochastic Gradient Descent\", SGDRegressor()),\n        (\"Decision Tree\", DecisionTreeRegressor()),\n        (\"Random Forest\", RandomForestRegressor()),\n        (\"Extra Trees\", ExtraTreesRegressor()),\n        (\"Gradient Boostin\", GradientBoostingRegressor()),\n        (\"KNeighbors\", KNeighborsRegressor()),\n        (\"SVM linear\", SVR(kernel='linear')),\n        (\"SVM rbf\", SVR(kernel='rbf')),\n        (\"Ada Boost\", AdaBoostRegressor())]\n\nfor name, model in models:\n    results = cross_val_score(model, X_train, y_train, cv=10)\n    print(f\"\\x1b[96m{name}\\x1b[0m: \\x1b[93m{results.mean():.4f}\\x1b[0m ± {results.std():.4f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"enet = ElasticNet(random_state=0)\nenet.fit(X_train, y_train)\n\nenet_predict = enet.predict(X_test)\n\nprint(\"score: \", enet.score(X_test, y_test))\nprint(\"cross_val_score: \", cross_val_score(enet, X_train, y_train, cv = 10).mean())\nprint(\"r2_score: \", r2_score(y_test, enet_predict))\nprint(\"\")\nprint(\"mean_absolute_error: \", mean_absolute_error(y_test, enet_predict))\nprint(\"mean_squared_error: \", mean_squared_error(y_test, enet_predict))\nprint(\"root_mean_squared_error: \", mean_squared_error(y_test, enet_predict, squared=False))\nprint(\"max_error: \", max_error(y_test, enet_predict))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"et = ExtraTreesRegressor()\net.fit(X_train, y_train)\n\net_predict = et.predict(X_test)\n\nprint(\"score: \", et.score(X_test, y_test))\nprint(\"cross_val_score: \", cross_val_score(et, X_train, y_train, cv = 10).mean())\nprint(\"r2_score: \", r2_score(y_test, et_predict))\nprint(\"\")\nprint(\"mean_absolute_error: \", mean_absolute_error(y_test, et_predict))\nprint(\"mean_squared_error: \", mean_squared_error(y_test, et_predict))\nprint(\"root_mean_squared_error: \", mean_squared_error(y_test, et_predict, squared=False))\nprint(\"max_error: \", max_error(y_test, et_predict))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train the model","metadata":{}},{"cell_type":"code","source":"gr_boosting = GradientBoostingRegressor(random_state=0,\n                                        loss='huber',\n                                        max_depth=5,\n                                        max_features=3,\n                                        learning_rate=0.2,\n                                        n_estimators=27,\n                                        min_samples_split=6,\n                                        min_samples_leaf=4)\n\ngr_boosting.fit(X_train, y_train)\n\nprint(f\"\"\"Тrain: {gr_boosting.score(X_train, y_train)}\\nТest: {gr_boosting.score(X_test, y_test)}\"\"\")\n\ngr_predict = gr_boosting.predict(X_test)\nprint(\"\")\nprint(\"mean_absolute_error: \", mean_absolute_error(y_test, gr_predict))\nprint(\"mean_squared_error: \", mean_squared_error(y_test, gr_predict))\nprint(\"root_mean_squared_error: \", mean_squared_error(y_test, gr_predict, squared=False))\nprint(\"max_error: \", max_error(y_test, gr_predict))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correct=[]\nerror=[]\nX_list=X_test.reset_index()\ny_list=list(y_test)\n\nfor i in range(len(X_test)):\n    r=y_list[i]\n    p=gr_boosting.predict([[X_list.loc[i,\"GDP per capita\"],\n                            X_list.loc[i,\"Social support\"],\n                            X_list.loc[i,\"Healthy life expectancy\"],\n                            X_list.loc[i,\"Freedom to make life choices\"],\n                            X_list.loc[i,\"Generosity\"],\n                            X_list.loc[i,\"Perceptions of corruption\"]]])[0]\n\n    correct.append((abs(r-p)/r))\n    error.append(abs(r-p))\n    print(f'real: {r:.4f} - predicted: {p:.4f} - difference: {abs(r-p):.4f} ({(abs(r-p)/r):.2f}%)')\n\nprint(f\"\\nMean accuracy: {1-sum(correct) / len(correct)}\")\nprint(f\"Mean error: {sum(error) / len(error)}\")\nprint(f\"Max error: {max(error)}\")\nprint(f\"Min error: {min(error)}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Importants","metadata":{}},{"cell_type":"code","source":"feature_importance = gr_boosting.feature_importances_\nsorted_idx = np.argsort(feature_importance)\npos = np.arange(sorted_idx.shape[0]) + .5\n\nfig = plt.figure(figsize=(17, 6))\nplt.barh(pos, feature_importance[sorted_idx], align='center')\nplt.yticks(pos, np.array(X_train.columns)[sorted_idx])\nplt.title('Feature Importance')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.inspection import permutation_importance\n\nperm_importance = permutation_importance(gr_boosting, X_test, y_test, n_repeats=30, random_state=0)\nsorted_idx = np.argsort(perm_importance.importances_mean)\npos = np.arange(sorted_idx.shape[0]) + .5\n\nfig = plt.figure(figsize=(17, 6))\n\nplt.barh(pos, perm_importance.importances_mean[sorted_idx], align='center')\nplt.yticks(pos, np.array(X_train.columns)[sorted_idx])\nplt.title('Permutation Importance')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shap\n\nexplainer = shap.TreeExplainer(gr_boosting)\nshap_values = explainer.shap_values(X_test)\n\nshap.summary_plot(shap_values, X_test, plot_type=\"bar\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.summary_plot(shap_values, X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.dependence_plot('GDP per capita', shap_values, X_test, interaction_index='Healthy life expectancy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.initjs()\nshap.force_plot(explainer.expected_value, shap_values, X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.inspection import plot_partial_dependence, PartialDependenceDisplay\n\nfig, ax = plt.subplots(figsize=(17, 8))\ngrb_plot=plot_partial_dependence(gr_boosting, X_test, [\"GDP per capita\", \"Social support\", 'Healthy life expectancy',\n                                                       'Freedom to make life choices', 'Generosity', 'Perceptions of corruption'], \n                                 ax=ax, method='brute', n_jobs=-1)\n\net_plot=plot_partial_dependence(et, X_test, [\"GDP per capita\", \"Social support\", 'Healthy life expectancy',\n                                             'Freedom to make life choices', 'Generosity', 'Perceptions of corruption'], \n                                ax=grb_plot.axes_, line_kw={\"color\": \"red\"}, n_jobs=-1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(2, 6, figsize=(20, 6))\ngrb_plot.plot(ax=ax1, line_kw={\"color\": \"blue\"})\net_plot.plot(ax=ax2, line_kw={\"color\": \"red\"});","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Grid Search","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nparam_rf={# 'max_depth': [3, 4, 5, 6],\n#           'max_features': [3, 4, 5, 6],\n          'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],\n#           'min_samples_split': [4, 5, 6, 7],\n#           'min_samples_leaf': [2, 3, 4, 5],\n#           'loss': ['ls', 'lad', 'huber', 'quantile'],\n          'n_estimators' :[20, 30, 50, 100, 200, 300]}\n\ngs_rf = GridSearchCV(GradientBoostingRegressor(), param_grid = param_rf, n_jobs=-1)\ngs_rf.fit(X_train, y_train.values.ravel())\n# print(gs_rf.best_estimator_)\nprint(gs_rf.best_params_)\nprint('score=',gs_rf.best_score_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predictions","metadata":{}},{"cell_type":"code","source":"import ipywidgets as widgets\nfrom ipywidgets import Button, Layout\n\nstyle = {'description_width': '170px'}\nlayout = Layout(width='600px')\n\ngdp = widgets.FloatSlider(min=0, max=2.1, step=0.01, value=1, \n                          description='GDP per capita', style=style, layout=layout)\nsocial = widgets.FloatSlider(min=0, max=1.7, step=0.01, value=0.5,\n                             description='Social support', style=style, layout=layout)\nhealth = widgets.FloatSlider(min=0, max=1.2, step=0.01, value=0.5,\n                             description='Healthy life expectancy', style=style, layout=layout)\nfreedom = widgets.FloatSlider(min=0, max=0.7, step=0.01, value=0.5,\n                              description='Freedom to make life choices', style=style, layout=layout)\ngen = widgets.FloatSlider(min=0, max=0.6, step=0.01, value=0.3,\n                          description='Generosity', style=style, layout=layout)\ncor = widgets.FloatSlider(min=0, max=0.5, step=0.01, value=0.2,\n                          description='Perceptions of corruption', style=style, layout=layout)\n\ndef f(gdp, social, health, freedom, gen, cor):\n    print(f'Predicted value: {gr_boosting.predict([[gdp, social, health, freedom, gen, cor]])[0]:.5f}')\n\n    \nout = widgets.interactive_output(f, {'gdp': gdp, 'social': social, 'health': health, \n                                     'freedom': freedom, 'gen': gen, 'cor': cor,})\n\nwidgets.HBox([widgets.VBox([gdp, social, health, freedom, gen, cor]), out])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Features value","metadata":{}},{"cell_type":"code","source":"max_depths = np.arange(1, 31, 1)\nresults_train = []\nresults_test = []\n\nfor feature in max_depths:\n    rf = GradientBoostingRegressor(random_state=0, max_depth=feature, loss='huber')\n    rf.fit(X_train, y_train)\n        \n    results_train.append(rf.score(X_train, y_train))\n    results_test.append(rf.score(X_test, y_test))\n\nfig, ax = plt.subplots(figsize=(17,8)) \nplt.plot(max_depths, results_train, 'b')\nplt.plot(max_depths, results_test, 'r')\n\nax.set_axisbelow(True)\nax.minorticks_on()\nax.grid(which='major', linestyle='-', linewidth=0.5, color='black',)\nax.grid(which='minor', linestyle=':', linewidth=0.5, color='black', alpha=0.7)\n\nplt.title('max_depth')\n\nplt.gca().xaxis.set_major_locator(plt.MultipleLocator(1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(results_test[results_test.index(max(results_test))])\nprint(max_depths[results_test.index(max(results_test))])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_rates = np.arange(0.01, 0.5, 0.01)\nresults_train = []\nresults_test = []\n\nfor feature in learning_rates:\n    rf = GradientBoostingRegressor(random_state=0, max_depth=5, learning_rate=feature, loss='huber')\n    rf.fit(X_train, y_train)\n        \n    results_train.append(rf.score(X_train, y_train))\n    results_test.append(rf.score(X_test, y_test))\n\nfig, ax = plt.subplots(figsize=(17,8)) \n\nplt.plot(learning_rates, results_train, 'b')\nplt.plot(learning_rates, results_test, 'r')\n\nax.set_axisbelow(True)\nax.minorticks_on()\nax.grid(which='major', linestyle='-', linewidth=0.5, color='black',)\nax.grid(which='minor', linestyle=':', linewidth=0.5, color='black', alpha=0.7)\n\nplt.title('learning_rates')\n\nplt.gca().xaxis.set_major_locator(plt.MultipleLocator(0.1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(results_test[results_test.index(max(results_test))])\nprint(learning_rates[results_test.index(max(results_test))])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"min_samples_splits = np.arange(2, 20, 1)\nresults_train = []\nresults_test = []\n\nfor feature in min_samples_splits:\n    rf = GradientBoostingRegressor(random_state=0, min_samples_split=feature, \n                                   learning_rate=0.2, max_depth=5, loss='huber')\n    \n    rf.fit(X_train, y_train)\n        \n    results_train.append(rf.score(X_train, y_train))\n    results_test.append(rf.score(X_test, y_test))\n\nfig, ax = plt.subplots(figsize=(17,8)) \n\nplt.plot(min_samples_splits, results_train, 'b')\nplt.plot(min_samples_splits, results_test, 'r')\n\nax.set_axisbelow(True)\nax.minorticks_on()\nax.grid(which='major', linestyle='-', linewidth=0.5, color='black',)\nax.grid(which='minor', linestyle=':', linewidth=0.5, color='black', alpha=0.7)\n\nplt.title('min_samples_split')\n\nplt.gca().xaxis.set_major_locator(plt.MultipleLocator(1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(results_test[results_test.index(max(results_test))])\nprint(min_samples_splits[results_test.index(max(results_test))])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"min_samples_leafs = np.arange(0.01, 0.5, 0.01)\nresults_train = []\nresults_test = []\n\nfor feature in min_samples_leafs:\n    rf = GradientBoostingRegressor(random_state=0, min_samples_leaf=feature, \n                                   learning_rate=0.2, max_depth=5, loss='huber')\n    rf.fit(X_train, y_train)\n        \n    results_train.append(rf.score(X_train, y_train))\n    results_test.append(rf.score(X_test, y_test))\n\nfig, ax = plt.subplots(figsize=(17,8)) \n\nplt.plot(min_samples_leafs, results_train, 'b')\nplt.plot(min_samples_leafs, results_test, 'r')\n\nax.set_axisbelow(True)\nax.minorticks_on()\nax.grid(which='major', linestyle='-', linewidth=0.5, color='black',)\nax.grid(which='minor', linestyle=':', linewidth=0.5, color='black', alpha=0.7)\n\nplt.title('min_samples_leaf')\n\nplt.gca().xaxis.set_major_locator(plt.MultipleLocator(0.1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(results_test[results_test.index(max(results_test))])\nprint(min_samples_leafs[results_test.index(max(results_test))])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_features  = list(range(1,X.shape[1]+1))\nresults_train = []\nresults_test = []\n\nfor feature in max_features :\n    rf = GradientBoostingRegressor(random_state=0, max_features=feature,\n                                   learning_rate=0.2, max_depth=5, loss='huber')\n    \n    rf.fit(X_train, y_train)\n        \n    results_train.append(rf.score(X_train, y_train))\n    results_test.append(rf.score(X_test, y_test))\n\nfig, ax = plt.subplots(figsize=(17,8)) \n\nplt.plot(max_features, results_train, 'b')\nplt.plot(max_features, results_test, 'r')\n\nax.set_axisbelow(True)\nax.minorticks_on()\nax.grid(which='major', linestyle='-', linewidth=0.5, color='black',)\nax.grid(which='minor', linestyle=':', linewidth=0.5, color='black', alpha=0.7)\n\nplt.title('max_features')\n\nplt.gca().xaxis.set_major_locator(plt.MultipleLocator(1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_estimator  = np.arange(1, 100, 1)\nresults_train = []\nresults_test = []\n\nfor feature in n_estimator :\n    rf = GradientBoostingRegressor(random_state=0, n_estimators=feature,\n                                   learning_rate=0.2, max_depth=5, loss='huber')\n    rf.fit(X_train, y_train)\n        \n    results_train.append(rf.score(X_train, y_train))\n    results_test.append(rf.score(X_test, y_test))\n\nfig, ax = plt.subplots(figsize=(17,8)) \n\nplt.plot(n_estimator, results_train, 'b')\nplt.plot(n_estimator, results_test, 'r')\n\nax.set_axisbelow(True)\nax.minorticks_on()\nax.grid(which='major', linestyle='-', linewidth=0.5, color='black',)\nax.grid(which='minor', linestyle=':', linewidth=0.5, color='black', alpha=0.7)\n\nplt.title('n_estimators')\n\nplt.gca().xaxis.set_major_locator(plt.MultipleLocator(10))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(results_test[results_test.index(max(results_test))])\nprint(n_estimator[results_test.index(max(results_test))])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}