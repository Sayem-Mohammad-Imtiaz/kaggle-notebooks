{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Data Mining Project @ E-commerce Data"},{"metadata":{},"cell_type":"markdown","source":"#### Dimitris Chortarias Data Scientist\n\n"},{"metadata":{},"cell_type":"markdown","source":"## Loading Data & Packages"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# K-Means, CURE, DBSCAN\n!pip install pyclustering\nimport csv\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom yellowbrick.cluster import KElbowVisualizer\nfrom sklearn import preprocessing\nfrom sklearn.cluster import KMeans\nfrom sklearn.datasets import make_blobs\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom pyclustering.cluster.cure import cure\nfrom pyclustering.cluster import cluster_visualizer\nfrom pyclustering.samples.definitions import SIMPLE_SAMPLES\nfrom pyclustering.samples.definitions import FCPS_SAMPLES\nfrom pyclustering.utils import read_sample\nfrom pyclustering.utils import timedcall\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.datasets import make_blobs\nfrom mpl_toolkits import mplot3d\nfrom sklearn import metrics\nfrom sklearn.cluster import DBSCAN\n%matplotlib inline\n\ndf=pd.read_csv('../input/ecommerce-data/data.csv',encoding='iso-8859-1')\ndf['InvoiceDate'] =  pd.to_datetime(df['InvoiceDate'], format='%m/%d/%Y %H:%M')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Analysis & Preproccessing"},{"metadata":{},"cell_type":"markdown","source":"### Exploring Dataset"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure()\ndf.boxplot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Removing Null Values & filter Data on Quantity to be Positive"},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df.dropna().reset_index()\ndf = df[df.Quantity <=10000]\ndf = df[df.Quantity >=0]\ndf=df.sort_values(['Quantity'],ascending=False)\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure()\ndf.boxplot('Quantity')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Countries Contribution at Dataset "},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style=\"darkgrid\")\nf, ax = plt.subplots(figsize=(25, 5))\nax = sns.countplot(x=\"Country\", data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Selecting only UK due to sample size"},{"metadata":{"trusted":true},"cell_type":"code","source":"dfuk=df[df['Country']=='United Kingdom']\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Creating the metrics per Customers due to create the customer Segmentation"},{"metadata":{},"cell_type":"markdown","source":"We are going to run the project based on how much times does the customer bought, average price of the items that he buys and quantity per buy. "},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"dfukg = (dfuk.groupby(['CustomerID','Country'],as_index=False)\n          .agg({'InvoiceNo':'nunique', 'StockCode':'nunique','UnitPrice':'mean','Quantity':'sum'}))\ndfukg\ndfukg.reset_index()\ndfukg['avgitems']=dfukg['Quantity']/dfukg['InvoiceNo']\ndb=dfukg[['InvoiceNo','UnitPrice','avgitems']]\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Mark and Removing the outliers"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"import numpy as np\n\ni=0 \nwhile i<=len(db)-1:\n    quartile_1, quartile_3 = np.percentile(db['avgitems'], [25, 75])\n    iqr = quartile_3 - quartile_1\n    lower_bound = quartile_1 - (iqr *1.5 )\n    upper_bound = quartile_3 + (iqr *1.5)\n    \n    if db.loc[i,'avgitems']> upper_bound:\n        db.loc[i,'outlier']=1\n    elif db.loc[i,'avgitems']< lower_bound:\n        db.loc[i,'outlier']=1\n    else:\n        db.loc[i,'outlier']=0\n    i=i+1\n    \ndb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.countplot(x=\"outlier\", data=db)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"db=db[db['outlier']==0]\ndb= db.drop(columns=['outlier'])\ndb","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## K-Means with not normalized data"},{"metadata":{},"cell_type":"markdown","source":"### Elbow Method"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = KMeans()\nvisualizer = KElbowVisualizer(model, k=(2,12))\nvisualizer.fit(db)  \nvisualizer.show()        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Kmeans"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"kmeans = KMeans(5)\nkmeans.fit(db)\nidentified_clusters = kmeans.fit_predict(db)\ndata_with_clusters = db.copy()\ndata_with_clusters['Cluster'] = identified_clusters\nprint(kmeans.cluster_centers_)\nprint(identified_clusters)\n\nsns.set(style=\"darkgrid\")\nf, ax = plt.subplots(figsize=(25, 5))\nax = sns.countplot(x=\"Cluster\", data=data_with_clusters)\ndata_with_clusters.groupby(['Cluster']).count()\nfig = plt.figure()\nax = plt.axes(projection='3d')\nxline=data_with_clusters['InvoiceNo']\nyline=data_with_clusters['avgitems']\nzline=data_with_clusters['UnitPrice']\n\nax.scatter3D(xline, zline,yline,c=data_with_clusters['Cluster'])\nax.view_init(60, 60)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nax = plt.axes(projection='3d')\nxline=data_with_clusters['InvoiceNo']\nyline=data_with_clusters['avgitems']\nzline=data_with_clusters['UnitPrice']\n\nax.scatter3D(xline, zline,yline,c=data_with_clusters['Cluster'])\nax.view_init(60, 60)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_with_clusters[data_with_clusters['Cluster']==4]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans.cluster_centers_\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## K-Means with  normalized data"},{"metadata":{},"cell_type":"markdown","source":"### Scale Data"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nx_scaled=scaler.fit(db)\nx_scaled = scaler.fit_transform(db)\nx_scaled","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Elbow"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"model = KMeans()\nvisualizer = KElbowVisualizer(model, k=(1,12))\nvisualizer.fit(x_scaled)  \nvisualizer.show()     ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Kmeans"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"kmeans_scaled = KMeans(4)\nkmeans_scaled.fit(x_scaled)\nclusters_scaled = db.copy()\nclusters_scaled['cluster_pred']=kmeans_scaled.fit_predict(x_scaled)\nprint(identified_clusters)\nsns.set(style=\"darkgrid\")\nprint(kmeans.cluster_centers_)\nf, ax = plt.subplots(figsize=(25, 5))\nax = sns.countplot(x=\"cluster_pred\", data=clusters_scaled)\nclusters_scaled.groupby(['cluster_pred']).count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nax = plt.axes(projection='3d')\nxline=clusters_scaled['InvoiceNo']\nyline=clusters_scaled['avgitems']\nzline=clusters_scaled['UnitPrice']\n\nax.scatter3D(xline, zline,yline,c=clusters_scaled['cluster_pred'])\nax.view_init(35, 60)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cure Algorithm"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"def template_clustering(number_clusters, path, number_represent_points=1, compression=0.5, draw=True, ccore_flag=True):\n    sample = read_sample(path)\n    \n    cure_instance = cure(sample, number_clusters, number_represent_points, compression, ccore_flag)\n    (ticks, _) = timedcall(cure_instance.process)\n    \n    clusters = cure_instance.get_clusters()\n    representors = cure_instance.get_representors()\n    means = cure_instance.get_means()\n    print('clusters:',means)\n    print(\"Sample: \", path, \"\\t\\tExecution time: \", ticks, \"\\n\")\n    print([len(cluster) for cluster in clusters])\n\n    if draw is True:\n        visualizer = cluster_visualizer()\n\n        visualizer.append_clusters(clusters, sample)\n\n        for cluster_index in range(len(clusters)):\n            visualizer.append_cluster_attribute(0, cluster_index, representors[cluster_index], '*', 10)\n            visualizer.append_cluster_attribute(0, cluster_index, [ means[cluster_index] ], 'o')\n\n        visualizer.show()\n   \n\n\n\n        \nrec = db.to_records(index=False)\ndb.to_csv(r'/kaggle/working/pandas.txt', header=None, index=None, sep=' ', mode='a')\npath= '/kaggle/working/pandas.txt'\ntemplate_clustering(5,path)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cure Algorithm at Normalized Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"def template_clustering(number_clusters, path, number_represent_points=1, compression=0.5, draw=True, ccore_flag=True):\n    sample = read_sample(path)\n    \n    cure_instance = cure(sample, number_clusters, number_represent_points, compression, ccore_flag)\n    (ticks, _) = timedcall(cure_instance.process)\n    \n    clusters = cure_instance.get_clusters()\n    representors = cure_instance.get_representors()\n    means = cure_instance.get_means()\n    print('clusters:',means)\n    print(\"Sample: \", path, \"\\t\\tExecution time: \", ticks, \"\\n\")\n    print([len(cluster) for cluster in clusters])\n\n    if draw is True:\n        visualizer = cluster_visualizer()\n\n        visualizer.append_clusters(clusters, sample)\n\n        for cluster_index in range(len(clusters)):\n            visualizer.append_cluster_attribute(0, cluster_index, representors[cluster_index], '*', 10)\n            visualizer.append_cluster_attribute(0, cluster_index, [ means[cluster_index] ], 'o')\n\n        visualizer.show()\n   \n\n\ndtype = [('Col1','int32'), ('Col2','float32'), ('Col3','float32')]\nindex = ['Row'+str(i) for i in range(1, len(x_scaled)+1)]\n\nx_sc1 = pd.DataFrame(x_scaled, index=index)\n\nrec = x_sc1.to_records(index=False)\nx_sc1.to_csv(r'/kaggle/working/pa2ndas.txt', header=None, index=None, sep=' ', mode='a')\n\npath= '/kaggle/working/pa2ndas.txt'\ntemplate_clustering(4,path)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## DBSCAN with Normalized Data"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"\nstscaler = StandardScaler().fit(db)\ndb11 = stscaler.transform(db)\ndbsc = DBSCAN(eps = .5, min_samples = 5).fit(db11)\nclusters_scaled = db.copy()\nclusters_scaled['cluster_pred']=dbsc.fit_predict(db11)\nclusters_scaled\nax = sns.countplot(x=\"cluster_pred\", data=clusters_scaled)\nclusters_scaled.groupby(['cluster_pred']).count()\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nax = plt.axes(projection='3d')\nxline=clusters_scaled['InvoiceNo']\nyline=clusters_scaled['avgitems']\nzline=clusters_scaled['UnitPrice']\n\nax.scatter3D(xline, zline,yline,c=clusters_scaled['cluster_pred'])\nax.view_init(35, 60)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## DBSCAN "},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"dbsc = DBSCAN(eps = .5, min_samples = 5).fit(db)\ndata_with_clusters = db.copy()\ndata_with_clusters['cluster_pred']=dbsc.fit_predict(data_with_clusters)\ndata_with_clusters\nax = sns.countplot(x=\"cluster_pred\", data=data_with_clusters)\ndata_with_clusters.groupby(['cluster_pred']).count()\nfig = plt.figure()\nax = plt.axes(projection='3d')\nxline=data_with_clusters['InvoiceNo']\nyline=data_with_clusters['avgitems']\nzline=data_with_clusters['UnitPrice']\n\nax.scatter3D(xline, zline,yline,c=data_with_clusters['cluster_pred'])\nax.view_init(35, 60)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nax = plt.axes(projection='3d')\nxline=data_with_clusters['InvoiceNo']\nyline=data_with_clusters['avgitems']\nzline=data_with_clusters['UnitPrice']\n\nax.scatter3D(xline, zline,yline,c=data_with_clusters['cluster_pred'])\nax.view_init(35, 60)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.1"}},"nbformat":4,"nbformat_minor":1}