{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Loading Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport nltk\nimport spacy\nfrom wordcloud import WordCloud\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import text\nfrom tensorflow.keras.preprocessing import sequence\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.utils import to_categorical\nfrom nltk.corpus import stopwords, words\nfrom nltk.stem import WordNetLemmatizer\nimport time\nimport re\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.metrics import AUC\nfrom sklearn.metrics import confusion_matrix, classification_report","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loading Data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#loading training and testing dataframes\ntrain_data = pd.read_csv('/kaggle/input/covid-19-nlp-text-classification/Corona_NLP_train.csv', encoding='latin-1')\ntest_data = pd.read_csv('/kaggle/input/covid-19-nlp-text-classification/Corona_NLP_test.csv', encoding='latin-1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#preview of training dataframe\ntrain_data.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#preview of testing dataframe\ntest_data.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Non-Null Count and dtype of training dataframe\ntrain_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Non-Null Count and dtype of testing dataframe\ntest_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#descriptive statistics for training dataframe\ntrain_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#descriptive statistics for testing dataframe\ntest_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_dataframe(dataframe, name=None):\n    \n    \"\"\"\n    Function to preprocess dataframe: removes redundant columns, converts dates to datetime type, creates new columns for mentions and hashtags\n    \n    Parameters\n    ----------\n    dataframe: Pandas Dataframe\n        a dataframe to preprocess\n    name: str, default=None\n        The name to assign to a dataframe\n    \n    Returns\n    -------\n    dataframe: Pandas Dataframe\n        a preprocessed dataframe\n    \"\"\"\n    \n    dataframe = dataframe.drop(columns=['UserName', 'ScreenName', 'Location'])\n    dataframe['TweetAt'] = pd.to_datetime(dataframe['TweetAt'])\n    dataframe['mentions'] = pd.Series([[word for word in tweet.split() if word.startswith('@')] for tweet in dataframe['OriginalTweet'].values])\n    dataframe['hashtags'] = pd.Series([[word for word in tweet.split() if word.startswith('#')] for tweet in dataframe['OriginalTweet'].values])\n    \n    if name!=None:\n        dataframe.name = name\n    \n    return dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#preprocessing training and testing dataframes\ntrain_df = preprocess_dataframe(train_data, name='train')\ntest_df = preprocess_dataframe(test_data, name='test')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sentiment_countplot(data, title, figsize=(8, 5)):\n    \n    \"\"\"\n    Function that creates countplots for sentiments in a dataframe\n    \n    Parameters\n    ----------\n    data: Pandas dataframe\n        a dataframe for which to visualize sentiments\n    title: str\n        Title of the the plot\n    figsize: tuple, default=(8, 5)\n        The size of the figure\n    \"\"\"\n    fig = plt.figure(figsize=(8, 5))\n    sns.set_palette(\"RdYlGn\")\n    ax = sns.countplot(data=data,\n                  x='Sentiment',\n                  order=['Extremely Negative', 'Negative', 'Neutral', 'Positive', 'Extremely Positive'])\n    ax.set_title(title)\n    total = data.shape[0]\n    for p in ax.patches:\n        height = p.get_height()\n        ax.text(p.get_x()+p.get_width()/2.,\n                height + 3,\n                '{}%'.format(int(np.round(height/total*100))),\n                ha=\"center\") ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Exploratory Data Analysis**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Distribution of sentiments in training dataframe\nsentiment_countplot(train_df, 'Count of Sentiments in Train Data')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Distribution of sentiments in testing dataframe\nsentiment_countplot(test_df, 'Count of Sentiments in Test Data')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Distribution of tweet counts by sentiment over time in training dataframe\ntrain_df.groupby(['TweetAt', 'Sentiment'])['OriginalTweet'].count().unstack().plot(kind='area', figsize=(10, 5))\nplt.title('Count of Tweets in 2020')\nplt.ylabel('Tweet Count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Distribution of tweet counts by sentiment over time in testing dataframe\ntest_df.groupby(['TweetAt', 'Sentiment'])['OriginalTweet'].count().unstack().plot(kind='area', figsize=(10, 5))\nplt.title('Count of Tweets in 2020')\nplt.ylabel('Tweet Count')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Text Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"REPLACE_BY_SPACE = re.compile('[/(){}\\[\\]\\|,;&-_]') #punctuation to replace","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_text(text):\n    \n    \"\"\"\n    Function to preprocess text: removes links, punctuation, spaces, non-alpha words and stop_words\n    \n    Parameters\n    ----------\n    text: str\n        a string to be preprocessed\n        \n    Returns\n    -------\n    text: str\n        a preprocessed string\n    \"\"\"\n    text = text.lower()                                    #lowercase\n    text = re.sub(r\"http\\S+\", \"\", text)                    #replace links with \"\"\n    text = re.sub(r\"\\@\\S+\", \"\", text)                      #replace mentions with \"\"\n    text = re.sub(r\"#\\S+\", \"\", text)                       #replace hashtags with \"\"\n    text = re.sub(r\"won\\'t\", \"would not\", text)            #deal with contractions\n    text = re.sub(r\"n\\'t\", \" not\", text)                   #deal with contractions\n    text = REPLACE_BY_SPACE.sub(' ', text)                 #replace punctuation with space\n    text = [word.strip() for word in text.split()]         #strip space from words\n    text = [word for word in text if len(word)>2]          #removing words less than 2 characters\n    text = [word for word in text if word!='amp']          #removing twitter amp\n    text = ' '.join(text)\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#preprocessing text column in train and test dataframes\ntrain_df['Tweet'] = train_df['OriginalTweet'].apply(preprocess_text)\ntest_df['Tweet'] = test_df['OriginalTweet'].apply(preprocess_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_wordcloud(data, mode='Tweet', sentiments='all'):\n    \n    \"\"\"\n    \n    Function that generates a wordcloud for a givens sentiment from a dataframe containing a text column\n    \n    Parameters\n    ----------\n    data: Pandas DataFrame\n        a pandas dataframe with a text column\n    mode: str, default='Tweet'\n        name of column in dataframe\n    sentiments: str, default='all'\n        The sentiment type for which to generate a wordcloud.\n        Must be one of ['all', 'positive', 'negative']\n    filter_common: boolean, default=False\n        Removes \n    \"\"\"\n    \n    \n    df = data.copy()\n    \n    if sentiments=='positive':\n        df = df[df.Sentiment.isin(['Positive', 'Extremely Positive'])]\n    if sentiments=='negative':\n        df = df[df.Sentiment.isin(['Negative', 'Extremely Negative'])]\n    \n     \n#     if mode=='OriginalTweet':\n#         text = ' '.join([i for i in text if not i.lower().startswith('#') and not i.lower().startswith('@') and not i.lower().startswith('https')])\n    if mode=='Tweet':\n        text = df[mode].str.split(' ').values\n        text = ' '.join([' '.join(i) for i in text])\n        text = text.strip()\n    else:\n        text = df[mode].values\n        text = ' '.join([' '.join(i) for i in text])\n        text = text.strip()\n\n    \n    cloud = WordCloud().generate(text)\n    plt.figure()\n    plt.imshow(cloud)\n    try:\n        plt.title(data.name)\n    except:\n        pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotting wordcloud for tweets of positive sentiments in training and testing dataframes\nfor df in [train_df, test_df]:\n    generate_wordcloud(df, mode='Tweet', sentiments='positive')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotting wordcloud for tweets of negative sentiments in training and testing dataframes\nfor df in [train_df, test_df]:\n    generate_wordcloud(df, mode='Tweet', sentiments='negative')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotting wordcloud for tweets of all sentiments in training and testing dataframes\nfor df in [train_df, test_df]:\n    generate_wordcloud(df, mode='Tweet', sentiments='all')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotting wordcloud of mentions of positive sentiments in training and testing dataframes\nfor df in [train_df, test_df]:\n    generate_wordcloud(df, mode='mentions', sentiments='positive')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotting wordcloud of mentions of negative sentiments in training and testing dataframes\nfor df in [train_df, test_df]:\n    generate_wordcloud(df, mode='mentions', sentiments='negative')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotting wordcloud of mentions of all sentiments in training and testing dataframes\nfor df in [train_df, test_df]:\n    generate_wordcloud(df, mode='mentions', sentiments='all')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_top_grams(dataframe, sentiment, n_grams=2, top=10):\n    \n    \"\"\"\n    Function that generates the top n_grams from a text column of dataframe that correspond to\n    a particular sentiment\n    \n    Parameters\n    ----------\n    dataframe: Pandas dataframe\n        dataframe with a text column\n    sentiments: str\n        The sentiment type for which to generate the top n_grams\n        Must be one of ['all', 'negative', 'positive']\n    n_grams: int, default=2\n        The number of grams to generate\n    top: int, default=10\n        The number of most common words to display\n    \"\"\"\n    \n    sentiments = ['Positive', 'Extremely Positive', 'Neutral', 'Negative', 'Extremely Negative']\n    \n    if sentiments!='all':\n        if sentiment=='positive':\n            sentiments = ['Positive', 'Extremely Positive']\n        if sentiment=='negative':\n            sentiments = ['Negative', 'Extremely Negative']\n\n    df = dataframe[dataframe['Sentiment'].isin(sentiments)]['Tweet'].str.split()\n    \n    text = [word for words_list in df.values for word in words_list]\n    \n    grams = nltk.ngrams(text, n=n_grams)\n    \n    dist = nltk.FreqDist(grams)\n    \n    print(dist.most_common(top))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#displaying top biggrams for positive tweets in training dataframe\nget_top_grams(train_df, 'positive')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#displaying top bigrams for negative tweets in training dataframe\nget_top_grams(train_df, 'negative')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#displaying top bigrams of positive tweets in testing dataframe\nget_top_grams(test_df, 'positive')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#display top bigrams of negative tweets in testing dataframe\nget_top_grams(test_df, 'negative')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#calculating number of unique words\nunique_words = set([word for word_list in train_df['Tweet'].str.split().values for word in word_list])\nnum_unique_words = len(unique_words)\nprint(num_unique_words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_NB_WORDS = 20000 #maximum number of words to take from corpus\nTokenizer = text.Tokenizer(num_words=MAX_NB_WORDS, oov_token='<oov>') #initializing tokenizer\nTokenizer.fit_on_texts(train_df['Tweet'].values) #fitting tokenizer on training_datase","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_to_ind = Tokenizer.word_index #extracting word to index mapping from tokenzier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#displaying word to index mapping\nword_to_ind","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting text sequences from training and testing dataframes\nX_train = Tokenizer.texts_to_sequences(train_df['Tweet'].values)\nX_test = Tokenizer.texts_to_sequences(test_df['Tweet'].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculating maximum length of sequences among both training and testing dataframes\nMAXLEN = max([len(x) for x in X_train] + [len(x) for x in X_test])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#adding padding of zeros to obtain uniform length for all sequences\nX_train_padded = sequence.pad_sequences(X_train, maxlen=MAXLEN)\nX_test_padded = sequence.pad_sequences(X_test, maxlen=MAXLEN)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#encoding sentiment labels\nY_train = train_df['Sentiment'].values\nY_test = test_df['Sentiment'].values\nencoder = LabelEncoder()\nY_train = encoder.fit_transform(Y_train)\nY_test = encoder.transform(Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#one-hot-encoding sentiment labels\nY_train_enc = to_categorical(Y_train)\nY_test_enc = to_categorical(Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(MAXLEN)\nprint(MAX_NB_WORDS)\nprint(Y_train_enc.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Model Construction**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# defining embedding dimension\nEMBEDDING_DIM = 32\nLSTM_NODES = 128","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#building sequential neural network\nmodel = Sequential()\nmodel.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=MAXLEN, mask_zero=True))\nmodel.add(SpatialDropout1D(0.5))\nmodel.add(LSTM(LSTM_NODES, dropout=0.2, recurrent_dropout=0.2))\nmodel.add(Dense(Y_train_enc.shape[1], activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#displaying model architecture\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#defining pr-auc metric\nauc = AUC(curve='PR')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#compiling model\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy', auc])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#training model\nhistory = model.fit(X_train_padded, Y_train_enc, validation_data=(X_test_padded, Y_test_enc), epochs=5, batch_size=256, use_multiprocessing=True, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model Evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"#evaluating model on test set\nY_pred = model.predict(X_test_padded)\nY_pred = np.argmax(Y_pred, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#extract labels from encoder\nlabels = list(encoder.classes_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#calculate and plot confusion matrix\ncm = confusion_matrix(Y_test, Y_pred)\nsns.heatmap(cm, annot=True, xticklabels=labels, yticklabels=labels, fmt='g')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#printing classification report\nprint(classification_report(Y_test, Y_pred, target_names=labels))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Trying again with 3 classes instead of 5"},{"metadata":{"trusted":true},"cell_type":"code","source":"#mapping 5 classes to 3 more specific classes\nmapping = {\n    \"Extremely Positive\": \"Positive\",\n    \"Extremely Negative\": \"Negative\",\n    \"Positive\": \"Positive\",\n    \"Neutral\": \"Neutral\",\n    \"Negative\": \"Negative\"\n}\n\n#encoding sentiment labels\n\nY_train = train_df['Sentiment'].values\nY_test = test_df['Sentiment'].values\n\nY_train = list(map(mapping.get, Y_train))\nY_test = list(map(mapping.get, Y_test))\n\nencoder = LabelEncoder()\nY_train = encoder.fit_transform(Y_train)\nY_test = encoder.transform(Y_test)\n\nY_train_enc = to_categorical(Y_train)\nY_test_enc = to_categorical(Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#building sequential neural network\nmodel = Sequential()\nmodel.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=MAXLEN, mask_zero=True))\nmodel.add(SpatialDropout1D(0.5))\nmodel.add(LSTM(LSTM_NODES, dropout=0.2, recurrent_dropout=0.2))\nmodel.add(Dense(Y_train_enc.shape[1], activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#compiling model\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy', auc])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fitting model\nhistory = model.fit(X_train_padded, Y_train_enc, validation_data=(X_test_padded, Y_test_enc), epochs=5, batch_size=256, use_multiprocessing=True, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#evaluating model on test set\nY_pred = model.predict(X_test_padded)\nY_pred = np.argmax(Y_pred, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#extract labels from encoder\nlabels = list(encoder.classes_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#calculate and plot confusion matrix\ncm = confusion_matrix(Y_test, Y_pred)\nsns.heatmap(cm, annot=True, xticklabels=labels, yticklabels=labels, fmt='g')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#printing classification report\nprint(classification_report(Y_test, Y_pred, target_names=labels))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}