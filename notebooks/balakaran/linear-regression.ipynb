{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"2c79dcc7-13c1-5f65-75dd-6daef63f0812"},"source":"Linear Regression - handling large volume of data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4ff32a06-b65f-1990-cfd6-e1855690a321"},"outputs":[],"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"08a263c3-4e51-15dd-589f-70bd1125b088"},"outputs":[],"source":"# generate 3 independent variables x1,x2,x3 randomly drawn from standardised normal \n# distributions but with positive correlations with the dependent variable y1.\n# The dependent variable is also randomly drawn from a standardised normal.\n\n# We also enforced a strong correlation between two independent variables x2, x3\n\nimport numpy.random as nr\nnr.seed()\ny = nr.normal(0,1, (10000) )\ndef correlatedValue (x, r):\n  r2 = r**2\n  ve = 1-r2\n  SD = np.sqrt(ve)\n  e  = nr.normal(0, SD, (x.size))\n  y  = r*x + e\n  return(y)\nx1 = correlatedValue(y, r=0.6)\nx2 = correlatedValue(y, r=0.8)\nx3 = correlatedValue(x2, r=0.9)\ncorx1y = np.corrcoef(y,x1) \ncorx2y = np.corrcoef(y,x2)\ncorx3y = np.corrcoef(y,x3) \ncorx2x3 = np.corrcoef(x2,x3)\nprint ('cor (x1,y) = ', corx1y[0,1])\nprint ('cor (x2,y) = ', corx2y[0,1])\nprint ('cor (x3,y) = ', corx3y[0,1])\nprint ('cor (x2,x3) =', corx2x3[0,1])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d6885fa6-5cfc-4f88-7d87-b9322e14c834"},"outputs":[],"source":"x=np.array([x1,x2,x3])\nfor i in [1,2,3] :\n    plt.subplot (2,2,i)\n    plt.scatter (x[i-1],y)\n    plt.xlabel ('x'+ str (i) + ' vs y')\nplt.subplot (2,2,4)    \nplt.scatter (x[1],x[2])\nplt.xlabel ('x2 vs x3')\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"1c66bde4-dd23-b769-0ac5-25e11860f525"},"source":"Training a linear regression --> estimating the regression coefficients.  How can we handle a large volume of training data that doesn't fit in the memory, while we are training a linear regression?\n\nOrdinary Least Squares (OLS) require all training data available in the memory to calculate statistics such as means, standard deviations, correlations and covariances."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"61adefd3-c010-ded7-d8c9-a6d762c79a4b"},"outputs":[],"source":"#OLS implementation\nfrom scipy import stats\nimport numpy as np\niv = x2\ndv = y\n\nslope, intercept, cor, p_value, std_err = stats.linregress(iv,dv)\n# To get coefficient of determination (r_squared)\nprint ('correlation= ', cor, 'r-squared= ', cor**2, 'slope= ', slope, 'intercept=', intercept )"},{"cell_type":"markdown","metadata":{"_cell_guid":"9601bc1e-9978-92d7-caf1-cb56a22913ea"},"source":"Alternatively one could use \"gradient descent\" method to train the linear regression.  In this method, not all the training data needs to be available in the memory at the same time.\n\nIn this situation, one could use PyTables with hdf5 data format.  For example,  PyTables allows us to quickly and easily deal with large volumes of on-disk data, while largely keeping the complexity of the data storage invisible to the downstream processing in NumPy and SciPy. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"de3c4435-4918-37c1-1a76-524544ed229c"},"outputs":[],"source":"import tables\nimport numpy\nivariable = x2\ndvariable = y\nhdf5_path = \"mydata.hdf5\"\nhdf5_file = tables.open_file(hdf5_path, mode='w')\niv_storage = hdf5_file.create_array(hdf5_file.root, 'iv', ivariable)\ndv_storage = hdf5_file.create_array(hdf5_file.root, 'dv', dvariable)\nhdf5_file.close()\n\nread_hdf5_file = tables.open_file(hdf5_path, mode='r')\nhdf5_ivariable = read_hdf5_file.root.iv[:]\nhdf5_dvariable = read_hdf5_file.root.dv[:]\nread_hdf5_file.close()\n\nslope, intercept, cor, p_value, std_err = stats.linregress(hdf5_ivariable, hdf5_dvariable)\nprint ('correlation= ', cor, 'r-squared= ', cor**2, 'slope=', slope, 'intercept=', intercept)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}