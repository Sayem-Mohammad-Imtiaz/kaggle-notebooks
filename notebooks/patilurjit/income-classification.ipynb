{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 1.Problem Statement\n\n### This is a binary classification problem where the target variable is whether a person's income is lower than or equal to 50K (<=50K) or higher than 50K (>50K). \n\n### The models that will be used include LogisticRegression, DecisionTreeClassifier, RandomForestClassifier and GradientBoostingClassifier. The accuracy for each of the models will be evaluated and the best performing model will be selected as the final model.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 2.Import Libraries","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split,GridSearchCV\nfrom sklearn.metrics import confusion_matrix,classification_report,plot_confusion_matrix\n\nfrom imblearn.over_sampling import SVMSMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n\nfrom yellowbrick.model_selection import FeatureImportances","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Ignore warnings","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3.Import Dataset","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/income-classification/income_evaluation.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4.Overview of the dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Column names","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### If you can see in the output above, there are unnecessary whitespaces present in the column names which may lead to an error while indexing the data in the further steps. Below, the whitespaces have been removed manually.\n\n#### Then, the hyphens in the column names have been replaced with underscores.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns = ['age','workclass','fnlwgt','education','education-num','marital-status','occupation','relationship','race','sex','capital-gain',\n              'capital-loss','hours-per-week','native-country','income']\n\ndf.columns = df.columns.str.replace('-','_')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dataset with the formatted column names","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Shape of the dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## General information about the features present in the dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Overview of the numerical columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Creating a list of the categorical variables for easy indexing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical = [var for var in df.columns if df[var].dtype=='O']\n\nprint(categorical)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Overview of the categorical variables","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df[categorical].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Checking the dataset for any missing values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### As seen in the output above, the dataset does not seem to have any missing data.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Creating a copy of the dataset for further processing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = df.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4.Exploratory Data Analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### In the following steps, each feature will be studied individually to get a better understanding about the dataset.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### The general trend of the exploration will be:\n1. Distplot for numerical data\n2. Checking unique categories in categorical data followed by a countplot ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data['income'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### As seen in the plot above, there is a moderate imbalance in the two classes of the target variable.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(data['age'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### The distplot does not give much information about the age variable. To gain some more insight, bins of age groups are created manually. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = ['10-20','20-30','30-40','40-50','50-60','60-70','70-80','80-90']\nbins = [10,20,30,40,50,60,70,80,90]\nfreq_df = data.groupby(pd.cut(data['age'],bins = bins,labels = labels)).size()\nfreq_df = freq_df.reset_index(name = 'count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.bar(freq_df['age'],freq_df['count'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### This plot seems better the previous distplot. \n#### As seen from the plot, most of the subjects are concentrated between the ages 20 to 60.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['workclass'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### When checked previously, there were no missing values but '?' is present as observations in the data.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Replace '?' with 'Unknown'","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['workclass'] = data.workclass.str.replace('?','Unknown')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data['workclass'])\nplt.xticks(rotation = 90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### As seen in the data, majority of the 'workclass' is 'Private'. Some of the categories have very few observations and lead to an unnecessary increase in the cardinality of the variable. The problem of cardinality will be addressed later.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(data['fnlwgt'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### I could not find more information about this variable anywhere so I don't exactly know what it represents.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['education'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data['education'])\nplt.xticks(rotation = 90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The variable 'education' also has a lot of categories with most of the data being concentrated in specific categories. This variable also has high cardinality.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['education_num'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data['education_num'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The same trend is seen in the 'education_num' variable as most of the data is concentrated in specific categories.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['marital_status'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data['marital_status'])\nplt.xticks(rotation = 90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The 'marital_status' variable also exhibits the same trend. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['occupation'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### This variable also contains '?' as observations.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Replacing '?' with unknown","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['occupation'] = data.occupation.str.replace('?','Unknown')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data['occupation'])\nplt.xticks(rotation = 90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The variable 'occupation' also exhibits high cardinality.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['relationship'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data['relationship'])\nplt.xticks(rotation = 90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['race'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data['race'])\nplt.xticks(rotation = 90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Most of the subjects are white.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['sex'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data['sex'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Male subjects are more than female subjects.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['capital_loss'].value_counts().nlargest(15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Out of the 32561 observations, 31042 are 0.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['capital_gain'].value_counts().nlargest(15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Out of the 32561 observations, 29849 are 0.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['native_country'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['native_country'] = data.native_country.str.replace('?','Unknown')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data['native_country'])\nplt.xticks(rotation = 90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The 'native_country' variable has 42 categories and most of the data is concentrated in the 'United States' category. This is a very high number and will affect the accuracy of the model. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 5.Baseline Models","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Models fill be fit on the raw data to get a baseline for each model. This will help in understanding if the models improved after performing some feature engineering.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Seperating the data into dependent and independent variables","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x = data.drop('income',axis = 1)\ny = data['income']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### As some of the independent variables are categorical, they have to be converted into numerical data as the models require the data to be numeric for fitting. There are multiple ways to do this and here the 'pd.getdummies()' function is used. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x_dummy = pd.get_dummies(x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train-Test Split","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_test,y_train,y_test = train_test_split(x_dummy,y,test_size = 0.2,random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Defining a function to evalute the models\n\n#### This is not a necessary step but makes process easier as it prevents from writing the same lines of code for every model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def fit_model(model,x,y):\n    model.fit(x,y)\n    y_pred = model.predict(x_test)\n    print(\"Accuracy: \",model.score(x_test,y_test))\n    print(\"------------------------------\")\n    print(\"Classification Report\")\n    print(\"------------------------------\")\n    print(classification_report(y_test,y_pred))\n    print(\"------------------------------\")\n    print(\"Confusion Matrix\")\n    print(\"------------------------------\")\n    print(confusion_matrix(y_test,y_pred))\n    print(\"------------------------------\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression(max_iter = 1000)\n\nfit_model(lr,x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Logistic Regression gives an accuracy of 0.79.\n\nThe precision and recall for the majority class (<=50K) in the target varible is good but is not satisfactory for the minority class (>50K).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Decision Tree Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dtree = DecisionTreeClassifier()\n\nfit_model(dtree,x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Decision Tree gives an accuracy of 0.81.\n\nThe precision and recall for the majority class (<=50K) in the target varible is good and there is an improvment in the minority class (>50K) as compared to Logistic Regression.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Random Forest Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(random_state = 0)\n\nfit_model(rf,x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random Forest gives an accuracy of 0.84.\n\nThere is also an improvement in the precision of the minority class (>50K).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Gradient Boosting Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"gbm = GradientBoostingClassifier(random_state = 0)\n\nfit_model(gbm,x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Gradient Boosting Classifier gives an accuracy of 0.86.\n\nThere is also an improvement in the precision and recall.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### This was the performance of the models on the data without any transformations. After, performing transformations on the data it is expected that the accuracy of the models will increase.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 6.Reducing the cardinality of variables","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### During the initial analysis it was seen that some of the variables have a lot of categories while the data is concentrated in specific categories and some of the categories have very less data.The presence of a large number of categories affects the accuracy of the model.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The variables with high cardinality were:\n1. workclass\n2. education\n3. education_num\n4. marital_status\n5. occupation\n6. race\n7. native_country","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In the following steps, the cardinality of the variables will be reduced individually.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"All the categories with less than 5% of the data will be clubbed together as one category called 'Other'.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data1 = data.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1['workclass'].value_counts() / len(data1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"names = ['State-gov','Self-emp-inc','Federal-gov','Without-pay','Never-worked']\n\nfor i in names:\n    data1['workclass'] = data1.workclass.str.replace(i,'Other')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax =plt.subplots(1,2,figsize = (25,10))\nsns.countplot(data['workclass'],ax = ax[0])\nsns.countplot(data1['workclass'],ax = ax[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"'workclass' reduced from 9 categories to 5 categories.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"names1 = ['11th','9th','7th-8th','5th-6th','10th','1st-4th','Preschool','12th']\n\nfor i in names1:\n    data1['education'] = data1.education.str.replace(i,'Non Graduate')\n    \nnames2 = ['Assoc-acdm','Assoc-voc','Doctorate','Prof-school']\n\nfor i in names2:\n    data1['education'] = data1.education.str.replace(i,'Other')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax =plt.subplots(1,2,figsize = (25,10))\nsns.countplot(data['education'],ax = ax[0])\nsns.countplot(data1['education'],ax = ax[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"'education' reduced from 16 categories to 6 categories.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"'education_num' has categories from 1 to 16. The categories will be binned into 4 seperate categories each category containing 4 categories serially.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"names1 = [1,2,3,4]\n\nfor i in names1:\n    data1['education_num'] = data1.education_num.replace(i,'1-4')\n    \nnames2 = [5,6,7,8]\n\nfor i in names2:\n    data1['education_num'] = data1.education_num.replace(i,'5-8')\n    \nnames3 = [9,10,11,12]\n\nfor i in names3:\n    data1['education_num'] = data1.education_num.replace(i,'9-12')\n    \nnames4 = [13,14,15,16]\n\nfor i in names4:\n    data1['education_num'] = data1.education_num.replace(i,'13-16')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax =plt.subplots(1,2,figsize = (25,10))\nsns.countplot(data['education_num'],ax = ax[0])\nsns.countplot(data1['education_num'],ax = ax[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"'education_num' reduced from 16 categories to 4 categories.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data1['marital_status'].value_counts() / len(data1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"names = ['Married-spouse-absent','Separated','Married-AF-spouse','Widowed']\n\nfor i in names:\n    data1['marital_status'] = data1.marital_status.str.replace(i,'Other')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax =plt.subplots(1,2,figsize = (25,10))\nsns.countplot(data['marital_status'],ax = ax[0])\nsns.countplot(data1['marital_status'],ax = ax[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"'marital_status' reduced from 7 categories to 4 categories.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data1['occupation'].value_counts() / len(data1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"names = ['Handlers-cleaners','Transport-moving','Farming-fishing','Tech-support','Protective-serv','Armed-Forces','Priv-house-serv']\n\nfor i in names:\n    data1['occupation'] = data1.occupation.str.replace(i,'Other')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax =plt.subplots(1,2,figsize = (25,10))\nsns.countplot(data['occupation'],ax = ax[0])\nsns.countplot(data1['occupation'],ax = ax[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"'occupation' reduced from 15 categories to 9 categories.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data1['race'].value_counts() / len(data1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"names = ['Asian-Pac-Islander','Amer-Indian-Eskimo','Other']\n\nfor i in names:\n    data1['race'] = data1.race.str.replace(i,'Other')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax =plt.subplots(1,2,figsize = (25,10))\nsns.countplot(data['race'],ax = ax[0])\nsns.countplot(data1['race'],ax = ax[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"'race' reduced from 5 categories to 3 categories.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data1['native_country'].value_counts() / len(data1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"na = ['Cuba','Jamaica','Puerto-Rico','Honduras','Haiti','Dominican-Republic','El-Salvador','Guatemala','Nicaragua','United-States',\n      'Mexico','Canada']\n\nfor i in na:\n    data1['native_country'] = data1.native_country.str.replace(i,'NAmerica')\n    \ndata1['native_country'] = data1.native_country.str.strip().replace('Outlying-US(Guam-USVI-etc)','Outlying-US')\ndata1['native_country'] = data1.native_country.str.replace('Outlying-US','NAmerica')\n\nsa = ['Trinadad&Tobago','Columbia','Ecuador','Peru']\n\nfor i in sa:\n    data1['native_country'] = data1.native_country.str.replace(i,'SAmerica')\n    \nai = ['India','South','Iran','Philippines','Cambodia','Thailand','Laos','Taiwan','China','Japan','Vietnam','Hong']\n\nfor i in ai:\n    data1['native_country'] = data1.native_country.str.replace(i,'Asia')\n    \neu = ['England','Germany','Italy','Poland','Portugal','France','Yugoslavia','Scotland','Greece','Ireland','Hungary','Holand-Netherlands']\n\nfor i in eu:\n    data1['native_country'] = data1.native_country.str.replace(i,'Europe')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1.rename(columns = {'native_country':'region'}, inplace = True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax =plt.subplots(1,2,figsize = (25,10))\nsns.countplot(data['native_country'],ax = ax[0])\nsns.countplot(data1['region'],ax = ax[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"'native_country' reduced from 42 categories to 5 categories","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 7.Evaluating models on updated dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x = data1.drop('income',axis = 1)\ny = data1['income']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_dummy = pd.get_dummies(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_test,y_train,y_test = train_test_split(x_dummy,y,test_size = 0.2,random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression(max_iter = 1000)\n\nfit_model(lr,x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### The accuracy of the model improved from 0.79 to 0.83 with an increase in the precision and recall of the minority class (>50K) too.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dtree = DecisionTreeClassifier()\n\nfit_model(dtree,x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### The accuracy of the decision tree decreased by a small margin but it can be improved by tuning the hyperparameters.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(random_state = 0)\n\nfit_model(rf,x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### The accuracy of random forest also decreased by a small margin but it can be increased.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"gbm = GradientBoostingClassifier(random_state = 0)\n\nfit_model(gbm,x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### The accuracy of gradient boosting classifier improved with an improvement in the precision of the minority class (>50K).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### After reducing the cardinality of the variables:\n1. Accuracy of Logistic Regression improved significantly\n2. Accuracy of Decision Tree Classifier reduced by a small margin\n3. Accuracy of Random Forest Classifier reduced by a small margin\n4. Accuracy of Gradient Boosting Classifier improved by a small margin","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 8.Hyperparameter Tuning","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression","execution_count":null},{"metadata":{},"cell_type":"markdown","source":" #### Checking for the best value of solver","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#param_grid = {'solver':['newton-cg','lblinear','lbfgs']}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lr = LogisticRegression(max_iter = 1000)\n\n#gs = GridSearchCV(lr,param_grid,cv = 5,scoring = 'accuracy',n_jobs = -1,verbose = True)\n\n#gs.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#gs.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 'newton-cg' is the best performing solver","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Checking for the best value of penalty and C","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#param_grid = {'penalty':['l1','l2'],\n              #'C':[100.0,10.0,1.0,0.1,0.01]\n    \n#}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lr = LogisticRegression(solver = 'newton-cg',penalty = 'l2',max_iter = 1000)\n\n#gs = GridSearchCV(lr,param_grid,cv = 5,scoring = 'accuracy',n_jobs = -1,verbose = True)\n\n#gs.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#gs.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Best performing values of 'C' and 'penalty' are 0.1 and l2 respectively.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression(C = 0.1,solver = 'newton-cg',penalty = 'l2',max_iter = 1000)\n\nfit_model(lr,x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### The accuracy of Logistic Regression improved from 0.832 to 0.846 after tuning the hyperparameters.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Decision Tree Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#param_grid = {'criterion':['gini','entropy'],\n              #'splitter':['best','random'],\n              #'max_features':['auto','sqrt','log2'],\n              #'max_depth': np.arange(2,7,1),\n              #'min_samples_split': np.arange(2,10,1),\n              #'min_samples_leaf': np.arange(2,7,1)\n#}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dtree = DecisionTreeClassifier()\n\n#gs = GridSearchCV(dtree,param_grid,cv = 5,scoring = 'accuracy',n_jobs = -1,verbose = True)\n\n#gs.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#gs.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtree = DecisionTreeClassifier(criterion = 'gini',max_depth = 6,max_features = 'auto',min_samples_leaf = 4,min_samples_split = 5,\n                               splitter = 'best')\n\nfit_model(dtree,x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### The accuracy of Decision Tree Classifier improved from 0.807 to 0.823 after tuning the hyperparameters.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Random Forest Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#param_grid = {'criterion':['gini','entropy'],\n              #'bootstrap': [True,False],\n              #'n_estimators':[10,100,200,500,1000],\n              #'max_features':['auto','sqrt','log2'],\n              #'max_depth': [2,3,4,5,6,7,None],\n              #'min_samples_split': np.arange(2,10,1),\n              #'min_samples_leaf': np.arange(2,7,1)\n#}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#rf = RandomForestClassifier(random_state = 0)\n\n#gs = GridSearchCV(rf,param_grid,cv = 5,scoring = 'accuracy',n_jobs = -1,verbose = True)\n\n#gs.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#gs.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(bootstrap =True,criterion = 'entropy',max_depth = None,min_samples_leaf = 2,min_samples_split = 100,\n                            max_features = 17,n_estimators = 10,random_state = 0)\n\nfit_model(rf,x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### The accuracy of Random Forest Classifier improved from 0.847 to 0.858 after tuning the hyperparameters.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Gradient Boosting Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#param_grid = {'n_estimators':range(20,81,10),\n              #'max_depth':range(5,16,2),\n              #'min_samples_split':range(1000,2100,200),\n              #'min_samples_leaf':range(30,71,10),\n              #'max_features':[range(7,20,2),None],\n              #'subsample':[0.6,0.7,0.75,0.8,0.85,0.9]\n             #}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#gbm = GradientBoostingClassifier(n_estimators = 80,max_depth = 13,min_samples_split = 1000,min_samples_leaf = 30,max_features = None,\n                                 #random_state = 0)\n\n#gs = GridSearchCV(gbm,param_grid,cv = 5,scoring = 'accuracy',n_jobs = -1,verbose = True)\n\n#gs.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#gs.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gbm = GradientBoostingClassifier(n_estimators = 80,max_depth = 13,min_samples_split = 1000,min_samples_leaf = 30,max_features = None,\n                                 random_state = 0)\n\nfit_model(gbm,x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### The accuracy of Gradient Boosting Classifier increased from 0.861 to 0.865 after tuning the hyperparameters. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 9.Conclusion","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### The best performing model among the 4 models was the Gradient Boosting Classifier with an accuracy of 0.865.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Classification report and confusion matrix of the best performing model ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(plot_confusion_matrix(gbm,x_test,y_test))\nprint(classification_report(y_test,gbm.predict(x_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Importance","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (12,8)\nplt.style.use(\"ggplot\")\n\ngbm = GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n                           learning_rate=0.08, loss='deviance', max_depth=5,\n                           max_features=None, max_leaf_nodes=None,\n                           min_impurity_decrease=0.0, min_impurity_split=None,\n                           min_samples_leaf=30, min_samples_split=1000,\n                           min_weight_fraction_leaf=0.0, n_estimators=80,\n                           n_iter_no_change=None, presort='deprecated',\n                           random_state=0, subsample=1.0, tol=0.0001,\n                           validation_fraction=0.1, verbose=0,\n                           warm_start=False)\n\nviz = FeatureImportances(gbm)\nviz.fit(x_train, y_train)\nviz.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### I hope you found the kernel useful. Any suggestions or improvements are welcome.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}