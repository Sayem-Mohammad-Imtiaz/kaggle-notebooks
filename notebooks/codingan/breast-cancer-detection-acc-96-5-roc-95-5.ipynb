{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nnp.set_printoptions(precision=4)\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score , confusion_matrix, f1_score, roc_auc_score\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import GridSearchCV\nfrom IPython.display import display,Markdown,HTML\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/breast-cancer-wisconsin-data/data.csv')\ndf.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop(['id','Unnamed: 32'],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['diagnosis'] = [1 if x == 'M' else 0 for x in df['diagnosis']]\ndf['diagnosis']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_negative = \"Negative\"\ntext_positive = \"Positive\"\ntarget_column = \"diagnosis\"\n\ndf_all = df.copy()\n\ndf_positive = df[df[target_column]==1]\n\ndf_negative = df[df[target_column]==0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_pie(column, title=\"All Group/Class\"):\n    fig,axs = plt.subplots(1,1)\n    data = df_all[column].value_counts()\n    plt.pie(data,autopct='%1.2f%%',labels=data.index)\n    plt.title(title)\n    plt.show()\n    \ndef plot_hist(column, title=\"All Group/Class\"):\n    plt.hist(df_all[column],density=True)\n    plt.title(title)\n    plt.show()\n\ndef plot_bar(column, sort=False, title=\"All Group/Class\"):\n    if sort:\n        data_all = df_all[column].value_counts().sort_index()\n    else:\n        data_all = df_all[column].value_counts()\n    plt.bar(data_all.index.astype(str),data_all)\n    plt.title(title)\n    plt.show()\n    \ndef plot_bar_compare(column, sort=False):\n    if sort:\n        data_positive = df_positive[column].value_counts().sort_index()\n        data_negative = df_negative[column].value_counts().sort_index()\n    else:\n        data_positive = df_positive[column].value_counts()\n        data_negative = df_negative[column].value_counts()\n    \n    fig,axs = plt.subplots(2,1)\n    plt.subplots_adjust(left=0, bottom=0, right=1, top=2, wspace=0, hspace=0.2)\n    axs[0].bar(data_negative.index.astype(str),data_negative)\n    axs[0].title.set_text(text_negative)\n    axs[1].bar(data_positive.index.astype(str),data_positive)\n    axs[1].title.set_text(text_positive)\n    plt.show()\n\ndef plot_hist_compare(column, bins=5):\n    plt.hist([df_negative[column], df_positive[column]] , color=['c','r'])\n    plt.legend((text_negative, text_positive))\n    plt.show()\n    \ndef plot_pie_compare(column):\n    data_positive = df_positive[column].value_counts()\n    data_negative = df_negative[column].value_counts()\n    \n    fig,axs = plt.subplots(2,1)\n    plt.subplots_adjust(left=0, bottom=0, right=1, top=2, wspace=0, hspace=0.2)\n    axs[0].pie(data_negative,autopct='%1.2f%%',labels=data_negative.index)\n    axs[0].title.set_text(text_negative)\n    axs[1].pie(data_positive,autopct='%1.2f%%',labels=data_positive.index)\n    axs[1].title.set_text(text_positive)\n    plt.show()\n\ndef plot_boxplot(column, title=\"\"):\n    ax = sns.boxplot(x=target_column, y=column, palette=[\"c\", \"r\"],\n            hue=target_column,  data=df_all).set_title(title, fontsize=15)\n    plt.show()\n\ndef check_median(column):\n    data_negative = df_negative[column].describe()\n    data_positive = df_positive[column].describe()\n    print(\"Median:\")\n    print('{}: {}'.format(text_negative,data_negative['50%']))\n    print('{}: {}'.format(text_positive,data_positive['50%']))\n\ndef check_most(column):\n    data_negative = df_negative[column].value_counts()\n    data_positive = df_positive[column].value_counts()\n    print(\"Most:\")\n    print('{}: {}'.format(text_negative,data_negative.index[0]))\n    print('{}: {}'.format(text_positive,data_positive.index[0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eda(df_all):\n    display(HTML('<h1>Exploratory Data Analysis<h1>'))\n    \n    for column in df_all.columns:\n        if column == target_column:\n            continue\n        display(HTML('<h2>{}<h2>'.format(column)))\n        if df[column].dtype == 'int64' or df[column].dtype == 'float64':\n            if len(df[column].unique())>10 :\n                plot_boxplot(column)\n                check_median(column)\n            else:\n                plot_bar(column)\n                plot_pie(column)\n                plot_pie_compare(column)\n                check_most(column)\n        elif df[column].dtype == 'object':\n            if len(df[column].unique())>10 :\n                df[column].value_counts().head(5)\n            else:\n                plot_bar(column)\n                plot_pie(column)\n                plot_pie_compare(column)\n                check_most(column)\n        else:\n            None","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['diagnosis'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_pie('diagnosis')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eda(df_all)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = df.corr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data.sort_values(by='diagnosis',ascending=False)\ndata['diagnosis']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[data['diagnosis']>0.5].index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"X = df.copy()\n\ny = X['diagnosis']\n\nX = X.drop(['diagnosis'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1234)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\nsm = SMOTE(random_state=1234)\n\nX_sm, y_sm = sm.fit_resample(X_train, y_train)\n\nprint(f'''Shape of X before SMOTE: {X.shape}\nShape of X after SMOTE: {X_sm.shape}''')\n\nprint('\\nBalance of positive and negative classes (%):')\ny_sm.value_counts(normalize=True) * 100","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\n\nX_sm = sc.fit_transform(X_sm)\nX_test = sc.transform(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import ML Libraries\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.svm import SVC\nfrom catboost import CatBoostClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nclassifiers = [[CatBoostClassifier(verbose=0),'CatBoost Classifier'],[XGBClassifier(eval_metric='error'),'XGB Classifier'], [RandomForestClassifier(),'Random Forest'], \n    [KNeighborsClassifier(), 'K-Nearest Neighbours'], [SGDClassifier(),'SGD Classifier'], [SVC(),'SVC'],[LGBMClassifier(),'LGBM Classifier'],\n              [GaussianNB(),'GaussianNB'],[DecisionTreeClassifier(),'Decision Tree Classifier'],[LogisticRegression(),'Logistic Regression'],[AdaBoostClassifier(),\"AdaBoostClassifier\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for cls in classifiers:\n    model = cls[0]\n    model.fit(X_sm, y_sm)\n    \n    y_pred = model.predict(X_test)\n    print(cls[1])\n    print ('Confusion Matrix:')\n    print(confusion_matrix(y_test, y_pred))\n    print(\"Accuracy : \", accuracy_score(y_test, y_pred) *  100)\n    print(\"Recall : \", recall_score(y_test, y_pred) *  100)\n    print(\"Precision : \", precision_score(y_test, y_pred) *  100)\n    print(\"F1 : \", f1_score(y_test, y_pred) *  100)\n    print(\"ROC AUC : \", roc_auc_score(y_test, y_pred) *  100)\n    print('\\n\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Best Algorithms for predicting breast cancer are **SGD Classifier**, **SVC** , and **Logistic Regression**\n\n* Accuracy :  96.49122807017544\n* Recall :  91.11111111111111\n* Precision :  100.0\n* F1 :  95.34883720930233\n* ROC AUC :  95.55555555555554","metadata":{}}]}