{"cells":[{"metadata":{"_uuid":"8c90371e9853dd251201824ff94ec8de8c20df7d"},"cell_type":"markdown","source":"Take all 8123 samples in mushrooms.csv with edible and poisonous mushrooms. Draw a dendrogram of a hierarchical clustering by Orange3 software. In the dendrogram, we will select all poisonous samples. In the dendrogram, we can see that all poisonous samples are together in the same groups.\n![Image of dendogram](https://raw.githubusercontent.com/kopylovvlad/mushroom_classification/master/h_clust.png)"},{"metadata":{"_uuid":"384225ad7326cb9dc277155b49748a4259574206"},"cell_type":"markdown","source":"And now, we can assume how to write simple classifier. Split all samples into train and test subsets. Transform each sample-data to vector.  Take one sample from test subset and find 3 nearest vectors from train subset. If 2 samples from 3 nearest vectors have 'edible' class, we can assume, that sample from test subset is edible too. If 2 samples from 3 nearest vectors have 'poisonous' class, we can expect, that sample from test subset is poisonous too. "},{"metadata":{"_uuid":"942bb258a26f373a6074dc3a10fe00602e5c55f4"},"cell_type":"markdown","source":"Implementation for first step:\n* Open csv-file\n* Convert raw csv-data to dataset of vectors\n* Get train subset (for example, 100 samples)\n* Save train dataset to file\n\nThe code in python3.6 below:\n"},{"metadata":{"trusted":true,"_uuid":"b1677cd46b8d1d2ff2448b31e31a118c71afb07e"},"cell_type":"code","source":"from typing import List, Dict, Tuple\nimport clusters\nimport csv_helper as csv_h\nimport os\nimport argparse\nimport pickle\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\"-l\", '--limit', help='Csv row limit', type=int)\narguments = parser.parse_args()\ncsv_row_limit: int = arguments.limit or 100  # 8120\n\nprint('csv_limit is: %d' % csv_row_limit)\n\ndirname: str = os.path.dirname(os.path.abspath(__file__))\nitem_names, props, data = csv_h.csv_to_vector(dirname + '/mushrooms.csv')\n\ndata = data[:csv_row_limit]\nitem_names = item_names[:csv_row_limit]\nprint('We have %d train items' % len(data))\n\nf = open(dirname + '/tmp_data/mushrooms_data_vector1.pickle', 'wb')\npickle.dump((item_names, props, data), f)\nf.close()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e3764e6d0e132022cbeffe5cdda5bd4c7ac79abb"},"cell_type":"markdown","source":"Implementation for second step:\n* Open csv-file\n* Convert raw csv-data to dataset of vectors\n* Get test subset (for example, other 100 samples)\n* Pick samples one by one from test subset and find 3 nearest vectors from train subset\n* Check is predicted class eqial to real data (edible or poisonous)\n\nThe code in python3.6 below:"},{"metadata":{"trusted":true,"_uuid":"5d32d5fdda2a1e429bb60555fc48499ff4602581"},"cell_type":"code","source":"from typing import List, Dict\nimport clusters\nimport os\nimport csv\nimport argparse\nimport csv_helper as csv_h\nimport pickle\nimport sys\n\n#\n# prepare data\n#\n\ndirname: str = os.path.dirname(os.path.abspath(__file__))\nparser = argparse.ArgumentParser()\nparser.add_argument(\"-l\", '--limit', help='Csv row limit', type=int)\nparser.add_argument(\"-o\", '--offset', help='Offset limit', type=int)\narguments = parser.parse_args()\ncsv_row_limit: int = arguments.limit or 100  # 8120\noffset: int = arguments.offset or 100  # 8120\nprint('csv_limit is: %d' % csv_row_limit)\nprint('offset is: %d' % offset)\n\n\n#\n# prepare csv\n#\n\nprint('Opening csv ... ', end='')\nfile_path: str = dirname + '/mushrooms.csv'\ntest_item_names: List[str]\n_props: List[str]\ntest_data: List[List[int]]\ntest_item_names, _props, test_data = csv_h.csv_to_vector(file_path)\ndel _props\n\ntest_item_names = test_item_names[offset:][:csv_row_limit]\ntest_data = test_data[offset:][:csv_row_limit]\nprint('end')\n\nprint('We have %d test_items' % len(test_data))\n\n#\n# pickling\n#\n\nprint('Pickling ... ', end='')\nf = open(dirname + '/tmp_data/mushrooms_data_vector1.pickle', 'rb')\nknow_item_names, know_props, know_data = pickle.load(f)\nf.close()\n\nprint('Train data items: %d' % len(know_data))\n\n\ndef p_e_verict(three_item: List[str]) -> str:\n    p_size: int = 0\n    e_size: int = 0\n    for name in three_item:\n        word: str = name[len(name)-1]\n        if word == 'p':\n            p_size += 1\n        elif word == 'e':\n            e_size += 1\n        else:\n            raise BaseException('word is not into [p,e]')\n\n    if p_size > e_size:\n        return 'p'\n    else:\n        return 'e'\n\n\n#\n# processing\n#\ncassify_data: List[str] = []\nfor i in range(len(test_data)):\n    test_name: str = test_item_names[i]\n    test_row = test_data[i]\n    three_closest_name: List[str] = []  # list with names\n    three_closest_name = clusters.get_three_closest_names(\n        test_row,\n        know_item_names,\n        know_data,\n        distance=clusters.tanimoto_coeff\n    )\n    cassify_data.append(p_e_verict(three_closest_name))\n\n\n#\n# checking\n#\nstat: Dict[str, int] = {\n    'equal': 0,\n    'not_equal': 0\n}\nprint('Checking ... ', end='')\nfor i in range(len(test_data)):\n    test_full_name: str = test_item_names[i]\n    test_name = test_full_name[len(test_full_name) - 1]\n    predict_name: str = cassify_data[i]\n\n    if predict_name == test_name:\n        stat['equal'] = stat['equal'] + 1\n    else:\n        stat['not_equal'] = stat['not_equal'] + 1\nprint('')\n\nprint('Equal is: %d' % stat['equal'])\nprint('Not equal is: %d' % stat['not_equal'])\ndivisor: float = (stat['equal'] + stat['not_equal']) / 100\n\nif divisor == 0:\n    print('Accuracy is 0')\nelse:\n    print('Accuracy is %f' % (stat['equal'] / divisor))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dc28b4d3e1aa17e19381c074b0f4f6667c889947"},"cell_type":"markdown","source":"Let's run the scripts. For train subset, I choose 3500 samples. For test subset I decided to experiment with 3 sets (1000, 3500 and 4600 samples).\n\nResults are:\n* For 3500 train samples and 1000 test samples (aspect ratio - 7:2), accuracy is **97.9%**\n* For 3500 train samples and 3500 test samples (aspect ratio - 1:1), accuracy is **77.6%**\n* For 3500 train samples and 4600 test samples (aspect ratio - 7:9,2), accuracy is **71.5%**"},{"metadata":{"_uuid":"4c016976515d00723da6ff65f82f3d6ab1cbbbb2"},"cell_type":"markdown","source":"It works. This is my first experiment from scratch and python3.6. Source code is available in github. \n\nGithub link to [source code](https://github.com/kopylovvlad/mushroom_classification)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}