{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Predicting Heart Disease Using Machine Learning\n\nThis notebook looks into using various machine learning and data science libraries in an attempt to build a machine learning model capable of predicting whether or not someone has heart disease based on their medical attributes."},{"metadata":{},"cell_type":"markdown","source":"## Data Attribute Information\n\n* age - age in years\n* sex - (1 = male; 0 = female)\n* cp - chest pain type\n    * 0: Typical angina: chest pain related decrease blood supply to the heart\n    * 1: Atypical angina: chest pain not related to heart\n    * 2: Non-anginal pain: typically esophageal spasms (non heart related)\n    * 3: Asymptomatic: chest pain not showing signs of disease\n* trestbps - resting blood pressure (in mm Hg on admission to the hospital)\n    anything above 130-140 is typically cause for concern\n* chol - serum cholestoral in mg/dl\n    serum = LDL + HDL + .2 * triglycerides\n    above 200 is cause for concern\n* fbs - (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n    '>126' mg/dL signals diabetes\n* restecg - resting electrocardiographic results\n    * 0: Nothing to note\n    * 1: ST-T Wave abnormality\n        can range from mild symptoms to severe problems\n        signals non-normal heart beat\n    * 2: Possible or definite left ventricular hypertrophy\n        Enlarged heart's main pumping chamber\n* thalach - maximum heart rate achieved\n* exang - exercise induced angina (1 = yes; 0 = no)\n* oldpeak - ST depression induced by exercise relative to rest\n    looks at stress of heart during excercise\n    unhealthy heart will stress more\n* slope - the slope of the peak exercise ST segment\n    * 0: Upsloping: better heart rate with excercise (uncommon)\n    * 1: Flatsloping: minimal change (typical healthy heart)\n    * 2: Downslopins: signs of unhealthy heart\n* ca - number of major vessels (0-3) colored by flourosopy\n    colored vessel means the doctor can see the blood passing through\n    the more blood movement the better (no clots)\n* thal - thalium stress result\n    * 1,3: normal\n    * 6: fixed defect: used to be defect but ok now\n    * 7: reversable defect: no proper blood movement when excercising\n* target - have disease or not (1=yes, 0=no) (= the predicted attribute)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Importing the tools that we'll use\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Model evaluations\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom sklearn.metrics import plot_roc_curve\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/heart-disease-uci/heart.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['target'].value_counts().plot(kind='bar', color=['salmon', 'lightblue'], xlabel='Target', ylabel='Count');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Percentage of patients that have heart disease\ndf['target'].value_counts(normalize=True) * 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check to see if we have any missing values\ndf.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Heart Disease Frequency for Sex\npd.crosstab(df['target'], df['sex']).plot(kind='bar', figsize=(10, 6), color=['salmon', 'lightblue'])\nplt.title('Heart Disease Frequency for Sex')\nplt.xlabel('0: No Disease, 1: Disease')\nplt.ylabel('Amount')\nplt.legend(['Female', 'Male'])\nplt.xticks(rotation=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\n\n# Positve examples\nplt.scatter(df.age[df.target==1], \n            df.thalach[df.target==1], \n            c=\"salmon\")\n\n# Negative examples\nplt.scatter(df.age[df.target==0], \n            df.thalach[df.target==0], \n            c=\"lightblue\")\n\nplt.title(\"Heart Disease in function of Age and Max Heart Rate\")\nplt.xlabel(\"Age\")\nplt.legend([\"Disease\", \"No Disease\"])\nplt.ylabel(\"Max Heart Rate\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(df.cp, df.target).plot(kind=\"bar\", figsize=(10, 6), color=[\"lightblue\", \"salmon\"]);\nplt.title(\"Heart Disease Frequency Per Chest Pain Type\")\nplt.xlabel(\"Chest Pain Type\")\nplt.ylabel(\"Amount\")\nplt.legend([\"No Disease\", \"Disease\"])\nplt.xticks(rotation=0);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation Matrix\ncorr_matrix = df.corr()\nfig, ax = plt.subplots(figsize=(15, 10))\nax = sns.heatmap(corr_matrix, annot=True, linewidths=0.5, fmt=\".2f\", cmap=\"YlGnBu\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Turning Categorical variables into Dummy variables\ncp = pd.get_dummies(df['cp'], prefix = \"cp\")\nthal = pd.get_dummies(df['thal'], prefix = \"thal\")\nslope = pd.get_dummies(df['slope'], prefix = \"slope\")\nrestecg = pd.get_dummies(df['restecg'], prefix = \"restecg\")\nframes = [df, cp, thal, slope, restecg]\ndf = pd.concat(frames, axis = 1)\ndf = df.drop(columns = ['cp', 'thal', 'slope', 'restecg'])\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting the data into X and y and to train and test \nX = df.drop('target', axis=1)\ny = df['target']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape, X_test.shape, y_train.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Put models in a dictionary\nmodels = {\"Logistic Regression\": LogisticRegression(),\n         \"KNN\": KNeighborsClassifier(),\n         \"Random Forest\": RandomForestClassifier()}\n\n# Create a function to fit and score models\ndef fit_and_score(models, X_train, X_test, y_train, y_test):\n    \"\"\"\n    Fits and evaluatest given machine learning models. \n    models: a dict of different Scikit-Learn machine learning models\n    X_train: training data (no labels)\n    X_test: testing data (no labels)\n    y_train: training labels\n    y_test: testing labels\n    \"\"\"\n    # Set random seed \n    np.random.seed(42)\n    \n    # Make a dictionary to keep model scores\n    model_scores = {}\n    \n    for name, model in models.items():\n        model.fit(X_train, y_train)\n        model_scores[name] = model.score(X_test, y_test)\n    return model_scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_scores = fit_and_score(models=models, \n                             X_train=X_train, \n                             X_test=X_test, \n                             y_train=y_train, \n                             y_test=y_test)\nmodel_scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model comparison\nmodel_compare = pd.DataFrame(model_scores, index=[\"accuracy\"])\nmodel_compare.T.plot.bar();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Hyperparameter tuning and cross-validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's tuning KNeighborsClassifier\n\ntrain_scores = []\ntest_scores = []\n\n# Create a list of different values for n_neighbors\nneighbors = range(1, 21)\n\n# Setup KNN instance\nknn = KNeighborsClassifier()\n\n# Loop through different n_neighbors \nfor i in neighbors:\n    knn.set_params(n_neighbors=i)\n    # Fit the algorithm\n    knn.fit(X_train, y_train)\n    # Update the training scores list\n    train_scores.append(knn.score(X_train, y_train))\n    # Update the test scores list \n    test_scores.append(knn.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizing the KNN Scores\nplt.plot(neighbors, train_scores, label=\"Train scores\")\nplt.plot(neighbors, test_scores, label=\"Test scores\")\nplt.xticks(np.arange(1,21,1))\nplt.xlabel(\"Number of neighbors\")\nplt.ylabel(\"Model score\")\nplt.legend()\n\nprint(f\"Maximum KNN score on the test data: {max(test_scores)*100:.2f}%\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Hyperparameter Tuning - RandomizedSearchCV"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hyperparameter grid for LogisticRegression\nlogReg_grid = {\"C\": np.logspace(-4, 4, 20),\n                \"solver\": [\"liblinear\"]}\n\n# Hyperparameter grid for RandomForestClassifier\nrandomForest_grid = {\"n_estimators\": np.arange(10, 1000, 50),\n           \"max_depth\": [None, 3, 5, 10], \n           \"min_samples_split\": np.arange(2, 20, 2), \n           \"min_samples_leaf\": np.arange(1, 20, 2)}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tune LogisticsRegression\nnp.random.seed(42)\n\n# Setup random hyperparameter search for LogsiticRegression\nrs_logReg = RandomizedSearchCV(LogisticRegression(), \n                                param_distributions=logReg_grid, \n                                cv=5, n_iter=20, \n                                verbose=True)\n\n# Fit random hyperparameter search model for LogisticRegression\nrs_logReg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Best parameters for LogisticRegression in RandomizedSearchCV\nrs_logReg.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Score after RandomizedSearchCV Hyperparameter Tuning\nrs_logReg.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Score before RandomizedSearchCV Hyperparameter Tuning\nmodel_scores['Logistic Regression']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tune RandomForestClassifier\nnp.random.seed(42)\n\n# Setup randdom hyperparameter search for RandomForestClassifier\nrs_rf = RandomizedSearchCV(RandomForestClassifier(), \n                           param_distributions=randomForest_grid, \n                           cv=5, \n                           n_iter=20, \n                           verbose=True)\n\n# Fit random hyperparameter search model for RandomForestClassifier\nrs_rf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Best Parameters for RandomForestClassifier in RandomizedSearchCV\nrs_rf.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Score after RandomizedSearchCV Hyperparameter Tuning\nrs_rf.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Score before RandomizedSearchCV Hyperparameter Tuning\nmodel_scores['Random Forest']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No change. \nTry to improve Logistic Regression even more with GridSearchCV"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Different hyperparameters for our LogisticRegression model\nlog_reg_grid = {\"C\": np.logspace(-4, 4, 30),\n                \"solver\": [\"liblinear\"]}\n\n# Setup grid hyperparameter search for LogisticRegression\ngs_log_reg = GridSearchCV(LogisticRegression(), \n                          param_grid=log_reg_grid, \n                          cv=5,  \n                          verbose=True)\n\n# Fit grid hyperparameter search model\ngs_log_reg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Best parameters\ngs_log_reg.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluating the grid search LogisticRegression model\ngs_log_reg.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make predictions with tuned model\ny_preds = gs_log_reg.predict(X_test)\ny_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot ROC curve and calculate AUC metric\nplot_roc_curve(gs_log_reg, X_test, y_test);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion Matrix\nsns.set(font_scale=1.5)\n\nfig, ax = plt.subplots(figsize=(3, 3))\nax = sns.heatmap(confusion_matrix(y_test, y_preds),\n                    annot=True,\n                    cbar=False)\nplt.xlabel(\"True Label\")\nplt.ylabel(\"Predicted Label\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Classification Method\nprint(classification_report(y_test, y_preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check best hyperparameters\ngs_log_reg.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a new classifier with best parameters\nclf = LogisticRegression(C=0.20433597178569418, solver='liblinear')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cross-validated accuracy\ncv_acc = cross_val_score(clf, X, y, cv=5, scoring=\"accuracy\")\ncv_acc = np.mean(cv_acc)\ncv_acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cross-validated precision\ncv_precision = cross_val_score(clf, X, y, cv=5, scoring=\"precision\")\ncv_precision = np.mean(cv_precision)\ncv_precision","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cross-validated recall\ncv_recall = cross_val_score(clf, X, y, cv=5, scoring=\"recall\")\ncv_recall = np.mean(cv_recall)\ncv_recall","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cross-validated f1-score\ncv_f1 = cross_val_score(clf, X, y, cv=5, scoring=\"f1\")\ncv_f1 = np.mean(cv_f1)\ncv_f1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize the cross-validated metrics\ncv_metrics = pd.DataFrame({\"Accuracy\": cv_acc, \n                           \"Precision\": cv_precision,\n                           \"Recall\": cv_recall,\n                           \"F1\": cv_f1}, index=[0])\n\ncv_metrics.T.plot.bar(title=\"Cross-validated classification metrics\", \n                      legend=False);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}