{"cells":[{"metadata":{},"cell_type":"markdown","source":"# COVID-19 Pandemic\n\n![](https://www.statnews.com/wp-content/uploads/2020/02/Coronavirus-CDC-645x645.jpg)\n\nSource = https://www.statnews.com/wp-content/uploads/2020/02/Coronavirus-CDC-645x645.jpg\n"},{"metadata":{},"cell_type":"markdown","source":"# Beginners Intro to Coronavirus"},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import YouTubeVideo\nYouTubeVideo('i0ZabxXmH4Y', width=800, height=450)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load the libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport numpy as np\nimport pandas as pd\nsns.set()\nimport numpy as np # linear algebra\n # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import  Input, Conv2D, MaxPooling2D,GlobalMaxPooling2D, Flatten, Dense, GlobalAveragePooling2D, Activation, MaxPool2D, AvgPool2D, Dropout, Conv1D, MaxPooling1D\nfrom tensorflow.keras.optimizers import Adam, SGD, RMSprop\nfrom tensorflow.keras.applications import DenseNet121, VGG19, ResNet50\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfrom IPython.display import display, Image\nimport matplotlib.pyplot as mpimg\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport os\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.utils import shuffle\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/coronahack-chest-xraydataset/Chest_xray_Corona_Metadata.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_vals = train_df.isnull().sum()\nmissing_vals.plot(kind = 'bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.dropna(how = 'all')\ntrain_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = train_df[train_df['Dataset_type'] == 'TRAIN']\ntest_data = train_df[train_df['Dataset_type'] == 'TEST']\nassert train_data.shape[0] + test_data.shape[0] == train_df.shape[0]\nprint(f\"Shape of train data : {train_data.shape}\")\nprint(f\"Shape of test data : {test_data.shape}\")\ntest_data.sample(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's fill the missing values with 'unknown'"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_fill = train_data.fillna('unknown')\ntest_fill = test_data.fillna('unknown')\ndisplay(train_fill.head(5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Visualization of Unknown Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count plot for 3 attributes with unknown variable addition\ntargets = ['Label', 'Label_2_Virus_category', 'Label_1_Virus_category']\nfig, ax = plt.subplots(2,2, figsize=(20, 10))\nsns.countplot(x=targets[0], data=train_fill, ax=ax[0, 0])\nsns.countplot(x=targets[1], data=train_fill, ax=ax[0, 1])\nsns.countplot(x=targets[2], data=train_fill, ax=ax[1, 0])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Display Images"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_img_dir = '/kaggle/input/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/test'\ntrain_img_dir = '/kaggle/input/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/train'\n\nassert os.path.isdir(test_img_dir) == True\nassert os.path.isdir(train_img_dir) == True\n\nsample_train_images = list(os.walk(train_img_dir))[0][2][:8]\nsample_train_images = list(map(lambda x: os.path.join(train_img_dir, x), sample_train_images))\n\nsample_test_images = list(os.walk(test_img_dir))[0][2][:8]\nsample_test_images = list(map(lambda x: os.path.join(test_img_dir, x), sample_test_images))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\nplt.figure(figsize = (17,17))\nfor iterator, filename in enumerate(sample_train_images):\n    image = Image.open(filename)\n    plt.subplot(4,2,iterator+1)\n    plt.imshow(image)\n\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Displaying test images"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (17,17))\nfor iterator, filename in enumerate(sample_test_images):\n    image = Image.open(filename)\n    plt.subplot(4,2,iterator+1)\n    plt.imshow(image)\n\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4.1 Histogram analysis of Images"},{"metadata":{},"cell_type":"markdown","source":"**For COVID-19 cases**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(4, 2, figsize=(17, 17))\n\n\ncovid_path = train_data[train_data['Label_2_Virus_category']=='COVID-19']['X_ray_image_name'].values\n\nsample_covid_path = covid_path[:4]\nsample_covid_path = list(map(lambda x: os.path.join(train_img_dir, x), sample_covid_path))\n\nfor row, file in enumerate(sample_covid_path):\n    image = plt.imread(file)\n    ax[row, 0].imshow(image)\n    ax[row, 1].hist(image.ravel(), 256, [0,256])\n    ax[row, 0].axis('off')\n    if row == 0:\n        ax[row, 0].set_title('Images')\n        ax[row, 1].set_title('Histograms')\nfig.suptitle('Label 2 Virus Category = COVID-19', size=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Normal Histogram images**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(4, 2, figsize=(17, 17))\n\n\nnormal_path = train_data[train_data['Label']=='Normal']['X_ray_image_name'].values\n\nsample_normal_path = normal_path[:4]\nsample_normal_path = list(map(lambda x: os.path.join(train_img_dir, x), sample_normal_path))\n\nfor row, file in enumerate(sample_normal_path):\n    image = plt.imread(file)\n    ax[row, 0].imshow(image)\n    ax[row, 1].hist(image.ravel(), 256, [0,256])\n    ax[row, 0].axis('off')\n    if row == 0:\n        ax[row, 0].set_title('Images')\n        ax[row, 1].set_title('Histograms')\nfig.suptitle('Label = NORMAL', size=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Image Augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"final_train_data = train_data[(train_data['Label'] == 'Normal') | \n                              ((train_data['Label'] == 'Pnemonia') & (train_data['Label_2_Virus_category'] == 'COVID-19'))]\n\n\n# Create a target attribute where value = positive if 'Pnemonia + COVID-19' or value = negative if 'Normal'\nfinal_train_data['target'] = ['negative' if holder == 'Normal' else 'positive' for holder in final_train_data['Label']]\n\nfinal_train_data = shuffle(final_train_data, random_state=1)\n\nfinal_validation_data = final_train_data.iloc[1000:, :]\nfinal_train_data = final_train_data.iloc[:1000, :]\n\nprint(f\"Final train data shape : {final_train_data.shape}\")\nfinal_train_data.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_image_generator = ImageDataGenerator(\n    rescale=1./255,\n    validation_split = 0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n)\n\ntrain_generator = train_image_generator.flow_from_dataframe(\n    dataframe=final_train_data,\n    directory=train_img_dir,\n    x_col='X_ray_image_name',\n    y_col='target',\n    target_size=(224, 224),\n    batch_size=16,\n    seed=2020,\n    shuffle=True,\n    class_mode='binary'\n)\n\nvalidation_generator = train_image_generator.flow_from_dataframe(\n    dataframe=final_validation_data,\n    directory=train_img_dir,\n    x_col='X_ray_image_name',\n    y_col='target',\n    target_size=(224, 224),\n    batch_size=16,\n    seed=2020,\n    shuffle=True,\n    class_mode='binary'\n)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. Model Development"},{"metadata":{},"cell_type":"markdown","source":"# 6.1 Convolutional Neural Network"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32, (3, 3), input_shape= (224,224,3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n\nmodel.add(Conv2D(64,(3,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(Conv2D(250,(3,3)))\nmodel.add(Dropout(0.5))\nmodel.add(Activation(\"relu\"))\n  \nmodel.add(Conv2D(128,(3,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(AvgPool2D(2,2))\nmodel.add(Conv2D(64,(3,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(AvgPool2D(2,2))\n\nmodel.add(Conv2D(256,(2,2)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPool2D(2,2))\n    \nmodel.add(Flatten())\nmodel.add(Dense(32))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1))\nmodel.add(Activation(\"sigmoid\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 16\nEPOCHS = 30","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\nhistory = model.fit(train_generator,\n                              steps_per_epoch = train_generator.samples //BATCH_SIZE,\n                              validation_data=validation_generator,\n                              epochs=EPOCHS,\n                              validation_steps= validation_generator.samples //BATCH_SIZE,\n                              callbacks = [callbacks]\n                                     )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plots to estimate loss and accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(17,17))\nplt.subplot(2, 2, 1)\nplt.plot(history.history['loss'], label='Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend()\nplt.title('Training - Loss Function')\n\nplt.subplot(2, 2, 2)\nplt.plot(history.history['accuracy'], label='Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.legend()\nplt.title('Train - Accuracy')\n\nplt.legend()\nplt.title('Metrics estimations')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MobileNetV2"},{"metadata":{"trusted":true},"cell_type":"code","source":"mob_model = Sequential()\nmob_model.add(tf.keras.applications.MobileNetV2(include_top=False, pooling = 'avg', weights='imagenet',input_shape=(224, 224, 3), classes=2))\nmob_model.add(Dense(32, activation='relu'))\nmob_model.add(Dense(1, activation='sigmoid'))\nmob_model.layers[0].trainable = False\nmob_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mob_history = mob_model.fit_generator(train_generator,\n                              steps_per_epoch = len(train_generator),\n                              validation_data=validation_generator,\n                              epochs=20,\n                              validation_steps=len(validation_generator),\n                              callbacks = [callbacks]\n                                     )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(17,17))\n\nplt.subplot(2, 1, 2)\nplt.plot(mob_history.history['loss'], label='Loss')\nplt.plot(mob_history.history['loss'], label='Validation Loss')\n\nplt.legend()\nplt.title('Training - Loss Function')\n\nplt.subplot(2, 1, 2)\nplt.plot(mob_history.history['accuracy'], label='Accuracy')\nplt.plot(mob_history.history['val_accuracy'], label='Validation Accuracy')\n\n\nplt.legend()\nplt.title('Train - Accuracy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label = validation_generator.classes\nprint('Cases summary of the models : \\n{}'.format(label))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CNN predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred= model.predict(validation_generator)\npredicted_class_indices=np.argmax(pred,axis=1)\nlabels = (validation_generator.class_indices)\nlabels2 = dict((v,k) for k,v in labels.items())\npredictions = [labels2[k] for k in predicted_class_indices]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('CNN Model Predictions : \\n{}'.format(predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report\n\ncf_matrix = confusion_matrix(predicted_class_indices,label)\ncf_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"exp_series = pd.Series(label)\npred_series = pd.Series(predicted_class_indices)\npd.crosstab(exp_series, pred_series, rownames=['Actual'], colnames=['Predicted'],margins=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n\nmatrix_index = [\"Negative\", \"Positive\"]\n# Negative - no COVID\n\n\npreds = model.predict(validation_generator)\nclasspreds = np.argmax(preds, axis=1) # predicted classes \n#y_testclass = np.argmax(valida, axis=1) # true classes\n\ncm = confusion_matrix(predicted_class_indices,label)\nprint(classification_report(predicted_class_indices,label, target_names=matrix_index))\n\n# Get percentage value for each element of the matrix\ncm_sum = np.sum(cm, axis=1, keepdims=True)\ncm_perc = cm / cm_sum.astype(float) * 100\nannot = np.empty_like(cm).astype(str)\nnrows, ncols = cm.shape\nfor i in range(nrows):\n    for j in range(ncols):\n        c = cm[i, j]\n        p = cm_perc[i, j]\n        if i == j:\n            s = cm_sum[i]\n            annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n        elif c == 0:\n            annot[i, j] = ''\n        else:\n            annot[i, j] = '%.1f%%\\n%d' % (p, c)\n\n\n# Display confusion matrix \ndf_cm = pd.DataFrame(cm, index = matrix_index, columns = matrix_index)\ndf_cm.index.name = 'Actual'\ndf_cm.columns.name = 'Predicted'\nfig, ax = plt.subplots(figsize=(10,7))\nsns.heatmap(df_cm, annot=annot, fmt='')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MobileNet predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred= mob_model.predict(validation_generator)\npredicted_class_indices=np.argmax(pred,axis=1)\nlabels = (validation_generator.class_indices)\nlabels2 = dict((v,k) for k,v in labels.items())\npredictions = [labels2[k] for k in predicted_class_indices]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('MobileNet Model Predictions : \\n{}'.format(predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cf_matrix = confusion_matrix(predicted_class_indices,label)\ncf_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"exp_series = pd.Series(label)\npred_series = pd.Series(predicted_class_indices)\npd.crosstab(exp_series, pred_series, rownames=['Actual'], colnames=['Predicted'],margins=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix_index = [\"Negative\", \"Positive\" ]\n# Negative - no COVID\n\npreds = mob_model.predict(validation_generator)\nclasspreds = np.argmax(preds, axis=1) # predicted classes \n#y_testclass = np.argmax(valida, axis=1) # true classes\n\ncm = confusion_matrix(predicted_class_indices,label)\nprint(classification_report(predicted_class_indices,label, target_names=matrix_index))\n\n# Get percentage value for each element of the matrix\ncm_sum = np.sum(cm, axis=1, keepdims=True)\ncm_perc = cm / cm_sum.astype(float) * 100\nannot = np.empty_like(cm).astype(str)\nnrows, ncols = cm.shape\nfor i in range(nrows):\n    for j in range(ncols):\n        c = cm[i, j]\n        p = cm_perc[i, j]\n        if i == j:\n            s = cm_sum[i]\n            annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n        elif c == 0:\n            annot[i, j] = ''\n        else:\n            annot[i, j] = '%.1f%%\\n%d' % (p, c)\n\n\n# Display confusion matrix \ndf_cm = pd.DataFrame(cm, index = matrix_index, columns = matrix_index)\ndf_cm.index.name = 'Actual'\ndf_cm.columns.name = 'Predicted'\nfig, ax = plt.subplots(figsize=(10,7))\nsns.heatmap(df_cm, annot=annot, fmt='')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 8. References\nThanks to some amazing notebooks I was able to learn how to display images in an orderly fashion and was able to apply transfer learning CNN in COVID related applications.\n1. https://www.kaggle.com/adityam1311/covid-19-x-ray-images-eda-models/notebook\n2. https://www.kaggle.com/eswarchandt/covid-19-detection-from-lung-x-rays"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}