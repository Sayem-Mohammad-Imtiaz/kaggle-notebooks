{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"../input/ibm-hr-analytics-attrition-dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.set_index('EmployeeNumber')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe(include=\"all\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Attrition'].replace({\"Yes\":1,\"No\":0},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('Department').mean()['Attrition'].plot(kind='bar',color=['Green','Blue','Pink'])\nplt.title(\"Attrition Rate by Department\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=([10,20]))\nplt.subplots(12,figsize=[12,6])\nplt.subplot(121)\nsns.boxplot(x='Attrition',y='DistanceFromHome',data=df)\nplt.title(\"Attrition Rate by Distance From Home\")\nplt.subplot(122)\nsns.distplot(df['DistanceFromHome'])\nplt.xlim(0,30)\nsns.despine()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplt.subplots(12,figsize=[12,6])\nplt.subplot(121)\nsns.boxplot(x='Attrition',y='DailyRate',data=df)\nplt.title(\"Attrition Rate by Daily Rate\")\nplt.subplot(122)\nsns.distplot(df['DailyRate'],color='pink')\nplt.xlim(0,1750)\nsns.despine()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(12,figsize=[12,6])\nplt.subplot(121)\nsns.boxplot(x='Attrition',y='TotalWorkingYears',data=df)\nplt.title(\"Attrition Rate by Working Years\")\nplt.subplot(122)\nsns.distplot(df['TotalWorkingYears'],color='pink')\n\nsns.despine()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,20))\nsns.heatmap(df.corr(),annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above diagram we can get an understanding that that attrition has a lot todo with monthly income,years at company and total working level."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['EmployeeNumber','EmployeeCount'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_var=['BusinessTravel','Department','EducationField','Gender','JobRole', 'MaritalStatus', 'Over18','OverTime']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=pd.get_dummies(df,columns=cat_var,drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=X.drop('Attrition',axis=1)\ny=df['Attrition']\nX","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,classification_report\nfrom sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_var=[]\nfor i in X.columns:\n    if X[i].nunique()>3:\n        num_var.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_var","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler=StandardScaler()\nX[num_var] = scaler.fit_transform(X[num_var])\nX_train,X_test,y_train,y_test=train_test_split(X,y)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr=LogisticRegression(C=100,max_iter=10000)\nlr.fit(X_train,y_train)\ny_pred=lr.predict(X_test)\n#lr.score()\nprint(accuracy_score(y_test,y_pred))\nprint(classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" This is an interesting phenomenon. The accuracy score at this point is 0.9. However the question is it the only parameter that needs to be looked atis high recall. Employees that are likely to leave the organisation needs to be targeted to avoid them for leaving.For this case we need high recall rather than high precision. Furthermore, the biggest issue in these problems is that these problems are unbalanced. In the next code, we will see how this affects the overall results when we set the class_weight parameter to be balanced "},{"metadata":{},"cell_type":"markdown","source":"lr=LogisticRegression(C=100,max_iter=1000,class_weight='balanced')\nlr.fit(X_train,y_train)\ny_pred=lr.predict(X_test)\n#lr.score()\nprint(accuracy_score(y_test,y_pred))\nprint(classification_report(y_test,y_pred))"},{"metadata":{},"cell_type":"markdown","source":" This is a really good solution because although precision is lower however recall in this case is high which is what we want to see."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvc=SVC()\nsvc.fit(X_train,y_train)\nsvc.predict(X_test)\nprint(classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndc=DecisionTreeClassifier()\ndc.fit(X_train,y_train)\ndc.predict(X_test)\nprint(classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf=RandomForestClassifier(n_estimators=10,max_depth=4)\nrf.fit(X_train,y_train)\nrf.predict(X_test)\nprint(classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feat=rf.feature_importances_\nfeatures=pd.DataFrame(feat,index=X.columns,columns=[\"Feature Importance\"]).sort_values(by='Feature Importance',ascending=False)\nfeatures.head(8).plot(kind='barh')\nplt.title(\"Feature Importance for Attrition\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nclf=AdaBoostClassifier(n_estimators=100)\nclf.fit(X_test,y_test)\ny_pred=clf.predict(X_test)\nprint(classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\ngbc=AdaBoostClassifier(n_estimators=100)\ngbc.fit(X_test,y_test)\ny_pred=gbc.predict(X_test)\nprint(classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is a pretty decent solution. We have been able to increase performance using the AdaBoost Classifer .Boosting has allowed us not only to increase the accuracy but also the recall."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}