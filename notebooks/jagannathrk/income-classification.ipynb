{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#importing useful libararies\nimport pandas as pd\nimport numpy as np\nimport seaborn as sea\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#read the Sales Records excel file\ndf = pd.read_csv(r'../input/income-classification/income_evaluation.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets have a look to our data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**This Data Set Name is Income Classification**\n**Shape of the data set (32561,15)**\n**NuLL values:** Not Present\n\n**Variables:** 'age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', 'relationship','race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income'.\n\nThere are **9 categorical variables** and **6 Numerical variables.** \n\n**Income is the Target Variable**\n\n\nBy using this dataset, I try to make prediction whether the person is making over 50K or less than 50K. \nI have implemeted the Random Forest Classification with python. Also, I have also using ensemble learnig to increase the accuracy of our Model.\n"},{"metadata":{},"cell_type":"markdown","source":"### Correcting the columns names"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', 'relationship','race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Checking missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are no missing values"},{"metadata":{},"cell_type":"markdown","source":"#### Checking the data Types of the variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Seperating categorical and numerical variables apart"},{"metadata":{"trusted":true},"cell_type":"code","source":"num = [i for i in df.columns if df[i].dtype!='O']\ncat = [i for i in df.columns if df[i].dtype=='O']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### EDA on Categorical variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[cat].nunique().plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Observation**\n- This graph sows no of different categories in the categorical variables"},{"metadata":{},"cell_type":"markdown","source":"Checking the different categories in each categorical variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in df[cat]:\n    print(df[i].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observation**\n- There are some '?' values instead of null values are present in some variables. we need to remove these values.\n- You can see all different classes of categorical variables with their share or get the count of distribution of values."},{"metadata":{},"cell_type":"markdown","source":"### ****Replacing all invalid values to NaN values, so we can easily fill that****"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.replace(' ?', np.nan, inplace= True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"See we can easily get the count of NaN values"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### here you can see the counts of null values in the variables. \n\n### Now using fillna() function we need to replace the the null the previous column value "},{"metadata":{"trusted":true},"cell_type":"code","source":"df.fillna(method = 'bfill', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, there is no null or invalid values left in our data"},{"metadata":{},"cell_type":"markdown","source":"### Our target variable income, lets visualize it, with repect to others variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.income.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observation**\n- Only two categories in income variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"sea.countplot(x= 'income' ,data =df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.income.value_counts().plot(kind='pie')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observation**\n- There are more than 75% number of people making less than 50k."},{"metadata":{},"cell_type":"markdown","source":"### See the income distribution with respect to gender"},{"metadata":{"trusted":true},"cell_type":"code","source":"sea.countplot(x=\"income\", hue=\"sex\", data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observation**\n- people who are earning less than 50K are high in numbers also Male are high in numbers"},{"metadata":{},"cell_type":"markdown","source":"### Income distribution w.r.t workclass"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(12, 8))\nsea.countplot(x=\"income\", hue=\"workclass\", data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observation**\n- There are more people who employed with private sector, in both categories of income. "},{"metadata":{},"cell_type":"markdown","source":"### plotting the workclass w.r.t gender."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(12, 8))\nsea.countplot(hue=\"sex\", x=\"workclass\", data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observation**\n- In workclass the highest number of people doing work in private. And in all workclass males are highest. "},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in cat:\n    \n    print(i, ' contains ', len(df[i].unique()), ' labels')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### lets encode the categorical varibles with one hot encoding"},{"metadata":{},"cell_type":"markdown","source":"#### Remove the target variable income "},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df.income","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = pd.get_dummies(y,drop_first=True)\n#df.drop(['income'],axis =1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = pd.get_dummies(df[cat])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(df[cat],axis = 1,inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA on Numerical Variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[num].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### view the Distribution of Age variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"sea.distplot(df.age, bins=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observation**\n- most number of people are belong to 20 to 50 age group."},{"metadata":{},"cell_type":"markdown","source":"### Checking the outliers in Numerical variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"sea.boxplot(df.age)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Obseravation**\n\n -There are some outliers present in Age variables."},{"metadata":{},"cell_type":"markdown","source":"### Checking the correlation between numerical variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observation**\n- there is no correlation beween the variables."},{"metadata":{},"cell_type":"markdown","source":"### Scalling the Numerical varibales "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import RobustScaler\nscaler = RobustScaler()\ndf = scaler.fit_transform(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(df)\nx = pd.concat([x,df],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Splitting the data into test and train"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### visualize trainig data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fitting the Logistic Regression model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###  Testing the logistic model by predicting the test data and calculate the accuracy score "},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = logreg.predict(X_test)\naccuracy_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fitting the Random forest Model with only 10 decision trees "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(random_state=0,n_estimators=10)\nrfc.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Testing the random forest model by predicting the test data and calculate the accuracy score "},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = rfc.predict(X_test)\naccuracy_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fitting the Random forest Model with only 100 decision trees"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(random_state=0,n_estimators=100)\nrfc.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Testing the random forest model by predicting the test data and calculate the accuracy score with100 decision tress. "},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = rfc.predict(X_test)\naccuracy_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Accuracy increase by 0.1 by increasing the number of decision tress."},{"metadata":{},"cell_type":"markdown","source":"## Bagging method of ensemble learning "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import BaggingClassifier\nfrom sklearn import tree\nmodel = BaggingClassifier(random_state=0)\nmodel.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Testing the bagging model and calculate accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(X_test)\naccuracy_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fitting the Extream gradient boosting method with keeping hyperparamerter(learning rate is 0.1 ) then calculate accuracy."},{"metadata":{"trusted":true},"cell_type":"code","source":"#import xgboost as xgb\n#model=xgb.XGBClassifier(base_estimator = rfc,random_state=1,learning_rate=0.1)\n#model.fit(X_train, y_train)\n#model.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Summary**\n- This income prediction classification problem, the logistic regerssion achieved 85.13%.\n- The simple baggging with no base model gives accuracy 84.39%\n- Ensemble learning bagging technique with base model Random forest with 10 decision tress, gives accuracy is 84.95%\n- Ensemble learning bagging technique with base model Random Forest with 100 decision trees, gives accuracy is 85.40%\n- In Ensemble learning Boosting technique with base model random forest, gives accuracy 86.94%"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":4}