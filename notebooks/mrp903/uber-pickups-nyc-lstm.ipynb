{"cells":[{"metadata":{"_cell_guid":"dea2ffa4-58ef-4eda-982d-0710fa1778b2","_uuid":"fa32f5559f6f3217d1be484c68b12203593f5d7c"},"cell_type":"markdown","source":"## Uber Pickups in NYC\n\n### I recently learned few things in the context of RNN and LSTM and wanted to give it a try! Here, I'll use LSTM to forecast #uber-trips for last two weeks of June-2015. \n\n### I am only using Jan-June-2015 data. I aggregated all the trips on a daily basis. There are ~14M trips and once we aggregate it on a daily basis, we end up with ~180 records (i.e. 6 months).\n"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport time\n\nfrom datetime import datetime\nfrom collections import Counter\n\nfrom pandas.plotting import autocorrelation_plot as acp\nfrom statsmodels.graphics.tsaplots import plot_pacf","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false,"collapsed":true},"cell_type":"code","source":"uber_jan_june = pd.read_csv('../input/uber-raw-data-janjune-15.csv')\nprint (uber_jan_june.head())\nuber_jan_june.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"68154c92-91f5-4824-ba7e-801d05b5eac8","_uuid":"f90f465876d14dac1d62edc60921b6305d352cf3","collapsed":true,"trusted":false},"cell_type":"code","source":"## Extracting month and day from date-time\nuber_jan_june['Month_Day'] = uber_jan_june['Pickup_date'].apply(lambda pickup: datetime.strptime(pickup, '%Y-%m-%d %H:%M:%S').strftime('%m-%d').split('-'))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"fddbeffa-0496-4e28-a9b3-ca0e48d1e64f","_uuid":"577f5b2a0781aaaf3333e9c2f54a3a279fc64442","trusted":false,"collapsed":true},"cell_type":"code","source":"## Separate month and day\nuber_jan_june['Month'] = [month_day [0] for month_day in uber_jan_june['Month_Day']]\nuber_jan_june['Day'] = [month_day [1] for month_day in uber_jan_june['Month_Day']]\nuber_jan_june.tail(20)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1e257957-e90e-48ae-85c9-f0984eff2eb7","_uuid":"f6603e7e33e2596aac27f21c7382fbf2a708b2dd","trusted":false,"collapsed":true},"cell_type":"code","source":"jan_june_grouped = uber_jan_june.groupby(by = ['Month', 'Day']).size().unstack()\njan_june_grouped","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1a55d628-3f19-4876-aac0-220784aa78fc","_uuid":"02788e2c365677bfa1fa27d679cb34fedbecf898","trusted":false,"collapsed":true},"cell_type":"code","source":"## Aggregate results to form a time-series\nall_jan_june = [jan_june_grouped.iloc[r,:] for r in range(jan_june_grouped.shape[0])]\nall_jan_june = [trips for month in all_jan_june for trips in month]\nlen(all_jan_june)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5d469990-91a2-4a4c-b5d2-17ef3eab969d","_uuid":"65039e57bb0707da6a79a161fca985a9d74b9fd7","collapsed":true,"trusted":false},"cell_type":"code","source":"## Remove missing values: here missing values are the days when a month is shorter than 31 days.\nremove_inds = list(np.argwhere(np.isnan(all_jan_june) == True).reshape((1,5))[0])\nall_jan_june_mod = [all_jan_june[i] for i,j in enumerate(all_jan_june) if i not in remove_inds]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"39fb43c7-4a2f-43ab-95ce-388af06973f4","scrolled":true,"_uuid":"f5af4641456dd5884e417603d105e64bf32f1223","trusted":false,"collapsed":true},"cell_type":"code","source":"## Convert time-series into data-frame for modeling process\nuber_jan_june_final = pd.DataFrame({'Days': range(1,len(all_jan_june_mod)+1), 'Trips': all_jan_june_mod})\nuber_jan_june_final.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ccdbc89d-5dbe-4bb3-818f-2a03ce95f113","_uuid":"d565d418326954f5e7e2aba2b3971dec8238446c"},"cell_type":"markdown","source":"## Pre-processing data for RNN-LSTM"},{"metadata":{"_cell_guid":"e4c9d7f9-05ca-4900-930b-e90c10a5f63b","_uuid":"b454892b6ccd0da1fc5a381096e84aadef39c09c","trusted":false,"collapsed":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\n## Split into train-test set:\ntrain_jan_june = uber_jan_june_final.iloc[0:167,1:2].values\ntest_jan_june = uber_jan_june_final.iloc[167:,1:2].values\n\nprint ('Training data: ', train_jan_june.shape)\nprint ('Testing data: ', test_jan_june.shape)\n\n## Feature-scaling:\nmms = MinMaxScaler(feature_range = (0,1))\ntrain_jan_june_scaled = mms.fit_transform(train_jan_june)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"01d0764e-2597-49e4-bd4a-317d8c505250","_uuid":"0ea0e83a09550fabbc96c0d9445423c774a9c61a"},"cell_type":"markdown","source":"### To predict number of trips for any given  day, I use the data (i.e. number of trips) of last 14 days."},{"metadata":{"_cell_guid":"ba302105-47f6-4cac-b8ce-9b25e03e665b","_uuid":"4e7d22c6b4ce9e8e9c1f019727eb922e435362b4"},"cell_type":"markdown","source":"##### Create structured training set: I am considering last two weeks' data to predict the next value, i.e. #Uber-trips. So, need to create appropriate format of input data."},{"metadata":{"_cell_guid":"d3355a35-4ef4-47f3-8810-c39809e84e50","_uuid":"afc31f5b5b4cf4be41b686de6436203ef9388612","collapsed":true,"trusted":false},"cell_type":"code","source":"x_train = []\ny_train = []\n\nfor rides in range(14, 167):\n    x_train.append(train_jan_june_scaled[rides-14:rides,0])\n    y_train.append(train_jan_june_scaled[rides,0])\n    \nx_train, y_train = np.array(x_train), np.array(y_train)\nx_train = np.reshape(x_train, newshape = (x_train.shape[0], x_train.shape[1], 1))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"86e7d5de-ae93-4f23-800b-7491f471fdfa","_uuid":"e16991322dcca491dc1293ab081a8eab63e175fc"},"cell_type":"markdown","source":"## Build RNN:"},{"metadata":{"_cell_guid":"20bb1381-9749-4279-9a7b-f5cfc0844e94","_uuid":"c5e56a76995fa31eb6eb5f7e6c639490903620af","trusted":false,"collapsed":true},"cell_type":"code","source":"## Import required modules:\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense, Dropout\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c1a05916-3a00-42d9-a414-a177b971fb25","_uuid":"857ae07fec993720839bc86e883e25a2a00f45db"},"cell_type":"markdown","source":"### Parameters for LSTM:\n1. num_units = 40\n2. drpout = 0.2\n3. epochs = 1000\n4. size_of_batch = 16\n5. optimizer = 'adam'\n6. loss = 'mean_squared_error'"},{"metadata":{"_cell_guid":"1385f82f-d0fe-4a7a-a389-f24e6fab7e50","_uuid":"2ce62553a9c27fbe7f95fc35bee880d8b9412363","trusted":false,"collapsed":true},"cell_type":"code","source":"np.random.seed(11)\nt_start = time.time()\n\ndef build_rnn(num_units, input_x, input_y, drpout, epochs, size_of_batch, optimizer, loss):\n    \n    regressor = Sequential()\n\n    ## Adding first LSTM layer:\n    regressor.add(LSTM(units = num_units, return_sequences = True, input_shape = (input_x.shape[1],1)))\n    regressor.add(Dropout(drpout))\n\n    ## Adding second LSTM layer:\n    regressor.add(LSTM(units = num_units, return_sequences = True))\n    regressor.add(Dropout(drpout))\n\n    ## Adding third LSTM layer:\n    regressor.add(LSTM(units = num_units, return_sequences = True))\n    regressor.add(Dropout(drpout))\n\n    ## Adding fourth LSTM layer:\n    regressor.add(LSTM(units = num_units, return_sequences = True))\n    regressor.add(Dropout(drpout))\n\n    ## Adding fifth LSTM layer:\n    regressor.add(LSTM(units = num_units, return_sequences = False))\n    regressor.add(Dropout(drpout))\n\n    ## Adding o/p layer:\n    regressor.add(Dense(units = 1))\n\n    ## Compiling RNN:\n    regressor.compile(optimizer = optimizer, loss = loss)\n\n    ## Fitting RNN to training set:\n    regressor.fit(x = input_x, y = input_y, epochs = epochs, batch_size = size_of_batch)\n\n    return regressor\n    \nregressor = build_rnn(num_units = 40, input_x = x_train, input_y = y_train, drpout = 0.2, epochs = 1000, size_of_batch = 16, optimizer = 'adam', loss = 'mean_squared_error')\n\nprint (time.time() - t_start)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"fd0a8d8d-8869-4b8f-a94a-e6a11f4624d8","_uuid":"8f2249c7673f2c05415fa919894a458e8b614142"},"cell_type":"markdown","source":"### As I am using last 14 values to predict the next value, I still need the some data from train-set to make first prediction for test-set"},{"metadata":{"_cell_guid":"17640b04-cda8-4af3-8175-66ee6248a076","_uuid":"ce3444854fa7f09a542051beb16a8b23c8f3f003","trusted":false,"collapsed":true},"cell_type":"code","source":"adjusted_inputs = uber_jan_june_final[len(uber_jan_june_final) - len(test_jan_june) - 14:]['Trips'].values\nadjusted_inputs = adjusted_inputs.reshape(-1,1)\nadjusted_inputs = mms.transform(adjusted_inputs)\nadjusted_inputs[0:10]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c708b8e6-e74d-42ca-aedd-60449de27a12","_uuid":"449a08a247cfc31467b048552d270e4a41661d54","trusted":false,"collapsed":true},"cell_type":"code","source":"## Create properly structured test set:\nx_test = []\nfor rides in range(14,29):\n    x_test.append(adjusted_inputs[rides-14:rides,0])\n    \nx_test = np.array(x_test)\nx_test = np.reshape(x_test, newshape = (x_test.shape[0], x_test.shape[1], 1))\nx_test.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bd1e6003-9df2-4661-83f4-40b4f5d790f0","_uuid":"dac9beaaaa7ca169862174e4921be8385b4d455e","trusted":false,"collapsed":true},"cell_type":"code","source":"## Make prediction for test set and bring values back to original scale\npred = regressor.predict(x_test)\npred = mms.inverse_transform(pred)\n\n## Check RMSE on test-set\nresiduals = pred[0:-1] - test_jan_june\nrmse = np.sqrt(np.mean(residuals**2))\nrmse","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"433a6f80-613b-4c29-9fdb-64abbeda3446","_uuid":"e78b922e417547deb7dffd0baca0c2c134c85125","trusted":false,"collapsed":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (12,6))\n\ne = [i*0.05 for i in pred]\nax.plot(pred, color = 'red', label = 'Predictions')\nax.errorbar(x = range(15), y = pred, yerr = e, fmt = '*', color = 'r')\nax.plot(test_jan_june, color = 'black', label = 'True')\n\nax.set_xlabel('Time-steps (Last two weeks of June-2015)', fontsize = 15)\nax.set_ylabel('#Uber-trips', fontsize = 15)\nax.set_title('Comparing LSTM-predictions with Test-data \\n RMSE: {}'.format(np.round(rmse,2)), fontsize = 20)\n\nax.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"20cf254c-8488-419d-ab4f-36d5e14ba052","_uuid":"70d5139829542d19615cf39b12c8b6ef53e0de7b","trusted":false,"collapsed":true},"cell_type":"code","source":"fig ,ax = plt.subplots(figsize = (12,6))\nax.plot(residuals)\n\nax.set_xlabel('Days in test-set (last two weeks of June-2015)', fontsize = 15)\nax.set_ylabel('Error in predictions', fontsize = 15)\nax.set_title('Testing Data RMSE w/ LSTM: {}'.format(round(rmse, 3)), fontsize = 20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2ec54c0f-02ad-4905-b4b2-d3f116e417b8","_uuid":"d3388e759c125bbb48ddcadd101d0fa6331044f2","trusted":false,"collapsed":true},"cell_type":"code","source":"pred_train = regressor.predict(x_train)\npred_train = mms.inverse_transform(pred_train)\n\nresiduals_train = pred_train - train_jan_june[0:-14]\nrmse_train = np.sqrt(np.mean(residuals_train**2))\n\nfig, ax = plt.subplots(figsize = (14,6))\nax.plot(residuals_train)\nax.set_xlabel('Sequence of days (Jan - June 2015)', fontsize = 15)\nax.set_ylabel('Error in predictions', fontsize = 15)\nax.set_title('Training Data RMSE w/ LSTM: {}'.format(round(rmse_train,3)), fontsize = 20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"16801001-b10c-4a9e-b64b-bc5ed6b17a84","_uuid":"b7cfcce882fe739da6778132fcc5b50ff91d249e","trusted":false,"collapsed":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (16,6))\n\nax.plot(pred_train, color = 'red', label = 'Predictions')\nax.plot(train_jan_june, color = 'black', label = 'True')\n\nax.axvline(x = 26, color = 'y', linestyle = 'dashed')\nax.text(x = 29, y = 30000, s = 'Monday-01/26 \\n Nothing Special')\n\nax.axvline(x = 135, color = 'y', linestyle = 'dashed')\nax.text(x = 115, y = 30000, s = 'Friday-05/15 \\n Nothing Special')\n\nax.set_xlabel('Time-steps (Jan-June 2015)', fontsize = 15)\nax.set_ylabel('#Uber trips', fontsize = 15)\nax.set_title('Comparing LSTM-predictions with training data \\n RMSE: {}'.format(round(rmse_train,3)), fontsize = 20)\n\nax.legend()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"af75e784-1e9c-4da0-be04-60e5bcb1ccdc","_uuid":"5e4b0cc4d5083de7dfe8a7ba4f4caa1da9866ca0"},"cell_type":"markdown","source":"## Analysis of residuals"},{"metadata":{"_cell_guid":"35cfbc4d-d3b6-4dd1-a8cc-cce96e733617","_uuid":"1c92a6066503e5256e228d2851d10cbeac691c42","trusted":false,"collapsed":true},"cell_type":"code","source":"import matplotlib.gridspec as gridspec\nplt.figure(figsize = (20,12))\ng = gridspec.GridSpec(2,2)\n\nax1 = plt.subplot(g[0,0])\nax1.hist(residuals_train, normed = True)\npd.DataFrame(residuals_train).plot(kind = 'kde', ax = ax1, label = 'KDE')\nax1.set_title('KDE and Histogram of Residuals-Training', fontsize = 18)\nax1.legend_.remove()\n\nax2 = plt.subplot(g[0,1])\nimport scipy.stats as ss\nss.probplot(residuals_train[:,0].tolist(), plot = ax2)\nax2.set_title('Q-Q Plot-Training', fontsize = 18)\n\nax3 = plt.subplot(g[1,0])\nax3.plot(residuals_train)\nax3.set_xlabel('Sequence of days (Jan - June 2015)', fontsize = 15)\nax3.set_ylabel('Error in predictions', fontsize = 15)\nax3.set_title('Residuals ', fontsize = 20)\n\nax4 = plt.subplot(g[1,1])\nacp(residuals_train, ax = ax4)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"dfe04cf8-f185-4206-bd88-cc24a033c4eb","_uuid":"16ceab4ddc5b8c6587259d0873fc4c2a6f8034ea"},"cell_type":"markdown","source":"### Few notes for LSTM:\n#### Pros:\n\nFrom the comparison plot of LSTM vs. True data, we can observe that it does not capture the peaks in #Uber-trips on 10th day (plot of Testing Data). This can be considered a +ve sign in a way that #Uber-trips on that particular day is exceptionally high and can be considered as an anomaly. If we try to fit model for that then it may overfit the data and does not do well for future predictions. Same reason goes for the steep decline in #Uber-trips after the peak!\n\nThere are certain peaks and steep-decline in #Uber-trips on certain days (plot of Training Data) but further investigation suggests that nothing special happened that day, i.e. no holiday or no special occassion in general. There might be something in NYC only. Our model does not capture this extreme events which is better in a way that it's not over-fitting the data.\n\n#### Cons:\n\nThe RMSE for RNN-LSTM on training is: ~ 10600.\n\nIt does not tell us the underlying structure (or pattern) of Uber-trips with certainty, i.e. we cannot say when there's peak in #Uber-trips or how does the #Uber-trips vary for a certain week."},{"metadata":{"_cell_guid":"8b283817-c30d-4a7a-9b19-83a8e9108bfd","_uuid":"24c6a596b8a48f680813f978215d829d470cc629","collapsed":true,"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"21fa6c57-f96f-4c66-b607-54fcaec77602","_uuid":"3d6c9cc31afa3b3805bf7fb3dfe8852d8c1a1d3a"},"cell_type":"markdown","source":"### Still working on following"},{"metadata":{"_cell_guid":"17498a29-e7fb-4b59-ba4b-3a981fe259b4","_uuid":"02343cd67249bcc724889998bda76b0218532e18","collapsed":true,"trusted":false},"cell_type":"code","source":"# from pandas.plotting import autocorrelation_plot as acp\n# from statsmodels.graphics.tsaplots import plot_pacf\n# from statsmodels.tsa.stattools import adfuller\n\n## Do differencing\n# all_trips_df_diff = uber_jan_june_final[['Trips']] - uber_jan_june_final[['Trips']].shift()\n\n# from statsmodels.tsa.stattools import adfuller\n# train_jan_june = all_trips_df_diff['Trips'][0:167]\n# test_jan_june = all_trips_df_diff['Trips'][167:]\n\n# from statsmodels.tsa.arima_model import ARIMA\n# train_temp = pd.DataFrame({'original_series': uber_jan_june_final['Trips'][0:167], 'shifted_series': all_trips_df_diff['Trips'][0:167]})\n\n# def fit_ARIMA(train, temp):\n#     p_all = []\n#     q_all = []\n#     rmse_train = []\n#     predictions = []\n    \n#     for p in range(6):        \n#         for q in range(6):\n#             try: \n#                 model = ARIMA(np.array(train), order = (p,0,q))\n#                 results_arima = model.fit()                    \n#                 fitted_values = results_arima.fittedvalues\n\n#                 p_all.append(p)\n#                 q_all.append(q)\n\n#                 Back_to_original = [temp['shifted_series'][i+1] + temp['original_series'][i] for i in range(temp.shape[0]-1)]\n\n#                 ## Add first element as 0:\n#                 Back_to_original.insert(0,0)\n\n#                 back_to_actual_fitted_values = [fitted_values[i+1] + temp['original_series'][i] for i in range(temp.shape[0]-1)]\n#                 back_to_actual_fitted_values.insert(0,0)\n#                 predictions.append(back_to_actual_fitted_values)\n                \n#                 rmse = np.sqrt(np.mean((temp['original_series'][1:] - back_to_actual_fitted_values[1:])**2))\n#                 rmse_train.append(np.ceil(rmse))\n\n#             except:\n#                 pass\n                \n    \n#     grid_search_df = pd.DataFrame({'p': p_all, 'q': q_all, 'RMSE_train': rmse_train, 'Predictions': predictions})\n    \n#     return grid_search_df\n\n# train_grid_search_df = fit_ARIMA(train_jan_june, train_temp)\n# train_grid_search_df.sort_values(by = ['RMSE_train']).head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}