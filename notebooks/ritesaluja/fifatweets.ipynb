{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt \n\n#plotly\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode()\nimport plotly.graph_objs as py\n\n#for word cloud\nfrom subprocess import check_output\nfrom wordcloud import WordCloud, STOPWORDS\nstopwords = set(STOPWORDS)\n\nimport re\nimport os\nprint(os.listdir(\"../input\"))\nfrom IPython.display import HTML\nfrom IPython.display import display\n\nfrom PIL import Image\nfrom termcolor import colored\n\nfrom nltk.corpus import stopwords\nstop = set(stopwords.words('english'))\nstop.update(['.', ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}','']) # remove it if you need punctuation \n\nfrom nltk.stem import WordNetLemmatizer\n\nimport seaborn as sns\nimport nltk\n\n#to supress Warnings \nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n#---------------------------------------------\nimport pandas as pd\nimport string\nfrom nltk import word_tokenize\nfrom nltk.corpus import stopwords\nfrom textblob import TextBlob # for sentiment analysis\nfrom collections import Counter \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/world-cup-2018-tweets/FIFA.csv')\ndf.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(df.info())\n#dropping null tweets\ndf.dropna(subset=['Tweet'], inplace=True)\ndisplay(df.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"#replacing one or multiple occurences of '?' in name (cleaning name)\ndf.Name = df.Name.str.replace('[\\?]+','unknown', regex = True) \ndf.Name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('Place')['Name'].count().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of the Twitter Handlers (who tweeted for FIFA' 18) are from Lagos (largest city) in Nigeria, showcasing the support for their team in FIFA 2018"},{"metadata":{"trusted":true},"cell_type":"code","source":"#finding place of one of the most influence tweet (RTs)\nkt = df[['UserMentionID','Followers','Place','Orig_Tweet','Tweet', 'RTs']].sort_values(by = 'RTs', ascending = False).head(1)\ndisplay(kt.head(1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Tweet[529999]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This Tweet even made it to the news, no doubt it was the most tweeted!"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# Clean and Normalize Text\n# - tokenize\n# - lowercase\n# - remove punctuation\n# - remove alphanumeric characters\n# - remove stopwords\n\nstopwords = set(stopwords.words('english'))\n\ndef clean(text):\n    text = word_tokenize(text)\n    text = [word.lower() for word in text]\n    punct = str.maketrans('', '', string.punctuation) \n    text = [word.translate(punct) for word in text] \n    text = [word for word in text if word.isalpha()]\n    text = [word for word in text if not word in stopwords]\n    return \" \".join(text)\n\ndf['clean_tweet'] = df['Tweet'].apply(clean)\ndf.head(5)\n\n# Create Word Count Column for Clean Text\n\ndf['clean_word_count'] = df['clean_tweet'].str.split().str.len()\ndf.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"#tokenizing tweets\ntext = ' '.join(df.clean_tweet)\ndisplay(text)\ntext = word_tokenize(text)\ntext = [word.lower() for word in text]\npunct = str.maketrans('', '', string.punctuation) \ntext = [word.translate(punct) for word in text] \ntext = [word for word in text if word.isalpha()]\ntext = [word for word in text if not word in stopwords]\nprint(text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"tags = nltk.pos_tag(text)\nnouns = [word for word,pos in tags if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS')\n]\n\n#series with nouns\ns_index = pd.Series(nouns)\n\nprint(nouns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#Word cloud for Fifa -- lets see some popular Key words from the tweets \nwave_mask = np.array(Image.open( \"../input/beerimage/fifacup_.png\"))\nwordcloud = (WordCloud(width=1440, height=1080, mask = wave_mask, relative_scaling=0.5, stopwords=stopwords, background_color='grey').generate_from_frequencies(s_index.value_counts()))\n\n\nfig = plt.figure(1,figsize=(15, 15))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply Sentiment Polarity to Text with TextBlob\n\ndf['polarity'] = [round(TextBlob(word).sentiment.polarity, 2) for word in df['clean_tweet']]\ndf['sentiment'] = ['positive' if polarity > 0 \n                             else 'negative' if polarity < 0 \n                                 else 'neutral' \n                                     for polarity in df['polarity']]\n\n#Sentiments\ndf.sentiment.value_counts().plot(kind='pie')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tweets are mostly of Neutral sentiment! "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Can we predict RTs from followers, friends, hastag_count,sentiment, word_count?\n\n#hastag count - numeric fields required\n#df['hash_count'] = df.Hashtags.map(lambda x: [i.strip() for i in x.split(\",\")])\ndf['hash_count'] = df.Hashtags.apply(lambda x : len(str(x).split(',')))\ndff = df[['RTs','hash_count','Followers','Friends','len']]\ndff.head","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Pairplot \nimport seaborn as sns\n\nsns.set(style=\"ticks\", color_codes=True)\n#iris = sns.load_dataset(\"FIFA'18 Tweets\")\ng = sns.pairplot(dff)\n\n\nimport matplotlib.pyplot as plt\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Pair Plots"},{"metadata":{"trusted":true},"cell_type":"code","source":"#predict RTs (Popularity of Tweet - what makes a tweet tweetable?)\nfrom sklearn.model_selection import train_test_split\n\nX = dff[['hash_count','Followers','Friends','len']]\ny = dff['RTs']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n\n# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\nfrom sklearn.ensemble import RandomForestRegressor\n\nregressor = RandomForestRegressor(n_estimators=20, random_state=0)\nregressor.fit(X_train, y_train)\ny_pred = regressor.predict(X_test)\n\nfrom sklearn import metrics\n\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random Forest Regressor has done terrible in Prediction "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}