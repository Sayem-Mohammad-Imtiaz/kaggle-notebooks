{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <center> E-Commerce Clothing Review Classification with TF","metadata":{}},{"cell_type":"markdown","source":"# Aim of the Notebook\n\n**Hello, welcome to this Notebook!**\n\n**In this notebook, I will be working on the Women's E-Commerce Clothing Review dataset.**\n\n**First of all, I will make some exploratory data analysis for the features and the texts as well. And then, I will clean the text data using by NLTK library.**\n\n**For the next step, I will create an ANN model to achieve my aim.**\n\n**I am open to feedback and suggestions, feel free to comment your feedback and suggestions on the comment section or contact me.**\n\n**So, let's get started!**","metadata":{}},{"cell_type":"markdown","source":"# Importing the Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport plotly.graph_objects as go\nfrom wordcloud import WordCloud\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport re\nimport plotly.express as px\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Dropout\nfrom keras.layers import LSTM\nfrom keras.models import Sequential\nfrom keras.layers import Bidirectional\nfrom keras.layers import Embedding\nfrom keras.layers import GlobalAvgPool1D\nimport tensorflow as tf\n\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-24T20:07:18.483299Z","iopub.execute_input":"2021-08-24T20:07:18.483712Z","iopub.status.idle":"2021-08-24T20:07:21.996752Z","shell.execute_reply.started":"2021-08-24T20:07:18.483623Z","shell.execute_reply":"2021-08-24T20:07:21.995247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"../input/womens-ecommerce-clothing-reviews/Womens Clothing E-Commerce Reviews.csv\" , index_col=0)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:07:26.325503Z","iopub.execute_input":"2021-08-24T20:07:26.32591Z","iopub.status.idle":"2021-08-24T20:07:26.490227Z","shell.execute_reply.started":"2021-08-24T20:07:26.325879Z","shell.execute_reply":"2021-08-24T20:07:26.48905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**As you can see from the head of the dataset, we have some unnecessary features such as Clothing ID, Title. First of all, I will drop this features.**","metadata":{}},{"cell_type":"code","source":"data = data.drop(['Title', 'Clothing ID', 'Positive Feedback Count'], axis=1)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:07:30.685372Z","iopub.execute_input":"2021-08-24T20:07:30.685717Z","iopub.status.idle":"2021-08-24T20:07:30.703986Z","shell.execute_reply.started":"2021-08-24T20:07:30.685686Z","shell.execute_reply":"2021-08-24T20:07:30.702843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking for the missing values\ncount_NaN = data.isna().sum()\ncount_NaN","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:07:34.220298Z","iopub.execute_input":"2021-08-24T20:07:34.220762Z","iopub.status.idle":"2021-08-24T20:07:34.243669Z","shell.execute_reply.started":"2021-08-24T20:07:34.220718Z","shell.execute_reply":"2021-08-24T20:07:34.242321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**It is impossible to replace the Review Text features. Therefore, I will drop the missing rows from the dataset.**","metadata":{}},{"cell_type":"code","source":"# Dropping the missing values in the rows\ndata = data.dropna(subset=['Review Text', 'Division Name', 'Department Name', 'Class Name'], axis=0)\ndata = data.reset_index(drop=True)\n\n# Checking for the missing values after the drops\ncount_NaN_updated = data.isna().sum()\ncount_NaN_updated","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:07:36.864363Z","iopub.execute_input":"2021-08-24T20:07:36.864781Z","iopub.status.idle":"2021-08-24T20:07:36.913594Z","shell.execute_reply.started":"2021-08-24T20:07:36.864746Z","shell.execute_reply":"2021-08-24T20:07:36.912376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**It looks better now!**","metadata":{}},{"cell_type":"markdown","source":"# Distribution of the Ratings","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(data['Rating'],\n                   labels={'value': 'Rating',\n                           'count': 'Frequency',\n                           'color': 'Rating'}, color=data['Rating'])\nfig.update_layout(bargap=0.2)\nfig.update_traces(marker=dict(line=dict(color='#000000', width=2)))\nfig.update_layout(title_text='Distribution of the Ratings',\n                  title_x=0.5, title_font=dict(size=20))\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-24T20:07:38.688287Z","iopub.execute_input":"2021-08-24T20:07:38.688707Z","iopub.status.idle":"2021-08-24T20:07:39.121762Z","shell.execute_reply.started":"2021-08-24T20:07:38.688663Z","shell.execute_reply":"2021-08-24T20:07:39.12056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**According to the graph above, frequency of the Rating 5 is pretty high compared to the others.**","metadata":{}},{"cell_type":"markdown","source":"# Distribution of the Age of the Customers","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(data['Age'], marginal='box',\n                   labels={'value': 'Age'})\n\nfig.update_traces(marker=dict(line=dict(color='#000000', width=2)))\nfig.update_layout(title_text='Distribution of the Age of the Customers',\n                  title_x=0.5, title_font=dict(size=20))\nfig.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**As you can see from the 'Distribution of the Age of the Customers' graph, the age of the customers is usually distributed between 34 and 52. We have outliers that customers older than 80.**","metadata":{}},{"cell_type":"markdown","source":"# Distribution of the Recommendations","metadata":{}},{"cell_type":"code","source":"labels = ['Recommended', 'Not Recommended']\nvalues = [data[data['Recommended IND'] == 1]['Recommended IND'].value_counts()[1],\n          data[data['Recommended IND'] == 0]['Recommended IND'].value_counts()[0]]\ncolors = ['green', 'red']\n\nfig = go.Figure(data=[go.Pie(labels=labels, values=values, opacity=0.8)])\nfig.update_traces(textinfo='percent+label', marker=dict(line=dict(color='#000000', width=2), colors=colors))\nfig.update_layout(title_text='Distribution of the Recommendations', title_x=0.5, title_font=dict(size=20))\nfig.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**According to this pie chart, the most of the sales are Recommended.**","metadata":{}},{"cell_type":"markdown","source":"# Distribution of the Age and Recommendation","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(data['Age'], color=data['Recommended IND'],\n                   labels={'value': 'Age',\n                           'color': 'Recommended'}, marginal='box')\nfig.update_traces(marker=dict(line=dict(color='#000000', width=2)))\nfig.update_layout(title_text='Distribution of the Age and Recommendation',\n                  title_x=0.5, title_font=dict(size=20))\nfig.update_layout(barmode='overlay')\nfig.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Relationship between Ratings and Recommendation","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(data['Rating'], color=data['Recommended IND'],\n                   labels={'value': 'Rating',\n                           'color': 'Recommended?'})\nfig.update_layout(bargap=0.2)\nfig.update_traces(marker=dict(line=dict(color='#000000', width=2)))\nfig.update_layout(title_text='Relationship between Ratings and Recommendation',\n                  title_x=0.5, title_font=dict(size=20))\nfig.update_layout(barmode='group')\nfig.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**According to this graph above, almost all the Rating 5 and Rating 4 data points are recommended.**\n\n**In addition, Rating 1 and Rating 2 data points have almost no recommendations.**\n\n**For the further steps, I would create a common rating point with the Rating 4 and Rating 5 as well as Rating 1 and Rating 2. In this way, I would shrink the labels therefore, the model would perform better.**","metadata":{}},{"cell_type":"markdown","source":"# Relationship between Ratings and Departments","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(data['Rating'], color=data['Department Name'],\n                   labels={'value': 'Rating',\n                           'color': 'Department Name'})\nfig.update_layout(bargap=0.2)\nfig.update_traces(marker=dict(line=dict(color='#000000', width=2)))\nfig.update_layout(title_text='Relationship between Ratings and Departments',\n                  title_x=0.5, title_font=dict(size=20))\nfig.update_layout(barmode='group')\nfig.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**According to the graph above, Tops and Dresses have the most of the rating points. Trend and Jackets have the least.**","metadata":{}},{"cell_type":"markdown","source":"# Department and Recommendation Distribution","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(data['Department Name'], color=data['Recommended IND'],\n                   labels={'value': 'Department Name',\n                           'color': 'Recommended?'})\nfig.update_layout(bargap=0.2)\nfig.update_traces(marker=dict(line=dict(color='#000000', width=2)))\nfig.update_layout(title_text='Department Name and Recommendation Distribution',\n                  title_x=0.5, title_font=dict(size=20))\nfig.update_layout(barmode='group')\nfig.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Division and Recommendation Distribution\n","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(data['Division Name'], color=data['Recommended IND'],\n                   labels={'value': 'Division Name',\n                           'color': 'Recommended?'})\nfig.update_layout(bargap=0.2)\nfig.update_traces(marker=dict(line=dict(color='#000000', width=2)))\nfig.update_layout(title_text='Division Name and Recommendation Distribution',\n                  title_x=0.5, title_font=dict(size=20))\nfig.update_layout(barmode='group')\nfig.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Distribution of the Length of the Texts","metadata":{}},{"cell_type":"code","source":"data['length_of_text'] = [len(i.split(' ')) for i in data['Review Text']]\nfig = px.histogram(data['length_of_text'], marginal='box',\n                   labels={\"value\": \"Length of the Text\",\n                           \"color\": 'Recommended'},\n                   color=data['Recommended IND'])\n\nfig.update_traces(marker=dict(line=dict(color='#000000', width=2)))\nfig.update_layout(title_text='Distribution of the Length of the Texts',\n                  title_x=0.5, title_font=dict(size=20))\nfig.update_layout(barmode='overlay')\nfig.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**As you can see from the figure above, Recommended and not Recommended products almost have the same distribution length of text.**","metadata":{}},{"cell_type":"markdown","source":"# Top Frequent 200 Words in the Dataset (Before Cleaning)","metadata":{}},{"cell_type":"code","source":"FreqOfWords = data['Review Text'].str.split(expand=True).stack().value_counts()\nFreqOfWords_top200 = FreqOfWords[:200]\n\nfig = px.treemap(FreqOfWords_top200, path=[FreqOfWords_top200.index], values=0)\nfig.update_layout(title_text='Top Frequent 200 Words in the Dataset (Before Cleaning)',\n                  title_x=0.5, title_font=dict(size=20)\n                  )\nfig.update_traces(textinfo=\"label+value\")\nfig.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**According to this Treemap above, the top frequent 200 words usually include a stopword. For the further step of this notebook, I will remove them from the text.**","metadata":{}},{"cell_type":"markdown","source":"# <center> Data Preprocessing\n\n**In this step I will be dealing with the cleaning text data.**","metadata":{}},{"cell_type":"code","source":"# Lower Character all the Texts\ndata['Review Text'] = data['Review Text'].str.lower()\ndata['Review Text'].head()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:07:54.977691Z","iopub.execute_input":"2021-08-24T20:07:54.97807Z","iopub.status.idle":"2021-08-24T20:07:55.012811Z","shell.execute_reply.started":"2021-08-24T20:07:54.978034Z","shell.execute_reply":"2021-08-24T20:07:55.011484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Removing Punctuations and Numbers from the Text\ndef remove_punctuations_numbers(inputs):\n    return re.sub(r'[^a-zA-Z]', ' ', inputs)\n\n\ndata['Review Text'] = data['Review Text'].apply(remove_punctuations_numbers)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:07:56.911669Z","iopub.execute_input":"2021-08-24T20:07:56.912071Z","iopub.status.idle":"2021-08-24T20:07:57.679822Z","shell.execute_reply.started":"2021-08-24T20:07:56.912033Z","shell.execute_reply":"2021-08-24T20:07:57.678883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**In this section, I will remove all punctuations and numbers from the all dataframe. They will be not usefull for my model training.**","metadata":{}},{"cell_type":"markdown","source":"# Tokenizing with NLTK","metadata":{}},{"cell_type":"code","source":"def tokenization(inputs):  # Ref.1\n    return word_tokenize(inputs)\n\n\ndata['text_tokenized'] = data['Review Text'].apply(tokenization)\ndata['text_tokenized'].head()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:07:59.637386Z","iopub.execute_input":"2021-08-24T20:07:59.637735Z","iopub.status.idle":"2021-08-24T20:08:12.088388Z","shell.execute_reply.started":"2021-08-24T20:07:59.637705Z","shell.execute_reply":"2021-08-24T20:08:12.087045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Tokenizing with NLTK will help me to clean the dataset for better model training.**","metadata":{}},{"cell_type":"markdown","source":"# Stopwords Removal","metadata":{}},{"cell_type":"code","source":"stop_words = set(stopwords.words('english'))\nstop_words.remove('not')\n\n\ndef stopwords_remove(inputs):  # Ref.2\n    return [k for k in inputs if k not in stop_words]\n\n\ndata['text_stop'] = data['text_tokenized'].apply(stopwords_remove)\ndata['text_stop'].head()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:08:15.889043Z","iopub.execute_input":"2021-08-24T20:08:15.889494Z","iopub.status.idle":"2021-08-24T20:08:16.116816Z","shell.execute_reply.started":"2021-08-24T20:08:15.889457Z","shell.execute_reply":"2021-08-24T20:08:16.115268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lemmatization","metadata":{}},{"cell_type":"code","source":"lemmatizer = WordNetLemmatizer()\n\n\ndef lemmatization(inputs):  # Ref.1\n    return [lemmatizer.lemmatize(word=kk, pos='v') for kk in inputs]\n\n\ndata['text_lemmatized'] = data['text_stop'].apply(lemmatization)\ndata['text_lemmatized'].head()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:08:17.794509Z","iopub.execute_input":"2021-08-24T20:08:17.795033Z","iopub.status.idle":"2021-08-24T20:08:23.897507Z","shell.execute_reply.started":"2021-08-24T20:08:17.794991Z","shell.execute_reply":"2021-08-24T20:08:23.896731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Removing Words less than length 2\ndef remove_less_than_2(inputs):  # Ref.1\n    return [j for j in inputs if len(j) > 2]\n\n\ndata['final'] = data['text_lemmatized'].apply(remove_less_than_2)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:08:25.774362Z","iopub.execute_input":"2021-08-24T20:08:25.774977Z","iopub.status.idle":"2021-08-24T20:08:25.933561Z","shell.execute_reply.started":"2021-08-24T20:08:25.774896Z","shell.execute_reply":"2021-08-24T20:08:25.932208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Joining Tokens into Sentences\ndata['final'] = data['final'].str.join(' ')\ndata['final'].head()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:08:31.774508Z","iopub.execute_input":"2021-08-24T20:08:31.774972Z","iopub.status.idle":"2021-08-24T20:08:31.846524Z","shell.execute_reply.started":"2021-08-24T20:08:31.774914Z","shell.execute_reply":"2021-08-24T20:08:31.845355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Top Frequent 200 Words in the Dataset (After Cleaning)","metadata":{}},{"cell_type":"code","source":"FreqOfWords = data['final'].str.split(expand=True).stack().value_counts()\nFreqOfWords_top200 = FreqOfWords[:200]\n\nfig = px.treemap(FreqOfWords_top200, path=[FreqOfWords_top200.index], values=0)\nfig.update_layout(title_text='Top Frequent 200 Words in the Dataset (After Cleaning)',\n                  title_x=0.5, title_font=dict(size=20)\n                  )\nfig.update_traces(textinfo=\"label+value\")\nfig.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**As you can see from the Treemap above, all of the words are unique words and there are no stopwords in this set. Most words are 'dress', 'fit' and 'size'. Due to we are dealing with the clothing review dataset, this is pretty reasonable.**","metadata":{}},{"cell_type":"markdown","source":"# WordCloud of the Recommended Reviews","metadata":{}},{"cell_type":"code","source":"data_recommended = data[data['Recommended IND'] == 1]  # Dataframe that only includes recommended reviews\ndata_not_recommended = data[data['Recommended IND'] == 0]  # # Dataframe that only includes not recommended reviews\n\nWordCloud_recommended = WordCloud(max_words=500,\n                                  random_state=30,\n                                  collocations=True).generate(str((data_recommended['final'])))\n\nplt.figure(figsize=(15, 8))\nplt.imshow(WordCloud_recommended, interpolation='bilinear')\nplt.title('WordCloud of the Recommended Reviews', fontsize=20)\nplt.axis(\"off\")\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FreqOfWords = data_recommended['final'].str.split(expand=True).stack().value_counts()\nFreqOfWords_top200 = FreqOfWords[:200]\n\nfig = px.treemap(FreqOfWords_top200, path=[FreqOfWords_top200.index], values=0)\nfig.update_layout(title_text='Top Frequent 200 Words in the Recommended Reviews',\n                  title_x=0.5, title_font=dict(size=20)\n                  )\nfig.update_traces(textinfo=\"label+value\")\nfig.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# WordCloud of the Not Recommended Reviews","metadata":{}},{"cell_type":"code","source":"WordCloud_not_recommended = WordCloud(max_words=500,\n                                      random_state=30,\n                                      collocations=True).generate(str((data_not_recommended['final'])))\n\nplt.figure(figsize=(15, 8))\nplt.imshow(WordCloud_not_recommended, interpolation='bilinear')\nplt.title('WordCloud of the Not Recommended Reviews', fontsize=20)\nplt.axis(\"off\")\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FreqOfWords = data_not_recommended['final'].str.split(expand=True).stack().value_counts()\nFreqOfWords_top200 = FreqOfWords[:200]\n\nfig = px.treemap(FreqOfWords_top200, path=[FreqOfWords_top200.index], values=0)\nfig.update_layout(title_text='Top Frequent 200 Words in the Not Recommended Reviews',\n                  title_x=0.5, title_font=dict(size=20)\n                  )\nfig.update_traces(textinfo=\"label+value\")\nfig.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Distribution of the Length of the Texts after Cleaning","metadata":{}},{"cell_type":"code","source":"data['length_of_text'] = [len(i.split(' ')) for i in data['final']]\nfig = px.histogram(data['length_of_text'], marginal='box',\n                   labels={\"value\": \"Length of the Text\",\n                           \"color\": 'Recommended?'},\n                   color=data['Recommended IND'])\n\nfig.update_traces(marker=dict(line=dict(color='#000000', width=2)))\nfig.update_layout(title_text='Distribution of the Length of the Texts after Cleaning',\n                  title_x=0.5, title_font=dict(size=20))\nfig.update_layout(barmode='overlay')\nfig.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train-Test-Validation Split\n","metadata":{}},{"cell_type":"code","source":"# I will only use Text data to predict Recommendation\ny = data['Recommended IND']\nX = data['final']\n\nX.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:08:38.322362Z","iopub.execute_input":"2021-08-24T20:08:38.322775Z","iopub.status.idle":"2021-08-24T20:08:38.332082Z","shell.execute_reply.started":"2021-08-24T20:08:38.322739Z","shell.execute_reply":"2021-08-24T20:08:38.330467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train-Test-Validation Split\nx, X_test, y, y_test = train_test_split(X, y, test_size=0.2, random_state=13)  # Test: %20\n\nX_train, X_val, y_train, y_val = train_test_split(x, y, test_size=0.25, random_state=13)  # Val: %20\n\nprint('Shape of the X_train:', X_train.shape)\nprint('Shape of the X_test:', X_test.shape)\nprint('Shape of the X_val:', X_val.shape)\nprint('--'*20)\nprint('Shape of the y_train:', y_train.shape)\nprint('Shape of the y_test:', y_test.shape)\nprint('Shape of the y_val:', y_val.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:08:41.239277Z","iopub.execute_input":"2021-08-24T20:08:41.239812Z","iopub.status.idle":"2021-08-24T20:08:41.259301Z","shell.execute_reply.started":"2021-08-24T20:08:41.239777Z","shell.execute_reply":"2021-08-24T20:08:41.258062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tokenizing with Tensorflow\n","metadata":{}},{"cell_type":"code","source":"num_words = 10000\ntokenizer = Tokenizer(num_words=num_words, oov_token='<OOV>')\ntokenizer.fit_on_texts(X_train)\n\nTokenized_train = tokenizer.texts_to_sequences(X_train)\nTokenized_val = tokenizer.texts_to_sequences(X_val)\n\nprint('Non-tokenized Version: ', X_train[0])\nprint('Tokenized Version: ', tokenizer.texts_to_sequences([X_train[0]]))\nprint('--'*20)\nprint('Non-tokenized Version: ', X_train[80])\nprint('Tokenized Version: ', tokenizer.texts_to_sequences([X_train[80]]))","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:08:43.632717Z","iopub.execute_input":"2021-08-24T20:08:43.633474Z","iopub.status.idle":"2021-08-24T20:08:44.518957Z","shell.execute_reply.started":"2021-08-24T20:08:43.633401Z","shell.execute_reply":"2021-08-24T20:08:44.517975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Padding the Datasets\n","metadata":{}},{"cell_type":"code","source":"maxlen = 50\nPadded_train = pad_sequences(Tokenized_train, maxlen=maxlen, padding='pre')\nPadded_val = pad_sequences(Tokenized_val, maxlen=maxlen, padding='pre')","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:08:46.221281Z","iopub.execute_input":"2021-08-24T20:08:46.221688Z","iopub.status.idle":"2021-08-24T20:08:46.440355Z","shell.execute_reply.started":"2021-08-24T20:08:46.221653Z","shell.execute_reply":"2021-08-24T20:08:46.439273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <center> ANN Model Creation\n","metadata":{}},{"cell_type":"code","source":"# Creating the Model\nmodel = Sequential()\n\nmodel.add(Embedding(num_words, 16, input_length=maxlen))\nmodel.add(Dropout(0.2))\n\nmodel.add(GlobalAvgPool1D())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(1, activation='sigmoid'))\n\nopt = tf.optimizers.Adam(lr=0.55e-3)  # Learning Rate\n\nmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:08:48.258175Z","iopub.execute_input":"2021-08-24T20:08:48.258545Z","iopub.status.idle":"2021-08-24T20:08:48.391526Z","shell.execute_reply.started":"2021-08-24T20:08:48.258509Z","shell.execute_reply":"2021-08-24T20:08:48.390357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training the Model\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', mode='auto', patience=5,\n                                                  restore_best_weights=True)\n\nepochs = 100\nhist = model.fit(Padded_train, y_train, epochs=epochs,\n                 validation_data=(Padded_val, y_val),\n                 callbacks=[early_stopping], batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:08:52.911455Z","iopub.execute_input":"2021-08-24T20:08:52.911881Z","iopub.status.idle":"2021-08-24T20:09:46.600567Z","shell.execute_reply.started":"2021-08-24T20:08:52.911839Z","shell.execute_reply":"2021-08-24T20:09:46.599568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train and Validation Loss Graphs\n","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15, 8))\nplt.plot(hist.history['loss'], label='Train Loss')\nplt.plot(hist.history['val_loss'], label='Validation Loss')\nplt.title('Train and Validation Loss Graphs')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:09:49.533656Z","iopub.execute_input":"2021-08-24T20:09:49.534037Z","iopub.status.idle":"2021-08-24T20:09:49.858337Z","shell.execute_reply.started":"2021-08-24T20:09:49.534005Z","shell.execute_reply":"2021-08-24T20:09:49.85729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train and Validation Accuracy Graphs","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15, 8))\nplt.plot(hist.history['accuracy'], label='Train Accuracy')\nplt.plot(hist.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Train and Validation Accuracy Graphs')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:09:52.925088Z","iopub.execute_input":"2021-08-24T20:09:52.925478Z","iopub.status.idle":"2021-08-24T20:09:53.175351Z","shell.execute_reply.started":"2021-08-24T20:09:52.925447Z","shell.execute_reply":"2021-08-24T20:09:53.17411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preparing the Test Data\n","metadata":{}},{"cell_type":"code","source":"X_test = X_test.apply(tokenization)\nX_test = X_test.apply(stopwords_remove)\nX_test = X_test.apply(lemmatization)\nX_test = X_test.str.join(' ')\n\nX_test.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:09:57.879823Z","iopub.execute_input":"2021-08-24T20:09:57.880257Z","iopub.status.idle":"2021-08-24T20:10:00.107185Z","shell.execute_reply.started":"2021-08-24T20:09:57.88022Z","shell.execute_reply":"2021-08-24T20:10:00.106083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Tokenized_test = tokenizer.texts_to_sequences(X_test)\nPadded_test = pad_sequences(Tokenized_test, maxlen=maxlen, padding='pre')\n\ntest_evaluate = model.evaluate(Padded_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:10:01.759463Z","iopub.execute_input":"2021-08-24T20:10:01.759887Z","iopub.status.idle":"2021-08-24T20:10:02.106961Z","shell.execute_reply.started":"2021-08-24T20:10:01.75985Z","shell.execute_reply":"2021-08-24T20:10:02.106161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Confusion Matrix of the Test Data","metadata":{}},{"cell_type":"code","source":"pred_train_lstm = model.predict(Padded_train)\npred_test_lstm = model.predict(Padded_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:10:05.04853Z","iopub.execute_input":"2021-08-24T20:10:05.0491Z","iopub.status.idle":"2021-08-24T20:10:05.545212Z","shell.execute_reply.started":"2021-08-24T20:10:05.049056Z","shell.execute_reply":"2021-08-24T20:10:05.543976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, x in enumerate(pred_test_lstm):\n    if 0 <= x < 0.49:\n        pred_test_lstm[i] = 0\n    else:\n        pred_test_lstm[i] = 1\n\nfor i, x in enumerate(pred_train_lstm):\n    if 0 <= x < 0.49:\n        pred_train_lstm[i] = 0\n    else:\n        pred_train_lstm[i] = 1\n\nconf_mat = confusion_matrix(y_true=y_test, y_pred=pred_test_lstm)\nplt.figure(figsize=(15, 8))\nsns.heatmap(conf_mat, annot=True, fmt='g')\nplt.title('Confusion Matrix of the Test Data', fontsize=14)\nplt.ylabel('Real Class', fontsize=12)\nplt.xlabel('Predicted Class', fontsize=12)\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-24T20:10:06.875502Z","iopub.execute_input":"2021-08-24T20:10:06.875856Z","iopub.status.idle":"2021-08-24T20:10:07.290473Z","shell.execute_reply.started":"2021-08-24T20:10:06.875824Z","shell.execute_reply":"2021-08-24T20:10:07.289575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation Metrics of the LSTM Model","metadata":{}},{"cell_type":"code","source":"# Accuracy\ntrain_acc_lstm = round(accuracy_score(y_train, pred_train_lstm) * 100, 2)\nprint('Train Accuracy of the LSTM: %', train_acc_lstm)\ntest_acc_lstm = round(accuracy_score(y_test, pred_test_lstm) * 100, 2)\nprint('Test Accuracy of the LSTM: %', test_acc_lstm)\nprint('--' * 20)\n\n# Precision\ntrain_precision_lstm = round(precision_score(y_train, pred_train_lstm) * 100, 2)\nprint('Train Precision of the LSTM: %', train_precision_lstm)\nprecision_lstm = round(precision_score(y_test, pred_test_lstm) * 100, 2)\nprint('Test Precision of the LSTM: %', precision_lstm)\nprint('--' * 20)\n\n# Recall\ntrain_recall_lstm = round(recall_score(y_train, pred_train_lstm) * 100, 2)\nprint('Train Recall of the LSTM: %', train_recall_lstm)\nrecall_lstm = round(recall_score(y_test, pred_test_lstm) * 100, 2)\nprint('Test Recall of the LSTM: %', recall_lstm)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:10:09.824796Z","iopub.execute_input":"2021-08-24T20:10:09.825422Z","iopub.status.idle":"2021-08-24T20:10:09.861923Z","shell.execute_reply.started":"2021-08-24T20:10:09.825382Z","shell.execute_reply":"2021-08-24T20:10:09.860527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Having Fun with the LSTM Model","metadata":{}},{"cell_type":"code","source":"def predict_recommendation(input_text):  # The function for doing all the previous steps\n    input_text = input_text.lower()\n    input_text = re.sub(r'[^a-zA-Z]', ' ', input_text)\n    input_text = tokenization(input_text)\n    input_text = stopwords_remove(input_text)\n    input_text = lemmatization(input_text)\n    input_text = ' '.join(input_text)\n    input_text = tokenizer.texts_to_sequences([input_text])\n    input_text = pad_sequences(input_text, maxlen=maxlen, padding='pre')\n    input_text = model.predict(input_text)\n    if input_text >= 0.5:\n        input_text = f'Recommended with %{round(float(input_text*100), 2)}'\n    else:\n        input_text = f'Not Recommended with %{round(float(input_text*100), 2)}'\n\n    return print(input_text)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-24T20:10:13.834239Z","iopub.execute_input":"2021-08-24T20:10:13.834684Z","iopub.status.idle":"2021-08-24T20:10:13.842335Z","shell.execute_reply.started":"2021-08-24T20:10:13.834641Z","shell.execute_reply":"2021-08-24T20:10:13.841154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This reviews above are taken from several websites for testing the model with real world data. You can find these websites in the Ref.5\npredict_recommendation(\"The clothes are such poor quality and look nothing like they do on the website. I order 2 packages of fast fashion a year just as a treat, and I sorely regret buying from here. Fabrics are cheaper than what they charge, their seems to be no thought of sizing consitency and so on\")","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:10:15.862566Z","iopub.execute_input":"2021-08-24T20:10:15.863121Z","iopub.status.idle":"2021-08-24T20:10:15.909286Z","shell.execute_reply.started":"2021-08-24T20:10:15.863081Z","shell.execute_reply":"2021-08-24T20:10:15.908006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_recommendation(\"Beautiful colour of lemon great fit and length here in three days all l need is some fine weather to show if at it's best!!!!!\")","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:10:19.877282Z","iopub.execute_input":"2021-08-24T20:10:19.877637Z","iopub.status.idle":"2021-08-24T20:10:19.928018Z","shell.execute_reply.started":"2021-08-24T20:10:19.877607Z","shell.execute_reply":"2021-08-24T20:10:19.926843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_recommendation(\"As usual the clothes I ordered arrived quickly and were all a good fit, except for yoga pants , had to cit 4 ins off them but they are lovely pants. I shall wait for my next pay day!!\")","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:10:22.004332Z","iopub.execute_input":"2021-08-24T20:10:22.004878Z","iopub.status.idle":"2021-08-24T20:10:22.064689Z","shell.execute_reply.started":"2021-08-24T20:10:22.004834Z","shell.execute_reply":"2021-08-24T20:10:22.063159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_recommendation(\"I should've checked reviews before ordering... each item they sent was much worse quality in person than how it appeared online, and one of the dresses looked NOTHING in person what they said it was! I even double-checked to make sure they didn't accidentally send me the wrong item. see photos below.\")","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:10:24.260018Z","iopub.execute_input":"2021-08-24T20:10:24.260424Z","iopub.status.idle":"2021-08-24T20:10:24.313774Z","shell.execute_reply.started":"2021-08-24T20:10:24.260389Z","shell.execute_reply":"2021-08-24T20:10:24.312621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_recommendation(\"cheap material that falls apart in seconds. Clothes look nothing like the pictures. I bought the chunky heeled shoes they broke after two times of wearing them.\")","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:10:30.128203Z","iopub.execute_input":"2021-08-24T20:10:30.128721Z","iopub.status.idle":"2021-08-24T20:10:30.17516Z","shell.execute_reply.started":"2021-08-24T20:10:30.128686Z","shell.execute_reply":"2021-08-24T20:10:30.174085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_recommendation(\"Very fast dispatch and delivery. Clothes are always a consistent fit, good quality and well priced. Couldn't ask for more! Will be using again and would happily recommend.\")","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:10:32.571371Z","iopub.execute_input":"2021-08-24T20:10:32.57181Z","iopub.status.idle":"2021-08-24T20:10:32.62109Z","shell.execute_reply.started":"2021-08-24T20:10:32.571775Z","shell.execute_reply":"2021-08-24T20:10:32.619883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_recommendation(\"I have no complaints whatsoever, from ordering to getting my goods were excellent , down to the garments themselves, was as good as you see them on the website, I have shopped on here a few times and not disappointed at all, the only problem I have is that some trousers are a bit slim on leg and because I am a below knee amputee I have difficulty getting the right fit, otherwise very happy indeed.\")","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:10:34.988222Z","iopub.execute_input":"2021-08-24T20:10:34.988792Z","iopub.status.idle":"2021-08-24T20:10:35.038616Z","shell.execute_reply.started":"2021-08-24T20:10:34.988738Z","shell.execute_reply":"2021-08-24T20:10:35.037368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_recommendation(\"My dress had blue ink and biro stains on which was a real shame. I needed it for an outfit so had to put up with it but I'm not sure I'll order online again.\")","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:10:36.687323Z","iopub.execute_input":"2021-08-24T20:10:36.687795Z","iopub.status.idle":"2021-08-24T20:10:36.737678Z","shell.execute_reply.started":"2021-08-24T20:10:36.687756Z","shell.execute_reply":"2021-08-24T20:10:36.736541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ref. 6 from now on\npredict_recommendation(\"Sizes varied despite allegedly being the same size. Some of the quality was poor. I had to send most of my order back (including the jeans I didn't order) Usually I get good stuff from Yours, so I was disappointed\")","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:14:39.494483Z","iopub.execute_input":"2021-08-24T20:14:39.494848Z","iopub.status.idle":"2021-08-24T20:14:39.541357Z","shell.execute_reply.started":"2021-08-24T20:14:39.494814Z","shell.execute_reply":"2021-08-24T20:14:39.540262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_recommendation(\"I do really like yours clothing, just find the sizing is slightly off, a normal standard tshirt always seems too long and everything has dipped hems, doesn't look good when you're only short.\")","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:10:44.348316Z","iopub.execute_input":"2021-08-24T20:10:44.348714Z","iopub.status.idle":"2021-08-24T20:10:44.398985Z","shell.execute_reply.started":"2021-08-24T20:10:44.34868Z","shell.execute_reply":"2021-08-24T20:10:44.397574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_recommendation(\"I really love this dress. I ordered a large and it fits perfectly. There’s about 1/2” that touches the ground, which could easily be fixed with a pair of wedges. The cut is flattering, flowing and hides my mom belly. I am bottom heavy and this dress accommodated everything just fine. It shows just a bit of cleavage and just a bit of knee. The fabric doesn’t seem to need a slip. It gets a good breeze and looks pretty when you walk because of the ruffles. The color matched the picture exactly. If you’re considering this dress, I say, yes, buy it!\")","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:11:36.948997Z","iopub.execute_input":"2021-08-24T20:11:36.949458Z","iopub.status.idle":"2021-08-24T20:11:36.998467Z","shell.execute_reply.started":"2021-08-24T20:11:36.949419Z","shell.execute_reply":"2021-08-24T20:11:36.997347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_recommendation(\"I don't like writing negative reviews but this one pissed me off the second I pulled it out of the package. The fabric is the thinnest, cheapest crap I've ever seen used on a garment. None of the seams are finished properly with the seams visible on all the edges (see pictures for reference.) I just can't believe they're charging nearly $40 for this crap! I promptly returned it.\")","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:12:05.997467Z","iopub.execute_input":"2021-08-24T20:12:05.997939Z","iopub.status.idle":"2021-08-24T20:12:06.052443Z","shell.execute_reply.started":"2021-08-24T20:12:05.997883Z","shell.execute_reply":"2021-08-24T20:12:06.051087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_recommendation(\"The cheapest material I've ever seen. It was like someone wove paper napkins from the dollar store together to make a dress. It felt like if the fabric ever got wet it would disintegrate. Ordered the royal blue color but the dress was actually purple. The cut was flattering. Shame that was the only good thing.\")","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:12:50.604916Z","iopub.execute_input":"2021-08-24T20:12:50.605339Z","iopub.status.idle":"2021-08-24T20:12:50.653624Z","shell.execute_reply.started":"2021-08-24T20:12:50.605303Z","shell.execute_reply":"2021-08-24T20:12:50.651415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ref. 7 from now on\npredict_recommendation(\"I was so excited to receive this dress in the mail! The first day I wore it, I received so many compliments. The fit was true to size. I ordered an XS. Height 5'5, Weight 118, Bust 34B with an overall athletic build. I had no issues with the top of the dress as most of the review stated. If anything, I would suggest a pin. I would have rated this dress 5 stars however, I did have the side strap that holds the belt, break on the first day. I sowed it back into place but with the straps were a little more durable. Other than that, I love it!\")","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:13:35.641444Z","iopub.execute_input":"2021-08-24T20:13:35.64182Z","iopub.status.idle":"2021-08-24T20:13:35.690837Z","shell.execute_reply.started":"2021-08-24T20:13:35.641789Z","shell.execute_reply":"2021-08-24T20:13:35.68983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_recommendation(\"The dress does not look like the dress pictures. The material seems cheaper and this does not fit well. It’s way too big. I requested to return for a refund and now I have to pay to ship it back as well. If I could give zero stars I would. Would not recommend.\")","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:23:49.655258Z","iopub.execute_input":"2021-08-24T20:23:49.655732Z","iopub.status.idle":"2021-08-24T20:23:49.706877Z","shell.execute_reply.started":"2021-08-24T20:23:49.655686Z","shell.execute_reply":"2021-08-24T20:23:49.705665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_recommendation(\"I love this item it's was not dark blue like the picture but i love i it's very comfortable always wanted one I taken pics in side out to show the cord you can adjust also colour i would recommend this to anyone can we're all around the house also great to sleep in can not wait for my other two to arrive\")","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:24:40.169845Z","iopub.execute_input":"2021-08-24T20:24:40.170263Z","iopub.status.idle":"2021-08-24T20:24:40.230132Z","shell.execute_reply.started":"2021-08-24T20:24:40.17023Z","shell.execute_reply":"2021-08-24T20:24:40.228358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_recommendation(\"This kaftan is NOT a silky material at all, it is a slightly transparent and dull cotton material. It is NOT as bright nor pretty as in the picture, it's more of a navy colour. When it arrived it looked worn, not ironed and had 2 small patches of damage, like someone had tried it on and maybe some jewellery had gotten stuck upon the material which then had been pulled off. I have included a picture of the damage that I took on my phone.\")","metadata":{"execution":{"iopub.status.busy":"2021-08-24T20:25:28.695525Z","iopub.execute_input":"2021-08-24T20:25:28.695973Z","iopub.status.idle":"2021-08-24T20:25:28.746145Z","shell.execute_reply.started":"2021-08-24T20:25:28.695924Z","shell.execute_reply":"2021-08-24T20:25:28.744795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**I would love to have your feedbacks and suggestions. Please leave your comments about data preprocessing steps, learning curves and final evaluation resuls!**","metadata":{}},{"cell_type":"markdown","source":"# References\n\n[1] https://medium.com/analytics-vidhya/text-preprocessing-for-nlp-natural-language-processing-beginners-to-master-fd82dfecf95\n\n[2] https://stackabuse.com/removing-stop-words-from-strings-in-python/\n\n[3] https://www.geeksforgeeks.org/python-lemmatization-with-nltk/\n\n[4] https://www.kaggle.com/rmisra/news-headlines-dataset-for-sarcasm-detection\n\n[5] https://uk.trustpilot.com/review/www.yoursclothing.co.uk?stars=4\n\n[6] https://www.amazon.co.uk/product-reviews/B08FYWYMVL/ref=cm_cr_unknown?ie=UTF8&filterByStar=four_star&reviewerType=all_reviews&pageNumber=1#reviews-filter-bar\n\n[7] https://www.amazon.co.uk/product-reviews/B014R7EZT8/ref=cm_cr_getr_d_paging_btm_next_5?ie=UTF8&filterByStar=one_star&reviewerType=all_reviews&pageNumber=5#reviews-filter-bar","metadata":{}}]}