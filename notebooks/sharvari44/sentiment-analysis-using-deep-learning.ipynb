{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n\n# Time\nimport time\nimport datetime\n\n# Numerical\nimport numpy as np\nimport pandas as pd\n\n# Tools\nimport itertools\nfrom collections import Counter\n\n# NLP\nimport re\nfrom nltk.corpus import stopwords\n\n# Preprocessing\nfrom sklearn import preprocessing\nfrom sklearn.utils import class_weight as cw\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\n# Model Selection\nfrom sklearn.model_selection import train_test_split\n\n# Evaluation Metrics\nfrom sklearn import metrics \nfrom sklearn.metrics import f1_score, accuracy_score,confusion_matrix,classification_report\n\n# Deep Learing Preprocessing - Keras\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing import sequence\nfrom keras.utils import to_categorical\n\n# Deep Learning Model - Keras\nfrom keras.models import Model\nfrom keras.models import Sequential\n\nfrom keras.layers import Dense, Embedding\nfrom keras.models import Sequential\n\n# Deep Learning Model - Keras - RNN\nfrom keras.layers import Embedding, LSTM, Bidirectional\n\n# Deep Learning Model - Keras - General\nfrom keras.layers import Input, Add, concatenate, Dense, Activation, BatchNormalization, Dropout, Flatten\nfrom keras.layers import LeakyReLU, PReLU, Lambda, Multiply\n\nfrom keras.preprocessing import sequence\n\n# Deep Learning Parameters - Keras\nfrom keras.optimizers import RMSprop, Adam\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/Tweets.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[['text','airline_sentiment']]\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.reindex(np.random.permutation(df.index))\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\ndef text_cleaning(tweet):\n    letters = re.sub(\"^a-zA-Z\",\" \",tweet)\n    ht = re.sub(r'http\\S+', '',letters)\n    mention = re.sub(r'@\\w+', '', ht)\n    p = re.sub(r'[^\\w\\s]','',mention)\n    words = p.lower().split()\n    stops = set(stopwords.words(\"english\"))\n    meaningful_words = [w for w in words if not w in stops]\n    return( \" \".join(meaningful_words))\ndf['text_clean']=df['text'].apply(lambda x: text_cleaning(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y = df['airline_sentiment']\nlenc = LabelEncoder()\nY = lenc.fit_transform(Y)\nY = to_categorical(Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(df['text_clean'], Y, test_size=0.2,random_state=37)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_words = len(set(\" \".join(X_train).split()))\nmax_len = X_train.apply(lambda x: len(x)).max()\nmax_words, max_len","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tk = Tokenizer(num_words=max_words)\ntk.fit_on_texts(X_train)\nX_train_tk = tk.texts_to_sequences(X_train)\nX_test_tk = tk.texts_to_sequences(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_pad = sequence.pad_sequences(X_train_tk, maxlen=max_len)\nX_test_pad = sequence.pad_sequences(X_test_tk, maxlen = max_len)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes = 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_weight(y):\n    class_weight_current =  cw.compute_class_weight('balanced', np.unique(y), y)\n    return class_weight_current\nclass_weight = get_weight(Y_train.flatten())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model = Sequential()\nbase_model.add(Embedding(max_words, 8, input_length=max_len))\nbase_model.add(Flatten())\nbase_model.add(Dense(64, activation='relu'))\nbase_model.add(Dense(64, activation='relu'))\nbase_model.add(Dense(3, activation='softmax'))\nbase_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def deep_lr_model(model):\n    batch_size = 512\n    epochs = 20\n\n\n    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n    \n    history = model.fit(X_train_pad, Y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=1,class_weight=class_weight)\n    \n    return history\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_history = deep_lr_model(base_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = []\nscore_base = base_model.evaluate(X_test_pad, Y_test)\nscore.append(score_base[1]*100)\nscore_base[1]*100\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ypred1 = base_model.predict_classes(X_test_pad,verbose=1)\nypred1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg_model = Sequential()\nreg_model.add(Embedding(max_words, 8, input_length=max_len))\nreg_model.add(Flatten())\nreg_model.add(Dense(64, activation='relu'))\nreg_model.add(Dense(3, activation='softmax'))\nreg_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg_history = deep_lr_model(reg_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_reg = reg_model.evaluate(X_test_pad, Y_test)\nscore.append(score_reg[1]*100)\nscore_reg[1]*100\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_model = Sequential()\ndrop_model.add(Embedding(max_words, 8, input_length=max_len))\ndrop_model.add(Flatten())\ndrop_model.add(Dense(64, activation='relu'))\ndrop_model.add(Dropout(0.5))\ndrop_model.add(Dense(3, activation='softmax'))\ndrop_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dropout_history = deep_lr_model(drop_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_drop = drop_model.evaluate(X_test_pad, Y_test)\nscore.append(score_drop[1]*100)\nscore_drop[1]*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import regularizers\n\ndrop1_model = Sequential()\ndrop1_model.add(Embedding(max_words, 8, input_length=max_len))\ndrop1_model.add(Flatten())\ndrop1_model.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\ndrop1_model.add(Dense(3, activation='softmax'))\ndrop1_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rgz_history = deep_lr_model(drop1_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_drop1 = drop1_model.evaluate(X_test_pad, Y_test)\nscore.append(score_drop1[1]*100)\nscore_drop1[1]*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_performance(history, metric_name):\n    metric = history.history[metric_name]\n    val_metric = history.history['val_'+metric_name]\n    ep = range(1,21)\n    plt.plot(ep,metric,label=\"Training Accuracy\")\n    plt.plot(ep,val_metric,label=\"Validation Accuracy\")\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_performance(base_history,'acc')\nplot_performance(base_history,'loss')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_performance(dropout_history,'acc')\nplot_performance(dropout_history,'loss')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_performance(reg_history,'acc')\nplot_performance(reg_history,'loss')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_performance(rgz_history,'acc')\nplot_performance(rgz_history,'loss')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_model(model, epoch_stop):\n    model.fit(X_train_pad\n              , Y_train\n              , epochs=epoch_stop\n              , batch_size=512\n              , verbose=1)\n    results = model.evaluate(X_test_pad, Y_test)\n    \n    return results\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_results = test_model(base_model, 10)\nprint('/n')\nprint('Test accuracy of baseline model: {0:.2f}%'.format(base_results[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_results = test_model(drop_model, 10)\nprint('/n')\nprint('Test accuracy of baseline model: {0:.2f}%'.format(drop_results[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop1_results = test_model(drop1_model, 10)\nprint('/n')\nprint('Test accuracy of baseline model: {0:.2f}%'.format(drop1_results[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg_results = test_model(reg_model, 10)\nprint('/n')\nprint('Test accuracy of baseline model: {0:.2f}%'.format(reg_results[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l = ['base model','reduced model', 'dropout model','regularized model']\nindex = [1,2,3,4]\nplt.bar(index,score,color='rgcy')\nplt.xticks(index,['base model','reduced model', 'dropout model','regularized model'],rotation=90)\nplt.show()\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}