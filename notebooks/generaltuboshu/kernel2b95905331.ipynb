{"cells":[{"metadata":{"_uuid":"c630de5ca8daafbde03ac9c2cdce083605e046ff"},"cell_type":"markdown","source":"Data available in: https://www.kaggle.com/rdoume/beerreviews\n\nMethodology and experimentation schema based on: https://www.slideshare.net/tanyacash/strata-2017-nyc-how-to-hire-and-test-for-data-skills-a-onesizefitsall-interview-kit"},{"metadata":{"trusted":true,"_uuid":"d1e82513697f8ac7a7cd6e9385969db0856594a1"},"cell_type":"code","source":"import math\nimport numpy as np\nimport pandas as pd\nimport pandas_profiling\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da7ea6963b9b6c30fab6bb0db44569850118b04a"},"cell_type":"markdown","source":"# Data loading and exploratory analysis"},{"metadata":{"trusted":true,"_uuid":"e90b71069561bbc5bd661ece39863244167ac749"},"cell_type":"code","source":"beersDf = pd.read_csv( '../input/beerreviews/beer_reviews.csv' )\n# beers_df.shape\nbeersDf['review_time'] = pd.to_datetime( beersDf['review_time'], unit = 's' )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7cdfa30e38ba8c77d12923ae369a3df4e2f08923"},"cell_type":"code","source":"# beers_df.head()\n# beers_df.dtypes\n#pandas_profiling.ProfileReport( beers_df )\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot of reviews per year"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set()\n\ngroup_by_date = beersDf[[ 'review_time' ]].groupby(beersDf[ 'review_time' ].dt.year).agg( [ 'count' ] )\nplt.figure( figsize = ( 10, 5 ))\nplt.plot( group_by_date )\nplt.xlabel( 'Year', fontsize=28 )\nplt.ylabel( ' Number of reviews' , fontsize=28)\nplt.title( 'Number of Reviews per year', fontsize=28 )\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"091225634bf71eabc6187ad723655f9e86388bbc"},"cell_type":"code","source":"# I consider reviews from 2002 because for previous years there are no much information.\nbeersDf = beersDf.loc[ beersDf[ 'review_time' ].dt.year >= 2004]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Unique data numbers"},{"metadata":{"trusted":true,"_uuid":"ecf6e980cd4534d5291a9e68353c2e6723d577ab"},"cell_type":"code","source":"# Count of unique breweries => Integrity issues evidenced => Id is not considered for subsequent analysis\nprint( 'Unique breweries' )\nprint( 'By id:', beersDf[ 'brewery_id' ].nunique() )\nprint( 'By name:', beersDf[ 'brewery_name' ].nunique() )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee29c7a6aebe80a5d49b7c01fbd6744af9a400e1"},"cell_type":"code","source":"# Count of unique beers => Integrity issues evidenced => Id is not considered for subsequent analysis\nprint( 'Unique beers' )\nprint( 'By id:', beersDf[ 'beer_beerid' ].nunique() )\nprint( 'By name:', beersDf[ 'beer_name' ].nunique() )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6fc9b66b4ce66e130591ff1be3ad461eacd8ccf3"},"cell_type":"code","source":"# Count of unique users\nprint( 'Unique users:', beersDf[ 'review_profilename' ].nunique() )\nallUserNumbers = beersDf[ 'review_profilename' ].nunique()\n\ndef plotReviewNumbers():\n    beerReviewNumbers = []\n    beerReviewPercent = []\n    \n    for i in range(1, 6):\n        \n        numTemp = beersDf[ 'review_profilename' ].value_counts()[ beersDf[ 'review_profilename' ].value_counts() > i ].shape[0]\n        \n        beerReviewNumbers.append(numTemp)\n        beerReviewPercent.append(round(numTemp/allUserNumbers, 2)*100)\n    xRange = list(range(1, 6))\n    \n    plt.figure( figsize = ( 10, 5 ))\n    plt.plot(xRange, beerReviewNumbers)\n\n    plt.xlabel('review numbers', fontsize=28 )\n    plt.ylabel(' Number of users' , fontsize=28)\n    plt.title('Number of reviews vs Number of reviews', fontsize=28)\n    plt.show()\n    \n    plt.figure( figsize = ( 10, 5 ))\n    plt.plot(xRange, beerReviewPercent)\n\n    plt.xlabel('review numbers', fontsize=28 )\n    plt.ylabel(' percentage of users' , fontsize=28)\n    plt.title('Propotion of users vs Number of reviews ', fontsize=28)\n    plt.show()\n    \n        \nplotReviewNumbers()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prediction overall rating based on surprise\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"groupedOverall = beersDf[['review_profilename', 'beer_beerid',  'review_overall' ]].drop_duplicates()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### using SVD Matrix decomposition"},{"metadata":{"trusted":true},"cell_type":"code","source":"from surprise import SVD\nfrom surprise import Dataset\nfrom surprise import accuracy\nfrom surprise import Reader\nfrom surprise.model_selection import train_test_split\n# Load the movielens-100k dataset (download it if needed),\n# A reader is still needed but only the rating_scale param is requiered.\nreader = Reader(rating_scale=(0, 5))\ndata = Dataset.load_from_df(beersDf[ ['review_profilename', 'beer_beerid',  'review_overall' ] ].drop_duplicates(), reader)\n# sample random trainset and testset\n# test set is made of 25% of the ratings.\ntrainset, testset = train_test_split(data, test_size=.25)\n# We'll use the famous SVD algorithm.\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### prediction all testset as avearage[](http://)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def MSE(predictions, labels):\n    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n    return sum(differences) / len(differences)\n#     return sum(differences) / len(differences)\n\ndef predictAsAverage():\n    testPrediction = [trainset.global_mean]*len(testset)\n    testGroundTrue = []\n    for element in testset:\n        testGroundTrue.append(element[2])\n    \n    print(testPrediction[:10])\n    print(testGroundTrue[:10])\n    print(\"mse of prediction as average is \", MSE(testPrediction, testGroundTrue))\n    \npredictAsAverage()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# from surprise import KNNBaseline\n\n# def KNNBase():\n\n#     bsl_options = {'reg': 0,\n#                 'method': 'sgd',\n#                'learning_rate': .0005,\n#                'n_epochs': 10\n#                }\n    \n#     algo = KNNBaseline(bsl_options=bsl_options)\n#     algo.fit(trainset)\n#     predictions = algo.test(testset)\n#     # Then compute RMSE\n#     print(accuracy.rmse(predictions)**2)\n    \n# KNNBase()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom surprise import NormalPredictor\n\ndef normalPred():\n\n    algo = NormalPredictor()\n    algo.fit(trainset)\n    predictions = algo.test(testset)\n    # Then compute RMSE\n    print(accuracy.rmse(predictions)**2)\n    \nnormalPred()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### using BaselineOnly"},{"metadata":{"trusted":true},"cell_type":"code","source":"from surprise import BaselineOnly\n\ndef baselineOnlyNoReg():\n    print('Using SGD')\n    bsl_options = {'reg': 0,\n                    'method': 'sgd',\n                   'learning_rate': .0005,\n                   'n_epochs': 10\n                   }\n\n    algo = BaselineOnly(bsl_options=bsl_options)\n\n    algo.fit(trainset)\n    predictions = algo.test(testset)\n\n    # Then compute RMSE\n    print(accuracy.rmse(predictions)**2)\n\nbaselineOnlyNoReg()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from surprise import BaselineOnly\n\ndef baselineOnlyALS():\n    \n    print('Using ALS')\n    bsl_options = {'method': 'als',\n                   'n_epochs': 20,\n                   'reg_u': 12, #12\n                   'reg_i': 8  #8\n                   }\n\n    algo = BaselineOnly(bsl_options=bsl_options)\n    algo.fit(trainset)\n    predictions = algo.test(testset)\n    # Then compute RMSE\n    print(accuracy.rmse(predictions)**2)\n    \nbaselineOnlyALS()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def baselineOnlySGD():\n    print('Using SGD')\n    bsl_options = {'reg': 0.02, # 0.02\n                    'method': 'sgd',\n                   'learning_rate': .0005,\n                   'n_epochs': 20\n                   }\n\n    algo = BaselineOnly(bsl_options=bsl_options)\n\n    algo.fit(trainset)\n    predictions = algo.test(testset)\n\n    # Then compute RMSE\n    print(accuracy.rmse(predictions)**2)\n\nbaselineOnlySGD()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### using NMF"},{"metadata":{"trusted":true},"cell_type":"code","source":"from surprise import NMF\ndef NMF_():\n    \n    algo = NMF(biased = True)\n    algo.fit(trainset)\n    predictions = algo.test(testset)\n\n    # Then compute RMSE\n    print(accuracy.rmse(predictions)**2)\n    \nNMF_()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### using SVD"},{"metadata":{"trusted":true},"cell_type":"code","source":"from surprise import SVD\ndef SVD_():\n    algo = SVD()\n    # Train the algorithm on the trainset, and predict ratings for the testset\n    algo.fit(trainset)\n    predictions = algo.test(testset)\n    # Then compute RMSE\n    print(accuracy.rmse(predictions)**2)\n    \nSVD_()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## plot reviews distribution"},{"metadata":{"trusted":true,"_uuid":"c67ffe6aec3931672eca4d10ce31884d604b81ac"},"cell_type":"code","source":"# A beer subset removing review information is created \ngroupedBDF = beersDf[ [ 'beer_name', 'brewery_name', 'beer_style', 'beer_abv' ] ].drop_duplicates()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"444472e077a5a99e42e20dd3069749d468d41f29"},"cell_type":"code","source":"# Count of unique beers in grouped dataset => Integrity issues evidenced with respect to previous analysis => For beer identification, I will use these 4 keys\ngroupedBDF.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe6184792d8b9c8446463b0ef8b9463c05da09b7"},"cell_type":"code","source":"# Count of beers with the same name but different brewery, style or AVB%\ngroupedBDF.loc[ groupedBDF.duplicated( subset = [ 'beer_name' ], keep = False ) ].sort_values( by = 'beer_name'  ).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5a236f9bf050863dd7fe2eefdd4215518d70d4ec"},"cell_type":"code","source":"# Beers by brewery\ngroupedBDF[ 'brewery_name' ].value_counts( dropna = False ).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6fae5487ec1c685f8982495ad613a4690bf1cd57"},"cell_type":"code","source":"# Beers by style\ngroupedBDF[ 'beer_style' ].value_counts( dropna = False ).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### correlation map"},{"metadata":{"trusted":true,"_uuid":"77579001bafa6ee4c977128caa5068832f3799e0"},"cell_type":"code","source":"# # Pearson correlation\n# sns.heatmap( beersDf[ ['review_aroma', 'review_appearance', 'review_palate', 'review_taste', 'beer_abv', 'review_overall'] ].corr(), center = 0,  vmin = -1, vmax = 1 )\n\n# plt.title( 'Pearson Correlation' )\n\nimport seaborn as sb\npearsoncorr = beersDf[['review_aroma', 'review_appearance', 'review_palate', 'review_taste', 'beer_abv', 'review_overall']].corr(method='pearson')\n\nplt.figure( figsize = ( 5, 5 ))\nplt.title( 'Pearson Correlation' )\n\nsb.heatmap(pearsoncorr, \n            xticklabels=pearsoncorr.columns,\n            yticklabels=pearsoncorr.columns,\n            cmap='RdBu_r',\n            annot=True,\n            linewidth=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a8868a88e7f8cc4e3527d721503dc512801d65b"},"cell_type":"code","source":"# # Spearman correlation\n# sns.heatmap( beersDf[ [ 'review_overall', 'review_aroma', 'review_appearance', 'review_palate', 'review_taste', 'beer_abv' ] ].corr( method = 'spearman' ), center = 0,  vmin = -1, vmax = 1 )\n# plt.title( 'Spearman Correlation' )\n\n\npearsoncorr = beersDf[['review_aroma', 'review_appearance', 'review_palate', 'review_taste', 'beer_abv', 'review_overall']].corr(method='spearman')\n\nplt.figure( figsize = ( 6, 6 ))\nplt.title('Spearman Correlation')\nsb.heatmap(pearsoncorr, \n            xticklabels=pearsoncorr.columns,\n            yticklabels=pearsoncorr.columns,\n            cmap='RdBu_r',\n            annot=True,\n            linewidth=0.5)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = plt.cm.get_cmap( 'tab10' )\n\ndftemp = beersDf[['review_aroma', 'review_appearance', 'review_palate', 'review_taste', 'beer_abv', 'review_overall']]\ndftemp.hist(figsize = (12, 12))\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(beersDf[ 'review_overall' ].mean())\nprint(beersDf[ 'review_aroma' ].mean())\nprint(beersDf[ 'review_appearance' ].mean())\nprint(beersDf[ 'review_palate' ].mean())\nprint( beersDf[ 'review_taste' ].mean())\n\nmeanRatingList = []\nmeanRatingList.append(beersDf[ 'review_overall' ].mean())\nmeanRatingList.append(beersDf[ 'review_aroma' ].mean())\nmeanRatingList.append(beersDf[ 'review_appearance' ].mean())\nmeanRatingList.append(beersDf[ 'review_palate' ].mean())\nmeanRatingList.append(beersDf[ 'review_taste' ].mean())\n\nxRange = ['overall', 'aroma', 'appearance', 'palate', 'taste']\n\nplt.figure( figsize = ( 10, 5 ))\nplt.plot(xRange, meanRatingList)\n\nplt.xlabel('aspects', fontsize=28 )\nplt.ylabel('mean of ratings' , fontsize=28)\nplt.title('Mean rating per aspect', fontsize=28)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b3dafafd77ada95f72fda197172df5ab26c4c044"},"cell_type":"code","source":"# An new meassure is created by averaging review by factor\nbeersDf[ 'review_average' ] = round( ( ( beersDf[ 'review_overall' ] + beersDf[ 'review_aroma' ] + beersDf[ 'review_appearance' ] + beersDf[ 'review_palate' ] + beersDf[ 'review_taste' ] ) / 5 ) * 2 ) / 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"add5a138cc9305e9a604e7ab89703c4f7f279e00"},"cell_type":"code","source":"# # Groupping by different review factors for visualization purposes\n# group_by_review_overall = beersDf[ 'review_overall' ].value_counts( dropna = False ).reset_index().rename( columns = { 'index' : 'review', 'review_overall' : 'overall' } ).sort_values( by = 'review' )\n# group_by_review_aroma = beersDf[ 'review_aroma' ].value_counts( dropna = False ).reset_index().rename( columns = { 'index' : 'review', 'review_aroma' : 'aroma' } ).sort_values( by = 'review' )\n# group_by_review_appearance = beersDf[ 'review_appearance' ].value_counts( dropna = False ).reset_index().rename( columns = { 'index' : 'review', 'review_appearance' : 'appearance' } ).sort_values( by = 'review' )\n# group_by_review_palate = beersDf[ 'review_palate' ].value_counts( dropna = False ).reset_index().rename( columns = { 'index' : 'review', 'review_palate' : 'palate' } ).sort_values( by = 'review' )\n# group_by_review_taste = beersDf[ 'review_taste' ].value_counts( dropna = False ).reset_index().rename( columns = { 'index' : 'review', 'review_taste' : 'taste' } ).sort_values( by = 'review' )\n# group_by_review_average = beersDf[ 'review_average' ].value_counts( dropna = False ).reset_index().rename( columns = { 'index' : 'review', 'review_average' : 'average' } ).sort_values( by = 'review' )\n\n# group_by_review_overall[ 'review' ] = group_by_review_overall[ 'review' ].astype( str )\n# group_by_review_aroma[ 'review' ] = group_by_review_aroma[ 'review' ].astype( str )\n# group_by_review_appearance[ 'review' ] = group_by_review_appearance[ 'review' ].astype( str )\n# group_by_review_palate[ 'review' ] = group_by_review_palate[ 'review' ].astype( str )\n# group_by_review_taste[ 'review' ] = group_by_review_taste[ 'review' ].astype( str )\n# group_by_review_average[ 'review' ] = group_by_review_average[ 'review' ].astype( str )\n\n# group_by_review = group_by_review_overall.merge( group_by_review_aroma, how = 'outer', on = [ 'review' ] )\n# group_by_review = group_by_review.merge( group_by_review_appearance, how = 'outer', on = [ 'review' ] )\n# group_by_review = group_by_review.merge( group_by_review_palate, how = 'outer', on = [ 'review' ] )\n# group_by_review = group_by_review.merge( group_by_review_taste, how = 'outer', on = [ 'review' ] )\n# group_by_review = group_by_review.merge( group_by_review_average, how = 'outer', on = [ 'review' ] )\n# group_by_review = group_by_review.fillna( 0 )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"194874feafe58de2f88e1dcc8297462b78176ed2"},"cell_type":"code","source":"# cm = plt.cm.get_cmap( 'tab10' ).\n\n# f, ( ( ax1, ax2, ax3 ), ( ax4, ax5, ax6 ) ) = plt.subplots( 2, 3, sharex = 'col', sharey = 'row', figsize = ( 17, 10 ) )\n# ax1.barh( group_by_review[ 'review' ], group_by_review[ 'overall' ], color = cm )\n# ax1.set_title( 'Review Overall' )\n# ax2.barh( group_by_review[ 'review' ], group_by_review[ 'aroma' ], color = cm )\n# ax2.set_title( 'Review Aroma' )\n# ax3.barh( group_by_review[ 'review' ], group_by_review[ 'appearance' ], color = cm )\n# ax3.set_title( 'Review Appearance' )\n# ax4.barh( group_by_review[ 'review' ], group_by_review[ 'palate' ], color = cm )\n# ax4.set_title( 'Review Palate' )\n# ax5.barh( group_by_review[ 'review' ], group_by_review[ 'taste' ], color = cm )\n# ax5.set_title( 'Review Taste' )\n# ax6.barh( group_by_review[ 'review' ], group_by_review[ 'average' ], color = cm )\n# ax6.set_title( 'Review Average' )\n# f.suptitle( 'Distribution of Reviews by Ratings')\n# group_by_review = group_by_review.sort_values('review', ascending=False)\n\n# group_by_review.hist(figsize=(12,12))\n# plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### shuffle data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nrandom.seed(5)\n\nX = beersDf[['review_aroma', 'review_appearance', 'review_palate', 'review_taste']].values.tolist()\ny = beersDf[ 'review_overall' ].tolist()\ny = [int(i*2) for i in y]\n\n# Shuffle the data\nXy = list(zip(X,y))\nrandom.shuffle(Xy)\n\nX = [d[0] for d in Xy]\ny = [d[1] for d in Xy]\n\nprint(len(X))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### split data"},{"metadata":{"trusted":true,"_uuid":"a7969c0f51a4a85047168944d747a2f7a9e63a85"},"cell_type":"code","source":"# Defining the linear model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import datasets\n\n# X = beersDf[ [ 'review_aroma', 'review_appearance', 'review_palate', 'review_taste' ] ]\nsplit = int(1e5)\nXtrain = X[:2*split]\nytrain = y[:2*split]\nxtest = X[14*split:15*split]\nytest = y[14*split:15*split]\n\n# Create an instance of Logistic Regression Classifier and fit the data.\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## K-means (not working) "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\nimport numpy as np\ndef k_means():\n    kmeans = KMeans(n_clusters=11, random_state=0).fit(Xtrain)\n    y_km = kmeans.fit_predict(Xtrain)\n    y_km = list(y_km)\n    for i in range(1, 12):\n        print(i, y_km.count(i))\n    for i in range(11):\n        print(i, ytrain.count(i))\n# k_means()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## logistic regression "},{"metadata":{"trusted":true},"cell_type":"code","source":"def logistRegre():\n    mseList = []\n    CList = []\n    for i in range(10):\n        \n        ytestTemp = ytest\n        C = math.pow(10, i-6)\n        CList.append(C)\n        logreg = LogisticRegression(C=C, solver='lbfgs', multi_class='multinomial')\n        \n        logreg.fit(X = Xtrain, y = ytrain)\n        yPred = logreg.predict(xtest)\n\n        yPred = [i/2 for i in yPred]\n        ytestTemp = [i/2 for i in ytestTemp]\n        mseTemp = MSE(yPred, ytestTemp)\n        mseList.append(mseTemp)\n        print(\"C is \", C, \" and MSE is \", mseTemp)\n    \n    plt.figure( figsize = ( 20, 10 ))\n    plt.plot(CList, mseList)\n    plt.xscale('log')\n    plt.xlabel('regularization strength: C', fontsize=28 )\n    plt.ylabel('MSE' , fontsize=28)\n    plt.title('MSE vs regularization strength', fontsize=28)\n    plt.show()\n    \n    \nlogistRegre()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71199525a1fb0dd2c68515c4b339cbf801782f7b"},"cell_type":"code","source":"# Training and generating predictions for the model\nlinear_model = LinearRegression( normalize = True )\ndef linearRegre():\n    ytestTemp = ytest\n    linear_model.fit( X = Xtrain, y = ytrain )\n    yPred = linear_model.predict(xtest)\n    yPred = [i/2 for i in yPred]\n    ytestTemp = [i/2 for i in ytestTemp]\n    mseTemp = MSE(yPred, ytestTemp)\n    print(mseTemp)\n    print(linear_model.coef_)\n    \nlinearRegre()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"068dc306dac8d2ea36664dfdf3695fbbcb7409a3"},"cell_type":"code","source":"# Coeffifients for each feature (aroma, appearance, palate, taste)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bf513623b6702593d945578f55132f7fd5daf5be"},"cell_type":"markdown","source":"Similar to results by correlation, the coefficients contributing more information to the model are the corresponding to taste and aroma features."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":1}