{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**My first blog**\n\nThis Blog is an instance of performing data analysis to show how to perform data analysis using Python. In this notebook, We will be using Palmer Archipelago (Antarctica) penguin dataset collected by Dr. Kristen Gorman. I'll use this data to perform basic data analysis and then build machine learning model to predict the species of penguins using palmer penguins dataset","metadata":{}},{"cell_type":"markdown","source":"Firstly, I'll import library that I will be using in this session.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2021-09-21T15:28:24.116013Z","iopub.execute_input":"2021-09-21T15:28:24.116418Z","iopub.status.idle":"2021-09-21T15:28:24.120085Z","shell.execute_reply.started":"2021-09-21T15:28:24.11639Z","shell.execute_reply":"2021-09-21T15:28:24.119067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I'll use method \"pd.read_csv()\" to get dataset and use method \".sample()\" to see sample of dataset.","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"../input/palmer-archipelago-antarctica-penguin-data/penguins_size.csv\")\ndf.sample(10)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T15:28:24.121752Z","iopub.execute_input":"2021-09-21T15:28:24.122097Z","iopub.status.idle":"2021-09-21T15:28:24.174682Z","shell.execute_reply.started":"2021-09-21T15:28:24.122066Z","shell.execute_reply":"2021-09-21T15:28:24.174111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now Let's play a little bit with our dataset.\n\nLet's see meta data (infomation of dataset).","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-09-21T15:28:24.175918Z","iopub.execute_input":"2021-09-21T15:28:24.176299Z","iopub.status.idle":"2021-09-21T15:28:24.196245Z","shell.execute_reply.started":"2021-09-21T15:28:24.176272Z","shell.execute_reply":"2021-09-21T15:28:24.195533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then let's check our dataset if there are any missing values\n\nTo check if there are any missing values in our dataset or not, I'll use method \".isnull()\" and \".sum()\" to summarize how many missing values there are in each columns.","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-09-21T15:28:24.19744Z","iopub.execute_input":"2021-09-21T15:28:24.197857Z","iopub.status.idle":"2021-09-21T15:28:24.205779Z","shell.execute_reply.started":"2021-09-21T15:28:24.197827Z","shell.execute_reply":"2021-09-21T15:28:24.204998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After we checked our dataset, There are 5 columns that contain missing values (culmen_length_mm, culmen_depth_mm, flipper_length_mm, body_mass_g and sex)\n\nlet's clean the missing values\n\nFor columns culmen_length_mm, culmen_depth_mm, flipper_length_mm and body_mass_g, they are numeric variables. \n\nLet's calculate mean values for each column and replace missing values with mean values.","metadata":{}},{"cell_type":"code","source":"mean_culmen_length = round(df['culmen_length_mm'].mean(),1)\nmean_culmen_depth = round(df['culmen_depth_mm'].mean(),1)\nmean_flipper_length = round(df['flipper_length_mm'].mean(),1)\nmean_body_mass = round(df['body_mass_g'].mean(),1)\n\nprint(\"mean_culmen_length : \", mean_culmen_length)\nprint(\"mean_culmen_depth :\", mean_culmen_depth)\nprint(\"mean_flipper_length :\",mean_flipper_length)\nprint(\"mean_body_mass :\",mean_body_mass)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T15:28:24.208197Z","iopub.execute_input":"2021-09-21T15:28:24.208718Z","iopub.status.idle":"2021-09-21T15:28:24.217414Z","shell.execute_reply.started":"2021-09-21T15:28:24.208687Z","shell.execute_reply":"2021-09-21T15:28:24.216534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After calculating mean for each column, I'll replace missing missing values by using method \".replace()\".\n\nFor first argument, You need to define what you want to replace. So in this case, I want to replace missing values. In order to tell function that we want to replace missing values we need to put np.nan for the first argument.\n\nFor second argument, You need to define what you want replace missing values with. In this case, I want to replace missing values that I calculated in the previous code cell.\n\nAnd for third argument, Since I want to replace missing values with in the object df without making new object.\nI'll set inplace argument as true so that replace method will replace missing values in the object df. ","metadata":{}},{"cell_type":"code","source":"df['culmen_length_mm'].replace(np.nan , mean_culmen_length , inplace=True)\ndf['culmen_depth_mm'].replace(np.nan , mean_culmen_depth , inplace=True)\ndf['flipper_length_mm'].replace(np.nan , mean_flipper_length , inplace=True)\ndf['body_mass_g'].replace(np.nan , mean_body_mass , inplace=True)\n\ndf.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-09-21T15:28:24.218596Z","iopub.execute_input":"2021-09-21T15:28:24.219097Z","iopub.status.idle":"2021-09-21T15:28:24.235892Z","shell.execute_reply.started":"2021-09-21T15:28:24.219063Z","shell.execute_reply":"2021-09-21T15:28:24.235026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now missing numeric variables are already replaced. For sex variable, since it's category variable.\n\nI'll drop rows that contains missing sex variable. To drop missing values, I'll use method \".dropna\".\n\nFor first argument, I'll tell function the variable that I want drop.\n\nAnd for second argument, If you set axis as 0 , function will drop rows that cotain missing values. \n\nBut if you set axis as 1 , Function will drop colum that contain missing values.\n\nSo in this case, I want ot drop rows that contain missing values, I'll set axis as 1.","metadata":{}},{"cell_type":"code","source":"df.dropna(subset=['sex'] , axis = 0 , inplace = True)\n\nprint(df.isnull().sum())\nprint(\"observation : \",len(df))","metadata":{"execution":{"iopub.status.busy":"2021-09-21T15:28:24.237159Z","iopub.execute_input":"2021-09-21T15:28:24.23746Z","iopub.status.idle":"2021-09-21T15:28:24.249081Z","shell.execute_reply.started":"2021-09-21T15:28:24.237432Z","shell.execute_reply":"2021-09-21T15:28:24.248238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's use filter function to get data that you want.\n\nTo filter data in python, We can use method \".query()\"\n\nFor example, If i want to get data of penguins that are male, The code to execute will be like in the code cell below.","metadata":{}},{"cell_type":"code","source":"df.query(\"sex == 'MALE'\").sample(10)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T15:28:24.250356Z","iopub.execute_input":"2021-09-21T15:28:24.250575Z","iopub.status.idle":"2021-09-21T15:28:24.275217Z","shell.execute_reply.started":"2021-09-21T15:28:24.25055Z","shell.execute_reply":"2021-09-21T15:28:24.274476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"But if you have more than one criterias to filter your data, You can link youe criterias with \"and\" or \"or\". \n\nFor example, If you want to get data of penguins that are male and from Dream island, The code to execute will be like in the code cell below","metadata":{}},{"cell_type":"code","source":"df.query(\"sex == 'MALE' and island == 'Dream'\").sample(10)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T15:28:24.276592Z","iopub.execute_input":"2021-09-21T15:28:24.276857Z","iopub.status.idle":"2021-09-21T15:28:24.306076Z","shell.execute_reply.started":"2021-09-21T15:28:24.276832Z","shell.execute_reply":"2021-09-21T15:28:24.305105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's easily bin our penguins into different groups by\nusing body mass variable as a criteria.\n\nTo bin our penguins into different groups\nby using body mass, We need to generate four different numbers from body mass variable that are equally distant and use these four numbers to bin our penguins.\n\nI'll bin penguins into 3 different groups as small, medium and large group.\n\nTo generate numbers that are equally distant, I'll use \"np.linspace()\" function\n\nTo use \"np.linspace()\" function, There are three arguments to set. you need to set the range of number and specify how many numbers you want to generate.\n\nIn this case, I want to bin penguins into 3 different groups by using body mass variables, So the range of number that i'll generate is from minimum body mass to maximum body mass.","metadata":{}},{"cell_type":"code","source":"bin = np.linspace(df['body_mass_g'].min(),df['body_mass_g'].max(),4)\nlabel_names = ['small' , 'medium' , 'large']\nprint(bin)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T15:28:24.307397Z","iopub.execute_input":"2021-09-21T15:28:24.30759Z","iopub.status.idle":"2021-09-21T15:28:24.313578Z","shell.execute_reply.started":"2021-09-21T15:28:24.307567Z","shell.execute_reply":"2021-09-21T15:28:24.312786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As the result of executing code, We get four different numbers that are equally distant.\n\nHere is my criteria to bin penguins, If penguins' body mass is between 2700 and 3900, They will be binned into small group. \n\nIf penguins' body mass is between 3900 and 5100,\nThey will be binned into medium group. If penguins' body mass is between 5100 and 6300,\nThey will be binned into large group.\n\nSo to do binning penguins into groups, I'll use \"pd.cut()\" function and create new column named size.\n\nFor the first arguments, You need to specify what variable you want to use to bin your data.\n\nThe second argument is number that you want to use to bin your data.\n\nAnd the third argnment is the label of group that you want ot bin your data into.","metadata":{}},{"cell_type":"code","source":"df['size'] = pd.cut(df['body_mass_g'] , bin , labels = label_names )\ndf.sample(10)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T15:28:24.314984Z","iopub.execute_input":"2021-09-21T15:28:24.315187Z","iopub.status.idle":"2021-09-21T15:28:24.34584Z","shell.execute_reply.started":"2021-09-21T15:28:24.315163Z","shell.execute_reply":"2021-09-21T15:28:24.344788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After we binned our penguins in three different group, Let's create prediction model to predict specie of penguins by using variable flipper length and body mass variables. \n\nBut firstly, let make some visualization to see relationship between flipper length and body mass. ","metadata":{}},{"cell_type":"code","source":"sns.scatterplot(data = df , x = 'flipper_length_mm' , y = 'body_mass_g' , hue = 'species' , alpha = 0.5 , palette=['blue','green','orange'])\nplt.title(\"Relationship : flipper length vs body mass\")\nplt.xlabel(\"flipper length\")\nplt.ylabel(\"body mass\")","metadata":{"execution":{"iopub.status.busy":"2021-09-21T15:28:24.347281Z","iopub.execute_input":"2021-09-21T15:28:24.347721Z","iopub.status.idle":"2021-09-21T15:28:24.731105Z","shell.execute_reply.started":"2021-09-21T15:28:24.34769Z","shell.execute_reply":"2021-09-21T15:28:24.730077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As the graph displays, it seems that flipper length and body mass has positive correlation. \n\nIn this graph, I use diffenrent colors to display different species.\n\nAs the result, it sseems that gentoo is the largest specie and Chinstrap and \n\nSo let's calculate correlation of theses two variable by using method \".corr()\"","metadata":{}},{"cell_type":"code","source":"df[['flipper_length_mm' , 'body_mass_g']].corr()","metadata":{"execution":{"iopub.status.busy":"2021-09-21T15:28:24.735245Z","iopub.execute_input":"2021-09-21T15:28:24.735536Z","iopub.status.idle":"2021-09-21T15:28:24.748717Z","shell.execute_reply.started":"2021-09-21T15:28:24.735505Z","shell.execute_reply":"2021-09-21T15:28:24.747602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The correlation between flipper length and body mass is 0.87 which indicates that two variable are strongly positively correlated.\n\nNow it 's time  to make a model for prediction.\n\nWe need  to import our model \"KMeans\" from sklearn library which is the model that we're going to make in this session and we need to import train_test_split function to split our data for training and testing. \n\nWhy do we need to split data fro traing and testing?\n\nIn real life, If you take all your data for training model and you want to evaluate your model with data that your model' ve never seen before how do you get new data?\n\nWhen working with real projects, I don't think you'll have much time to collect data again to evaluate your model because of deadline.\n\nSo that's why we need to split data into two partition, One is for training model and one is for testing or evaluating your model.\n\n","metadata":{}},{"cell_type":"code","source":"from sklearn.cluster import KMeans\nfrom sklearn.model_selection import train_test_split \n","metadata":{"execution":{"iopub.status.busy":"2021-09-21T15:28:24.751973Z","iopub.execute_input":"2021-09-21T15:28:24.752224Z","iopub.status.idle":"2021-09-21T15:28:25.226099Z","shell.execute_reply.started":"2021-09-21T15:28:24.752194Z","shell.execute_reply":"2021-09-21T15:28:25.225185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I've already import model and \"train_test_split\" function.\n\nFor number of clusters, I'll set number of clusters equal to 3 whcih is eqaul to penguins' sepcies (Adelie, Chinstrap, Gentoo)\n\nAs i told earlier, I'll use flipper length and body mass variable to build prediction model In this session.\n\nSo i create object 'x' (contains variable used to predict) and 'y' (contains species variable which will be used later)\n\nand then put object 'x' and 'y' into 'train_test_split' function to split data where test size of data is equal to 20% of whole data.\n\nSo the code to execute will be like inthe following code cell.\n\n\n","metadata":{}},{"cell_type":"code","source":"model = KMeans(n_clusters = 3)\n\nx = df[['flipper_length_mm' , 'body_mass_g']]\ny = df['species']\n\nx_train,x_test,y_train,y_test = train_test_split(x, y , test_size = 0.2)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T15:28:25.227415Z","iopub.execute_input":"2021-09-21T15:28:25.227665Z","iopub.status.idle":"2021-09-21T15:28:25.235537Z","shell.execute_reply.started":"2021-09-21T15:28:25.227638Z","shell.execute_reply":"2021-09-21T15:28:25.23495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After spliting data into 2 partition, I'll use method \".fit()\" to fit dependent variables in the model.","metadata":{}},{"cell_type":"code","source":"model.fit(x_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T15:28:25.23722Z","iopub.execute_input":"2021-09-21T15:28:25.237533Z","iopub.status.idle":"2021-09-21T15:28:25.299986Z","shell.execute_reply.started":"2021-09-21T15:28:25.237493Z","shell.execute_reply":"2021-09-21T15:28:25.298957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then, I'll use method \".labels_\" to see the result of prediction from the model that i build.","metadata":{}},{"cell_type":"code","source":"model.labels_","metadata":{"execution":{"iopub.status.busy":"2021-09-21T15:28:25.301517Z","iopub.execute_input":"2021-09-21T15:28:25.301794Z","iopub.status.idle":"2021-09-21T15:28:25.309476Z","shell.execute_reply.started":"2021-09-21T15:28:25.301754Z","shell.execute_reply":"2021-09-21T15:28:25.30837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I'll create new column and named \"species\" and put y_test into this new column.\n\nand create new column named \"predicted_species\" and put the result of prediction from model into this new column.","metadata":{}},{"cell_type":"code","source":"x_train['species'] = y_train\nx_train['predicted_species'] = model.labels_\n\nx_train","metadata":{"execution":{"iopub.status.busy":"2021-09-21T15:28:25.31093Z","iopub.execute_input":"2021-09-21T15:28:25.311998Z","iopub.status.idle":"2021-09-21T15:28:25.360541Z","shell.execute_reply.started":"2021-09-21T15:28:25.311953Z","shell.execute_reply":"2021-09-21T15:28:25.35965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I'll create new object nameก \"center\". This object contains three numbers of x axis and y axis generated by model.\n\nTo get number, I'll use method \".cluster_centers_\".","metadata":{}},{"cell_type":"code","source":"center = model.cluster_centers_\nprint(center)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T15:28:25.361993Z","iopub.execute_input":"2021-09-21T15:28:25.3625Z","iopub.status.idle":"2021-09-21T15:28:25.370357Z","shell.execute_reply.started":"2021-09-21T15:28:25.362458Z","shell.execute_reply":"2021-09-21T15:28:25.369327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I take number of x axis and y axis and the result of prediction from model to make visaulization.\n\nHere is scatter plot of relationship between flipper length and body mass. In each point, It represents each observation as species.\n\nCompares to previous graph the I'll build before building model, Yellow, Blue and Green color represent \n\nas Getoo species, Chinstrap and Adelie respectively.\n\nAnd three number of x axis and y axis will be displayed as black diamond in the graph.\n\nHere is how model works to predict specie of penguins. After fitting model, it generates number of x axis and y axis displayed \n\nas black diamond in graph and I'll cal this as group point. \n\nand model will calculate distance between each data point and group point.\n\nAnd model will group each data point into the group point that is the closest. ","metadata":{}},{"cell_type":"code","source":"plt.scatter(x = center[:,0] , y = center[:,1] , marker = 'D' , color = 'black')\nsns.scatterplot(data=x_train , x = 'flipper_length_mm' , y = 'body_mass_g' , hue='predicted_species',alpha=0.5,palette=['blue','green','orange'])","metadata":{"execution":{"iopub.status.busy":"2021-09-21T15:28:25.372074Z","iopub.execute_input":"2021-09-21T15:28:25.372692Z","iopub.status.idle":"2021-09-21T15:28:25.841079Z","shell.execute_reply.started":"2021-09-21T15:28:25.372591Z","shell.execute_reply":"2021-09-21T15:28:25.840135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train['predicted_species'].replace([0,1,2] , ['Adelie','Gentoo','Chinstrap'] , inplace=True)\nx_train","metadata":{"execution":{"iopub.status.busy":"2021-09-21T15:28:25.845692Z","iopub.execute_input":"2021-09-21T15:28:25.848213Z","iopub.status.idle":"2021-09-21T15:28:25.884583Z","shell.execute_reply.started":"2021-09-21T15:28:25.848163Z","shell.execute_reply":"2021-09-21T15:28:25.883821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.crosstab(x_train['species'] ,x_train['predicted_species'])","metadata":{"execution":{"iopub.status.busy":"2021-09-21T15:28:25.888801Z","iopub.execute_input":"2021-09-21T15:28:25.889394Z","iopub.status.idle":"2021-09-21T15:28:25.917873Z","shell.execute_reply.started":"2021-09-21T15:28:25.889352Z","shell.execute_reply":"2021-09-21T15:28:25.917204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = x_train['species'] == x_train['predicted_species']\nprint(result)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T15:28:25.919015Z","iopub.execute_input":"2021-09-21T15:28:25.919375Z","iopub.status.idle":"2021-09-21T15:28:25.926132Z","shell.execute_reply.started":"2021-09-21T15:28:25.919344Z","shell.execute_reply":"2021-09-21T15:28:25.924992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result.mean()","metadata":{"execution":{"iopub.status.busy":"2021-09-21T15:28:25.929202Z","iopub.execute_input":"2021-09-21T15:28:25.930189Z","iopub.status.idle":"2021-09-21T15:28:25.943084Z","shell.execute_reply.started":"2021-09-21T15:28:25.930017Z","shell.execute_reply":"2021-09-21T15:28:25.942179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict = model.predict(x_test)\nprint(predict)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T15:28:25.944269Z","iopub.execute_input":"2021-09-21T15:28:25.944634Z","iopub.status.idle":"2021-09-21T15:28:25.958107Z","shell.execute_reply.started":"2021-09-21T15:28:25.944604Z","shell.execute_reply":"2021-09-21T15:28:25.957502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test['species'] = y_test\nx_test['predicted_species'] = predict\n\nx_test","metadata":{"execution":{"iopub.status.busy":"2021-09-21T15:28:25.959319Z","iopub.execute_input":"2021-09-21T15:28:25.959762Z","iopub.status.idle":"2021-09-21T15:28:25.984965Z","shell.execute_reply.started":"2021-09-21T15:28:25.959709Z","shell.execute_reply":"2021-09-21T15:28:25.984328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.scatterplot(data=x_test , x = 'flipper_length_mm' , y = 'body_mass_g' , hue='predicted_species',alpha=0.7,palette=['blue','green','orange'])\nplt.scatter(x=center[:,0] , y=center[:,1] , color = 'black' , marker = 'D')","metadata":{"execution":{"iopub.status.busy":"2021-09-21T15:28:25.986102Z","iopub.execute_input":"2021-09-21T15:28:25.986457Z","iopub.status.idle":"2021-09-21T15:28:26.345594Z","shell.execute_reply.started":"2021-09-21T15:28:25.986428Z","shell.execute_reply":"2021-09-21T15:28:26.344868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test['predicted_species'].replace([0,1,2],['Adelie','Gentoo','Chinstrap'],inplace=True)\nx_test","metadata":{"execution":{"iopub.status.busy":"2021-09-21T15:28:26.348634Z","iopub.execute_input":"2021-09-21T15:28:26.348883Z","iopub.status.idle":"2021-09-21T15:28:26.370678Z","shell.execute_reply.started":"2021-09-21T15:28:26.348855Z","shell.execute_reply":"2021-09-21T15:28:26.369882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.crosstab(x_test['species'] , x_test['predicted_species'])","metadata":{"execution":{"iopub.status.busy":"2021-09-21T15:28:26.371761Z","iopub.execute_input":"2021-09-21T15:28:26.372065Z","iopub.status.idle":"2021-09-21T15:28:26.394076Z","shell.execute_reply.started":"2021-09-21T15:28:26.372033Z","shell.execute_reply":"2021-09-21T15:28:26.393472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_test = x_test['species'] == x_test['predicted_species']\nprint(result_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T15:28:26.395174Z","iopub.execute_input":"2021-09-21T15:28:26.395515Z","iopub.status.idle":"2021-09-21T15:28:26.408352Z","shell.execute_reply.started":"2021-09-21T15:28:26.395485Z","shell.execute_reply":"2021-09-21T15:28:26.407782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_test.mean()","metadata":{"execution":{"iopub.status.busy":"2021-09-21T15:28:26.409271Z","iopub.execute_input":"2021-09-21T15:28:26.410071Z","iopub.status.idle":"2021-09-21T15:28:26.423497Z","shell.execute_reply.started":"2021-09-21T15:28:26.410033Z","shell.execute_reply":"2021-09-21T15:28:26.422495Z"},"trusted":true},"execution_count":null,"outputs":[]}]}