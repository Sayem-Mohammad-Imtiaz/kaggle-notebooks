{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"17b70126-57a1-e218-10d8-7aaf4b32b609"},"source":"# Predicting Solar Radiation\n\n### *Gil Wassermann*"},{"cell_type":"markdown","metadata":{"_cell_guid":"55b47a86-2254-7cbd-6559-b5b61f32cf7b"},"source":"### Load Data\n\n(NB this analysis was conducted locally so apologies for any odd formatting due to upload)\n\nThe first step is to load in the data and have a quick look at the dataset and the structure of the data to be predicted."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9c2b31ec-d62e-c26d-3a22-642265c317fe"},"outputs":[],"source":"# libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport datetime\nimport pytz\nfrom sklearn import linear_model\n\n%matplotlib inline"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3001ac05-27e6-34f3-aa95-3ff172d4797e"},"outputs":[],"source":"# import data\ndata = pd.read_csv('../input/SolarPrediction.csv')\n\n# read few lines\ndata.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a43515ac-09e2-36d1-56a1-4c061f23797c"},"outputs":[],"source":"# time is in reverse order, therefore order ascending\ndata = data.sort_values(by='UNIXTime', ascending=True).reset_index(drop=True)\ndata.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"75717b50-5a49-d111-1b48-2d259728314c"},"outputs":[],"source":"# set Hawaii tz\nHItz = pytz.timezone(zone='US/Hawaii')\n\n# create a column which is type datetime\ndatetimeHI = data['UNIXTime'].apply(lambda x: \n                                 datetime.datetime.utcfromtimestamp(x).replace(tzinfo=pytz.utc).astimezone(HItz))\n# add to df\ndata['DatetimeHI'] = datetimeHI"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"657cda02-7d60-6b70-6ea7-a718cf542a49"},"outputs":[],"source":"# show data to predict\nplt.plot(data['DatetimeHI'], data['Radiation'])\nplt.title('Radiation Between Sept 2016 and Dec 2016')\nplt.xticks(rotation=45);"},{"cell_type":"markdown","metadata":{"_cell_guid":"b1c9d9ff-5b1e-e995-96fa-e3ce328b3f15"},"source":"##### Preliminary Thoughts\n\n* There appear to be daily spikes, might consider a micro- and a macro- model\n* Something odd is happening late nov, early Dec, should be looked into. Missing data? Thanksgiving? Weather patterns?\n* Need to think about how to split into training and testing data: take random days? block off December? "},{"cell_type":"markdown","metadata":{"_cell_guid":"ac068b6e-b15d-4681-7e86-25c0f81abf54"},"source":"### One Week Analysis\n\nFrom very basic data analysis it appears that there is some sort of oscillating pattern on a more micro level. To investigate this, we will take the first week of the data and explore."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"57cabed2-ddb7-53ae-9933-f44f1a3c476a"},"outputs":[],"source":"# extract one week of data\nweekendmarker = datetime.datetime(2016,9, 8).replace(tzinfo=HItz)\nweekonedata = data[data['DatetimeHI'] < weekendmarker]\nplt.plot(weekonedata['DatetimeHI'], weekonedata['Radiation'])\nplt.title('Radiation 9/1/2016 - 9/8/2016')\nplt.xticks(rotation=45)\nplt.ylabel('Radiation Level')\nplt.xlabel('Date');"},{"cell_type":"markdown","metadata":{"_cell_guid":"c077b6ff-2ae6-8009-9a1b-8c666db9b240"},"source":"So definitely there is definitely a daily spike. Will be interesting to see if any smoothing functions need to be used.\n\nAlso, it appears that whatever the final model is, there should be an indicator variable governing whether the sun is up or not as, in hours of darkness solar radiation drops off.\n\nWe need to see how the other variables evolve over week:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"98d529cb-5361-94c5-ea1c-591714b69888"},"outputs":[],"source":"def abstract_week_plot(ax, dates, col, colname):\n    # function to take in column of data and plot the\n    # week's worth of data\n    # returns an axis so can be added to a larger plot\n    \n    # color radiation so it is easy to identify as the dependent var\n    if colname == 'Radiation':\n        plt_color = 'red'\n    else:\n        plt_color = 'blue'\n    \n    # plot the data\n    ax.plot(dates, col, c=plt_color)\n    \n    # format\n    ax.set_title('{colname} 9/1/2016 - 9/8/2016'.format(colname=colname))\n    ax.set_ylabel('{colname} Level'.format(colname=colname))\n    ax.set_xlabel('Date')\n    \n    # rotation\n    for tick in ax.get_xticklabels():\n        tick.set_rotation(45)\n    \n    return ax"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"45185f8f-16c7-b03c-6272-51f7cc3b0aee"},"outputs":[],"source":"# make plot larger\nplt.rcParams['figure.figsize'] = 16, 12\n\n# loop over all columns important in data\nts_cols = ['Radiation', 'Temperature', 'Pressure', 'Humidity', 'WindDirection(Degrees)', 'Speed']\nfig, axes = plt.subplots(len(ts_cols), sharex=True)\nfor i, ax in enumerate(axes):\n    ax = abstract_week_plot(ax, weekonedata['DatetimeHI'], weekonedata[ts_cols[i]], ts_cols[i])\n\n# prevent squashing\nfig.tight_layout()"},{"cell_type":"markdown","metadata":{"_cell_guid":"cefadc54-4283-b02c-23ee-0a97911c9377"},"source":"From the above graphs, the following can be seen:\n\n* Temperature and Radiation have a very close connection. Oscillations appear to be quite in step. \n* The volatility of wind direction could have something to do with the spikes in radiaton.\n* Pressure is also cyclic but has a different period than radiation.\n* Speed and Humidity appear to be noisy but there could be something lurking there!"},{"cell_type":"markdown","metadata":{"_cell_guid":"53d90797-f235-ae3a-f0a7-51c528637a2a"},"source":"### Anomalous Radiation Investigation\n\nLooking at the plot of radiation through the dataset, there appears to be a period of time where data is missing and around which the level of radiation appears to be very small indeed. We will now look at this perdiod in greater depth. To do this we will expand the functionality of our week plot for time series."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fe27c393-8b73-63e2-f964-2e6dff8413a5"},"outputs":[],"source":"def abstract_subsection_plot(ax, data, colname, start_dt, end_dt):\n    # function to take in column of data and plot the\n    # week's worth of data\n    # returns an axis so can be added to a larger plot\n    \n    # subset the data\n    subset_data = data[(data['DatetimeHI'] > start_dt) & (data['DatetimeHI'] < end_dt)]\n    dates = subset_data['DatetimeHI']\n    col = subset_data[colname]\n    \n    # turn start date and end date into strings\n    srt = start_dt.strftime('%m/%d/%Y')\n    end = end_dt.strftime('%m/%d/%Y')\n    \n    # color radiation so it is easy to identify as the dependent var\n    if colname == 'Radiation':\n        plt_color = 'red'\n    else:\n        plt_color = 'blue'\n    \n    # plot the data\n    ax.plot(dates, col, c=plt_color)\n    \n    # format\n    ax.set_title('{colname} {srt} - {end}'.format(colname=colname, srt=srt, end=end))\n    ax.set_ylabel('{colname} Level'.format(colname=colname))\n    ax.set_xlabel('Date')\n    \n    # rotation\n    for tick in ax.get_xticklabels():\n        tick.set_rotation(45)\n    \n    return ax"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"96e0d397-6dc3-299f-44a5-e5658726d428"},"outputs":[],"source":"# loop over all columns important in data\nfig, axes = plt.subplots(len(ts_cols), sharex=True)\nfor i, ax in enumerate(axes):\n    ax = abstract_subsection_plot(\n        ax,\n        data,\n        ts_cols[i],\n        datetime.datetime(2016,11, 27).replace(tzinfo=HItz),\n        datetime.datetime(2016,12, 15).replace(tzinfo=HItz),\n    )\n# prevent squashing\nfig.tight_layout()"},{"cell_type":"markdown","metadata":{"_cell_guid":"57637c1b-f579-1507-9c0c-0d6fb82b8e73"},"source":"It appears that the data between November 29th and December 9th has been corrupted in some way and there is a certain amount of missing data here:\n\n* There appears to be missing data between the end of Nov 29th and the start of Dec 1st and the end of Dec 5th and the middle of Dec 8th: no measurements for any fields.\n* There appears to be holes in the temperature and humidity datasets between Nov 29th and the middle of Dec 8th. \n\nSo, we have some missing data. The next step is to decide what to do with this. We could perform some sort of imputation in these dates. However, I would argue that because the behaviour of the dependent variable (the radiation) is abnormally small between these dates, there is something interesting going on here and I would not want to impute using values using data from times that do not reflect this abnormality in radiation.\n\nTherefore, I will drop the dates between Nov 29th and Dec 8th from the dataset. Given this gap in data, I will then use Dec 8th to Dec 31st as my testing data and the data from Sep 1st to Nov 29th as my training data.\n\nThere are another two points that I will further investigate as well that show up as odd blips in the full plot from the first section of this notebook."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"38b3244b-3f37-043c-c3cc-336900561c6e"},"outputs":[],"source":"# loop over all columns important in data\nfig, axes = plt.subplots(len(ts_cols), sharex=True)\nfor i, ax in enumerate(axes):\n    ax = abstract_subsection_plot(\n        ax,\n        data,\n        ts_cols[i],\n        datetime.datetime(2016,9, 8).replace(tzinfo=HItz),\n        datetime.datetime(2016,10, 3).replace(tzinfo=HItz),\n    )\n# prevent squashing\nfig.tight_layout()"},{"cell_type":"markdown","metadata":{"_cell_guid":"b0196a45-604f-483d-e4b7-cb05d4416725"},"source":"Unlike the graphs in late November the \"flat spots\" that occur here occur in all data columns at the same time. Therefore, they do not need to be dealt with. They appear flat here as matplotlib places these on a timeline. Therefore, our cutoffs from above hold."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6e2089e1-9d6f-65b9-5182-da4de403cb08"},"outputs":[],"source":"start_train = datetime.datetime(2016, 9, 1).replace(tzinfo=HItz)\nend_train = datetime.datetime(2016,11, 29).replace(tzinfo=HItz)\nstart_test = datetime.datetime(2016,12, 9).replace(tzinfo=HItz)\nend_test = datetime.datetime(2016,12, 31).replace(tzinfo=HItz)"},{"cell_type":"markdown","metadata":{"_cell_guid":"f1cbf76b-8fe5-f78d-99d2-5c119ff6891b"},"source":"#### Adding Variables\n\nNow that the graphs above have been investigated, it will be important to add some variables derived from the ones given here. This is because there might be missing some signal by just using the observed characteristics. \n\nAs one of the models I plan on using is a regression, if a variable is omitted, this has a profound affected on the bias and of the regression coefficients."},{"cell_type":"markdown","metadata":{"_cell_guid":"5b6ad501-b788-53fa-40c1-bef0d33f53c5"},"source":"##### Day\n\nAn indicator variable. 1 if the measurement is within the hours of daylight. 0 otherwise."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"052c29f0-1a14-0ce6-9e03-5bfe56d2277b"},"outputs":[],"source":"def is_day(row):\n    sun_rise = datetime.datetime.strptime(row['TimeSunRise'], '%H:%M:%S').time()\n    sun_set = datetime.datetime.strptime(row['TimeSunSet'], '%H:%M:%S').time()\n    if ((sun_set > row['DatetimeHI'].time()) & (sun_rise < row['DatetimeHI'].time())):\n        return 1\n    else:\n        return 0\n    \nday_bool = np.empty(data.shape[0])\n\nfor i in np.arange(data.shape[0]):\n    day_bool[i] = is_day(data.iloc[i])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9dcf6a7e-1381-b24f-47ea-85e3719a49c7"},"outputs":[],"source":"day_bool"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"53cc6716-02d7-2ecc-00e0-55345fca2049"},"outputs":[],"source":"data['Day'] = day_bool"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ff7dd595-5ed2-99d9-5dbd-964b97559ea6"},"outputs":[],"source":"# add interaction terms for Day\ndata['Day x Temperature'] = data['Temperature'] * day_bool\ndata['Day x Pressure'] = data['Pressure'] * day_bool\ndata['Day x Humidity'] = data['Humidity'] * day_bool\ndata['Day x WindDirection(Degrees)'] = data['WindDirection(Degrees)'] * day_bool\ndata['Day x Speed'] = data['Speed'] * day_bool"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"df4bc298-06f1-b578-c155-73ef7d6cdff3"},"outputs":[],"source":"data.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"e2515b58-9242-2056-a623-e9ff87cb8382"},"source":"##### Hour of Day\n\nAs spikes occur every day, the hour of the day should be a useful metric. We are going to enhance this a little by using hours since sunrise."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0865d412-1d20-1e74-eacb-9c3d92339e90"},"outputs":[],"source":"from datetime import timedelta\nimport time\n\n# create a series of number of hours since sunrise\n# if not Day, then 0\nhour_of_day = np.empty((data.shape[0], ))\n\nfor ix in data.index:\n    # sunrise, sunset; probably a fiddler on the roof joke in there somewhere\n    sr = datetime.datetime.strptime(data.loc[ix, 'TimeSunRise'], '%H:%M:%S').replace(tzinfo=HItz)\n    ss = datetime.datetime.strptime(data.loc[ix, 'TimeSunSet'], '%H:%M:%S').replace(tzinfo=HItz)\n    \n    # if night, 0\n    if ((data.loc[ix, 'DatetimeHI'].time() > ss.time()) | (data.loc[ix, 'DatetimeHI'].time() < sr.time())):\n        hour_of_day[ix] = 0.\n    else:\n        time_ix = data.loc[ix, 'DatetimeHI'].time()\n    \n        # need to account for minutes\n        # sunrise of 6:59 and time of 7:01 is closer to 0 hours apart than 1\n        if (time_ix.hour - sr.hour > 0) & (time_ix.minute - sr.minute < 30):\n            hour_of_day[ix] = time_ix.hour - sr.hour - 1\n        else:\n            hour_of_day[ix] = time_ix.hour - sr.hour"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"981467f5-2144-b093-be45-2fd79d967944"},"outputs":[],"source":"hour_of_day"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6fab2f78-c559-f4bd-820a-a438052be88b"},"outputs":[],"source":"from scipy import stats\nstats.describe(hour_of_day)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8730754a-259c-5e15-2f59-8652366b89ab"},"outputs":[],"source":"# have a look at dataframe to add\npd.get_dummies(hour_of_day).head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ad7d2320-277f-f1ef-0902-fc8c4670d823"},"outputs":[],"source":"# add this to the full data frame\ndata = pd.concat([data, pd.get_dummies(hour_of_day)], axis=1)"},{"cell_type":"markdown","metadata":{"_cell_guid":"5aa453cd-f195-0d50-8516-df76f9216d5d"},"source":"### Model Building\n\nNow that we have done some basic data visualization, cleaning and added some possible new predictors. We will now begin to build models.\n\nWe will train and tune a linear regression model to use as a baseline.\n\nAll metrics/visualizations are the OOS results"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e4006702-086e-830d-1c5a-8f2ff39252f5"},"outputs":[],"source":"TRAIN = data[(data['DatetimeHI'] > start_train) & (data['DatetimeHI'] < end_train)]\nTEST = data[(data['DatetimeHI'] > start_test) & (data['DatetimeHI'] < end_test)]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0ca25c81-8756-b346-6932-92b92a576556"},"outputs":[],"source":"# split training and testing into X and y for compatibility with sklearn\nX_train = TRAIN.drop(['UNIXTime', 'Data', 'Time', 'Radiation', 'TimeSunRise', 'TimeSunSet', 'DatetimeHI'], axis=1)\nX_test = TEST.drop(['UNIXTime', 'Data', 'Time', 'Radiation', 'TimeSunRise', 'TimeSunSet', 'DatetimeHI'], axis=1)\ny_train = TRAIN['Radiation']\ny_test = TEST['Radiation']"},{"cell_type":"markdown","metadata":{"_cell_guid":"0b257aaa-52f8-450b-ebd0-0fa56e40a71a"},"source":"##### Linear Regression"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"946cba4b-f20f-d87d-0d45-82e43d4573d1"},"outputs":[],"source":"lin_reg = linear_model.LinearRegression()\nlin_reg.fit(X_train, y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c03b4d12-f7d2-93d6-e373-2e16efb9454e"},"outputs":[],"source":"lin_reg.score(X=X_test, y=y_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bdbeed66-1a1f-e69d-3817-74bb1609d644"},"outputs":[],"source":"y_pred = lin_reg.predict(X_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9d516b67-9b5b-ec75-d623-47831b6a8268"},"outputs":[],"source":"# resize\nplt.rcParams['figure.figsize'] = 10, 8\n\n# plot results\nplt.plot(TEST['DatetimeHI'], y_pred, c='blue', label='Predicted')\nplt.plot(TEST['DatetimeHI'], y_test, c='red', label='Observed')\nplt.title('Observed vs Predicted')\nplt.ylabel('Radiation')\nplt.xlabel('Date');"},{"cell_type":"markdown","metadata":{"_cell_guid":"00fb5123-680b-97d8-10f8-cf96e1f2522c"},"source":"Strip away the least important estimators:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"54c7ce5d-b747-4ccc-17e9-ec6a8e82aca3"},"outputs":[],"source":"# perform a backwards stepwise regression\nfrom sklearn.feature_selection import RFE\n\n# fit reduced model\nreg = linear_model.LinearRegression()\nreduced_reg = RFE(reg)\nreduced_reg.fit(X_train, y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c72578d6-7cd4-7579-9a9a-b0accf16daa4"},"outputs":[],"source":"reduced_reg.score(X=X_test, y=y_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"50710b4c-2cd0-21eb-a926-96cc2c2a75ee"},"outputs":[],"source":"# predict using the reduced model\ny_pred = reduced_reg.predict(X_test)\n\n# plot results\nplt.plot(TEST['DatetimeHI'], y_pred, c='blue', label='Predicted')\nplt.plot(TEST['DatetimeHI'], y_test, c='red', label='Observed')\nplt.title('Observed vs Predicted')\nplt.ylabel('Radiation')\nplt.xlabel('Date');"},{"cell_type":"markdown","metadata":{"_cell_guid":"6f89004e-e2a0-298a-bf0a-d1fe0bbf912e"},"source":"So this is as far as a linear regression will go. This gives us a baseline $R^2$ of 61.2% to build from with a more complicated model.\n\nThe most obvious thing that will need to be improved is the fact that negative radiation is impossible. Therefore, we will need a model that can deal with this. "},{"cell_type":"markdown","metadata":{"_cell_guid":"aa01b502-bffa-7c7e-2fda-387063273289"},"source":"##### Decision Tree"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"30fca7d4-6925-65c0-1e1f-f931e99e93a0"},"outputs":[],"source":"from sklearn.tree import DecisionTreeRegressor as DTR\n\n# fit random forest\ndt = DTR()\ndt.fit(X_train, y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"791ba546-b57a-cf31-9692-54597fb61d37"},"outputs":[],"source":"dt.score(X=X_test, y=y_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"615eae31-634e-955c-2f8c-c1fd097cda6a"},"outputs":[],"source":"# predict using the random forest model\ny_pred = dt.predict(X_test)\n\n# plot results\nplt.plot(TEST['DatetimeHI'], y_pred, c='blue', label='Predicted')\nplt.plot(TEST['DatetimeHI'], y_test, c='red', label='Observed')\nplt.title('Observed vs Predicted')\nplt.ylabel('Radiation')\nplt.xlabel('Date');"},{"cell_type":"markdown","metadata":{"_cell_guid":"937e6acc-f100-9e7e-06dd-f251195121c1"},"source":"There seems to be a large amount of noise in this model, perhaps due to overfitting."},{"cell_type":"markdown","metadata":{"_cell_guid":"b4ccc09f-053a-161a-2119-a699d0ed4005"},"source":"##### Random Forest"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e3711bb9-1dff-5cb5-593f-9857eb9a03fa"},"outputs":[],"source":"from sklearn.ensemble import RandomForestRegressor as RFR\n\n# set seed for consistency\nnp.random.seed(171)\n\n# fit random forest\nrandom_forest = RFR()\nrandom_forest.fit(X_train, y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"19a765d2-7c76-2289-d7de-52d71bfefb3a"},"outputs":[],"source":"random_forest.score(X=X_test, y=y_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e436757f-d170-0cf4-073f-2f1aa7d86327"},"outputs":[],"source":"# predict using the random forest model\ny_pred = random_forest.predict(X_test)\n\n# plot results\nplt.plot(TEST['DatetimeHI'], y_pred, c='blue', label='Predicted')\nplt.plot(TEST['DatetimeHI'], y_test, c='red', label='Observed')\nplt.title('Observed vs Predicted')\nplt.ylabel('Radiation')\nplt.xlabel('Date');"},{"cell_type":"markdown","metadata":{"_cell_guid":"fd10af29-acf4-e3af-76ef-7322f96ad731"},"source":"The random forest model has the advantage over the linear regression model as it does not return any negative predictions of radiation. Let us tune the model to see if the preformance can be boosted."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b7eef97e-e1df-2f52-7845-a114e3f466b1"},"outputs":[],"source":"# depths to search\nrf_depths = np.arange(5) + 1\n\n# number of esimators to search\nrf_estimators = np.linspace(1, 301, num=16)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"840d95d3-2a5e-d86f-b04f-bd581166bfa3"},"outputs":[],"source":"rf_score_grid = np.empty((len(rf_depths), len(rf_estimators)))\n\n# loop through sc\nfor i, depth in enumerate(rf_depths):\n    for j, est in enumerate(rf_estimators):\n        rf_ = RFR(max_depth=int(rf_depths[i]), n_estimators=int(rf_estimators[j]))\n        rf_.fit(X_train, y_train)\n        rf_score_grid[i, j] = rf_.score(X_test, y_test)\n\n# display results\nrf_score_grid"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ba2b5e5b-e454-e9a5-d82f-e139a7a78289"},"outputs":[],"source":"import seaborn as sns\n\n# place in dataframe\nrf_score_grid = pd.DataFrame(\n    rf_score_grid,\n    columns=[str(i) for i in rf_estimators],\n    index=[str(i) for i in rf_depths]\n)\n\n# display as heatmap\nsns.heatmap(rf_score_grid)\nplt.title('Heatmap of Score for Tuned Random Forest');"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"43a948a2-abd8-cdbb-4f66-fd170fe77a08"},"outputs":[],"source":"rf_score_grid"},{"cell_type":"markdown","metadata":{"_cell_guid":"4aaf4281-ad79-ceaf-a50f-558fb393a365"},"source":"So, the maximum $R^2$ for the tuned random forest is 69.1% (`max_depth`=5, `n_estimators`=161). Let us now have a look at these predictions vs the observed values:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"59d9444c-6529-0908-6a6f-330fddf18f4f"},"outputs":[],"source":"# predict using the tuned random forest model\nrf = RFR(max_depth=5, n_estimators=161)\nrf.fit(X_train, y_train)\ny_pred = rf.predict(X_test)\n\n# resize\nplt.rcParams['figure.figsize'] = 14, 12\n\n# plot results\nplt.plot(TEST['DatetimeHI'], y_pred, c='blue', label='Predicted')\nplt.plot(TEST['DatetimeHI'], y_test, c='red', label='Observed')\nplt.title('Observed vs Predicted Tuned Random Forest')\nplt.ylabel('Radiation')\nplt.xlabel('Date');"},{"cell_type":"markdown","metadata":{"_cell_guid":"84eb2dad-d1b7-384b-5509-28d9526eef07"},"source":"##### Boosted Decision Tree"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"afbab663-6b2f-dcbe-0fc4-448f6a378473"},"outputs":[],"source":"from sklearn.ensemble import AdaBoostRegressor\n\n# fit boosted tree\nboosted_tree = AdaBoostRegressor(DTR(max_depth=3), n_estimators=200)\nboosted_tree.fit(X_train, y_train)\n\n# score\nboosted_tree.score(X=X_test, y=y_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3044d714-53b7-c271-2356-fd368b255685"},"outputs":[],"source":"# predict using the random forest model\ny_pred = boosted_tree.predict(X_test)\n\n# plot results\nplt.plot(TEST['DatetimeHI'], y_pred, c='blue', label='Predicted')\nplt.plot(TEST['DatetimeHI'], y_test, c='red', label='Observed')\nplt.title('Observed vs Predicted')\nplt.ylabel('Radiation')\nplt.xlabel('Date');"},{"cell_type":"markdown","metadata":{"_cell_guid":"78de9790-2027-5ece-da49-469102c4240c"},"source":"Let us try to tune the boosted decision tree now:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7d44338e-a35e-777b-331a-7118ddba5b1c"},"outputs":[],"source":"from tqdm import tqdm, trange\n\nboost_depths = rf_depths \nboost_estimators = rf_estimators\n\nboost_score_grid = np.empty((len(boost_depths), len(boost_estimators)))\n\n# loop through sc ; tqdm will give a progress bar\nfor i, depth in enumerate(tqdm(boost_depths, total=len(boost_depths))):\n    for j, est in enumerate(boost_estimators):\n        boost_ = AdaBoostRegressor(DTR(max_depth=int(boost_depths[i])), n_estimators=int(boost_estimators[j]))\n        boost_.fit(X_train, y_train)\n        boost_score_grid[i, j] = boost_.score(X_test, y_test)\n\n# display results\nboost_score_grid"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"657c9edb-2abb-186e-dbfb-cc840940c5eb"},"outputs":[],"source":"# place in dataframe\nboost_score_grid = pd.DataFrame(\n    boost_score_grid,\n    columns=[str(i) for i in boost_estimators],\n    index=[str(i) for i in boost_depths]\n)\n\n# display as heatmap\nsns.heatmap(boost_score_grid)\nplt.title('Heatmap of Score for Boosted Decision Tree');"},{"cell_type":"markdown","metadata":{"_cell_guid":"208f51b7-892b-9798-c842-2da05c6f6c5e"},"source":"The best fit here has an $R^2$ of 69.9%. Little bit more effective than the random forest. Let us have a look at this fit:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"928a1034-86b8-cded-04d8-d103979d5ae8"},"outputs":[],"source":"# predict using the boosted\nbt = AdaBoostRegressor(DTR(max_depth=5), n_estimators=181)\nbt.fit(X_train, y_train)\ny_pred = bt.predict(X_test)\n\n# plot results\nplt.plot(TEST['DatetimeHI'], y_pred, c='blue', label='Predicted')\nplt.plot(TEST['DatetimeHI'], y_test, c='red', label='Observed')\nplt.title('Observed vs Predicted')\nplt.ylabel('Radiation')\nplt.xlabel('Date');"},{"cell_type":"markdown","metadata":{"_cell_guid":"cbce0cc0-9360-abbd-5b05-ebc3ca571ca9"},"source":"Still, it looks like model is effective at gauging oscillation of the radiation, but not the extent of the peak. This is probably due to the fact that hour from sunrise is the most important predictor, leaving little variance due to the other independent variables. "},{"cell_type":"markdown","metadata":{"_cell_guid":"52a77850-5847-2e19-cc0c-21386f77a2b8"},"source":"### Going Forward\n\nFor future iterations of this model I will seek to:\n* Add more derived independent variables (variance of wind speed etc., many intraction terms)\n* Perhaps use some smoothing functions\n* More complicated models"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}