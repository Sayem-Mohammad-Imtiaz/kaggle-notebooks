{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfrom sklearn import tree\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/titanic/train_and_test2.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Multiple Linear Regression uygulamak için kategorik veriyi sayısal değere dönüştürmek için kolonu bir değişkene atadık\npassengerid =  pd.DataFrame(data.iloc[:,0:1].values,index=range(len(data.iloc[:,0:1].values)),columns=['passengerid',])\n# Multiple Linear Regression uygulamak için kategorik veriyi sayısal değere dönüştürmek için kolonu bir değişkene atadık.\nage = pd.DataFrame(data.iloc[:,1:2].values,index=range(len(data.iloc[:,1:2].values)),columns=['age',])\n# Tahmin ettireceğimiz kolonun değerlerini bir değişkene atadık.\nsex = pd.DataFrame(data.iloc[:,2:3].values,index=range(len(data.iloc[:,2:3].values)),columns=['sex',])\nembarked = pd.DataFrame(data.iloc[:,23:24].values,index=range(len(data.iloc[:,23:24].values)),columns=['embarked',])\nsibsp = pd.DataFrame(data.iloc[:,4:5].values,index=range(len(data.iloc[:,4:5].values)),columns=['sibsp',])\nsurvived = pd.DataFrame(data.iloc[:,26:27].values,index=range(len(data.iloc[:,26:27].values)),columns=['survived',])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(passengerid)\nprint(passengerid )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preData = pd.concat([passengerid,age,sex,embarked,sibsp,survived],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preData.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.heatmap(preData.isnull(), yticklabels=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colormap = plt.cm.viridis\nplt.figure(figsize=(12,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(preData.astype(float).corr(),linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preData[['sex', 'survived']].groupby(['sex'], as_index=False).agg(['mean', 'count', 'sum'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(preData,survived,test_size=0.33,random_state=0)\n# sklearn kütüphanesini kullanarak LinearRegression sınıfını dahil ediyoruz.\nfrom sklearn.linear_model import LinearRegression\n# LinearRegression sınıfından bir nesne oluşturuyoruz.\nlr = LinearRegression()\n# Train veri kümelerini vererek makineyi eğitiyoruz.\nlr.fit(x_train,y_train)\n# test kümesini vererek eğittiğimiz makinenin tahmin üretmesini sağlıyoruz.\nresult = lr.predict(x_test)\nprint(result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv = KFold(n_splits=10)            # Desired number of Cross Validation folds\naccuracies = list()\nmax_attributes = len(list(preData))\ndepth_range = range(1, max_attributes + 1)\n\n# Testing max_depths from 1 to max attributes\n# Uncomment prints for details about each Cross Validation pass\nfor depth in depth_range:\n    fold_accuracy = []\n    tree_model = tree.DecisionTreeClassifier(max_depth = depth)\n    # print(\"Current max depth: \", depth, \"\\n\")\n    for train_fold, valid_fold in cv.split(preData):\n        f_train = preData.loc[train_fold] # Extract train data with cv indices\n        f_valid = preData.loc[valid_fold] # Extract valid data with cv indices\n\n        model = tree_model.fit(X = f_train.drop(['survived'], axis=1), \n                               y = f_train[\"survived\"]) # We fit the model with the fold train data\n        valid_acc = model.score(X = f_valid.drop(['survived'], axis=1), \n                                y = f_valid[\"survived\"])# We calculate accuracy with the fold validation data\n        fold_accuracy.append(valid_acc)\n\n    avg = sum(fold_accuracy)/len(fold_accuracy)\n    accuracies.append(avg)\n    # print(\"Accuracy per fold: \", fold_accuracy, \"\\n\")\n    # print(\"Average accuracy: \", avg)\n    # print(\"\\n\")\n    \n# Just to show results conveniently\ndf = pd.DataFrame({\"Max Depth\": depth_range, \"Average Accuracy\": accuracies})\ndf = df[[\"Max Depth\", \"Average Accuracy\"]]\nprint(df.to_string(index=False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create Numpy arrays of train, test and target (Survived) dataframes to feed into our models\n\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(preData.drop(['survived'],axis=1).values,preData['survived'],test_size=0.33,random_state=0)\n# Create Decision Tree with max_depth = 3\ndecision_tree = tree.DecisionTreeClassifier(max_depth = 3)\n\ndecision_tree.fit(x_train, y_train)\n\n# Predicting results for test dataset\ny_pred = decision_tree.predict(x_test)\nprint(y_pred)\n\n        \n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}