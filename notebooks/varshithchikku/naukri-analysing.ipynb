{"nbformat":4,"metadata":{"language_info":{"version":"3.6.4","file_extension":".py","mimetype":"text/x-python","codemirror_mode":{"version":3,"name":"ipython"},"nbconvert_exporter":"python","name":"python","pygments_lexer":"ipython3"},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"}},"nbformat_minor":1,"cells":[{"source":"import numpy as np\nimport pandas as pd\nimport matplotlib as plt\nimport sklearn\n%matplotlib inline\n","execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"outputs":[]},{"source":"df = pd.read_csv('../input/naukri_com-job_sample.csv')\ndf.head()","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"df.describe()","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"df.count()","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"df.describe(include = ['object'])","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"\n#Indian Institute of Technology Bombay is the higest recuter  from your site with frequency of 403 different offerings\n##The most frequent expirence is 2-7 years \n###The most common jobs are in IT  fiels and in banglore\n####there are 45 different types of skills \n","execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"outputs":[]},{"source":"df['numberofpositions'].isnull()","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"df['numberofpositions'].mean()","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"df['numberofpositions'].fillna(6, inplace = True)","execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"outputs":[]},{"source":"df['numberofpositions'].head()","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"df['company'].value_counts().head(10)","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"df['company'].value_counts().head().plot(kind = 'bar')","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"df['payrate'].value_counts().head()","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"df['education'].value_counts().head()","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"df['education'].unique()","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"df['education'].nunique()","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"df['industry'].value_counts().head()","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"df['joblocation_address'].value_counts().head(10)","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"replacements = {\n   'joblocation_address': {\n      r'(Bengaluru/Bangalore)': 'Bangalore',\n      r'Bengaluru': 'Bangalore',\n      r'Hyderabad / Secunderabad': 'Hyderabad',\n      r'Mumbai , Mumbai': 'Mumbai',\n      r'Noida': 'NCR',\n      r'Delhi': 'NCR',\n      r'Gurgaon': 'NCR', \n      r'Delhi/NCR(National Capital Region)': 'NCR',\n      r'Delhi , Delhi': 'NCR',\n      r'Noida , Noida/Greater Noida': 'NCR',\n      r'Ghaziabad': 'NCR',\n      r'Delhi/NCR(National Capital Region) , Gurgaon': 'NCR',\n      r'NCR , NCR': 'NCR',\n      r'NCR/NCR(National Capital Region)': 'NCR',\n      r'NCR , NCR/Greater NCR': 'NCR',\n      r'NCR/NCR(National Capital Region) , NCR': 'NCR', \n      r'NCR , NCR/NCR(National Capital Region)': 'NCR', \n      r'Bangalore , Bangalore / Bangalore': 'Bangalore',\n      r'Bangalore , karnataka': 'Bangalore',\n      r'NCR/NCR(National Capital Region)': 'NCR',\n      r'NCR/Greater NCR': 'NCR',\n      r'NCR/NCR(National Capital Region) , NCR': 'NCR'\n       \n   }\n}\n\ndf.replace(replacements, regex=True, inplace=True)\ny = df['joblocation_address'].value_counts()","execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"outputs":[]},{"source":"y.head(10)","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"df['joblocation_address'].value_counts().head().plot(kind = 'bar')","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"df['industry'].value_counts().head(10)","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"df['industry'].value_counts().head(10).plot(kind = 'bar')","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"p = df['industry'].value_counts().head(20)\nq = df['joblocation_address'].value_counts().head(20)","execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"outputs":[]},{"source":"df['jobtitle'].value_counts().head(10)","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"df['jobtitle'].value_counts().head(10).plot(kind = 'bar')","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"df.head()\n","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"df['payrate'].value_counts().head(10)","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"df['payrate'].value_counts().head().plot(kind = 'bar')","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"#df['payrate'].value_counts().head(10).plot(kind = 'bar')\n#this paticular  cell is to display the elements from 1st position\n#df.loc()\na = df['payrate'].value_counts().head(10)\na\n","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"df.info(memory_usage = 'deep')","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"#df.iloc[1:10,9].value_counts()\na.iloc[1:,].plot(kind = 'bar')\n#This representation of payrates of actually given by companies","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"#df['payrate'].head(20)\ndf['industry'].head(10)","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"#df['payrate'].exclude('Not Disclosed by Recruiter').head(20)\nX = df.payrate[(df.payrate != 'Not Disclosed by Recruiter')]\nX.head(10)","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"X.count()","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"#This is in the form of cobject\n#in order to train the data sets we have to convert it into feture vectors\nB = df.groupby('industry').payrate","execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"outputs":[]},{"source":"v = df['payrate'].isnull() \nv.unique().sum()","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"#No null values in the payment section\n#so we will do classification with respect to payment and industry\ndf_class = df.filter(['payrate','industry'], axis=1)","execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"outputs":[]},{"source":"df9 = df['industry'] +df['experience']\ndf9.head()","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"df_class.head(10)","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"#df_class.drop('Not Disclosed by Recruiter', axis = 1 )\n#df_class = [(df_class.payrate != 'Not Disclosed by Recruiter')]\ndf_class1 = df_class[df_class.payrate != 'Not Disclosed by Recruiter']\ndf_class1.head()","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"#X.head(10)\ndf_class1.describe()","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"#p = df_class1['payrate' == '12,00,000 - 22,00,000 P.A']\n#p","execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"outputs":[]},{"source":"#df_class1.payrate\ndf_class1['payrate'] = df_class1['payrate'].str.replace(',', '')\n'''\ndf_class1['payrate'] = df_class1['payrate'].astype(str)\ndf_class1['payrate'] = df_class1['payrate'].replace(',', '')\ndf_class1['payrate'] = df_class1['payrate'].astype(float)\ndf_class1.payrate.head()\n'''","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"#df_class1['payrate'] = df_class1['payrate'].str.extract('(\\d)', expand=False)\n#df_class1['payrate'] = df_class1.payrate.str.replace(r\"[a-zA-Z]\",'')\n#df_class1.payrate\ndata_set = df_class1.payrate\ndata_set.head()","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"data_set.dropna(inplace = True)\n#print(data_set[3768])\n#data_set.drop(df.index[3768], inplace=True)\n#print(data_set[3768])","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"#print(data_set)\narray_data = []\nbottom_data = []\ntop_data = []\nindex_numbers = []\nindex_numbers = data_set.index\nnew_index_numbers = []\n#print(data_set[2])\n#print(data_set.index)\nfor element in index_numbers:\n    #print(element)\n    #print(data_set[element])\n    #if data_set[element] == nan:\n        #print(\"found null\")\n    if data_set[element].find(\"0\") != -1:\n        #print(array_data[-1].find(\" P.A\"))\n        array_data.append(data_set[element][:data_set[element].find(\" P.A\")])\n        #print(element)\n        new_index_numbers.append(element)\n        continue\n    #else:\n        #print(\"to be removed\")\n    #remove element\n    \n#print(array_data)\n#print(index_numbers)\ntotal = 0\nskipped = 0\nnewer_index_numbers = []\nfor element in range(len(array_data)):\n    #print(element)\n    total += 1\n    if array_data[element][:array_data[element].find(\" \")].isdigit() == False or array_data[element][array_data[element].find(\" \")+3:].isdigit() == False:\n        #print(\"Skipped\", element)\n        skipped += 1\n        continue\n    bottom_data.append(int(array_data[element][:array_data[element].find(\" \")]))\n    top_data.append(int(array_data[element][array_data[element].find(\" \")+3:]))\n    newer_index_numbers.append(new_index_numbers[element])\n\nprint(\"total = \", total)\nprint(\"skipped = \",skipped)\n\n#print(new_index_numbers)   \n#print(top_data)\n#print(bottom_data)\naverage_data = []\nfor element in range(len(top_data)):\n    average_data.append((top_data[element]+bottom_data[element])/2)\n#print(average_data)","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"print(average_data)","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"print(len(average_data))\n#df_class1\n#print(newer_index_numbers)","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"d = {'payrate' : average_data}\ndf2 = pd.DataFrame(data=d, index= newer_index_numbers)\ndf10 = pd.DataFrame(data=d, index= newer_index_numbers)\ndf2.head()","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"df2['industry'] = df_class1['industry']","execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"outputs":[]},{"source":"df10['industry'] = df9\ndf10.head()","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"df2.head()","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"df_class1.industry.head(10)","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"#df_class1.drop()\n#df_class1[df_class1.industry == 'IT-Software / Software Services']","execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"outputs":[]},{"cell_type":"markdown","metadata":{},"source":"df_class1['industry'] "},{"source":"#train_x = pandas.get_dummies(test[cols])\nX = df2.industry\ny = df2.payrate\n#X.head()\ny.head()","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"#X.value_counts()\n#P =df.industry\n","execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"outputs":[]},{"source":"#y.head(20)\n#df_class1['industry'].apply(lambda row: row.astype(str).str.contains('IT-Software / Software Services').any())\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n\n","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"#X = pandas.get_dummies(test[cols])\n\n'''\nfrom sklearn.preprocessing import MinMaxScaler,PolynomialFeatures\n\nif addpoly:\n    all_data = pd.concat((X_train,\n                          X_test), ignore_index=True)\n\n    scaler = MinMaxScaler()\n    scaler.fit(all_data)\n    all_data=scaler.transform(all_data)\n    poly = PolynomialFeatures(2)\n    all_data=poly.fit_transform(all_data)\n\n    X_train = all_data[:train_dataset.shape[0]]\n    X_test = all_data[train_dataset.shape[0]:]\n    ##\n    print(X_train.shape)\n    print(Y_train.shape)\n    print(X_test.shape)\n '''\n\n#print(X_train)\nprint(X_test)","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"#from sklearn.preprocessing import LabelEncoder\nfrom sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nle.fit(X_train)\nlist(le.classes_)","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"le.transform(X_train)","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"le.fit(X_test)\nle.transform(X_test)","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"from sklearn.svm import LinearSVC, SVC\nfrom sklearn.datasets import make_classification\nX_train, y_train = make_classification()\nclf = LinearSVC(multi_class = 'crammer_singer')\nclf.fit(X_train, y_train)\n\nX_test, y_test = make_classification()\n#clf = LinearSVC(multi_class = 'crammer_singer')\n#clf.fit(X_test, y_test)\n","execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"outputs":[]},{"source":"print(clf.coef_)\nprint(clf.intercept_)","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"clf.predict(X_test)\n","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"print(clf.decision_function(X_test))\n","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"clf.score(X_test, y_test, sample_weight=None)\n#we got the 55 percentage with the Liner SVM","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"#Now we try the Naive Bayes\nfrom sklearn.naive_bayes import BernoulliNB\nclf = BernoulliNB()\nclf.fit(X_train, y_train)","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"clf.predict(X_test)\n","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"clf.score(X_test, y_test, sample_weight = None)","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"#now we will apply the decision tree\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.datasets import load_iris\nclf = DecisionTreeClassifier(random_state=0)\nclf.fit(X_train, y_train)","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"clf.predict(X_test)","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"clf.score(X_test, y_test, sample_weight=None)","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"from sklearn.multiclass import OneVsRestClassifier\nclf = OneVsRestClassifier(SVC(kernel = 'linear'))\nclf.fit(X_train,y_train)\nclf.predict(X_test)\nclf.score(X_test, y_test)\n","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"from sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier(max_depth=2, random_state=0)\nclf.fit(X_train, y_train)\nclf.predict(X_test)\nclf.score(X_test, y_test)","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"#as the accuracy is not satisfying we will go for the rnns\n#implenantion of rnn using keras\nfrom keras.preprocessing import sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding\nfrom keras.layers import LSTM\n\n","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"#LSTM model with rnn in keras\n","execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"outputs":[]},{"source":"#model = Sequential()\n#model.add(LSTM(4,input_shape=(1, p)))","execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"outputs":[]},{"source":"","execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"outputs":[]},{"source":"","execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"outputs":[]},{"source":"","execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"outputs":[]},{"source":"","execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"outputs":[]},{"source":"","execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"outputs":[]},{"source":"df10.head()\n#until now we have predicted with only two values\n#but now we will add another extra column i.e expirence\n#we will join this column along with the training set i.e industry","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"P = df10.industry\nq = df10.payrate\n","execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"outputs":[]},{"source":"from sklearn.model_selection import train_test_split\nP_train,P_test, q_train, q_test = train_test_split(P, q, test_size=0.30, random_state=42)\n\n","execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"outputs":[]},{"source":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nle.fit(P_train)\nlist(le.classes_)","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"le.transform(P_train)","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"le.fit(P_test)\nle.transform(P_test)","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"from sklearn.svm import LinearSVC, SVC\nfrom sklearn.datasets import make_classification\nP_train, q_train = make_classification()\nclf = LinearSVC(multi_class = 'crammer_singer')\nclf.fit(P_train, q_train)\n\nP_test, q_test = make_classification()\n#clf = LinearSVC(multi_class = 'crammer_singer')\n#clf.fit(X_test, y_test)\nprint(clf.coef_)\nprint(clf.intercept_)\nprint(clf.predict(P_test))\n","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"clf.score(P_test, q_test)","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"from sklearn.multiclass import OneVsRestClassifier\nclf = OneVsRestClassifier(SVC(kernel = 'linear'))\nclf.fit(P_train,q_train)\nclf.predict(P_test)\nclf.score(P_test, q_test)","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.datasets import load_iris\nclf = DecisionTreeClassifier(random_state=0)\nclf.fit(P_train, q_train)\nclf.predict(P_test)\nclf.score(P_test, q_test, sample_weight = None)","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"from sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier(max_depth=2, random_state=0)\nclf.fit(P_train, q_train)\nclf.predict(P_test)\nclf.score(P_test, q_test)","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"","execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"outputs":[]},{"source":"","execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"outputs":[]},{"source":"\n\n\n\n\n\n\n\n'''\nclass MultinomialEncoder:\n    def _init_(self, columns = None):\n        self.columns = columns\n        \n    def fit(self, X_test, y_test = None):\n        return self\n    \n    def transform(self, X_test):\n        output = X_test.copy()\n        if self.columns is not None:\n            for col in self.columns:\n                output[col] = LabelEncoder().fit_transform(output[col])\n        else:\n            for colname,col in output.iteritems():\n                output[colname] = LabelEncoder().fit_transform(col)\n        return output\n    \n    def fit_transform(self,X_test,y_test=None):\n        return self.fit(X_test,y_test).transform(X_test)\n  \n    '''","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"'''\n#from sklearn.preprocessing import LabelEncoder\nfrom sklearn import preprocessing\nfrom sklearn.pipeline import Pipeline\nclass MultinomialEncoder:\n    def _init_(self, columns = None):\n        self.columns = columns\n        \n    def fit(self, X_train, y_train = None):\n        return self\n    \n    def transform(self, X_train):\n        output = X_train.copy()\n        if self.columns is not None:\n            for col in self.columns:\n                output[col] = LabelEncoder().fit_transform(output[col])\n        else:\n            for colname,col in output.iteritems():\n                output[colname] = LabelEncoder().fit_transform(col)\n        return output\n    \n    def fit_transform(self,X_train,y_train=None):\n        return self.fit(X_train,y_train).transform(X_train)\n  '''  \n    \n    \n    \n#le = preprocessing.LabelEncoder()\n#le.fit(X_train)\n#le = LabelEncoder().fit_transform\n#le.classes_\n#X_train.apply(LabelEncoder().fit_transform)","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"'''\n#from sklearn.preprocessing import OneHotEncoder\n#enc = OneHotEncoder()\n#enc.fit(X_train)\nfrom sklearn.naive_bayes import BernoulliNB\nclf = BernoulliNB()\nclf.fit(X_train, y_train)\n'''","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"'''\n#from sklearn import preprocessing\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer_train = CountVectorizer()\nvectorizer_train.fit(X_train)\nvector_train = vectorizer_train.transform(X_train)\nprint(vector_train.shape)\nprint(type(vector_train))\nprint(vector_train.toarray())\n'''\n\n#print(clf.predict(X_test))","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"'''\nvectorizer_test = CountVectorizer()\nvectorizer_test.fit(X_test)\nvector_test = vectorizer_test.transform(X_test)\nprint(vector_test.shape)\nprint(type(vector_test))\nprint(vector_test.toarray())\n'''","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"'''\n#X_scaled = preprocessing.scale(X)\nprint(vectorizer_train.vocabulary_)\nprint(vectorizer_test.vocabulary_)\n'''","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"#first we will convert our object to vectors\n#here we will train 4238 values and we will use the rest to test our set\n\n#from sklearn import preprocessing\n#from sklearn.model_selection import train_test_split\n#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n#Application of the svm\n#from sklearn.svm import LinearSVC, SVC\n#from sklearn.datasets import make_classification\n#X_train, y_train = make_classification()\n#clf = LinearSVC(multi_class = 'crammer_singer')\n#clf.fit(X_train, y_train)\n","execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"outputs":[]},{"source":"#print(clf.coef_)\n#print(clf.intercept_)\n\n\n'''\nfrom sklearn.preprocessing import MinMaxScaler, PolynomialFeatures\nif addpoly:\nall_data = pd.concat((X_train, X_test), ignore_index = True)\nscaler = MinMaxScaler()\nscaler.fit(all_data)\n    all_data = scaler.transform(all_data)\n    ploy = PolynomialFeatures(2)\n    all_data = poly.fit_transform(all_data)\n    \n    X_train = all_data[:train_dataset.shape[0]]\n    X_test = all_data[train_dataset,shape[0]:]\n    \n    ##\n    \n    print(X_train.shape)\n    print(y_train.shape)\n    print(X_test.shape)\n    '''","execution_count":null,"cell_type":"code","metadata":{},"outputs":[]},{"source":"#Now  we will countvectorizer to convert out object data into vector form\n#from sklearn.feature_extraction.text import CountVectorizer\n#from sklearn.feature_extraction import DictVectorizer\n#print(clf.predict([X_test] ))\n#clf.predict(X_test)\n","execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"outputs":[]},{"source":"#vect = CountVectorizer(ngram_range=(1,1), token_pattern=r'\\b\\w{1,}\\b')","execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"outputs":[]},{"source":"#vect.fit(X_train)\n#vocab = vect.vocabulary_\n","execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"outputs":[]},{"source":"#vect.fit(y_train)\n#vocab = vect.vocabulary_","execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"outputs":[]},{"source":"#def convert_X_to_X_word_ids(X):\n    #return X.apply( lambda x: [vocab[w] for w in [w.lower().strip() for w in x.split()] if w in vocab] )","execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"outputs":[]},{"source":"#X_train_word_ids = convert_X_to_X_word_ids(X_train)\n#X_test_word_ids  = convert_X_to_X_word_ids(X_test)","execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"outputs":[]},{"source":"#X_train_padded_seqs = pad_sequences(X_train_word_ids, maxlen=150, value=0)\n#X_test_padded_seqs  = pad_sequences(X_test_word_ids , maxlen=150, value=0)","execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"outputs":[]},{"source":"","execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"outputs":[]},{"source":"#from sklearn import svm\n#clf = svm.SVC()\n#clf.fit(X, y)","execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"outputs":[]},{"source":"","execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"outputs":[]},{"source":"#Actual network\n","execution_count":null,"cell_type":"code","metadata":{"collapsed":true},"outputs":[]}]}