{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Libraries\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport sys\nimport os\nimport random\nfrom pathlib import Path\nimport imageio\nimport skimage\nimport skimage.io\nimport skimage.transform\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nfrom plotly import tools\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\nimport scipy\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom keras import optimizers\nfrom keras.initializers import Constant\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten, MaxPool2D, Dropout, BatchNormalization,LeakyReLU\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\nfrom keras.utils import to_categorical\nfrom keras.layers.advanced_activations import LeakyReLU, PReLU\nimport tensorflow_addons as tfa\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nimport tensorflow as tf\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Parameters to be used in the convolutional network"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"IMAGE_PATH = '../input/chinese-mnist/data/data/'\nIMAGE_WIDTH = 64\nIMAGE_HEIGHT = 64\nIMAGE_CHANNELS = 1\nRANDOM_STATE = 42\nTEST_SIZE = 0.2\nVAL_SIZE = 0.2\nBATCH_SIZE = 32\nNO_EPOCHS = 50\nPATIENCE = 5\nVERBOSE = 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df = pd.read_csv('../input/chinese-mnist/chinese_mnist.csv')\nprint(data_df.shape) \ndata_df.sample(100).head(4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Checking the amount of images stored"},{"metadata":{"trusted":true},"cell_type":"code","source":"image_files = list(os.listdir(IMAGE_PATH))\nprint(\"Number of image files: {}\".format(len(image_files)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Adding the full name of the image"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_file_name(x):\n    \n    file_name = f\"input_{x[0]}_{x[1]}_{x[2]}.jpg\"\n    return file_name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df[\"file\"] = data_df.apply(create_file_name, axis=1)\ndata_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Checking the amount of images\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"file_names = list(data_df['file'])\nprint(\"Matching image names: {}\".format(len(set(file_names).intersection(image_files))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Checking the dimension of the images"},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_image_sizes(file_name):\n    image = skimage.io.imread(IMAGE_PATH + file_name)\n    return list(image.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tqdm.pandas()\nm = np.stack(data_df['file'].progress_apply(read_image_sizes))\ndf = pd.DataFrame(m,columns=['w','h'])\ndata_df = pd.concat([data_df,df],axis=1, sort=False)\ndata_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Checking samples and sub-samples of the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Number of suites: {data_df.suite_id.nunique()}\")\nprint(f\"Samples: {data_df.sample_id.unique()}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating datasets to build the network"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df, test_df = train_test_split(data_df, \n                                     test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=data_df[\"code\"].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df, val_df = train_test_split(train_df, \n                                    test_size=VAL_SIZE, random_state=RANDOM_STATE, stratify=train_df[\"code\"].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train set rows: {}\".format(train_df.shape[0]))\nprint(\"Test  set rows: {}\".format(test_df.shape[0]))\nprint(\"Val   set rows: {}\".format(val_df.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Encoding images to create network"},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_image(file_name):\n    image = skimage.io.imread(IMAGE_PATH + file_name)\n    image = skimage.transform.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT, 1), mode='reflect')\n    return image[:,:,:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def categories_encoder(dataset, var='character'):\n    X = np.stack(dataset['file'].apply(read_image))\n    y = pd.get_dummies(dataset[var], drop_first=False)\n    return X, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, y_train = categories_encoder(train_df)\nX_val, y_val = categories_encoder(val_df)\nX_test, y_test = categories_encoder(test_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating network topology, inspired by [Xiaoa (2017)](https://arxiv.org/pdf/1702.07975.pdf)\n\n- the architecture is composed of 7 layers of convolution\n- A hidden layer of 1024 neurons\n- as an activation function PRelu is used\n- It was not necessary to use a pruning process, as used in the paper\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"model=Sequential()\n\nmodel.add(Conv2D(filters = 64, kernel_size=(3,3), input_shape=(64, 64, 1), padding='same'))\nmodel.add(PReLU(alpha_initializer=Constant(value=0.25)))\nmodel.add(MaxPool2D(2))\n\n\nmodel.add(Conv2D(filters = 128, kernel_size=(3,3), padding='same'))\nmodel.add(PReLU(alpha_initializer=Constant(value=0.25)))\nmodel.add(MaxPool2D(2))\n\n\nmodel.add(Conv2D(filters = 160, kernel_size=(3,3),  padding='same'))\nmodel.add(PReLU(alpha_initializer=Constant(value=0.25)))\nmodel.add(MaxPool2D(2))\n\n\nmodel.add(Conv2D(filters = 256, kernel_size=(3,3), padding='same'))\nmodel.add(PReLU(alpha_initializer=Constant(value=0.25)))\nmodel.add(Conv2D(filters = 256, kernel_size=(3,3), padding='same'))\nmodel.add(PReLU(alpha_initializer=Constant(value=0.25)))\nmodel.add(MaxPool2D(2))\n\n\nmodel.add(Conv2D(filters = 384, kernel_size=(3,3),  padding='same'))\nmodel.add(PReLU(alpha_initializer=Constant(value=0.25)))\nmodel.add(Conv2D(filters = 384, kernel_size=(3,3), padding='same'))\nmodel.add(PReLU(alpha_initializer=Constant(value=0.25)))\nmodel.add(MaxPool2D(2))\n\n\nmodel.add(Dropout(0.5))\nmodel.add(Flatten())\nmodel.add(Dense(1024))\nmodel.add(PReLU(alpha_initializer=Constant(value=0.25)))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(15, activation='softmax'))\nmodel.add(PReLU(alpha_initializer=Constant(value=0.25)))\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training the neural network"},{"metadata":{"trusted":true},"cell_type":"code","source":"annealer = LearningRateScheduler(lambda x: 1e-3 * 0.99 ** (x+NO_EPOCHS))\nearlystopper = EarlyStopping(monitor='loss', patience=PATIENCE, verbose=VERBOSE)\ncheckpointer = ModelCheckpoint('best_model.h5',\n                                monitor='val_accuracy',\n                                verbose=VERBOSE,\n                                save_best_only=True,\n                                save_weights_only=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_model  = model.fit(X_train, y_train,\n                  batch_size=BATCH_SIZE,\n                  epochs=NO_EPOCHS,\n                  verbose=1,\n                  validation_data=(X_val, y_val),\n                  callbacks=[earlystopper, checkpointer, annealer])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualizing the evolution of loss and accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_trace(x,y,ylabel,color):\n        trace = go.Scatter(\n            x = x,y = y,\n            name=ylabel,\n            marker=dict(color=color),\n            mode = \"markers+lines\",\n            text=x\n        )\n        return trace\n    \ndef plot_accuracy_and_loss(train_model):\n    hist = train_model.history\n    acc = hist['accuracy']\n    val_acc = hist['val_accuracy']\n    loss = hist['loss']\n    val_loss = hist['val_loss']\n    epochs = list(range(1,len(acc)+1))\n    #define the traces\n    \n    trace_ta = create_trace(epochs,acc,\"Training accuracy\", \"Green\")\n    trace_va = create_trace(epochs,val_acc,\"Validation accuracy\", \"Red\")\n    trace_tl = create_trace(epochs,loss,\"Training loss\", \"Blue\")\n    trace_vl = create_trace(epochs,val_loss,\"Validation loss\", \"Magenta\")\n    fig = tools.make_subplots(rows=1,cols=2, subplot_titles=('Training and validation accuracy',\n                                                             'Training and validation loss'))\n    #add traces to the figure\n    fig.append_trace(trace_ta,1,1)\n    fig.append_trace(trace_va,1,1)\n    fig.append_trace(trace_tl,1,2)\n    fig.append_trace(trace_vl,1,2)\n    #set the layout for the figure\n    fig['layout']['xaxis'].update(title = 'Epoch')\n    fig['layout']['xaxis2'].update(title = 'Epoch')\n    fig['layout']['yaxis'].update(title = 'Accuracy', range=[0,1])\n    fig['layout']['yaxis2'].update(title = 'Loss', range=[0,1])\n    #plot\n    iplot(fig, filename='accuracy-loss')\n\nplot_accuracy_and_loss(train_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reviewing the metrics in the validation and test sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"score = model.evaluate(X_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = model.evaluate(X_val, y_val, verbose=0)\nprint('Val loss:', score[0])\nprint('Val accuracy:', score[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_accuracy_report(model):\n    predicted = model.predict(X_test)\n    test_predicted = np.argmax(predicted, axis=1)\n    test_truth = np.argmax(y_test.values, axis=1)\n    print(metrics.classification_report(test_truth, test_predicted, target_names=y_test.columns)) \n    test_res = model.evaluate(X_test, y_test.values, verbose=0)\n    print('Loss function: %s, accuracy:' % test_res[0], test_res[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_optimal = model\nmodel_optimal.load_weights('best_model.h5')\nscore = model_optimal.evaluate(X_test, y_test, verbose=0)\nprint(f'Best validation loss: {score[0]}, accuracy: {score[1]}')\n\ntest_accuracy_report(model_optimal)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusions\n\n- The model shows no signs of being over-fitting or under-fitting\n- Metrics of more than 99% accuracy were obtained in both the test data and the validation data\n- The architecture of the network is not exactly the same as the paper used but it has the same amount of layers.\n- In the table above we can notice the accuracy per element, revealing that the element with less accuracy has a value of 0.97\n- These results confirm the efficiency of the study done by Xiaoa"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}