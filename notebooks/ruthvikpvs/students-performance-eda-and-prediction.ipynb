{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Importing the libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.stats import norm\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmpl.rcParams['axes.spines.top'] = False\nmpl.rcParams['axes.spines.right'] = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_data=pd.read_csv(\"../input/students-performance-in-exams/StudentsPerformance.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=raw_data.copy()\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Use the shape method to see the number of rows and columns in our dataset.","metadata":{}},{"cell_type":"code","source":"data.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* There are 1000 rows and 8 columns in our dataset.\n* The info() method gives the summary of our data. This us useful as we can check if there are any missing values present or not.","metadata":{}},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Descriptive Analytics","metadata":{}},{"cell_type":"code","source":"data.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Checking for missing values","metadata":{}},{"cell_type":"code","source":"data.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are no missing values present in our dataset. ","metadata":{}},{"cell_type":"code","source":"# Adding a column for the total marks.\ndata['total_marks']=data['math score']+data['reading score']+data['writing score']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Classification\nIt is good practice to categorize the numerical and categorical variables.","metadata":{}},{"cell_type":"code","source":"data_numerical = data[['math score','reading score','writing score','total_marks']]\ndata_categorical=data[['gender','race/ethnicity','parental level of education','lunch','test preparation course']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We use histograms to observe how the scores of students are distributed.","metadata":{}},{"cell_type":"code","source":"fig,ax=plt.subplots(2,2,figsize=(15,10))\nfor i,idx in enumerate(data_numerical.columns):\n    sns.histplot(ax=ax[i%2,i//2],data=data_numerical[idx],kde=True)\n    ax[i%2,i//2].set_title(idx)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that our numerical data follows the normal distribution.","metadata":{}},{"cell_type":"markdown","source":"#### KDE plot","metadata":{}},{"cell_type":"code","source":"sns.kdeplot(data=data_numerical,shade=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Skewness and kurtosis\ns_k=[]\nfor i in data_numerical.columns:\n    s_k.append([i,data_numerical[i].skew(),data_numerical[i].kurt()])\nskew_kurt=pd.DataFrame(s_k,columns=['Columns','Skewness','Kurtosis'])\nskew_kurt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As a general rule of thumb: If skewness is less than -1 or greater than 1, the distribution is highly skewed. If skewness is between -1 and -0.5 or between 0.5 and 1, the distribution is moderately skewed. If skewness is between -0.5 and 0.5, the distribution is approximately symmetric. \n","metadata":{}},{"cell_type":"markdown","source":"#### Scatterplots for the numerical variables","metadata":{}},{"cell_type":"code","source":"fig,ax = plt.subplots(2,2,figsize=(15,12))\n\n#Math and reading scores\nax[0,0].scatter(x='math score',y='reading score',data=data[data['gender']=='male'],alpha=0.5,label='male')\nax[0,0].scatter(x='math score',y='reading score',data=data[data['gender']=='female'],alpha=0.5,label='female',color='brown')\nax[0,0].set_xlabel('Math Scores')\nax[0,0].set_ylabel('Reading Scores')\nax[0,0].set_title('Math and reading score')\nax[0,0].legend()\n\n# Mathematics and Writing Scores\nax[0,1].scatter(x='math score',y='writing score',data=data[data['gender']=='male'],alpha=0.5,label='male')\nax[0,1].scatter(x='math score',y='writing score',data=data[data['gender']=='female'],alpha=0.5,label='female',color='brown')\nax[0,1].set_xlabel('Math Scores')\nax[0,1].set_ylabel('Writing Scores')\nax[0,1].set_title('Math and writing score')\nax[0,1].legend()\n# Reading and writing Scores\nax[1,0].scatter(x='writing score',y='reading score',data=data[data['gender']=='male'],alpha=0.5,label='male')\nax[1,0].scatter(x='writing score',y='reading score',data=data[data['gender']=='female'],alpha=0.5,label='female',color='brown')\nax[1,0].set_xlabel('Reading Score')\nax[1,0].set_ylabel('Writing Score')\nax[1,0].set_title('Reading and writing score')\nax[1,0].legend()\nax[1,1].set_visible(False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see from the above figure that :\n1. Most of the scores fall between 40-100 range.\n2. Only a small portion of students scored less than 40.\n3. The scores increases linearly with each other.","metadata":{}},{"cell_type":"markdown","source":"#### Group  with most number of people\n","metadata":{}},{"cell_type":"code","source":"color_map = ['lightgrey' for _ in range(5)]\ncolor_map[0] =color_map[1]='seagreen'\nfig,ax = plt.subplots(1,1,figsize=(12,5))\ndata_group = data['race/ethnicity'].value_counts().sort_values(ascending=False)\nax.bar( data_group.index, data_group , width=0.4,color=color_map )\nax.grid(linestyle=':',axis='y',alpha=0.4)\nfor an in data_group.index:\n    ax.annotate(data_group[an],xy=(an,data_group[an]+10),va='center',ha='center')\nfor i in ['top','right']:\n    ax.spines[i].set_visible(False)\nplt.title('Number of people in different groups',fontweight='bold')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Group C has the most number of people and Group A has the least amount of people.","metadata":{}},{"cell_type":"markdown","source":"### Categorical Scatterplots","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\nfor indx,val in enumerate(data_categorical.columns):\n    plt.subplot(2,3,indx+1)\n    sns.swarmplot(x=data_categorical[val],y=data_numerical['total_marks'],palette='OrRd')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we cannot see the parental level of education clearly , I will plot it again.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.swarmplot(x=data_categorical['parental level of education'],y=data_numerical['total_marks'],palette='OrRd')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can observe from the above graphs that most of the students score above 150 marks.","metadata":{}},{"cell_type":"markdown","source":"\n#### Education level of Parents","metadata":{}},{"cell_type":"code","source":"color_map = ['lightgrey' for _ in range(6)]\ncolor_map[0] =color_map[1]='seagreen'\nfig,ax = plt.subplots(1,1,figsize=(12,5))\ndata_group = data['parental level of education'].value_counts().sort_values(ascending=False)\nax.bar( data_group.index, data_group , width=0.4,color=color_map)\nax.grid(linestyle=':',axis='y',alpha=0.4)\nfor an in data_group.index:\n    ax.annotate(data_group[an],xy=(an,data_group[an]+10),va='center',ha='center')\nfor i in ['top','right']:\n    ax.spines[i].set_visible(False)\nplt.title('Education Level of Parents')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Most of the parents attended some college(226) and almost the same amount of people have an associate's degree. Parents who hold a master's degree are very few in number.","metadata":{}},{"cell_type":"markdown","source":"#### Gender , Lunch and Test preperation","metadata":{}},{"cell_type":"code","source":"data1=data[['gender','lunch','test preparation course']]\nfig,ax=plt.subplots(2,2,figsize=(10,10))\ncolor_map = ['lightgrey' for _ in range(2)]\ncolor_map[0] ='seagreen' #color highlight\nfor i,idx in enumerate(data1.columns):\n    z=data1[idx].value_counts().sort_index()\n    ax[i%2][i//2].bar(z.index,z , color=color_map)\n    ax[i%2][i//2].set_title(idx)  \n    ax[i%2][i//2].grid(linestyle=':',axis='y',alpha=0.4)  \n    \nax[1][1].set_visible(False)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can observe from the above figures that:\n1. Females students are more than male students.\n2. The students who have completed any course are less than the students who did not prepare.\n3. Students who prefer standard lunch are more in number than students who prefer free/reduced lunch.","metadata":{}},{"cell_type":"markdown","source":"#### The group of people who scored the highest number of total marks","metadata":{}},{"cell_type":"code","source":"highest_group = data.groupby(by='race/ethnicity')['total_marks'].sum().sort_values(ascending=False).reset_index()\ncolor_map = ['lightgrey' for _ in range(5)]\ncolor_map[0] =color_map[1]='seagreen' #color highlight\nfig,ax = plt.subplots(1,1,figsize=(12,5))\nax.bar(highest_group['race/ethnicity'],highest_group['total_marks'],color=color_map,width=0.55,linewidth=0.7)\nfor an in highest_group.index:\n    ax.annotate(highest_group['total_marks'][an],xy=(highest_group['race/ethnicity'][an],highest_group['total_marks'][an]+1000),va='center',ha='center')\nfor i in ['top','right']:\n    ax.spines[i].set_visible(False)\nplt.title('Total marks of people')\nax.grid(axis='y',linestyle='-',alpha=0.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The students in Group C scored the most number of marks among all the groups followed by groups D,B,E and group A.","metadata":{}},{"cell_type":"markdown","source":"#### Parents educational levels and students performance","metadata":{}},{"cell_type":"code","source":"parents= data.groupby(by='parental level of education')['total_marks'].sum().sort_values(ascending=False).reset_index()\ncolor_map = ['lightgrey' for _ in range(6)]\ncolor_map[0] =color_map[1]='seagreen' #color highlight\nfig,ax = plt.subplots(1,1,figsize=(12,5))\nax.bar(parents['parental level of education'],parents['total_marks'],color=color_map,width=0.55,linewidth=0.7)\nfor an in parents.index:\n    ax.annotate(parents['total_marks'][an],xy=(parents['parental level of education'][an],parents['total_marks'][an]+1000),va='center',ha='center')\nfor i in ['top','right']:\n    ax.spines[i].set_visible(False)\nplt.title('Parents effect')\nax.grid(axis='y',linestyle='-',alpha=0.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### How does gender effect the students performance individually","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,7))\ncolor_map = ['lightgrey' for _ in range(6)]\ncolor_map[0] ='seagreen' #color highlight\nplt.subplot(1, 3, 1)\nsns.barplot(x='test preparation course',y='math score',data=data,hue='gender',palette=color_map)\nplt.title('MATH SCORES')\nplt.subplot(1, 3, 2)\nsns.barplot(x='test preparation course',y='reading score',data=data,hue='gender',palette=color_map)\nplt.title('READING SCORES')\nplt.subplot(1, 3, 3)\nsns.barplot(x='test preparation course',y='writing score',data=data,hue='gender',palette=color_map)\nplt.title('WRITING SCORES')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Number of students who passed in math\ndata['maths_passed']= data['math score'].apply(lambda x : 'P' if x>40 else 'F')\ndata['maths_passed'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of students who passed in reading\ndata['reading_passed'] = data['reading score'].apply(lambda x: 'P' if x>40 else 'F')\ndata['reading_passed'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of students who passed in writing.\ndata['writing_passed']=data['writing score'].apply(lambda x: 'P' if x>40 else 'F')\ndata['writing_passed'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Which subject has the most number of failures?\n","metadata":{}},{"cell_type":"code","source":"plt.subplots(1,3,figsize=(15,7))\nplt.subplot(1,3,1)\nsns.countplot(x='gender',data=data,hue='maths_passed',palette=color_map)\nplt.title('Students who passed in maths')\nplt.subplot(1,3,2)\nsns.countplot(x='gender',data=data,hue='reading_passed',palette=color_map)\nplt.title('Students who passed in reading')\nplt.subplot(1,3,3)\nsns.countplot(x='gender',data=data,hue='writing_passed',palette=color_map)\nplt.title('Students who passed in writing')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. The number of people who failed in mathematics are more than other subjects.\n2. Overall the number of students who failed are significantly less than the students who passed.","metadata":{}},{"cell_type":"code","source":"# Students percentage\ndata['Percentage']=data['total_marks']/3  # Percentage = number/100, here the highest marks =300. So,dividing by 3 gives the % .","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Grading the Students","metadata":{}},{"cell_type":"code","source":"data['OverAll_PassStatus'] = data.apply(lambda x : 'F' if x['maths_passed'] == 'F' or \n                                    x['reading_passed'] == 'F' or x['writing_passed'] == 'F' else 'P', axis =1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def GetGrade(Percentage, OverAll_PassStatus):\n    if ( OverAll_PassStatus == 'F'):\n        return 'F'    \n    if ( Percentage >= 80 ):\n        return 'A'\n    if ( Percentage >= 70):\n        return 'B'\n    if ( Percentage >= 60):\n        return 'C'\n    if ( Percentage >= 50):\n        return 'D'\n    if ( Percentage >= 40):\n        return 'E'\n    else: \n        return 'F'\n\ndata['Grade'] = data.apply(lambda x : GetGrade(x['Percentage'], x['OverAll_PassStatus']), axis=1)\ncolor_map[0] =color_map[1]='seagreen'\ngrades=data['Grade'].value_counts().sort_values(ascending=False)\nfig,ax=plt.subplots(1,1,figsize=(12,5))\nax.bar(grades.index,grades,color=color_map,width=0.55)\nfor an in grades.index:\n    ax.annotate(grades[an],xy=(an,grades[an]+5),va='center',ha='center')\nfor i in ['top','right']:\n    ax.spines[i].set_visible(False)\nax.set_title('Grades of students')\nax.grid(axis='y',linestyle='-',alpha=0.4)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Most of the students achieved a B Grade followed by Grade C. ","metadata":{}},{"cell_type":"markdown","source":"#### Male and Female Students Grades\n","metadata":{}},{"cell_type":"code","source":"color_map = ['lightgrey' for _ in range(2)]\ncolor_map[0] ='seagreen'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig,ax=plt.subplots(1,1,figsize=(12,5))\nsns.countplot(x='Grade',hue='gender',data=data,palette=color_map)\nax.set_title('Male and Female Students Grades')\nax.grid(axis='y',linestyle=':',alpha=0.4)\nfor i in ['top','right']:\n    ax.spines[i].set_visible(False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Relationship between grades and lunch","metadata":{}},{"cell_type":"code","source":"fig,ax=plt.subplots(1,1,figsize=(12,5))\nsns.countplot(x='Grade',hue='lunch',data=data,palette=color_map)\nax.set_title(' Relationship between grades and lunch')\nax.grid(axis='y',linestyle=':',alpha=0.4)\nfor i in ['top','right']:\n    ax.spines[i].set_visible(False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Test Preperation Course and Grades","metadata":{}},{"cell_type":"code","source":"fig,ax=plt.subplots(1,1,figsize=(12,5))\nsns.countplot(x='Grade',hue='test preparation course',data=data,palette=color_map)\nax.set_title('Test Preperation Course and Grades')\nax.grid(axis='y',linestyle=':',alpha=0.4)\nfor i in ['top','right']:\n    ax.spines[i].set_visible(False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Creating dummy variables","metadata":{}},{"cell_type":"markdown","source":"We use One-Hot Encoding to encode categorical variables. Encoding is necessary because machine learning models do not work with categorical variables. For One-Hot Encoding we use pd.get_dummies()","metadata":{}},{"cell_type":"code","source":"data_dummies = data[['gender', 'race/ethnicity', 'parental level of education', 'lunch',\n       'test preparation course']]\ndata_dummies=pd.get_dummies(data_dummies)\ndata_dummies.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_totalmarks=data['total_marks']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training the Models","metadata":{}},{"cell_type":"code","source":"# Importing the libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting the data into training and testing sets\nx_train,x_test,y_train,y_test = train_test_split(data_dummies,data_totalmarks,test_size=0.2,random_state=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Evaluating the performance of our regression models.","metadata":{}},{"cell_type":"code","source":"#https://towardsdatascience.com/what-are-the-best-metrics-to-evaluate-your-regression-model-418ca481755b\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\ndata_scores=[]\ndef EvaluatingModels(true_value,predicted_value,model):\n    MSE=mean_squared_error(true_value,predicted_value,squared=True) # If squared = True then its MSE, if squared = False then its RMSE\n    RMSE=mean_squared_error(true_value,predicted_value,squared=False)\n    MAE= mean_absolute_error(true_value,predicted_value)\n    R_Squared = r2_score(true_value,predicted_value)\n    data_scores.append([model,MSE,RMSE,MAE,R_Squared])\n    print(\"MSE:\", MSE)\n    print(\"MAE:\", MAE)\n    print(\"RMSE:\", RMSE)\n    print(\"R-squared:\", R_Squared)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"R squared : Measures how much of variability in dependent variable can be explained by the model.\n\nMAE : Gives us the difference between the actual value and predicted value. (Eg: If the actual value is 10000 and the predicted value is 5000, then we can say that the actual value is 5000 more than the predicted value).\n\nMSE : Mean Square Error is an absolute measure of the goodness for the fit.","metadata":{}},{"cell_type":"markdown","source":"#### Linear Regression","metadata":{}},{"cell_type":"code","source":"linear_regressor=LinearRegression(normalize=True)\nlinear_regressor.fit(x_train,y_train)\nlin_prediction= linear_regressor.predict(x_test)\nEvaluatingModels(y_test,lin_prediction,'Linear Regression')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Decision Tree Regression","metadata":{}},{"cell_type":"code","source":"regress_dtree=DecisionTreeRegressor(random_state=1)\ndtree_model = regress_dtree.fit(x_train,y_train)\ny_predtree = dtree_model.predict(x_test)\nEvaluatingModels(y_test,y_predtree,'Decision Tree Regression')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### RandomForest Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nrf_regressor=RandomForestRegressor(random_state=1)\nrf_model=rf_regressor.fit(x_train,y_train)\ny_rfpred = rf_model.predict(x_test)\nEvaluatingModels(y_test,y_rfpred,'Random Forest Regression')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Feature Importance Plot for Random Forest","metadata":{}},{"cell_type":"code","source":"# https://towardsdatascience.com/running-random-forests-inspect-the-feature-importances-with-this-code-2b00dd72b92e\nfeature_importances = pd.DataFrame(rf_model.feature_importances_,\n                                   index = x_train.columns,\n                                    columns=['importance']).sort_values('importance',ascending=False)\nplt.figure(figsize=(10,10))\nsns.barplot(x=feature_importances['importance'].values, y= feature_importances['importance'].index,palette='rocket_r')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Comparing the performance","metadata":{}},{"cell_type":"code","source":"df=pd.DataFrame(data_scores,columns=['Model','MSE','RMSE','MAE','R2'])\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If we compare the three models we used for predictions. We can observe that:\n1. Linear regression performed far better than Decision Trees and Random Forest algorithms.\n2. The Mean Square Error value of Linear Regression is 1436 (on average the predictions have 1436 difference from the actual values)\n3. The R squared value of Decision Tree Regression is negative. R-squared values less than 0 means a horizontal line fits the data better than our model. So, decision tree regression is not suitable for our data.\n4. Random Forest performs better than Decision Trees but not as good as Linear Regression.\n5. Even though Linear Regression performs better than these models, the r_squared value is only 0.24 and the predictions are not accurate most of the time. ","metadata":{}},{"cell_type":"markdown","source":"#### My other notebooks \n1) https://www.kaggle.com/ruthvikpvs/stroke-data-eda-and-prediction\n\n2) https://www.kaggle.com/ruthvikpvs/heart-attack-analysis-eda-and-prediction","metadata":{}},{"cell_type":"markdown","source":"### References","metadata":{}},{"cell_type":"markdown","source":"1. https://www.kaggle.com/spscientist/student-performance-in-exams\n2. https://www.kaggle.com/subinium/simple-matplotlib-visualization-tips\n3. https://www.kaggle.com/subinium/kaggle-2020-visualization-analysis\n4. https://www.kaggle.com/josephchan524/studentperformanceregressor-rmse-12-26-r2-0-26","metadata":{}},{"cell_type":"markdown","source":"### Do upvote the kernel if you find it useful. Feedback is highly appreciated. Thank You.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}