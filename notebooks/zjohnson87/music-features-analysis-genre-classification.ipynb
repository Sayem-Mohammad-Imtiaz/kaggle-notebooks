{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom pandas.plotting import scatter_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Goals\n### In this analysis, I would like to explore some of the fundamental differences between various genres of music.\n### I will also be creating a model to see how well I can use this data to classify songs by their genre.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### First, I will read in the data and concatenate the two files into one dataframe.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data_1 = pd.read_csv('../input/musicfeatures/data.csv')\ndata_2 = pd.read_csv('../input/musicfeatures/data_2genre.csv')\n\ndata = pd.concat([data_1, data_2])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Here is a list of the genres in our dataframe, along with their counts:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### It looks like there are some weird numerical values. By looking at the data I see that \"1\" corresponds to \"pop\" and the \"2\" corresponds to \"classical\". Let's change those.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['label'] = data['label'].replace(to_replace={1: 'pop', 2: 'classical'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now we can see the true value counts","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Next, I'll do some exploratory data analysis to see what kind of relationships we have between our features.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Tempo Distribution\n#### Here we can see the differences in tempo distribution between some different genres. \n#### Most have fairly normal distributions with peaks around 100 BPM.\n#### Disco is distinctly different, with a peak closer to 150 BPM.\n#### Classical and Jazz are the most diverse, having less prominent peaks and a wider spread of tempos.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30,10))\n\nsns.kdeplot(data=data.loc[data['label']=='jazz', 'tempo'], label=\"Jazz\")\nsns.kdeplot(data=data.loc[data['label']=='pop', 'tempo'], label=\"Pop\")\nsns.kdeplot(data=data.loc[data['label']=='classical', 'tempo'], label=\"Classical\")\nsns.kdeplot(data=data.loc[data['label']=='hiphop', 'tempo'], label=\"Hiphop\")\nsns.kdeplot(data=data.loc[data['label']=='disco', 'tempo'], label=\"Disco\")\nsns.kdeplot(data=data.loc[data['label']=='country', 'tempo'], label=\"Country\")\nsns.kdeplot(data=data.loc[data['label']=='rock', 'tempo'], label=\"Rock\")\nsns.kdeplot(data=data.loc[data['label']=='metal', 'tempo'], label=\"Metal\")\nsns.kdeplot(data=data.loc[data['label']=='reggae', 'tempo'], label=\"Reggae\")\nsns.kdeplot(data=data.loc[data['label']=='blues', 'tempo'], label=\"Blues\")\n\nplt.title(\"Distribution of tempos by genre\", fontsize = 18)\n\nplt.xlabel(\"Tempo\", fontsize = 18)\n\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tempo Mean\n#### However, if we look at the average tempo of each we can see that they are all very similar","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30,10))\n\ngenres = data['label'].unique()\n\ntempos = [ data[data['label']==x].tempo.mean() for x in genres ]\n\nsns.barplot(x=genres, y=tempos, palette=\"deep\")\n\nplt.title(\"Average tempo by genre\", fontsize = 18)\n\nplt.xlabel('Genre', fontsize = 18)\nplt.ylabel('Mean Tempo', fontsize = 18)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now I am going to look at some of the less intuitive features in the dataset.\n#### These features are more technical. I had to do some research to understand their meanings and implications, so I will explain them below.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 1. Spectral Centroid\n#### Spectral centroid is the average of frequencies weighted by amplitude, so a high spectral centroid implies that higher frequencies have higher amplitudes, or are more prominent, in this sample.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Spectral Centroid Distribution\n#### Songs in the classical, jazz, and country genres seem to trend toward lower spectral centroids, while pop, disco, hiphop, and metal songs tend to have higher centroids. It's possible that high spectral centroids could be correlated with catchy songs that grab your attention with high frequencies, while low spectral centroids correlate with low-toned, more relaxed music that is more common in classical, jazz, and country.\n#### The classical and metal genres both have fairly low variance, implying that they are less diverse in terms of spectral centroids.\n#### The distributions of classical and metal have very little overlap. We could discern between these two genres fairly accurately even if we only used this feature.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30,10))\n\nsns.kdeplot(data=data.loc[data['label']=='jazz', 'spectral_centroid'], label=\"Jazz\")\nsns.kdeplot(data=data.loc[data['label']=='pop', 'spectral_centroid'], label=\"Pop\")\nsns.kdeplot(data=data.loc[data['label']=='classical', 'spectral_centroid'], label=\"Classical\")\nsns.kdeplot(data=data.loc[data['label']=='hiphop', 'spectral_centroid'], label=\"Hiphop\")\nsns.kdeplot(data=data.loc[data['label']=='disco', 'spectral_centroid'], label=\"Disco\")\nsns.kdeplot(data=data.loc[data['label']=='country', 'spectral_centroid'], label=\"Country\")\nsns.kdeplot(data=data.loc[data['label']=='rock', 'spectral_centroid'], label=\"Rock\")\nsns.kdeplot(data=data.loc[data['label']=='metal', 'spectral_centroid'], label=\"Metal\")\nsns.kdeplot(data=data.loc[data['label']=='reggae', 'spectral_centroid'], label=\"Reggae\")\nsns.kdeplot(data=data.loc[data['label']=='blues', 'spectral_centroid'], label=\"Blues\")\n\nplt.title(\"Distribution of spectral centroids by genre\", fontsize = 18)\n\nplt.xlabel(\"Spectral Centroid\", fontsize = 18)\n\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Spectral Centroid Mean\n#### As can be seen below, there is much more variance in the means of the spectral centroids than there was for tempo.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30,10))\n\ngenres = data['label'].unique()\n\nspectral_centroids = [ data[data['label']==x].spectral_centroid.mean() for x in genres ]\n\nsns.barplot(x=genres, y=spectral_centroids, palette=\"deep\")\n\nplt.title(\"Average spectral centroid by genre\", fontsize = 18)\n\nplt.xlabel('Genre', fontsize = 18)\nplt.ylabel('Mean Spectral Centroid', fontsize = 18)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Spectral Bandwidth\n#### Spectral bandwidth is the width of the frequency band for which the frequencies are at least half of the maximum amplitude. Basically, it shows us how wide the range of prominent frequencies is.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Spectral Bandwidth Distribution\n#### Interestingly, there are three very distinct peaks in this graph: classical, metal, and pop. Their distributions have relatively low variance, and they have little overlap with each other, meaning that this feature will be useful in distinguishing them.\n#### Most classical songs have a smaller spectral bandwidth. This could be due to many classical songs being played by a single instrument, such as piano, limiting the tonal range.\n#### Pop songs tend to have higher bandwidths. This may be because most pop songs include multiple instruments and vocal parts.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30,10))\n\nsns.kdeplot(data=data.loc[data['label']=='jazz', 'spectral_bandwidth'], label=\"Jazz\")\nsns.kdeplot(data=data.loc[data['label']=='pop', 'spectral_bandwidth'], label=\"Pop\")\nsns.kdeplot(data=data.loc[data['label']=='classical', 'spectral_bandwidth'], label=\"Classical\")\nsns.kdeplot(data=data.loc[data['label']=='hiphop', 'spectral_bandwidth'], label=\"Hiphop\")\nsns.kdeplot(data=data.loc[data['label']=='disco', 'spectral_bandwidth'], label=\"Disco\")\nsns.kdeplot(data=data.loc[data['label']=='country', 'spectral_bandwidth'], label=\"Country\")\nsns.kdeplot(data=data.loc[data['label']=='rock', 'spectral_bandwidth'], label=\"Rock\")\nsns.kdeplot(data=data.loc[data['label']=='metal', 'spectral_bandwidth'], label=\"Metal\")\nsns.kdeplot(data=data.loc[data['label']=='reggae', 'spectral_bandwidth'], label=\"Reggae\")\nsns.kdeplot(data=data.loc[data['label']=='blues', 'spectral_bandwidth'], label=\"Blues\")\n\nplt.title(\"Distribution of spectral bandwidth by genre\", fontsize = 18)\n\nplt.xlabel(\"Spectral Bandwidth\", fontsize = 18)\n\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Spectral Bandwidth Mean\n#### The spectral bandwidth means look very similar to the spectral centroid means. This may indicate some kind of correlation.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30,10))\n\ngenres = data['label'].unique()\n\nspectral_bandwidths = [ data[data['label']==x].spectral_bandwidth.mean() for x in genres ]\n\nsns.barplot(x=genres, y=spectral_bandwidths, palette=\"deep\")\n\nplt.title(\"Average spectral_bandwidth by genre\", fontsize = 18)\n\nplt.xlabel('Genre', fontsize = 18)\nplt.ylabel('Mean Spectral Bandwidth', fontsize = 18)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Rolloff\n#### Rolloff is a term typically used to describe filters. It describes the steepness of the transition from the stop band to the pass band (the stop band includes the blocked frequencies, while the pass band includes the audible frequencies). A higher rolloff might indicate music that has less overtones (peripheral frequencies with lower amplitude), or that sounds more \"crisp\" and clean.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Rolloff Distribution\n#### The rolloff distributions looks almost the same as the spectral bandwidth distributions. This very likely indicates a correlation between the two.\n#### Pop, disco, hiphop, and metal have high rolloff. This seems to support my theory about \"crisp\" sounding music.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30,10))\n\nsns.kdeplot(data=data.loc[data['label']=='jazz', 'rolloff'], label=\"Jazz\")\nsns.kdeplot(data=data.loc[data['label']=='pop', 'rolloff'], label=\"Pop\")\nsns.kdeplot(data=data.loc[data['label']=='classical', 'rolloff'], label=\"Classical\")\nsns.kdeplot(data=data.loc[data['label']=='hiphop', 'rolloff'], label=\"Hiphop\")\nsns.kdeplot(data=data.loc[data['label']=='disco', 'rolloff'], label=\"Disco\")\nsns.kdeplot(data=data.loc[data['label']=='country', 'rolloff'], label=\"Country\")\nsns.kdeplot(data=data.loc[data['label']=='rock', 'rolloff'], label=\"Rock\")\nsns.kdeplot(data=data.loc[data['label']=='metal', 'rolloff'], label=\"Metal\")\nsns.kdeplot(data=data.loc[data['label']=='reggae', 'rolloff'], label=\"Reggae\")\nsns.kdeplot(data=data.loc[data['label']=='blues', 'rolloff'], label=\"Blues\")\n\nplt.title(\"Distribution of rolloff by genre\", fontsize = 18)\n\nplt.xlabel(\"Rolloff\", fontsize = 18)\n\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Rolloff Means\n#### There is a lot of variance in the means of the rolloff. It also closely resembles the means of the spectral bandwidth.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30,10))\n\ngenres = data['label'].unique()\n\nrolloffs = [ data[data['label']==x].rolloff.mean() for x in genres ]\n\nsns.barplot(x=genres, y=rolloffs, palette=\"deep\")\n\nplt.title(\"Average rolloff by genre\", fontsize = 18)\n\nplt.xlabel('Genre', fontsize = 18)\nplt.ylabel('Rolloff', fontsize = 18)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Correlations\n#### This heatmap shows the correlations between all of the features. This quantifies how close they are to a perfect linear relationship.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"correlations = data.corr()\n\nfig, ax = plt.subplots(figsize=(30,30))\nsns.heatmap(correlations, vmax=1.0, center=0, fmt='.2f',\n            square=True, linewidths=.5, annot=True, cbar_kws={\"shrink\": .70})\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### This filtered list more clearly shows the features with the strongest positive correlations.\n#### Here we can see that rolloff is strongly correlated with both spectral centroid and spectral bandwidth.\n#### I am not sure what the difference between tempo and beats is, but there seems to be some minor discrepancy.\n#### We can also see that there is also a fairly strong correlation between spectral bandwidth and centroid\n#### I would have expected the correlation between zero crossing rate and spectral centroid to be higher, since they are both dependent on frequency.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"c = data.corr()\n\ns = c.unstack()\nso = s.sort_values(kind=\"quicksort\")\n\nprint(so[745:-28])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### This one shows the features with the strongest negative correlations.\n\n#### mfcc2 (the second coefficient of the Mel-frequency cepstrum, a mathematical representation of the sound) has a strong negative correlation with centroid, rolloff, and bandwidth.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"c = data.corr()\n\ns = c.unstack()\nso = s.sort_values(kind=\"quicksort\")\n\nprint(so[:10])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Scatter Plots\n#### These scatter plots effectively visualize the relationships between the highly correlated variables.\n#### Most notably, we can see that some variables have negative, non-linear relationships with mfcc2. It is hard to say why this is, because my understanding of Mel-frequency cepstrum is fairly weak.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"attributes = [\"mfcc2\", \"spectral_centroid\",\n              \"spectral_bandwidth\", \"rolloff\", \"zero_crossing_rate\" ]\nsm = scatter_matrix(data[attributes], figsize=(20, 15), diagonal = \"kde\");\n\n#Hide all ticks\n[s.set_xticks(()) for s in sm.reshape(-1)];\n[s.set_yticks(()) for s in sm.reshape(-1)];\n\nfor x in sm.ravel():\n    x.set_xlabel(x.get_xlabel(), fontsize = 14)\n    x.set_ylabel(x.get_ylabel(), fontsize = 14)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing and Feature Selection","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Since all the data is numerical and we have no NaN values (shown below) preprocessing should be easy.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### First we should train and evaluate a model including all the features, and then one with some features removed to see which method is preferable.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold, GridSearchCV\n\ndata = data.drop('filename', axis=1)\n\nX = data.loc[:, data.columns != 'label']\ny = data['label']\n\nlabel_encoder = LabelEncoder().fit(y)\nname_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_model = RandomForestClassifier()\nxgb_model = XGBClassifier()\nk_fold = KFold(n_splits=5, random_state=0, shuffle=True)\n\nrf_params = { \n    'n_estimators': [ i*10 for i in range(15, 30) ],\n    'max_features': ['auto'],\n    'n_jobs': [-1],\n    'random_state': [0]\n}\n\nxgb_params = {\n    'max_depth': range (2, 10, 1),\n    'n_estimators': range(60, 220, 40),\n    'learning_rate': [0.1],\n    'n_jobs': [-1],\n    'random_state': [0]\n}\n\nrf_grid = GridSearchCV(estimator=rf_model, param_grid=rf_params, cv=k_fold, n_jobs=-1)\nxgb_grid = GridSearchCV(estimator=xgb_model, param_grid=xgb_params, cv=k_fold, n_jobs=-1)\n\nrf_grid.fit(X_train, y_train)\nxgb_grid.fit(X_train, y_train)\n\nrf_params_max = rf_grid.best_params_\nxgb_params_max = xgb_grid.best_params_\n\nprint(\"RF accuracy:\")\nprint(rf_grid.score(X_train, y_train))\nprint(\"RF params:\")\nprint(rf_params_max)\nprint(\"\")\nprint(\"XGB accuracy:\")\nprint(xgb_grid.score(X_train, y_train))\nprint(\"XGB params:\")\nprint(xgb_params_max)\nprint(\"\")\n\nrf_model = RandomForestClassifier(**rf_params_max)\nxgb_model = XGBClassifier(**xgb_params_max)\n\nrf_model.fit(X_train, y_train)\nxgb_model.fit(X_train, y_train)\n\nrf_preds = rf_model.predict(X_test)\nxgb_preds = xgb_model.predict(X_test)\n\nprint(\"RF validation accuracy\")\nprint(accuracy_score(y_test, rf_preds))\nprint(\"\")\nprint(\"Random Forest Classification Report: \\n\" + classification_report(y_test, rf_preds))\nprint(\"\")\n\nprint(\"XGB validation accuracy:\")\nprint(accuracy_score(y_test, xgb_preds))\nprint(\"\")\nprint(\"XGB Classification Report: \\n\" + classification_report(y_test, xgb_preds))\nprint(\"\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Now we can drop some of the features to see if it improves the model\n#### As expected, removing the highly correlated features had very little effect.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create models with the parameters found in grid search\nrf_model = RandomForestClassifier(**rf_params_max)\nxgb_model = XGBClassifier(**xgb_params_max)\n\nX_train = X_train.drop(['rolloff', 'mfcc2', 'beats'], axis=1)\nX_test = X_test.drop(['rolloff', 'mfcc2', 'beats'], axis=1)\n\nrf_grid = GridSearchCV(estimator=rf_model, param_grid=rf_params, cv=k_fold, n_jobs=-1)\nxgb_grid = GridSearchCV(estimator=xgb_model, param_grid=xgb_params, cv=k_fold, n_jobs=-1)\n\nrf_grid.fit(X_train, y_train)\nxgb_grid.fit(X_train, y_train)\n\nrf_params_max = rf_grid.best_params_\nxgb_params_max = xgb_grid.best_params_\n\nprint(\"RF accuracy:\")\nprint(rf_grid.score(X_train, y_train))\nprint(\"RF params:\")\nprint(rf_params_max)\nprint(\"\")\nprint(\"XGB accuracy:\")\nprint(xgb_grid.score(X_train, y_train))\nprint(\"XGB params:\")\nprint(xgb_params_max)\nprint(\"\")\n\nrf_model = RandomForestClassifier(**rf_params_max)\nxgb_model = XGBClassifier(**xgb_params_max)\n\nrf_model.fit(X_train, y_train)\nxgb_model.fit(X_train, y_train)\n\nrf_preds = rf_model.predict(X_test)\nxgb_preds = xgb_model.predict(X_test)\n\nprint(\"RF validation accuracy\")\nprint(accuracy_score(y_test, rf_preds))\nprint(\"\")\nprint(\"Random Forest Classification Report: \\n\" + classification_report(y_test, rf_preds))\nprint(\"\")\n\nprint(\"XGB validation accuracy\")\nprint(accuracy_score(y_test, xgb_preds))\nprint(\"\")\nprint(\"XGB Classification Report: \\n\" + classification_report(y_test, xgb_preds))\nprint(\"\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Summary\n### We were able to classify about 70% of songs correctly in the test set. XGBoost very slightly outperformed the Random Forest model, in most cases by 1-2%. It could be worth trying additional models or feature engineering techniques in the future to see if performance can be improved.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}