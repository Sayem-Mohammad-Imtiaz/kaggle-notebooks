{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\nHello everyone! This is my data analysis on the Hotel Booking dataset, and this is the first time that I will try to analyze the data and define my own question and solve it. I am very excited! Now, let's us first take a look at our data."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport math\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.model_selection import GridSearchCV\nimport plotly.express as px\nfrom sklearn.model_selection import train_test_split, KFold, cross_validate, cross_val_score\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"full_data = pd.read_csv(\"/kaggle/input/hotel-booking-demand/hotel_bookings.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The parameters are:\")\nprint(full_data.columns.unique())\nlen(full_data.columns.unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Following columns contain missing values:\")\nprint(full_data.columns[full_data.isna().any()].unique())\nlen(full_data.columns[full_data.isna().any()].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So we just had a quick look at the data. There are 119390 rows with 32 parameters, and four of the parameters have missing values. Let's now look deeper into these four columns and see how many values are missed."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of empty values in children column: \", full_data['children'].isnull().sum())\nprint(\"Percentage： \", full_data['children'].isnull().sum() / full_data.shape[0] * 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of empty values in country column: \", full_data['country'].isnull().sum())\nprint(\"Percentage： \", full_data['country'].isnull().sum() / full_data.shape[0] * 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of empty values in agent column: \", full_data['agent'].isnull().sum())\nprint(\"Percentage： \", full_data['agent'].isnull().sum() / full_data.shape[0] * 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of empty values in company column: \", full_data['company'].isnull().sum())\nprint(\"Percentage： \", full_data['company'].isnull().sum() / full_data.shape[0] * 100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So from the above we can see the exact number of rows with missing values in each column, and it is shown that the company column has essentially 94.3% values missing! This basically means that we should not use the company column for further data analysis as there are too many missing values. So let's just drop this column."},{"metadata":{"trusted":true},"cell_type":"code","source":"full_data = full_data.drop(['company'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_data.columns.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Univariate Data analysis\n\nNow we have see the general picture of our data. I say we can explore some of the columns deeper and visualize their distributions and check outliers and other characteristics. Let's begin!"},{"metadata":{},"cell_type":"markdown","source":"**Hotel**\n\nFrom this column, we can see that more people(almost double) prefer to book a city hotel. This may be intuitive because a city hotel is usually cheaper than a resort hotel. "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 10))\nplt.title(\"Hotel Column\")\nsns.countplot(x=full_data['hotel'])\nplt.show()\n\nprint(\"Percentages: \")\nprint(full_data['hotel'].value_counts() / full_data.shape[0] * 100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**is_canceled**\n\nFrom this column, we can see that more people(almost double) tend to not cancel their bookings. "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 10))\nplt.title(\"is_canceled Column\")\nsns.countplot(x=full_data['is_canceled'])\nplt.show()\n\nprint(\"Percentages: \")\nprint(full_data['is_canceled'].value_counts() / full_data.shape[0] * 100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**lead_time**\n\nSo here we see that this column is highly right-skewed. Most people only book the hotel a few days before they go, but there is people who book two years prior to their check in!"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 10))\nplt.title(\"lead_time Column\")\nsns.distplot(a=full_data['lead_time'], kde=False, axlabel=\"Number of elapsed days\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 10))\nplt.title(\"lead_time Column\")\nsns.boxplot(x=full_data['lead_time'])\nplt.show()\n\nprint(full_data['lead_time'].describe())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Arrival Month**\n\nSo from this column, we see that there is a slighly increase in arrivings during summer, which is also intuitive because most families can travel together during summer because kids are in vocation. "},{"metadata":{"trusted":true},"cell_type":"code","source":"ordered_months = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \n          \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n\nsorted_month = pd.Categorical(full_data[\"arrival_date_month\"], categories=ordered_months, ordered=True)\n\nplt.figure(figsize=(15, 10))\nplt.title(\"Arrival Month\")\nsns.countplot(x=sorted_month)\nplt.show()\n\nprint(\"Percentages: \")\nprint(sorted_month.value_counts() / full_data.shape[0] * 100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**stays_in_weekend_nights**\n\nSo most people actually don't stay overnight during weekends, but there are people who basically lived in the hotel for a few weeks."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 10))\nplt.title(\"Weekend Nights Column\")\nsns.countplot(x=full_data['stays_in_weekend_nights'])\nplt.show()\n\nprint(\"Percentages: \")\nprint(full_data['stays_in_weekend_nights'].value_counts() / full_data.shape[0] * 100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Number of adults**\n\nSo most groups consist of two adults, which is normal. Those customers with 20 or 50 adults are likely to be tourist groups"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 10))\nplt.title(\"Adult Column\")\nsns.countplot(x=full_data['adults'])\nplt.show()\n\nprint(full_data['adults'].value_counts() / full_data.shape[0] * 100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Number of Children**\n\nSo most customers don't bring children to the hotel."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 10))\nplt.title(\"Children Column\")\nsns.countplot(x=full_data['children'])\nplt.show()\n\nprint(full_data['children'].value_counts() / full_data.shape[0] * 100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**babies**\n\nAgain, most customers don't bring babdies."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 10))\nplt.title(\"Baby Column\")\nsns.countplot(x=full_data['babies'])\nplt.show()\n\nprint(full_data['babies'].value_counts() / full_data.shape[0] * 100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Country**"},{"metadata":{"trusted":true},"cell_type":"code","source":"country_data = pd.DataFrame(full_data.loc[full_data[\"is_canceled\"] == 0][\"country\"].value_counts())\ncountry_data.rename(columns={\"country\": \"Number of Guests\"}, inplace=True)\ntotal_guests = country_data[\"Number of Guests\"].sum()\ncountry_data[\"Guests in %\"] = round(country_data[\"Number of Guests\"] / total_guests * 100, 2)\ncountry_data[\"country\"] = country_data.index\n\nguest_map = px.choropleth(country_data,\n                    locations=country_data.index,\n                    color=country_data[\"Guests in %\"], \n                    hover_name=country_data.index, \n                    color_continuous_scale=px.colors.sequential.Plasma,\n                    title=\"Home country of guests\")\nguest_map.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"OK, so I just visualized some columns that I am interested in. This type of analysis did tell us some basic information about the customers such as what type of hotel they book, where they come from, and usually how many people travel together. These are all useful information, but this sort of analysis is too vague and waste of time. I would say let's now define our question and then see what we can do."},{"metadata":{},"cell_type":"markdown","source":"# Define Question\n\nIf I am a hotel manager, I will be very interested in knowing if a customer will cancel his hotel reservation, because that deeply correlates with the revenues our hotel can earn. Therefore, let's try to build a model to predict if someone will cancel his hotel reservation from other parameters."},{"metadata":{},"cell_type":"markdown","source":"**Cancellation Correlations**\n\nNow we have defined the problem, let's first see what columns are highly associated with the is_cancelled column"},{"metadata":{"trusted":true},"cell_type":"code","source":"cancel_corr = full_data.corr()[\"is_canceled\"]\ncancel_corr.abs().sort_values(ascending=False)[1:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is thus shown that lead_time, total_of_special_requests, required_car_parking_spaces, booking_changes and previous_cancellations are the 5 most correlated numerical variables with is_cancelled column. But to prevent possible data leakage, we should exclude booking_changes, which may include the cancellation of hotel reservation. Furthermore, reservation_status also include whether a customer cancels the booking or not. So it must also be excluded to prevent data leakage. "},{"metadata":{},"cell_type":"markdown","source":"Now let's look at the categorical features."},{"metadata":{},"cell_type":"markdown","source":"**Hotel**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 10))\nplt.title(\"Hotel Column\")\nsns.barplot(x=full_data['hotel'], y=full_data['is_canceled'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The type of hotel seems to affect if a customer will cancel the reservation."},{"metadata":{},"cell_type":"markdown","source":"**Meal**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 10))\nplt.title(\"Meal Column\")\nsns.barplot(x=full_data['meal'], y=full_data['is_canceled'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Meal also seems to affect cancelation chance. Specifically, customers who ordered full board are more likely to cancel reservations."},{"metadata":{},"cell_type":"markdown","source":"**Market Segment**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 10))\nplt.title(\"Market Column\")\nsns.barplot(x=full_data['market_segment'], y=full_data['is_canceled'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This column also seem to affect reservation cancelation."},{"metadata":{},"cell_type":"markdown","source":"**Distribution Channel**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 10))\nplt.title(\"Distribution Channel Column\")\nsns.barplot(x=full_data['distribution_channel'], y=full_data['is_canceled'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Again, has an effect"},{"metadata":{},"cell_type":"markdown","source":"**Reserved Room Type**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 10))\nplt.title(\"Reserved Room Type Column\")\nsns.barplot(x=full_data['reserved_room_type'], y=full_data['is_canceled'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This column also seems to have a strong impact on cancellation. Customers who reserved P type room is more likely to cancel reservation."},{"metadata":{},"cell_type":"markdown","source":"**Assigned Room Type**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 10))\nplt.title(\"Assigned Room Type Column\")\nsns.barplot(x=full_data['assigned_room_type'], y=full_data['is_canceled'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Customers who were assigned P or L rooms are more likely to cancel reservations."},{"metadata":{},"cell_type":"markdown","source":"**Deposit Type**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 10))\nplt.title(\"Deposit Column\")\nsns.barplot(x=full_data['deposit_type'], y=full_data['is_canceled'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Despoit definitely indicates if a customer is more likely to cancel reservation. Visitors with non-refund type deposite are more likely to cancel booking."},{"metadata":{},"cell_type":"markdown","source":"**Customer Type**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 10))\nplt.title(\"Customer Type Column\")\nsns.barplot(x=full_data['customer_type'], y=full_data['is_canceled'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Customer type also seems to be an indicator. Specifically transient customers are more likely to cancel reservations."},{"metadata":{},"cell_type":"markdown","source":"# Model Selection\n\nBefore we make further analysis, let's select a machine learning model to use for our prediction. In this section I will create several simple models and see which one has the best performance. "},{"metadata":{"trusted":true},"cell_type":"code","source":"num_features = [\"lead_time\",\"arrival_date_week_number\",\"arrival_date_day_of_month\",\n                \"stays_in_weekend_nights\",\"stays_in_week_nights\",\"adults\",\"children\",\n                \"babies\",\"is_repeated_guest\", \"previous_cancellations\",\n                \"previous_bookings_not_canceled\",\"agent\",\n                \"required_car_parking_spaces\", \"total_of_special_requests\", \"adr\"]\n\ncat_features = [\"hotel\",\"arrival_date_month\",\"meal\",\"market_segment\",\n                \"distribution_channel\",\"reserved_room_type\",\"assigned_room_type\", \"deposit_type\",\"customer_type\"]\n\n\nfeatures = num_features + cat_features\nX = full_data.drop([\"is_canceled\"], axis=1)[features]\ny = full_data[\"is_canceled\"]\n\nnum_transformer = SimpleImputer(strategy=\"constant\")\n\ncat_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n    (\"onehot\", OneHotEncoder(handle_unknown='ignore'))])\n\npreprocessor = ColumnTransformer(transformers=[(\"num\", num_transformer, num_features),\n                                               (\"cat\", cat_transformer, cat_features)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\nbase_models = [(\"DT_model\", DecisionTreeClassifier(random_state=42)),\n               (\"RF_model\", RandomForestClassifier(random_state=42,n_jobs=-1)),\n               (\"LR_model\", LogisticRegression(random_state=42,n_jobs=-1)),\n               (\"XGB_model\", XGBClassifier(random_state=42, n_jobs=-1)),\n               (\"Ada_model\", AdaBoostClassifier(random_state=42)),\n               (\"KNN_model\", KNeighborsClassifier(n_jobs=-1))]\n\nkfolds = 4 # 4 = 75% train, 25% validation\nsplit = KFold(n_splits=kfolds, shuffle=True, random_state=42)\n\n'''\nfor name, model in base_models:\n    model_steps = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', model)])\n    \n    cv_results = cross_val_score(model_steps, \n                                 X, y, \n                                 cv=split,\n                                 scoring=\"accuracy\",\n                                 n_jobs=-1)\n    \n    min_score = round(min(cv_results), 4)\n    max_score = round(max(cv_results), 4)\n    mean_score = round(np.mean(cv_results), 4)\n    std_dev = round(np.std(cv_results), 4)\n    print(f\"{name} cross validation accuarcy score: {mean_score} +/- {std_dev} (std) min: {min_score}, max: {max_score}\")\n'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that random forest classifier had the best performance(86.664%). Therefore, we will use this model for later predictions.\n\nDetail: RF_model cross validation accuarcy score: 0.8664 +/- 0.0012 (std) min: 0.8646, max: 0.8676"},{"metadata":{},"cell_type":"markdown","source":"# More Bivariate Analysis\n\nWe have found the columns that affect is_cancelled the strongest. Now let's actually visualize the correlations."},{"metadata":{},"cell_type":"markdown","source":"**lead-time**\n\nWe see that generally the earlier the customer books the hotel, the more likely he will cancel the reservation"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 10))\nplt.title(\"lead_time Column\")\nsns.barplot(x=full_data['is_canceled'], y=full_data['lead_time'])\nplt.show()\n\nprint( full_data[[\"lead_time\",\"is_canceled\"]].groupby([\"is_canceled\"], as_index = False).mean() )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**total_of_special_requests**\n\nWe see that the more requests the customer makes, the less likely he will cancel the reservation"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 10))\nplt.title(\"total_of_special_requests Column\")\nsns.barplot(x=full_data['total_of_special_requests'], y=full_data['is_canceled'])\nplt.show()\n\nprint( full_data[[\"total_of_special_requests\",\"is_canceled\"]].groupby([\"total_of_special_requests\"], as_index = False).mean() )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**required_car_parking_spaces**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 10))\nplt.title(\"required_car_parking_spaces Column\")\nsns.countplot(x=full_data['required_car_parking_spaces'])\nplt.show()\n\nprint(full_data['required_car_parking_spaces'].value_counts() / full_data.shape[0] * 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 10))\nplt.title(\"required_car_parking_spaces Column\")\nsns.barplot(x=full_data['required_car_parking_spaces'], y=full_data['is_canceled'])\nplt.show()\n\nprint( full_data[[\"required_car_parking_spaces\",\"is_canceled\"]].groupby([\"required_car_parking_spaces\"], as_index = False).mean() )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So we see that if the customer requires at least one car parking space, the chance to cancel the reservation is very small. I say we can actually modify this column to only show if a customer makes a requirement(denoted as 1) or not(denoted as 0), which perhaps is more straightforward to our model?"},{"metadata":{"trusted":true},"cell_type":"code","source":"full_data.loc[full_data['required_car_parking_spaces'] != 0, 'required_car_parking_spaces'] = 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After the change:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 10))\nplt.title(\"required_car_parking_spaces Column\")\nsns.countplot(x=full_data['required_car_parking_spaces'])\nplt.show()\n\nprint(full_data['required_car_parking_spaces'].value_counts() / full_data.shape[0] * 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 10))\nplt.title(\"required_car_parking_spaces Column\")\nsns.barplot(x=full_data['required_car_parking_spaces'], y=full_data['is_canceled'])\nplt.show()\n\nprint( full_data[[\"required_car_parking_spaces\",\"is_canceled\"]].groupby([\"required_car_parking_spaces\"], as_index = False).mean() )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see if this would make any difference to our model's prediction score."},{"metadata":{"trusted":true},"cell_type":"code","source":"X = full_data.drop([\"is_canceled\"], axis=1)[features]\ny = full_data[\"is_canceled\"]\n\nmodel_steps = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', RandomForestClassifier(random_state=42,n_jobs=-1))])\n    \ncv_results = cross_val_score(model_steps, \n                             X, y, \n                             cv=split,\n                             scoring=\"accuracy\",\n                             n_jobs=-1)\n\nmin_score = round(min(cv_results), 4)\nmax_score = round(max(cv_results), 4)\nmean_score = round(np.mean(cv_results), 4)\nstd_dev = round(np.std(cv_results), 4)\nprint(f\"RF Model cross validation accuarcy score: {mean_score} +/- {std_dev} (std) min: {min_score}, max: {max_score}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nice! We see an improvement in accuracy, which means this modification actually works!"},{"metadata":{},"cell_type":"markdown","source":"**previous_cancellations**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 10))\nplt.title(\"previous_cancellations Column\")\nsns.countplot(x=full_data['previous_cancellations'])\nplt.show()\n\nprint(full_data['previous_cancellations'].value_counts() / full_data.shape[0] * 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 10))\nplt.title(\"previous_cancellations Column\")\nsns.barplot(x=full_data['previous_cancellations'], y=full_data['is_canceled'])\nplt.show()\n\nprint( full_data[[\"previous_cancellations\",\"is_canceled\"]].groupby([\"previous_cancellations\"], as_index = False).mean() )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So we see that if the number of previous_cancellations is 1 or above 12, the chance of canceling the reservation is very high. This makes me wonder that will the prediction be better if I apply the same modification as parking space. Let's find out"},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_previous_cancel = full_data['previous_cancellations'].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_data.loc[(full_data['previous_cancellations'] == 1) | (full_data['previous_cancellations'] >= 13), 'previous_cancellations'] = 1\nfull_data.loc[(full_data['previous_cancellations'] != 1) & (full_data['previous_cancellations'] < 13), 'previous_cancellations'] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 10))\nplt.title(\"previous_cancellations Column\")\nsns.countplot(x=full_data['previous_cancellations'])\nplt.show()\n\nprint(full_data['previous_cancellations'].value_counts() / full_data.shape[0] * 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 10))\nplt.title(\"previous_cancellations Column\")\nsns.barplot(x=full_data['previous_cancellations'], y=full_data['is_canceled'])\nplt.show()\n\nprint( full_data[[\"previous_cancellations\",\"is_canceled\"]].groupby([\"previous_cancellations\"], as_index = False).mean() )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now our model's performance is:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = full_data.drop([\"is_canceled\"], axis=1)[features]\ny = full_data[\"is_canceled\"]\n\nmodel_steps = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', RandomForestClassifier(random_state=42,n_jobs=-1))])\n    \ncv_results = cross_val_score(model_steps, \n                             X, y, \n                             cv=split,\n                             scoring=\"accuracy\",\n                             n_jobs=-1)\n\nmin_score = round(min(cv_results), 4)\nmax_score = round(max(cv_results), 4)\nmean_score = round(np.mean(cv_results), 4)\nstd_dev = round(np.std(cv_results), 4)\nprint(f\"RF Model cross validation accuarcy score: {mean_score} +/- {std_dev} (std) min: {min_score}, max: {max_score}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Sadly, this actually makes the performance worse, so let's undo this change. "},{"metadata":{"trusted":true},"cell_type":"code","source":"full_data['previous_cancellations'] = temp_previous_cancel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 10))\nplt.title(\"previous_cancellations Column\")\nsns.barplot(x=full_data['previous_cancellations'], y=full_data['is_canceled'])\nplt.show()\n\nprint( full_data[[\"previous_cancellations\",\"is_canceled\"]].groupby([\"previous_cancellations\"], as_index = False).mean() )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = full_data.drop([\"is_canceled\"], axis=1)[features]\ny = full_data[\"is_canceled\"]\n\nmodel_steps = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', RandomForestClassifier(random_state=42,n_jobs=-1))])\n    \ncv_results = cross_val_score(model_steps, \n                             X, y, \n                             cv=split,\n                             scoring=\"accuracy\",\n                             n_jobs=-1)\n\nmin_score = round(min(cv_results), 4)\nmax_score = round(max(cv_results), 4)\nmean_score = round(np.mean(cv_results), 4)\nstd_dev = round(np.std(cv_results), 4)\nprint(f\"RF Model cross validation accuarcy score: {mean_score} +/- {std_dev} (std) min: {min_score}, max: {max_score}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Final Tuning\n\nNow we have done all the modifications. Let's finally adjust the hyperparameters and make the final predictions."},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_model_enh = RandomForestClassifier(n_estimators=160,\n                               max_features=0.4,\n                               min_samples_split=2,\n                               n_jobs=-1,\n                               random_state=0)\n\nsplit = KFold(n_splits=kfolds, shuffle=True, random_state=42)\nmodel_pipe = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', rf_model_enh)])\ncv_results = cross_val_score(model_pipe, \n                                 X, y, \n                                 cv=split,\n                                 scoring=\"accuracy\",\n                                 n_jobs=-1)\n# output:\nmin_score = round(min(cv_results), 4)\nmax_score = round(max(cv_results), 4)\nmean_score = round(np.mean(cv_results), 4)\nstd_dev = round(np.std(cv_results), 4)\nprint(f\"Enhanced RF model cross validation accuarcy score: {mean_score} +/- {std_dev} (std) min: {min_score}, max: {max_score}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So our final perdiction accyracy is 87.12%."},{"metadata":{},"cell_type":"markdown","source":"# Checking Parameters\n\nNow we have trained a random forest classifier. I am curious in which factors weight the most in this model and if there is a way for us to further improve it. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = preprocessor.fit_transform(X)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\n\nrf_model_enh.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"important_features = pd.Series(data=rf_model_enh.feature_importances_,index=X_train.columns)\nimportant_features.sort_values(ascending=False,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}