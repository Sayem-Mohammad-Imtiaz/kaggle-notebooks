{"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import cluster, mixture # For clustering \nimport types\nfrom sklearn import metrics\nimport os\nfrom sklearn.manifold import TSNE\nimport plotly.graph_objs as go\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.datasets import make_blobs\nfrom sklearn.cluster import MeanShift, estimate_bandwidth\ninit_notebook_mode(connected=True)\nfrom pandas import read_csv\n%matplotlib inline","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"def loadData():\n    dataset = pd.read_csv(\"../input/2017.csv\")\n    dataset.head(5)\n    return dataset\n\ndef normalizeData(dataset):\n    # Instantiate Scaler Object \n    ss = StandardScaler()\n    # Fit and transform \n    ss.fit_transform(dataset)\n    dataset.head(10)\n    country.head(10)\n    return dataset\ndef univariateAnaly(dataset):\n    sns.distplot(dataset['Happiness.Score'])\ndef heatmapAnaly(dataset):\n    plt.figure(figsize=(10,8))\n    datasetCorr=dataset.drop(['Happiness.Rank'],axis = 1)\n    datasetCorr = datasetCorr.corr()\n    sns.heatmap(datasetCorr, vmax=.8, square=True,annot=True,linewidths = .5, fmt='.2f',annot_kws={'size': 10} )\ndef missingValueChk(dataset):\n    print(dataset.isnull().sum())\ndef detectOutlier(dataset):\n    for i in range(3,dataset.shape[1]):\n        quartile_1, quartile_3 = np.percentile(dataset[dataset.columns.values[i]], [25, 75])\n        iqr = quartile_3 - quartile_1\n        lower_bound = quartile_1 - (iqr * 1.5)\n        upper_bound = quartile_3 + (iqr * 1.5)\n        print((\"Outlier in \",dataset.columns[i],\":\",np.where((dataset[dataset.columns.values[i]] > upper_bound) | (dataset[dataset.columns.values[i]] < lower_bound))))\ndef visualizeOutlier(dataset):\n    sns.lmplot('Happiness.Score','Family',data=dataset,fit_reg=False) \n    sns.lmplot('Happiness.Score','Generosity',data=dataset,fit_reg=False)  \n    sns.lmplot('Happiness.Score','Trust..Government.Corruption.',data=dataset,fit_reg=False)\n    sns.lmplot('Happiness.Score','Dystopia.Residual',data=dataset,fit_reg=False)\ndef removeOutliers(col):\n    quartile_1, quartile_3 = np.percentile(dataset[col], [25, 75])\n    iqr = quartile_3 - quartile_1\n    mean=dataset[col].mean()\n    lower_bound = quartile_1 - (iqr * 1.5)\n    upper_bound = quartile_3 + (iqr * 1.5)\n    repeat=False\n    for i in range(dataset.shape[0]):\n        if((dataset[col].values[i]>upper_bound) | (dataset[col].values[i]<lower_bound)):\n                dataset[col].values[i]=mean \n              #  print(\"repeat\", repeat)\n                repeat=True\n    return repeat\ndef iterateOutliers(dataset):\n    repeat=True\n    while (repeat):\n        detectOutlier(dataset)\n        repeat1=removeOutliers('Family')\n        repeat2=removeOutliers('Generosity')\n        repeat3=removeOutliers('Trust..Government.Corruption.')\n        repeat4=removeOutliers('Dystopia.Residual')\n        repeat=repeat1 or repeat2 or repeat3 or repeat4\n        detectOutlier(dataset)\n    return dataset\ndef clustering(type,dataset,params):\n    ds=dataset.drop(['Happiness.Rank','Happiness.Score'],axis=1)\n    if(type=='kmeans'):\n        kmeans = cluster.KMeans(n_clusters =params['nclusters'] )\n        return kmeans.fit_predict(ds)\n    if(type=='meanshift'):\n        meanShift = cluster.MeanShift(bandwidth=params['bandwidth'])\n        return  meanShift.fit_predict(ds)\n    if(type=='minibatchkmeans'):\n        miniBatch = cluster.MiniBatchKMeans(n_clusters=params['nclusters'])\n        return miniBatch.fit_predict(ds)\n    if(type=='dbscan'):\n        dbscan = cluster.DBSCAN(eps=params['eps'])\n        return dbscan.fit_predict(ds)\n    if(type=='spectral'):\n        spectral = cluster.SpectralClustering(n_clusters=params['nclusters'])\n        return spectral.fit_predict(ds)\n    if(type=='affinitypropagation'):\n        affinityPropagation =  cluster.AffinityPropagation(damping=params['damping'], preference=params['preference'])\n        affinityPropagation.fit(ds)\n        return affinityPropagation.predict(ds)\n    if(type=='birch'):\n        birch = cluster.Birch(n_clusters=params['nclusters'])\n        return birch.fit_predict(ds)\n    if(type=='gaussian'):\n        gmm = mixture.GaussianMixture( n_components=params['nclusters'], covariance_type='full')\n        gmm.fit(ds)\n        return  gmm.predict(ds)\n\ndef performClustering(clusterTypes,ds,params):\n    fig,ax = plt.subplots(nrows,ncols, figsize=(10,10)) \n    i = 0\n    j=0\n    silhouetteDf=[]\n    clusterName=[]\n    for ct in clusterTypes['clustType'] :\n        clusteringResult = clustering(ct,ds,params)\n        clusterName.append(ct)\n        ds[ct] = pd.DataFrame(clusteringResult)\n        ax[i,j].scatter(ds.iloc[:, 4], ds.iloc[:, 5],  c=clusteringResult)\n        ax[i,j].set_title(ct+\"Clustering Result\")\n        j=j+1\n        if( j % ncols == 0) :\n            j= 0\n            i=i+1\n    plt.subplots_adjust(bottom=-0.5, top=1.5)\n    plt.show()\n    return ds\n\n","outputs":[],"execution_count":null,"metadata":{"collapsed":true}},{"cell_type":"markdown","source":"## Variable Identification\n\n### First, identify Predictor (Input) and Target (output) variables. Next, identify the data type and category of the variables.\n-  Target:\n    1. Happiness_Score\n-  Predictors:\n    1. Whisker_high\n    2. Whisker_low\n    3. Economy_GDP_per_Capita\n    4. Family\n    5. Health_Life_Expectancy\n    6. Freedom\n    7. Generosity\n    8. Trust_Government_Corruption\n    9. Dystopia_Residual\n-  DataTypes","metadata":{"collapsed":true}},{"cell_type":"code","source":"dataset=loadData()\ncountry=dataset[dataset.columns[0]]\ndataset=dataset.drop(['Country'],axis=1)\ndataset=normalizeData(dataset)\ndataset.head(5)","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"markdown","source":"-  None of the variable is categorical\n\n## Univariate Analysis","metadata":{"collapsed":true}},{"cell_type":"code","source":"univariateAnaly(dataset)","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"heatmapAnaly(dataset)","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"markdown","source":"### Happiness Score is strongly correlated with:\n1. Whisker_high           : 1.0\n2. Whisker_low            : 1.0\n3. Economy_GDP_per_Capita : 0.81\n4. Family                 : 0.75\n5. Health_Life_Expectancy : 0.78\n","metadata":{}},{"cell_type":"markdown","source":"## Check Missing Values","metadata":{}},{"cell_type":"code","source":"missingValueChk(dataset)","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"markdown","source":"## Outlier Detection\n\n- IQR Method","metadata":{"collapsed":true}},{"cell_type":"code","source":"detectOutlier(dataset)","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"visualizeOutlier(dataset)","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"markdown","source":"### Remove Outliers","metadata":{}},{"cell_type":"code","source":"dataset=iterateOutliers(dataset)","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"markdown","source":"## Perform Clustering","metadata":{}},{"cell_type":"code","source":"clusterTypes = {'clustType':['kmeans',\"meanshift\",\"minibatchkmeans\",\"dbscan\",\"spectral\",\"affinitypropagation\",\"birch\",\"gaussian\"]}\nncols = 2\nnrows = 4\nnclusters= 3\nbandwidth = 0.1 \neps = 0.3\ndamping = 0.9\npreference = -200\nparams = {'nclusters' :  nclusters, 'eps' : eps,'bandwidth' : bandwidth, 'damping' : damping, 'preference' : preference}\ndataset.head(10)\ndataset=performClustering(clusterTypes,dataset,params)","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"dataset=pd.concat([dataset,country],axis=1)\ndataset.head(10)","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"\ndata = dict(type = 'choropleth', \n           locations = dataset['Country'],\n           locationmode = 'country names',\n           z = dataset['Happiness.Score'], \n           text = dataset['Country'],\n           colorbar = {'title':'Happiness Score'})\nlayout = dict(title = 'Global Happiness Score', \n             geo = dict(showframe = False, \n                       projection = {'type': 'Mercator'}))\nchoromap3 = go.Figure(data = [data], layout=layout)\niplot(choromap3) ","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"dataset.columns\ndata = dict(type = 'choropleth', \n           locations = dataset['Country'],\n           locationmode = 'country names',\n           z = dataset['kmeans'], \n           text = dataset['Country'],\n           colorbar = {'title':'Cluster Group'})\nlayout = dict(title = 'Kmeans Clustering', \n           geo = dict(showframe = False, \n           projection = {'type': 'Mercator'}))\nchoromap3 = go.Figure(data = [data], layout=layout)\niplot(choromap3) ","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"dataset.columns\ndata = dict(type = 'choropleth', \n           locations = dataset['Country'],\n           locationmode = 'country names',\n           z = dataset['meanshift'], \n           text = dataset['Country'],\n           colorbar = {'title':'Cluster Group'})\nlayout = dict(title = 'MeanShift Clustering', \n           geo = dict(showframe = False, \n           projection = {'type': 'Mercator'}))\nchoromap3 = go.Figure(data = [data], layout=layout)\niplot(choromap3) ","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"dataset.columns\ndata = dict(type = 'choropleth', \n           locations = dataset['Country'],\n           locationmode = 'country names',\n           z = dataset['minibatchkmeans'], \n           text = dataset['Country'],\n           colorbar = {'title':'Cluster Group'})\nlayout = dict(title = 'Minibatch Kmeans Clustering', \n           geo = dict(showframe = False, \n           projection = {'type': 'Mercator'}))\nchoromap3 = go.Figure(data = [data], layout=layout)\niplot(choromap3) ","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"","outputs":[],"execution_count":null,"metadata":{"collapsed":true}}],"nbformat":4,"nbformat_minor":1,"metadata":{"language_info":{"file_extension":".py","version":"3.6.3","codemirror_mode":{"version":3,"name":"ipython"},"name":"python","pygments_lexer":"ipython3","nbconvert_exporter":"python","mimetype":"text/x-python"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}}}