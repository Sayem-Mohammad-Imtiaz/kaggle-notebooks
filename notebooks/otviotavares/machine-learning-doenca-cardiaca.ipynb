{"cells":[{"metadata":{},"cell_type":"markdown","source":"<a id='top'>Top reference</a>\n<h1 style=\"text-align:center\">\n<img src=\"https://files.aredacao.com.br/upload/content/doencas-cardiacas-merecem-atencao-em-meio-a-pandemia.jpg\" style=\"width:900px;height:400px;\">\n\n### Notas de lançamento\n\n- Versão 1: Verificação dos dados e distribuição dos dados.\n- Versão 2: Seleção sobre as melhores variáveis.\n- Versão 3: Ajuste sobre as escalas.\n- Versão 4: Divisão dados de treino/teste e cross validation.\n- Versão 5: Treinamento de diversos modelos de machine learning.\n- Versão 6: Calculo das métricas de treino e de teste.\n\n\n## Conteúdo\n\n1. [Introdução](#1)\n 1. [Módulos](#1.1)\n2. [Ajustando dados para os modelos de Machine Learning](#2)\n 1. [Escala](#2.1)\n3. [Featute Selection](#3)\n 1. [Seleção Univariada](#3.1)\n 2. [Eliminação Recursiva de Atributos](#3.2)\n 3. [Método Ensemble](#3.3)\n4. [Divisão dos dados](#4)\n5. [Avaliando a Performance](#5)\n 1. [Curva ROC](#5.1)\n 2. [Acurácia](#5.2)\n 3. [Precisão](#5.3)\n 4. [Recall](#5.3)\n6. [Modelos de Machine Learning](#6)\n 1. [Logistic Regression](#6.1)\n 2. [Decision Tree Classifier](#6.2)\n 3. [Kneighbors Classifier](#6.3)\n 4. [Linear Discriminant Analysis](#6.4)\n 5. [Gaussian NB](#6.5)\n 6. [Suport Vector Machine](#6.6)\n7. [Otimização de Performance com Métodos Ensemble](#7)\n 1. [Bagged Decision Trees](#7.1)\n 2. [Random Forest](#7.2)\n 3. [AdaBoost](#7.3)\n 4. [Gradient Boosting](#7.4) \n 4. [Voting Ensemble](#7.5)\n 5. [XGboost](#7.6)\n8. [Conclusão](#8)"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"1\"></a> <br>\n# <div class=\"alert alert-block alert-info\">1 - Introducão</div>\n\n**As Doenças Cardiovasculares (DCV) são, atualmente, a maior causa de mortes no mundo. Elas foram responsáveis\npor mais de 17 milhões de óbitos em 2008, dos quais três milhões ocorreram antes dos 60 anos de idade, e grande\nparte poderia ter sido evitada. A Organização Mundial de Saúde estima que em 2030 quase 23,6 milhões de\npessoas morrerão de doenças cardiovasculares.**\n\n**O ônus econômico das doenças cardiovasculares cresceu exponencialmente nas últimas décadas. Em 2000, as doenças\ncardiovasculares foram responsáveis pela principal alocação de recursos públicos em hospitalizações no Brasil e\nforam a terceira causa de permanência hospitalar prolongada. Entre 1991 e 2000, os custos hospitalares atribuídos \nàs doenças cardiovasculares aumentaram cerca de 176%**"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"1.1\"></a> <br>\n# <div class=\"alert alert-warning\">1.1 - Módulos</div>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Manipulação dos dados e visualização\nimport numpy as np \nimport pandas as pd \nimport plotly.graph_objects as go\nimport plotly.express as px\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport time\n\n#Normalização dos dados\nfrom sklearn.preprocessing import MinMaxScaler\n\n#Seleção de variáveis\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nfrom sklearn.feature_selection import RFE\nfrom sklearn.ensemble import ExtraTreesClassifier\n\n#Divisão de dados\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\n\n#Modelos de Machine Learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\n\n#Métricas\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import auc\nfrom sklearn.metrics import plot_roc_curve\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import accuracy_score\n\n#Otimização Performance com Métodos Ensemble\nfrom sklearn.ensemble import BaggingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/heart-disease-uci/heart.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. **age:** Idade\n1. **sex:** Sexo\n1. **cp:** Tipo de dor no peito (4 valores)\n1. **trestbps:** Pressão sanguínea em repouso\n1. **chol:** Colesterol sérico em mg / dl\n1. **fbs:** Açúcar no sangue em jejum> 120 mg / dl\n1. **restecg:** Resultados eletrocardiográficos de repouso (valores 0,1,2)\n1. **thalach:** Frequência cardíaca máxima alcançada\n1. **exang:** Angina induzida por exercício\n1. **oldpeak:** Depressão de ST induzida por exercício em relação ao repouso\n1. **slope:** A inclinação do segmento ST de pico do exercício\n1. **ca:** Número de vasos principais (0-3) coloridos por fluorosopia\n1. **thal:** 3 = normal; 6 = defeito corrigido; 7 = defeito reversível\n1. **target:** Indica a presença ou ausência de doença cardíaca. (= o atributo previsto)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Tamanho do df\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Verificar se existe valores NaN\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Tipos de dados que iremos trabalhar\ndf.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Verificar a distribuição entre casos confirmados e não confirmados, o ideal seria uma distribuição de 50%.\n\n(df['target'].value_counts()/df.shape[0])*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Skew se refere a distribuição dos dados que é assumida ser normal ou gaussiana. \n#Muitos algoritmos de Machine Learning consideram que os dados possuem uma distribuição normal.\n\ndf.skew()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correlacao = df.corr()\nmask = np.zeros_like(correlacao)\nmask[np.triu_indices_from(mask)] = True\nwith sns.axes_style(\"white\"):\n    \n    f, ax = plt.subplots(figsize=(10, 8))\n    sns.heatmap(correlacao,center=0,cmap=\"coolwarm\",mask=mask,annot=True, square=True, fmt='.2f')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"2\"></a> <br>\n# <div class=\"alert alert-block alert-info\">2 - Ajustando dados para os modelos de Machine Learning</div>\n\n**Muitos algoritmos esperam receber os dados em um formato específico. Portanto, é necessário entregar os dados\ncom uma estrutura que seja adequada ao algoritmo que será utilizado**"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"2.1\"></a> <br>\n# <div class=\"alert alert-warning\">2.1 - Escala</div>\n\n**A escala é uma das primeiras tarefas dentro do pré-processamento, que consiste em deixar os dados na mesma escala.\nMuitos algoritmos de machine learning vão se beneficiar disso e produzir resultados melhores.**\n\n**Na etapa abaixo é chamado de normalização e significa colocar os dados em uma escala com range entre 0 e 1.\nIsso é útil para otimização, sendo usado nos algoritmos de Machine Learning, como gradient descent.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Normalização sobre as escalas de valores\n\ndf_X = df.drop(columns=[\"target\"])\ndf_Y = df[\"target\"]\n\n\nX = df_X.values\nY = df_Y.values\n\nscaler = MinMaxScaler(feature_range=(0,1))\nrescaledx = scaler.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"3\"></a> <br>\n# <div class=\"alert alert-block alert-info\">3 - Featute Selection</div>\n\n**Os atributos presentes no dataset, terão grande influência na precisão e no modelo predito.**\n- Atributos irrelevantes terão impacto negativo na performance.\n- Atributos colineares podem afetar na acurácia do modelo.\n\n**Nesta etapa é onde selecionamos os atributos (variáveis) que serão melhores candidatas a variáveis preditoras.\nAjudando a reduzir o overfitting, aumentando a acurácia do modelo e reduzindo o tempo de treinamento.**"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"3.1\"></a> <br>\n# <div class=\"alert alert-warning\">3.1 - Seleção Univariada</div>\n\n**Testes estatísticos podem ser usados para selecionar os atributos que possuem forte\nrelacionamento com a variável que queremos prever.\nFoi utilizado a função SelectKBest() que pode ser utilizada em diversos testes estatísticos,\npara selecionar os atributos.**\n\n**Foi utilizado o tese do Qui-Quadrado**\n\n**O teste de independência Qui-Quadrado é usado para descobrir se existe uma associação entre \na variável de linha e coluna variável em uma tabela de contingência construído à partir dos dados.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Extraçao de variáveis\ntestagem = SelectKBest(score_func=chi2,k=7)\nfit = testagem.fit(rescaledx,Y)\n\n#Sumarização do score\nscore = fit.scores_\ncolunas = df_X.columns\n\nnew_df = pd.DataFrame()\nnew_df[\"Colunas\"] = colunas\nnew_df[\"Score chi2\"] = score\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"3.2\"></a> <br>\n# <div class=\"alert alert-warning\">3.2 - Eliminação Recursiva de Atributos</div>\n\n**Esta é outra técnica para seleção de atributos, que recursivamente remove os atributos\ne constroí o modelo com os atributos remanescentes.\nEsta técnica utiliza a acurácia do modelo para identificar os atributos que mais\ncontribuem para prever a variável alvo.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Criando o modelo\nmodelo = LogisticRegression(max_iter=1000)\n\n#Recursive Feature Elimination (RFE)\nrfe = RFE(modelo, n_features_to_select=1)\nfit = rfe.fit(rescaledx,Y)\n\n#Resultados\nnew_df[\"ranking RFE\"] = fit.ranking_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"3.3\"></a> <br>\n# <div class=\"alert alert-warning\">3.3 - Método Enseable para seleção de variáveis</div>\n\n**Bagged Decision Trees, como o algoritmo Random Forest, podem ser usados para estimar\na importância de cada atributo.\nEsse método retorna um score para cada atributo, quanto maior, maior a importância de\ncada atributo**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Criando o modelo\nmodelo = ExtraTreesClassifier()\nmodelo.fit(rescaledx,Y)\n\nnew_df[\"Enseable\"] = modelo.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Melhores variáveis \nprint(new_df)\n\n\n#Variáveis qui-quadrado(Chi2)\ncolunas_chi2 = [\"exang\",\"cp\",\"ca\",\"oldpeak\",\"sex\",\"slope\",\"thal\"]\n\n#Variáveis RFE\ncolunas_rfe = [\"oldpeak\",\"thalach\",\"ca\",\"thal\",\"cp\",\"slope\",\"sex\"]\n\n#Variáveis Enseable\ncolunas_enseable = [\"ca\",\"cp\",\"exang\",\"thal\",\"thalach\",\"oldpeak\",\"age\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3 style=\"text-align:center;font-size:200%;;\">Conclusão do projeto</h3>\n<div class=\"progress\">\n  <div class=\"progress-bar\" role=\"progressbar\" style=\"width: 35%;\" aria-valuenow=\"25\" aria-valuemin=\"0\" aria-valuemax=\"100\">35% Concluído</div>\n</div>"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4\"></a> <br>\n# <div class=\"alert alert-block alert-info\">4 - Divisão dos dados</div>\n\n**Foi utilizado a função train_test_split() para dividir os dados de treino e de teste.\nFoi realizado um split de 75% para dados de treino e 25% para dados de teste.**\n\n**Por fim utilizamos o Cross Validation sobre os dados de treino em cada modelo.**\n\n**Cross validation é uma técnica que pode ser utilizada para avaliar a performance de um modelo\ncom menos vaariância que a técnica de dividir os dados de treino/teste.**\n\n\n**Com está técnica dividmos os dados em partes normalmente chamadas em k-folds.\nEle executa cada fold por vez até k-1 fold, por fim, podemos sumarizar a performance\nde cada fold usando a média e o desvio padrão**\n\n<h1 style=\"text-align:center\">\n<img src=\"https://miro.medium.com/max/500/1*0_jdEVi6l1Nj-DKK8wJTTQ.png\">"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"5\"></a> <br>\n# <div class=\"alert alert-block alert-info\">5 - Avaliando a Performance </div>\n\n\n**As métricas que são escolhidas para avaliar a performance do modelo vão influenciar\na forma como a performance é medida e comparada com modelos criados com outros algoritmos.**"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"5.1\"></a> <br>\n# <div class=\"alert alert-warning\">5.1 - Curva ROC</div>\n\n**A curva ROC permite analisar a métrica AUC (Area Unde the Curve).**\n\n**A curva ROC mostra o quão bom o modelo criado pode distinguir entre duas coisas (já que é utilizado para classificação). \nEssas duas coisas podem ser 0 ou 1, ou positivo e negativo. Os melhores modelos conseguem distinguir com precisão o binômio.**\n\n**O valor do AUC varia de 0,0 até 1,0 e o limiar entre a classe é 0,5. Ou seja, acima desse limite, o algoritmo classifica em uma classe e abaixo na outra classe.\nQuanto maior o AUC, melhor.**\n\n<h1 style=\"text-align:center\">\n<img src=\"https://miro.medium.com/max/2400/1*RqK5DjVxcj4qZsCdN4FOSQ.png\">"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"5.2\"></a> <br>\n# <div class=\"alert alert-warning\">5.2 - Acurácia</div>\n\n\n**Esta é a métrica mais simples. É basicamente o número de acertos (positivos) divido pelo número total de exemplos. Ela deve ser usada em datasets com a mesma proporção de exemplos para cada classe, e quando as penalidades de acerto e erro para cada classe forem as mesmas.**\n\n**Em problemas com classes desproporcionais, ela causa uma falsa impressão de bom desempenho. Por exemplo, num dataset em que 80% dos exemplos pertençam a uma classe, só de classificar todos os exemplos naquela classe já se atinge uma precisão de 80%, mesmo que todos os exemplos da outra classe estejam classificados incorretamente.**"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"5.3\"></a> <br>\n# <div class=\"alert alert-warning\">5.3 - Precisão</div>\n\n**A precisão pode ser usada em uma situação em que os Falsos Positivos são considerados mais prejudiciais que os Falsos Negativos. Por exemplo, ao classificar uma ação como um bom investimento, é necessário que o modelo esteja correto, mesmo que acabe classificando bons investimentos como maus investimentos (situação de Falso Negativo) no processo.**\n\n**Ou seja, o modelo deve ser preciso em suas classificações, pois a partir do momento que consideramos um investimento bom quando na verdade ele não é, uma grande perda de dinheiro pode acontecer.**"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"5.4\"></a> <br>\n# <div class=\"alert alert-warning\">5.4 - Recall</div>\n\n**O recall pode ser usada em uma situação em que os Falsos Negativos são considerados mais prejudiciais que os Falsos Positivos.**\n\n**Por exemplo, o modelo deve de qualquer maneira encontrar todos os pacientes doentes, mesmo que classifique alguns saudáveis como doentes (situação de Falso Positivo) no processo. Ou seja, o modelo deve ter alto recall, pois classificar pacientes doentes como saudáveis pode ser uma tragédia.**"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6\"></a> <br>\n# <div class=\"alert alert-block alert-info\">6 - Modelos de Machine Learning</div>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#DataFrame para verificaçao de todos os modelos\n\ndf_modelos = pd.DataFrame(columns=[\"Modelo\",\"Categoria\",\"Tempo (s)\",\"Train AUC ROC\",\"Train ACURÁCIA\",\"Train PRECISÃO\",\"Train RECALL\",\n                                             \"Test AUC ROC\",\"Test ACURÁCIA\",\"Test PRECISÃO\",\"Test RECALL\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6.1\"></a> <br>\n# <div class=\"alert alert-warning\">6.1 - Logistic Regression</div>\n\n**A Regressão Logística é uma análise que nos permite estimar a probabilidade associada à ocorrência de determinado evento em face de um conjunto de variáveis explanatórias.**\n\n**As vantagens desse tipo de regressão incluem:**\n- Facilidade para lidar com variáveis independentes categóricas;\n- Fornece resultados em termos de probabilidade;\n- Facilidade de classificação de indivíduos em categorias;\n- Requer pequeno número de suposições;\n- Possui alto grau de confiabilidade.\n\n<h1 style=\"text-align:center\">\n<img src=\"https://static.javatpoint.com/tutorial/machine-learning/images/logistic-regression-in-machine-learning.png\" style=\"width:900px;height:400px;\">"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6.2\"></a> <br>\n# <div class=\"alert alert-warning\">6.2 - Linear Discriminant Analysis</div>\n\n**O objetivo da análise discriminante é desenvolver funções discriminantes que nada mais são do que a combinação linear de variáveis ​​independentes que discriminarão entre as categorias da variável dependente de maneira perfeita.**\n\n**Deseja-se que as amostras tenham a maior distância entre classes e a menor distância dentro da classe, ou seja, maximização da separação entre duas ou mais classes**"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6.3\"></a> <br>\n# <div class=\"alert alert-warning\">6.3 - Gaussian NB</div>\n\n**O algoritmo Naïve Bayes é um algoritmo de aprendizagem supervisionada, baseado no teorema de Bayes e utilizado para resolver problemas de classificação.**\n\n**O Naïve Bayes Classifier é um dos algoritmos de classificação mais simples e eficazes que ajuda na construção de modelos de aprendizado de máquina rápidos que podem fazer previsões rápidas.**\n\n**É um classificador probabilístico, o que significa que prevê com base na probabilidade de um objeto .**"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6.4\"></a> <br>\n# <div class=\"alert alert-warning\">6.4 - KNeighbors Classifier</div>\n\n**Em estatística , o algoritmo k-nearest neighbors ( k-NN ) é um método não paramétrico proposto por Thomas Cover usado para classificação e regressão .**\n\n**k-NN é um tipo de aprendizagem baseada em instância , ou aprendizagem preguiçosa , onde a função é aproximada apenas localmente e todos os cálculos são adiados até a avaliação da função. Como esse algoritmo depende da distância para classificação, normalizar os dados de treinamento pode melhorar drasticamente sua precisão.**\n\n**Tanto para classificação quanto para regressão, uma técnica útil pode ser atribuir pesos às contribuições dos vizinhos, de modo que os vizinhos mais próximos contribuam mais para a média do que os mais distantes.**\n\n<h1 style=\"text-align:center\">\n<img src=\"https://static.javatpoint.com/tutorial/machine-learning/images/k-nearest-neighbor-algorithm-for-machine-learning2.png\" style=\"width:900px;height:400px;\">"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6.5\"></a> <br>\n# <div class=\"alert alert-warning\">6.5 - Decision Tree Classifier</div>\n\n\n**Uma árvore de decisão\ntoma como entrada um objeto ou situação descrito por um\nconjunto de atributos e retorna uma decisão - o valor de\nsaída previsto, de acordo com a entrada**\n\n**A árvore de classificação é o resultado de se fazer uma\nsequência ordenada de perguntas, e as perguntas feitas a cada\npasso na sequência dependem das respostas às perguntas\nanteriores. A sequência termina em uma previsão da classe.**\n\n<h1 style=\"text-align:center\">\n<img src=\"https://i.ytimg.com/vi/CcQMS_eaBWE/maxresdefault.jpg\" style=\"width:600px;height:250px;\">"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6.6\"></a> <br>\n# <div class=\"alert alert-warning\">6.6 - Suport Vector Machine</div>\n\n\n**As Máquinas de Vetor Suporte destacam-se pela forte fundamentação teórica\nexistente, possuindo como base a teoria da aprendizagem estatística, sendo esta característica\num diferencial sobre outras técnicas como redes neurais, que não possui um modelo teórico.**\n\n**A capacidade em trabalhar com padrões de alta dimensionalidade é outra\ncaracteréstica interessante desta técnica, sendo ideal para aplicação em problemas de visão\ncomputacional, como reconhecimento de padrões e filtragem**\n"},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"#Seleceçao de modelos\n\ndef selecao_modelos(df,colunas,previsao,df_modelo,variavel):\n    \n    df_X = df[colunas]\n    df_Y = df[previsao]\n    \n    #Realizando o split sobre os dados\n    variaveis = variavel\n    seed = 7   \n    X_train, X_test, y_train, y_test = train_test_split(df_X, df_Y, test_size = 0.25,random_state=seed)  \n    \n   \n    #Separando o array em componentes X e Y\n    X = X_train\n    Y = y_train\n    \n    #Normalização\n    scaler = MinMaxScaler(feature_range=(0,1))\n    rescaledx = scaler.fit_transform(X)\n    \n    #Definindo os valores para o número de folds\n    num_folds = 5\n    num_instances = len(rescaledx)\n    \n    \n    #Preparando o modelo\n    modelos = []\n    modelos.append((\"LR\",LogisticRegression(max_iter=400)))\n    modelos.append((\"LDA\",LinearDiscriminantAnalysis()))\n    modelos.append((\"NB\",GaussianNB()))\n    modelos.append((\"KNN\",KNeighborsClassifier()))\n    modelos.append((\"CART\",DecisionTreeClassifier()))\n    modelos.append((\"SVM\",SVC()))\n       \n    for nome,modelo in modelos:\n        \n        kfold = StratifiedKFold(n_splits = num_folds,random_state=seed,shuffle = True)\n        \n        inicio =time.time()\n        cv_roc = cross_val_score(modelo,rescaledx,Y,cv = kfold,scoring=\"roc_auc\")\n        cv_acc = cross_val_score(modelo,rescaledx,Y,cv = kfold,scoring=\"accuracy\")\n        cv_prec = cross_val_score(modelo,rescaledx,Y,cv = kfold,scoring=\"precision\")\n        cv_recall = cross_val_score(modelo,rescaledx,Y,cv = kfold,scoring=\"recall\")\n        \n        \n        modelo_test = modelo.fit(rescaledx,Y)\n        \n        #Normalização\n        \n        scaler = MinMaxScaler(feature_range=(0,1))\n        rescaledx_test = scaler.fit_transform(X_test)\n        \n        y_pred = modelo_test.predict(rescaledx_test)\n\n        cv_acc_test = accuracy_score(y_test,y_pred)\n        cv_roc_test = roc_auc_score(y_test,y_pred)\n        cv_prec_test = precision_score(y_test,y_pred)\n        cv_recall_test = recall_score(y_test,y_pred)\n        \n        fim = time.time()\n\n        \n                \n        msg = \"Modelo: %s, AUC ROC: %.2f%% (%.2f%%) Acurácia: %.2f%% (%.2f%%) Precisão: %.2f%% (%.2f%%) Recall: %.2f%% (%.2f%%) \" %(nome,cv_roc.mean()*100,cv_roc.std()*100,\n                                                                          cv_acc.mean()*100,cv_acc.std()*100,\n                                                                          cv_prec.mean()*100,cv_prec.std()*100,\n                                                                          cv_recall.mean()*100,cv_recall.std()*100)\n        tempo = fim - inicio\n        print(msg)\n        df_modelo.loc[len(df_modelo)+1] = [nome,variaveis,tempo,cv_roc.mean()*100,cv_acc.mean()*100,cv_prec.mean()*100,cv_recall.mean()*100,\n                                                cv_acc_test.mean()*100,cv_roc_test.mean()*100,cv_prec_test.mean()*100,cv_recall_test.mean()*100]\n       \n              \n        \nprint(\"Modelo CHI2\")\nselecao_modelos(df,colunas_chi2,\"target\",df_modelo = df_modelos,variavel=\"CHI2\")\n\nprint(\"\\n\")\nprint(\"Modelo RFE\")\nselecao_modelos(df,colunas_rfe,\"target\",df_modelo = df_modelos,variavel=\"RFE\")\n\nprint(\"\\n\")\nprint(\"Modelo ENSEABLE\")\nselecao_modelos(df,colunas_enseable,\"target\",df_modelo = df_modelos,variavel=\"ENSEABLE\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3 style=\"text-align:center;font-size:200%;;\">Conclusão do projeto</h3>\n<div class=\"progress\">\n  <div class=\"progress-bar\" role=\"progressbar\" style=\"width: 75%;\" aria-valuenow=\"25\" aria-valuemin=\"0\" aria-valuemax=\"100\">75% Concluído</div>\n</div>"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"7\"></a> <br>\n# <div class=\"alert alert-block alert-info\">7 - Otimização de Performance com Métodos Ensemble</div>\n\n**Métodos Ensemble permitem aumentar consideralvemente o nível de precisão nas suas previsões. Foi criado métodos Ensemble mais poderosos:**\n\n**Bagging: Para consutrução de múltiplos modelos a partir de diferentes subset no dataset de treino**\n\n**Boosting: Para construção de múltiplos modelos, onde cada modelo aprende a corrigir os erros gerados pelo modelo anterior.**\n\n**Voting: Para construção de múltiplos modelos (normalmente de tipos diferentes) e estatística simples são usadas para combinar as previsões.**"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"7.1\"></a> <br>\n# <div class=\"alert alert-warning\">7.1 - Bagged Decision Trees</div>\n\n**Este método funciona bem quando existe alta variância nos dados**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Bagged Decision Trees\n\n\ndef selecao_modelos(df,colunas,previsao,df_modelo,variavel):\n    df_X = df[colunas]\n    df_Y = df[previsao]\n    \n    #Realizando o split sobre os dados\n    variaveis = variavel\n    seed = 7   \n    X_train, X_test, y_train, y_test = train_test_split(df_X, df_Y, test_size = 0.25,random_state=seed)  \n    \n   \n    #Separando o array em componentes X e Y\n    X = X_train\n    Y = y_train\n    \n    #Normalização\n    scaler = MinMaxScaler(feature_range=(0,1))\n    rescaledx = scaler.fit_transform(X)\n    \n    #Definindo os valores para o número de folds\n    num_folds = 5\n    num_instances = len(rescaledx)\n    \n    #Preparando o modelo\n    modelos = []\n    modelos.append((\"BDT LR\",LogisticRegression(max_iter=400)))\n    modelos.append((\"BDT LDA\",LinearDiscriminantAnalysis()))\n    modelos.append((\"BDT NB\",GaussianNB()))\n    modelos.append((\"BDT KNN\",KNeighborsClassifier()))\n    modelos.append((\"BDT CART\",DecisionTreeClassifier()))\n    modelos.append((\"BDT SVM\",SVC()))\n    \n    \n    for nome,modelo in modelos:\n        kfold = StratifiedKFold(n_splits = num_folds,random_state=seed,shuffle = True)\n        \n        inicio =time.time()\n        modelo_bagging = BaggingClassifier(base_estimator=modelo,\n                                          n_estimators = 100,random_state = seed)\n\n        cv_roc = cross_val_score(modelo_bagging,rescaledx,Y,cv = kfold,scoring=\"roc_auc\")\n        cv_acc = cross_val_score(modelo_bagging,rescaledx,Y,cv = kfold,scoring=\"accuracy\")\n        cv_prec = cross_val_score(modelo_bagging,rescaledx,Y,cv = kfold,scoring=\"precision\")\n        cv_recall = cross_val_score(modelo_bagging,rescaledx,Y,cv = kfold,scoring=\"recall\")\n\n        \n        \n        modelo_test = modelo_bagging.fit(rescaledx,Y)\n        \n        #Normalização\n        \n        scaler = MinMaxScaler(feature_range=(0,1))\n        rescaledx_test = scaler.fit_transform(X_test)\n        \n        y_pred = modelo_test.predict(rescaledx_test)\n\n        cv_acc_test = accuracy_score(y_test,y_pred)\n        cv_roc_test = roc_auc_score(y_test,y_pred)\n        cv_prec_test = precision_score(y_test,y_pred)\n        cv_recall_test = recall_score(y_test,y_pred)\n\n        \n        fim = time.time()\n        \n                \n        msg = \"Modelo: %s, AUC ROC: %.2f%% (%.2f%%) Acurácia: %.2f%% (%.2f%%) Precisão: %.2f%% (%.2f%%) Recall: %.2f%% (%.2f%%) \" %(nome,cv_roc.mean()*100,cv_roc.std()*100,\n                                                                          cv_acc.mean()*100,cv_acc.std()*100,\n                                                                          cv_prec.mean()*100,cv_prec.std()*100,\n                                                                          cv_recall.mean()*100,cv_recall.std()*100)\n        tempo = fim - inicio\n        print(msg)\n        df_modelo.loc[len(df_modelo)+1] = [nome,variaveis,tempo,cv_roc.mean()*100,cv_acc.mean()*100,cv_prec.mean()*100,cv_recall.mean()*100,\n                                                cv_acc_test.mean()*100,cv_roc_test.mean()*100,cv_prec_test.mean()*100,cv_recall_test.mean()*100]\n\nprint(\"Modelo CHI2\")\nselecao_modelos(df,colunas_chi2,\"target\",df_modelo = df_modelos,variavel=\"CHI2\")\nprint(\"\\n\")\nprint(\"Modelo RFE\")\nselecao_modelos(df,colunas_rfe,\"target\",df_modelo = df_modelos,variavel=\"RFE\")\nprint(\"\\n\")\nprint(\"Modelo ENSEABLE\")\nselecao_modelos(df,colunas_enseable,\"target\",df_modelo = df_modelos,variavel=\"ENSEABLE\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"7.2\"></a> <br>\n# <div class=\"alert alert-warning\">7.2 - Random Forest</div>\n\n**Random Forest é uma extensão do Bagging Decision Tree. Amostras do dataset de treino são usadas com reposição, mas as árvoes são criadas de uma forma que reduz a correlação entre classificadores individuais.**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Random Forest\n\n\ndef selecao_modelos(df,colunas,previsao,df_modelo,variavel):\n    df_X = df[colunas]\n    df_Y = df[previsao]\n    \n    #Realizando o split sobre os dados\n    variaveis = variavel\n    seed = 7   \n    X_train, X_test, y_train, y_test = train_test_split(df_X, df_Y, test_size = 0.25,random_state=seed)  \n    \n   \n    #Separando o array em componentes X e Y\n    X = X_train\n    Y = y_train\n    \n    #Normalização\n    scaler = MinMaxScaler(feature_range=(0,1))\n    rescaledx = scaler.fit_transform(X)\n    \n    #Definindo os valores para o número de folds\n    num_folds = 5\n    num_instances = len(rescaledx)\n    \n    nome = \"Random Forest\"\n    \n    kfold = StratifiedKFold(n_splits = num_folds,random_state=seed,shuffle = True)\n    inicio =time.time()\n        \n    modelo= RandomForestClassifier(n_estimators = 100,max_features = 3)\n        \n    cv_roc = cross_val_score(modelo,rescaledx,Y,cv = kfold,scoring=\"roc_auc\")\n    cv_acc = cross_val_score(modelo,rescaledx,Y,cv = kfold,scoring=\"accuracy\")\n    cv_prec = cross_val_score(modelo,rescaledx,Y,cv = kfold,scoring=\"precision\")\n    cv_recall = cross_val_score(modelo,rescaledx,Y,cv = kfold,scoring=\"recall\")\n\n        \n    \n    modelo_test = modelo.fit(rescaledx,Y)\n    \n    #Normalização\n        \n    scaler = MinMaxScaler(feature_range=(0,1))\n    rescaledx_test = scaler.fit_transform(X_test)\n        \n    y_pred = modelo_test.predict(rescaledx_test)\n\n    cv_acc_test = accuracy_score(y_test,y_pred)\n    cv_roc_test = roc_auc_score(y_test,y_pred)\n    cv_prec_test = precision_score(y_test,y_pred)\n    cv_recall_test = recall_score(y_test,y_pred)\n\n    fim = time.time()    \n                \n    msg = \"Modelo: %s, AUC ROC: %.2f%% (%.2f%%) Acurácia: %.2f%% (%.2f%%) Precisão: %.2f%% (%.2f%%) Recall: %.2f%% (%.2f%%) \" %(nome,cv_roc.mean()*100,cv_roc.std()*100,\n                                                                          cv_acc.mean()*100,cv_acc.std()*100,\n                                                                          cv_prec.mean()*100,cv_prec.std()*100,\n                                                                          cv_recall.mean()*100,cv_recall.std()*100)\n    tempo = fim - inicio\n    print(msg)\n    df_modelo.loc[len(df_modelo)+1] = [nome,variaveis,tempo,cv_roc.mean()*100,cv_acc.mean()*100,cv_prec.mean()*100,cv_recall.mean()*100,\n                                                cv_acc_test.mean()*100,cv_roc_test.mean()*100,cv_prec_test.mean()*100,cv_recall_test.mean()*100]\n\nprint(\"Modelo CHI2\")\nselecao_modelos(df,colunas_chi2,\"target\",df_modelo = df_modelos,variavel=\"CHI2\")\nprint(\"\\n\")\nprint(\"Modelo RFE\")\nselecao_modelos(df,colunas_rfe,\"target\",df_modelo = df_modelos,variavel=\"RFE\")\nprint(\"\\n\")\nprint(\"Modelo ENSEABLE\")\nselecao_modelos(df,colunas_enseable,\"target\",df_modelo = df_modelos,variavel=\"ENSEABLE\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"7.3\"></a> <br>\n# <div class=\"alert alert-warning\">7.3 - AdaBoost</div>\n\n**Algoritmo baseado em Boosting Ensemble criam uma sequência de modelos que tentam corrigir os erros dos modelos anteriores dentro da sequência. Uma vez criados, os modelos fazem previsões que podem receber um peso de acordo com sua acurácia e os resultados são combinados para criar uma previsão única final.**\n\n**O AdaBoost atribui pesos às instâncias no dataset, definindo quão fácil ou difícil elas são para o precesso de classificação, permitindo que o algoritmo tenham mais ou menos atenção às instâncias durante o processo de construção dos modelos.**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# AdaBoost\n\ndef selecao_modelos(df,colunas,previsao,df_modelo,variavel):\n    df_X = df[colunas]\n    df_Y = df[previsao]\n    \n    #Realizando o split sobre os dados\n    variaveis = variavel\n    seed = 7   \n    X_train, X_test, y_train, y_test = train_test_split(df_X, df_Y, test_size = 0.25,random_state=seed)  \n    \n   \n    #Separando o array em componentes X e Y\n    X = X_train\n    Y = y_train\n    \n    #Normalização\n    scaler = MinMaxScaler(feature_range=(0,1))\n    rescaledx = scaler.fit_transform(X)\n    \n    #Definindo os valores para o número de folds\n    num_folds = 5\n    num_instances = len(rescaledx)\n    \n    nome = \"AdaBoost\"\n\n    kfold = StratifiedKFold(n_splits = num_folds,random_state=seed,shuffle = True)\n    inicio =time.time()\n        \n    modelo= AdaBoostClassifier(n_estimators = 30,random_state=seed)\n    \n    cv_roc = cross_val_score(modelo,rescaledx,Y,cv = kfold,scoring=\"roc_auc\")\n    cv_acc = cross_val_score(modelo,rescaledx,Y,cv = kfold,scoring=\"accuracy\")\n    cv_prec = cross_val_score(modelo,rescaledx,Y,cv = kfold,scoring=\"precision\")\n    cv_recall = cross_val_score(modelo,rescaledx,Y,cv = kfold,scoring=\"recall\")\n\n        \n    \n    modelo_test = modelo.fit(rescaledx,Y)\n    #Normalização\n        \n    scaler = MinMaxScaler(feature_range=(0,1))\n    rescaledx_test = scaler.fit_transform(X_test)\n        \n    y_pred = modelo_test.predict(rescaledx_test)\n\n    cv_acc_test = accuracy_score(y_test,y_pred)\n    cv_roc_test = roc_auc_score(y_test,y_pred)\n    cv_prec_test = precision_score(y_test,y_pred)\n    cv_recall_test = recall_score(y_test,y_pred)\n\n        \n    fim = time.time()\n    \n    msg = \"Modelo: %s, AUC ROC: %.2f%% (%.2f%%) Acurácia: %.2f%% (%.2f%%) Precisão: %.2f%% (%.2f%%) Recall: %.2f%% (%.2f%%) \" %(nome,cv_roc.mean()*100,cv_roc.std()*100,\n                                                                          cv_acc.mean()*100,cv_acc.std()*100,\n                                                                          cv_prec.mean()*100,cv_prec.std()*100,\n                                                                          cv_recall.mean()*100,cv_recall.std()*100)\n    tempo = fim - inicio\n    print(msg)\n    df_modelo.loc[len(df_modelo)+1] = [nome,variaveis,tempo,cv_roc.mean()*100,cv_acc.mean()*100,cv_prec.mean()*100,cv_recall.mean()*100,\n                                                cv_acc_test.mean()*100,cv_roc_test.mean()*100,cv_prec_test.mean()*100,cv_recall_test.mean()*100]\n\nprint(\"Modelo CHI2\")\nselecao_modelos(df,colunas_chi2,\"target\",df_modelo = df_modelos,variavel=\"CHI2\")\nprint(\"\\n\")\nprint(\"Modelo RFE\")\nselecao_modelos(df,colunas_rfe,\"target\",df_modelo = df_modelos,variavel=\"RFE\")\nprint(\"\\n\")\nprint(\"Modelo ENSEABLE\")\nselecao_modelos(df,colunas_enseable,\"target\",df_modelo = df_modelos,variavel=\"ENSEABLE\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"7.4\"></a> <br>\n# <div class=\"alert alert-warning\">7.4 - Gradiente Boosting</div>\n\n**Também chamado de Stochastic Gradient Boosting, é um dos métodos Ensemble mais sofisticados**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Gradiente Boosting\n\n\ndef selecao_modelos(df,colunas,previsao,df_modelo,variavel):\n    df_X = df[colunas]\n    df_Y = df[previsao]\n    \n    #Realizando o split sobre os dados\n\n    variaveis = variavel\n    seed = 7   \n    X_train, X_test, y_train, y_test = train_test_split(df_X, df_Y, test_size = 0.25,random_state=seed)  \n    \n   \n    #Separando o array em componentes X e Y\n    X = X_train\n    Y = y_train\n    \n    #Normalização\n    scaler = MinMaxScaler(feature_range=(0,1))\n    rescaledx = scaler.fit_transform(X)\n    \n    #Definindo os valores para o número de folds\n    num_folds = 5\n    num_instances = len(rescaledx)\n    \n    nome = \"Gradiente Boosting\"\n\n    kfold = StratifiedKFold(n_splits = num_folds,random_state=seed,shuffle = True)\n    inicio =time.time()\n        \n    modelo= GradientBoostingClassifier(n_estimators = 30,random_state=seed)\n\n    cv_roc = cross_val_score(modelo,rescaledx,Y,cv = kfold,scoring=\"roc_auc\")\n    cv_acc = cross_val_score(modelo,rescaledx,Y,cv = kfold,scoring=\"accuracy\")\n    cv_prec = cross_val_score(modelo,rescaledx,Y,cv = kfold,scoring=\"precision\")\n    cv_recall = cross_val_score(modelo,rescaledx,Y,cv = kfold,scoring=\"recall\")\n\n        \n    \n    modelo_test = modelo.fit(rescaledx,Y)\n    \n    #Normalização\n        \n    scaler = MinMaxScaler(feature_range=(0,1))\n    rescaledx_test = scaler.fit_transform(X_test)\n        \n    y_pred = modelo_test.predict(rescaledx_test)\n\n    cv_acc_test = accuracy_score(y_test,y_pred)\n    cv_roc_test = roc_auc_score(y_test,y_pred)\n    cv_prec_test = precision_score(y_test,y_pred)\n    cv_recall_test = recall_score(y_test,y_pred)\n\n    fim = time.time()\n                \n    msg = \"Modelo: %s, AUC ROC: %.2f%% (%.2f%%) Acurácia: %.2f%% (%.2f%%) Precisão: %.2f%% (%.2f%%) Recall: %.2f%% (%.2f%%) \" %(nome,cv_roc.mean()*100,cv_roc.std()*100,\n                                                                          cv_acc.mean()*100,cv_acc.std()*100,\n                                                                          cv_prec.mean()*100,cv_prec.std()*100,\n                                                                          cv_recall.mean()*100,cv_recall.std()*100)\n    tempo = fim - inicio\n    print(msg)\n    df_modelo.loc[len(df_modelo)+1] = [nome,variaveis,tempo,cv_roc.mean()*100,cv_acc.mean()*100,cv_prec.mean()*100,cv_recall.mean()*100,\n                                                cv_acc_test.mean()*100,cv_roc_test.mean()*100,cv_prec_test.mean()*100,cv_recall_test.mean()*100]\n\nprint(\"Modelo CHI2\")\nselecao_modelos(df,colunas_chi2,\"target\",df_modelo = df_modelos,variavel=\"CHI2\")\nprint(\"\\n\")\nprint(\"Modelo RFE\")\nselecao_modelos(df,colunas_rfe,\"target\",df_modelo = df_modelos,variavel=\"RFE\")\nprint(\"\\n\")\nprint(\"Modelo ENSEABLE\")\nselecao_modelos(df,colunas_enseable,\"target\",df_modelo = df_modelos,variavel=\"ENSEABLE\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"7.5\"></a> <br>\n# <div class=\"alert alert-warning\">7.5 - Voting Ensenble</div>\n\n**Este é um dos métodos Ensemble mais simples. Este método cria dois ou mais modelos separados a partir do dataset de treino. O classificados Voting então utiliza a média das previsões em novos conjuntos de dados.**\n\n**As previsões de cada sub-modelo podem receber pesos, atráves de heurística.**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#Voting Ensenble\n\n\ndef selecao_modelos(df,colunas,previsao,df_modelo,variavel):\n    df_X = df[colunas]\n    df_Y = df[previsao]\n    \n    #Realizando o split sobre os dados\n    variaveis = variavel\n    seed = 7   \n    X_train, X_test, y_train, y_test = train_test_split(df_X, df_Y, test_size = 0.25,random_state=seed)  \n    \n   \n    #Separando o array em componentes X e Y\n    X = X_train\n    Y = y_train\n    \n    #Normalização\n    scaler = MinMaxScaler(feature_range=(0,1))\n    rescaledx = scaler.fit_transform(X)\n    \n    #Definindo os valores para o número de folds\n    num_folds = 5\n    num_instances = len(rescaledx)\n    \n    #Preparando o modelo\n    modelos = []\n    modelos.append((\"LR\",LogisticRegression(max_iter=400)))\n    modelos.append((\"LDA\",LinearDiscriminantAnalysis()))\n    modelos.append((\"NB\",GaussianNB()))\n    modelos.append((\"KNN\",KNeighborsClassifier()))\n    modelos.append((\"CART\",DecisionTreeClassifier()))\n    modelos.append((\"SVN\",SVC()))\n    \n    #Criando o modelo ensemble\n    inicio =time.time()\n    ensemble = VotingClassifier(modelos)\n    kfold = StratifiedKFold(n_splits = num_folds,random_state=seed,shuffle = True)\n    \n    cv_acc = cross_val_score(modelo,rescaledx,Y,cv = kfold,scoring=\"accuracy\")\n    cv_prec = cross_val_score(modelo,rescaledx,Y,cv = kfold,scoring=\"precision\")\n    cv_recall = cross_val_score(modelo,rescaledx,Y,cv = kfold,scoring=\"recall\")\n\n        \n    \n    modelo_test = modelo.fit(rescaledx,Y)\n    #Normalização\n        \n    scaler = MinMaxScaler(feature_range=(0,1))\n    rescaledx_test = scaler.fit_transform(X_test)\n        \n    y_pred = modelo_test.predict(rescaledx_test)\n\n    cv_acc_test = accuracy_score(y_test,y_pred)\n    cv_prec_test = precision_score(y_test,y_pred)\n    cv_recall_test = recall_score(y_test,y_pred)\n\n    \n    nome = \"Voting Ensenble\"\n    fim = time.time()\n                \n    msg = \"Modelo: %s, Acurácia: %.2f%% (%.2f%%) Precisão: %.2f%% (%.2f%%) Recall: %.2f%% (%.2f%%) \" %(nome,\n                                                                          cv_acc.mean()*100,cv_acc.std()*100,\n                                                                          cv_prec.mean()*100,cv_prec.std()*100,\n                                                                          cv_recall.mean()*100,cv_recall.std()*100)\n    tempo = fim - inicio\n    print(msg)\n    df_modelo.loc[len(df_modelo)+1] = [nome,variaveis,tempo,None,cv_acc.mean()*100,cv_prec.mean()*100,cv_recall.mean()*100,\n                                                None,cv_acc_test.mean()*100,cv_prec_test.mean()*100,cv_recall_test.mean()*100]\n\nprint(\"Modelo CHI2\")\nselecao_modelos(df,colunas_chi2,\"target\",df_modelo = df_modelos,variavel=\"CHI2\")\nprint(\"\\n\")\nprint(\"Modelo RFE\")\nselecao_modelos(df,colunas_rfe,\"target\",df_modelo = df_modelos,variavel=\"RFE\")\nprint(\"\\n\")\nprint(\"Modelo ENSEABLE\")\nselecao_modelos(df,colunas_enseable,\"target\",df_modelo = df_modelos,variavel=\"ENSEABLE\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"7.6\"></a> <br>\n# <div class=\"alert alert-warning\">7.6 - XGBoost </div>\n\n**O algoritmo XGBoost é uma extensão do GBM (Gradient Boosting Method) que permite trabalhar com multi threading em uma única máquina e precessamento paralelo em um cluster de vários servidores.**\n\n**A principal vantagem do XGBoost sobre GBM é sua capacidade de gerenciar dados esparsos**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#XGBoost - Extreme Gradient Boosting\n\ndef selecao_modelos(df,colunas,previsao,df_modelo,variavel):\n    df_X = df[colunas]\n    df_Y = df[previsao]\n    \n    #Realizando o split sobre os dados\n    variaveis = variavel\n    seed = 7   \n    X_train, X_test, y_train, y_test = train_test_split(df_X, df_Y, test_size = 0.25,random_state=seed)  \n    \n   \n    #Separando o array em componentes X e Y\n    X = X_train\n    Y = y_train\n    \n    #Normalização\n    scaler = MinMaxScaler(feature_range=(0,1))\n    rescaledx = scaler.fit_transform(X)\n    \n    #Definindo os valores para o número de folds\n    num_folds = 5\n    num_instances = len(rescaledx)\n    \n    \n    #Criando o modelo\n    nome = \"XGBoost\"\n    inicio =time.time()\n    modelo = XGBClassifier()\n    kfold = StratifiedKFold(n_splits = num_folds,random_state=seed,shuffle = True)\n\n    cv_roc = cross_val_score(modelo,rescaledx,Y,cv = kfold,scoring=\"roc_auc\")\n    cv_acc = cross_val_score(modelo,rescaledx,Y,cv = kfold,scoring=\"accuracy\")\n    cv_prec = cross_val_score(modelo,rescaledx,Y,cv = kfold,scoring=\"precision\")\n    cv_recall = cross_val_score(modelo,rescaledx,Y,cv = kfold,scoring=\"recall\")\n\n        \n    \n    modelo_test = modelo.fit(rescaledx,Y)\n    #Normalização\n        \n    scaler = MinMaxScaler(feature_range=(0,1))\n    rescaledx_test = scaler.fit_transform(X_test)\n        \n    y_pred = modelo_test.predict(rescaledx_test)\n\n    cv_acc_test = accuracy_score(y_test,y_pred)\n    cv_roc_test = roc_auc_score(y_test,y_pred)\n    cv_prec_test = precision_score(y_test,y_pred)\n    cv_recall_test = recall_score(y_test,y_pred)\n\n    fim = time.time()\n                \n    msg = \"Modelo: %s, AUC ROC: %.2f%% (%.2f%%) Acurácia: %.2f%% (%.2f%%) Precisão: %.2f%% (%.2f%%) Recall: %.2f%% (%.2f%%) \" %(nome,cv_roc.mean()*100,cv_roc.std()*100,\n                                                                          cv_acc.mean()*100,cv_acc.std()*100,\n                                                                          cv_prec.mean()*100,cv_prec.std()*100,\n                                                                          cv_recall.mean()*100,cv_recall.std()*100)\n    tempo = fim - inicio\n    print(msg)\n    df_modelo.loc[len(df_modelo)+1] = [nome,variaveis,tempo,cv_roc.mean()*100,cv_acc.mean()*100,cv_prec.mean()*100,cv_recall.mean()*100,\n                                                cv_acc_test.mean()*100,cv_roc_test.mean()*100,cv_prec_test.mean()*100,cv_recall_test.mean()*100]\n\nprint(\"Modelo CHI2\")\nselecao_modelos(df,colunas_chi2,\"target\",df_modelo = df_modelos,variavel=\"CHI2\")\nprint(\"\\n\")\nprint(\"Modelo RFE\")\nselecao_modelos(df,colunas_rfe,\"target\",df_modelo = df_modelos,variavel=\"RFE\")\nprint(\"\\n\")\nprint(\"Modelo ENSEABLE\")\nselecao_modelos(df,colunas_enseable,\"target\",df_modelo = df_modelos,variavel=\"ENSEABLE\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"8\"></a> <br>\n# <div class=\"alert alert-block alert-info\">8 - Conclusão</div>\n\n**É possível observar o dataframe sobre todos os modelos e suas métricas avaliadas com os dados de treino e com os dados de teste. Onde, diversos modelos distintos apresentaram ótimos valores em métricas distintas.**\n\n**Porém, neste trabalho o principal fator para prever doenças cardíacas sera aquele que obteve a melhor avaliação sobre a métrica de Recall nos dados de teste.\nEssa métrica se mostrou com maior significância pois um paciente ser diágnósticado como falso negativo é extremamente grave. E essa métrica é utilizada em uma situação em que os Falsos Negativos são considerados mais prejudiciais que os Falsos Positivos.**\n\n**Os modelos com os maiores valores para o Recall, foram:**\n- KNN (CHI2)\n- BDT SVM (CHI2)\n- SVM (CHI2)\n- BDT KNN (CHI2)\n- SVM (RFE)\n\n**Porém, entre esses modelos, o modelo KNN (CHI2) apresentou a maior curva AUC ROC, acurácia, precisão para os dados de teste.**\n\n**Portanto o modelo KNN utilizando a seleção de variáveis qui-quadrado (CHI2), obteve:**\n\n**Dados de TESTE**\n\n**AUC ROC: 81.57%**\n\n**Ácurácia: 81.84%**\n\n**Precisão: 75.55%**\n\n**Recall: 91.89%**\n\n\n**Tempo de treinamento do modelo: 0.099 segundos**\n\n\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_modelos.sort_values([\"Test RECALL\"],ascending=False,ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#KNN (CHI2)\n\ndef selecao_modelos(df,colunas,previsao,variavel):\n    df_X = df[colunas]\n    df_Y = df[previsao]\n    \n    variaveis = variavel\n    seed = 7   \n    X_train, X_test, y_train, y_test = train_test_split(df_X, df_Y, test_size = 0.25,random_state=seed) \n    \n    \n    #Separando o array em componentes X e Y\n    X = df_X.values\n    Y = df_Y.values\n\n    \n    #Normalização\n    scaler = MinMaxScaler(feature_range=(0,1))\n    rescaledx = scaler.fit_transform(X)\n    \n    #Definindo os valores para o número de folds\n    num_folds = 5\n    num_instances = len(rescaledx)   \n    \n    \n    kfold = StratifiedKFold(n_splits = num_folds,random_state=seed,shuffle = True)\n    inicio =time.time()\n    modelo = KNeighborsClassifier()\n    cv_results = cross_val_score(modelo,rescaledx,Y,cv = kfold,scoring=\"accuracy\")\n    fim = time.time()\n    tempo = fim - inicio\n        \n    tprs = []\n    aucs = []\n    mean_fpr = np.linspace(0, 1, 100)\n\n    fig, ax = plt.subplots(figsize=(8,6))\n    for i, (train, test) in enumerate(kfold.split(rescaledx, Y)):\n        modelo.fit(rescaledx[train], Y[train])\n        viz = plot_roc_curve(modelo, rescaledx[test], Y[test],\n                             name='ROC fold {}'.format(i),\n                             alpha=0.3, lw=1, ax=ax)\n        interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n        interp_tpr[0] = 0.0\n        tprs.append(interp_tpr)\n        aucs.append(viz.roc_auc)\n\n    ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n                    label='Chance', alpha=.8)\n\n    mean_tpr = np.mean(tprs, axis=0)\n    mean_tpr[-1] = 1.0\n    mean_auc = auc(mean_fpr, mean_tpr)\n    std_auc = np.std(aucs)\n    ax.plot(mean_fpr, mean_tpr, color='b',\n            label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n            lw=2, alpha=.8)\n\n    std_tpr = np.std(tprs, axis=0)\n    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n    ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n                    label=r'$\\pm$ 1 std. dev.')\n\n    ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n                 title=\"k-nearest neighbors (CHI2)\")\n    ax.legend(loc=\"lower right\")\n    plt.show()\n       \nprint(\"Característica de Operação do Receptor (ROC) com cross validation para o melhor modelo.\")\nselecao_modelos(df,colunas_chi2,\"target\",variavel=\"RFE\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3 style=\"text-align:center;font-size:200%;;\">Conclusão do projeto</h3>\n<div class=\"progress\">\n  <div class=\"progress-bar\" role=\"progressbar\" style=\"width: 100%;\" aria-valuenow=\"25\" aria-valuemin=\"0\" aria-valuemax=\"100\">100% Concluído</div>\n</div>"},{"metadata":{},"cell_type":"markdown","source":"<a href=\"#top\" class=\"btn btn-success btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Voltar para o topo</a>"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}