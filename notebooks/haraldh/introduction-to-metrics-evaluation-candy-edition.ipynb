{"cells":[{"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.linear_model import LinearRegression\nfrom matplotlib import pyplot as plt\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\n#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","metadata":{"_kg_hide-input":true,"_cell_guid":"1f1c1cf7-cc85-40c9-8369-0056b28d84d6","_kg_hide-output":true,"_uuid":"5b411c804d2b6e4eb7fcd4ada912e4ac611992a5"},"cell_type":"code","outputs":[],"execution_count":1},{"source":"# Introduction:\nThis notebook is aimed to novices, to show how different sizes of hold-out sets can affect your conclusions and your models.\nFor this we will use the following Dataframe:","metadata":{},"cell_type":"markdown"},{"source":"df = pd.read_csv('../input/candy-data.csv')\ndf.head()","metadata":{},"cell_type":"code","outputs":[],"execution_count":2},{"source":"df.describe()","metadata":{},"cell_type":"code","outputs":[],"execution_count":3},{"source":"## Objective: see how different sizes of Hold-out sets affect our models.\n#### sidenote: since we don't care that much about the quality of the model, little data preprocessing will be done","metadata":{},"cell_type":"markdown"},{"source":"cols = df.columns[1:]\ndata = df[cols].values\nfeatures = data[:,:-1]\ntarget = data[:,-1]","metadata":{},"cell_type":"code","outputs":[],"execution_count":4},{"source":"def normalize(feat):\n    return (feat-np.min(feat, axis=0))/(np.max(feat, axis=0)-np.min(feat, axis=0))","metadata":{},"cell_type":"code","outputs":[],"execution_count":5},{"source":"n_feat = normalize(features) ","metadata":{},"cell_type":"code","outputs":[],"execution_count":6},{"source":"partitions=np.linspace(0.3,0.95,6)\nx=np.random.binomial(1,0.8,size=len(df))\ntrain_feat = n_feat[x==1,:]\ntrain_t = target[x==1]\ntest_feat = n_feat[x==0,:]\ntest_t = target[x==0]\n# Baseline Model\nbaseline = np.sqrt(np.sum((test_t-np.mean(train_t))**2))/np.sqrt(len(test_t))\nprint ('The Error of the baseline Model is: {}'.format(baseline))\nfor prob in partitions:\n    print (prob)\n    x=np.random.binomial(1,prob,size=len(df))\n    train_feat = n_feat[x==1,:]\n    train_t = target[x==1]\n    test_feat = n_feat[x==0,:]\n    test_t = target[x==0]\n    lm = LinearRegression()\n    lm.fit(train_feat,train_t)\n    rmse = np.sqrt(np.sum((test_t-lm.predict(test_feat))**2))/np.sqrt(len(test_t))\n    print ('The Error of the linear model is: {}'.format(rmse))\n    plt.scatter(test_t,lm.predict(test_feat))\n    plt.title('how the predictions are scattered: predicted v/s real target')\n    plt.show()\n","metadata":{"scrolled":false},"cell_type":"code","outputs":[],"execution_count":7},{"source":"### Conclusions:\nIf you got too litte data, your model won't be abble to learn the patterns in the data, and this will cause it to perform poorly (In this case, when prob< 0.5 or so). but, since you got a lot of testing data, you will be quite confident that the model is in fact, performing poorly. on te other hand, if you train the model with a  partition of the data too big (prob>0.9) your model might be performing well, but you won't know for sure, because of the high variability of the RMSE in your testing data.\nTo get a decent estimation of the error just using a hold-out set, you should choose to use about 80% of the data for training, and the rest for testing. Nonetheless, if you few data, perhaps it's better to use more advanced techniques of cross-validation (Leave One Out, etc).\nREMEMBER: the production model should be always be trained with the maximum amount of data.","metadata":{},"cell_type":"markdown"},{"source":"","metadata":{"collapsed":true},"cell_type":"code","outputs":[],"execution_count":null}],"nbformat":4,"metadata":{"language_info":{"nbconvert_exporter":"python","version":"3.6.3","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"name":"python","file_extension":".py","mimetype":"text/x-python"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat_minor":1}