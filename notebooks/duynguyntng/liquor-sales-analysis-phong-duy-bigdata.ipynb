{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport gc  # Garbage collection. We will use it a lot.\n\nfrom tqdm.notebook import trange, tqdm\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('../input/iowa-liquor-sales'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_data_from_records():\n    \"\"\"\n    This function may dowmload all records from Iowa.gov;\n    but it is too slow so it times out. You can get full csv from the same site though.\n    \"\"\"\n    # make sure to install these packages before running:\n    !pip install sodapy\n\n    from sodapy import Socrata\n\n    # Unauthenticated client only works with public data sets. Note 'None'\n    # in place of application token, and no username or password:\n    client = Socrata(\"data.iowa.gov\", None)\n\n    # Example authenticated client (needed for non-public datasets):\n    # client = Socrata(data.iowa.gov,\n    #                  MyAppToken,\n    #                  userame=\"user@example.com\",\n    #                  password=\"AFakePassword\")\n\n    # First 2000 results, returned as JSON from API / converted to Python list of\n    # dictionaries by sodapy.\n    results = client.get_all(\"m3tr-qhgy\")\n\n    # Convert to pandas DataFrame\n    results_df = pd.DataFrame.from_records(results)\n    \n    return results_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def basic_preprocessing(df):\n    \"\"\"\n    Basic preprocessing of the original Iowa Liquor Sales dataframe:\n    - cast all object values to lowercase\n    - split names into meaningfull parts [Store_Name, Store_subname, Store_Number]\n    \n    NOTE: the latter part needs improvement:\n    - some names have mulitple \"/\", need to eyeball such strings\n    - some do not have # before the number, possible solution .str.extract(pat=r'(\\d+$)')\n    \"\"\"\n    # get object columns\n    object_column_list = list(df.dtypes[df.dtypes == object].index)\n    \n    # cast all object values to lowercase\n    for object_column in object_column_list:\n        df.loc[:,object_column] = df.loc[:,object_column].str.lower().str.strip().str.split().str.join(' ')\n        gc.collect()\n    \n    # split Store_Names to [Store_Name, Store_subname, Store_Number]\n    df[['Store Name','Store Subname']] = df['Store Name'].str.rsplit(pat=\" / \", expand=True, n=1)\n    df[['Store Name','Store SubNumber']] = df['Store Name'].str.rsplit(pat=\" #\", expand=True, n=1)\n    \n    return df\n\ndef get_number_to_name_dict(df, name_to_number_dict):\n    \"\"\"\n    For every column pair (name_column, id_column) in name_to_number_dict\n    creates one-to-one mapping of id_number to longest_name_string.\n    \"\"\"\n    def max_length_dict(df, number_column, name_column):\n        \"\"\"\n        For given pair of (name_column, id_column) creates one-to-one mapping of id_number to longest_name_string.\n        \"\"\"\n        # get all unique pairs of (id_number, name),\n        # usually there are multiple names for every id\n        stores_df = df.loc[:,[number_column, name_column]].drop_duplicates()\n\n        # create dictionary to map id_number to longest name,\n        # so that we can only keep the longest names\n        number_to_name_dict = stores_df.fillna('#').groupby(number_column)[name_column].max().to_dict()\n\n        return number_to_name_dict\n\n    map_dict = {}\n    \n    # for every pair of id_column, name_column\n    for name in name_to_number_dict:\n        # add dict record: {name: number_to_name_dict}\n        map_dict[name] = max_length_dict(df,name_to_number_dict[name],name)\n    \n    return map_dict\n\n# dict of name_column, id_column pairs:\nname_to_number_dict = {\n    'Store Name':'Store Number',\n    'Store Subname':'Store Number',\n    'County':'County Number',\n    'Vendor Name':'Vendor Number',\n    'Category Name':'Category'\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"useful_columns = ['Invoice/Item Number', 'Date', 'Store Number', 'Store Name', 'Address',\n       'City', 'Zip Code', 'County Number', 'County',\n       'Category', 'Category Name', 'Vendor Number', 'Vendor Name',\n       'Item Number', 'Item Description', 'Pack', 'Bottle Volume (ml)',\n       'State Bottle Cost', 'State Bottle Retail', 'Bottles Sold',\n       'Sale (Dollars)', 'Volume Sold (Liters)']\n\n# Load raw dataset and sample 10% of it right away:\nFILE_NAME = '../input/iowa-liquor-sales/Iowa_Liquor_Sales.csv'\nraw_df = pd.read_csv(FILE_NAME, parse_dates=['Date'], usecols=useful_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_df['Date'].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"samples_idx = np.array_split(\n    np.random.permutation(raw_df.shape[0]), # permutated index\n    10 # number of parts to split index\n)\n\n# use index values from the first part:\nraw_df = raw_df.iloc[samples_idx[0],:]\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_df = basic_preprocessing(raw_df)\n\n# get a dict to map id_number to longest name\nnumber_to_name_dict = get_number_to_name_dict(raw_df, name_to_number_dict)\n\n# map names to longest names based on id_numbers\nfor name in name_to_number_dict:\n    raw_df[name] = raw_df[name_to_number_dict[name]].map(number_to_name_dict[name])\n    \n# save the processed chunk\nraw_df.to_csv('iowa_processed.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for idx in tqdm(samples_idx[1:]):\n\n    raw_df = pd.read_csv(\n        FILE_NAME,\n        parse_dates=['Date'],\n        usecols=useful_columns\n    )  # skiprows = lambda x: x not in np.append([0],idx)  # append column names row in the beginning \n    \n    raw_df = raw_df.iloc[idx,:] # the lamda seemed to be faster but it is not\n    gc.collect() # this might be unnecessary if using lambdas\n    \n    # same as above: lowercase, split, map using existing dicts, save_append\n    raw_df = basic_preprocessing(raw_df)\n    for name in name_to_number_dict:\n        raw_df[name] = raw_df[name_to_number_dict[name]].map(number_to_name_dict[name])\n    raw_df.to_csv('iowa_processed.csv', mode='a', header=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_df['month'] = pd.DatetimeIndex(raw_df['Date']).month\nraw_df['year'] = pd.DatetimeIndex(raw_df['Date']).year\n\ndf_month_category = raw_df.groupby(['Category Name','year','month']).mean()[['Volume Sold (Liters)', 'Sale (Dollars)']]\ndf_month_category.reset_index(inplace=True)\n\niowa_temp_month_high_avg = [29.1,35.4,48.2,61.3,72.3,81.8,86.0,83.9,75.9,63.5,46.7,33.1]\niowa_temp_month_high_avg_dict = dict(zip(list(range(1,13)),iowa_temp_month_high_avg))\ndf_month_category['mnth_avg_temp'] = df_month_category.month.map(iowa_temp_month_high_avg_dict)\ndf_month_category","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"year2020 = df_month_category.groupby('year').month.describe()\nyear2020","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_year = df_month_category.groupby('year').mean().drop('month', axis = 1).drop('mnth_avg_temp', axis = 1)\ndf_year","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.rc('font', size=12)\nfig, ax = plt.subplots(figsize=(10, 6))\nax.plot(df_month_category.year, df_month_category.Sale(Dollars))\nax.set_xlabel('year')\nax.set_ylabel('Sale (Dollars)')\nax.set_title('Sale (Dollars) through the years')\nax.grid(True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"minSale = df_year['Sale (Dollars)'].min()\nif minSale == df_year.iloc[8,1]:\n    print('Year 2020 has a lowest sale point for alcohol since 2012.')\nelse:\n    print('Year 2020 does not has a lowest sale point for alcohol since 2012.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"category_names_list = list(df_month_category['Category Name'].unique())\nfor i, category_name in enumerate(category_names_list):\n    category_mask = df_month_category['Category Name']==category_name\n    pivot_data = df_month_category[category_mask].pivot('year','month','Sale (Dollars)')\n    fig, ax = plt.subplots()\n    fig.set_size_inches(12, pivot_data.shape[0])\n    sns.heatmap(pivot_data).set_title(category_name.upper(),pad=20, fontdict={'fontsize': 20, 'fontweight': 'medium'})","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}