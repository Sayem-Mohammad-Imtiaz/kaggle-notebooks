{"nbformat_minor":1,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"version":3,"name":"ipython"},"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.3","mimetype":"text/x-python","file_extension":".py","name":"python"}},"cells":[{"source":"<h1>TMDB Analysis <h1>\n\nIn order to get a structured and in deth analysis of TMDB datbases we have divided our research into sex sections. <span style=\"color:red\">On basis of our findings during the analysis we try to make a accurate predictions for **(1), (2), (3), (4), (5)** \n    \n    - Part 1: Exploring and Preparing the data for analysis\n    - Part 2: Analyse  genres\n    - Part 3: Analyse keywords\n    - Part 4: Analyse Actors\n    - Part 5: Analyse Directors\n    - Part 6: Predictions\n    \n    ","cell_type":"markdown","metadata":{"_uuid":"32ffe50da42e7b2859676479bfd58970981ca547","_cell_guid":"43233258-f411-4372-8545-966de997838e"}},{"source":"<h2> Part 1: Exploring and  preparing the data for analysis </h2> \n We start with the import of packages we will eventually need. Furthermore, we import the datasets and start with exploring and preparing the data for further analysis.\n \n Firstly, we import the packages we need in the notebook for the analysis of the two uploaded datasets. Afterthat,  we start exploring the datasets to get a brief overview of the available data. In order to make a proper analysis we preparing the datasets by cleaning and reordering the different collums and rows.","cell_type":"markdown","metadata":{"_uuid":"01090834384d4d38704f7fd71c67fd838ca95a0f","_cell_guid":"13ca24a5-5033-45e2-af40-059be883228a"}},{"source":"\nfrom sklearn.preprocessing import Imputer\nfrom sklearn.decomposition import PCA # Principal Component Analysis module\nfrom sklearn.cluster import KMeans # KMeans clustering \nimport nltk\nfrom nltk.corpus import wordnet\nPS = nltk.stem.PorterStemmer()\nimport matplotlib.pyplot as plt\nimport plotly.offline as pyo\npyo.init_notebook_mode()\nfrom plotly.graph_objs import *\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode,iplot\ninit_notebook_mode(connected=True)\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\n\nimport json\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nfrom sklearn.preprocessing import Imputer\nfrom sklearn.decomposition import PCA # Principal Component Analysis module\nfrom sklearn.cluster import KMeans # KMeans clustering \n\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\n\nmovies = pd.read_csv('../input/tmdb_5000_movies.csv')\ncredits = pd.read_csv('../input/tmdb_5000_credits.csv')\n\n","outputs":[],"cell_type":"code","metadata":{"_uuid":"5d7762e7e6a3a1948c2badf10cdd6ab594bb47fb","_cell_guid":"b38e4ac8-fc0f-4461-b711-528ae409ea62"},"execution_count":256},{"source":"<h4> What does the data look like?</h4>\nWe'll start with taking a look at the movies data frame to see what we've got the work with.\n","cell_type":"markdown","metadata":{"_uuid":"06c444c86f78e4492cb641f21f31e95b8e734ce2","_cell_guid":"1b993148-9acb-46fa-b90e-26711e3d44e6","collapsed":true}},{"source":"movies.head()","outputs":[],"cell_type":"code","metadata":{"_uuid":"0eaa70314d70d4b70f12ab71b08d5fc3c99f1f4d","_cell_guid":"2725269d-378e-4efd-b31d-fd0336493087"},"execution_count":257},{"source":"<h4> What are remarkable observations/findings if we take a quick look at the dataframe?</h4>\nThe first thing we notice is that the columns are a strange order to take a fine look at the data. A preferable first column of this data frame, would, for example, be the title of the movie and not the movie's budget. \n\nFurthermore,  we notice that the columns 'genres', 'keywords', 'production_companies', 'production_countries' and 'spoken_languages' are of the dictionary type, so right now they are quite hard to read, but later on we will find a way to work with them.\n\nAmongst the numerical columns, there's a movie budget, a movie ID, popularity, revenue, runtime, a vote average and the amount of votes a movie has received.  Besides the fact that the ID column is numerical, it is also not of interest for making predictions about. \n\nFor now, we leave this data frame as it is and we'll take a quick look at the other one.","cell_type":"markdown","metadata":{"_uuid":"5166b5cb4418ad0ca96ed2298a6cec0c2b9ba3cd","_cell_guid":"df7fac77-3d46-468e-950c-d067de697ec6"}},{"source":"credits.head()","outputs":[],"cell_type":"code","metadata":{"_uuid":"c4e3cff701a1ce5d1de33592e8417683e86807c6","_cell_guid":"fd8ad6e3-5e36-4995-856a-935ed96bc8e4"},"execution_count":258},{"source":"<h4> What are remarkable observations/findings if we take a quick look at the dataframe?</h4>\nThe data frame credits has way fewer columns. The cast and crew might be interesting later on. Since this data frame contains only two extra columns, we'll try to merge it with the  movies data frame. If tthe collumns have the same value, we can just concatenate the data frames,. We use the following function to see if in both data frames every row is about the same movie.","cell_type":"markdown","metadata":{"_uuid":"b9c8445c34c73ae7aae19b5d6f748f05d80222f8","_cell_guid":"71164a29-f3d1-4f09-840d-26989b2bf99e"}},{"source":"(credits['title']==movies['title']).describe()","outputs":[],"cell_type":"code","metadata":{"_uuid":"cd5e12e3c4ed20b5157b547be3e64b204254b081","_cell_guid":"25476689-3372-489b-ab6c-dbf0ea6479c7"},"execution_count":259},{"source":"We can conclude that every row in the collumn title of the credits data base has the same value  as the same row in the collumn title of the  movies data base. To prevent getting duplicate columns, we'll remove the movie_id and title column from the credits data frame and concatenate them. This results in the following combined dataframe:","cell_type":"markdown","metadata":{"_uuid":"5c662bcfaab873f88a5e185bbad3bd3a4fda7203","_cell_guid":"17e2e700-97e9-4c6c-aac2-543d3d40703e"}},{"source":"del credits['title']\ndel credits['movie_id']\nmovie_df = pd.concat([movies, credits], axis=1)\nmovie_df.head()","outputs":[],"cell_type":"code","metadata":{"_uuid":"6fc2bf03e1d0570c783dfd363760709b9d11e782","_cell_guid":"ce281788-be9f-46dd-b5e2-a756a39eeb14"},"execution_count":260},{"source":"The collumns are still in a stange order if we take a quick look at the dataframe. Moreover, columns like homepage, id and status aren't really interesting for us. Therefore, we choose the interesting columns (in our case), put them in a nice order and create a new data frame.\n","cell_type":"markdown","metadata":{"_uuid":"4459fabdb2936abbcc81a89f4cffbce8018f6ed9","_cell_guid":"834bfaa0-ca5d-4d40-82c1-9c3b5a7eafff"}},{"source":"newCols = ['title','release_date','popularity','vote_average','vote_count',\n           'budget','revenue','genres','keywords','cast','crew','tagline', 'runtime', 'production_companies', \n           'production_countries', 'status']\n\ndf2 = movie_df[newCols]\ndf2.head()","outputs":[],"cell_type":"code","metadata":{"_uuid":"fb9e4b891a2fd5bc19626076fbc6df93cab00a59","_cell_guid":"e8d67d4c-37c7-45f4-91dc-a2c8001523db"},"execution_count":261},{"source":"<h4>What can the numerical collumns tell us if we make a quick analysis?</h4>","cell_type":"markdown","metadata":{"_uuid":"900f21ba6b884e523eed2eb371bdb4b230a91864","_cell_guid":"1016db94-005b-4ec9-b086-99178d5daa2a"}},{"source":"df2.describe().round()","outputs":[],"cell_type":"code","metadata":{"_uuid":"a8e6c47342dc80d0e11c96a56b4517faca3f5c9f","_cell_guid":"b9b52a14-2417-4f9d-8b8a-d443c8ce6bc4"},"execution_count":262},{"source":"Note that runtime consists of two empty values, before we can really work with our data frame, we need to solve this. We use an imputer for this, which replaces the missing value by a computed average.","cell_type":"markdown","metadata":{"_uuid":"b50b2b2ecf1cef2040286b9f4233a9882328f695","_cell_guid":"eb8681d4-2fe1-49b8-a63d-f58dbc3071d3"}},{"source":"my_imputer = Imputer()\n\ntemp=df2\nX2 = my_imputer.fit_transform(df2[['runtime']])\ndf2['runtime'] = X2\ndf2.describe().round()","outputs":[],"cell_type":"code","metadata":{"_uuid":"2b9c00768110931ae1550d75ca75dd454728a0f6","_cell_guid":"50d3d414-705e-4d0e-b8e2-bc7e3d6c8896"},"execution_count":263},{"source":"<h4>How are all numerical variables distributed?</h4>\n<span style=\"color:red\">We firstly devide the vote average into four classes (low, medium-low, medium-high, high) .....\n","cell_type":"markdown","metadata":{"_uuid":"b8c1c085567949fcde734b31931d29d1e214fcd0","_cell_guid":"261ca333-5e32-44c4-9c50-62c3a731fae9"}},{"source":"#df2['vote_classes'] = pd.cut(df2['vote_average'],10, labels=[\"1\", \"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"])\ndf2['vote_classes'] = pd.cut(df2['vote_average'],4, labels=[\"low\", \"medium-low\",\"medium-high\",\"high\"])","outputs":[],"cell_type":"code","metadata":{"_uuid":"f2ddbf0dfd9d454d2911bb0c90f66eb13aacc48f","_cell_guid":"1ad95288-ddfb-4e05-a759-176c0500955d","collapsed":true},"execution_count":264},{"source":"df2['log_budget'] = np.log(df2['budget'])\ndf2['log_popularity'] = np.log(df2['popularity'])\ndf2['log_vote_average'] = np.log(df2['vote_average'])\ndf2['log_vote_count'] = np.log(df2['vote_count'])\ndf2['log_revenue']= np.log(df2['revenue'])\ndf2['log_runtime']= np.log(df2['runtime'])\ndf3=df2[df2.columns[-5:]]\n\n#df3.replace([np.inf, -np.inf], np.nan).dropna(axis=1)\ndf3=df3[df3.replace([np.inf, -np.inf], np.nan).notnull().all(axis=1)]\ndf3=df3.dropna(axis=1)\n#df3[~df3.isin([np.nan, np.inf, -np.inf]).any(1)]\n","outputs":[],"cell_type":"code","metadata":{"_uuid":"6082811e3b941dbe30427ada8b5c431f80ae8013","_cell_guid":"36adf6e7-acfb-4f96-80a0-e43cc6090ea3","collapsed":true},"execution_count":265},{"source":"from pandas.plotting import scatter_matrix\nscatter_matrix(df3,alpha=0.2, figsize=(20, 20), diagonal='kde')","outputs":[],"cell_type":"code","metadata":{"_uuid":"f82df58e8ad11a0a8a1f62cac09e1ed8e9f99289","scrolled":false,"_cell_guid":"012a07bb-20c9-4d84-9c7d-6b2250f495b0"},"execution_count":266},{"source":"<span style=\"color:red\">If we take a look at the distrbutions we can conclude that ....","cell_type":"markdown","metadata":{"_uuid":"84e5bcee18634e9cdd91c8ea6dc57634e2489796","_cell_guid":"e6bc5b82-fd17-4f4f-bb2b-68f6391772d7"}},{"source":"Early_df = df2[df2.columns[0:16]]\nEarly_df.head()","outputs":[],"cell_type":"code","metadata":{"_uuid":"240f1bc78084c6b6a8190d2ac5738dde94c7356f","_cell_guid":"e540dc5f-dece-4f1d-aa47-f7f675505b20"},"execution_count":267},{"source":"Note that everything is quite skewed. We'll try getting more in depth into this later.\n\n<span style=\"color:red\">Snap het doel van de  laatste tabel niet helemaal en wat je met deze opmerking bedoelt.","cell_type":"markdown","metadata":{"_uuid":"8e4138df3db3cdbf2e46cfa8a2f26816d6dd2f52","_cell_guid":"8d4fdc1a-e93e-4bfc-a071-0683c3e72fe5"}},{"source":"<h2> Part 2: Analyze genres </h2>\nNow that we've got a good overview of the distribution of our numerical variables, let's take a closer look at our non-numerical variables. We choose to start with looking at the genres, since this variable has got the least variability, should be the most easy target for analysis.\n\nThe genres column contains variables of the string type, while they are in dictionaries. Moreover, the colomn is a json column. To analyse and understand the data it is necessary to change the type of the variable and filter the columns.\nDespite the fact that we already loaded our data for the exploration, we'll reload it here and make sure to load the json columns correctly. To do this, we made use of a few tricks found in another Kernel*","cell_type":"markdown","metadata":{"_uuid":"fc43c19c83caa27d529a8e3b7aca2943d7ac9ea4","_cell_guid":"5d761fd4-ea8d-46bb-9494-8ded461964c6"}},{"source":"def load_tmdb_movies(path):\n    df = pd.read_csv(path)\n    df['release_date'] = pd.to_datetime(df['release_date']).apply(lambda x: x.date())\n    json_columns = ['genres', 'keywords', 'production_countries', 'production_companies', 'spoken_languages']\n    for column in json_columns:\n        df[column] = df[column].apply(json.loads)\n    return df\n\ndef load_tmdb_credits(path):\n    df = pd.read_csv(path)\n    json_columns = ['cast', 'crew']\n    for column in json_columns:\n        df[column] = df[column].apply(json.loads)\n    return df\n\ndef pipe_flatten_names(keywords):\n    return '|'.join([x['name'] for x in keywords])\n\ncredits = load_tmdb_credits(\"../input/tmdb_5000_credits.csv\")\nmovies = load_tmdb_movies(\"../input/tmdb_5000_movies.csv\")\n\ndel credits['title']\ndf = pd.concat([movies, credits], axis=1)\n\ndf['genres'] = df['genres'].apply(pipe_flatten_names)\n\nliste_genres = set()\nfor s in df['genres'].str.split('|'):\n    liste_genres = set().union(s, liste_genres)\nliste_genres = list(liste_genres)\nliste_genres.remove('')","outputs":[],"cell_type":"code","metadata":{"_uuid":"ae548a0a33350d637c8a605eaabf9a7b81358687","_cell_guid":"7cd6fbee-ea88-41e0-b78a-8f762e08dd09","collapsed":true},"execution_count":268},{"source":"\nSo what happened here is the following: first, we changed the type of the genres variable. Aferwards, we made use of the structure of the column and the *split()* function.  Because the genre always appears after the word *name*, we were able to filter out al the words after the word name and create a list of every genre that occurs in the genre-column.\n\nNow, let's reduce our data frame. To get more insight about the influence of a movie's genre, title, vote_average, release_data, runtime, budget and revenue are the most import important variables. We also add a column for every genre, containing only 1s and 0s whether a movie is of a specific genre or not.  ","cell_type":"markdown","metadata":{"_uuid":"7359db8de5160173d2fb51428f79d380b2e180ef","_cell_guid":"213962e1-cfe9-459c-a4fb-fff5daa088d6"}},{"source":"df_reduced = df[['title','vote_average','release_date','runtime','budget','revenue']].reset_index(drop=True)\n\nfor genre in liste_genres:\n    df_reduced[genre] = df['genres'].str.contains(genre).apply(lambda x:1 if x else 0)\ndf_reduced[:5]\n\ndf_reduced.head()","outputs":[],"cell_type":"code","metadata":{"_uuid":"872bbe1b21c1e01d3a781cb432c503859b00b0c2","_cell_guid":"c30f199a-20a0-4dd4-bcc5-7e73d57ac4f1"},"execution_count":269},{"source":"<h4>How are the genres distributed?</h4>\nBy creating a pie chart we can get a good overview/visualition of the distribution of the genres in the dataset.","cell_type":"markdown","metadata":{"_uuid":"e7c965e688f8a84716b585b787f5633894b14617","_cell_guid":"5e162a45-3bcb-4f6f-b9a6-3bc636e33da8"}},{"source":"plt.rc('font', weight='bold')\nf, ax = plt.subplots(figsize=(5,5))\ngenre_count = []\nfor genre in liste_genres:\n    genre_count.append([genre, df_reduced[genre].values.sum()])\ngenre_count.sort(key = lambda x:x[1], reverse = True)\nlabels, sizes = zip(*genre_count)\nlabels_selected = [n if v > sum(sizes) * 0.01 else '' for n, v in genre_count]\nax.pie(sizes, labels=labels_selected,\n      autopct = lambda x:'{:2.0f}%'.format(x) if x>1 else '',\n      shadow = False, startangle=0)\nax.axis('equal')\nplt.tight_layout()","outputs":[],"cell_type":"code","metadata":{"_uuid":"95e084d16b6e4ad9671d49dcd27411608e481ca2","_cell_guid":"31407e63-2509-499e-8ffa-095c69523b65"},"execution_count":270},{"source":"This pie chart shows which genres are most common in the movies dataset. We find that drama movies are most common, followed by comedy. Afterwards, thriller and action movies are the most popular. Interestingly, half of the movies is from the top 5 genres. (51%). This suggest that the main genre of the most movies are drama, comedy, thriller, action. However, the top 5 most common genres could be seen as more general descriptions. For example, movies with the genre war might also be tagged as action movies or drama movies.\n\nNow let's try to get a more in depth view of the genres. In this cell we calculate the average votes, budget, and revenue for the different genres. We create a new data frame consisiting of every genre and the calculated averages. Lastly, we add an extra collumn, profit, which is basicly mean revenue subtracted by mean budget.","cell_type":"markdown","metadata":{"_uuid":"1748a70022387bb720dafced4697b287a8e3fa50","_cell_guid":"bad2ec31-e627-470a-83fb-47416b3a8c59"}},{"source":"mean_per_genre = pd.DataFrame(liste_genres)\n\n#Mean votes average\nnewArray = []*len(liste_genres)\nfor genre in liste_genres:\n    newArray.append(df_reduced.groupby(genre, as_index=True)['vote_average'].mean())\nnewArray2 = []*len(liste_genres)\nfor i in range(len(liste_genres)):\n    newArray2.append(newArray[i][1])\n\nmean_per_genre['mean_votes_average']=newArray2\n\n#Mean budget\nnewArray = []*len(liste_genres)\nfor genre in liste_genres:\n    newArray.append(df_reduced.groupby(genre, as_index=True)['budget'].mean())\nnewArray2 = []*len(liste_genres)\nfor i in range(len(liste_genres)):\n    newArray2.append(newArray[i][1])\n\nmean_per_genre['mean_budget']=newArray2\n\n#Mean revenue \nnewArray = []*len(liste_genres)\nfor genre in liste_genres:\n    newArray.append(df_reduced.groupby(genre, as_index=True)['revenue'].mean())\nnewArray2 = []*len(liste_genres)\nfor i in range(len(liste_genres)):\n    newArray2.append(newArray[i][1])\n\nmean_per_genre['mean_revenue']=newArray2\n\nmean_per_genre['profit'] = mean_per_genre['mean_revenue']-mean_per_genre['mean_budget']\n\nmean_per_genre    ","outputs":[],"cell_type":"code","metadata":{"_uuid":"8746016cd7d4978250628d685a94581a810afaa2","_cell_guid":"ec92952c-0c80-452a-ba30-b63ec341d862"},"execution_count":271},{"source":"<h4>Which genre is best scoring in the catagories mean votes average, mean budget, mean revenue and profit?","cell_type":"markdown","metadata":{"_uuid":"5f9bc16e0291f09f6b02b48f9ff82a2e04392f95","_cell_guid":"e108e1a1-75d6-4e59-b5d5-1602287d3059"}},{"source":"mean_per_genre.sort_values('mean_votes_average', ascending=False).head()\n","outputs":[],"cell_type":"code","metadata":{"_uuid":"4b3ec808c1a23885a30017cf0d82b61e5dec77bc","_cell_guid":"4d11c090-22bf-453e-bbed-505734ee6ab0"},"execution_count":272},{"source":"mean_per_genre.sort_values('mean_budget', ascending=False).head()","outputs":[],"cell_type":"code","metadata":{"_uuid":"d08d1db2a1729095d3913bf6833d9ac845c08546","_cell_guid":"98c154de-f21e-495e-a05d-13bc0cffff64"},"execution_count":273},{"source":"mean_per_genre.sort_values('mean_revenue', ascending=False).head()","outputs":[],"cell_type":"code","metadata":{"_uuid":"3b102756ffebeb09f231b2b8328e9db381b5966c","_cell_guid":"d938df06-ec40-424a-9511-0a62dbde2397"},"execution_count":274},{"source":"mean_per_genre.sort_values('profit', ascending=False).head()","outputs":[],"cell_type":"code","metadata":{"_uuid":"06263167d241c26eac291a3132cd4972b12b15e4","_cell_guid":"880e9d11-0f84-45f6-9155-6516f990e29b"},"execution_count":275},{"source":"It's very interesting to see that the top 5 highest vote average consists of *History, War, Drama, Music* and *Foreign*, while none of these genres are in either one of the other three categories, which all have the same top 3: *Animation, Adventure, Fantasy*. This is easily explained, since budget and revenue should be closely related and profit is directly derived from budget and revenue. However, we would have expected a higher correlation between the budget and the quality of a movie.\n\nTo go even more in depth, we want to analyse the averages per genre per year.  Therefore, we first extend the dataframe. with the year of release per movie.  Afterwards, we create a new dataframe which contains the average votes, average runtime, and average budget per release year and per genre. \n\nIn the last step in the cell below, only the rows that contain a 1 for genre are kept, so we create a data frame with only the specific genres. ","cell_type":"markdown","metadata":{"_uuid":"5bb5ea965f943ff090ac68d15a63e7a9eb02e109","_cell_guid":"346a51ce-b42d-4e0f-a01b-122096aeddeb"}},{"source":"from datetime import datetime\n\nt = df_reduced['release_date']\nt = pd.to_datetime(t)\nt = t.dt.year\ndf_reduced['release_year'] = t\n\ndf_list = []*len(liste_genres)\nfor genre in liste_genres:\n    df_list.append(df_reduced.groupby([genre,'release_year']).mean().reset_index())\n\ndf_per_genre = []*len(liste_genres)\nfor i in range(len(df_list)):\n    df_per_genre.append(df_list[i][df_list[i].ix[:,0] == 1])\n","outputs":[],"cell_type":"code","metadata":{"_uuid":"756fbc41e0f7b112e6b60e7b2495d17a3b4e6706","_cell_guid":"9fcdbaa0-1d9e-4a50-a07c-c58bc5e19746","collapsed":true},"execution_count":276},{"source":"Now we create tables which contain the average budget, average revenue, and average votes per year per genre. We start with creating a new table with the cloumns 1988 till 2017. Afterwards, the data for the different variables is implemented. ","cell_type":"markdown","metadata":{"_uuid":"4747dbe0851e7d52e6430bdccc42abb8c117dad6","_cell_guid":"42932903-d22d-4533-a46f-67a0883f26e9"}},{"source":"# Budget\ncolumns = range(1988,2018)\nbudget_genre = pd.DataFrame( columns = columns)\n\nfor genre in liste_genres:\n    temp=(df_per_genre[liste_genres.index(genre)].pivot_table(index = genre, columns = 'release_year', values = 'budget', aggfunc = np.mean))\n    temp = temp[temp.columns[-30:]].loc[1]\n    budget_genre.loc[liste_genres.index(genre)]=temp\nbudget_genre['genre']=liste_genres\n\n# Revenue \n\ncolumns = range(1988,2018)\nrevenue_genre = pd.DataFrame( columns = columns)\n\nfor genre in liste_genres:\n    temp=(df_per_genre[liste_genres.index(genre)].pivot_table(index = genre, columns = 'release_year', values = 'revenue', aggfunc = np.mean))\n    temp = temp[temp.columns[-30:]].loc[1]\n    revenue_genre.loc[liste_genres.index(genre)]=temp\nrevenue_genre['genre']=liste_genres\n\n# Vote average \ncolumns = range(1988,2018)\nvote_avg_genre = pd.DataFrame( columns = columns)\n\nfor genre in liste_genres:\n    temp=(df_per_genre[liste_genres.index(genre)].pivot_table(index = genre, columns = 'release_year', values = 'vote_average', aggfunc = np.mean))\n    temp = temp[temp.columns[-30:]].loc[1]\n    vote_avg_genre.loc[liste_genres.index(genre)]=temp\nvote_avg_genre['genre']=liste_genres\n\n#vote_avg_genre.index = vote_avg_genre['genre']","outputs":[],"cell_type":"code","metadata":{"_uuid":"203b23b2c8b1a0f415abdb1235833bcf3948675c","_cell_guid":"002c17d2-abf5-4b3b-a912-9deb8132d3cc","collapsed":true},"execution_count":277},{"source":"Let's take a look at the data frames we generated.","cell_type":"markdown","metadata":{"_uuid":"2fa64e74ad476f3b29cde956a6f7cc1cb02c5a6a","_cell_guid":"95b4fcf2-6e96-40d1-b3c7-ec8d057da90e"}},{"source":"### Mean budget per genre per year:","cell_type":"markdown","metadata":{"_uuid":"04218eb4ff4005182b6a3e3223dcac6ec7a7d6e9","_cell_guid":"a2eeae17-0d16-45e1-a18e-717f921d9190"}},{"source":"budget_genre.index = budget_genre['genre']\nbudget_genre","outputs":[],"cell_type":"code","metadata":{"_uuid":"7b20331d3843949bfa4542a3eae492782a57c8ae","_cell_guid":"782c6822-8bca-472d-9c4e-a89820f35719"},"execution_count":278},{"source":"### Mean revenue per genre per year:","cell_type":"markdown","metadata":{"_uuid":"07ece8c3632bb39c95bbdf98861e96f1f7b8eecd","_cell_guid":"5e8ff604-af59-4c26-b6a3-461145a1b6d4"}},{"source":"revenue_genre.index = revenue_genre['genre']\nrevenue_genre\n","outputs":[],"cell_type":"code","metadata":{"_uuid":"deda1f2c4f05904804a1f4947c3fa4fb51ec586e","_cell_guid":"411df1fc-e087-4499-b508-02fc1ac35dce"},"execution_count":279},{"source":"### Mean vote average per genre per year:","cell_type":"markdown","metadata":{"_uuid":"04907ef7fd7a8b39c94ea62e4f45fb75867bee72","_cell_guid":"e5047da0-2154-4d27-b34c-3fb509459691"}},{"source":"vote_avg_genre.index = vote_avg_genre['genre']\nvote_avg_genre","outputs":[],"cell_type":"code","metadata":{"_uuid":"9509d23876cfa146e060abc2d4fca507e41994c1","_cell_guid":"c51a50d4-4ec2-4f00-be0f-d59b41a46cc6"},"execution_count":280},{"source":"#revenue_genre[revenue_genre.columns[1]]\n#budget_genre[budget_genre.columns[1]]\nprofit_genre = revenue_genre[revenue_genre.columns[0:29]]-budget_genre[budget_genre.columns[0:29]]\n#df2[df2.columns[0:16]","outputs":[],"cell_type":"code","metadata":{"_uuid":"c1498941ce46ab691c20536666e7d3c6eece9b9f","_cell_guid":"6bacfdb4-14f5-45f3-8b10-41fb503d9550","collapsed":true},"execution_count":281},{"source":"<h4> How are the genres and budget related over the years?","cell_type":"markdown","metadata":{"_uuid":"1890ca6fc6b64bc4da01f8e1af29d1209df6db34","_cell_guid":"3a47d56c-5adf-4a0f-84ba-103f230c88f9"}},{"source":"fig, ax = plt.subplots(figsize=(9,9))\ncmap = sns.cubehelix_palette(start = 1.5, rot = 1.5, as_cmap = True)\nsns.heatmap(budget_genre.ix[:,0:30], xticklabels=3, cmap=cmap, linewidths=0.05)","outputs":[],"cell_type":"code","metadata":{"_uuid":"a63481acf40045e027cb78c035f0f72d74ab692d","_cell_guid":"0a4a4992-3f40-404b-8167-2d162494d2ab"},"execution_count":282},{"source":"The heatmap shows that in general, movies had  an increasing budget over the years. Especially the genres Fantasy, advernture, family, action, science fiction, and animation. The heatmap also shows that Western movies had an extremely high budget in 2013. This could mean that a costly movie is produced in 2013 which has great influence on the average.  We might later on remove this possible outlier, to get a better overview of the distribution of the rest of the movies.","cell_type":"markdown","metadata":{"_uuid":"4fb033ce2500812842d37c7464af5928e502d4c1","_cell_guid":"9790a686-a240-4a82-9494-63a9ca7e4119"}},{"source":"<h4> How are the genres and revenue related over the years?","cell_type":"markdown","metadata":{"_uuid":"bbb6ee57e7b0dc097844ab3da37aa12ce1726b51","_cell_guid":"f39845d7-9268-416d-8ff5-7cf085525c5d"}},{"source":"\nfig, ax = plt.subplots(figsize=(9,9))\ncmap = sns.cubehelix_palette(start = 1.5, rot = 1.5, as_cmap = True)\nsns.heatmap(revenue_genre.ix[:,0:30], xticklabels=3, cmap=cmap, linewidths=0.05)","outputs":[],"cell_type":"code","metadata":{"_uuid":"fa901321d89c0ac0507b0c966398ff0a943547ae","_cell_guid":"2cca70eb-fca1-482c-adba-a5f05cfe25db"},"execution_count":283},{"source":"This heatmap shows the average revenue of genres from 1988 till 2017. The most clear increase of average is in the genres fantasy, adventure, family, action, science fiction. Interestingly, the graph shows that the revenues of the genre animation are colored black in 1994. This is surprisingly because there are no black colored revenues in the graph and in general revenues are lower in 1994 than movies that are produced in later years.  A reason for this could be that there are only a few movies in the genre animation in 1994 and that those movies did extremely well.  The previous heatmap does not show an above average budget for animation movies in 1994. \n","cell_type":"markdown","metadata":{"_uuid":"a2651aa14cc3d4c5b61dbcde80db57ad77013a1c","_cell_guid":"12e3f28c-f44e-4388-b8e3-b22aa75e612c"}},{"source":"<h4> How are the genres and profit related over the years?","cell_type":"markdown","metadata":{"_uuid":"b961d767163a91f2aef6df00f545015b44fb2327","_cell_guid":"9fe7a05c-496d-48cf-86e0-46e296bbf12f"}},{"source":"fig, ax = plt.subplots(figsize=(9,9))\ncmap = sns.cubehelix_palette(start = 1.5, rot = 1.5, as_cmap = True)\nsns.heatmap(profit_genre, xticklabels=3, cmap=cmap, linewidths=0.05)","outputs":[],"cell_type":"code","metadata":{"_uuid":"35be4d5c39f5c7553f2e08e3aafbdc9d923e7b07","_cell_guid":"751b98df-8d94-4369-9f87-f208b4e2d372"},"execution_count":284},{"source":"<h4> How are the genres and vote average related over the years?","cell_type":"markdown","metadata":{"_uuid":"42721ee3590329102fb385605398256d90a8139a","_cell_guid":"fe6df8e5-d727-4f0a-8823-7380ecd09286"}},{"source":"fig, ax = plt.subplots(figsize=(9,9))\ncmap = sns.cubehelix_palette(start = 1.5, rot = 1.5, as_cmap = True)\nsns.heatmap(vote_avg_genre.ix[:,0:30], xticklabels=3, cmap=cmap, linewidths=0.05)","outputs":[],"cell_type":"code","metadata":{"_uuid":"465ce8c77199e58d25da58cfc1a03043d1eb0111","_cell_guid":"f32c90a3-5775-4e13-8ef4-d04f04f86d06"},"execution_count":285},{"source":"This heatmap is way darker than the previous two, which suggests that the average is relatively higher than in the other two categories. Most of the categories seem to be getting somewhere around a 6 out of 10 score. Especially notable is the fact that there are very few green or orange colored cells, which should mean that the most movies are on average just a nice watch.","cell_type":"markdown","metadata":{"_uuid":"d7b212beb3bc44f5d271002072d304a86df07107","_cell_guid":"ea12fc5a-ab2e-4956-b714-49b4e5ded171"}},{"source":"<h4> How are the genres and budget related over the years if we remove the outlier?</h4>\nAs said before, we would like to remove the very high budget input from the Western genre, to make the heatmap less skewed. Let's see what happens:","cell_type":"markdown","metadata":{"_uuid":"eb3c3798334132b0b891f8555b080804834e80dd","_cell_guid":"76ab1f38-14b1-4b2a-8383-5551b1132dd9"}},{"source":"temp = budget_genre\ntemp[2013]=temp[2013].replace(2.550000e+08, 0)\n\nfig, ax = plt.subplots(figsize=(9,9))\ncmap = sns.cubehelix_palette(start = 1.5, rot = 1.5, as_cmap = True)\nsns.heatmap(temp.ix[:,0:30], xticklabels=3, cmap=cmap, linewidths=0.05)","outputs":[],"cell_type":"code","metadata":{"_uuid":"0f8f0acda5902cc103cefab3be2e739703f50cd0","_cell_guid":"2fbe958c-f9a1-4b25-99af-635ff92dedde"},"execution_count":286},{"source":"This heatmap obviously shows that Fantasy Adventure, Science Fiction, and Animation have on average the highest budget. It is also clear that movies had an increasing budget over the years. However, there are a few exceptions. For example  Western movies had an above average budget in 2004 and history in 2000. This might be an effect of individual movies with a high budget. ","cell_type":"markdown","metadata":{"_uuid":"51b321a729d054067ce40e054d63ea18829074d9","_cell_guid":"d5a4f57b-0db6-4c89-9b37-e15b8329c3ea"}},{"source":"<h4>How are the genres and revenue related over the years if we remove the outliers?</h4>\nRevenue also has some very extreme outliers in the animation category. The values of both 1992 and 1994 are removed from the dataset.","cell_type":"markdown","metadata":{"_uuid":"88005a3915074c94c59adf32fdf5a9ae5198a6cd","_cell_guid":"96188e12-4ded-40fa-8e0c-7fd843fe45d8"}},{"source":"temp2 = revenue_genre\ntemp2[1994] = temp2[1994].replace(788241776.0, 0)\ntemp2[1992] = temp2[1992].replace(504050219.0, 0)\n\nfig, ax = plt.subplots(figsize=(9,9))\ncmap = sns.cubehelix_palette(start = 1.5, rot = 1.5, as_cmap = True)\nsns.heatmap(temp2.ix[:,0:30], xticklabels=3, cmap=cmap, linewidths=0.05)","outputs":[],"cell_type":"code","metadata":{"_uuid":"6d0dd832fe4ce7c72c1b0b408cc44bf3f6a91c49","scrolled":true,"_cell_guid":"952dc5fc-cfd7-4410-8123-76a73daaa37c"},"execution_count":287},{"source":"<h4>How are the genres and revenue related over the years if we remove the outliers from revenue and budget?</h4>\n<span style=\"color:red\">Nog een heatmap toevoegen voor genres en profit waarbij de outliners van budget en revenue zijn verwijderd.","cell_type":"markdown","metadata":{"_uuid":"366b7deb1b5c1acbb785d6ce0580e58507213bf7","_cell_guid":"de05b6bd-114f-4311-9d7c-244cf67175f2"}},{"source":"<span style=\"color:red\">Wat willen over de onderstaande tabel zeggen?","cell_type":"markdown","metadata":{"_uuid":"3bbf1ca49b091c284066c93309710dfce0691f26","_cell_guid":"73397584-eb64-45e5-98ec-e1a588c70ee6"}},{"source":"from datetime import datetime\n\ndf_genre = pd.DataFrame(columns = ['genre', 'cgenres', 'budget', 'gross', 'year'])\n#list(map(datetime.year, df_reduced[\"release_date\"]))\nt = df['release_date']\nt = pd.to_datetime(t)\nt = t.dt.year\ndf_genre['release_year'] = t\n\ncolnames = ['budget', 'genres', 'revenue']\ndf_clean = df[colnames]\ndf_clean['release_year'] = t\ndf_clean = df_clean.dropna()\ndf_genre = df_genre.dropna()\ndf_clean.head()","outputs":[],"cell_type":"code","metadata":{"_uuid":"02d374f7c8d9481fff775f0d0dea1b1e49173ca1","_cell_guid":"e433ee46-12dc-4323-98e5-ddadfd01d86e"},"execution_count":288},{"source":"<h4>Which genres are related to each other?</h4>\nDue to the fact that each movie can be subdivide into several genres. In the graph below is show to what extend the genres are raelated to each other.","cell_type":"markdown","metadata":{"_uuid":"a5127292a35fa810c0dd99e0966304488703ae42","_cell_guid":"7112fccf-48eb-470b-abf8-5e46bf5ade96"}},{"source":"def genreRemap(row):\n    global df_genre\n    d = {}\n    genres = np.array(row['genres'].split('|'))\n    n = genres.size\n    d['budget'] = [row['budget']]*n\n    d['revenue'] = [row['revenue']]*n\n    d['year'] = [row['release_year']]*n\n    d['genre'], d['cgenres'] = [], []\n    for genre in genres:\n        d['genre'].append(genre)\n        d['cgenres'].append(genres[genres != genre])\n    df_genre = df_genre.append(pd.DataFrame(d), ignore_index = True)\n\ndf_clean.apply(genreRemap, axis = 1)\ndf_genre['year'] = df_genre['year'].astype(np.int16)\ndf_genre = df_genre[['genre', 'budget', 'gross', 'year', 'cgenres']]","outputs":[],"cell_type":"code","metadata":{"_uuid":"c55730f23f7b53d4c1f5cba8ee7dd3e7c47fca1c","_cell_guid":"95b750ac-70b0-4706-9fce-5ab7d7eabf22","collapsed":true},"execution_count":289},{"source":"####################\n# make connections #\n####################\nd_genre = {}\ndef connect(row):\n    global d_genre\n    genre = row['genre']\n    cgenres = row['cgenres']\n    if genre not in d_genre:\n        d_cgenres = dict(zip(cgenres, [1]*len(cgenres)))\n        d_genre[genre] = d_cgenres\n    else:\n        for cgenre in cgenres:\n            if cgenre not in d_genre[genre]:\n                d_genre[genre][cgenre] = 1\n            else:\n                d_genre[genre][cgenre] += 1\n                \ndf_genre.apply(connect, axis = 1)\nl_genre = list(d_genre.keys())\nl_genre.sort()\n###########################\n# find largest connection #\n###########################\ncmax = 0\nfor key in d_genre:\n    for e in d_genre[key]:\n        if d_genre[key][e] > cmax:\n            cmax = d_genre[key][e]\n#########################\n# visualize connections #\n#########################\nfrom matplotlib.path import Path\nimport matplotlib.patches as patches\nfrom matplotlib import cm\ncolor = cm.get_cmap('rainbow')\nf, ax = plt.subplots(figsize = (7, 9))\n\ncodes = [Path.MOVETO, Path.CURVE4, Path.CURVE4, Path.CURVE4]\n\nX, Y = 1, 1\nwmin, wmax = 1, 32\namin, amax = 0.1, 0.25\ngetPy = lambda x: Y*(1 - x/len(l_genre))\nfor i, genre in enumerate(l_genre):\n    yo = getPy(i)\n    ax.text(0, yo, genre, ha = 'right')\n    ax.text(X, yo, genre, ha = 'left')\n    for cgenre in d_genre[genre]:\n        yi = getPy(l_genre.index(cgenre))\n        verts = [(0.0, yo), (X/4, yo), (2*X/4, yi), (X, yi)]\n        path = Path(verts, codes)\n        r, g, b, a = color(i/len(l_genre))\n        width = wmin + wmax*d_genre[genre][cgenre]/cmax\n        alpha = amin + amax*(1 - d_genre[genre][cgenre]/cmax)\n        patch = patches.PathPatch(path, facecolor = 'none', edgecolor = (r, g, b), lw = width, alpha = alpha)\n        ax.add_patch(patch)\n\nax.grid(False)\nax.set_xlim(0.0, X)\nax.set_ylim(0.0, Y + 1/len(l_genre))\nax.set_yticklabels([])\nax.set_xticklabels([])\nplt.show()","outputs":[],"cell_type":"code","metadata":{"_uuid":"9ecabdecd9d81edc3b69eb65ab1f6bef14055d8f","_cell_guid":"6d2da110-8bff-4dc7-ab41-72e4208982a0"},"execution_count":290},{"source":"<h2> Part 3: Analyse keywords </h2>\n\nNow we have some more insight on the different genres, let's take a look at different keywords. Are there keywords which influence a movie's rating in one way or another? What about the revenue? We take quite the same approach as with our genre analysis.","cell_type":"markdown","metadata":{"_uuid":"629e601b009600b68ea3867751906b344a921215","_cell_guid":"39ec958e-d710-4260-bf9c-bdca90c9e5cd"}},{"source":"credits = load_tmdb_credits(\"../input/tmdb_5000_credits.csv\")\nmovies = load_tmdb_movies(\"../input/tmdb_5000_movies.csv\")\n\ndel credits['title']\ndf = pd.concat([movies, credits], axis=1)\n\ndf['keywords'] = df['keywords'].apply(pipe_flatten_names)\n\nliste_keywords = set()\nfor s in df['keywords'].str.split('|'):\n    liste_keywords = set().union(s, liste_keywords)\nliste_keywords = list(liste_keywords)\nliste_keywords.remove('')","outputs":[],"cell_type":"code","metadata":{"_uuid":"95a2d19b494bfde93f5857d304696e4400526e58","_cell_guid":"0252027f-4c35-4c35-a42e-6b63ed0fde24","collapsed":true},"execution_count":291},{"source":"<h4>Which keywords occur the most in the dataset?</h4>\nWe use the following function to count them.","cell_type":"markdown","metadata":{"_uuid":"3a6af05a8d23335366cce16e48b7a94c872173fb","_cell_guid":"bdd0d14b-554b-497d-981f-ca6b1b4d26e1"}},{"source":"def count_word(df, ref_col, liste):\n    keyword_count = dict()\n    for s in liste: keyword_count[s] = 0\n    for liste_keywords in df[ref_col].str.split('|'):        \n        if type(liste_keywords) == float and pd.isnull(liste_keywords): continue        \n        for s in [s for s in liste_keywords if s in liste]: \n            if pd.notnull(s): keyword_count[s] += 1\n    #______________________________________________________________________\n    # convert the dictionary in a list to sort the keywords by frequency\n    keyword_occurences = []\n    for k,v in keyword_count.items():\n        keyword_occurences.append([k,v])\n    keyword_occurences.sort(key = lambda x:x[1], reverse = True)\n    return keyword_occurences, keyword_count","outputs":[],"cell_type":"code","metadata":{"_uuid":"f1156c43f08662f1501a1814dcf6bf292171e1c5","_cell_guid":"858af055-9d30-404f-b47f-7a9ff0cf2803","collapsed":true},"execution_count":292},{"source":"keyword_occurences, dum = count_word(df, 'keywords', liste_keywords)\nkeyword_occurences[:5]","outputs":[],"cell_type":"code","metadata":{"_uuid":"3d9693531b2c93f83101bd1486daf1acca54fd77","_cell_guid":"d9fbf94d-7af2-404e-be0f-f8462272361a"},"execution_count":293},{"source":"#We collect all the keywords:\ndef keywords_inventory(dataframe, colonne = 'keywords'):\n    PS = nltk.stem.PorterStemmer()\n    keywords_roots  = dict()  # collect the words / root\n    keywords_select = dict()  # association: root <-> keyword\n    category_keys = []\n    icount = 0\n    for s in dataframe[colonne]:\n        if pd.isnull(s): continue\n        for t in s.split('|'):\n            t = t.lower() ; racine = PS.stem(t)\n            if racine in keywords_roots:                \n                keywords_roots[racine].add(t)\n            else:\n                keywords_roots[racine] = {t}\n    \n    for s in keywords_roots.keys():\n        if len(keywords_roots[s]) > 1:  \n            min_length = 1000\n            for k in keywords_roots[s]:\n                if len(k) < min_length:\n                    clef = k ; min_length = len(k)            \n            category_keys.append(clef)\n            keywords_select[s] = clef\n        else:\n            category_keys.append(list(keywords_roots[s])[0])\n            keywords_select[s] = list(keywords_roots[s])[0]\n                   \n    print(\"Nb of keywords in variable '{}': {}\".format(colonne,len(category_keys)))\n    return category_keys, keywords_roots, keywords_select","outputs":[],"cell_type":"code","metadata":{"_uuid":"490443b747511fea2cff690b00f31e0b4b6a05ef","_cell_guid":"887d0ce0-788b-47d6-b1c8-e630fa758875","collapsed":true},"execution_count":294},{"source":"<h4>Roots</h4>\nOf course, different movies use different keywords for their movies. A problem is, that often a lot of those keywords are the same, although they are communicated in a different form by the different movie producers. The function above inventorizes the different keywords using nltk. The package identifies the 'roots' of different words and groups the different words according to its root. Then, we can replace the words that have a common root with their root. In this way, similar words that are phrased differently are assigned a common 'root'.\n\nWhen executing the function, it also shows the amount of different keywords, 9474 in our case.","cell_type":"markdown","metadata":{"_uuid":"ba5d3c30f952eada0cf0af656ef3b4ce63710616","_cell_guid":"859179e5-39ca-4109-b996-1048289d2a2e"}},{"source":"keywords, keywords_roots, keywords_select = keywords_inventory(df, colonne = 'keywords')","outputs":[],"cell_type":"code","metadata":{"_uuid":"1a49b20fbd62da97aefc1146591914489663c879","_cell_guid":"6ef0456c-6c6e-4d25-a23e-f9b4fe825dc7"},"execution_count":295},{"source":"Below are 14 examples of different words with similar roots.","cell_type":"markdown","metadata":{"_uuid":"daf1fa6f9ad0e9a51fddf4834d44ba1a8e663d8a","_cell_guid":"e6144782-b79b-4cca-95fb-c4fd367b0ad9"}},{"source":"# Plot of a sample of keywords that appear in close varieties \n#------------------------------------------------------------\nicount = 0\nfor s in keywords_roots.keys():\n    if len(keywords_roots[s]) > 1: \n        icount += 1\n        if icount < 15: print(icount, keywords_roots[s], len(keywords_roots[s]))","outputs":[],"cell_type":"code","metadata":{"_uuid":"0bf9044ba1ebeeb9beae695874a4b39343d72a46","_cell_guid":"ebf00714-3615-48f5-b824-fdeae4240c60"},"execution_count":296},{"source":"The function below replaces the different forms of the words by their root.","cell_type":"markdown","metadata":{"_uuid":"7986a63a36adfa9532966a080ecd038ff1df8884","_cell_guid":"1483763a-ab10-4d8c-8f1d-74177870da32"}},{"source":"def remplacement_df_keywords(df, dico_remplacement, roots = False):\n    df_new = df.copy(deep = True)\n    for index, row in df_new.iterrows():\n        chaine = row['keywords']\n        if pd.isnull(chaine): continue\n        nouvelle_liste = []\n        for s in chaine.split('|'): \n            clef = PS.stem(s) if roots else s\n            if clef in dico_remplacement.keys():\n                nouvelle_liste.append(dico_remplacement[clef])\n            else:\n                nouvelle_liste.append(s)       \n        df_new.set_value(index, 'keywords', '|'.join(nouvelle_liste)) \n    return df_new\n","outputs":[],"cell_type":"code","metadata":{"_uuid":"71efee355fad46b8358dcef73d9a9de54bd63ae2","_cell_guid":"680377ec-4a53-48d6-9f3f-33c9716dbd75","collapsed":true},"execution_count":297},{"source":"We store the cleaned keywords in a new dataframe.","cell_type":"markdown","metadata":{"_uuid":"25480dda935e107aebf1518232b5f303ad0c8411","_cell_guid":"3e865529-ca64-4475-9c24-f6eb2231a0de"}},{"source":"df_keywords_cleaned = remplacement_df_keywords(df, keywords_select,roots = True)\ndf_keywords_cleaned.head()","outputs":[],"cell_type":"code","metadata":{"_uuid":"0b66be3f7a30cfe365c326a3b1f90cfcee4f04be","_cell_guid":"efbada6a-54c0-4176-9579-1de2cd9b4309"},"execution_count":298},{"source":"<h4>Synonyms</h4>\nNext, we will use the nltk package to get rid of synonyms. The function below take a word as a parameter and returns all of the synonyms of that word according to the nltk package.","cell_type":"markdown","metadata":{"_uuid":"9b69edab7b1ca0d6b306836eeb62ee9813e92c32","_cell_guid":"e4f111fe-e7f3-4d9e-9e0e-0772956d7eb6"}},{"source":"def get_synonymes(word):\n    lemma = set()\n    for ss in wordnet.synsets(word):\n        for w in ss.lemma_names():\n            #_______________________________\n            # We just get the 'nouns':\n            index = ss.name().find('.')+1\n            if ss.name()[index] == 'n': lemma.add(w.lower().replace('_',' '))\n    return lemma   \n","outputs":[],"cell_type":"code","metadata":{"_uuid":"1c95bcce2a82dbf444f5090e186b51abdb621dc4","_cell_guid":"3884baf3-36da-4871-86b3-1a229e35eec7","collapsed":true},"execution_count":299},{"source":"def test_keyword(mot, key_count, threshold):\n    return (False , True)[key_count.get(mot, 0) >= threshold]","outputs":[],"cell_type":"code","metadata":{"_uuid":"e01172d7e172fad3c1d215c5f81b5b717feda6a2","_cell_guid":"f650fccb-e006-49e9-ac01-216da0af099f","collapsed":true},"execution_count":300},{"source":"keyword_occurences.sort(key = lambda x:x[1], reverse = False)\nkey_count = dict()\nfor s in keyword_occurences:\n    key_count[s[0]] = s[1]\n#__________________________________________________________________________\n# Creation of a dictionary to replace keywords by higher frequency keywords\nremplacement_mot = dict()\nicount = 0\nfor index, [mot, nb_apparitions] in enumerate(keyword_occurences):\n    if nb_apparitions > 5: continue  # only the keywords that appear less than 5 times\n    lemma = get_synonymes(mot)\n    if len(lemma) == 0: continue     # case of the plurals\n    #_________________________________________________________________\n    liste_mots = [(s, key_count[s]) for s in lemma \n                  if test_keyword(s, key_count, key_count[mot])]\n    liste_mots.sort(key = lambda x:(x[1],x[0]), reverse = True)    \n    if len(liste_mots) <= 1: continue       # no replacement\n    if mot == liste_mots[0][0]: continue    # replacement by himself\n    icount += 1\n    if  icount < 8:\n        print('{:<12} -> {:<12} (init: {})'.format(mot, liste_mots[0][0], liste_mots))    \n    remplacement_mot[mot] = liste_mots[0][0]\n\nprint(90*'_'+'\\n'+'The replacement concerns {}% of the keywords.'\n      .format(round(len(remplacement_mot)/len(keywords)*100,2)))","outputs":[],"cell_type":"code","metadata":{"_uuid":"19b16bc18a1304995cb209578f482b8a0db12b03","_cell_guid":"d33569e8-eb42-49b0-9cbd-ab986cac47ee"},"execution_count":301},{"source":"# 2 successive replacements\n#---------------------------\nprint('Keywords that appear both in keys and values:'.upper()+'\\n'+45*'-')\nicount = 0\nfor s in remplacement_mot.values():\n    if s in remplacement_mot.keys():\n        icount += 1\n        if icount < 10: print('{:<20} -> {:<20}'.format(s, remplacement_mot[s]))\n\nfor key, value in remplacement_mot.items():\n    if value in remplacement_mot.keys():\n        remplacement_mot[key] = remplacement_mot[value]            ","outputs":[],"cell_type":"code","metadata":{"_uuid":"687fcafa942ee7a879bdbe2d5e2b99635aa68a7f","_cell_guid":"36817be2-1cac-478e-bb82-6c53af76dbf8"},"execution_count":302},{"source":"# replacement of keyword varieties by the main keyword\n#----------------------------------------------------------\ndf_keywords_synonyms = remplacement_df_keywords(df_keywords_cleaned, remplacement_mot, roots = False)   \nkeywords, keywords_roots, keywords_select = keywords_inventory(df_keywords_synonyms, colonne = 'keywords')","outputs":[],"cell_type":"code","metadata":{"_uuid":"12f7fc8c03ccc21459c3f95b1045febcda572330","_cell_guid":"0b3d0c79-f4a3-4fb1-ae41-92e6b63227cc"},"execution_count":303},{"source":"# New count of keyword occurences\n#-------------------------------------\nkeywords.remove('')\nnew_keyword_occurences, keywords_count = count_word(df_keywords_synonyms,\n                                                    'keywords',keywords)\nnew_keyword_occurences[:5]","outputs":[],"cell_type":"code","metadata":{"_uuid":"b8273f0249af9c1e3c17f17d16185c360b028126","_cell_guid":"171a37cd-5df8-4874-aefe-f1baa6cd2a87"},"execution_count":304},{"source":"# deletion of keywords with low frequencies\n#-------------------------------------------\ndef remplacement_df_low_frequency_keywords(df, keyword_occurences):\n    df_new = df.copy(deep = True)\n    key_count = dict()\n    for s in keyword_occurences: \n        key_count[s[0]] = s[1]    \n    for index, row in df_new.iterrows():\n        chaine = row['keywords']\n        if pd.isnull(chaine): continue\n        nouvelle_liste = []\n        for s in chaine.split('|'): \n            if key_count.get(s, 4) > 3: nouvelle_liste.append(s)\n        df_new.set_value(index, 'keywords', '|'.join(nouvelle_liste))\n    return df_new","outputs":[],"cell_type":"code","metadata":{"_uuid":"3346e0ec7dfad0fa69b2e9a752b2e77730f0f119","_cell_guid":"6f467b3c-5de1-419b-b71f-b5739f59442a","collapsed":true},"execution_count":305},{"source":"If we analyze the amount of keywords again, we see a drastic decrease in different keywords","cell_type":"markdown","metadata":{"_uuid":"cfce2b64520d2593d3cd5be89fa5bc9f6a4c2ecc","_cell_guid":"970c19b4-cf1e-449d-8de6-7794cc771e2d"}},{"source":"# Creation of a dataframe where keywords of low frequencies are suppressed\n#-------------------------------------------------------------------------\ndf_keywords_occurence = remplacement_df_low_frequency_keywords(df_keywords_synonyms, new_keyword_occurences)\nkeywords, keywords_roots, keywords_select = keywords_inventory(df_keywords_occurence, colonne = 'keywords')   ","outputs":[],"cell_type":"code","metadata":{"_uuid":"f5891c2ea15edf2a050bd81562b2ffbb2a82d297","_cell_guid":"5d50ce19-525f-49d9-9215-6e531d091667"},"execution_count":306},{"source":"df_keywords_occurence.head()","outputs":[],"cell_type":"code","metadata":{"_uuid":"d21269a4a94e4251bf562d137838491123a2c239","_cell_guid":"d330ea5d-621e-4f60-82ac-6e2e675a2085"},"execution_count":307},{"source":"Now let's try to analyze the influence of keywords on movie ratings or revenue. We apply the same method as where we analyzed the genres.","cell_type":"markdown","metadata":{"_uuid":"92cf6f5df1873a8762458d587b76ebe96c24409f","_cell_guid":"82f95597-f595-4a59-9634-ba95994887ef"}},{"source":"df_keywords= df_keywords_occurence\nkeyword_list = set()\nfor s in df_keywords['keywords'].str.split('|'):\n    keyword_list = set().union(s, keyword_list)\nkeyword_list = list(keyword_list)\nkeyword_list.remove('')\nkeyword_list[:5]","outputs":[],"cell_type":"code","metadata":{"_uuid":"34caaabd9cd83b0a84f0f65286ce9101f4422c74","_cell_guid":"6ce5047c-5b7f-4b36-8b6d-fb305baf720d"},"execution_count":308},{"source":"df_reduced = df_keywords[['title','vote_average','release_date','runtime','budget','revenue']].reset_index(drop=True)\n\nfor keyword in keyword_list:\n    df_reduced[keyword] = df['keywords'].str.contains(keyword).apply(lambda x:1 if x else 0)\ndf_reduced[:5]\n\ndf_reduced.head()\n","outputs":[],"cell_type":"code","metadata":{"_uuid":"e6bc8089dc0782381ae7947668d9579a2a849e7d","_cell_guid":"9d630a2e-34e6-44c8-b6b5-003f5d6cb690"},"execution_count":309},{"source":"mean_per_keyword = pd.DataFrame(keyword_list)\n\n#Mean votes average\nnewArray1 = []*len(keyword_list)\nfor keyword in keyword_list:\n    newArray1.append(df_reduced.groupby(keyword, as_index=True)['vote_average'].mean())\n    \n#Mean budget\nnewArray2 = []*len(keyword_list)\nfor keyword in keyword_list:\n    newArray2.append(df_reduced.groupby(keyword, as_index=True)['budget'].mean())\n    \n#Mean revenue\nnewArray3 = []*len(keyword_list)\nfor keyword in keyword_list:\n    newArray3.append(df_reduced.groupby(keyword, as_index=True)['revenue'].mean())\n\nmean_per_keyword['mean_vote_average']=list(pd.DataFrame(newArray1)[1])\nmean_per_keyword['mean_budget']=list(pd.DataFrame(newArray2)[1])\nmean_per_keyword['mean_revenue']=list(pd.DataFrame(newArray3)[1])\n\n","outputs":[],"cell_type":"code","metadata":{"_uuid":"a67a7a1fc1c2761f7dfc70a9b3a59b52433fe4b8","_cell_guid":"e38409f5-b6c2-4379-9b08-cc1d4151ba77","collapsed":true},"execution_count":310},{"source":"<h4>Which genre is best scoring in the catagories mean votes average, mean budget and mean revenue?","cell_type":"markdown","metadata":{"_uuid":"bd13f35689af3569a22a48ac814f4add5247d7a9","_cell_guid":"c71c5b29-c479-4d9f-bacc-1fe1ff04cd74"}},{"source":"mean_per_keyword.sort_values('mean_vote_average', ascending=False).head()","outputs":[],"cell_type":"code","metadata":{"_uuid":"ff8927b0a51c48321b37393c70ad0b4ae272c16c","_cell_guid":"7b808f80-5863-4d90-a09a-a5ca54472338"},"execution_count":311},{"source":"mean_per_keyword.sort_values('mean_budget', ascending=False).head()","outputs":[],"cell_type":"code","metadata":{"_uuid":"e6f4260d7b170a02fbd10c62d57e60b85ea7ba15","_cell_guid":"741144fe-1511-4420-9ef6-99fe02bbdd5e"},"execution_count":312},{"source":"mean_per_keyword.sort_values('mean_revenue', ascending=False).head()","outputs":[],"cell_type":"code","metadata":{"_uuid":"a1193748d6b64b3f0f0b5b3cde8180ff71e40ddc","_cell_guid":"080d32de-ac33-40e0-8125-4faa695a594a"},"execution_count":313},{"source":"We want to create the tables above again, but then for only the 50 most occuring keywords. Of course it's cool to see the keywords 'hobbit' and 'school of witchcraft' as high-revenue-keywords, but they probably don't occur outside of he Lord of the Rings and Harry Potter movies, so they're actually not that interesting. We start by showing the 50 most occuring keywords in a bar plot.","cell_type":"markdown","metadata":{"_uuid":"90e04011918dae3a024043f4c7f8c57e09df09a8","_cell_guid":"86119167-680f-4a0a-8d82-388bfd2b931d"}},{"source":"fig = plt.figure(1, figsize=(18,13))\ntrunc_occurences = new_keyword_occurences[0:50]\n# LOWER PANEL: HISTOGRAMS\nax2 = fig.add_subplot(2,1,2)\ny_axis = [i[1] for i in trunc_occurences]\nx_axis = [k for k,i in enumerate(trunc_occurences)]\nx_label = [i[0] for i in trunc_occurences]\nplt.xticks(rotation=85, fontsize = 15)\nplt.yticks(fontsize = 15)\nplt.xticks(x_axis, x_label)\nplt.ylabel(\"Nb. of occurences\", fontsize = 18, labelpad = 10)\nax2.bar(x_axis, y_axis, align = 'center', color='g')\n#_______________________\nplt.title(\"Keywords popularity\",bbox={'facecolor':'k', 'pad':5},color='w',fontsize = 25)\nplt.show()","outputs":[],"cell_type":"code","metadata":{"_uuid":"0eb14a47a23db6b330c2c8e961fb8b0c4c2610b3","_cell_guid":"4367f75d-28d5-43f9-bcbb-d787e5c61b6f"},"execution_count":314},{"source":"We now create a data frame with average movie scores, budget and revenue for the most occuring keywords.","cell_type":"markdown","metadata":{"_uuid":"aaf102ebe03fd111534978a3ec9a3a47ea23a926","_cell_guid":"36846e71-ba87-4a2d-9701-dc7a86357a20"}},{"source":"Df1 = pd.DataFrame(trunc_occurences)\nDf2 = mean_per_keyword\nresult = Df1.merge(Df2, left_on=0, right_on=0, how='inner')","outputs":[],"cell_type":"code","metadata":{"_uuid":"fa47ceb4780597be1aa5761ab886a504d3c06068","_cell_guid":"8546b962-703f-420f-97d7-9babd5b81e47","collapsed":true},"execution_count":315},{"source":"result = result.rename(columns ={0:'keyword', 1:'occurences'})","outputs":[],"cell_type":"code","metadata":{"_uuid":"d910c0130216edc0bd8237e58dcebc34560fdf78","_cell_guid":"f181b59e-a139-4af1-867e-f018242b7024","collapsed":true},"execution_count":316},{"source":"result.sort_values('mean_vote_average', ascending= False)","outputs":[],"cell_type":"code","metadata":{"_uuid":"e3a139d93f69f7ac71cf4ee99abc6d35de279862","_cell_guid":"c6c74b46-72eb-46b2-828a-cc8425ad1e0b"},"execution_count":317},{"source":"Let's try to visualize this table a little bit clearer. We want to see which keywords pop out, so let's make a few plots.","cell_type":"markdown","metadata":{"_uuid":"0fa75007f3f58f0977ca1f30c6aba75cba078a36","_cell_guid":"7576d66b-18c7-459e-8ef3-ff0286cfe167"}},{"source":"result['mean_vote_average'].mean()","outputs":[],"cell_type":"code","metadata":{"_uuid":"ca59e15b1734e23aaaa67bfc916ccadcd56aac5a","_cell_guid":"c5ba6bab-e846-4cd5-9fe1-fd56ae92c70a"},"execution_count":318},{"source":"import matplotlib.pyplot as plt\n\nax = result.plot.bar(x = 'keyword', y='mean_vote_average', title=\"mean vote average\",\n                     figsize=(15,4), legend=True, fontsize=12, color='green', label = \"mean vote average\")\nax.set_ylim(5, 8)\nax.axhline(y=result['mean_vote_average'].mean(),c=\"blue\",linewidth=0.5, label='mean')\nax.legend()\nplt.show()\n","outputs":[],"cell_type":"code","metadata":{"_uuid":"f98564c950ac068c0858fb18cf5f98c498028787","_cell_guid":"73729736-2c35-4d58-82e6-c66aa86cb844"},"execution_count":319},{"source":"import matplotlib.pyplot as plt\n\nax = result.plot.bar(x = 'keyword', y='mean_budget', title=\"mean budget\",\n                     figsize=(15,4), legend=True, fontsize=12, color='green', label=\"mean budget\")\nax.axhline(y=result['mean_budget'].mean(),c=\"blue\",linewidth=0.5, label='mean')\nax.legend()\nplt.show()\n","outputs":[],"cell_type":"code","metadata":{"_uuid":"0293b9d1cf20fe2a62f4f9cd3a256db728a1656a","_cell_guid":"2573bbd5-e596-4321-aa50-5edc07ea433c"},"execution_count":320},{"source":"result.sort_values('mean_budget').head()","outputs":[],"cell_type":"code","metadata":{"_uuid":"0d518f0f3a45ce615a10d3227fc17853842ef4a1","_cell_guid":"bbdecc3b-ac47-4643-a3af-57c48f2b4498"},"execution_count":321},{"source":"Now this is interesting. The keyword with by far the highest average rating - Serial Killer - also has by far the lowest average budget. Also note that superhero movies score below average, but have a highly above average budget. Let's take a look at the revenue:","cell_type":"markdown","metadata":{"_uuid":"a67206a07063a34af855e06a0e8a7629c67351e9","_cell_guid":"29598d67-3df4-44cf-bb4c-4f2bfc3cb765"}},{"source":"ax = result.plot.bar(x = 'keyword', y='mean_revenue', title=\"mean revenue\",\n                     figsize=(15,4), legend=True, fontsize=12, color='green', label=\"mean revenue\")\nax.axhline(y=result['mean_revenue'].mean(),c=\"blue\",linewidth=0.5, label='mean')\nax.legend()\nplt.show()","outputs":[],"cell_type":"code","metadata":{"_uuid":"67a6211082aa101ac18a3566ced6944bcde91bf4","_cell_guid":"6ec7b5f3-5b0d-4d75-ab02-164727a57e0d"},"execution_count":322},{"source":"So superhero movies do have a high revenue and serial killer movies do not. Let's take a look at the differences:","cell_type":"markdown","metadata":{"_uuid":"571a564001bdd0429c14f38c64829a70a00cc63e","_cell_guid":"b2b13461-250f-4d34-8faa-08d5d1742635"}},{"source":"result['profit'] = result['mean_revenue'] - result['mean_budget']\nresult.head()","outputs":[],"cell_type":"code","metadata":{"_uuid":"9df34d504441e45dfe5d336fdab8f3ce6dee19b3","_cell_guid":"0f9a98f2-8392-4bdc-af3d-b365d020fb8d"},"execution_count":323},{"source":"ax = result.plot.bar(x = 'keyword', y='profit', title=\"profit\",\n                     figsize=(15,4), legend=True, fontsize=12, color='green', label=\"profit\")\nax.axhline(y=result['profit'].mean(),c=\"blue\",linewidth=0.5, label='mean')\nax.legend()\nplt.show()","outputs":[],"cell_type":"code","metadata":{"_uuid":"00750cf65798f355155a7a0da2c5dd4d43f713a1","_cell_guid":"ce1dc048-7e3a-4463-a2c6-96262a66cb8c"},"execution_count":324},{"source":"What's also notable is that despite the popularity of female directors and independent movies, they do not have high scores on either revenue or vote_average.","cell_type":"markdown","metadata":{"_uuid":"ab4a6fc1177a8144a9914451652b67e405aa4cc9","_cell_guid":"7e0058e2-76d5-4fb0-ad3d-6ba7f87caf81"}},{"source":"<h2> Part 4: Analyse Actors\n\nPart 4 contains is about the actors of the movies. We analyse which actors made the most revenue, resulted in a high IMDB score, and played in movies with the highest budgets. We also made a graph that contains information about the average budget and every revenue per actor. Lastly, we made a clear overview for all the movies Morgan Freeman played in and what the IMDB scores where. The main purpuse of this part is getting more insight in the data and answering the following questions:  <br> \n    - Which actors played in movies with the highest revenue/highest budget/ highest IMDB score?\n    \n","cell_type":"markdown","metadata":{"_uuid":"93c2d0a792e189dbac84885febe46cbc6edab8eb","_cell_guid":"404bc425-8324-4bbb-8c1b-d87fd412ccc9"}},{"source":"A previous version of this dataset only contained the top three actors per movie. Since we only want to analyze the most important actors of a movie and since the old dataset was a bit more suited to do that, we convert the dataset back to its previous state using Sohier Dane's method.","cell_type":"markdown","metadata":{"_uuid":"c721debe3548cc66e2642de11f1257f5424bd764","_cell_guid":"b639f1db-66bc-4fcb-9d92-979cf76df105"}},{"source":"# Columns that existed in the IMDB version of the dataset and are gone.\nLOST_COLUMNS = [\n    'actor_1_facebook_likes',\n    'actor_2_facebook_likes',\n    'actor_3_facebook_likes',\n    'aspect_ratio',\n    'cast_total_facebook_likes',\n    'color',\n    'content_rating',\n    'director_facebook_likes',\n    'facenumber_in_poster',\n    'movie_facebook_likes',\n    'movie_imdb_link',\n    'num_critic_for_reviews',\n    'num_user_for_reviews'\n                ]\n\n# Columns in TMDb that had direct equivalents in the IMDB version. \n# These columns can be used with old kernels just by changing the names\nTMDB_TO_IMDB_SIMPLE_EQUIVALENCIES = {\n    'budget': 'budget',\n    'genres': 'genres',\n    'revenue': 'gross',\n    'title': 'movie_title',\n    'runtime': 'duration',\n    'original_language': 'language',  # it's possible that spoken_languages would be a better match\n    'keywords': 'plot_keywords',\n    'vote_count': 'num_voted_users',\n                                         }\n\nIMDB_COLUMNS_TO_REMAP = {'imdb_score': 'vote_average'}\n\n\ndef safe_access(container, index_values):\n    # return a missing value rather than an error upon indexing/key failure\n    result = container\n    try:\n        for idx in index_values:\n            result = result[idx]\n        return result\n    except IndexError or KeyError:\n        return pd.np.nan\n\n\ndef get_director(crew_data):\n    directors = [x['name'] for x in crew_data if x['job'] == 'Director']\n    return safe_access(directors, [0])\n\n\ndef pipe_flatten_names(keywords):\n    return '|'.join([x['name'] for x in keywords])\n\n\ndef convert_to_original_format(movies, credits):\n    # Converts TMDb data to make it as compatible as possible with kernels built on the original version of the data.\n    tmdb_movies = movies.copy()\n    tmdb_movies.rename(columns=TMDB_TO_IMDB_SIMPLE_EQUIVALENCIES, inplace=True)\n    tmdb_movies['title_year'] = pd.to_datetime(tmdb_movies['release_date']).apply(lambda x: x.year)\n    # I'm assuming that the first production country is equivalent, but have not been able to validate this\n    tmdb_movies['country'] = tmdb_movies['production_countries'].apply(lambda x: safe_access(x, [0, 'name']))\n    tmdb_movies['language'] = tmdb_movies['spoken_languages'].apply(lambda x: safe_access(x, [0, 'name']))\n    tmdb_movies['director_name'] = credits['crew'].apply(get_director)\n    tmdb_movies['actor_1_name'] = credits['cast'].apply(lambda x: safe_access(x, [1, 'name']))\n    tmdb_movies['actor_2_name'] = credits['cast'].apply(lambda x: safe_access(x, [2, 'name']))\n    tmdb_movies['actor_3_name'] = credits['cast'].apply(lambda x: safe_access(x, [3, 'name']))\n    tmdb_movies['genres'] = tmdb_movies['genres'].apply(pipe_flatten_names)\n    tmdb_movies['plot_keywords'] = tmdb_movies['plot_keywords'].apply(pipe_flatten_names)\n    return tmdb_movies","outputs":[],"cell_type":"code","metadata":{"_uuid":"3d0a1b9cf958f2d8e2f134bdadaac2de0c338d1d","_cell_guid":"73fe22df-17f8-46a3-8bc7-e8e948e0cb43","collapsed":true},"execution_count":325},{"source":"credits = load_tmdb_credits(\"../input/tmdb_5000_credits.csv\")\nmovies = load_tmdb_movies(\"../input/tmdb_5000_movies.csv\")\ndf = convert_to_original_format(movies, credits)","outputs":[],"cell_type":"code","metadata":{"_uuid":"5ff299f54e04e0319df8fa19ac631ce67fbde1d1","_cell_guid":"1c7a0a0b-eace-44c9-a33b-bb724d13f36f","collapsed":true},"execution_count":326},{"source":"We can now see that the dataframe is simplified.","cell_type":"markdown","metadata":{"_uuid":"e5f6e3870f84432de8685e1944f942c495407264","_cell_guid":"1f964d44-b480-4a8e-8a24-654d2d48c088"}},{"source":"df.head()","outputs":[],"cell_type":"code","metadata":{"_uuid":"ced3ea87cb3112d21a40a5385ff52ac57f7bc2d5","_cell_guid":"e2d28b41-42bc-4e8d-be27-bf17d9eabe4b"},"execution_count":327},{"source":"df3 = df # We store a copy of the dataframe for later use","outputs":[],"cell_type":"code","metadata":{"_uuid":"34e2137cbfe9a3c6ad59584722f0eec901526a33","_cell_guid":"ec26ba50-7cd4-4aaf-ad9d-1cf76a05d41d","collapsed":true},"execution_count":328},{"source":"Next, we delete all the columns we won't be needing for this analysis.","cell_type":"markdown","metadata":{"_uuid":"203474446cccea2d3b41639e6150085b370baed6","_cell_guid":"bc9f2c91-a844-4e39-95d3-440456088abb"}},{"source":"columns = ['homepage', 'plot_keywords', 'language', 'overview', 'popularity', 'tagline',\n           'original_title', 'num_voted_users', 'country', 'spoken_languages', 'duration',\n          'production_companies', 'production_countries', 'status']\n\ndf = df.drop(columns, axis=1)","outputs":[],"cell_type":"code","metadata":{"_uuid":"303d2384c040f54b6963be0ed247593846544099","_cell_guid":"f77f0dfd-b679-4d1b-a3a2-d859ed70fc82","collapsed":true},"execution_count":329},{"source":"We are interested in the same descriptives for the actors, as we were for keywords and the genres. To do that, we first have to, once again, restructure the dataframe.\n\nWe first create a seperate dataframe for each of the three actors, after which we can combine them to get one dataframe with all three types of actor.","cell_type":"markdown","metadata":{"_uuid":"c78068b0d6d642424bdc3b2659ee3b26aacc7d22","_cell_guid":"4e0b23fa-e74e-4636-82ef-55a427c364c3"}},{"source":"liste_genres = set()\nfor s in df['genres'].str.split('|'):\n    liste_genres = set().union(s, liste_genres)\nliste_genres = list(liste_genres)\nliste_genres.remove('')","outputs":[],"cell_type":"code","metadata":{"_uuid":"34c837c3afe6a05b7398c687dfc764fcd2e19ed9","_cell_guid":"915b70e8-0719-4749-bb31-4beb57eb6859","collapsed":true},"execution_count":330},{"source":"df_reduced = df[['actor_1_name', 'vote_average',\n                 'title_year', 'movie_title', 'gross', 'budget']].reset_index(drop = True)\nfor genre in liste_genres:\n    df_reduced[genre] = df['genres'].str.contains(genre).apply(lambda x:1 if x else 0)\n\ndf_reduced2 = df[['actor_2_name', 'vote_average',\n                 'title_year', 'movie_title', 'gross', 'budget']].reset_index(drop = True)\nfor genre in liste_genres:\n    df_reduced2[genre] = df['genres'].str.contains(genre).apply(lambda x:1 if x else 0)\n\ndf_reduced3 = df[['actor_3_name', 'vote_average',\n                 'title_year', 'movie_title', 'gross', 'budget']].reset_index(drop = True)\nfor genre in liste_genres:\n    df_reduced3[genre] = df['genres'].str.contains(genre).apply(lambda x:1 if x else 0)\n","outputs":[],"cell_type":"code","metadata":{"_uuid":"0aa9e7c00d32c3c4b237f57bea749f61a6d260a3","_cell_guid":"3c83135e-4541-4c57-8141-044462db5316","collapsed":true},"execution_count":331},{"source":"Next, we combine the three dataframes.","cell_type":"markdown","metadata":{"_uuid":"316600b2833c63767af35bdb2db7d8aa92ea8e4b","_cell_guid":"54c24495-0170-4795-851e-10109a05e560"}},{"source":"df_reduced = df_reduced.rename(columns={'actor_1_name': 'actor'})\ndf_reduced2 = df_reduced2.rename(columns={'actor_2_name': 'actor'})\ndf_reduced3 = df_reduced3.rename(columns={'actor_3_name': 'actor'})\n\ntotal = [df_reduced, df_reduced2, df_reduced3]\ndf_total = pd.concat(total)\ndf_total.head()","outputs":[],"cell_type":"code","metadata":{"_uuid":"570611eea38d22e096047363e9c91d638aa81501","_cell_guid":"17e574d7-c3b3-4cd1-8b99-9cb08d0aa4b6"},"execution_count":332},{"source":"We compute averages for all actors in two categories: vote_average and title_year. We also compute an actors favorite genre.","cell_type":"markdown","metadata":{"_uuid":"ecbc47bfb4612efa78dad1271d062aefed43ad51","_cell_guid":"6e16cffc-ffe9-417f-9d3f-8d77ab24df89"}},{"source":"df_actors = df_total.groupby('actor').mean()\ndf_actors.loc[:, 'favored_genre'] = df_actors[liste_genres].idxmax(axis = 1)\ndf_actors.drop(liste_genres, axis = 1, inplace = True)\ndf_actors = df_actors.reset_index()","outputs":[],"cell_type":"code","metadata":{"_uuid":"fae6b9bcb92198c2db3a942d94de3320d3eb795e","_cell_guid":"4e4807f5-1bf1-4b27-95fd-36d3b128651e","collapsed":true},"execution_count":333},{"source":"We expect the dataframe to contain a lot of actors that have only a single observation. These observation are likely to cause outliers if these observations are very extreme. We delete all actors that are linked to less than 10 movies in our dataframe.","cell_type":"markdown","metadata":{"_uuid":"a3668f9374189a7025f1e1bf18a2ea508b709fe2","_cell_guid":"4db791aa-ea36-422b-af49-02b423177cfc"}},{"source":"df_appearance = df_total[['actor', 'title_year']].groupby('actor').count()\ndf_appearance = df_appearance.reset_index(drop = True)\nselection = df_appearance['title_year'] > 9\nselection = selection.reset_index(drop = True)\nmost_prolific = df_actors[selection]","outputs":[],"cell_type":"code","metadata":{"_uuid":"09495373643f62f2e46a52f2fe9992f4d62f1a9a","_cell_guid":"c32149d0-5b43-4f5f-b496-c19dbb3c3649","collapsed":true},"execution_count":334},{"source":"Now that we have a clear dataframe, let us show some descriptive statistics. We first sort the dataframe on all the different attributes from highest to lowest.","cell_type":"markdown","metadata":{"_uuid":"a30af7a1a8f8fcc8dd53137928c29caca78fff7c","_cell_guid":"ef8ff57e-4877-4278-b988-28adf1ee9a6a"}},{"source":"most_prolific.sort_values('vote_average', ascending=False).head()","outputs":[],"cell_type":"code","metadata":{"_uuid":"1d418870176c45c4650f2ac150a22b2bdb9f93e5","_cell_guid":"1e06e9f8-8a46-4eba-b7b6-2f38ee947341"},"execution_count":335},{"source":"most_prolific.sort_values('gross', ascending=False).head()","outputs":[],"cell_type":"code","metadata":{"_uuid":"0947f0f387f73eb63e021a6e21e7a12feae3c2de","_cell_guid":"3b67194a-14bd-4d25-92d0-79b0cd464b60"},"execution_count":336},{"source":"most_prolific.sort_values('budget', ascending=False).head()","outputs":[],"cell_type":"code","metadata":{"_uuid":"a385bef8520d7b99188a2e8ba6ca8cde46d6c651","_cell_guid":"44320deb-6038-4e58-aabf-ae6a8420dda7"},"execution_count":337},{"source":"Looks like Sir Ian McKellen has had quite a career. He came out on top on all three of our attributes. He plays in the movies with the highsest budget, but returns this with the highest average revenues. It makes sense that these enormous budgets lead to good movies. This is reflected by him having the highest average score on IMDB.\n\nWe can now develop several plots to analyze our actors. Let us start by plotting the average budget per actor and the average revenue per actor.","cell_type":"markdown","metadata":{"_uuid":"faf6d5f63cdeba52e53316e84eac25ec32b80c1b","_cell_guid":"d80e1167-c099-40c9-aa3a-897276571405"}},{"source":"genre_count = []\nfor genre in liste_genres:\n    genre_count.append([genre, df_reduced[genre].values.sum()])\ngenre_count.sort(key = lambda x:x[1], reverse = True)\nlabels, sizes = zip(*genre_count)\nlabels_selected = [n if v > sum(sizes) * 0.01 else '' for n, v in genre_count]\nreduced_genre_list = labels[:19]\ntrace=[]\nfor genre in reduced_genre_list:\n    trace.append({'type':'scatter',\n                  'mode':'markers',\n                  'y':most_prolific.loc[most_prolific['favored_genre']==genre,'gross'],\n                  'x':most_prolific.loc[most_prolific['favored_genre']==genre,'budget'],\n                  'name':genre,\n                  'text': most_prolific.loc[most_prolific['favored_genre']==genre,'actor'],\n                  'marker':{'size':10,'opacity':0.7,\n                            'line':{'width':1.25,'color':'black'}}})\nlayout={'title':'Actors favored genres',\n       'xaxis':{'title':'mean year of activity'},\n       'yaxis':{'title':'mean score'}}\nfig=Figure(data=trace,layout=layout)\npyo.iplot(fig)","outputs":[],"cell_type":"code","metadata":{"_uuid":"d810e2f9752ee7bed0ac19fac84aed7c9a6ff216","_cell_guid":"c7e339e8-ca15-4b34-846c-2da77c2e35e3"},"execution_count":338},{"source":"We can also use this data to highlight single actors. Let us take a look at actors for who we have data of more than 20 movies.","cell_type":"markdown","metadata":{"_uuid":"23dd5ecdaafec803ef3bc7b3aa363a91a53e2bd1","_cell_guid":"109b149c-7752-48da-859c-d9c09fb0ce7d"}},{"source":"selection = df_appearance['title_year'] > 20\nmost_prolific = df_actors[selection]\nmost_prolific","outputs":[],"cell_type":"code","metadata":{"_uuid":"03d6d5703bc5b88db349a977afde2c6791f0c124","_cell_guid":"bba677a1-32b5-475d-b67d-78fa07690088"},"execution_count":339},{"source":"So let's have a look at Morgan Freeman. We would like to have a clear overview of all the movies he played in and what his movies scored on IMDB. We can do this using a polar chart.","cell_type":"markdown","metadata":{"_uuid":"4516789fd884c2e0e5c89b86ab0582fc68af6215","_cell_guid":"9cd704ee-ce91-4402-abed-bbcc7a2d1765"}},{"source":"class Trace():\n    #____________________\n    def __init__(self, color):\n        self.mode = 'markers'\n        self.name = 'default'\n        self.title = 'default title'\n        self.marker = dict(color=color, size=110,\n                           line=dict(color='white'), opacity=0.7)\n        self.r = []\n        self.t = []\n    #______________________________\n    def set_color(self, color):\n        self.marker = dict(color = color, size=110,\n                           line=dict(color='white'), opacity=0.7)\n    #____________________________\n    def set_name(self, name):\n        self.name = name\n    #____________________________\n    def set_title(self, title):\n        self.na = title\n    #___________________________\n    def set_actor(self, actor):\n        self.actor = actor\n    \n    #__________________________\n    def set_values(self, r, t):\n        self.r = np.array(r)\n        self.t = np.array(t)","outputs":[],"cell_type":"code","metadata":{"_uuid":"5c28d8cf96279c2de7812c6eef3b101de03dd106","_cell_guid":"5fa7dcdc-b9a5-49e6-831f-856dd176e39c","collapsed":true},"execution_count":340},{"source":"names =['Morgan Freeman']\ndf2 = df_reduced[df_reduced['actor'] == 'Morgan Freeman']\ntotal_count  = 0\nyears = []\nimdb_score = []\ngenre = []\ntitles = []\nactor = []\nfor s in liste_genres:\n    icount = df2[s].sum()\n    #__________________________________________________________________\n    # Here, we set the limit to 3 because of a bug in plotly's package\n    if icount > 3: \n        total_count += 1\n        genre.append(s)\n        actor.append(list(df2[df2[s] ==1 ]['actor']))\n        years.append(list(df2[df2[s] == 1]['title_year']))\n        imdb_score.append(list(df2[df2[s] == 1]['vote_average'])) \n        titles.append(list(df2[df2[s] == 1]['movie_title']))\nmax_y = max([max(s) for s in years])\nmin_y = min([min(s) for s in years])\nyear_range = max_y - min_y\n\nyears_normed = []\nfor i in range(total_count):\n    years_normed.append( [360/total_count*((an-min_y)/year_range+i) for an in years[i]])","outputs":[],"cell_type":"code","metadata":{"_uuid":"6f3b491913c182bbc172b0c8127badeaf18eabc2","_cell_guid":"c9a796b4-7af6-436a-8139-eb185abdf3ec","collapsed":true},"execution_count":341},{"source":"color = ('royalblue', 'grey', 'wheat', 'c', 'firebrick', 'seagreen', 'lightskyblue',\n          'lightcoral', 'yellowgreen', 'gold', 'tomato', 'violet', 'aquamarine', 'chartreuse', 'red')","outputs":[],"cell_type":"code","metadata":{"_uuid":"bbb70c61e0a81f825fc57d8406767d34330da59a","_cell_guid":"98954d0c-da27-4f3a-8c81-3a4d264969a0","collapsed":true},"execution_count":342},{"source":"trace = [Trace(color[i]) for i in range(total_count)]\ntr    = []\nfor i in range(total_count):\n    trace[i].set_name(genre[i])\n    trace[i].set_title(titles[i])\n    trace[i].set_values(np.array(imdb_score[i]),\n                        np.array(years_normed[i]))\n    tr.append(go.Scatter(r      = trace[i].r,\n                         t      = trace[i].t,\n                         mode   = trace[i].mode,\n                         name   = trace[i].name,\n                         marker = trace[i].marker,\n#                         text   = ['default title' for j in range(len(trace[i].r))], \n                         hoverinfo = 'all'\n                        ))        \nlayout = go.Layout(\n    title='Morgan Freeman movies',\n    font=dict(\n        size=15\n    ),\n    plot_bgcolor='rgb(223, 223, 223)',\n    angularaxis=dict(        \n        tickcolor='rgb(253,253,253)'\n    ),\n    hovermode='Closest',\n)\nfig = go.Figure(data = tr, layout=layout)\npyo.iplot(fig)","outputs":[],"cell_type":"code","metadata":{"_uuid":"99e9ef677471b485fda8bdcc757338d3d78887fc","_cell_guid":"b528dabf-cbd2-4b61-ad67-2a3e5a9738fa"},"execution_count":343},{"source":"Unfortunately, plotly doesn't allow us to put hover text on the different notes. This means we can't add the movie name and year of release to all the different nodes.","cell_type":"markdown","metadata":{"_uuid":"39c138a4d542e4c342425bb872f71548f0d6ac1b","_cell_guid":"4cf7dc54-3521-4d45-a395-5c515f3aed8b"}},{"source":"# Director Analysis\n\nDirectors of movies are known as an important influence for the quality of a movie. This part will analyse the IMDB score per director. In this analyse we try to discover if the IMDB score of movies from high scoring directors are influenced by the budget. This brings us to the following questions: <br> \n<br> \nFor directors with more than 4/ and directors with more than 15 movies: \n    - Which directors have the highest revenue per movie?\n    - Which directors have the highest budget per movie?\n    - Do directors with high budgets also have high revenues? \n    \n    ","cell_type":"markdown","metadata":{"_uuid":"822b9a9a613129c0dfc8c17f21be88d76f2c6373","_cell_guid":"d520c45a-4211-4e46-bf71-2f072b399a93"}},{"source":"","cell_type":"markdown","metadata":{"_uuid":"92d7af5fbef7109c95da5046e858a809da0ff356","_cell_guid":"d0083beb-abf2-485c-b9d1-b647c2658974"}},{"source":"We start by retrieving the copy of the database we created earlier.","cell_type":"markdown","metadata":{"_uuid":"96b095424415714ad473e01aeb44e9666113dfd6","_cell_guid":"2894bb9f-85fe-48bc-810f-75cafbc740dd"}},{"source":"df = df3","outputs":[],"cell_type":"code","metadata":{"_uuid":"d01ce43e2dcaf016cf15dc73dedf5007c5164e5c","_cell_guid":"6b0a5569-26fc-4cf6-9d4e-da4288acd76b","collapsed":true},"execution_count":344},{"source":"We start the actual analysis by computing the average per movie and total gross of the directors. We only took into account the directs for which we have at least 4 movies as observations, to exclude extreme outliers. Not surprisingly, the top rated directors are probably directors you have heard about.","cell_type":"markdown","metadata":{"_uuid":"ef5c1c9e420ed90cbe1017fda551c94e526ff06a","_cell_guid":"dc2f8002-7e22-4b1e-a0da-b3cd3f098e44"}},{"source":"def create_comparison_database(name, value, x, no_films):\n    \n    comparison_df = df3.groupby(name, as_index=False)\n    \n    if x == 'mean':\n        comparison_df = comparison_df.mean()\n    elif x == 'median':\n        comparison_df = comparison_df.median()\n    elif x == 'sum':\n        comparison_df = comparison_df.sum() \n    \n    # Create database with either name of directors or actors, the value being compared i.e. 'gross',\n    # and number of films they're listed with. Then sort by value being compared.\n    name_count_key = df[name].value_counts().to_dict()\n    comparison_df['films'] = comparison_df[name].map(name_count_key)\n    comparison_df.sort_values(value, ascending=False, inplace=True)\n    comparison_df[name] = comparison_df[name].map(str) + \" (\" + comparison_df['films'].astype(str) + \")\"\n   # create a Series with the name as the index so it can be plotted to a subgrid\n    comp_series = comparison_df[comparison_df['films'] >= no_films][[name, value]][10::-1].set_index(name).ix[:,0]\n    \n    return comp_series","outputs":[],"cell_type":"code","metadata":{"_uuid":"ec9fa9d782bde418dd295a50f98b3df94a0c541c","_cell_guid":"9e871d0e-5c0c-4515-a78c-2c3a98d96f28","collapsed":true},"execution_count":345},{"source":"fig = plt.figure(figsize=(18,6))\n\n# Director_name\nplt.subplot2grid((2,3),(0,0), rowspan = 2)\ncreate_comparison_database('director_name','gross','sum', 4).plot(kind='barh', color='#006600')\nplt.legend().set_visible(False)\nplt.title(\"Total Gross for Directors with 4+ Films\")\nplt.ylabel(\"Director (no. films)\")\nplt.xlabel(\"Gross (in billons)\")\n\nplt.subplot2grid((2,3),(0,1), rowspan = 2)\ncreate_comparison_database('director_name','gross','mean', 4).plot(kind='barh', color='#ffff00')\nplt.legend().set_visible(False)\nplt.title('Average revenue for Directors with 4+ Films')\nplt.ylabel(\"Director (no. films)\")\nplt.xlabel(\"Gross (in billons)\")\n\nplt.tight_layout()","outputs":[],"cell_type":"code","metadata":{"_uuid":"d80dfcf708b456172627ff4c2090e376939c2d3d","_cell_guid":"979c5b84-c391-469d-a6cb-6f20d40f933b"},"execution_count":346},{"source":"Next, we plot the average IMDB score and average year of activity for the directors.","cell_type":"markdown","metadata":{"_uuid":"6e0d9371db0a117315327c82298f8b71943b9e5d","_cell_guid":"bce85d58-383f-4c95-ab67-6e29e9753728"}},{"source":"fig = plt.figure(figsize=(18,6))\n\n# Director_name\nplt.subplot2grid((2,3),(0,0), rowspan = 2)\ncreate_comparison_database('director_name','budget','mean', 4).plot(kind='barh', color='#006600')\nplt.legend().set_visible(False)\nplt.title(\"Average budget for Directors with 4+ Filmss\")\nplt.ylabel(\"Director (no. films)\")\nplt.xlabel(\"Budget (in billons)\")\n\nplt.subplot2grid((2,3),(0,1), rowspan = 2)\ncreate_comparison_database('director_name','vote_average','mean', 4).plot(kind='barh', color='#ffff00')\nplt.legend().set_visible(False)\nplt.title('Mean IMDB Score for Directors with 4+ Films')\nplt.ylabel(\"Director (no. films)\")\nplt.xlabel(\"IMDB Score\")\nplt.xlim(0,10)\n\nplt.tight_layout()","outputs":[],"cell_type":"code","metadata":{"_uuid":"78dc1ce0a283802a9ae7f7e7831357a2507c9d31","_cell_guid":"5b104378-012f-4eb1-8ac3-97b1fb545efa"},"execution_count":347},{"source":"** Conclusion directors 4+ movies ** <br> \nNotice how many of the directors that have a very high average budget per movie were nowhere to be seen in the revenue plot. Implying that, although they make expensive movies, they don't make the most grossing movies. Also note that a lot of high scoring directors are not found in the top ten highest budgeted directors. This implies that a big budget doesn't necessarily lead to a good, or well-received, movie. On the other hand, it shows that some directors, for instance Hayao Miyazaki, is capable of creating excellent movies with needing a very high budget.\n\nNow, all of this is of course only true for directors with 4+ movies. It is possible that directors with few movies were lucky. A question to ask the dataset could be whether there exist any directors that are capable of consistently creating well-received movies, without the need for big budgets. To answer this question we plot the average budget next to the average score per director, for directors with at least 15 movies.","cell_type":"markdown","metadata":{"_uuid":"6d852adbc0f45a54b5f59893425c1f3b99b06207","_cell_guid":"769c042d-89e4-40e0-bbca-356e34affa6f"}},{"source":"fig = plt.figure(figsize=(18,6))\n\n# Director_name\nplt.subplot2grid((2,3),(0,0), rowspan = 2)\ncreate_comparison_database('director_name','budget','mean', 10).plot(kind='barh', color='#006600')\nplt.legend().set_visible(False)\nplt.title(\"Average budget for Directors with 15+ Filmss\")\nplt.ylabel(\"Director (no. films)\")\nplt.xlabel(\"Budget (in billons)\")\n\nplt.subplot2grid((2,3),(0,1), rowspan = 2)\ncreate_comparison_database('director_name','vote_average','mean', 10).plot(kind='barh', color='#ffff00')\nplt.legend().set_visible(False)\nplt.title('Mean IMDB Score for Directors with 15+ Films')\nplt.ylabel(\"Director (no. films)\")\nplt.xlabel(\"IMDB Score\")\nplt.xlim(0,10)\n\nplt.tight_layout()","outputs":[],"cell_type":"code","metadata":{"_uuid":"b1cd8c535e2d23f19ea6513da15bf9d61a5e088b","_cell_guid":"d616a3d5-5711-4cdb-be7b-a78b534538d4"},"execution_count":348},{"source":"**Conclusion directors with 15+ movies ** <br> \nNow, we easily see that the two bar plots have more directors in common. Still, there are some directors who manage to create excellent movies without the need for a big budget. A funny observation is Michael Bay. While he is easily the king of budget, he is nowhere to be found in the top ten highest scoring directors.","cell_type":"markdown","metadata":{"_uuid":"02325b6570b20ad0ce5f66c7ac052f76a4fc0e50","_cell_guid":"6cfc94c9-78f2-4bf2-a986-c4434303bb57"}},{"source":"df2.head()","outputs":[],"cell_type":"code","metadata":{"_uuid":"f200a363425ff14fb412914523b643d65f89e545","_cell_guid":"ef3809b4-a68a-43e8-83ff-c979ccb6b401"},"execution_count":349},{"source":"# Numerical Analysis","cell_type":"markdown","metadata":{"_uuid":"04ccd6c62a45543f645edaedc41885d627a672f4","_cell_guid":"1c3649b0-840e-4b65-bb1e-14d54672ac79"}},{"source":"In this part we take a closer look at the numerical columns in the data frame. Which enables us to gather more information about how the data is correlated and which variables might be interesting for the prediction in later parts. The main question for this part is: \n    - How is the numerical data in our dataframe correlated? \n    \nThe first step is to create a dataframe which only contains numerical data. Since we want to analyse numerical data for this part only","cell_type":"markdown","metadata":{"_uuid":"79e868e165762027b21417614faa573b18f0415d","_cell_guid":"40b87af8-9feb-4f80-9390-54149b9b2bcb"}},{"source":"df2 = Early_df","outputs":[],"cell_type":"code","metadata":{"_uuid":"5a82beb361c677bf5dfe2b044e6e5f798287d21e","_cell_guid":"a5f17a82-7630-427a-a214-3525ea5d19f7","collapsed":true},"execution_count":350},{"source":"df2['log_budget'] = np.log(df2['budget'])\ndf2['log_popularity'] = np.log(df2['popularity'])\ndf2['log_vote_average'] = np.log(df2['vote_average'])\ndf2['log_vote_count'] = np.log(df2['vote_count'])\ndf2['log_revenue']= np.log(df2['revenue'])\ndf2['log_runtime']= np.log(df2['runtime'])\ndf3=df2[df2.columns[-6:]]\n\ndf3=df3[df3.replace([np.inf, -np.inf], np.nan).notnull().all(axis=1)]\ndf3=df3.dropna(axis=1)\ndf3.head()","outputs":[],"cell_type":"code","metadata":{"_uuid":"6ef942fc4777816d9a7a665b0dbb70bbe777d1d1","_cell_guid":"7b1c78d3-aa0c-4759-b399-37a4b6172275"},"execution_count":351},{"source":"num_list = ['budget','popularity','revenue','runtime','vote_average','vote_count']\nmovie_num = df2[num_list]\nmovie_num.head()","outputs":[],"cell_type":"code","metadata":{"_uuid":"576695fd153903fe07abd8a14c6c47d28fefbcf2","_cell_guid":"8b0352b8-73d6-4e68-850b-666631e71c2f"},"execution_count":352},{"source":"df3.head()","outputs":[],"cell_type":"code","metadata":{"_uuid":"5eddd4b74fa377e025aaea46ef979e170eab8f81","_cell_guid":"c7f2a15a-b2ce-4696-8d87-2687bc16d791"},"execution_count":353},{"source":"movie_num['revenue'] .plot(kind='hist')","outputs":[],"cell_type":"code","metadata":{"_uuid":"b081dc0749bba3b90111c2839e9015bd5ac1752d","_cell_guid":"ecb4c27a-3b8a-4441-b82e-9e2973cb33c0"},"execution_count":354},{"source":"df3['log_revenue'].plot(kind='hist')","outputs":[],"cell_type":"code","metadata":{"_uuid":"34f3876c5fdedcdc045cc2a83d8dd44effce361c","_cell_guid":"795a5779-e2ac-45fb-ad30-5598333da5d6"},"execution_count":355},{"source":"Let's take a look at how everything is correlated:","cell_type":"markdown","metadata":{"_uuid":"226ed5a53e351db495ff5ac2103a9762d96067be","_cell_guid":"6f77ce8d-c2b2-4912-bdd2-84074e068b13"}},{"source":"f, ax = plt.subplots(figsize=(12,10))\nplt.title('Pearson Correlation of Movie Features')\nsns.heatmap(movie_num.astype(float).corr(), linewidths=0.25, vmax=1.0, square=True,\n           cmap=\"YlGnBu\", linecolor='black', annot=True)","outputs":[],"cell_type":"code","metadata":{"_uuid":"42ce321f8ef81985c12abda83e9d2fc3a342c6fd","_cell_guid":"62319b61-a9d2-49ff-bae0-1b3aee252c81"},"execution_count":356},{"source":"# Numerical Analysis\nIn this part the purpose was to find out which variables are correlated. As the graph shows there are quite some dark/blue squares which means high correlation. Therefore, we expect that we can make a decent model in the next part where we try to predict the vote count. The variables that have a higher correlation than 0.70 are: <br> \n    - Revenue and Budget, correlation of 0.73.\n    - Vote count and popularity, correlation of 0.78.\n    - Vote count and revenue, correaltion of 0.78. \n","cell_type":"markdown","metadata":{"_uuid":"d7550a9c5ba83663441285e84fc367e96be3b365","_cell_guid":"fc0e9f56-bf27-4ade-8f79-8d56368e0798"}},{"source":"# Comparing different regression techniques\n\n\nIn this part we want to compare a few regression techniques to help us in making predictions. We'll use linear regression and random forest.<br> \nThis section gives answer on the following questions: <br> \n    - Which regression technique provides the best predicitions?\n    - How well are we able to predict the average votes given the budget, popularity, revenue, runtime, and vote_count? \nWe start by recreating our numerical data frame.","cell_type":"markdown","metadata":{"_uuid":"969817e6cdadca82eba8c11589d2f4b32c258a41","_cell_guid":"e6d3250a-f2a3-4286-8efb-e75fa2932303"}},{"source":"num_list = ['budget','runtime','vote_average']\nmovie_num = df2[num_list]\nmovie_num.head()","outputs":[],"cell_type":"code","metadata":{"_uuid":"15695ca4fda786de92c1c941e0184027a79e1bc1","_cell_guid":"597cf1a9-bfb8-450e-bda0-1e286e1b0b52"},"execution_count":357},{"source":"We want the vote_average to be our target values, budget, popularity, revenue, runtime and vote_count are trainng values.","cell_type":"markdown","metadata":{"_uuid":"68e98ba57763e9068dcb1c196d71beccc5c1193a","_cell_guid":"b5dd4215-1935-4822-b541-7f8d8cf949eb"}},{"source":"training_list = ['budget','runtime']\ntraining = movie_num[training_list]\ntarget = movie_num['vote_average']","outputs":[],"cell_type":"code","metadata":{"_uuid":"1dc487caeec25cbe85762877a41e4a53d659496b","_cell_guid":"c4fecb54-86d1-4400-be15-4ed986f8dd8c","collapsed":true},"execution_count":358},{"source":"X = training.values\ny = target.values","outputs":[],"cell_type":"code","metadata":{"_uuid":"e37b9ef3726f1c7c459c9ea8515ac2d457cefd59","_cell_guid":"bc571ae4-8050-443d-9adb-b80266d35dcd","collapsed":true},"execution_count":359},{"source":"We split our data in a train and a test frame.","cell_type":"markdown","metadata":{"_uuid":"6b7152f81a6313f3ec577052db7d869081c8cade","_cell_guid":"d0da5d56-9087-42a5-9def-b6a5c747efbd"}},{"source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.33, random_state=42)","outputs":[],"cell_type":"code","metadata":{"_uuid":"8a85cd5bab9a10d364a701042f7c672b82bd6870","_cell_guid":"6b653ee0-fd89-4759-a7e0-ba531995a9c7","collapsed":true},"execution_count":360},{"source":"Now let's train a linear regression model and plot the results: \\***","cell_type":"markdown","metadata":{"_uuid":"d0c7610b88612d8b9313b2cec348c492cf9a8675","_cell_guid":"f6d22aed-de64-4180-81f1-956873f7e395"}},{"source":"from sklearn import linear_model\n# Create linear regression object\nregr = linear_model.LinearRegression()\n\n# Train the model using the training sets\nregr.fit(X_train, y_train)\n\n# Make predictions using the testing set\ny_pred_lr = regr.predict(X_test)","outputs":[],"cell_type":"code","metadata":{"_uuid":"fde481a3fd940fc8e2b0709c0876fb0588d48726","_cell_guid":"c3560a54-1b4a-469c-8a45-4bb8f86b826d","collapsed":true},"execution_count":361},{"source":"f = plt.figure(figsize=(10,5))\nplt.scatter(X_test[:,1], y_test, s=50,label=\"Real vote_average\");\nplt.scatter(X_test[:,1], y_pred_lr,s=100, c='r',label=\"Predicted vote_average\");\nplt.ylabel(\"vote_average\");\nplt.legend(loc=2);","outputs":[],"cell_type":"code","metadata":{"_uuid":"49c84f85029d56466c0f251b1ff72cb337d61bb4","_cell_guid":"07666f6b-e968-41bc-ba44-77784aa2e925"},"execution_count":362},{"source":"Now let's see what happens if we use a random forest regression model:","cell_type":"markdown","metadata":{"_uuid":"9cb65257aedfaa6b2d94cd24aeb8d18a26ee90d6","_cell_guid":"3fb01fc3-d3bb-4dbe-ac37-09989ce2c40d"}},{"source":"from sklearn.ensemble import RandomForestRegressor\n# Create linear regression object\nrf = RandomForestRegressor(1)\n\n# Train the model using the training sets\nrf.fit(X_train, y_train)\n\n# Make predictions using the testing set\ny_pred_rf = rf.predict(X_test)","outputs":[],"cell_type":"code","metadata":{"_uuid":"87ee0d2142eba0336bf7d4ec6bb5b5c33f86bccc","_cell_guid":"8da35a43-733e-44f8-af70-55e2cef4dd9c","collapsed":true},"execution_count":363},{"source":"f = plt.figure(figsize=(10,5))\nplt.scatter(X_test[:,1], y_test, s=50,label=\"Real vote_average\");\nplt.scatter(X_test[:,1], y_pred_rf,s=100, c='r',label=\"Predited vote_average\");\nplt.ylabel(\"vote_average\");\nplt.legend(loc=2);","outputs":[],"cell_type":"code","metadata":{"_uuid":"5336e7a59a4e759c9c392055fce5435fbdcd4d94","_cell_guid":"888edfd3-b52f-4593-aa74-1df6e1f3c448"},"execution_count":364},{"source":"And let's compare them:","cell_type":"markdown","metadata":{"_uuid":"25c914c5c7c5ba9f394df2e62593d0d717e6f53c","_cell_guid":"e65b692e-4a32-41da-8dc8-e0df742ecf8c"}},{"source":"from sklearn.metrics import mean_squared_error\n\nerror_lr = mean_squared_error(y_test,y_pred_lr)\nerror_rf = mean_squared_error(y_test,y_pred_rf)\n\nprint(error_lr)\nprint(error_rf)","outputs":[],"cell_type":"code","metadata":{"_uuid":"83df0085bd433d1142b3b7e11b2835819137f531","_cell_guid":"948e08f7-e4c0-4cd1-8bb9-efaac89955f0"},"execution_count":365},{"source":"f = plt.figure(figsize=(10,5))\nplt.bar(range(2),[error_lr,error_rf])\nplt.xlabel(\"Classifiers\");\nplt.ylabel(\"Mean Squared Error of the vote_average\");\nplt.xticks(range(2),['Linear Regression','Random Forest'])\nplt.legend(loc=2);","outputs":[],"cell_type":"code","metadata":{"_uuid":"f8f8c5fdf808977fa9f7570fd9013b6f9d8771ee","_cell_guid":"643637d3-468a-4161-bf77-2ca79a9ce1e2"},"execution_count":366},{"source":"num_list = ['budget','revenue', \"runtime\"]\nmovie_num = df2[num_list]\n \ntraining_list = ['budget','runtime']\ntraining = movie_num[training_list]\ntarget = movie_num['revenue']\n\nX = training.values\ny = target.values\n \nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.33, random_state=42)\n\nfrom sklearn import linear_model\n# Create linear regression object\nregr = linear_model.LinearRegression()\n\n# Train the model using the training sets\nregr.fit(X_train, y_train)\n\n# Make predictions using the testing set\ny_pred_lr = regr.predict(X_test)\n \nf = plt.figure(figsize=(10,5))\nplt.scatter(X_test[:,1], y_test, s=50,label=\"Real vote_average\");\nplt.scatter(X_test[:,1], y_pred_lr,s=100, c='r',label=\"Predicted vote_average\");\nplt.ylabel(\"vote_average\");\nplt.legend(loc=2);\n \n #-----------------------------------------\nfrom sklearn.ensemble import RandomForestRegressor\n# Create linear regression object\nrf = RandomForestRegressor(1)\n\n# Train the model using the training sets\nrf.fit(X_train, y_train)\n\n# Make predictions using the testing set\ny_pred_rf = rf.predict(X_test)\n \nf = plt.figure(figsize=(10,5))\nplt.scatter(X_test[:,1], y_test, s=50,label=\"Real vote_average\");\nplt.scatter(X_test[:,1], y_pred_rf,s=100, c='r',label=\"Predited vote_average\");\nplt.ylabel(\"vote_average\");\nplt.legend(loc=2);\n \nfrom sklearn.metrics import mean_squared_error\n\nerror_lr = mean_squared_error(y_test,y_pred_lr)\nerror_rf = mean_squared_error(y_test,y_pred_rf)\n\nprint(error_lr)\nprint(error_rf)\n \nf = plt.figure(figsize=(10,5))\nplt.bar(range(2),[error_lr,error_rf])\nplt.xlabel(\"Classifiers\");\nplt.ylabel(\"Mean Squared Error of the vote_average\");\nplt.xticks(range(2),['Linear Regression','Random Forest'])\nplt.legend(loc=2);","outputs":[],"cell_type":"code","metadata":{},"execution_count":394},{"source":"<h3> Conclusion comparing different regression techniques </h3>\nThis parts purpose was to found out how well we can predict the vote average and test which regression method is better. Firstly, both models estimators seem to be very decent. Which shows that we are able to predict the average votes for a movie, with the given variables, without much error. The mean squared error for random forrest is slightly higher than the mean squared error for the linear regression. So this suggest that the model of linear regression is the best model to use for our data. However, both models are able to predict with precision. ","cell_type":"markdown","metadata":{"_uuid":"ee612bd24b328ad805fb5ec9e11d6173415beca8","_cell_guid":"303113f0-72c4-4de7-a9c4-f91c9009bade"}},{"source":"\\* https://www.kaggle.com/fabiendaniel/categorizing-actors-hands-on-plotly <br>\n\\** https://www.kaggle.com/diegoinacio/imdb-genre-based-analysis <br>\n\\*** introduction to data science, week 4, Comparison of Regression Techniques on House prediction prices.ipynb\n\nResources:\n\nhttps://www.kaggle.com/fabiendaniel/film-recommendation-engine\n\nhttps://www.kaggle.com/fabiendaniel/categorizing-actors-hands-on-plotly\n\nhttps://www.kaggle.com/willacy/director-and-actor-s-total-gross-and-imdb-score","cell_type":"markdown","metadata":{"_uuid":"d7c2f6f0b6d45ad72fabaab774e03c5ecd7320f6","_cell_guid":"e0fe96bc-a8b5-463e-9b90-f95c423159d5"}},{"source":"#----------------------------------------------------------------------","cell_type":"markdown","metadata":{"_uuid":"2b97ded0bbf09f4fe545928ecac6072010086ce1","_cell_guid":"cca9df46-bde3-4a18-9537-040f80c8d069"}},{"source":"# 4. Predictive","cell_type":"markdown","metadata":{"_uuid":"3dc076b5d00e72853b7b0633cec15be55fc9b425","_cell_guid":"c7dd9cd0-1079-4b09-bc2e-dbee3f6f4f81"}},{"source":"In this part we want to compare a few regression techniques to help us in making predictions. We use linear regression and random forest.<br> \nThis section gives answer on the following questions: <br> \n    - Which regression technique provides the best predicitions?\n    - How well are we able to predict the average votes given the budget, popularity, revenue, runtime, and vote_count? \nWe start by recreating our numerical data frame.","cell_type":"markdown","metadata":{"_uuid":"1ef0fa3c05fa6783945332220943afda2db940e7","_cell_guid":"33ac0f93-7902-46b2-83c4-f64e736a3e5b"}},{"source":"num_list = ['budget','popularity','revenue','runtime','vote_average','vote_count']\nmovie_num = df2[num_list]\nmovie_num.head()","outputs":[],"cell_type":"code","metadata":{"_uuid":"8bf2ba4a0f2d73903db95ae425056385c73fb7f4","_cell_guid":"7f4c4966-ea5f-43b9-82ff-74fd3ecb00f3"},"execution_count":367},{"source":"","cell_type":"markdown","metadata":{"_uuid":"c897cbe29f1d84f61aadcda523a78c508921f64e","_cell_guid":"5b23e8e4-0d00-4d6c-975b-36b4be1ea253"}},{"source":"","cell_type":"markdown","metadata":{"_uuid":"73ff0a77ddf398f223f277ab5226be9302a2d95c","_cell_guid":"6ccaddac-78a4-4548-bfbc-271eab7b8a43"}},{"source":"df2['vote_classes'] = pd.cut(df2['vote_average'],4, labels=[\"low\",'medium-low','medium-high','high'])\nnum_list = ['budget','popularity','revenue','runtime','vote_count','vote_classes']\nmovie_num = df2[num_list]\nmovie_num.head()\n\nfrom sklearn.ensemble import RandomForestClassifier\nimport pandas as pd\nimport numpy as np\n\ndf = movie_num\ndf['is_train'] = np.random.uniform(0, 1, len(df)) <= .75\n\ntrain, test = df[df['is_train']==True], df[df['is_train']==False]\n\nfeatures = df.columns[:5]\nclf = RandomForestClassifier(n_jobs=10)\ny, _ = pd.factorize(train['vote_classes'])\nclf.fit(train[features],y)\n\npreds = df.vote_classes[clf.predict(test[features])]\npd.crosstab(test['vote_classes'], preds.values, rownames=['actual'], colnames=['preds'])","outputs":[],"cell_type":"code","metadata":{"_uuid":"1a900045c3f9606f0d6bfaa3bfedc7903c972f14","_cell_guid":"05049a09-673d-4075-bf2c-cf747dfef827"},"execution_count":368},{"source":"By altering the first line of the above code, you can choose in how many classes you want to cut the value you want to predict, like this:\n","cell_type":"markdown","metadata":{"_uuid":"ecf4638e46c4b090a0385cbb638d21c309cb97a8","_cell_guid":"1945ccaa-34b4-4e7f-8bf8-591b8134d2aa"}},{"source":"df2['vote_classes'] = pd.cut(df2['vote_average'],10, labels=range(10))","outputs":[],"cell_type":"code","metadata":{"_uuid":"ee62504ef4505e143864045d8bfb57491a3c4bec","_cell_guid":"41404755-3f2c-45bd-8d38-687926eb0958","collapsed":true},"execution_count":369},{"source":"I took \"labels=range(10)\", so they get named 1 to 10, if you cut it in 10 pieces.\n\nWhat happens to the predictions if we perform a log transform?\n","cell_type":"markdown","metadata":{"_uuid":"10b76452b74732809d51a7ac2c166495e12cfe46","_cell_guid":"3fd804a6-1384-4c60-86a0-e72f630db3b1"}},{"source":"df3['vote_classes'] = pd.cut(df2['vote_average'],4, labels=['low','medium-low','medium-high','high'])\nnum_list = ['log_budget','log_popularity','log_revenue','log_runtime','log_vote_count','vote_classes']\nmovie_num = df3[num_list]\nmovie_num.head()\n\nfrom sklearn.ensemble import RandomForestClassifier\nimport pandas as pd\nimport numpy as np\n\ndf = movie_num\ndf['is_train'] = np.random.uniform(0, 1, len(df)) <= .75\n\ntrain, test = df[df['is_train']==True], df[df['is_train']==False]\n\nfeatures = df.columns[:5]\nclf = RandomForestClassifier(n_jobs=1000)\ny, _ = pd.factorize(train['vote_classes'])\nclf.fit(train[features],y)\n\npreds = df.vote_classes[clf.predict(test[features])]\npd.crosstab(test['vote_classes'], preds.values, rownames=['actual'], colnames=['preds'])","outputs":[],"cell_type":"code","metadata":{"_uuid":"2dc54e556ee2635c5d69e1fcd5c0388dae447ac3","_cell_guid":"2fb3946b-ee14-411d-891e-9fb7fdef05a6"},"execution_count":370},{"source":"We can also try it with normalized data:","cell_type":"markdown","metadata":{"_uuid":"fb62fb9de5635e218a2d2d8bdbbf4bc676751a3f","_cell_guid":"7fd33d2b-ac5c-4a7c-9c64-056620bfbca3"}},{"source":"df2['vote_classes'] = pd.cut(df2['vote_average'],4, labels=['low','medium-low','medium-high','high'])\nnum_list = ['budget','popularity','revenue','runtime','vote_count','vote_classes']\nmovie_num = df2[num_list]\nmovie_num.head()\n\nfrom sklearn.preprocessing import StandardScaler\n\nmovie_num['normBudget'] = StandardScaler().fit_transform(movie_num['budget'].reshape(-1, 1))\nmovie_num['normPopularity'] = StandardScaler().fit_transform(movie_num['popularity'].reshape(-1, 1))\nmovie_num['normRevenue'] = StandardScaler().fit_transform(movie_num['revenue'].reshape(-1, 1))\nmovie_num['normVoteCount'] = StandardScaler().fit_transform(movie_num['vote_count'].reshape(-1, 1))\nmovie_num['normRuntime'] = StandardScaler().fit_transform(movie_num['runtime'].reshape(-1, 1))\n#movie_num['vote_classes'] = pd.cut(movie_num['vote_average'],2, labels=[0,1])\n\nmovie_test = movie_num.drop(['budget','popularity','vote_count','revenue','runtime'],axis=1)\ncols=['normBudget','normPopularity','normRevenue','normVoteCount','normRuntime','vote_classes']\nmovie_num = movie_test[cols]\n#movie_test = movie_test[:-1] + movie_test[-1:]\nmovie_num.head()","outputs":[],"cell_type":"code","metadata":{"_uuid":"0bd44f6453a9dc0f01c0dac6254abdce6f8e67c9","_cell_guid":"12897a5e-02f8-4484-b7fa-62054f9e672b"},"execution_count":371},{"source":"from sklearn.ensemble import RandomForestClassifier\nimport pandas as pd\nimport numpy as np\n\ndf = movie_num\ndf['is_train'] = np.random.uniform(0, 1, len(df)) <= .75\n\ntrain, test = df[df['is_train']==True], df[df['is_train']==False]\n\nfeatures = df.columns[:5]\nclf = RandomForestClassifier(n_jobs=1000)\ny, _ = pd.factorize(train['vote_classes'])\nclf.fit(train[features],y)\n\npreds = df.vote_classes[clf.predict(test[features])]\npd.crosstab(test['vote_classes'], preds.values, rownames=['actual'], colnames=['preds'])","outputs":[],"cell_type":"code","metadata":{"_uuid":"cdd6ae1ee07cb6d84b7fbf50c3e1ea505d1f52d1","_cell_guid":"86962e9e-7c53-4ccf-b533-cf69732feeca"},"execution_count":372},{"source":"We do the same for revenue:\n\n","cell_type":"markdown","metadata":{"_uuid":"9c74e685910f207920b6ff66b6f6572ecee0f2f5","_cell_guid":"d1ff7b45-4954-4801-b79d-baaa0a206d20"}},{"source":"df2['revenue_classes'] = pd.cut(df2['revenue'],3, labels=['low','medium','high'])\nnum_list = ['budget','popularity','vote_average','runtime','vote_count','revenue_classes']\nmovie_num = df2[num_list]\nmovie_num.head()\n\nfrom sklearn.ensemble import RandomForestClassifier\nimport pandas as pd\nimport numpy as np\n\ndf = movie_num\ndf['is_train'] = np.random.uniform(0, 1, len(df)) <= .75\n\ntrain, test = df[df['is_train']==True], df[df['is_train']==False]\n\nfeatures = df.columns[:5]\nclf = RandomForestClassifier(n_jobs=100)\ny, _ = pd.factorize(train['revenue_classes'])\nclf.fit(train[features],y)\n\npreds = df.revenue_classes[clf.predict(test[features])]\npd.crosstab(test['revenue_classes'], preds.values, rownames=['actual'], colnames=['preds'])","outputs":[],"cell_type":"code","metadata":{"_uuid":"8bbb4b2145e375f1c2ad7650569d93f65def7205","_cell_guid":"ace76709-71ea-4fae-b039-3b85e9925b34"},"execution_count":373},{"source":"And on the log transformation:","cell_type":"markdown","metadata":{"_uuid":"d66fd92b21839f3da720fc830f1de05713d0349d","_cell_guid":"2c52e9a3-629c-4221-bd95-acb767f0bad9"}},{"source":"df3['revenue_classes'] = pd.cut(df2['revenue'],3, labels=['low','medium','high'])\nnum_list = ['log_budget','log_popularity','log_vote_average','log_runtime','log_vote_count','revenue_classes']\nmovie_num = df3[num_list]\nmovie_num.head()\n\nfrom sklearn.ensemble import RandomForestClassifier\nimport pandas as pd\nimport numpy as np\n\ndf = movie_num\ndf['is_train'] = np.random.uniform(0, 1, len(df)) <= .75\n\ntrain, test = df[df['is_train']==True], df[df['is_train']==False]\n\nfeatures = df.columns[:5]\nclf = RandomForestClassifier(n_jobs=1000)\ny, _ = pd.factorize(train['revenue_classes'])\nclf.fit(train[features],y)\n\npreds = df.revenue_classes[clf.predict(test[features])]\npd.crosstab(test['revenue_classes'], preds.values, rownames=['actual'], colnames=['preds'])","outputs":[],"cell_type":"code","metadata":{"_uuid":"bd341ca3fc41f0005c2e494bd359f8fabce4381c","_cell_guid":"c6ab07c5-f555-438d-b1b8-c6fb52233a59"},"execution_count":374},{"source":"And for normalized data:","cell_type":"markdown","metadata":{"_uuid":"d90f7eb3946b6d5b9e77b7deed40aa2e082e5495","_cell_guid":"5c9cfa62-d8da-4f5d-8520-8fe16664be2f"}},{"source":"df2['revenue_classes'] = pd.cut(df2['revenue'],3, labels=range(3))\nnum_list = ['budget','popularity','vote_average','runtime','vote_count','revenue_classes']\nmovie_num = df2[num_list]\nmovie_num.head()\n\nfrom sklearn.preprocessing import StandardScaler\n\nmovie_num['normBudget'] = StandardScaler().fit_transform(movie_num['budget'].reshape(-1, 1))\nmovie_num['normPopularity'] = StandardScaler().fit_transform(movie_num['popularity'].reshape(-1, 1))\n#movie_num['normVoteAverage'] = StandardScaler().fit_transform(movie_num['vote_average'].reshape(-1, 1))\nmovie_num['normRuntime'] = StandardScaler().fit_transform(movie_num['runtime'].reshape(-1, 1))\nmovie_num['normVoteCount'] = StandardScaler().fit_transform(movie_num['vote_count'].reshape(-1, 1))\n\n\n#movie_num['revenue_classes'] = pd.cut(movie_num['vote_average'],2, labels=[0,1])\n\nmovie_test = movie_num.drop(['budget','popularity','runtime','vote_count',],axis=1)\ncols=['normBudget','normPopularity','vote_average','normVoteCount','normRuntime','revenue_classes']\nmovie_num = movie_test[cols]\n#movie_test = movie_test[:-1] + movie_test[-1:]\nmovie_num.head()","outputs":[],"cell_type":"code","metadata":{"_uuid":"5b3f1575fc97ca9de32afa666da9de070aaed355","_cell_guid":"246b5498-287b-4d0f-83fe-03ebd19676b2"},"execution_count":375},{"source":"from sklearn.ensemble import RandomForestClassifier\nimport pandas as pd\nimport numpy as np\n\ndf = movie_num\ndf['is_train'] = np.random.uniform(0, 1, len(df)) <= .75\n\ntrain, test = df[df['is_train']==True], df[df['is_train']==False]\n\nfeatures = df.columns[:5]\nclf = RandomForestClassifier(n_jobs=1000)\ny, _ = pd.factorize(train['revenue_classes'])\nclf.fit(train[features],y)\n\npreds = df.revenue_classes[clf.predict(test[features])]\npd.crosstab(test['revenue_classes'], preds.values, rownames=['actual'], colnames=['preds'])","outputs":[],"cell_type":"code","metadata":{"_uuid":"5de695f64cdd6bc80ff3aa7d102a85bf1f470e7d","_cell_guid":"36840f1e-0c45-4ac6-b026-9954ac2d974c"},"execution_count":376},{"source":"","outputs":[],"cell_type":"code","metadata":{"_uuid":"12dc6da4f630254c98eccc200b766c7c5157f488","_cell_guid":"52fd22bf-29c9-463d-9535-f1c9470c007c","collapsed":true},"execution_count":null}],"nbformat":4}