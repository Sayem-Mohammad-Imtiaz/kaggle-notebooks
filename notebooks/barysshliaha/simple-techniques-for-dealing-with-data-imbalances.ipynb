{"cells":[{"metadata":{},"cell_type":"markdown","source":"It is necessary to predict whether the client will leave the Bank in the near future or not. You are presented with historical data on customer behavior and termination of contracts with the Bank."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.metrics import f1_score, roc_auc_score, accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import roc_curve\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nrndd = 12345\n\ndf = pd.read_csv('/kaggle/input/bank-customer-churn-modeling/Churn_Modelling.csv')\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **1. DataSet preparation**"},{"metadata":{},"cell_type":"markdown","source":"As we can see the data set is full without any NaN values.\nNow let's briefly see the data from the top and from the end."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"The 'RowNumber' columns looks like index duplicate. Let's dropp it."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop('RowNumber', axis = 1, inplace = True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For a make prediction via scikit-learn, we should prepare our dataset, the should consist only numeric values. We starting from 'Gender' column."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Gender.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The consist only from two values, for this purpose we change values to int"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Gender = df.Gender.map({'Female': 0, 'Male':1})\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For columns 'Surname' and 'Geography' we will used OrdinalEncoder, for coding every string value to the int value. In general cloumns like 'Surname' should not be presented in real dataset, and they cannot affect the final result, but looking a little ahead in our case have a positive impact on the metrics."},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder = OrdinalEncoder()\ndata = encoder.fit_transform(df)\ndf_trans = pd.DataFrame(data, columns = df.columns)\ndf_trans.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see dataset consist only from numeric values.\n<br> Now checking value types."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_trans.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can optimize value types."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_trans = df_trans.astype({\n    'CustomerId'    : 'int32',\n    'Surname'       : 'int32',\n    'Geography'     : 'int32',\n    'Gender'        : 'int32',\n    'Age'           : 'int32',\n    'Tenure'        : 'int32',\n    'NumOfProducts' : 'int32',\n    'HasCrCard'     : 'int32',\n    'IsActiveMember': 'int32',\n    'Exited'        : 'int32'})\ndf_trans.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **2. Split data for trainig**"},{"metadata":{},"cell_type":"markdown","source":"Now let's create datasets for training. First cut the 'Exited' it is our target value."},{"metadata":{"trusted":true},"cell_type":"code","source":"target = df_trans['Exited']\ntrain = df_trans.drop('Exited', axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For having ability to reproduce experimental values , we define constant for future using in random state generators"},{"metadata":{},"cell_type":"markdown","source":"rndd=12345"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.25, random_state=rndd)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"![](http://)now we have training a model RandomForestClassifier, let's start training data and predict target data."},{"metadata":{"trusted":true},"cell_type":"code","source":"#create a model for prediction\nrand_Forest = RandomForestClassifier(random_state = rndd)\n\n# define model parameters and values for tuning\nparameters = {\n    'n_estimators':np.arange(1,300, 50),\n    'max_depth' : np.arange(2, 30, 2),\n    'min_samples_split': np.arange(2, 30, 2),\n    'min_samples_leaf': np.arange(2, 30, 2)    \n}\n#create a searchCV to cycle through the possible values\nrand_Forest_grid = RandomizedSearchCV(\n    estimator = rand_Forest,\n    param_distributions  = parameters,\n    scoring='f1',\n    n_jobs=2,\n    cv = 5,\n    n_iter = 150,\n    verbose=True, refit=True, return_train_score = True, random_state = rndd)\n    \n#fit the model    \nrand_Forest_grid.fit(X_train, y_train)\n#check scores result\nf1_train = rand_Forest_grid.best_score_\nprint('Best Estimator: ', rand_Forest_grid.best_estimator_)\nprint('Best Params: ', rand_Forest_grid.best_params_)\nprint('f1 =', f1_train)\npredicted_train = rand_Forest_grid.predict(X_train)\naccuracy_train = accuracy_score(y_train, predicted_train)\nprint('accuracy =', accuracy_train)\nroc_auc_score_train =  roc_auc_score(y_train, predicted_train)\nprint('roc_auc_score',  roc_auc_score_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now checking our model on test parts of data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#predict values on previously trained model\ny_predicted = rand_Forest_grid.predict(X_test)\n\nf1_test = f1_score(y_test, y_predicted)\naccuracy_test = accuracy_score(y_test, y_predicted)\nroc_auc_score_test =  roc_auc_score(y_test, y_predicted)\nprint('TEST       f1      =', f1_test)\nprint('TEST accuracy      =', accuracy_test)\nprint('TEST roc_auc_score =', roc_auc_score_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For future comparing results we will save all result in dataset result."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create empty dataframe with columns\nresults = pd.DataFrame(columns=['expirement', 'f1_train', 'f1_test', 'accuracy_train', 'accuracy_test', 'roc_auc_train', 'roc_auc_test'])\n#add values to columns accordingly\nresults = results.append([{'expirement':'simple model',\n                           'f1_train':f1_train, 'f1_test': f1_test,\n                           'accuracy_train': accuracy_train, 'accuracy_test':accuracy_test,\n                           'roc_auc_train':roc_auc_score_train, 'roc_auc_test':roc_auc_score_test}])\nresults","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For now we got not bad results. Lets check our data deeper."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see EstimatedSalary mean = 5008.469733 and CreditScore mean=260.16760  - the order of values is 5008/260 = 16+ times different. It is not good for model. Let's bring to one order via StandartScaler"},{"metadata":{"trusted":true},"cell_type":"code","source":"#create scaler\nscaler = StandardScaler()\n#fit and transform data\nX_train_scaled = scaler.fit_transform(X_train)\n#transform data based on previous fit process\nX_test_scaled = scaler.transform(X_test)\n\n#put transformed data for pretty print\nd = pd.DataFrame(columns=X_train.columns, data=X_train_scaled).describe()\nprint('order of values', abs(d.loc['mean','EstimatedSalary']/ d.loc['mean','CreditScore']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now the scale order of values is same, lets check result on our model. For now we will used hyper parmeters from previous grid trainig.\n<br> Best Params:  {'n_estimators': 101, 'min_samples_split': 20, 'min_samples_leaf': 2, 'max_depth': 18}"},{"metadata":{"trusted":true},"cell_type":"code","source":"#create model with parameters vased on previous training result\nrand_Forest = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n                       max_depth=18, max_features='auto', max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=2, min_samples_split=20,\n                       min_weight_fraction_leaf=0.0, n_estimators=101,\n                       n_jobs=None, oob_score=False, random_state=12345,\n                       verbose=0, warm_start=False)\n\n#define function for reducing code duplication\ndef checkModel(X_train, y_train, X_test, y_test, model = rand_Forest):\n    \n    model.fit(X_train, y_train)\n    y_train_predicted = rand_Forest.predict(X_train)\n    f1_train = f1_score(y_train, y_train_predicted)\n    accuracy_train = accuracy_score(y_train, y_train_predicted)\n    roc_auc_score_train =  roc_auc_score(y_train, y_train_predicted)\n    \n    print('roc_auc_score',  roc_auc_score_train)\n    print('f1 =', f1_train)\n    print('accuracy =', accuracy_train)\n    \n    y_test_predicted = rand_Forest.predict(X_test)\n    f1_test = f1_score(y_test, y_test_predicted)\n    accuracy_test = accuracy_score(y_test, y_test_predicted)\n    roc_auc_score_test =  roc_auc_score(y_test, y_test_predicted)\n    \n    print('TEST       f1 =', f1_test)\n    print('TEST accuracy =', accuracy_test)\n    print('TEST roc_auc_score =', roc_auc_score_test)\n    \n    return f1_train, accuracy_train, roc_auc_score_train, f1_test, accuracy_test, roc_auc_score_test\n\n#call function\nf1_train, accuracy_train, roc_auc_score_train, f1_test, accuracy_test, roc_auc_score_test = checkModel(X_train_scaled, y_train, X_test_scaled, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Put result scores to dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"results = results.append([{'expirement':'scaled data model',\n                           'f1_train':f1_train, 'f1_test': f1_test,\n                           'accuracy_train': accuracy_train, 'accuracy_test':accuracy_test,\n                           'roc_auc_train':roc_auc_score_train, 'roc_auc_test':roc_auc_score_test}])\nresults","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see there are improvements, but they showed themselves only in the training sample. Now lets check our target value"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We observe that 0 is a value 4 times greater than 1. Let's try to equalize their number by applying the technique upsampling/downsampling. To do this, randomly mix the existing data with the target feature 1. For this porprouse define a function upsample_1"},{"metadata":{"trusted":true},"cell_type":"code","source":"def upsample_1(features, target, repeat):\n    #array only with 0 values from features\n    features_zeros = features[target == 0]\n    #array only with 1 values from features\n    features_ones = features[target == 1]\n    \n    #array only with 0 values from target\n    target_zeros = target[target == 0]\n    #array only with 1 values from target\n    target_ones = target[target == 1]\n    \n    #create new data frame with features 0 values and features 1 value repeated Repeat(incoming parameters in functions) times\n    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n    \n    #create new data frame with target 0 values and target 1 value repeated Repeat(incoming parameters in functions) times\n    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n    \n    #just shuffle values in dataframe\n    features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=rndd)\n    \n    return features_upsampled, target_upsampled","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check their upsmpling result"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_u, y_train_u = upsample_1(X_train, y_train, 4)\nX_test_u, y_test_u = upsample_1(X_test, y_test, 4)\ny_train_u.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now you can see taht 0 and 1 meet about the same time, lets check result on our model."},{"metadata":{"trusted":true},"cell_type":"code","source":"f1_train, accuracy_train, roc_auc_score_train, f1_test, accuracy_test, roc_auc_score_test = checkModel(X_train_u, y_train_u, X_test_u, y_test_u)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"put result to our dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"results = results.append([{'expirement':'upsmpled data model',\n                           'f1_train':f1_train, 'f1_test': f1_test,\n                           'accuracy_train': accuracy_train, 'accuracy_test':accuracy_test,\n                           'roc_auc_train':roc_auc_score_train, 'roc_auc_test':roc_auc_score_test}])\nresults","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see the result is also positive. Particularly for the main metric for classification F1\n<br> Now lets apply scaller also, and check result."},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nX_train_u_scaled = scaler.fit_transform(X_train_u)\nX_test_u_scaled = scaler.transform(X_test_u)\n\nf1_train, accuracy_train, roc_auc_score_train, f1_test, accuracy_test, roc_auc_score_test = checkModel(X_train_u_scaled, y_train_u, X_test_u_scaled, y_test_u)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = results.append([{'expirement':'upsmpled scaled data model',\n                           'f1_train':f1_train, 'f1_test': f1_test,\n                           'accuracy_train': accuracy_train, 'accuracy_test':accuracy_test,\n                           'roc_auc_train':roc_auc_score_train, 'roc_auc_test':roc_auc_score_test}])\nresults","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**In this paper, we have considered two techniques for dealing with data imbalances in data classification. This is a dimensionality reduction of values and upsampling by target value.**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}