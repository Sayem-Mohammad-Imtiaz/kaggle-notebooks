{"cells":[{"metadata":{},"cell_type":"markdown","source":"<img style=\"float: left;\" src=\"http://sindser.org.br/s/wp-content/uploads/2013/09/iesb1.jpg\"  width=\"400\" height=\"400\">\n\n## Instituto de Educação Superior de Brasília\n## Pós Graduação em Ciência de Dados\n## Data Mining e Machine Learning II\n## Victor Hugo - 1931133079\n"},{"metadata":{},"cell_type":"markdown","source":"___"},{"metadata":{},"cell_type":"markdown","source":"# <center>Tratamento e modelagem da base <a href='https://www.kaggle.com/ajay1735/hmeq-data'>hmeq_data</a></center>"},{"metadata":{},"cell_type":"markdown","source":"# <a id='1'> 1. Dados</a>\n"},{"metadata":{},"cell_type":"markdown","source":"## <a id= '1.1'> 1.1. Visão geral da base</a>\nO dataset Home Equality (HMEQ), termo que se refere à diferença entre o preço de mercado da propriedade e o saldo pendente de todos os ônus atrelados a ela, contem uma base de informações sobre a performanse de 5960 emprestimos recentes voltados para a casa própria. A variável target (BAD) é do tipo binária e informa quando houve negligência no pagamento deste emprestimo. Esta realidade ocorreu em 1.890 dos casos (20%). Para cada indivíduo foram colhidas 12 variáveis."},{"metadata":{},"cell_type":"markdown","source":"# <a id='2'> 2. Exploração dos dados </a>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Importação das bibliotecas necessárias e leitura da base\nimport numpy as np # realização de calculos computacionais\nimport pandas as pd # manipulação dos dados\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ndf = pd.read_csv('/kaggle/input/hmeq-data/hmeq.csv')\ndf2 = df.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='2.1'> 2.1. Variáveis </a>"},{"metadata":{},"cell_type":"markdown","source":"* BAD (Realizou o pagamento do emprestimo \"0\", não realizou \"1\")\n* LOAN (Quantidade de emprestimo solicitado)\n* MORTDUE (Divida referente a uma hipotéca já existente)\n* VALUE (Valor da propriedade atual)\n* REASON (Motivo do emprestimo, sendo DebtCon = Consolidação de débitos e HomeImp = Melhorias na propriedade)\n* JOB (Informa em qual das seis categorias ocupacionais está o indivíduo)\n* YOJ (Quantidade de anos no atual emprego)\n* DEROG (Quantidade de relatórios depreciativos, os principais)\n* DELINQ (Quantidade de inadimplências em linhas de crédito) \n* CLAGE (Quantidade de meses desde a Trade Line mais antiga, trade line e responsável por gravar o comportamento de créditos ao consumidor)\n* NINQ (Quantidade de linhas de crédito recentes)\n* CLNO (Número total de linhas de Crédito)\n* DEBTINC (Taxa de débitos que ainda estão por vir)"},{"metadata":{},"cell_type":"markdown","source":"## <a id=\"2.2\"> 2.2. Visualização da base </a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Seleciona uma amostra com 10 observações da base e as mostra na tela\ndisplay(df.sample(10).T)\n\n# Informa a quantidade de linhas e colunas respectivamente\ndisplay(df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Informações básicas da base como quantidade de colunas e seus respectivos nomes, quantidade des observações não nulas e seus respectivos tipos\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def missing_values(data_frame):\n    \"\"\"\n    Função responsável por mostrar quantos \n    valores missing há na base em cada \n    coluna\n    \"\"\"\n    display(data_frame.isnull().sum().rename_axis('Colunas').reset_index(name='Missing Values'))\n\n\n#chamada da função\nmissing_values(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nseleciona as variáveis númericas da base para uma primeira análise, \ndeixando de fora apenas a varíavel target \"BAD\", pois pelo fato da mesma \nser binária, vizulizaremos-a melhor posteriormente em outro gráfico\n'''\nnumeric_feats = [c for c in df.columns if df[c].dtype != 'object' and c not in ['BAD']]\ndf_numeric_feats = df[numeric_feats]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cria um gráfico de paridade relacionado cada uma das variáveis entre si\nsns.pairplot(df_numeric_feats)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Analisando estes gráficos gerados pode-se a uma primeira vista ver que há idícios de correlação entre a variável \"VALUE\" e \"MORTDUE\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cria histogramas das variáveis selecionadas anteriormente\ndf_numeric_feats.hist(figsize=(20,8), bins=30)\nplt.tight_layout() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nestes gráficos percebemos que enquanto algumas variáveis estão mais próximos de uma distribuição normal outras se aproximam de uma distribuição poisson."},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nCria uma sequência de gráficos relacionando \nas variáveis númericas anteriormente \nselecionadas com a variável target \"BAD\"\n'''\nplt.figure(figsize=(18,18))\nc = 1\nfor i in df_numeric_feats.columns:\n    if c < len(df_numeric_feats.columns):\n        plt.subplot(3,3,c)\n        sns.boxplot(x='BAD' , y= i, data=df)\n        c+=1\n    else:\n        sns.boxplot(x='BAD' , y= i, data=df)\nplt.tight_layout() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Analisando estes gráficos, percebe-se que algumas das variáveis como \"LOAN\", \"YOJ\" e \"CLAGE\" apresentam uma média ligeiramente diferente entre os que pagaram e os que não pagaram os emprestimos tomados. E é possível notar também a quantidade de outliers presentes em cada uma dessas váriáveis, os quais podem estar consideravelmente influênciando o valor da média."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cria um sequência de gráficos relacionando as varáveis númericas com a variável \"JOB\".\nplt.figure(figsize=(18,18))\nc = 1\nfor i in df_numeric_feats.columns:\n    if c < len(df_numeric_feats.columns):\n        plt.subplot(3,3,c)\n        sns.boxplot(x='JOB' , y= i, data=df)\n        c+=1\n    else:\n        sns.boxplot(x='JOB' , y= i, data=df)\nplt.tight_layout() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Assim como na plotagem anterior, nesta é possíve identificar as diferentes médias das váriaveis entre as diferentes ocupações do indivíduo que tomou o emprestimo. E também os outliers que podem estar consideravelmente influenciando no valor da média."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dropa os campos com valores faltantes na coluna \"JOB\", sem alterar o datafram original, e pega os possíveis valores nesta coluna.\njobs = df['JOB'].dropna().unique()\n\n#Cria uma série de histogramas da váriavel \"VALUE\" segmentando pela variável \"JOB\"\nplt.figure(figsize=(14,15))\nc=1\nfor i in jobs:\n    plt.subplot(7,1,c)\n    plt.title(i)\n    df[df['JOB'] == i]['VALUE'].hist(bins=20)\n    c+=1\nplt.tight_layout() \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como já demonstrado nos gráficos anteriores aqui consguimos perceber também a ligeira diferença entre as médias para esta variável para cada ocupaçã do indivíduo."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Motra um histograma dos valores presentes na variável \"VALUE\" onde na coluna JOB está faltando dado\nprint(df[df['JOB'].isnull()]['VALUE'].hist(bins=20))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false,"_kg_hide-output":false},"cell_type":"code","source":"#Cria uma série de boxplot relacionando as variáveis númericas com a variável categórica \"REASON\".\nplt.figure(figsize=(18,18))\nc = 1\nfor i in df_numeric_feats.columns:\n    if c < len(df_numeric_feats.columns):\n        plt.subplot(3,3,c)\n        sns.boxplot(x='REASON' , y= i, data=df)\n        c+=1\n    else:\n        sns.boxplot(x='REASON' , y= i, data=df)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id=\"2.3\"> 2.3. Atestando algumas informações </a>"},{"metadata":{},"cell_type":"markdown","source":"Para atestar estatisticamente algumas das informações obtidas com a visualização dos dados anteriormente será realizado alguns testes estatísticos.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importando as bibliotecas necessárias\nimport scipy.stats as stats\nfrom scipy.stats import ttest_ind","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id=\"2.3.1\"> 2.3.1. Teste de Normalidade </a>"},{"metadata":{},"cell_type":"markdown","source":"Primeiro, será realizado um teste para verificar a normalidade da distribuição dos valores da variável \"VALUE\" segmentada pela variável \"REASON\" para seguir então para o teste de diferença das médias. "},{"metadata":{},"cell_type":"markdown","source":"Para este teste será utilizado o teste de Shapiro–Wilk\n\n$${{W} = {\\frac{(\\sum_{i=1}^{n} {a}_{i}{x}_{(i)})^{2}}{\\sum_{i=1}^{n}({x}^{i} - \\tilde{x})^{2}}}}$$"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Seleciona os valores da variável \"VALUE\" onde o valor da varoável \"REASON\" e igual a \"HomeImp\"\ndf_reason_homeimp = df[df['REASON']=='HomeImp']['VALUE']\n# Seleciona os valores da variável \"VALUE\" onde o valor da varoável \"REASON\" e igual a \"DebtCon\"\ndf_reason_debtcon = df[df['REASON']=='DebtCon']['VALUE']\n\n# teste Shapiro-Wilk (Normalidade) para o subconjunto da variável \"VALUE\" onde o valor da variável \"REASON\" e igual a \"HomeImp\"\nshapiro_stat_reason_homeimp, shapiro_p_valor_reason_homeimp = stats.shapiro(df_reason_homeimp)\n# teste Shapiro-Wilk (Normalidade) para o subconjunto da variável \"VALUE\" onde o valor da variável \"REASON\" e igual a \"DebtCon\"\nshapiro_stat_reason_debtcon, shapiro_p_valor_reason_debtcon = stats.shapiro(df_reason_debtcon)\n\n# Mostra o P valor do teste de normalidade\nprint('teste de normalidade')\nprint('reason homeimp: {}'.format(shapiro_p_valor_reason_homeimp))\nprint('reason_debtcon: {}'.format(shapiro_p_valor_reason_debtcon))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Seleciona os valores da variável \"VALUE\" onde o valor da varoável \"BAD\" e igual a \"1\"\ndf_bad1 = df[df['BAD']== 1]['VALUE']\n# Seleciona os valores da variável \"VALUE\" onde o valor da varoável \"BAD\" e igual a \"0\"\ndf_bad0 = df[df['BAD']== 0]['VALUE']\n\n# teste Shapiro-Wilk (Normalidade) da biblioteca scipy para o subconjunto da variável \"VALUE\" onde o valor da variável \"bAD\" e igual a \"1\"\nshapiro_stat_bad1,  shapiro_p_valor_bad1 = stats.shapiro(df_bad1)\n# teste Shapiro-Wilk (Normalidade) da biblioteca scipy para o subconjunto da variável \"VALUE\" onde o valor da variável \"bAD\" e igual a \"0\"\nshapiro_stat_bad0, shapiro_p_valor_bad0 = stats.shapiro(df_bad0)\n\n# Mostra o P valor do teste de normalidade\nprint('teste de normalidade')\nprint('Value com Bad igual a 1: {}'.format(shapiro_p_valor_bad1))\nprint('Value com Bad igual a 0: {}'.format(shapiro_p_valor_bad0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Seleciona os valores da variável \"DEBTINC\" onde o valor da varoável \"BAD\" e igual a \"1\"\ndf_debtinc_bad1 = df[df['BAD']== 1]['DEBTINC']\n# Seleciona os valores da variável \"DEBTINC\" onde o valor da varoável \"BAD\" e igual a \"0\"\ndf_debtinc_bad0 = df[df['BAD']== 0]['DEBTINC']\nshapiro_stat_bad1,  shapiro_p_valor_debtinc_bad1 = stats.shapiro(df_debtinc_bad1)\nshapiro_stat_bad0, shapiro_p_valor_debtinc_bad0 = stats.shapiro(df_debtinc_bad0)\n\n# Mostra o P valor do teste de normalidade\nprint('teste de normalidade')\nprint('Debtinc com Bad igual a 1: {}'.format(shapiro_p_valor_debtinc_bad1))\nprint('Debtinc com Bad igual a 0: {}'.format(shapiro_p_valor_debtinc_bad0))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Considerando um $\\alpha $ = 0.05 não se discarta a hipotese nula, tendo em vista que o P Value resultado destes testes. Ou seja, estas distribuições se aproximam de uma distribuição normal."},{"metadata":{},"cell_type":"markdown","source":"### <a id=\"2.3.2\"> 2.3.2. Teste de hipótese </a>"},{"metadata":{},"cell_type":"markdown","source":"Considerando que a distribuiçãço destes dubconjuntos se aproxima de uma distribuição normal, a variáncia dos mesmos são parecidas e o tamanha das amostras são diferentes, será realizado o T-Test para testar a diferença entre as médias.\n\n$${{t} = {\\frac{\\tilde{x}_{1} - \\tilde{x}_{2}}{{S}_{x_1 x_2} .\\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}}}}$$"},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove os valores campos com valores faltantes, sem alterar o dataframe original e realiza o t-test atraves da função ttest_ind da biblioteca scipy\n_, ttest_p_value = ttest_ind(df_reason_homeimp.dropna(), df_reason_debtcon.dropna())\n\n# Mostra o P valor  do t-teste\nprint('T-teste: {:.4f}'.format(ttest_p_value))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Considerando um $\\alpha $ = 0.05, não se regeita a hipótese nula, sendo assim, as media dos valores da propriedades dos indivíduos que pegaram emprestimos para melhorias da propriedade (HomeImp) e a média do valor da propriedade dos indivíduos que pegaram emprestimos para a consolidação de créditos (DebtCon) não se diferem."},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove os valores campos com valores faltantes, sem alterar o dataframe original e realiza o t-test atraves da função ttest_ind da biblioteca scipy\n_, ttest_p_value_bad = ttest_ind(df_bad1.dropna(), df_bad0.dropna())\n\n# Mostr o P valor do teste\nprint('T-teste: {:.4f}'.format(ttest_p_value_bad))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Considerando um $\\alpha $ = 0.05, regeita-se a hipótese nula, sendo assim, as media dos valores da propriedades dos indivíduos que não foram inadimplentes e os que foram, se diferem."},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove os valores campos com valores faltantes, sem alterar o dataframe original e realiza o t-test atraves da função ttest_ind da biblioteca scipy\n_, ttest_p_value_debtinc_bad = ttest_ind(df_debtinc_bad1.dropna(), df_debtinc_bad0.dropna())\n\n# Mostr o P valor do teste\nprint('T-teste: {:.4f}'.format(ttest_p_value_debtinc_bad))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Considerando um $\\alpha $ = 0.05, regeita-se a hipótese nula, sendo assim, as media dos valores das taxas que ainda estão por vir dos indivíduos que estão em dia com seus emprestimos e a média do valores das taxas que ainda estão por vir dos indivíduos que fora inadimplentos em seus emprestimso se diferem."},{"metadata":{},"cell_type":"markdown","source":"### <a id='2.3.3'> 2.3.3. Análise de Variancia One Way </a>"},{"metadata":{},"cell_type":"markdown","source":"Não é interessante utilizar os métodos para o teste de média entre duas variáveis como o T test para testar  diferença entre muitas muitas variáveis, pois isto se tornaria um processo muito oneroso. Para isso existe a analise de variâcia (Analise Of Variance - ANOVA)\n"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# pegando os valores da variável \"VALUE\" e agrupando por ocupação \"JOB\"\nanova_value_by_job = {job:df['VALUE'][df['JOB'] == job] for job in jobs}\n\n# realizando o teste de análise de variácia\n_, anova_value_job_p = stats.f_oneway(anova_value_by_job['Other'].dropna(),\n                                          anova_value_by_job['Office'].dropna(),\n                                          anova_value_by_job['Sales'].dropna(),\n                                          anova_value_by_job['Mgr'].dropna(),\n                                          anova_value_by_job['ProfExe'].dropna(), \n                                          anova_value_by_job['Self'].dropna())\n# Mostra o P value do teste\nprint('One Way Anova: {:.4f}'.format(anova_value_job_p))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Considerando um $\\alpha $ = 0.05, podemos dizer que a média de \"VALUE\" em pelo menos uma das ocupações e diferente das demais."},{"metadata":{},"cell_type":"markdown","source":"No intúito de verificar se removendo os outliers estas médias continuariam resultando em um P valor baixo para a ANOVA, fora realizada a remoção dos outliers utilizando a regra do IQR (Inter Quartile Range) que diz que valores menores que 1.5 * Quartil 1 ou maiores que 1.5 * o Quartil 3 são considerados outliers."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculando o primeiro quartil da variável \"VALUE\"\nq1 = df['VALUE'].quantile(0.25)\n# Calculando o terceiro quartil da variável \"VALUE\"\nq3 = df['VALUE'].quantile(0.75)\n\n# Calculando o IQR\niqr = q3 - q1 \n\n# Guardando domente os valores que não são considerados outliers \ndf_value_and_job_no_outlier = df[~((df['VALUE'] < (q1 - 1.5  * iqr)) | (df['VALUE']  > (q3 + 1.5 * iqr)))][['VALUE', 'JOB', 'BAD']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando se as medias continuao diferentes\nanova_value_by_job = {job:df_value_and_job_no_outlier['VALUE'][df_value_and_job_no_outlier['JOB'] == job] for job in jobs}\nanova_job_f, anova_job_p = stats.f_oneway(anova_value_by_job['Other'].dropna(),\n                                          anova_value_by_job['Office'].dropna(),\n                                          anova_value_by_job['Sales'].dropna(),\n                                          anova_value_by_job['Mgr'].dropna(),\n                                          anova_value_by_job['ProfExe'].dropna(), \n                                          anova_value_by_job['Self'].dropna())\n#Mostra o P valor do teste\nprint('One Way Anova: {:.4f}'.format(anova_job_p))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Houve mundança no resultado, contudo, ainda assim, considerando o alpha já estabelecido de 5%, a média do valor da variável \"VALUE\" em pelo menos uma das ocupações e diferente das demais."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='JOB', y='VALUE', data=df_value_and_job_no_outlier)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nanova_debtinc_by_job = {job:df['DEBTINC'][df['JOB'] == job] for job in jobs}\nanova_debtinc_f, anova_debtinc_p = stats.f_oneway(anova_debtinc_by_job['Other'].dropna(),\n                                          anova_debtinc_by_job['Office'].dropna(),\n                                          anova_debtinc_by_job['Sales'].dropna(),\n                                          anova_debtinc_by_job['Mgr'].dropna(),\n                                          anova_debtinc_by_job['ProfExe'].dropna(), \n                                          anova_debtinc_by_job['Self'].dropna())\n#Ao menos um dos Jobs tem valores diferentes entre si, estatisticamente falando\nprint('One Way Anova: {:.4f}'.format(anova_debtinc_p))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Verificando agora a variável \"DEBTINC\" pela ocupação dos indivíduos, considerando o P valor ao menos um das ocupações apresenta um valor médio diferente das demais para a variável \"DEBTINC\"."},{"metadata":{},"cell_type":"markdown","source":"Para a variável \"YOJ\" será realizado a mesma verificação retirando os outliers."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Selecionando o primeiro Quartil da variável \"YOJ\"\nq1 = df['YOJ'].quantile(0.25)\n# Selecionando o segundo Quartil da variável \"YOJ\"\nq3 = df['YOJ'].quantile(0.75)\n\n#Ralizando o calculo do iqr\niqr = q3 - q1\n\n#descartando os outliers e \ndf_yoj_and_job_no_outlier = df[~((df['YOJ'] < (q1 - 1.5  * iqr)) | (df['YOJ']  > (q3 + 1.5 * iqr)))][['YOJ', 'JOB']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nanova_yoj_by_job = {job:df_yoj_and_job_no_outlier['YOJ'][df_yoj_and_job_no_outlier['JOB'] == job] for job in jobs}\nanova_yoj_f, anova_yoj_p = stats.f_oneway(anova_yoj_by_job['Other'].dropna(),\n                                          anova_yoj_by_job['Office'].dropna(),\n                                          anova_yoj_by_job['Sales'].dropna(),\n                                          anova_yoj_by_job['Mgr'].dropna(),\n                                          anova_yoj_by_job['ProfExe'].dropna(), \n                                          anova_yoj_by_job['Self'].dropna())\n#Ao menos um dos Jobs tem valores diferentes entre si, estatisticamente falando\nprint('One Way Anova: {:.4f}'.format(anova_yoj_p))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Assim como as anteriores e conforme mostrado nos gáficos, estatisticamente há pelo menos uma das categorias que possui o valor médio na variável \"YOJ\" diferente das demais."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='JOB', y= 'YOJ', data=df_yoj_and_job_no_outlier)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a id='3'> 3. Manipulação da base </a>"},{"metadata":{},"cell_type":"markdown","source":"## <a id='3.1'> 3.1. Imputação dos dados </a>"},{"metadata":{},"cell_type":"markdown","source":"Agora que já foram atestadas as informações que fora percebido na analise dos gráficos, estas serão utilizadas para o tratamento da base.\nO valor médio da variável \"VALUE\" foi constatado que difera entre os diferentes tipos de ocupação do indivíduo, variável \"JOB\", e difere também entre os indivíduos adimplentes e inadimlentes, sendo assim um metodo conciso para para a imputação dos dados seria pela média de \"VALUE\" por \"JOB\" e BAD. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Salvando as médias da variável VALUE por ocupação\nvalue_mean_by_job = df_value_and_job_no_outlier.groupby(['JOB', 'BAD'])['VALUE'].mean()\n\n# instancia um objeto pandas series sem conteúdo.\nimp_value = pd.Series([]) \n\n'''\nreseta o idice do data frame para garantir \nque cada iteração verifique um ídice do \ndataframe evitando com que observações \nfiquem sem ser verificadas.\n'''\ndf.reset_index()\n'''\nitera sobre o dataframe e, caso valor do \ncampo \"VALUE\" esteja nulo, verifica a \nocupação do indivíduo e coloca a média de \n\"VALUE\" para aquele \"JOB\" naquela posição \ndentro de um objeto Series, caso \"VALUE\"\nnão seja nulo, atribui ao objeto o próprio\nvalor de \"VALUE\"\n'''\nfor i in range(len(df)):\n    if df['VALUE'][i] != df['VALUE'][i]:\n        if df['JOB'][i] == 'Mgr':\n            if df['BAD'][i] == 0:\n                imp_debtinc[i] = value_mean_by_job['Mgr'][0]\n            else:\n                imp_value[i] = value_mean_by_job['Mgr'][1]\n        if df['JOB'][i] == 'Office':\n            if df['BAD'][i] == 0:\n                imp_value[i] = value_mean_by_job['Office'][0]\n            else:\n                imp_value[i] = value_mean_by_job['Office'][1]\n        if df['JOB'][i] == 'Other':\n            if df['BAD'][i] == 0:\n                imp_value[i] = value_mean_by_job['Other'][0]\n            else:\n                imp_value[i] = value_mean_by_job['Other'][1]\n        if df['JOB'][i] == 'ProfExe':\n            if df['BAD'][i] == 0:\n                imp_value[i] = value_mean_by_job['ProfExe'][0]\n            else:\n                imp_value[i] = value_mean_by_job['ProfExe'][1]\n        if df['JOB'][i] == 'Sales':\n            if df['BAD'][i] == 0:\n                imp_value[i] = value_mean_by_job['Sales'][0]\n            else:\n                imp_value[i] = value_mean_by_job['Sales'][1]\n        if df['JOB'][i] == 'Self':\n            if df['BAD'][i] == 0:\n                imp_value[i] = value_mean_by_job['Self'][0]\n            else:\n                imp_value[i] = value_mean_by_job['Self'][1]\n            \n    else: \n        imp_value[i] = df['VALUE'][i]\n'''\ncasi já exista alguma coluna com o nome IMP_VALUE\nrealiza a exclusão o mesmo\n'''\nif \"IMP_VALUE\" in np.array(df.columns):\n    df.drop(\"IMP_VALUE\", axis=1, inplace=True)\n    \n# Inserie o objeto no dataframe como uma coluna\ndf.insert(13, \"IMP_VALUE\", imp_value) \ndf.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Seleciona as observações do dataframe onde a coluna \"IMP_VALUE\" apresenta valores faltantes\ndf[df['IMP_VALUE'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vemos que alguns campos ainda ficaram com dados faltantes, pois o campo \"JOB\" também possui dados faltantes. Ao mesmo tempo é possíve ver que existem algumas obsesrvações que preticamente só possuem o valor da variável \"BAD\" e \"LOAN\", neste caso a melhor opção no momento foi dropar esta observações que possuem mais que 10 campos missings."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Descarta todas as observações que possuam mais que 10 campos com valores faltantes.\ndf.dropna(thresh=10, inplace=True)\n# Mostra a estrutura do dataframe\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Seleciona as observações do dataframe onde a coluna \"IMP_VALUE\" apresenta valores faltantes\ndf[df['IMP_VALUE'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dropna(axis=0,subset=['IMP_VALUE'], inplace=True)\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Agora com a variável \"IMP_VALUE\", a variável \"VALUE\" não será mais necessária, tendo em vista que transmite a mesma informação. Sendo assim, a mesma será descartada."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop('VALUE', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dentro das variáveis com valores faltantes, temos as duas variáveis qualititavas da base \"JOB\" e \"REASON\".\nTendo em vista as diferentes médias que as outras variáveis tem quando agrupadas por estas variáveis, seria interessante tentar imputar esta coluna utilizando um ensemble metodo como GBM ou Random Forest, contudo, por hora, foi decidido apenas dropar estas observações."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dropna(axis=0, subset=['JOB'], inplace=True)\ndf.dropna(axis=0, subset=['REASON'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Anteriormente durante a análise gráfico percebeu-se uma certa correlação entre a variável \"VALUE\" agora \"IMP_VALUE\" e a variável \"MORTDUE\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['IMP_VALUE', 'MORTDUE']].corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(df['IMP_VALUE'], df['MORTDUE'])\nplt.ylabel('IMP_VALUE')\nplt.xlabel('MORTDUE')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Sendo assim, uma forma interessante de se imputar os dados neste caso seria através de uma regressão linear."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_mortdue = df[df['MORTDUE'].isnull()][['IMP_VALUE', 'MORTDUE']]\nnot_missing_mortdue = df[df['MORTDUE'].notnull()][['IMP_VALUE', 'MORTDUE']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = not_missing_mortdue['IMP_VALUE'].values.reshape(-1, 1)\ny = not_missing_mortdue['MORTDUE'].values.reshape(-1, 1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LinearRegression()\nlr.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mortdue_pred = lr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"real_vs_pred = pd.DataFrame({'Real': y_test.flatten(), 'Predito': mortdue_pred.flatten()})\nreal_vs_pred.sample(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplt.scatter(X_test, y_test, color='gray')\nplt.plot(X_test, mortdue_pred, color='red', linewidth=2)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Raiz quadrada do Erro medio ao quadrado: {}'.format(np.sqrt(metrics.mean_squared_error(y_test, mortdue_pred))))\nprint('R quadrado: {}'.format(metrics.r2_score(y_test, mortdue_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# trantando outliers para tentar diminuir o erro.\n# calculando o iqr\nq1 = not_missing_mortdue.quantile(0.25)\nq3 = not_missing_mortdue.quantile(0.75)\n\niqr = q3-q1\n\nprint(iqr)\nnot_missing_and_outliers_mortdue = not_missing_mortdue[~((not_missing_mortdue < (q1 - 1.5  * iqr)) | (not_missing_mortdue > (q3 + 1.5 * iqr))).any(axis=1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"not_missing_mortdue.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"not_missing_and_outliers_mortdue.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_no_outliers = not_missing_and_outliers_mortdue['IMP_VALUE'].values.reshape(-1, 1)\ny_no_outliers = not_missing_and_outliers_mortdue['MORTDUE'].values.reshape(-1, 1)\nX_no_outliers_train, X_no_outliers_test, y_no_outliers_train, y_no_outliers_test = train_test_split(X_no_outliers, y_no_outliers, test_size=0.20, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_no_outliers = LinearRegression()\nlr_no_outliers.fit(X_no_outliers_train, y_no_outliers_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mortdue_pred = lr.predict(X_test)\nreal_vs_pred = pd.DataFrame({'Real': y_test.flatten(), 'Predito': mortdue_pred.flatten()})\nreal_vs_pred.sample(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Raiz quadrada do Erro medio ao quadrado: {:.2f}'.format(np.sqrt(metrics.mean_squared_error(y_test, mortdue_pred))))\nprint('R quadrado: {}'.format(metrics.r2_score(y_test, mortdue_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplt.scatter(X_test, y_test, color='gray')\nplt.plot(X_test, mortdue_pred, color='red', linewidth=2)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imp_mortdue = pd.Series([])\nimp_mortdue = lr.predict(df['IMP_VALUE'].values.reshape(-1,1))\nimp_mortdue","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.insert(13, 'IMP_MORTDUE', np.round(imp_mortdue, 2))\ndf.drop('MORTDUE', axis=1, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='JOB', y='DEBTINC', data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='BAD', y='DEBTINC', data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q1 = df['DEBTINC'].quantile(0.25)\nq3 = df['DEBTINC'].quantile(0.75)\n\niqr = q3 - q1\n\ndf_debtinc_and_job_no_outlier = df[~((df['DEBTINC'] < (q1 - 1.5  * iqr)) | (df['DEBTINC']  > (q3 + 1.5 * iqr)))][['DEBTINC', 'JOB', 'BAD']]\ndebtinc_mean_by_job = df_debtinc_and_job_no_outlier.groupby(['JOB', 'BAD'])['DEBTINC'].mean()\ndebtinc_mean_by_job\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"debtinc_mean_by_job['Mgr'][1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imp_debtinc = pd.Series([]) \n\ndf.reset_index(inplace=True)\nfor i in range(len(df)):\n    if df['DEBTINC'][i] != df['DEBTINC'][i]:\n        if df['JOB'][i] == 'Mgr':\n            if df['BAD'][i] == 0:\n                imp_debtinc[i] =  debtinc_mean_by_job['Mgr'][0]\n            else:\n                imp_debtinc[i] =  debtinc_mean_by_job['Mgr'][1]\n        if df['JOB'][i] == 'Office':\n            if df['BAD'][i] == 0:\n                imp_debtinc[i] =  debtinc_mean_by_job['Office'][0]\n            else:\n                imp_debtinc[i] =  debtinc_mean_by_job['Office'][1]\n        if df['JOB'][i] == 'Other':\n            if df['BAD'][i] == 0:\n                imp_debtinc[i] =  debtinc_mean_by_job['Other'][0]\n            else:\n                imp_debtinc[i] =  debtinc_mean_by_job['Other'][1]\n        if df['JOB'][i] == 'ProfExe':\n            if df['BAD'][i] == 0:\n                imp_debtinc[i] =  debtinc_mean_by_job['ProfExe'][0]\n            else:\n                imp_debtinc[i] =  debtinc_mean_by_job['ProfExe'][1]\n        if df['JOB'][i] == 'Sales':\n            if df['BAD'][i] == 0:\n                imp_debtinc[i] =  debtinc_mean_by_job['Sales'][0]\n            else:\n                imp_debtinc[i] =  debtinc_mean_by_job['Sales'][1]\n        if df['JOB'][i] == 'Self':\n            if df['BAD'][i] == 0:\n                imp_debtinc[i] =  debtinc_mean_by_job['Self'][0]\n            else:\n                imp_debtinc[i] =  debtinc_mean_by_job['Self'][1]\n    else: \n        imp_debtinc[i] = df['DEBTINC'][i]\n\nif \"IMP_DEBTINC\" in np.array(df.columns):\n    df.drop(\"IMP_DEBTINC\", axis=1, inplace=True)\n    \ndf.insert(13, \"IMP_DEBTINC\", imp_debtinc) \ndf.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop('DEBTINC', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='JOB', y='YOJ', data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yoj_mean_by_job = df_yoj_and_job_no_outlier.groupby(['JOB'])['YOJ'].mean()\nimp_yoj = pd.Series([]) \n\ndf.reset_index(inplace=True)\nfor i in range(len(df)):\n    if df['YOJ'][i] != df['YOJ'][i]:\n        if df['JOB'][i] == 'Mgr':\n            imp_yoj[i] =  yoj_mean_by_job['Mgr']\n        if df['JOB'][i] == 'Office':\n            imp_yoj[i] = yoj_mean_by_job['Office']\n        if df['JOB'][i] == 'Other':\n            imp_yoj[i] = yoj_mean_by_job['Other']\n        if df['JOB'][i] == 'ProfExe':\n            imp_yoj[i] = yoj_mean_by_job['ProfExe']\n        if df['JOB'][i] == 'Sales':\n            imp_yoj[i] = yoj_mean_by_job['Sales']\n        if df['JOB'][i] == 'Self':\n            imp_yoj[i] = yoj_mean_by_job['Self']\n    else: \n        imp_yoj[i] = df['YOJ'][i]\n        \nif \"IMP_YOJ\" in np.array(df.columns):\n    df.drop(\"IMP_YOJ\", axis=1, inplace=True)\n    \ndf.insert(13, \"IMP_YOJ\", imp_yoj) \ndf.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop('YOJ', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Em virtude a falta de tempo para as outra variaveis (DEROG,DELINQ, CLAGE e NINQ)  fora imputadas pela media \ndf.fillna(df.mean(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# antes de ir para o modelo propriamente dito vou realizar um one hot encoding nas variaveis categoricas.\ndf = pd.get_dummies(data=df, columns=['JOB', 'REASON'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Iniciando o modelo de predicao","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pip install -U scikit-learn == 0.22.1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pip install -U imbalanced-learn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Classes desbalanceadas, vamos rodar um modelo com as classes do jeito que estao.\ndf['BAD'].value_counts().plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\nfrom sklearn.metrics import classification_report\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feats = [c for c in df.columns if c not in ['BAD']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df[feats]\ny = df['BAD']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid_decision_tree = {\n    'criterion': ('gini', 'entropy'),\n    'splitter': ('best', 'random'),\n    'max_features': ('auto', 'sqrt', 'log2')\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_decision_tree = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid_decision_tree)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_decision_tree.fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('\\nOs melhores parametros foram: \\n' + str(grid_decision_tree.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_decision_tree = cross_val_score(grid_decision_tree, X, y, cv=10)\nprint(cv_decision_tree)\nprint(cv_decision_tree.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid_random_forest = {\n    'criterion': ('gini', 'entropy'),\n    'max_features': ('log2', 'sqrt')\n}\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_random_forest_classifier = GridSearchCV(RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1, bootstrap = True, oob_score = True), param_grid_random_forest)\ngrid_random_forest_classifier.fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('\\nOs melhores parametros foram: \\n' + str(grid_random_forest_classifier.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_random_forest = cross_val_score(grid_random_forest_classifier, X, y, cv=10, n_jobs=-1)\nprint(cv_random_forest)\nprint(cv_random_forest.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid_gbost_classifier = {\n    'criterion': ['friedman_mse', 'mse', 'mae'],\n    'max_features': ('log2', 'sqrt')\n} ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_gradiente_boost_machine = GridSearchCV(GradientBoostingClassifier(n_estimators=200, learning_rate=1.0, max_depth=1, random_state=42, n_jobs=-1), param_grid_gbost_classifier)\ngrid_gradiente_boost_machine.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('\\nOs melhores parametros foram: \\n' + str(grid_gradiente_boost_machine.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_gradiente_boost_machine = cross_val_score(grid_gradiente_boost_machine, X, y, cv=10)\nprint(cv_gradiente_boost_machine)\nprint(cv_gradiente_boost_machine.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# realizando um over sapling da classe minoritaria\nsmt = SMOTE(sampling_strategy=0.80)\nX, y = smt.fit_sample(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.value_counts().plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_decision_tree.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_decision_tree = cross_val_score(grid_decision_tree, X, y, cv=10, n_jobs=-1)\nprint(cv_decision_tree)\nprint(cv_decision_tree.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_random_forest_classifier.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_random_forest = cross_val_score(grid_random_forest_classifier, X, y, cv=10, n_jobs=-1)\nprint(cv_random_forest)\nprint(cv_random_forest.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_gradiente_boost_machine.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_gradiente_boost_machine = cross_val_score(grid_gradiente_boost_machine, X, y, cv=10, n_jobs=-1)\nprint(cv_gradiente_boost_machine)\nprint(cv_gradiente_boost_machine.mean())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}