{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Predicting Train Ticket Prices"},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nsns.set(style=\"darkgrid\")\nsns.set(rc={'figure.figsize':(9,6)})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load data\ndata = pd.read_csv(\"../input/renfe.csv\")\n#Lets drop missing values for EDA\ndata = data.dropna(axis=0,how='any')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For this simple analysis I just dropped any data points that were missing values."},{"metadata":{},"cell_type":"markdown","source":"The code aggregates the origin and destination into one variable called route."},{"metadata":{"trusted":true},"cell_type":"code","source":"data['duration'] = (pd.to_datetime(data.end_date)-pd.to_datetime(data.start_date)).apply(lambda x: (x.seconds)/60)\n#Some fares are too small and redundent combine them to for other\ndata.fare.replace(['Individual-Flexible','Mesa','Grupos Ida'],'Other',inplace=True)\ndata['route'] = data.origin+data.destination\n# One hot encode routes and add to data frame\nroute_names = {}\ni = 1\nfor route in data.route.unique().tolist():\n    route_names[\"route_\"+route] = \"route\"+str(i)\n    i = i+1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets split the start date to month, day and dayname. I did not split the end date because the duration of the trips was less than 1 day."},{"metadata":{"trusted":true},"cell_type":"code","source":"#add month\ndata['month'] = pd.to_datetime(data.start_date).apply(lambda x: x.month)\ndata['day'] = pd.to_datetime(data.start_date).apply(lambda x: x.day)\ndata['dayname'] = pd.to_datetime(data.start_date).apply(lambda x: x.day_name())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.rename(index=str,columns=route_names)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distribution of prices and train duration\nfig,axs = plt.subplots(ncols=2,nrows=1,figsize=(15,5))\n_ = sns.distplot(data.price,ax=axs[0])\n_ = sns.distplot(data.duration,ax=axs[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The figures above show the distribution of price for a ticket and the duration for the trip."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets check the count fo the categorical variables\nfig,axs = plt.subplots(ncols=2,nrows=2,figsize=(15,15))\n_ = sns.countplot(x=data.route,ax=axs[0,0]).set_xticklabels(rotation=90,labels=data.route.unique())\n_ = sns.countplot(x=data.train_class,ax=axs[0,1]).set_xticklabels(rotation=90,labels=data.train_class.unique())\n_ = sns.countplot(x=data.train_type,ax=axs[1,0]).set_xticklabels(rotation=90,labels=data.train_type.unique())\n_ = sns.countplot(x=data.fare,ax=axs[1,1]).set_xticklabels(rotation=90,labels=data.fare.unique())\nfig.subplots_adjust(hspace=.9)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The categorical variables are unevenly distributed."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets check how they might effect the price\nfig,axs = plt.subplots(ncols=2,nrows=4,figsize=(15,15))\n_ = sns.violinplot(x=data.route,y=data.price,ax=axs[0,0]).set_xticklabels(rotation=90,labels=data.route.unique())\n_ = sns.violinplot(x=data.train_class,y=data.price,ax=axs[0,1]).set_xticklabels(rotation=90,labels=data.train_class.unique())\n_ = sns.violinplot(x=data.train_type,y=data.price,ax=axs[1,0]).set_xticklabels(rotation=90,labels=data.train_type.unique())\n_ = sns.violinplot(x=data.fare,y=data.price,ax=axs[1,1]).set_xticklabels(rotation=90,labels=data.fare.unique())\n_ = sns.violinplot(x=data.month,y=data.price,ax=axs[2,0]).set_xticklabels(rotation=90,labels=data.month.unique())\n_ = sns.violinplot(x=data.dayname,y=data.price,ax=axs[2,1]).set_xticklabels(rotation=90,labels=data.dayname.unique())\n_ = sns.violinplot(x=data.day,y=data.price,ax=axs[3,0]).set_xticklabels(rotation=90,labels=data.day.unique())\nfig.subplots_adjust(hspace=1.5)\nfig.delaxes(axs[3,1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above figue, we can see that there are clear distinction between the classes for the average price of the train ticket.\nThe distinction is not as obvious for the day plot. Months and dayname have different distributions as well. This suggesting that different months and days will have an impact on the price."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets check the data ranges\nfig,axs = plt.subplots(ncols=2,nrows=4,figsize=(15,15))\n_ = sns.boxplot(x=data.route,y=data.price,ax=axs[0,0]).set_xticklabels(rotation=90,labels=data.route.unique())\n_ = sns.boxplot(x=data.train_class,y=data.price,ax=axs[0,1]).set_xticklabels(rotation=90,labels=data.train_class.unique())\n_ = sns.boxplot(x=data.train_type,y=data.price,ax=axs[1,0]).set_xticklabels(rotation=90,labels=data.train_type.unique())\n_ = sns.boxplot(x=data.fare,y=data.price,ax=axs[1,1]).set_xticklabels(rotation=90,labels=data.fare.unique())\n_ = sns.boxplot(x=data.month,y=data.price,ax=axs[2,0]).set_xticklabels(rotation=90,labels=data.month.unique())\n_ = sns.boxplot(x=data.dayname,y=data.price,ax=axs[2,1]).set_xticklabels(rotation=90,labels=data.dayname.unique())\n_ = sns.boxplot(x=data.day,y=data.price,ax=axs[3,0]).set_xticklabels(rotation=90,labels=data.day.unique())\nfig.subplots_adjust(hspace=1.5)\nfig.delaxes(axs[3,1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Box plots reveal similar story about the distribution of prices for each category."},{"metadata":{},"cell_type":"markdown","source":"## Lets check how our dates effects the price more closely."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,axs = plt.subplots(ncols=2,nrows=2,figsize=(15,15))\n_ = sns.lineplot(x='dayname',y='price',data=data,ax=axs[0,0])\n_ = sns.lineplot(x='month',y='price',data=data,ax=axs[0,1])\n_ = sns.lineplot(x='day',y='price',data=data,ax=axs[1,0])\nfig.delaxes(axs[1,1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This information suggests that there are differences in pricing given the dayname and price. We should treat these variables as categorical variables. On the other hand, day of the month will be treated as ordinal for model simplicity. It's interesting to note that the cheapest tickets are on the 15th of each month,saturday, and in july."},{"metadata":{},"cell_type":"markdown","source":"##  Lets perform basic linear regression to check which variables are statistically significant predictors\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_i = data[['route','month','dayname','train_class','train_type','fare','duration','day','price']]\ndata_i.price = (data_i.price - data_i.price.mean())/data_i.price.std()\ndata_i.duration = (data_i.duration - data_i.duration.mean())/data_i.duration.std()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_i.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"formula = \"price~C(route)+C(month)+C(dayname)+C(train_class)+C(train_type)+C(fare)+duration+day\"\n#Due to multico had to drop train_type and day\nformula = \"price~C(route)+C(month)+C(dayname)+C(train_class)+C(fare)+duration\"\n\n# Unable to run due to issues with statsmodel\n# import statsmodels.formula.api as smf\n# reg = smf.ols(formula = formula,data=data_i).fit()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"#reg.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"       \"                            OLS Regression Results                            \",\n       \"==============================================================================\",\n       \"Dep. Variable:                  price   R-squared:                       0.816\",\n       \"Model:                            OLS   Adj. R-squared:                  0.816\",\n       \"Method:                 Least Squares   F-statistic:                 3.858e+05\",\n       \"Date:                Sat, 22 Jun 2019   Prob (F-statistic):               0.00\",\n       \"Time:                        12:57:47   Log-Likelihood:            -1.3020e+06\",\n       \"No. Observations:             2269090   AIC:                         2.604e+06\",\n       \"Df Residuals:                 2269063   BIC:                         2.604e+06\",\n       \"Df Model:                          26                                         \",\n       \"Covariance Type:            nonrobust                                         \",\n       \"================================================================================\",\n       \"                                           coef    std err          t      P>|t|\",\n       \"--------------------------------------------------------------------------------\",\n       \"Intercept                                2.4169      0.057     42.167      0.000\",\n       \"C(route)[T.MADRIDBARCELONA]              0.0096      0.001     10.182      0.000\",\n       \"C(route)[T.MADRIDPONFERRADA]            -1.7084      0.002   -806.150      0.000\",\n       \"C(route)[T.MADRIDSEVILLA]               -1.2110      0.001  -1139.434      0.000\",\n       \"C(route)[T.MADRIDVALENCIA]              -1.6855      0.001  -1516.575      0.000\",\n       \"C(route)[T.PONFERRADAMADRID]            -1.7285      0.002   -834.537      0.000\",\n       \"C(route)[T.SEVILLAMADRID]               -1.2063      0.001  -1126.973      0.000\",\n       \"C(route)[T.VALENCIAMADRID]              -1.6672      0.001  -1495.629      0.000\",\n       \"C(month)[T.5]                           -0.1060      0.001   -135.860      0.000\",\n       \"C(month)[T.6]                           -0.1260      0.001   -101.805      0.000\",\n       \"C(month)[T.7]                           -0.1459      0.004    -40.722      0.000\",\n       \"C(dayname)[T.Monday]                    -0.1020      0.001    -97.370      0.000\",\n       \"C(dayname)[T.Saturday]                  -0.1679      0.001   -145.315      0.000\",\n       \"C(dayname)[T.Sunday]                     0.0258      0.001     23.941      0.000\",\n       \"C(dayname)[T.Thursday]                  -0.0904      0.001    -87.970      0.000\",\n       \"C(dayname)[T.Tuesday]                   -0.1406      0.001   -134.688      0.000\",\n       \"C(dayname)[T.Wednesday]                 -0.1104      0.001   -105.328      0.000\",\n       \"C(train_class)[T.Cama Turista]          -0.1204      0.059     -2.048      0.041\",\n       \"C(train_class)[T.Preferente]            -0.3115      0.057     -5.444      0.000\",\n       \"C(train_class)[T.Turista]               -1.2094      0.057    -21.141      0.000\",\n       \"C(train_class)[T.Turista Plus]          -0.8300      0.057    -14.509      0.000\",\n       \"C(train_class)[T.Turista con enlace]    -0.8561      0.057    -14.970      0.000\",\n       \"C(fare)[T.Flexible]                      0.6005      0.003    233.555      0.000\",\n       \"C(fare)[T.Other]                         3.5440      0.047     75.048      0.000\",\n       \"C(fare)[T.Promo]                        -0.5216      0.003   -202.514      0.000\",\n       \"C(fare)[T.Promo +]                      -0.2454      0.003    -74.600      0.000\",\n       \"duration                                -0.3481      0.001   -496.996      0.000\",\n       \"==============================================================================\",\n       \"Omnibus:                   186159.428   Durbin-Watson:                   1.568\",\n       \"Prob(Omnibus):                  0.000   Jarque-Bera (JB):           973915.556\",\n       \"Skew:                           0.217   Prob(JB):                         0.00\",\n       \"Kurtosis:                       6.180   Cond. No.                         887.\",\n       \"==============================================================================\",\n       \n       \"Warnings:\",\n       \"[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\","},{"metadata":{"trusted":true},"cell_type":"code","source":"#_ = sns.distplot(reg.resid)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see from the summary above that all of these variables are statistically significant in predicting the price of the ticket. The best forumla is price~C(route)+C(month)+C(dayname)+C(train_class)+C(fare)+duration. I dropped some variables as there was strong multicolinearity. Still, the model has a relatively high R-squared value. Now lets run random forest regression in scikit to improve the regression."},{"metadata":{"trusted":true},"cell_type":"code","source":"skdata  = data[['route','month','dayname','train_class','fare','price','duration']]\nskdata.duration = (skdata.duration - skdata.duration.mean())/skdata.duration.std()\nskdata = pd.get_dummies(skdata,columns=['route','month','dayname','train_class','fare'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skdata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.neural_network import MLPRegressor\n\n\nlinreg = LinearRegression()\nrfreg = RandomForestRegressor(n_estimators=10)\nnn = MLPRegressor(hidden_layer_sizes=(100,),\n                 activation='relu',\n                 solver='sgd',\n                 learning_rate='adaptive',\n                 learning_rate_init=.001,\n                 verbose=True)\ny = skdata.price\nx = skdata[skdata.keys()[1:]]\n\nprint(\"Linear Regression R-Squared: \",cross_val_score(linreg,cv=10,X=x,y=y))\nprint(\"RF Regression R-Squared: \",cross_val_score(rfreg,cv=10,X=x,y=y))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Unsurprisingly the random forest regression performs better than linear regression. Let's split the data into sets for validation and testing. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import train_test_split\n\ny = skdata.price\nx = skdata[skdata.keys()[1:]]\n\nX_train,X_test,y_train,y_test = train_test_split(x,y,test_size=.3)\n\nrf = RandomForestRegressor(n_estimators=10,\n                           n_jobs=4)\ncv  = KFold(n_splits=10,shuffle=True)\n\ntrain_r = []\ntest_r = []\ntest_mse = []\ni = 0\nfor train_idx,test_idx in cv.split(X=X_train,y=y_train):\n        i+=1\n        print(\"CV: \",i)\n        \n        \n        # Random forest regression\n        rf.fit(X=X_train.iloc[train_idx,:],y=y_train[train_idx])\n        train_r.append(rf.score(X_train.iloc[train_idx,:],y=y_train[train_idx]))\n        preds = rf.predict(X=X_train.iloc[test_idx,:])\n        test_r.append(r2_score(y_train.iloc[test_idx],preds))\n        test_mse.append(mean_squared_error(y_train.iloc[test_idx],preds))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets test the predictive ability of the model by predicting the prices for the trainning set."},{"metadata":{"trusted":true},"cell_type":"code","source":"test_p = rf.predict(X_test)\nrestest = y_test - test_p\npx = np.arange(0,len(test_p))\n\nfig,axs = plt.subplots(ncols=2,nrows=1,figsize=(15,5))\nax = sns.scatterplot(px[:100],test_p[:100],label=\"Predicted\",ax=axs[0])\nax = sns.scatterplot(px[:100],y_test[:100],label=\"Truth\",ax=axs[0])\nax = sns.scatterplot(px[:100],restest[:100],label=\"Res\",ax=axs[0])\nax.set(title=\"Comparing Some Predicted, Truth and the Residuals\")\nax2 = sns.distplot(restest,label=\"Residual Distribution\")\n_ = ax2.set(title=\"Residual Distribtion\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see from the plots above, that the random forest regression model has good predictive ability for the testing data set. Further more the residuals appear to be normal which suggests that the model was able to capture most of signal in the data. This is a good model."},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import normaltest\nfrom sklearn.metrics import explained_variance_score\nprint(\"PREDICTED MEAN SQUARED ERROR: \",mean_squared_error(y_test,test_p))\nprint(\"R2: \",r2_score(y_test,test_p))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion\nWe were able to fit the price of the train tickets with an R2 of 0.91. This is a very good fit. The only other model I tested was vanilla linear regression which had a lower R2 at around 0.81. "}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.2"}},"nbformat":4,"nbformat_minor":1}