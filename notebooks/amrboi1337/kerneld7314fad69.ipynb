{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Primeiro trabalho de Aprendizado de Máquina"},{"metadata":{},"cell_type":"markdown","source":"## Base de dados\n\nA base de dados pode ser encontrada em https://www.kaggle.com/jsphyg/weather-dataset-rattle-package\n\nEla contêm informações sobre observações diárias do tempo em várias estações meteorológicas da Austrália para prever se vai ou não chover amanhã através do treinamento de um modelo de classificação binária no alvo \"RainTomorrow\" (Sim ou Não)."},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Apresentação dos dados"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Import das bibliotecas necessárias para rodar o programa\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport sklearn.metrics\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score\nimport graphviz\nfrom sklearn import tree\nfrom sklearn.tree import export_graphviz\nfrom sklearn.metrics import roc_auc_score,roc_curve","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Lendo os dados do Dataset\ndados = pd.read_csv('weatherAUS.csv')\nprint(dados.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Visualizando as primeiras 5 instâncias do Dataset\ndados.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Analisando mais detalhadamente cada coluna do Dataset\ndados.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Verificando o tipo dos dados presentes na tabela\ndados.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pré-processamento"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Descobrindo se há dados faltantes, caso seja True pode-se afirmar que existem dados faltantes na respectiva coluna\ndados.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Colocando as colunas com dados faltantes em uma lista para serem tratadas futuramente. Nessa lista são colocadas\n# apenas as colunas com dados numéricos\ncolunas_dados_faltantes = ['MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'Sunshine', \\\n                           'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', \\\n                           'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', \\\n                           'Cloud3pm', 'Temp9am', 'Temp3pm']\n\n# Substituindo valores numéricos com a média dos valores não nulos presentes na coluna\nfor coluna in colunas_dados_faltantes:\n    dados[coluna] = dados[coluna].fillna(dados[coluna].mean())\n    \n# Colocando as colunas com dados faltantes em uma lista. Nessa lista são colocadas as colunas com dados categóricos\ncolunas_dados_categoricos = ['WindGustDir', 'WindDir3pm', 'WindDir9am']\n\n# Substituindo valores categóricos pela moda dos valores não nulos presentes na coluna\nfor coluna in colunas_dados_categoricos:\n    dados[coluna] = dados[coluna].fillna(dados[coluna].mode()[0])\n\n# Verificando se ainda existem dados faltantes no Dataset\ndados.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Substituindo os valores de objeto dos atributos 'RainToday' pra 0 e 1 (antes eram \"Yes\" e \"No\")\n# e substituindo valores faltantes por 0\ndados['RainToday'] = dados['RainToday'].replace({'No': 0, 'Yes': 1}).fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Substituindo No e Yes por 0 e 1 para o atributo alvo\ndados['RainTomorrow'] = dados['RainTomorrow'].replace({'No': 0, 'Yes': 1})","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Verificando quantas cidades existem no Dataset\nlen(set(dados['Location']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Escolhemos LabelEncoder porque há 49 localizações diferentes e, portanto, \n# seriam necessários mais 49 atributos utilizando One-HotEncoder\n\nfrom sklearn import preprocessing\n\ncolunas_dados_categoricos.append('Location')\n\nfor coluna in colunas_dados_categoricos:\n    le = preprocessing.LabelEncoder()\n    le.fit(dados[coluna])\n    dados[coluna] = le.transform(dados[coluna])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Visualizando as primeiras 5 instâncias do Dataset, para analisar as mudanças feitas\ndados.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Novamente analisando mais detalhadamente cada coluna do Dataset, agora sem os dados faltantes\ndados.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Analisando a correlação dos dados do Dataset\n# Para isso, plotamos a matriz de correlação entre os valores numéricos\n\nrain_data_num = dados[['MinTemp','MaxTemp','Rainfall','WindSpeed9am','WindSpeed3pm',\n                           'Humidity9am','Humidity3pm','Pressure9am','Pressure3pm',\n                           'Temp9am','Temp3pm','RainToday','RainTomorrow', 'RISK_MM']]\nplt.figure(figsize=(12,8))\nsns.heatmap(rain_data_num.corr(),annot=True,cmap='bone',linewidths=0.25)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Percebe-se que a coluna `Temp9am` se correlaciona com algumas outras.\n\nAssim, é interessante desconsiderá-la."},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Desconsiderando a coluna Temp9am\ndados = dados.drop(columns=['Temp9am', 'MaxTemp', 'MinTemp'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Desconsiderando a coluna: RISK_MM\n# Note: You should exclude the variable Risk-MM when training a binary classification model. \n# Not excluding it will leak the answers to your model and reduce its predictability.\ndados = dados.drop(columns=['RISK_MM'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"rain_data_num = dados[['Rainfall','WindSpeed9am','WindSpeed3pm',\n                           'Humidity9am','Humidity3pm','Pressure9am','Pressure3pm',\n                           'Temp3pm','RainToday','RainTomorrow']]\nplt.figure(figsize=(12,8))\nsns.heatmap(rain_data_num.corr(),annot=True,cmap='bone',linewidths=0.25)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Gráficos"},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"#Plotando gráficos relacionandos à coluna Humidity3pm com RainTomorrow para analisar como os dados da humidade \n# do ar as 3pm se relacionam com a probabilidade de chover amanhã.\n\nsns.catplot(x='RainTomorrow', y='Humidity3pm', hue='RainTomorrow',\n            kind=\"violin\", split=False, data=dados);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Assim, pode-se perceber que, quando a humidade tem valores entre 60 e 80, há uma maior chance de chover amanhã, \nrepresentada pelo gráfico laranja. Já a parte mais significativa dos dados que mortram que não vai chover \namanhã se encontra entre 40 e 60."},{"metadata":{},"cell_type":"markdown","source":"## Classificação"},{"metadata":{"trusted":false},"cell_type":"code","source":"from statistics import stdev\n# Divisão dos dados para treinamento e teste\nY = dados.pop('RainTomorrow').values\nX = dados.drop(columns=['Date']).values\n\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.20,random_state=42)\n\nprint(x_train.shape)\nprint(x_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nmodelo = GaussianNB()\nmodelo.fit(x_train, y_train)\nScore_1=modelo.score(x_test, y_test)\n\n# Cálculo de Acurácia\nprint('Acurácia do modelo Naive-Bayes utilizando holdout de 20%%: %.4f%%' % (Score_1*100))\n\nscore_3 = cross_val_score(modelo, x_test, y_test, cv=10)\nprint('Acurácia do modelo Naive Bayes utilizando 10-fold: %.4f%% +- %.4f%%' % (score_3.mean()*100, stdev(score_3)*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Matriz de Confusão (Naive Bayes)\ntargetnames = ['RainTomorrow ','Not RainTomorrow']\n\ny_pred = modelo.predict(x_test)\nconfusion_matrix= sklearn.metrics.confusion_matrix(y_test, y_pred)\n\ndf_cm = pd.DataFrame(confusion_matrix, index = [i for i in targetnames], columns = [i for i in targetnames])\nprint(confusion_matrix)\n\ncmap = sns.light_palette(\"navy\", as_cmap=True)\nplt.figure(figsize=(8, 6))\nplt.title('Confusion matrix of the classifier')\nsns.heatmap(df_cm, annot=True, cmap=cmap)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Algoritmo de Classificação Árvore de Decisão\n\nmodelo_2 = DecisionTreeClassifier(criterion='entropy')\nmodelo_2.fit(x_train, y_train)\n\nmodelo_2_Score_1=modelo_2.score(x_test, y_test)\nprint('Acurácia do modelo Decision Tree utilizando holdout de 20%%: %.4f%%' % (modelo_2_Score_1*100))\nprint(modelo_2_Score_1)\n\nmodelo_2_score_2 = cross_val_score(modelo_2, x_test, y_test, cv=10)\nprint('Acurácia do modelo Decision Tree utilizando cross validation 10-fold: %.4f%% +- %.4f%%' % (modelo_2_score_2.mean()*100, stdev(modelo_2_score_2)*100))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Plotando a Árvore de Decisão\n\nfeature_names = ['Date','Location','Rainfall','Evaporation','Sunshine','WindGustDir',\n                 'WindGustSpeed','WindDir9am','WindDir3pm','WindSpeed9am','WindSpeed3pm','Humidity9am',\n                 'Humidity3pm','Pressure9am','Pressure3pm','Cloud9am','Cloud3pm','Temp3pm']\ntarget_names = ['Rain', 'Not Rain']\n\nexport_graphviz(modelo_2, out_file='tree.dot', feature_names=feature_names, \n                class_names=target_names, filled=True, rounded=True,special_characters=True)\n\nfrom subprocess import call\ncall(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=200'])\n\nfrom IPython.display import Image\nImage(filename = 'tree.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Matriz de Confusão (Decision Tree)\n\ntargetnames = ['RainTomorrow ','Not RainTomorrow']\n\ny_pred_2 = modelo_2.predict(x_test)\nconfusion_matrix= sklearn.metrics.confusion_matrix(y_test, y_pred_2)\n\nprint(confusion_matrix)\n\ndf_cm = pd.DataFrame(confusion_matrix, index = [i for i in targetnames], columns = [i for i in targetnames])\ncmap = sns.light_palette(\"navy\", as_cmap=True)\n\nplt.figure(figsize=(8, 6))\nplt.title('Confusion matrix of the classifier')\nsns.heatmap(df_cm, annot=True, cmap=cmap)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.svm import SVC\n\nmodelo_3 = SVC(kernel='rbf', gamma='scale')\nmodelo_3.fit(x_train, y_train)\n\nmodelo_3_score1 = modelo_3.score(x_test, y_test)\nmodelo_3_score2 = cross_val_score(modelo_3, x_test, y_test, cv=10)\n\nprint('Acurácia do modelo SVM utilizando holdout de 20%%: %.4f%%' % (modelo_3_score1*100))\nprint('Acurácia do modelo SVM utilizando cross validation 10-fold: %.4f%% +- %.4f%%' % (modelo_3_score2.mean()*100, stdev(modelo_3_score2)*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"targetnames = ['RainTomorrow ','Not RainTomorrow']\n\ny_pred = modelo_3.predict(x_test)\nconfusion_matrix= sklearn.metrics.confusion_matrix(y_test, y_pred)\n\ndf_cm = pd.DataFrame(confusion_matrix, index = [i for i in targetnames], columns = [i for i in targetnames])\nprint(confusion_matrix)\n\ncmap = sns.light_palette(\"navy\", as_cmap=True)\nplt.figure(figsize=(8, 6))\nplt.title('Confusion matrix of the classifier')\nsns.heatmap(df_cm, annot=True, cmap=cmap)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}