{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Introduction to Natural Language Processing**","metadata":{"id":"lpZEkTg61Oj9"}},{"cell_type":"markdown","source":"**Today's Agenda**\n* What is NLP?\n* Applications of NLP\n* NLP around us\n* Essentials\n    * Corpus\n    * Tokens\n    * Sentences and words\n    * Stopwords\n    * Stemming\n    * Lemmatizing\n* Machine Learning in NLP\n    * What is ML?\n    * What are features?\n    * Sentences to Vectors\n        * BOW\n        * TF-IDF\n        * Deep Learning based ideas\n* Project","metadata":{}},{"cell_type":"markdown","source":"# Essential modules","metadata":{"id":"XmxCd_5hCT_u"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport nltk\nnltk.download('punkt')","metadata":{"id":"eaN-lRHNBcf1","outputId":"f163c49a-c81a-48c5-fd05-d217388fcf08","execution":{"iopub.status.busy":"2021-08-01T06:52:27.443317Z","iopub.execute_input":"2021-08-01T06:52:27.443774Z","iopub.status.idle":"2021-08-01T06:52:49.034069Z","shell.execute_reply.started":"2021-08-01T06:52:27.443676Z","shell.execute_reply":"2021-08-01T06:52:49.032747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Extracting Sentences & Words from Sentences**\n\nhttps://www.nltk.org/api/nltk.tokenize.html","metadata":{"id":"bJf8qrj9CmAM"}},{"cell_type":"code","source":"text = \"The Natural Language Toolkit, or more commonly NLTK, is a suite of libraries and programs for symbolic and statistical natural language processing (NLP) for English written in the Python programming language. It was developed by Steven Bird and Edward Loper in the Department of Computer and Information Science at the University of Pennsylvania. NLTK includes graphical demonstrations and sample data. It is accompanied by a book that explains the underlying concepts behind the language processing tasks supported by the toolkit, plus a cookbook. NLTK is intended to support research and teaching in NLP or closely related areas, including empirical linguistics, cognitive science, artificial intelligence, information retrieval, and machine learning. NLTK has been used successfully as a teaching tool, as an individual study tool, and as a platform for prototyping and building research systems. There are 32 universities in the US and 25 countries using NLTK in their courses. NLTK supports classification, tokenization, stemming, tagging, parsing, and semantic reasoning functionalities\"","metadata":{"id":"UfU1B6iNEEF9","execution":{"iopub.status.busy":"2021-08-01T06:52:49.036445Z","iopub.execute_input":"2021-08-01T06:52:49.036908Z","iopub.status.idle":"2021-08-01T06:52:49.042139Z","shell.execute_reply.started":"2021-08-01T06:52:49.036861Z","shell.execute_reply":"2021-08-01T06:52:49.040558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text","metadata":{"id":"zZxoKhoGEYrX","outputId":"6941bb52-50ae-4e45-b211-ee17bfad557c","execution":{"iopub.status.busy":"2021-08-01T06:52:49.044413Z","iopub.execute_input":"2021-08-01T06:52:49.04491Z","iopub.status.idle":"2021-08-01T06:52:49.060247Z","shell.execute_reply.started":"2021-08-01T06:52:49.044867Z","shell.execute_reply":"2021-08-01T06:52:49.058977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentences = nltk.sent_tokenize(text)","metadata":{"id":"0xkwpcJrEZUk","execution":{"iopub.status.busy":"2021-08-01T06:52:49.061985Z","iopub.execute_input":"2021-08-01T06:52:49.062386Z","iopub.status.idle":"2021-08-01T06:52:49.086667Z","shell.execute_reply.started":"2021-08-01T06:52:49.062354Z","shell.execute_reply":"2021-08-01T06:52:49.08571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentences","metadata":{"id":"Vy7DtHMLFO53","outputId":"30e05922-e052-4c7a-8a64-869eb216a521","execution":{"iopub.status.busy":"2021-08-01T06:52:49.087828Z","iopub.execute_input":"2021-08-01T06:52:49.088251Z","iopub.status.idle":"2021-08-01T06:52:49.094666Z","shell.execute_reply.started":"2021-08-01T06:52:49.088211Z","shell.execute_reply":"2021-08-01T06:52:49.093512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words = nltk.word_tokenize(text)","metadata":{"id":"SuYaMyGKFOuJ","execution":{"iopub.status.busy":"2021-08-01T06:52:49.095656Z","iopub.execute_input":"2021-08-01T06:52:49.095907Z","iopub.status.idle":"2021-08-01T06:52:49.105492Z","shell.execute_reply.started":"2021-08-01T06:52:49.095881Z","shell.execute_reply":"2021-08-01T06:52:49.104745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words","metadata":{"id":"3t5lDmjjFXP_","outputId":"685e10f9-4934-41dc-cfcc-71e44d4bfd99","execution":{"iopub.status.busy":"2021-08-01T06:52:49.106927Z","iopub.execute_input":"2021-08-01T06:52:49.107191Z","iopub.status.idle":"2021-08-01T06:52:49.12114Z","shell.execute_reply.started":"2021-08-01T06:52:49.107165Z","shell.execute_reply":"2021-08-01T06:52:49.120123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Removing Stop Words**\n\nStop words are a set of commonly used words in a language. Examples of stop words in English are “a”, “the”, “is”, “are” and etc. Stop words are commonly used in Text Mining and Natural Language Processing (NLP) to eliminate words that are so commonly used that they carry very little useful information.\n\nFor Further Reading - https://www.opinosis-analytics.com/knowledge-base/stop-words-explained/#.YQJDdI4zY2w\n\nhttps://stackoverflow.com/questions/5486337/how-to-remove-stop-words-using-nltk-or-python","metadata":{"id":"9I_8WwKJGrsx"}},{"cell_type":"code","source":"from nltk.corpus import stopwords\nnltk.download('stopwords')\nstop_words = set(stopwords.words('english'))\nstop_words","metadata":{"id":"ryehPtUcGqfn","outputId":"e9334115-2c3d-44da-873a-4b357a2075cb","execution":{"iopub.status.busy":"2021-08-01T06:52:49.125546Z","iopub.execute_input":"2021-08-01T06:52:49.125907Z","iopub.status.idle":"2021-08-01T06:53:09.169014Z","shell.execute_reply.started":"2021-08-01T06:52:49.125865Z","shell.execute_reply":"2021-08-01T06:53:09.167808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(sentences)):\n    print('Original --> ', [word for word in sentences[i].split()])\n    print('New -->      ', [word for word in sentences[i].split() if word.lower() not in stop_words])\n    sentences[i] = ' '.join([word for word in sentences[i].split() if word.lower() not in stop_words])","metadata":{"id":"gd8MC8pKHN2M","outputId":"e9eb6d63-9e89-48b2-8de3-75c930cd5605","execution":{"iopub.status.busy":"2021-08-01T06:53:09.170787Z","iopub.execute_input":"2021-08-01T06:53:09.171071Z","iopub.status.idle":"2021-08-01T06:53:09.182109Z","shell.execute_reply.started":"2021-08-01T06:53:09.171043Z","shell.execute_reply":"2021-08-01T06:53:09.180944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentences","metadata":{"id":"40bJoNRLH71f","outputId":"e1ca032e-e324-446f-8eb2-b54e2ec703a6","execution":{"iopub.status.busy":"2021-08-01T06:53:09.183529Z","iopub.execute_input":"2021-08-01T06:53:09.183939Z","iopub.status.idle":"2021-08-01T06:53:09.193913Z","shell.execute_reply.started":"2021-08-01T06:53:09.183896Z","shell.execute_reply":"2021-08-01T06:53:09.19291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Impact of Removing Stop Words\n","metadata":{"id":"yml-shmw3aDv"}},{"cell_type":"code","source":"onebillionspecial = \"\"\"Rickrolling, alternatively Rick-rolling or Rickroll, is a prank and an Internet meme involving an unexpected appearance of the music video for the 1987 Rick Astley song \"Never Gonna Give You Up\". The meme is a type of bait and switch using a disguised hyperlink that leads to the music video. When victims click on a seemingly unrelated link, the site with the music video loads instead of what was expected, and in doing so they are said to have been 'Rickrolled'. The meme has also extended to using the song's lyrics in unexpected places.The meme grew out of a similar bait-and-switch trick called \"duckrolling\" that was popular on the 4chan website in 2006. The video bait-and-switch trick grew popular on 4chan by the 2007 April Fools' Day, and spread to other Internet sites later that year. The meme gained mainstream attention in 2008 through several publicized events, particularly when YouTube used it on its 2008 April Fools' Day event. Initially, Astley, who had only recently returned to performing after a ten-year hiatus, was hesitant about using his newfound popularity from the meme to further his career, but accepted the fame when he Rickrolled the 2008 Macy's Thanksgiving Day Parade with a surprise performance of the song. Since then, Astley has seen his performance career revitalized by the meme's popularity. Astley himself has also been Rickrolled several times.\"\"\"","metadata":{"id":"XKLBp_ad3fKM","execution":{"iopub.status.busy":"2021-08-01T06:53:09.195314Z","iopub.execute_input":"2021-08-01T06:53:09.195788Z","iopub.status.idle":"2021-08-01T06:53:09.204385Z","shell.execute_reply.started":"2021-08-01T06:53:09.195699Z","shell.execute_reply":"2021-08-01T06:53:09.203323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l1 = len(onebillionspecial)\nl1","metadata":{"id":"WnfSZMXt4IY-","outputId":"5c95b511-f9e7-4a59-de16-2b124da56a16","execution":{"iopub.status.busy":"2021-08-01T06:53:09.205642Z","iopub.execute_input":"2021-08-01T06:53:09.206145Z","iopub.status.idle":"2021-08-01T06:53:09.225982Z","shell.execute_reply.started":"2021-08-01T06:53:09.206099Z","shell.execute_reply":"2021-08-01T06:53:09.224893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentences_rick = nltk.sent_tokenize(onebillionspecial)","metadata":{"id":"ySvGDmX_4bop","execution":{"iopub.status.busy":"2021-08-01T06:53:09.227324Z","iopub.execute_input":"2021-08-01T06:53:09.22794Z","iopub.status.idle":"2021-08-01T06:53:09.237989Z","shell.execute_reply.started":"2021-08-01T06:53:09.227905Z","shell.execute_reply":"2021-08-01T06:53:09.23684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(sentences_rick)):\n  print('Original --> ', [word for word in sentences_rick[i].split()])\n  print('New -->      ', [word for word in sentences_rick[i].split() if word.lower() not in stop_words])\n  sentences_rick[i] = ' '.join([word for word in sentences_rick[i].split() if word.lower() not in stop_words])","metadata":{"id":"pF2X3JmX4S20","outputId":"2aeb29d5-8418-419c-a801-757bd794daed","execution":{"iopub.status.busy":"2021-08-01T06:53:09.239335Z","iopub.execute_input":"2021-08-01T06:53:09.239666Z","iopub.status.idle":"2021-08-01T06:53:09.258839Z","shell.execute_reply.started":"2021-08-01T06:53:09.239633Z","shell.execute_reply":"2021-08-01T06:53:09.257878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l2 = 0\nfor i in sentences_rick:\n  l2+=len(i)\nl2","metadata":{"id":"4JLq0BV-4ltN","outputId":"036fae7a-4d90-4f5d-8daf-56031d8ea9a3","execution":{"iopub.status.busy":"2021-08-01T06:53:09.260072Z","iopub.execute_input":"2021-08-01T06:53:09.260375Z","iopub.status.idle":"2021-08-01T06:53:09.271826Z","shell.execute_reply.started":"2021-08-01T06:53:09.260346Z","shell.execute_reply":"2021-08-01T06:53:09.270552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l1-l2","metadata":{"id":"ninjCUbY5gxg","outputId":"f71f6564-0e12-46d2-fe3b-6c3ce0b2c040","execution":{"iopub.status.busy":"2021-08-01T06:53:09.273469Z","iopub.execute_input":"2021-08-01T06:53:09.274261Z","iopub.status.idle":"2021-08-01T06:53:09.286836Z","shell.execute_reply.started":"2021-08-01T06:53:09.274204Z","shell.execute_reply":"2021-08-01T06:53:09.285797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f\"Hence {(l1-l2)*100/l1}% data is not giving us any context and our model will use it to generate insights if we don't remove the stopwords\"","metadata":{"id":"70P2Bd876VDQ","outputId":"b07fe54d-63b8-473f-c61b-f2ecede9db1e","execution":{"iopub.status.busy":"2021-08-01T06:53:09.288188Z","iopub.execute_input":"2021-08-01T06:53:09.28852Z","iopub.status.idle":"2021-08-01T06:53:09.299306Z","shell.execute_reply.started":"2021-08-01T06:53:09.288488Z","shell.execute_reply":"2021-08-01T06:53:09.298603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Stemming**\n\n\"Stemming is the process of reducing inflection in words to their root forms such as mapping a group of words to the same stem even if the stem itself is not a valid word in the Language.\"\n\nStem (root) is the part of the word to which you add inflectional (changing/deriving) affixes such as (-ed,-ize, -s,-de,mis). So stemming a word or sentence may result in words that are not actual words. Stems are created by removing the suffixes or prefixes used with a word.\n\nSource - https://www.datacamp.com/community/tutorials/stemming-lemmatization-python\n","metadata":{"id":"5CAzNCWMFy21"}},{"cell_type":"code","source":"from nltk.stem import PorterStemmer\nstemmer = PorterStemmer()","metadata":{"id":"eVF-4BgUFg1G","execution":{"iopub.status.busy":"2021-08-01T06:53:09.300471Z","iopub.execute_input":"2021-08-01T06:53:09.301012Z","iopub.status.idle":"2021-08-01T06:53:09.316366Z","shell.execute_reply.started":"2021-08-01T06:53:09.300981Z","shell.execute_reply":"2021-08-01T06:53:09.315312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(sentences)):\n  sentences[i] = ' '.join([stemmer.stem(word) for word in nltk.word_tokenize(sentences[i]) if word.lower() not in stop_words])","metadata":{"id":"XSqMecAcGd2D","execution":{"iopub.status.busy":"2021-08-01T06:53:09.317508Z","iopub.execute_input":"2021-08-01T06:53:09.317858Z","iopub.status.idle":"2021-08-01T06:53:09.332129Z","shell.execute_reply.started":"2021-08-01T06:53:09.317824Z","shell.execute_reply":"2021-08-01T06:53:09.331274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentences","metadata":{"id":"pr3K8vKGKEp3","execution":{"iopub.status.busy":"2021-08-01T06:53:09.33331Z","iopub.execute_input":"2021-08-01T06:53:09.333705Z","iopub.status.idle":"2021-08-01T06:53:09.346841Z","shell.execute_reply.started":"2021-08-01T06:53:09.333658Z","shell.execute_reply":"2021-08-01T06:53:09.345659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"PorterStemmer uses Suffix Stripping to produce stems. PorterStemmer will give the root (stem) of the word \"cats\" by simply removing the 's' after cat. This is a suffix added to cat to make it plural. But if you look at 'trouble', 'troubling' and 'troubled' they are stemmed to 'trouble' because **PorterStemmer algorithm does not follow linguistics rather a set of 5 rules for different cases that are applied in phases (step by step) to generate stems**. This is the reason why PorterStemmer does not often generate stems that are actual English words. It does not keep a lookup table for actual stems of the word but applies algorithmic rules to generate stems. It uses the rules to decide whether it is wise to strip a suffix.","metadata":{"id":"AcHmeNmyKYTv"}},{"cell_type":"markdown","source":"**Lemmatization**\n\nLemmatization, unlike Stemming, reduces the inflected words properly ensuring that the root word belongs to the language. In Lemmatization root word is called Lemma. A lemma (plural lemmas or lemmata) is the canonical form, dictionary form, or citation form of a set of words.\n\nFor example, runs, running, ran are all forms of the word run, therefore run is the lemma of all these words. Because lemmatization returns an actual word of the language, it is used where it is necessary to get valid words.","metadata":{"id":"TTl54VHuKM0n"}},{"cell_type":"code","source":"from nltk.stem import WordNetLemmatizer\nnltk.download('wordnet')\nlemmatizer = WordNetLemmatizer()\nfrom nltk import pos_tag\nnltk.download('averaged_perceptron_tagger')","metadata":{"id":"Tl9Csi52KGqk","execution":{"iopub.status.busy":"2021-08-01T06:53:09.348192Z","iopub.execute_input":"2021-08-01T06:53:09.348735Z","iopub.status.idle":"2021-08-01T06:53:49.420329Z","shell.execute_reply.started":"2021-08-01T06:53:09.348689Z","shell.execute_reply":"2021-08-01T06:53:49.419578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentences = nltk.sent_tokenize(text)\nsentences","metadata":{"id":"1vYeREdJLvPZ","execution":{"iopub.status.busy":"2021-08-01T06:53:49.421267Z","iopub.execute_input":"2021-08-01T06:53:49.4215Z","iopub.status.idle":"2021-08-01T06:53:49.428499Z","shell.execute_reply.started":"2021-08-01T06:53:49.421475Z","shell.execute_reply":"2021-08-01T06:53:49.427611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(sentences)):\n  sentences[i] = ' '.join([lemmatizer.lemmatize(word) for word in sentences[i].split() if word.lower() not in stop_words])","metadata":{"id":"hbGncYZNK3ri","execution":{"iopub.status.busy":"2021-08-01T06:53:49.430087Z","iopub.execute_input":"2021-08-01T06:53:49.430444Z","iopub.status.idle":"2021-08-01T06:53:51.053554Z","shell.execute_reply.started":"2021-08-01T06:53:49.43041Z","shell.execute_reply":"2021-08-01T06:53:51.052766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentences","metadata":{"id":"RsG2Nk5KLAEd","execution":{"iopub.status.busy":"2021-08-01T06:53:51.054832Z","iopub.execute_input":"2021-08-01T06:53:51.055328Z","iopub.status.idle":"2021-08-01T06:53:51.061104Z","shell.execute_reply.started":"2021-08-01T06:53:51.05529Z","shell.execute_reply":"2021-08-01T06:53:51.060118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lemmatizer.lemmatize('demonstration', 'v')","metadata":{"id":"S9rQG3zYLfTH","execution":{"iopub.status.busy":"2021-08-01T06:53:51.062494Z","iopub.execute_input":"2021-08-01T06:53:51.062899Z","iopub.status.idle":"2021-08-01T06:53:51.074933Z","shell.execute_reply.started":"2021-08-01T06:53:51.062858Z","shell.execute_reply":"2021-08-01T06:53:51.074007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Bag of Words (BoW)**","metadata":{"id":"dxnrn5uvv9Bu"}},{"cell_type":"code","source":"import re\nimport pandas as pd\nsentences = nltk.sent_tokenize(text)\ncorpus = []\nfor i in range(len(sentences)):\n    sentence = re.sub('[^a-zA-Z]', ' ', sentences[i])\n    sentence = sentence.lower()\n    sentence = sentence.split()\n    sentence = [stemmer.stem(word) for word in sentence if not word in set(stopwords.words('english'))]\n    sentence = ' '.join(sentence)\n    corpus.append(sentence)","metadata":{"id":"SBaZvm7WNUSA","execution":{"iopub.status.busy":"2021-08-01T06:53:51.080372Z","iopub.execute_input":"2021-08-01T06:53:51.080752Z","iopub.status.idle":"2021-08-01T06:53:51.113966Z","shell.execute_reply.started":"2021-08-01T06:53:51.080719Z","shell.execute_reply":"2021-08-01T06:53:51.112991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corpus","metadata":{"id":"CP5mCZTNxBsX","execution":{"iopub.status.busy":"2021-08-01T06:53:51.11616Z","iopub.execute_input":"2021-08-01T06:53:51.116465Z","iopub.status.idle":"2021-08-01T06:53:51.122746Z","shell.execute_reply.started":"2021-08-01T06:53:51.116433Z","shell.execute_reply":"2021-08-01T06:53:51.121776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(max_features = 1500)\nX = cv.fit_transform(corpus).toarray()","metadata":{"id":"8req335pxQAi","execution":{"iopub.status.busy":"2021-08-01T06:53:51.124282Z","iopub.execute_input":"2021-08-01T06:53:51.124724Z","iopub.status.idle":"2021-08-01T06:53:51.140854Z","shell.execute_reply.started":"2021-08-01T06:53:51.124679Z","shell.execute_reply":"2021-08-01T06:53:51.139422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"id":"Fjspf13vxVNc","execution":{"iopub.status.busy":"2021-08-01T06:53:51.142884Z","iopub.execute_input":"2021-08-01T06:53:51.143459Z","iopub.status.idle":"2021-08-01T06:53:51.158019Z","shell.execute_reply.started":"2021-08-01T06:53:51.1434Z","shell.execute_reply":"2021-08-01T06:53:51.15691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for x in X:\n    print(*x)","metadata":{"id":"mPm_o7psxV2a","execution":{"iopub.status.busy":"2021-08-01T06:53:51.159406Z","iopub.execute_input":"2021-08-01T06:53:51.160071Z","iopub.status.idle":"2021-08-01T06:53:51.231944Z","shell.execute_reply.started":"2021-08-01T06:53:51.160028Z","shell.execute_reply":"2021-08-01T06:53:51.230746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = pd.DataFrame(X)\ndf1","metadata":{"id":"IRqk4BsK0qYo","execution":{"iopub.status.busy":"2021-08-01T06:53:51.23323Z","iopub.execute_input":"2021-08-01T06:53:51.233497Z","iopub.status.idle":"2021-08-01T06:53:51.260684Z","shell.execute_reply.started":"2021-08-01T06:53:51.233469Z","shell.execute_reply":"2021-08-01T06:53:51.259746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**TF-IDF**","metadata":{"id":"gcfBjTym00dN"}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\ncv = TfidfVectorizer()\nY = cv.fit_transform(corpus).toarray()","metadata":{"id":"v0PTvYi2yle9","execution":{"iopub.status.busy":"2021-08-01T06:53:51.261988Z","iopub.execute_input":"2021-08-01T06:53:51.262362Z","iopub.status.idle":"2021-08-01T06:53:51.274716Z","shell.execute_reply.started":"2021-08-01T06:53:51.26232Z","shell.execute_reply":"2021-08-01T06:53:51.273697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y","metadata":{"id":"T3yOCqiF0FSU","execution":{"iopub.status.busy":"2021-08-01T06:53:51.276122Z","iopub.execute_input":"2021-08-01T06:53:51.276408Z","iopub.status.idle":"2021-08-01T06:53:51.2953Z","shell.execute_reply.started":"2021-08-01T06:53:51.276379Z","shell.execute_reply":"2021-08-01T06:53:51.294012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for y in Y:\n    print(*y)","metadata":{"id":"-p0BuNCV0GBK","execution":{"iopub.status.busy":"2021-08-01T06:53:51.296675Z","iopub.execute_input":"2021-08-01T06:53:51.297049Z","iopub.status.idle":"2021-08-01T06:53:51.368477Z","shell.execute_reply.started":"2021-08-01T06:53:51.297013Z","shell.execute_reply":"2021-08-01T06:53:51.367399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(Y)","metadata":{"id":"bge4KMCk0Jto","execution":{"iopub.status.busy":"2021-08-01T06:53:51.370463Z","iopub.execute_input":"2021-08-01T06:53:51.3708Z","iopub.status.idle":"2021-08-01T06:53:51.374657Z","shell.execute_reply.started":"2021-08-01T06:53:51.370764Z","shell.execute_reply":"2021-08-01T06:53:51.373781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"id":"X7jWHWs40dFt","execution":{"iopub.status.busy":"2021-08-01T06:53:51.375513Z","iopub.execute_input":"2021-08-01T06:53:51.375783Z","iopub.status.idle":"2021-08-01T06:53:51.414639Z","shell.execute_reply.started":"2021-08-01T06:53:51.375757Z","shell.execute_reply":"2021-08-01T06:53:51.413397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Spam or Ham?","metadata":{}},{"cell_type":"code","source":"df_spam_ham = pd.read_csv('../input/sms-spam-collection-dataset/spam.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-01T06:53:51.416005Z","iopub.execute_input":"2021-08-01T06:53:51.416286Z","iopub.status.idle":"2021-08-01T06:53:51.449554Z","shell.execute_reply.started":"2021-08-01T06:53:51.416258Z","shell.execute_reply":"2021-08-01T06:53:51.44851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_spam_ham","metadata":{"execution":{"iopub.status.busy":"2021-08-01T06:53:51.451012Z","iopub.execute_input":"2021-08-01T06:53:51.451341Z","iopub.status.idle":"2021-08-01T06:53:51.473899Z","shell.execute_reply.started":"2021-08-01T06:53:51.451311Z","shell.execute_reply":"2021-08-01T06:53:51.472914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_spam_ham = df_spam_ham.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T06:53:51.475283Z","iopub.execute_input":"2021-08-01T06:53:51.475676Z","iopub.status.idle":"2021-08-01T06:53:51.486068Z","shell.execute_reply.started":"2021-08-01T06:53:51.475617Z","shell.execute_reply":"2021-08-01T06:53:51.484901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_spam_ham","metadata":{"execution":{"iopub.status.busy":"2021-08-01T06:53:51.487604Z","iopub.execute_input":"2021-08-01T06:53:51.487974Z","iopub.status.idle":"2021-08-01T06:53:51.503229Z","shell.execute_reply.started":"2021-08-01T06:53:51.487917Z","shell.execute_reply":"2021-08-01T06:53:51.502444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA on Data","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nsns.set_style(\"whitegrid\")\nax = sns.countplot(x=\"v1\",data=df_spam_ham)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T06:53:51.50427Z","iopub.execute_input":"2021-08-01T06:53:51.504518Z","iopub.status.idle":"2021-08-01T06:53:51.953564Z","shell.execute_reply.started":"2021-08-01T06:53:51.504494Z","shell.execute_reply":"2021-08-01T06:53:51.952667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"content = df_spam_ham[['v2']].to_numpy()","metadata":{"execution":{"iopub.status.busy":"2021-08-01T06:53:51.955339Z","iopub.execute_input":"2021-08-01T06:53:51.955735Z","iopub.status.idle":"2021-08-01T06:53:51.961446Z","shell.execute_reply.started":"2021-08-01T06:53:51.955696Z","shell.execute_reply":"2021-08-01T06:53:51.960405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"content","metadata":{"execution":{"iopub.status.busy":"2021-08-01T06:53:51.962707Z","iopub.execute_input":"2021-08-01T06:53:51.962973Z","iopub.status.idle":"2021-08-01T06:53:51.976189Z","shell.execute_reply.started":"2021-08-01T06:53:51.962945Z","shell.execute_reply":"2021-08-01T06:53:51.975034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sizes = []\nfor content_val in content:\n    sizes.append(len(content_val[0]))","metadata":{"execution":{"iopub.status.busy":"2021-08-01T06:53:51.977598Z","iopub.execute_input":"2021-08-01T06:53:51.97795Z","iopub.status.idle":"2021-08-01T06:53:51.990647Z","shell.execute_reply.started":"2021-08-01T06:53:51.977918Z","shell.execute_reply":"2021-08-01T06:53:51.989618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure\nfigure(figsize=(16, 10), dpi=80)\nfigure = plt.hist(sizes, bins = 40)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-01T06:53:51.991958Z","iopub.execute_input":"2021-08-01T06:53:51.992226Z","iopub.status.idle":"2021-08-01T06:53:52.267816Z","shell.execute_reply.started":"2021-08-01T06:53:51.9922Z","shell.execute_reply":"2021-08-01T06:53:52.266868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\ncorpus = []\nfor i in range(0, len(df_spam_ham)):\n    sms = re.sub('[^a-zA-Z]', ' ', df_spam_ham['v2'][i])\n    sms = sms.lower()\n    sms = sms.split()\n    sms = [stemmer.stem(word) for word in sms if not word in stopwords.words('english')]\n    sms = ' '.join(sms)\n    corpus.append(sms)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T06:53:52.269176Z","iopub.execute_input":"2021-08-01T06:53:52.269547Z","iopub.status.idle":"2021-08-01T06:54:03.646042Z","shell.execute_reply.started":"2021-08-01T06:53:52.269502Z","shell.execute_reply":"2021-08-01T06:54:03.644963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(max_features = 3000)\nfeature_vectors = cv.fit_transform(corpus).toarray()","metadata":{"execution":{"iopub.status.busy":"2021-08-01T06:54:03.647286Z","iopub.execute_input":"2021-08-01T06:54:03.647562Z","iopub.status.idle":"2021-08-01T06:54:03.766985Z","shell.execute_reply.started":"2021-08-01T06:54:03.647532Z","shell.execute_reply":"2021-08-01T06:54:03.765855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_vectors = pd.get_dummies(df_spam_ham['v1']).iloc[:,1].values","metadata":{"execution":{"iopub.status.busy":"2021-08-01T06:54:03.768221Z","iopub.execute_input":"2021-08-01T06:54:03.76851Z","iopub.status.idle":"2021-08-01T06:54:03.774878Z","shell.execute_reply.started":"2021-08-01T06:54:03.768482Z","shell.execute_reply":"2021-08-01T06:54:03.7738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfeature_vectors_train, feature_vectors_test, target_vectors_train, target_vectors_test = train_test_split(feature_vectors, target_vectors, test_size = 0.20, random_state = 0)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T06:54:03.776337Z","iopub.execute_input":"2021-08-01T06:54:03.776697Z","iopub.status.idle":"2021-08-01T06:54:03.859451Z","shell.execute_reply.started":"2021-08-01T06:54:03.776665Z","shell.execute_reply":"2021-08-01T06:54:03.858493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nspam_detect_model = MultinomialNB().fit(feature_vectors_train, target_vectors_train)\n\npredictions = spam_detect_model.predict(feature_vectors_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T06:54:03.860709Z","iopub.execute_input":"2021-08-01T06:54:03.860995Z","iopub.status.idle":"2021-08-01T06:54:03.993653Z","shell.execute_reply.started":"2021-08-01T06:54:03.860966Z","shell.execute_reply":"2021-08-01T06:54:03.99207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions","metadata":{"execution":{"iopub.status.busy":"2021-08-01T06:54:03.995881Z","iopub.execute_input":"2021-08-01T06:54:03.9964Z","iopub.status.idle":"2021-08-01T06:54:04.018733Z","shell.execute_reply.started":"2021-08-01T06:54:03.996355Z","shell.execute_reply":"2021-08-01T06:54:04.015793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![](https://miro.medium.com/max/1400/1*VSchph99Wiv6tQpNIvMJbw.png)","metadata":{}},{"cell_type":"code","source":"import sklearn.metrics\nfrom sklearn.metrics import confusion_matrix\ndf_cm_cv = pd.DataFrame(sklearn.metrics.confusion_matrix(target_vectors_test, predictions))\nsns.set(font_scale=1.4)\nsns.heatmap(df_cm_cv, annot=True, annot_kws={\"size\": 16})","metadata":{"execution":{"iopub.status.busy":"2021-08-01T06:54:04.021617Z","iopub.execute_input":"2021-08-01T06:54:04.022102Z","iopub.status.idle":"2021-08-01T06:54:04.329107Z","shell.execute_reply.started":"2021-08-01T06:54:04.022052Z","shell.execute_reply":"2021-08-01T06:54:04.328099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score\nsklearn.metrics.f1_score(target_vectors_test, predictions)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T06:54:04.33039Z","iopub.execute_input":"2021-08-01T06:54:04.33069Z","iopub.status.idle":"2021-08-01T06:54:04.339068Z","shell.execute_reply.started":"2021-08-01T06:54:04.33066Z","shell.execute_reply":"2021-08-01T06:54:04.337802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\ncv_unigram_bigram = CountVectorizer(max_features=3000, ngram_range=(1,2))\nfeature_vectors_unigram_bigram = cv_unigram_bigram.fit_transform(corpus).toarray()","metadata":{"execution":{"iopub.status.busy":"2021-08-01T06:54:04.340323Z","iopub.execute_input":"2021-08-01T06:54:04.340575Z","iopub.status.idle":"2021-08-01T06:54:04.578534Z","shell.execute_reply.started":"2021-08-01T06:54:04.34055Z","shell.execute_reply":"2021-08-01T06:54:04.577677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_vectors_unigram_bigram=pd.get_dummies(df_spam_ham['v1']).iloc[:,1].values","metadata":{"execution":{"iopub.status.busy":"2021-08-01T06:54:04.579588Z","iopub.execute_input":"2021-08-01T06:54:04.58008Z","iopub.status.idle":"2021-08-01T06:54:04.586235Z","shell.execute_reply.started":"2021-08-01T06:54:04.580046Z","shell.execute_reply":"2021-08-01T06:54:04.58518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfeature_vectors_train_ub, feature_vectors_test_ub,target_vectors_train_ub, target_vectors_test_ub = train_test_split(feature_vectors_unigram_bigram, target_vectors_unigram_bigram, test_size = 0.20, random_state = 0)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T06:54:04.587509Z","iopub.execute_input":"2021-08-01T06:54:04.58787Z","iopub.status.idle":"2021-08-01T06:54:04.668494Z","shell.execute_reply.started":"2021-08-01T06:54:04.587839Z","shell.execute_reply":"2021-08-01T06:54:04.66746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nspam_detect_model = MultinomialNB().fit(feature_vectors_train_ub, target_vectors_train_ub)\n\npredictions_ub=spam_detect_model.predict(feature_vectors_test_ub)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T06:54:04.669765Z","iopub.execute_input":"2021-08-01T06:54:04.670052Z","iopub.status.idle":"2021-08-01T06:54:04.779364Z","shell.execute_reply.started":"2021-08-01T06:54:04.670019Z","shell.execute_reply":"2021-08-01T06:54:04.778079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn.metrics\nfrom sklearn.metrics import confusion_matrix\ndf_cm_ub = pd.DataFrame(sklearn.metrics.confusion_matrix(target_vectors_test_ub, predictions_ub))\nsns.set(font_scale=1.4)\nsns.heatmap(df_cm_ub, annot=True, annot_kws={\"size\": 16})","metadata":{"execution":{"iopub.status.busy":"2021-08-01T06:54:04.78452Z","iopub.execute_input":"2021-08-01T06:54:04.785001Z","iopub.status.idle":"2021-08-01T06:54:05.056236Z","shell.execute_reply.started":"2021-08-01T06:54:04.784954Z","shell.execute_reply":"2021-08-01T06:54:05.055563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score\nsklearn.metrics.f1_score(target_vectors_test_ub, predictions_ub)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T06:54:05.057235Z","iopub.execute_input":"2021-08-01T06:54:05.057646Z","iopub.status.idle":"2021-08-01T06:54:05.065169Z","shell.execute_reply.started":"2021-08-01T06:54:05.057582Z","shell.execute_reply":"2021-08-01T06:54:05.064431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\ncv = TfidfVectorizer(max_features=2500)\nfeature_vectors_tfidf = cv.fit_transform(corpus).toarray()","metadata":{"execution":{"iopub.status.busy":"2021-08-01T06:54:05.066253Z","iopub.execute_input":"2021-08-01T06:54:05.066647Z","iopub.status.idle":"2021-08-01T06:54:05.239243Z","shell.execute_reply.started":"2021-08-01T06:54:05.066601Z","shell.execute_reply":"2021-08-01T06:54:05.238245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_vectors_tfidf = pd.get_dummies(df_spam_ham['v1']).iloc[:,1].values","metadata":{"execution":{"iopub.status.busy":"2021-08-01T06:54:05.240349Z","iopub.execute_input":"2021-08-01T06:54:05.2407Z","iopub.status.idle":"2021-08-01T06:54:05.246424Z","shell.execute_reply.started":"2021-08-01T06:54:05.240659Z","shell.execute_reply":"2021-08-01T06:54:05.245708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfeature_vectors_train_tfidf, feature_vectors_test_tfidf, target_vectors_train_tfidf, target_vectors_test_tfidf = train_test_split(feature_vectors_tfidf, target_vectors_tfidf, test_size = 0.20, random_state = 0)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T06:54:05.247444Z","iopub.execute_input":"2021-08-01T06:54:05.248065Z","iopub.status.idle":"2021-08-01T06:54:05.314897Z","shell.execute_reply.started":"2021-08-01T06:54:05.248033Z","shell.execute_reply":"2021-08-01T06:54:05.314118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nspam_detect_model = MultinomialNB().fit(feature_vectors_train_tfidf, target_vectors_train_tfidf)\n\npredictions_tfidf = spam_detect_model.predict(feature_vectors_test_tfidf)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T06:54:05.31588Z","iopub.execute_input":"2021-08-01T06:54:05.316258Z","iopub.status.idle":"2021-08-01T06:54:05.357906Z","shell.execute_reply.started":"2021-08-01T06:54:05.316228Z","shell.execute_reply":"2021-08-01T06:54:05.356673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_tfidf","metadata":{"execution":{"iopub.status.busy":"2021-08-01T06:54:05.359672Z","iopub.execute_input":"2021-08-01T06:54:05.360184Z","iopub.status.idle":"2021-08-01T06:54:05.36923Z","shell.execute_reply.started":"2021-08-01T06:54:05.360132Z","shell.execute_reply":"2021-08-01T06:54:05.367805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn.metrics\nfrom sklearn.metrics import confusion_matrix\ndf_cm_tfidf = pd.DataFrame(sklearn.metrics.confusion_matrix(target_vectors_test_tfidf, predictions_tfidf))\nsns.set(font_scale=1.4)\nsns.heatmap(df_cm_tfidf, annot=True, annot_kws={\"size\": 16})","metadata":{"execution":{"iopub.status.busy":"2021-08-01T06:54:05.370736Z","iopub.execute_input":"2021-08-01T06:54:05.371235Z","iopub.status.idle":"2021-08-01T06:54:05.649934Z","shell.execute_reply.started":"2021-08-01T06:54:05.371172Z","shell.execute_reply":"2021-08-01T06:54:05.64897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score\nsklearn.metrics.f1_score(target_vectors_test_tfidf, predictions_tfidf)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T06:54:05.651309Z","iopub.execute_input":"2021-08-01T06:54:05.651726Z","iopub.status.idle":"2021-08-01T06:54:05.658655Z","shell.execute_reply.started":"2021-08-01T06:54:05.651681Z","shell.execute_reply":"2021-08-01T06:54:05.658023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Datasets which can be tried out after this session - \n* https://www.kaggle.com/snap/amazon-fine-food-reviews\n* https://www.kaggle.com/crowdflower/twitter-airline-sentiment\n\nResources for NLP - \n* [NLP Book](https://web.stanford.edu/~jurafsky/slp3/)\n* [NLTK](https://www.youtube.com/watch?v=FLZvOKSCkxY&list=PLQVvvaa0QuDf2JswnfiGkliBInZnIC4HL)\n* [Stanford NLP Course](https://www.youtube.com/watch?v=8rXD5-xhemo&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z)","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}