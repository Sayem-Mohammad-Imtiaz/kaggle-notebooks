{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Naive prediction of game wins, given only team data\n* A proper model would HAVE to have player data (accurate to the time of each game). \n* Even given more granular and exogenous data, we would expect this to be a very difficult task to predict on - there's a lot of luck involved. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom catboost import Pool, cv, CatBoostClassifier\nfrom sklearn.model_selection import TimeSeriesSplit, train_test_split\nfrom sklearn.metrics import  classification_report, log_loss, roc_auc_score\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Load games data and remove columns that would be a leak for predicting the described game\n* A proper model would incorporate these features from previous games, e.g. teams which win by a large margin.\n    * I leave this as an exercise \"to the reader\" ;)\n    \n* As a lazy historical feature, we can take the rankings from the previous season! \n    * Requires us to \"shift\" and order by season - I may be doing this wrong (I have no idea how seasons work), so beware leaks!"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"GAME_COLS  =['GAME_DATE_EST', 'GAME_ID', 'HOME_TEAM_ID',\n       'VISITOR_TEAM_ID', 'SEASON', 'HOME_TEAM_WINS']\ndf = pd.read_csv(\"/kaggle/input/nba-games/games.csv\",usecols = GAME_COLS,parse_dates=[\"GAME_DATE_EST\"],infer_datetime_format=True)\ndf = df.drop_duplicates().sort_values(\"GAME_DATE_EST\").set_index([\"GAME_DATE_EST\"])\nprint(df.shape)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_players = pd.read_csv(\"/kaggle/input/nba-games/players.csv\")\nprint(df_players.shape)\ndf_players.head()\n\n### joining the players means a many to 1 join - of all players per team. Kludgy code, skip for now, especially without further features at the player level","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_teams = pd.read_csv(\"/kaggle/input/nba-games/teams.csv\")\nprint(df_teams.shape)\ndf_teams.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If there are only 30 teams, aggregate features per team may help (there are \"only\" 20k games), but not by much.   (30 is not an extremely high cardinality).\n    * What might help are features per team that change over time, where there's a lot more variation!"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.HOME_TEAM_ID.nunique() ## no obvious mismatch in # teams","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ranking = pd.read_csv(\"/kaggle/input/nba-games/ranking.csv\",parse_dates=[\"STANDINGSDATE\"])\ndf_ranking.sort_values(\"STANDINGSDATE\",inplace=True)\nprint(df_ranking.shape)\n\n## drop the less interesting or amenably columns . We could get ratio features from the record cols, but that'd require splitting first : \ndf_ranking.drop([\"CONFERENCE\",\"LEAGUE_ID\",\"HOME_RECORD\",\"ROAD_RECORD\"],axis=1,inplace=True) \n\ndf_ranking.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*  it looks like seasons aren't simply \"decade+number\" - making it trickier to add histoircal ones\n* Instead of merging by season_id , we'll merge by dates \"Before\", using pandas's asoiaf function"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ranking[\"SEASON_ID\"].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.shape)\n\ndf_ranking.set_index(\"STANDINGSDATE\",inplace=True)\n\ndf = pd.merge_asof(df, df_ranking.add_suffix(\"_homeTeam\"),\n              left_index=True,\n                       right_index=True,\n              left_by=\"HOME_TEAM_ID\",\n                       right_by='TEAM_ID'+\"_homeTeam\",\n#                         suffixes=\"_homeTeam\",  ## for some reason this gives error, so we workaround it by adding suffixes\n                       allow_exact_matches=False)\n\ndf = pd.merge_asof(df, df_ranking.add_suffix(\"_awayTeam\"),\n              left_index=True,\n              right_index=True,\n              left_by=\"VISITOR_TEAM_ID\",\n                       right_by='TEAM_ID'+\"_awayTeam\",\n                       allow_exact_matches=False)\n\ndf.drop([\"SEASON_ID_awayTeam\",\"TEAM_ID_awayTeam\",\"TEAM_ID_homeTeam\"],axis=1,inplace=True) ## redundant\ndf.rename(columns={\"SEASON_ID_homeTeam\":\"SEASON_ID\"},inplace=True)\nprint(df.shape)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[df.G_homeTeam==0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* we see rows with all 0 = missing values. We'll set their values to -1 , as a proxy for missingness.   (We can expect to theoretically see teams with 0 wins/losses after all, although it's very unlikely)\n* We set 0s to nans for away or home \n\n* Since there are just 571 such games (likely the firs tones of each season, we could also simply drop them "},{"metadata":{"trusted":true},"cell_type":"code","source":"def missing_game_rankings(row,suffix=\"_homeTeam\"):\n    if ((row[\"G\"+suffix]==0) & (row[\"W\"+suffix]==0)): \n        row[\"G\"+suffix]=np.nan\n        row[\"W\"+suffix]=np.nan\n        row[\"L\"+suffix]=np.nan\n        row[\"W_PCT\"+suffix]=np.nan\n    return row\n  \ndf = df.apply(lambda x: missing_game_rankings(x,suffix=\"_awayTeam\"),axis=1)\ndf = df.apply(lambda x: missing_game_rankings(x,suffix=\"_homeTeam\"),axis=1)\n\nprint(df.isna().sum())\n\ndf = df.dropna()\nprint(\"df without nans size:\", df.shape[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ML Model\n* Split data by time\n* Build a machine learning model\n\n* Ideally we'd evaluate by probabilities (logloss) , to build a betting model. "},{"metadata":{"trusted":true},"cell_type":"code","source":"## sklearn temporal split is for CV - we don't need. data is sorted, so we'll just take the last 20% of rows\n## get only numeric columns - we don't need the strings here\nCUTOFF_ROW = int(df.shape[0]*0.8)\n# X = df.reset_index().drop([\"SEASON\"],axis=1)._get_numeric_data().copy() \nX = df.drop([\"SEASON\"],axis=1)._get_numeric_data().copy() \nX_train = X[:CUTOFF_ROW].drop([\"HOME_TEAM_WINS\"],axis=1)\nprint(\"X_train\",X_train.shape)\nX_test = X[CUTOFF_ROW:].drop([\"HOME_TEAM_WINS\"],axis=1)\nprint(\"X_test\",X_test.shape)\ny_train = X[:CUTOFF_ROW][\"HOME_TEAM_WINS\"]\nprint(\"y_train\",len(y_train))\ny_test = X[CUTOFF_ROW:][\"HOME_TEAM_WINS\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### if using catboost or lgbm, we'll define categorical variables & Pool\n\n* catboost hyperparam tuning : https://colab.research.google.com/github/catboost/tutorials/blob/master/python_tutorial.ipynb#scrollTo=nSteluuu_mif\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"print([c for c in X_train.columns if 5<X_train[c].nunique()<8000])\n\ncategorical_cols = ['HOME_TEAM_ID', 'VISITOR_TEAM_ID']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## catBoost Pool object\ntrain_pool = Pool(data=X_train,label = y_train,cat_features=categorical_cols,\n#                   baseline= X_train[\"W_PCT_homeTeam\"], ## not as relevant as a baseline, since we subtracted by it (rather than dividing)\n#                   group_id = X_train['SEASON_ID']\n                 )\n\ntest_pool = Pool(data=X_test,label = y_test,cat_features=categorical_cols,\n#                   baseline= X_train[\"W_PCT_homeTeam\"], ## not as relevant as a baseline, since we subtracted by it (rather than dividing)\n#                   group_id = X_test['SEASON_ID']\n                 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = CatBoostClassifier(verbose=False) # ,task_type=\"GPU\") # use GPU acceleration - requires kernel to have GPU activated and limits availability\n\nmodel.fit(train_pool, plot=True,silent=True)\nprint(model.get_best_score())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## get results on test set \ntest_preds = model.predict(test_pool,prediction_type='Class')\nprint(classification_report(y_true=y_test,y_pred=test_preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds_proba = model.predict(test_pool,prediction_type='Probability')[:,1]\n\nprint(\"Test AUC:\")\nprint(\"%.4f\" % roc_auc_score(y_true=y_test, y_score = test_preds_proba))\n\nprint(\"Test Log Loss:\")\nprint(\"%.4f\" % log_loss(y_true=y_test, y_pred = test_preds_proba))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Temporally cross validated model : \n* Just on the train set. "},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n          \"loss_function\": \"Logloss\",\n          \"verbose\": False,\n          \"use_best_model\":True, ## requires a validation dataset to be provided.\n          \"custom_metric\":['Logloss', 'AUC',\"Precision\"],\n         }\n\ndf_cv = cv(pool=train_pool,params=params,plot=True,type=\"TimeSeries\",fold_count=6,metric_period=3)\n\ndisplay(df_cv.sample(5))\n\ntest_eval_cols = [c for c in df_cv.columns if (\"test\" in c) & (\"mean\" in c)]\ndisplay(df_cv[test_eval_cols].median())\ndisplay(df_cv.tail(1)[test_eval_cols])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Feature importances\n* Can Look also at Shapley values : https://github.com/slundberg/shap\n    * catboost + shap has issues. .. \n        * e.g. https://github.com/slundberg/shap/issues/750\n        * tutoiral doesn't help - https://github.com/slundberg/shap/blob/master/notebooks/tree_explainer/Catboost%20tutorial.ipynb\n        \n            * Likely caused due to categorical features + catboost and null splits : https://github.com/slundberg/shap/issues/757"},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importances = model.get_feature_importance(train_pool)\nfeature_names = X_train.columns\nfor score, name in sorted(zip(feature_importances, feature_names), reverse=True):\n    print('{}: {}'.format(name, score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Export data for comparisons/benchmarking"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.concat([X_train,y_train],axis=1).to_csv(\"NBA_teams_train.csv\")\npd.concat([X_test,y_test],axis=1).to_csv(\"NBA_teams_test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.concat([X_train,y_train],axis=1)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}