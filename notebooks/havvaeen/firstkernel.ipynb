{"cells":[{"metadata":{},"cell_type":"markdown","source":"**IMPORT AND FIRST LOOK DATA**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/suicide-rates-overview-1985-to-2016/master.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Datada 27820 intihar bilgisi girişi yapılmış.\nData 12 feature'dan oluşmakta. (ülke, yıl, cinsiyet, yaş, intihar sayısı, popülasyon, intihar/100k popülasyon oranı, ülke-yıl bilgisi, yıllara göre HDI(insani gelişme indeksi), yıllara göre GSYİH, kişi başına düşen GSYİH, jenerasyon)\nDatatype'ler: 2 adet float, 4 adet integer, 6 adet object\nData, hafızada 2.5+ MB hafıza kaplamakta"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"gdp_per_capita($) feature'si ve HDI for year feature'si arasındaki korelasyon 0.78. 1'e yakın olan bu değer, bu iki featurenin doğru orantılı olduğunu gösterir.\n\nNegatif korelasyon da ter orantıyı ifade eder."},{"metadata":{"trusted":true},"cell_type":"code","source":"#correlation map\nf, ax = plt.subplots(figsize=(18,18))\nsns.heatmap(data.corr(), annot=True, linewidths=.5, fmt='.1f', ax=ax)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seaborn bir visualition tool.\nKorelasyon tablosu görsel bir şekilde oluşturuluyor.\nannot = True, korelasyon haritasındaki her bir karenin üzerinde sayıların gözükmesi anlamına geliyor. \nlinewidth, karler arasındaki çizginin kalınlığı.\nfmt, 0'dan sonra yazdıracağı değer.\nax, f'in yanındaki ax.\nfigsize(18,18) ile figürün size'ı önceden belirlendi. Eğer belirlenmeseydi size, default bir değer olacaktı. Bu da figürün daha küçük gözükmesine neden olacaktı.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**1. INTRODUCTION TO PYTHON**"},{"metadata":{},"cell_type":"markdown","source":"A. MATPLOTLIB"},{"metadata":{},"cell_type":"markdown","source":"Line plot: x axis is time.\nScatter plot: correlation between two variables.\nHistogram: to see distrubution of numericl data.\n\nCustomization: colors(color), labels(label), thickness of line(linewidth), title, opacity(alpha), grid(grid), ticks of axis and linestyle(linestyle)"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndata.year.plot(kind='line', color='g', label='year', linewidth=1, alpha=0.5, grid=True, linestyle=':')\ndata.population.plot(color='r', label='population', linewidth=1, alpha=0.5, grid=True, linestyle='-.')\nplt.legend(loc='upper right') #puts label into plot\nplt.xlabel('x axis') #label= name of label\nplt.ylabel('y axis') \nplt.title('Line Plot') #title= title of plot\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#scatter plot\n#x = year\n#y = population\ndata.plot(kind='scatter', x='year', y='population', alpha=0.5, color='red')\nplt.xlabel('year')\nplt.ylabel('population')\nplt.title('Year Population No Scatter Plot')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#histogram\n#bins=number of bar in figure\ndata.suicides_no.plot(kind='hist', bins=50, figsize=(12,12))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#clf() = cleans it up again you can start a fresh\ndata.suicides_no.plot(kind='hist', bins=50)\nplt.clf\n#BUT we cannot see plot due to clf()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"B. DICTIONARY\nIt has key and value.\nFaster than lists."},{"metadata":{"trusted":true},"cell_type":"code","source":"#create dictionary and look its keys and values\ndictionary ={'izmir': 'cesme', 'antalya':'belek'}\nprint(dictionary.keys())\nprint(dictionary.values())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Keys have to be immutable objects like string, boolean, float, integer or tuples\n#List is not immutable.\n#Keys are unique.\ndictionary['izmir']='dikili' #uptade existing entry\nprint(dictionary)\ndictionary['mugla']='bodrum' #add new entry\nprint(dictionary)\ndel dictionary['izmir'] #remove entry with key 'izmir'\nprint(dictionary)\nprint('mugla' in dictionary) #check include or not\nprint('izmir' in dictionary)\ndictionary.clear() #remove all entries in dict\nprint(dictionary)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#In order to run all code you need to take comment this line\n#del dictionary #delete entire dictionary\nprint(dictionary) #it gives error because dictionary is deleted.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"C. PANDAS"},{"metadata":{},"cell_type":"markdown","source":"csv : comma separated values"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/suicide-rates-overview-1985-to-2016/master.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"series = data['age'] # data['suicide_no'] =series \nprint(type(series))\ndata_frame = data [['age']] # data[['age']] = data frame\nprint(type(data_frame))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"D. LOGIC, CONTROL FLOW AND FILTERING"},{"metadata":{"trusted":true},"cell_type":"code","source":"#comparison operator\nprint(3 > 2)\nprint(3!=2)\n#Boolean operators\nprint(True and False)\nprint(True or False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1 - Filtering Pandas Data Frame\nx = data ['year'] >2013 # There are 1840 suicide information who have higher year 2013 \ndata[x]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#2 - Filtering pandas with logical _ and\n# There are 431 suicide information who have higher year than 2013 and higher population than 2000000\n# Therefore we can also use'&' for filtering\ndata[np.logical_and(data['year']>2013, data['population']>2000000)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"E. LOOP DATA STRUCTURES"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stay in loop if condition (i is not equal 5) is true\ni = 0\nwhile i != 5 :\n    print('i is: ',i)\n    i+=1\nprint(i, 'is equal to 5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stay in loop if condition (i is not equal 5) is true\nlis = [1,2,3,4,5]\nfor i in lis:\n    print('i is: ',i)\nprint('')\n\n# Enumerate index and value of list\n#index : value = 0:1, 1:2, 2:3, 3:4, 4:5\nfor index, value in enumerate (lis):\n    print(index, \" : \", value)\nprint('')\n\n# For dictionaries\n# We can use for loop to achieve key and value of dictionary. We learnt key and value at dictionary part.\ndictionary = {'izmir':'urla', 'antalya':'kas'}\nfor key, value in dictionary.items():\n    print(key,\" : \", value)\nprint('')\n\n# For pandas we can achieve index and value\nfor index, value in data[['age']][0:1].iterrows(): #0 inclusive ; 1 exclusive\n    print(index, \" : \", value)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**2. PYTHON DATA SCIENCE TOOLBOX**"},{"metadata":{},"cell_type":"markdown","source":"A. USER DEFINED FUNCTION"},{"metadata":{},"cell_type":"markdown","source":"Tuble: Sequence of immutable python objects\nCan't modify values\nUnpack tuble into several variables like a,b,c = tuble\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Example of what we learn above \ndef tuble_ex():\n    \"\"\"return defined t tuble\"\"\"\n    t = (1,2,3)\n    return t\na,b,c = tuble_ex()\nprint(a,b,c)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"B. SCOPE"},{"metadata":{},"cell_type":"markdown","source":"Global : Defined main body in script\nLocal : Defined in a function \nBuilt in scope : Names in predefined built in scope module such as print, len"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Guess print what\nx = 2\ndef f():\n    x = 3\n    return x\nprint(x) # x = 2 global scope\nprint(f()) # x = 3 local scope","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What if there is no local scope, first local scopesearched, then global scope searched. If two of them cannot be found lastly built in scope searched."},{"metadata":{"trusted":true},"cell_type":"code","source":"# How we learn what is built in scope\nimport builtins\ndir(builtins)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"C. NESTED FUNCTION"},{"metadata":{},"cell_type":"markdown","source":"Function inside function"},{"metadata":{"trusted":true},"cell_type":"code","source":"# nested function\ndef square():\n    \"\"\"return square of value\"\"\"\n    def add():\n        \"\"\"add two local variable\"\"\"\n        x = 2\n        y = 3\n        z = x + y\n        return z\n    return add()**2\nprint(square())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"D. DEFAULT AND FLEXIBLE ARGUMENTS"},{"metadata":{"trusted":true},"cell_type":"code","source":"# default arguments\ndef f(a, b = 1, c = 2):\n    y = a + b + c\n    return y\nprint(f(5))\n# what if we want to change default arguments\nprint(f(5, 4, 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# flexible arguments *args \n# args can be one or more\ndef f(*args):\n    for i in args:\n        print(i)\nf(1)\nprint(\"\")\nf(1, 2, 3, 4)\n\n# flexible arguments **kgwargs that is dictionary \ndef f(**kwargs):\n    \"\"\"print key and value of dictionary\"\"\"\n    for key, value in kwargs.items():\n        print(key, \" \", value)\nf(country = 'spain', capital = 'madrid', population = 123456)\n        \n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"E. LAMBDA FUNCTION"},{"metadata":{"trusted":true},"cell_type":"code","source":"square = lambda x : x**2\nprint(square(4))\ntot = lambda x, y, z : x+y+z\nprint (tot(1,2,3))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"F. ANONYMOUS FUNCTİON "},{"metadata":{"trusted":true},"cell_type":"code","source":"number_list = [1,2,3]\ny = map (lambda x : x**2, number_list)\nprint(list(y)) #sonucu liste olarak yazdır","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"G. ITERATORS"},{"metadata":{},"cell_type":"markdown","source":"İterable is an object that can return an iterator.\nİterable : An object with an associated iter() method \nexample : list, strings and dictionaries\niterator: Produces next value with next() method."},{"metadata":{"trusted":true},"cell_type":"code","source":"# iteration example\nname = \"ronaldo\"\nit = iter(name)\nprint(next(it)) # print next iteration\nprint(*it) # print remaining iteration","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# zip():zip lists\n# zip example\nlist1 = [1,2,3,4]\nlist2 = [5,6,7,8]\nz = zip(list1, list2)\nprint(z)\nz_list = list (z)\nprint(z_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"un_zip = zip(*z_list)\nun_list1, un_list2 = list(un_zip) # unzip returns tuple\nprint(un_list1)\nprint(un_list2)\nprint(type(un_list2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"H. LIST COMPREHENSION"},{"metadata":{"trusted":true},"cell_type":"code","source":"num1 = [1,2,3]\nnum2 = [i + 1 for i in num1]\nprint(num2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[i +1 for i in num1] : list of comprehension\ni + 1 : list comprehension syntax\nfor i in num1 : for loop syntax\ni : iterator\nnum1 : iterable object"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Conditionals on iterable \nnum1 = [5, 10, 15]\nnum2 = [i**2 if i==10 else i-5 if i<7 else i+5 for i in num1]\nprint(num2)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. CLEANING DATA\n"},{"metadata":{},"cell_type":"markdown","source":"A. DIAGNOSE DATA FOR CLEANING"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/suicide-rates-overview-1985-to-2016/master.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape # Shape gives number of rows and columns in a tuple ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"B. EXPLORATORY DATA ANALYSIS"},{"metadata":{},"cell_type":"markdown","source":"value_counts() : frequency counts \noutliers : the value that is considerably higher or lower from rest of the data.\nvalue at 75% is Q3 and value at 25% is Q1\nOutlier are smaller than Q1 - 1.5(Q3-Q1) and bigger than Q3 + 1.5(Q3-Q1). (Q3-Q1) = IQR\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data['country'].value_counts(dropna=False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe() #ignore null entries","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"C. VISUAL EXPLORATORY DATA ANALYSIS"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.boxplot(column = 'population', by = 'country')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"D. TIDY DATA"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Firstly I create new data from suicides data to explain melt nore easily.\ndata_new = data.head()\ndata_new","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets melt\n# id_vars = what we do not wish to melt\n# value_vars = what we want to melt\nmelted = pd.melt(frame=data_new, id_vars = 'suicides_no', value_vars = ['population','year'])\nmelted","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"E. PIVOTING DATA"},{"metadata":{},"cell_type":"markdown","source":"Reverse of melting"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Index is country\n# I want to make that columns are variable\n# Finally values in columns are value\nmelted.pivot(index ='suicides_no', columns = 'variable', values ='value')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"F. CONCATENATING DATA"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Firstly lets create 2 data frame\ndata1 = data.head()\ndata2 = data.tail()\nconc_data_row = pd.concat([data1, data2], axis = 0, ignore_index = True)\nconc_data_row","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1 = data['population'].head()\ndata2 = data['country'].head()\nconc_data_col = pd.concat([data1, data2], axis=1)\nconc_data_col","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"G.DATA TYPES"},{"metadata":{},"cell_type":"markdown","source":"5 data types: object, boolean, integer, float and categorical"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets convert object to categorical and int to float\ndata['country'] = data['country'].astype('category')\ndata['suicides_no'] = data['suicides_no'].astype('float')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"H. MISSING DATA AND TESTING WITH ASSERT"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets look at does suicide data have nan value.\nAs you can see there are 27820 entries. However HDI for years 8364 non-null float so it has 19456 null float."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets chech HDI for year \ndata[\"HDI for year\"].value_counts(dropna=False)\n# As you can see, there are 19456 NAN value","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets drop nan values\ndata1 = data # Also we will use data to fill missing value, so I assign it to data1 variable.\ndata1[\"HDI for year\"].dropna(inplace = True) # inplace=True means we do not assign it to new variable. Changes automatically assigned to data.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets check with assert statement \n# Assert statement:\nassert 1==1 #return nothing because it is true","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# assert 1==2 #return to error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert data['HDI for year'].notnull().all() # returns nothing because we do not have nan values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"4. PANDAS FOUNDATION"},{"metadata":{},"cell_type":"markdown","source":"single column = series\nNan = not a number\ndataframe.values = numpy"},{"metadata":{},"cell_type":"markdown","source":"A. BUILDING DATA FRAMES FROM SCRATCH"},{"metadata":{},"cell_type":"markdown","source":"We can build dtaframe from csv we did earlier.\nAlso we can build dataframe from dictionaries.\nzip() = This function returns a list of tuples, where the i-ht tuple contains the i-th element from each of the argument sequences or iterables\nAddinng new column\nBroadcasting : Create new column and assign a value to entire column."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data frames from dictionaries\ncity = [\"izmir\", \"antalya\"]\npopulation = [\"11\",\"12\"]\nlist_label = [\"city\",\"population\"]\nlist_col = [city, population]\nzipped = list(zip(list_label,list_col))\ndata_dict = dict(zipped)\ndf = pd.DataFrame(data_dict)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add new columns\ndf[\"region\"] = [\"ege\",\"akdeniz\"]\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Broadcasting\ndf[\"income\"] = 0 # Broadcasting entire column\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"B. VISUAL EXPLORATORY DATA ANALYSIS"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting all data\ndata1 = data.loc[:,[\"population\",\"HDI for year\", \"gdp_per_capita ($)\", \"year\"]]\ndata1.plot()\nplt.show()\n# it is confusing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# subplot\ndata1.plot(subplots = True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# scatter plot\ndata1.plot(kind = \"scatter\", x = \"population\", y = \"HDI for year\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# hist plot\ndata1.plot(kind = \"hist\", y=\"year\", bins = 50, range = (0,250), normed = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# histogram subplot with non cumulative and cumulative\nfig, axes = plt.subplots(nrows = 2, ncols = 1)\ndata1.plot(kind = \"hist\", y = \"year\", bins = 50, range = (0,250), normed = True, ax = axes[0])\ndata1.plot(kind = \"hist\", y = \"year\", bins = 50, range = (0,250), normed = True, ax = axes[1], cumulative = True)\nplt.savefig('graph.png')\nplt\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"C. STATISTICAL EXPLORATORY DATA ANALYSIS"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"D. INDEXING PANDAS TIME SERIES\ndatetime = object\nparse_dates(boolean) : Transform date to ISO 8601 (yyyy-mm-dd hh:mm:ss) format"},{"metadata":{"trusted":true},"cell_type":"code","source":"time_list = [\"1992-03-08\", \"1992-04-12\"]\nprint(type(time_list[1])) # As you can see date is string\n# However we want to it to be datetime object\ndatetime_object = pd.to_datetime(time_list)\nprint(type(datetime_object))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# close warning \nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# in order to practice lets take head of suicide data and add it a time list\ndata2 = data.head()\ndate_list = [\"2019-08-23\", \"2019-11-15\", \"2019-12-29\", \"2020-01-11\", \"2020-02-11\"]\ndatetime_object = pd.to_datetime(date_list)\ndata2[\"date\"] = datetime_object\n# lets make date as index\ndata2 = data2.set_index(\"date\")\ndata2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# now we can select according to our date index\nprint(data2.loc[\"2020-02-11\"])\nprint(data2.loc[\"2019-12-29\":\"2020-02-11\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"E. RESAMPLING PANDAS TIME SERIES"},{"metadata":{},"cell_type":"markdown","source":"Resampling : Statistical method over different intervals.\nNeeds string to specify frequency like \"M\" = month or \"A\" = year.\nDownsampling : reduce date time rows to slower frequency like from daily to weekly.\nUpsampling: increase date time rows to faster frequency like from daily to hourly.\nInterpolate: Interpolate values according to different methods like ‘linear’, ‘time’ or index."},{"metadata":{"trusted":true},"cell_type":"code","source":"# we will use data2 that we create at previous part\ndata2.resample(\"A\").mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets resample with month\ndata2.resample(\"M\").mean()\n# As you can see there are a lot of nan because data2 does not include all months","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# in real life (data is real. Not created from us like data2) we can solve this problem with interpolate\n# we can interpolate with mean().\ndata2.resample(\"M\").mean().interpolate(\"linear\") # mean() yerine first() : interpolate from first value","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"MANIPULATING DATA FRAMES WITH PANDAS "},{"metadata":{},"cell_type":"markdown","source":"A. INDEXING DATA FRAMES"},{"metadata":{},"cell_type":"markdown","source":"Indexing using square brackets\nUsing column attribute and row label\nUsing loc accessor\nSelecting only some columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"# read data\ndata = pd.read_csv('../input/suicide-rates-overview-1985-to-2016/master.csv')\n#data= data.set_index(\"#\") #NEDEN HATA\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# indexing using square brackets\ndata[\"population\"][1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using column attribute and row label\ndata.population[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using loc accessor\ndata.loc[1, [\"population\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# selecting only some columns\ndata[[\"population\", \"country\"]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"B. SLICING DATA FRAME"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Difference between selecting columns: series and dataframes\nprint(type(data[\"population\"])) #series\nprint(type(data[[\"population\"]])) # data frames","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# slicing and indexing series\ndata.loc[1:10, \"year\":\"population\"]  # 10 and populatşon inclusive","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reverse slicing\ndata.loc[10:1:-1, \"year\":\"population\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from something to end\ndata.loc[1:10, \"population\":]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"C. FILTERING DATA FRAMES"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating boolean series\nboolean = data.population > 30000\ndata[boolean]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Combining filters\nfirst_filter = data.population > 30000\nsecond_filter = data.year > 2015\ndata[first_filter & second_filter]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# filtering column based others\ndata.population[data.year > 2015]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"D. TRANSFORMING DATA"},{"metadata":{"trusted":true},"cell_type":"code","source":"# plain python functions\ndef div(n):\n    return n/2\ndata.population.apply(div)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# or we can use lambda function\ndata.population.apply(lambda n : n/2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# defining column using other columns\ndata[\"total_power\"] = data.population + data.year\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"E. INDEX OBJECTS AND LABELED DATA"},{"metadata":{},"cell_type":"markdown","source":"index: sequence of label"},{"metadata":{"trusted":true},"cell_type":"code","source":"# our index name is this:\nprint(data.index.name)\n#lets change it\ndata.index.name = \"index_name\"\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# overwrite index\n# if we want to modify index we need to change all of them.\ndata.head()\n#first copy of our data to data3 then change index \ndata3 = data.copy()\n#lets make index start from 100. it is not remarkable change but it is just example\ndata3.index = range(100,27920,1)\ndata3.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"F. HIERARCHICAL INDEXING"},{"metadata":{},"cell_type":"markdown","source":"Setting indexing"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/suicide-rates-overview-1985-to-2016/master.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# setting index: country is outer year is inner index\ndata1 = data.set_index([\"country\", \"year\"])\ndata1.head(100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"G. PIVOTING DATA FRAMES"},{"metadata":{},"cell_type":"markdown","source":"pivoting: reshape tool"},{"metadata":{"trusted":true},"cell_type":"code","source":"dic = {\"treatment\":[\"A\",\"A\",\"B\",\"B\"], \"gender\":[\"F\",\"M\",\"F\",\"M\"], \"response\":[10,45,5,9],\"age\":[12,45,78,96]}\ndf = pd.DataFrame(dic)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pivoting\ndf.pivot(index =\"treatment\",columns = \"gender\", values = \"response\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I. STACKING AND UNSTACKING DATAFRAME"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df.set_index([\"treatment\",\"gender\"])\ndf1\n# lets unstack it","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# level determines indexes\ndf1.unstack(level=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.unstack(level=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# change inner and outer level index position\ndf2 = df1.swaplevel(0,1)\ndf2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"J. MELTING DATA FRAMES"},{"metadata":{},"cell_type":"markdown","source":"Reverse of pivoting"},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df.pivot(index=\"treatment\",columns=\"gender\",values=\"response\")\npd.melt(df,id_vars=\"treatment\",value_vars=[\"age\",\"response\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"K. CATEGORICALS AND GROUPBY"},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will use df\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# according to treatment take means of other features\ndf.groupby(\"treatment\").mean() # mean is aggregation / reduction method\n# there are other methods like sum, std,max or min","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we can only choose one of the feature\ndf.groupby(\"treatment\").age.max() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Or we can choose multiple features\ndf.groupby(\"treatment\")[[\"age\",\"response\"]].min() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()\n# as you can see gender is object\n# however if we use groupby, we can convert it categorical data.\n##df[\"gender\"] = df[\"gender\"].astype(\"category\")\n#df[\"treatment\"] = df[\"treatment\"].astype(\"category\")\n#df.info()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}