{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Introduction"},{"metadata":{},"cell_type":"markdown","source":"A commercial success movie not only entertains audience, but also enables film companies to gain tremendous profit. A lot of factors such as good directors, experienced actors are considerable for creating good movies. However, famous directors and actors can always bring an expected box-office income but cannot guarantee a highly rated imdb score."},{"metadata":{},"cell_type":"markdown","source":"## Data Description "},{"metadata":{},"cell_type":"markdown","source":"The dataset (movie-review-data.csv) contains 28 variables for 5043 movies, spanning across 100 years in 66 countries. There are 2399 unique director names, and thousands of actors/actresses. “imdb_score” is the response variable while the other 27 variables are possible predictors."},{"metadata":{},"cell_type":"markdown","source":"## Problem Statement"},{"metadata":{},"cell_type":"markdown","source":"Build Model to predict what kind of movies are more successful.Take imdb scores as response variable and focus on operating predictions by analyzing the rest of variables in the movie data."},{"metadata":{},"cell_type":"markdown","source":"## Importing Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data loading  "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reading the dataset\ndata = pd.read_csv('../input/imdb-5000-movie-dataset/movie_metadata.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Name of 28 Columns in the dataset\ndata.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Shape: Number of columns & Number of rows in the dataset\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#To check non-null values out of total values & datatype of columns\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Used for calculating some statistical data like percentile, mean and std of the numerical values\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#This will include count, unique, top and freq. The top is the most common value. The freq is the most common value’s frequency.\ndata.describe(include = 'object')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finding Columns with Missing Values\ndata.isna().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finding the number of missing values in all columns\ndata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,6))\nheatmap = sns.heatmap(data.isnull(),cmap='Oranges',cbar=False,yticklabels=False)\nheatmap.set_xticklabels(heatmap.get_xmajorticklabels(), fontsize = 18)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#bifurcating numerical as well as categorical columns\nNum_columns = [column for column in data.columns if data[column].dtype != 'object']\nCat_columns = [column for column in data.columns if data[column].dtype == 'object']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Num_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Cat_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Replacing some of the Categorical variables with the mode\ndata['color'].fillna(data['color'].mode()[0], inplace=True)\ndata['country'].fillna(data['country'].mode()[0], inplace=True)\ndata['language'].fillna(data['language'].mode()[0], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['content_rating'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Filling not rated value in null values \ndata['content_rating'].fillna('Not Rated', inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Replacing some of the Numerical variables with the median(not using mean because there may be some outliers)\ndata['num_critic_for_reviews'].fillna(data['num_critic_for_reviews'].median(), inplace=True)\ndata['duration'].fillna(data['duration'].median(), inplace=True)\ndata['director_facebook_likes'].fillna(data['director_facebook_likes'].median(), inplace=True)\ndata['actor_3_facebook_likes'].fillna(data['actor_3_facebook_likes'].median(), inplace=True)\ndata['actor_1_facebook_likes'].fillna(data['actor_1_facebook_likes'].median(), inplace=True)\ndata['actor_2_facebook_likes'].fillna(data['actor_2_facebook_likes'].median(), inplace=True)\ndata['gross'].fillna(data['gross'].median(), inplace=True)\ndata['facenumber_in_poster'].fillna(data['facenumber_in_poster'].median(), inplace=True)\ndata['num_user_for_reviews'].fillna(data['num_user_for_reviews'].median(), inplace=True)\ndata['budget'].fillna(data['budget'].median(), inplace=True)\ndata['title_year'].fillna(data['title_year'].mode()[0], inplace=True)\ndata['aspect_ratio'].fillna(data['aspect_ratio'].mode()[0], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking number of unique values \ndata['plot_keywords'].nunique(), data['director_name'].nunique(), data['actor_2_name'].nunique(),data['actor_1_name'].nunique(),data['actor_3_name'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dropping Null values for these column because they havemany unique values so can't replace them with mode or median\ndata = data.dropna(axis = 0, subset = ['plot_keywords','director_name','actor_2_name','actor_1_name','actor_3_name'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dropping duplicate rows \ndata.drop_duplicates(inplace = True)\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We lost around 305 rows from the data which is around 6% of whole data. "},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Visualization "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 8))\nsns.distplot(data['imdb_score'], color='g', bins=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With this information we can see that the imdb scores are left skewed"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.hist(bins=30,figsize=(16,16),color='Orange',xlabelsize=8, ylabelsize=8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 6))\nplot = sns.countplot(x='color', data=data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 6))\nplot = sns.countplot(x='country', data=data)\nplt.xticks(rotation = 90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 6))\nplot = sns.countplot(x='language', data=data)\nplt.xticks(rotation = 90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 6))\nplot = sns.countplot(x='content_rating', data=data)\nplt.xticks(rotation = 90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16, 6))\nax = sns.boxplot(x='color', y='imdb_score', data=data)\nplt.setp(ax.artists, alpha=.5, linewidth=2, edgecolor=\"k\")\nplt.xticks(rotation=45)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16, 6))\nax = sns.boxplot(x='content_rating', y='imdb_score', data=data)\nplt.setp(ax.artists, alpha=.5, linewidth=2, edgecolor=\"k\")\nplt.xticks(rotation=45)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16, 6))\nax = sns.boxplot(x='country', y='imdb_score', data=data)\nplt.setp(ax.artists, alpha=.5, linewidth=2, edgecolor=\"k\")\nplt.xticks(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16, 6))\nax = sns.boxplot(x='language', y='imdb_score', data=data)\nplt.setp(ax.artists, alpha=.5, linewidth=2, edgecolor=\"k\")\nplt.xticks(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(round(len(Num_columns) / 3), 3, figsize = (18, 20))\n\nfor i, ax in enumerate(fig.axes):\n    if i < len(Num_columns) - 1:\n        sns.regplot(x=Num_columns[i],y='imdb_score', data=data[Num_columns], ax=ax, label = Num_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(0, len(Num_columns), 5):\n    sns.pairplot(data=data[Num_columns],\n                x_vars=Num_columns[i:i+5],\n                y_vars=['imdb_score'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Pre-Processing "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Replacing some special characters with comma\ndata['plot_keywords'] = data['plot_keywords'].str.replace('|',',')\ndata['genres'] = data['genres'].str.replace('|',',')\ndata['movie_title'] = data['movie_title'].str.replace('Â',' ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#New column(Profit) to calculate the net profit made by the movie (Gross-Budget) \ndata['Profit']=data['budget'] - data['gross']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#New column(Profit%) to calculate the net profit made by the movie (Gross-Budget) \ndata['Profit%']=(data['Profit']/data['gross'])*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['country'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"from the above output we can observed most of the movies are produced in USA & UK (around 85%)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Replacing other than USK & UK with others\ncountries = ['USA','UK']\ndata['country'] = data['country'].where(data['country'].isin(countries), 'other')\ndata['country'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['language'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"from the above output we can observed most of the movies have english as a language(around 94%)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Replacing all the language other than english with others\nmost_occurred_language = ['English']\ndata['language'] = data['language'].where(data['language'].isin(most_occurred_language), 'other')\ndata['language'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"#Correlation_Matrix- Finding Correlation between variables\ncorrelation = data.corr()\nf,ax = plt.subplots(figsize=(15,15))\nsns.heatmap(correlation, annot=True, cmap=\"YlGnBu\", linewidths=.5,fmt='.2f')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above heatmap it was observed that actor_1_facebook_likes and cast_total_facebook_likes are highly correlated to each other."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dropping highly correlated columns\ndata.drop('cast_total_facebook_likes',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Converting categorical features into numerical features by using label encoder "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting the column labels into numeric form\nlabelencoding = LabelEncoder()\ncategories=['color', 'director_name', 'actor_2_name',\n        'genres', 'actor_1_name',\n        'actor_3_name',\n        'plot_keywords',\n        'language', 'country', 'content_rating',\n       'title_year', 'aspect_ratio','movie_title','movie_imdb_link']\ndata[categories]=data[categories].apply(lambda x:labelencoding.fit_transform(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scales all the data features in the range [0, 1]\ny = data['imdb_score']\nX = data.drop(['imdb_score'], axis = 1)\nscaler = MinMaxScaler()\nX = scaler.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Building "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Splitting the data-set into train and test data-set\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, test_size = 0.3, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape, y_train.shape, X_test.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Training the model\nn_trees=300\ngbregressor = GradientBoostingRegressor(loss='ls',learning_rate=0.02,n_estimators=n_trees,max_depth=3)\ngbregressor.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predicting the output on test data-set\ny_pred=gbregressor.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calculating the error on the basis of actual & predicted output\nprint('The mean squared error using Gradient boosting regressor  is: ',mean_squared_error(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Constructing a new dataframe with column names and feature importance\nfeatureimp = pd.DataFrame()\ndatanew = data.drop(['imdb_score'], axis = 1)\nfeatureimp['columns'] = datanew.columns\n\nfeatureimp['Feature_importance'] = gbregressor.feature_importances_\n#Sorting with feature importance column\nfeatureimp = featureimp.sort_values(by='Feature_importance', ascending=True)\n\n#Barplot indicating Feature Importance\nplt.figure(figsize=(16, 16))\nplt.barh(y=featureimp['columns'], width=featureimp['Feature_importance'], color='blue')\nplt.title('Feature Importance', fontsize=20, fontweight='bold', pad=20)\nplt.xlabel('Importance', fontsize=14, labelpad=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using Cross-validation for Hyperparameter tuning\nparam_grid = {\n    'loss' : ['ls'],\n    'max_depth' : [3,4,5],\n    'learning_rate' : [0.05, 0.01,0.001],\n    'n_estimators': [300,500,1000],\n    'min_samples_split' : [1,2],\n    'min_samples_leaf' : [0.5,1],\n    'max_features' : [15,20,25]}\ngbregressor = GradientBoostingRegressor()\ngb_gridsearch = GridSearchCV(estimator = gbregressor, param_grid = param_grid, \n                          cv = 5, n_jobs = -1, verbose = 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Training the model with best hyperparameter and printing the best hyperparameters used\ngb_gridsearch.fit(X_train, y_train)\ngb_gridsearch.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predicting the output after the cross-validation with best hyperparameter & calcualting the error\ny_pred_gridsearch = gb_gridsearch.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Output\ny_pred_gridsearch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('The mean squared error using Gradient boosting regressor after hyparameter tuning is: ',mean_squared_error(y_test,y_pred_gridsearch))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}