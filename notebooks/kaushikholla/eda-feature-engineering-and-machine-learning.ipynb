{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Thanks for Dropping by.**\n\n**Please consider upvoting** if you like the notebook.\n\nIf you have any suggestions and improvements please consider dropping them in comments and I will definetly go over them. \n\n**Thanks in Advance**"},{"metadata":{},"cell_type":"markdown","source":"**Note:** I am still working on this notebook. Please consider dropping by again to see more updates."},{"metadata":{},"cell_type":"markdown","source":"**Summary:** \n\nThe data is related with direct marketing campaigns of a Portuguese banking institution, based on phone calls (Moro, Cortez, and Rita 2014).The goal of the campaigns were to get the clients to subscribe to a term deposit. \nThere are 20 input variables and 1 binary output variable (y) that indicates whether the client subscribed to a term deposit with values ‘yes’,‘no’. \nThe input variables can be divided into four categories: \n1. bank client data \n2. data related to last contact of current campaign\n3. social and economic context attributes\n4. other attributes. \n\nBank client data contains variables containing information about the client. It includes variables indicating age, job, marital status, education, whether they have credit in default, whether they have a housing loan, whether they have a personal loan. \n\nData related to the last contact of the current campaign contain variables indicating the mode of communication, month of last communication, day of week when the last contact was made and the last call duration. \n\nSocial and economic context attributes contain variables with the quarterly employment variation rate, monthly consumer price index, monthly consumer confidence index, number of employees and the euribor 3 month rate. \n\nOther attributes include number of previous contacts with the client during the current campaign, number of days since the last contact for the previous campaign, number of contacts performed before the current campaign for the client and the outcome of the previous marketing campaign. \n\nThe goal of the project is to classify with high accuracy whether the campaign will be successful or not given a set of input variables.\n\n**Proposed Plan:** \n\nIn this project I will use the above data parameters to predict the outcome of the marketing campaign for the customer. \n\nI will be using Matplotlib and Seaborn for basic visualization and exploratory data analysis. I will also be making use of pandas packages to wrangle the data. Some data wrangling techniques that we will be using are imputation of missing/ NA data values, and converting categorical variables to numeric variables using one hot encoding. \n\nFor classification, I am planning on using:\n1. Logistic Regression \n2. Random Forests \n3. K-Nearest Neighbours \n4. Support Vector Machines\n5. Neural Networks. \n\nThe preliminary challenges that I might face would be in data wrangling and feature selection. Since there are 20 variables to fit the models and predict the outcome of the survey, it would be a challenge to select only those features which have a significant impact on the response variable. We plan to carry out feature engineering to create new features based on pre-existing ones.\n\n**Preliminary Results:**\n\nAfter performing exploratory data analysis, it was found that social and economic context attributes affect the outcome the most. The bank client data and data related to the last campaign had little to no effect on the outcome. We will use this as a basis to start building our machine learning models. Hence, we will be able to produce feasible models."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Importing libraries\n\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom imblearn.under_sampling import NearMiss\nfrom scipy import stats\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/bank-marketing/bank-additional-full.csv\", delimiter=';')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting categorical into boolean using get_dummies \n# Getting the predicted values in terms of 0 and 1\nY = (df['y'] == 'yes')*1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looking at statistics of our data\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looking at all the columns in the dataset.\ndf.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping y from the original dataset as we have read it seperately\ndf.drop('y', axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# First five rows of the dataset after dropping y from the dataset\nprint(df.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **1. Exploratory Data Analysis**\n\nWill perform some Exploratory Data Analysis to see how different features are distribute in the dataset. "},{"metadata":{},"cell_type":"markdown","source":"1.1 Visaulizing how age is distributed in the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visaulizing how age is distributed in the dataset\nsns.distplot(df['age'], hist = True, color = \"#07247D\", hist_kws = {'edgecolor':'black'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1.2 Visualizing how Maritial Status and Education is distributed in the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizing how Maritial Status and Education is distributed in the dataset. \nfig, (ax1, ax2) = plt.subplots(nrows = 1, ncols = 2, figsize = (13, 5))\n\n# First plot for marital status\nsns.countplot(x = \"marital\", data = df, ax = ax1)\nax1.set_title(\"marital status distribution\", fontsize = 13)\nax1.set_xlabel(\"Marital Status\", fontsize = 12)\nax1.set_ylabel(\"Count\", fontsize = 12)\n\n# Second plot for Education distribution\nsns.countplot(x = \"education\", data = df, ax = ax2)\nax2.set_title(\"Education distribution\", fontsize = 13)\nax2.set_xlabel(\"Education level\", fontsize = 12)\nax2.set_ylabel(\"Count\", fontsize = 12)\nax2.set_xticklabels(ax2.get_xticklabels(), rotation = 70)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1.3 Visualizing how Jobs are distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\nfig.set_size_inches(15,5)\nsns.countplot(x = \"job\", data = df)\nax.set_xlabel('Job', fontsize = 12)\nax.set_ylabel('Count', fontsize = 12)\nax.set_title(\"Job Count Distribution\", fontsize = 13)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1.4 Housing and Loan Distribution\n\nVisualizing how: \n\n1. Housing Loans are distributed. \n2. Personal Loans are distributed. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Housing loan data distribution\nfig, (ax1, ax2) = plt.subplots(nrows = 1, ncols = 2, figsize = (15, 5))\nsns.countplot(x = \"housing\", data = df, ax = ax1, order = ['yes', 'no', 'unknown'])\nax1.set_title(\"Housing Loan distribution\")\nax1.set_xlabel(\"Housing Loan\")\nax1.set_ylabel(\"Count\")\n\n# Personal loan data distribution\nsns.countplot(x = \"loan\", data = df, ax = ax2, order = ['yes', 'no', 'unknown'])\nax2.set_title(\"Personal Loan Distribution\")\nax2.set_xlabel(\"Personal Loan\")\nax2.set_ylabel(\"Count\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Getting total count for: \n\n1. Credit Defaulters \n2. People with Housing loan \n3. People with Personal loan"},{"metadata":{},"cell_type":"markdown","source":"*Credit Defaulter*"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of people with credit default: \", df[df['default'] == 'yes']['default'].count())\nprint(\"Number of people with no credit default: \", df[df['default'] == 'no']['default'].count())\nprint(\"Number of people who's credit default is unknown: \", df[df['default'] == 'unknown']['default'].count())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Housing Loan*"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of people with Housing loan: \", df[df['housing'] == 'yes']['housing'].count())\nprint(\"Number of people with no Housing loan: \", df[df['housing'] == 'no']['housing'].count())\nprint(\"Number of people who's Housing loan is unknown: \", df[df['housing'] == 'unknown']['housing'].count())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Personal Loan*"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of people with Personal loan: \", df[df['loan'] == 'yes']['loan'].count())\nprint(\"Number of people with no Personal loan: \", df[df['loan'] == 'no']['loan'].count())\nprint(\"Number of people who's Personal loan is unknown: \", df[df['loan'] == 'unknown']['loan'].count())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1.4 Visualisation related to \"Last Contact of the Current Campaign\" "},{"metadata":{},"cell_type":"markdown","source":"<i> Visualisation related to Duration </i>\n\nPlotting duration using boxplot makes it difficult to obtain some important values like average of distribution and so I am plotting histogram on the side to see how its distributed and check for mean value (If its possible). "},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(nrows = 1, ncols = 2, figsize = (15, 5))\n\nsns.boxplot(x = \"duration\", data = df, orient = 'v', ax = ax1)\nax1.set_xlabel(\"Calls\")\nax1.set_ylabel(\"Duration\")\nax1.set_title(\"Call distribution\")\n\nsns.distplot(df['duration'], ax = ax2)\nax2.set_xlabel(\"Call duration\")\nax2.set_ylabel(\"Count\")\nax2.set_title(\"Call Duration vs Count\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Getting all the Mean, Standard Diveation, Minimum and Maximum values for duration  "},{"metadata":{"trusted":true},"cell_type":"code","source":"min_duration = df['duration'].min()\nmax_duration = df['duration'].max()\nmedian_duration = df['duration'].mean()\nstandard_dev_duration = df[\"duration\"].std()\n\nprint(\"Min call duration: \", min_duration)\nprint(\"Max call duration: \", max_duration)\nprint(\"Median call duration: \", round(median_duration, 2))\nprint(\"Standard diveation in call duration: \", round(standard_dev_duration, 2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see from the box plot that most call duration is around the mean so finding the interquartile range will help us in understanding how long the call might last"},{"metadata":{"trusted":true},"cell_type":"code","source":"first_quartile = df['duration'].quantile(q = 0.25)\nsecond_quartile = df['duration'].quantile(q = 0.50)\nthird_quartile = df['duration'].quantile(q = 0.75)\nfourth_quartile = df['duration'].quantile(q = 1)\nIRQ = third_quartile - second_quartile\n\nprint(\"Second Quartile: \", second_quartile)\nprint(\"Third Quartile: \", third_quartile)\nprint(\"Inter quartile range(range within which most data is present): \",IRQ)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" <i> Visualisation related to \"Contact, Month and Day of the week\" </i>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# For contact and Days of the week\nfig, (ax1, ax2) = plt.subplots(nrows = 1, ncols = 2, figsize = (15, 5))\n\nsns.countplot(x = 'contact', data = df, ax = ax1)\nax1.set_xlabel(\"Contact Method\")\nax1.set_ylabel(\"Count\")\nax1.set_title(\"Count of Contact Methods\")\n\nsns.countplot(df['day_of_week'], ax = ax2)\nax2.set_xlabel(\"Days of the week\")\nax2.set_ylabel(\"Count\")\nax2.set_title(\"Count of Calls made on Days of the week\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For Months\nfig, ax = plt.subplots(figsize = (15, 5))\nsns.countplot(x = 'month', data = df, order = ['mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec'])\nax.set_xlabel(\"Months\")\nax.set_ylabel(\"Count\")\nax.set_title(\"Count of contacts made in each month\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Checking if there exists a relation between  Duration of call and Jobs*"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (15, 5))\nsns.boxplot(x = \"job\", y = \"duration\", data = df, orient = 'v')\nax.set_xlabel(\"Jobs\")\nax.set_ylabel(\"Duration\")\nax.set_yscale(\"log\")\nax.set_title(\"log(Duration) vs Jobs\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Checking if there is a relation between average duration of call and eduacation *"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (15, 5))\nsns.boxplot(x = \"education\", y = \"duration\", data = df, orient = 'v')\nax.set_xlabel(\"Education\")\nax.set_ylabel(\"Duration\")\nax.set_yscale(\"log\")\nax.set_title(\"log(Duration) vs Education\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above graph we can observe that the average duration of call is less with illiterates. "},{"metadata":{},"cell_type":"markdown","source":"## 2. Categorical Treatment"},{"metadata":{},"cell_type":"markdown","source":"*Different categorial features and there values in the dataset are:*"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Jobs: \\n\", df[\"job\"].unique(),'\\n')\nprint(\"Marital Status: \\n\", df['marital'].unique(),'\\n')\nprint(\"Education: \\n\", df['education'].unique(),'\\n')\nprint(\"Default on Credit: \\n\", df['default'].unique(),'\\n')\nprint(\"Housing loan: \\n\", df['housing'].unique(),'\\n')\nprint(\"Loan default: \\n\", df['loan'].unique(),'\\n')\nprint(\"Contact type: \\n\", df['contact'].unique(),'\\n')\nprint(\"Months: \\n\", df['month'].unique(),'\\n')\nprint(\"day_of_week: \\n\", df['day_of_week'].unique(),'\\n')\nprint(\"Poutcome: \\n\",df[\"poutcome\"].unique(),'\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Creating label encoders to treat all categorical variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"labelencoder_X = LabelEncoder()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"job\"] = labelencoder_X.fit_transform(df[\"job\"])\ndf[\"marital\"] = labelencoder_X.fit_transform(df[\"marital\"])\ndf[\"education\"] = labelencoder_X.fit_transform(df[\"education\"])\ndf[\"default\"] = labelencoder_X.fit_transform(df[\"default\"])\ndf[\"housing\"] = labelencoder_X.fit_transform(df[\"housing\"])\ndf[\"loan\"] = labelencoder_X.fit_transform(df[\"loan\"])\ndf[\"contact\"] = labelencoder_X.fit_transform(df[\"contact\"])\ndf[\"month\"] = labelencoder_X.fit_transform(df[\"month\"])\ndf[\"day_of_week\"] = labelencoder_X.fit_transform(df[\"day_of_week\"])\ndf[\"poutcome\"] = labelencoder_X.fit_transform(df[\"poutcome\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For dataframes to display all the columns in the output\npd.set_option('max_columns', None)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['y'] = Y","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Undersampling and Feature Engineering"},{"metadata":{},"cell_type":"markdown","source":"##### 3.1 Undersampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['y'] == 1].shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above output we can see that out of 41k odd entries, we have only 4640 positive instances. Out data is imballenced.\n\n#### Dealing with imballenced dataset\n\nWe can see that the data is imballenced so the output of the model will be biased. One way to move forward is:\n1. Undersample the data\n2. Oversample the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# There are three types of undersample that we can use. I will be using version 3 for undersampling\nundersample = NearMiss(version=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preparing the dataframe to be fed into undersample\ndf_x = df.iloc[:,:-1]\ndf_y = df['y']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting out new data\nX, y = undersample.fit_resample(df_x, df_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding output column back to X to perform feature selection\nX['y'] = y\nX.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### 3.2 Feature Selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate correlation matrix heat map to check which feature has greatest influence on the output \nfig, ax = plt.subplots(figsize = (20, 10))\nmatrix = np.triu(X.corr())\nsns.heatmap(df.corr(), annot=True, fmt='.1f', vmin=-1, vmax=1, center= 0, cmap= 'coolwarm', mask=matrix)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Output has a good correlation with duration, pdays, emp.var.rate, euribor3m and nr.employed. Therefore they might form a very good features compared to others.\nWe should also note that emp.var.rate has a high correlation with nr.employed, euribor3m and cons.price.idx. So we might need to consider this while selecting our features."},{"metadata":{},"cell_type":"markdown","source":"##### For Categorical features:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking to see if any categorical variables have direct relationship with y\n\nfor i in [\"job\",\"marital\",\"education\",\"default\",\"housing\",\"loan\",\"contact\",\"month\",\"day_of_week\",\"poutcome\"]:\n    print(\"Results for categorical variable {} is:\\n\".format(i))\n    print(X.groupby(i)['y'].mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above output we cant come to any conclusion but one thing we can observe is that in poutcome, when the value is '2', there is 72.5% positive outcome. "},{"metadata":{},"cell_type":"markdown","source":"##### Lets check categorical plot for categorical features."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate categorical plots for features\nfor col in [\"job\",\"marital\",\"education\",\"default\",\"housing\",\"loan\",\"contact\",\"month\",\"day_of_week\",\"poutcome\"]:\n    sns.catplot(x=col, y='y', data=X, kind='point', aspect=2, )\n    plt.ylim(0, 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above graphs we can see that Housing and loan remains almost constant and dont have much if an effect. So probably we can elemenate them. Lets perform statistical tests to determine that."},{"metadata":{},"cell_type":"markdown","source":"##### Statistical Significane Test"},{"metadata":{"trusted":true},"cell_type":"code","source":"def describe_cont_feature(feature):\n    print('\\n*** Results for {} ***'.format(feature))\n    print(X.groupby('y')[feature].describe())\n    print(ttest(feature))\n    \ndef ttest(feature):\n    survived = X[X['y']==1][feature]\n    not_survived = X[X['y']==0][feature]\n    tstat, pval = stats.ttest_ind(survived, not_survived, equal_var=False)\n    print('t-statistic: {:.1f}, p-value: {:.3}'.format(tstat, pval))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in ['age', 'job', 'marital', 'education', 'default', 'housing', 'loan',\n       'contact', 'month', 'day_of_week', 'duration', 'campaign', 'pdays',\n       'previous', 'poutcome', 'emp.var.rate', 'cons.price.idx',\n       'cons.conf.idx', 'euribor3m', 'nr.employed']:\n    describe_cont_feature(feature)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above output, we can see that age, housing and month have p-value greater than 0.5 therefore we can eleminate them as they fail null hypothesis. "},{"metadata":{},"cell_type":"markdown","source":"## 4. Building Machine Learning Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}