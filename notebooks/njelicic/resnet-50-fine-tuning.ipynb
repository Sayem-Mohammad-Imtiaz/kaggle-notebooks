{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom keras.applications import ResNet50\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import GlobalAveragePooling2D, Dense, Conv2D, Dropout, BatchNormalization\nfrom keras.models import Model \nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom keras import regularizers\nfrom keras import optimizers\nfrom keras import backend as K \n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(len(os.listdir(\"../input/celeba-dataset/img_align_celeba/img_align_celeba\")))\n\n# Any results you write to the current directory are saved as output.\ndf_path = \"../input/celeba-dataset/list_attr_celeba.csv\"\ndf_train = pd.read_csv(df_path)","execution_count":5,"outputs":[{"output_type":"stream","text":"202599\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df_train.rename(columns={'image_id':'filename','Male':'class'})\ndf_train = df_train.replace(1,'Male')\ndf_train = df_train.replace(-1,'Female')\ndf_train.head()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"     filename 5_o_Clock_Shadow  ...  Wearing_Necktie Young\n0  000001.jpg           Female  ...           Female  Male\n1  000002.jpg           Female  ...           Female  Male\n2  000003.jpg           Female  ...           Female  Male\n3  000004.jpg           Female  ...           Female  Male\n4  000005.jpg           Female  ...           Female  Male\n\n[5 rows x 41 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>5_o_Clock_Shadow</th>\n      <th>Arched_Eyebrows</th>\n      <th>Attractive</th>\n      <th>Bags_Under_Eyes</th>\n      <th>Bald</th>\n      <th>Bangs</th>\n      <th>Big_Lips</th>\n      <th>Big_Nose</th>\n      <th>Black_Hair</th>\n      <th>Blond_Hair</th>\n      <th>Blurry</th>\n      <th>Brown_Hair</th>\n      <th>Bushy_Eyebrows</th>\n      <th>Chubby</th>\n      <th>Double_Chin</th>\n      <th>Eyeglasses</th>\n      <th>Goatee</th>\n      <th>Gray_Hair</th>\n      <th>Heavy_Makeup</th>\n      <th>High_Cheekbones</th>\n      <th>class</th>\n      <th>Mouth_Slightly_Open</th>\n      <th>Mustache</th>\n      <th>Narrow_Eyes</th>\n      <th>No_Beard</th>\n      <th>Oval_Face</th>\n      <th>Pale_Skin</th>\n      <th>Pointy_Nose</th>\n      <th>Receding_Hairline</th>\n      <th>Rosy_Cheeks</th>\n      <th>Sideburns</th>\n      <th>Smiling</th>\n      <th>Straight_Hair</th>\n      <th>Wavy_Hair</th>\n      <th>Wearing_Earrings</th>\n      <th>Wearing_Hat</th>\n      <th>Wearing_Lipstick</th>\n      <th>Wearing_Necklace</th>\n      <th>Wearing_Necktie</th>\n      <th>Young</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000001.jpg</td>\n      <td>Female</td>\n      <td>Male</td>\n      <td>Male</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Male</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Male</td>\n      <td>Male</td>\n      <td>Female</td>\n      <td>Male</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Male</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Male</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Male</td>\n      <td>Male</td>\n      <td>Female</td>\n      <td>Male</td>\n      <td>Female</td>\n      <td>Male</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Male</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000002.jpg</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Male</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Male</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Male</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Male</td>\n      <td>Female</td>\n      <td>Male</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Male</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Male</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Male</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000003.jpg</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Male</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Male</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Male</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Male</td>\n      <td>Male</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Male</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Male</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Male</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000004.jpg</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Male</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Male</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Male</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Male</td>\n      <td>Female</td>\n      <td>Male</td>\n      <td>Female</td>\n      <td>Male</td>\n      <td>Male</td>\n      <td>Female</td>\n      <td>Male</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>000005.jpg</td>\n      <td>Female</td>\n      <td>Male</td>\n      <td>Male</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Male</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Male</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Male</td>\n      <td>Male</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Male</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Male</td>\n      <td>Female</td>\n      <td>Female</td>\n      <td>Male</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n        rescale=1./255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=False\n)\n\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    directory ='../input/celeba-dataset/img_align_celeba/img_align_celeba/',\n    dataframe=df_train ,\n    X_col ='filename' ,\n    Y_col = 'class',\n    batch_size=64,\n    class_mode='binary'\n)\n\nstep_train = train_generator.n//train_generator.batch_size","execution_count":7,"outputs":[{"output_type":"stream","text":"Found 202599 images belonging to 2 classes.\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"\n\nK.clear_session()\n\nbase_model = ResNet50(weights=\"../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\",include_top=False)\n\nfor layer in base_model.layers:\n    layer.trainable = True\n\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\npredictions = Dense(1, activation = 'sigmoid',activity_regularizer=regularizers.l1(0.01)) (x)\n\n\n\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n\noptim = optimizers.SGD(lr=0.001)\nmodel.compile(optimizer=optim, loss='binary_crossentropy',metrics=['accuracy'])","execution_count":8,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit_generator(\n    train_generator,\n    steps_per_epoch=step_train,\n    epochs=1,\n)","execution_count":9,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nEpoch 1/1\n3165/3165 [==============================] - 4329s 1s/step - loss: 0.4183 - acc: 0.9252\n","name":"stdout"},{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"<keras.callbacks.History at 0x7fa36efa95f8>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('resnet_face.hdf5')","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir(\"../input\"))","execution_count":12,"outputs":[{"output_type":"stream","text":"['celeba-dataset', 'resnet50']\n","name":"stdout"}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}