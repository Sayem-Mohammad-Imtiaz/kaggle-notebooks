{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This notebook is following my progress through dataset 1 of Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow by Aurelien Geron"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"housing = pd.read_csv(\"/kaggle/input/california-housing-prices/housing.csv\")\nhousing.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.hist(bins = 50, figsize=(20,15))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Creating a Test Set:**\nPick some instances randomly, typically 20% of the dataset and set them aside"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_set, test_set = train_test_split(housing, test_size = 0.2, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create strata to separate incomes - an important attribute to predict housing prices\nhousing['income_cat'] = pd.cut(housing['median_income'],\n                              bins = [0. ,1.5, 3.0, 4.5, 6.0, np.inf],\n                              labels = [1,2,3,4,5])\nhousing['income_cat'].hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\nsplit = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)\nfor train_index, test_index in split.split(housing, housing['income_cat']):\n    strat_train_set = housing.loc[train_index]\n    strat_test_set = housing.loc[test_index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"strat_test_set['income_cat'].value_counts()/len(strat_test_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#remove income_cat\nfor set_ in (strat_train_set,strat_test_set):\n    set_.drop('income_cat', axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Visualing Geographical Data**\nCreating a scatterplot will allow us to use longitute and latitude information from the dataset to visualize distribution of all districts"},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.plot(kind = 'scatter', x = 'longitude', y = 'latitude', alpha = 0.1)\n#result actually resembles california","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot housing prices\n# s - radius of circle, represents districts population\n# c - represents price\nhousing.plot(kind = 'scatter', x = 'longitude', y = 'latitude', alpha = 0.4,\n             s = housing['population']/100, label = 'population', figsize = (10,7),\n             c = 'median_house_value', cmap = plt.get_cmap('jet'), colorbar = True)\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Look for Correlations**\nThe dataset is not too large, so we can compute the Pearson's r fairly easily using corr()"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix = housing.corr()\n#how much does each attribute correlate with the median housing value\ncorr_matrix['median_house_value'].sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Results above show that the median income has the greatest correlation to median house value and it seems longitude and latitude (location) have a negative correlation\n\nCorrelation coefficient only measures linear correlation. "},{"metadata":{},"cell_type":"markdown","source":"**Experimenting with Attribute Combinations**\nTransform attributes to create new ones that are more telling."},{"metadata":{"trusted":true},"cell_type":"code","source":"housing['rooms_per_household'] = housing['total_rooms']/housing['households']\nhousing['bedrooms_per_room'] = housing['total_bedrooms']/housing['total_rooms']\nhousing['population_per_household'] = housing['population']/housing['households']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing = strat_train_set.drop(\"median_house_value\", axis = 1)\nhousing_labels = strat_train_set['median_house_value'].copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Cleaning Data**\nMost machine learning algorithms cannot work with missing features. Our dataset feature *total_bedrooms* has missing features. Options:\n* Get rid of the corresponding districts\n* Get rid of the whole attribute\n* Set the values to some value (zero, median, median, etc)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#replace missing values using SimpleImupter, replace with median\nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(strategy = 'median')\n#median only computed on numerical attributes, copy data without text attribute\nhousing_num = housing.drop('ocean_proximity', axis = 1)\nimputer.fit(housing_num)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#transform training set by replacing missing values with learned medians\nX = imputer.transform(housing_num)\n\n#put back into pandas dataframe\nhousing_tr = pd.DataFrame(X, columns = housing_num.columns, index = housing_num.index)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Handling Text Attributes**"},{"metadata":{"trusted":true},"cell_type":"code","source":"housing_cat = housing[['ocean_proximity']]\n#convert categories from text to numbers\nfrom sklearn.preprocessing import OrdinalEncoder\nordinal_encoder = OrdinalEncoder()\nhousing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#view list of categories\nordinal_encoder.categories_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A potential issue is the ML algorithms will assume that two nearby avlues are more similar than two distant values, which is not always the case. Solution is to create one binary attribute per category. *One-hot encoding*"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\ncat_encoder = OneHotEncoder()\nhousing_cat_1hot = cat_encoder.fit_transform(housing_cat)\nhousing_cat_1hot.toarray()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Feature Scaling**\nML algorithms don't perform well when the input numerical attributes have very different scales, e.g. total number of rooms range from 6 to 39,000 while median income ranges from 0 to 15. Options:\n* Min-Max Scaling\n* Standardization"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\n\nrooms_ix, bedrooms_ix, population_ix, households_ix = 3,4,5,6\n\nclass CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n    def __init__(self, add_bedrooms_per_room = True):\n        self.add_bedrooms_per_room = add_bedrooms_per_room\n    def fit(self,X,y=None):\n        return self\n    def transform(self, X):\n        rooms_per_household = X[:,rooms_ix]/X[:,households_ix]\n        population_per_household = X[:,population_ix]/X[:,households_ix]\n        if self.add_bedrooms_per_room:\n            bedrooms_per_room = X[:,bedrooms_ix]/ X[:,rooms_ix]\n            return np.c_[X, rooms_per_household,population_per_household, bedrooms_per_room]\n        else:\n            return np.c_[X, rooms_per_household, population_per_household]\nattr_adder = CombinedAttributesAdder(add_bedrooms_per_room = False)\nhousing_extra_attribs = attr_adder.transform(housing.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nnum_pipeline = Pipeline([\n            ('imputer', SimpleImputer(strategy='median')),\n            ('attribs_adder', CombinedAttributesAdder()),\n            ('std_scalar', StandardScaler())])\nhousing_num_tr = num_pipeline.fit_transform(housing_num)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}