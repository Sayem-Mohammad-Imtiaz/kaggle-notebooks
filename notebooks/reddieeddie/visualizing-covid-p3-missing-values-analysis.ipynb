{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"cell_type":"markdown","source":"# COVID Data Visualization - Part 3\n[Edward Toth, PhD, University of Sydney]\n\n- e-mail: eddie_toth@hotmail.com\n- Add me on: https://www.linkedin.com/in/edward-toth/ \n- Join the community: https://www.meetup.com/Get-Singapore-Meetup-Group/\n\nUsing different data visualization tools, we attempt to understand the spread of COVID through pretty pictures. In these tutorials you learn more about:\n- the spread of COVID\n- explore the following Python libraries for visualizing data\n\n \n  \n\n__PART 3:__\n - __`missingno`__ (offers a quick visual summary of missing values in data)\n - `wordcloud` to visualize text data\n - `seaborn` for further visualizations \n \n YES THIS IS PART THREE so if you haven't already, check out \n - Part 1 (Active Cases): https://www.kaggle.com/reddieeddie/visualizing-covid-part-1-active-cases\n - Part 2 (Interactive Plots): https://www.kaggle.com/reddieeddie/visualizing-covid-p2-awesome-interactive-plots\n \n\nFor more detail on data visualization libraries: https://mode.com/blog/python-data-visualization-libraries/\n\nIn this tutorial we use: \n\n- Data: https://www.kaggle.com/sudalairajkumar/novel-corona-virus-2019-dataset\n- contains 8 `.csv` files\n- records of confirmed cases, death and recovered patients\n- Description of patients (gender, age, location, etc.)\n\n \n","execution_count":null},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from IPython.display import display\nimport matplotlib.pyplot as plt\nimport pandas as pd\n# !pip install missingno\nimport missingno as mn\npath = '../input/novel-corona-virus-2019-dataset/' \ncovid_data = pd.DataFrame(pd.read_csv(path+'covid_19_data.csv'))\nindiv_list = pd.DataFrame(pd.read_csv(path+'COVID19_line_list_data.csv'))\nopen_list = pd.DataFrame(pd.read_csv(path+'COVID19_open_line_list.csv'))\nconfirmed_US = pd.DataFrame(pd.read_csv(path+'time_series_covid_19_confirmed_US.csv'))\nconfirmed = pd.DataFrame(pd.read_csv(path+'time_series_covid_19_confirmed.csv'))\ndeaths_US = pd.DataFrame(pd.read_csv(path+'time_series_covid_19_deaths_US.csv'))\ndeaths = pd.DataFrame(pd.read_csv(path+'time_series_covid_19_deaths.csv'))\nrecovered = pd.DataFrame(pd.read_csv(path+'time_series_covid_19_recovered.csv'))\n# Check tail for most recent date\ndisplay(covid_data.tail())\n# Define dates for time series\ndates = confirmed.columns[4:]\n# dates[-1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## missingno\n- Check which column varibales are useful\n- `missingno` visualize missing values\n- See if there is a possible relationship between columns with missing values\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt \nimport missingno as mn\nmn.bar(covid_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframes= [confirmed, deaths ,recovered ,  covid_data,indiv_list, open_list]\n# # Lazy way\nnames = ['confirmed', 'deaths' ,'recovered',  'covid_data', 'indiv_list', 'open_list']\nfig, axes = plt.subplots(figsize=(10,10))\nfor num in range(len(dataframes)):#df in dataframes:\n    plt.subplot(3,2,num+1).title.set_text(names[num])\n    #plt.title(dataframes[num])\n    mn.bar(dataframes[num],color='DarkBlue')\nfig.tight_layout()\n ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Interpretation\n- First three plots contain time series where most values are not missing (many date columns)\n- `covid_data` (2 row, 2 col) has half of province/state field missing.\n- Many missing values in different columns of `indiv_list` ('COVID19_line_list_data.csv') and `open_list` ('COVID19_open_line_list.csv'","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get rid of blank columns (all missing entries) in open_list and indiv_list\n# print(\"Proportion of missing values\", open_list.isnull().mean())\n# Extract columns where not all values are missing\ncols = open_list.columns[open_list.isnull().mean() != 1]\nopen_list = open_list[cols] # Get rid of totally missing values in the column\n# Repeat for indiv_list\ncols = indiv_list.columns[indiv_list.isnull().mean() != 1]\nindiv_list = indiv_list[cols]\n\n# Bar shows the proportion/number of non-missing values\nplt.subplot(121)\nplt.gca().set_title('open_list', fontsize=30) \nmn.bar(open_list,color=(0.25, 0.5, 0.25)) # ignore completely missing columns\nplt.subplot(122)\nplt.gca().set_title('indiv_list', fontsize=30) \nmn.bar(indiv_list,color=(0.5, 0.25, 0.25))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n### Interpretation\n`open_list` contains many missing values:\n- many columns have a large proportion of missing values such as age, sex, date of hospital admission. \n- columns with most values include: city, province, country, latitude, longitude, from wuhan or not. \n\n`indiv_list` contains many missing values:\n- some columns have a large proportion of missing values such as symptoms,  exposure start and end dates.\n- columns with most values include: location, country, gender, age, death. \n\n## Matrix plot\nVisualize if there are patterns in data structure for missing values in `indiv_list`:\n- 1 is the earliest time, 1085 is the latest entry \n- At the start of data collection, case_in_country (possible not symptoms) was not recorded\n- There are certain chunks of missing values taht are consistent over variables, symptom_onset to exposure_end. \n- Line plot (on the right) shows the number of non-missing values plotted against row number \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize the missing values in the dataframe\nmn.matrix(indiv_list,color=(0.5, 0.25, 0.25)) # adds more red","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Heatmap\n- Visualize the closeness between column structures based on missing values\n- Ignores columns where all values are filled (link, source, recovered, death, etc.)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# indiv_list contains less variables (columns)\n# heatmap to pick up interesting correlations between missing values\nmn.heatmap(indiv_list)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dendrograms\n- perform hierarchical clustering columns based on their closeness of missing values in similar rows\n- suggests which variable have similar structures of missing values. \n- Note:  one column where the first half of the values are missing is a terrible partner with another column where the second half is missing. \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#dendrogram reports on the closeness of missing values in different variables\nmn.dendrogram(open_list)\nmn.dendrogram(indiv_list) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Interpretation\n\nIn `open_list`, columns with a higher closeness of missing values structure include:\n- (large proportion of filled values from bar plot): geo_resolution, longitude and latitude; country_new and admin_id (not that interesting to look at)\n- (a lot of missing values from bar plot): age and sex, outcome and date of death/discharge, date of onset symptoms and date of hospital admission, travel history dates and location, province and admin1, city and admin2 \n\nIn `indiv_list`, columns with a higher closeness (or correlation) between missing values structure include:\n1. 'reporting date' has a similar structure to link, source, recovered, death, visiting Wuhan, id, location. \n2. 'summary' and 'from Wuhan' have a high closeness (Almost 100% of filled values, correlation of 0.9) \n3. 'gender' and 'age' are usually recorded together (around 80% of values are filled from bar plot,correlation of 0.7)\n\n### We focus on these three items in the subsequent visualizations!\nThe above variables are in the first level of the hierachy (closest in structure). If we look at the second level (less correlated missing value columns) and using the correlation heatmap: \n- hospital visit date may be explored with sympton onset and if onset approximated \n\n__Reminder:__ that the correlation here is based on the patterns of missing entries between columns. It does not equate to a high Pearson's correlation to evaluate the relationship between numeric values. \n\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"display(open_list[['date_confirmation','geo_resolution', 'longitude', 'latitude', 'country_new','admin_id']].head(10))\n# indiv_list['death'].value_counts().head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Even though large proportion of filled values in columns: geo_resolution, longitude and latitude; country_new and admin_id, it's not that interesting to look at. \n\n### 1. 'reporting date' has a similar structure to link, source, recovered, death, visiting Wuhan, id, location. \n- Not too much interesting stuff going on \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"display(indiv_list[['reporting date','link','source','recovered','death','visiting Wuhan', 'id','location']].head(2))\ndisplay(\"Main sources of news mainly include offical government sources with some popular media outlets:\")\nindiv_list['source'].value_counts().head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Other possibilities:\n- examine the variable `visiting Wuhan` with `death` and `recovered` ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sb\n\ndata=indiv_list[['visiting Wuhan','death','recovered']]\n# [el not in ['0','1'] for el in indiv_list['recovered'].values]\n \n \nselect = [el not in ['0','1'] for el in data['recovered'].values]\ndata = data.copy()\ndata.loc[select,'recovered'] = '1'\nselect = [el not in ['0','1'] for el in data['death'].values]\ndata.loc[select,'death'] = '1'\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,5))\nsb.countplot(x='visiting Wuhan', data=data,ax=axes[0], hue='death').set_title('Patients who Visited Wuhan: Deaths')\n#  \nsb.countplot(x='visiting Wuhan', data=data,ax=axes[1], hue='recovered').set_title('Patients who Visited Wuhan: Recovered')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Interpretation\n- From the countplots (left graph), it seems that a small amount of patients who were visiting Wuhan died  \n- On the right countplot, a significant proportion of people visiting Wuhan actually recovered\n- The data here suggest a large proportion of COVID cases are still active (that is not treated as recovered or death)\n\n\n### 2. 'summary' and 'from Wuhan' have a high closeness (Almost 100% of filled values, correlation of 0.9) \n\nIn `indiv_list`, columns with a higher closeness (or correlation) between missing values structure include:\n- 'summary' and 'from Wuhan' have a high correlation of 0.9 (with almost 100% of filled values) \n- separate `summary` text based on whether patient is from Wuhan or not from Wuhan \n- visualize text in a wordcloud and compare word frequencies  ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nimport nltk\ndef word_counts(df):\n    StopWords = ['confirmed','COVID-19','patient','new',\"'new\",'onset','female','male','went']#,\"'new\",\" in \",\"on\",\"to\",\"of\",\"and\",\"went\",\",\",\"from\"]\n    txt = str(df.tolist()).split(' ')\n    text1 = [str(item).replace(\" in \",\"\") for item in txt if str(item) not in StopWords]\n    text = [str(item).replace(\",\",\"\").replace(\"'\",\"\") for item in text1 if str(item) not in STOPWORDS]\n    counts = pd.Series(text).value_counts()\n    wordcloud = WordCloud(background_color=\"white\").generate_from_frequencies(counts)\n    plt.imshow(wordcloud,  interpolation=\"bilinear\")\n    plt.axis(\"off\")\n    return counts\n# Visualize the wordcloud\nfig = plt.figure(figsize=(20,10))\ndf1 = indiv_list['summary'][indiv_list['from Wuhan'] < 1]\nplt.subplot(1,2,1).title.set_text(\"Text Summary for patients, not from Wuhan\")\ntext_notfromWuhan = word_counts(df1)\n#\ndf2 = indiv_list['summary'][indiv_list['from Wuhan'] > 0]\nplt.subplot(1,2,2).title.set_text(\"Text Summary for patients from Wuhan\")\ntext_fromWuhan = word_counts(df2)\n# display(\"Cases not from Wuhan:\", len(df1), text_notfromWuhan.head(20),\"Cases from Wuhan:\", len(df2), text_fromWuhan.head(20))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Interpretation\nThe text `summary` of patients that not from Wuhan contains; \n- more cases of males than females\n- foreign cases like from Japan, South Korea, Hong Kong \n- a smaller proportion of cases mention pneumonia and fever \n\nThe text `summary` of patients from Wuhan mainly contains words such as:\n- Wuhan, resident\n- pneumonia, symptom, hospitalized, death \n- a larger proportion of cases mention pneumonia and fever \n\nIn `indiv_list`, columns with a higher closeness (or correlation) between missing values structure include:\n- 'reporting date' has a similar structure to link, source, summary, recovered, death, visiting Wuhan, country, id, location (Almost 100% of filled values)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 3. 'gender' and 'age' are usually recorded together (around 80% of values are filled from bar plot,correlation of 0.7)\nIn `indiv_list`, columns with a higher closeness (or correlation) between missing values structure include:\n- `gender` and `age` are usually recorded together (around 80% of values are filled from bar plot,correlation of 0.7)\n- examine `gender` and `age` with information about `deaths` and `recovered`\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sb\ndata=indiv_list[['gender','age','death','recovered']]\n# [el not in ['0','1'] for el in indiv_list['recovered'].values]\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,5))\nsb.violinplot(x='gender', y='age', data=data,ax=axes[0]).set_title('Violinplot: Age vs. Gender')\nplt.title('Boxplot: Age vs. Gender')\nsb.boxplot(x='gender', y='age', data=data,ax=axes[1])\n\n# pd.options.mode.chained_assignment = None\ndata=indiv_list[['gender','age','death','recovered']]\nselect = [el not in ['0','1'] for el in data['recovered'].values]\ndata['recovered'][select] = '1'\nselect = [el not in ['0','1'] for el in data['death'].values]\ndata['death'][select] = '1'\n# data.loc[select, 'death'] = 1\n# plot\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,5))\nsb.stripplot(x='gender', y='age', data=data,ax=axes[0], hue='recovered').set_title('Deaths: Age vs. Gender')\nplt.title('Recovered Patients: Age vs. Gender')\nsb.stripplot(x='gender', y='age', data=data,ax=axes[1], hue='death')\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n# Add me! \n\n- e-mail: eddie_toth@hotmail.com\n- Connect with me: https://www.linkedin.com/in/edward-toth/ \n- Join the community: https://www.meetup.com/Get-Singapore-Meetup-Group/","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# The End [Back to Netflix!]","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}