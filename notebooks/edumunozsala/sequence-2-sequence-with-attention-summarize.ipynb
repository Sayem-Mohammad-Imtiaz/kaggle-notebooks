{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Text summarization using machine learning techniques\n\n## A sequence-to-sequence model using an Encoder-Decoder with Attention\n\nThe encoder-decoder model for recurrent neural networks is an architecture for sequence-to-sequence prediction problems. It comprised two parts:\n-\t**Encoder**: The encoder is responsible for stepping through the input time steps, read the input words one by one and encoding the entire sequence into a fixed length vector called a context vector.\n-\t**Decoder**: The decoder is responsible for stepping through the output time steps while reading from the context vector, extracting the words one by one.\nThe trouble with seq2seq is that the only information that the decoder receives from the encoder is the last encoder hidden state which is like a numerical summary of an input sequence. So, for a long input text, we expect the decoder to use just this one vector representation to output a translation. This might lead to catastrophic forgetting.\n\nTo solve this problem, the attention mechanism was developed. **Attention** is proposed as a method to both align and translate. It identifies which parts of the input sequence are relevant to each word in the output (alignment) and use that relevant information to select the right output (translation). So instead of encoding the input sequence into a single fixed context vector (reason for the mentioned bad performance), the attention model develops a context vector that is filtered specifically for each output time step [11]. Attention provides the decoder with information from every encoder hidden state. With this setting, the model can selectively focus on useful parts of the input sequence and hence, learn the alignment between them.\n\nIn the next few sections we will go through the whole process: Load the datasets and vector representation, build the vocabulary, define the encoder, decoder and attention mechanism. Then we will code the train stage, iterating over the datasets, and finally we will make the predictions for the validation dataset to get the value of the metrics of interest.\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Importing the libraries","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n\n#Import libraries for plotting\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.switch_backend('agg')\nimport matplotlib.ticker as ticker\n\n#Import libraries for text processing\n#from nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nimport string\nimport re\n\nstop_words = stopwords.words('english')\n\n#Import some utils\nfrom io import open\nimport unicodedata\nimport random\nimport pickle\n\n#Import the pytorch libraries and modules\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Install and import the library to calculate the evaluations metrics: ROUGE","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install rouge\n#Import library to calculate the evaluation metric\nfrom rouge import Rouge","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Set parameters with the train and validation filenames","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_path = '/kaggle/input/cleaned-news-summary/cl_train_news_summary_more.csv'\nvalid_path = '/kaggle/input/cleaned-news-summary/cl_valid_news_summary_more.csv'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loading the train and validation datasets","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We are reading just a subset of 10,000 rows from the validation datasets to reduce the runnig time.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the csv file\ndata = pd.read_csv(data_path,encoding='utf-8')\n#Drop rows with duplicate values in the text column\ndata.drop_duplicates(subset=[\"text\"],inplace=True)\n#Drop rows with null values in the text variable\ndata.dropna(inplace=True)\ndata.reset_index(drop=True,inplace=True)\n# we are using the text variable as the summary and the ctext as the source text\nprint('Drop null and duplicates, Total rows:', len(data))\n# Rename the columns\ndata.columns = ['summary','text']\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the csv file\nvalid_dataset = pd.read_csv(valid_path,encoding='utf-8', nrows=10000)\n#Drop rows with duplicate values in the text column\nvalid_dataset.drop_duplicates(subset=[\"text\"],inplace=True)\n#Drop rows with null values in the text variable\nvalid_dataset.dropna(inplace=True)\nvalid_dataset.reset_index(drop=True,inplace=True)\n# we are using the text variable as the summary and the ctext as the source text\nprint('Drop null and duplicates, Total rows:', len(valid_dataset))\n# Rename the columns\nvalid_dataset.columns = ['summary','text']\nvalid_dataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cleaning the data\n\nWe create a mapping from common contractions to it expanded form, we will use it later to clean and process the texts.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n\n                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n\n                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n\n                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n\n                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n\n                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n\n                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n\n                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n\n                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n\n                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n\n                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n\n                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n\n                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n\n                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n\n                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n\n                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n\n                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n\n                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n\n                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n\n                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n\n                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n\n                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n\n                           \"you're\": \"you are\", \"you've\": \"you have\"}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Function to preprocess the data (but it could be processed previously)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(text):\n    ''' Function to clean the input text: convert to lowercase, expand the contractions, remove the stopwords,\n        remove punctuations\n    '''\n\n    text = text.lower() # lowercase\n    text = text.split() # convert have'nt -> have not\n    \n    for i in range(len(text)): # For every token or word in the text\n        word = text[i]\n        if word in contraction_mapping:\n            text[i] = contraction_mapping[word] # Expand the contractions\n            \n    text = \" \".join(text) # Rejoin the word to a sentence\n    text = text.split() # Split the text into words\n    newtext = []\n    for word in text: # For every token or word in the text\n        if word not in stop_words:\n            newtext.append(word) #Include only the non stopwords\n    text = \" \".join(newtext)\n    text = text.replace(\"'s\",'') # Expand contractions, convert your's -> your\n    text = re.sub(r'\\(.*\\)','',text) # remove (words)\n    text = re.sub(r'[^a-zA-Z0-9. ]','',text) # remove punctuations\n    text = re.sub(r'\\.',' . ',text)\n    return text\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Apply the cleaning and preprocess function to remove symbols, especial characters, stopwords,.. on the training and validation datasets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['summary'] = data['summary'].apply(lambda x:preprocess(x))\ndata['text'] = data['text'].apply(lambda x:preprocess(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_dataset['summary'] = data['summary'].apply(lambda x:preprocess(x))\nvalid_dataset['text'] = data['text'].apply(lambda x:preprocess(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Show a example of the cleaned text and summary:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['summary'][20]\ndata['text'][20]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, we split our pandas dataframe to two variables, x and y, for training ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x = data['text']\ny = data['summary']\nprint(x[50],y[50],sep='\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Set a global variable to indicate if there is a GPU available for training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Define and create the vocabularies\n\nNow we create a Vocab (vocabulary) Class to store the vocabulary, the mapping between words and its numeric representation and functions to add words and sentences to the vocabulary. There is also some function to transform a sentence to its vector representation and to transform the representation to a Torch tensor.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"SOS_token = 0\nEOS_token = 1\n\n\nclass Vocab:\n    def __init__(self, name):\n        self.name = name\n        self.word2index = {}\n        self.word2count = {}\n        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n        self.n_words = 2  # Count SOS and EOS\n\n    def addSentence(self, sentence):\n        ''' Add every word in a sentence to the vocabulary '''\n        for word in sentence.split(' '):\n            self.addWord(word)\n\n    def addWord(self, word):\n        ''' Add a word to the vocabulary'''\n        if word not in self.word2index:\n            #Include the word in the mapping from word to index\n            self.word2index[word] = self.n_words\n            #Set the count of ocurrencies of the word to 1\n            self.word2count[word] = 1\n            # Include the word in the indexes\n            self.index2word[self.n_words] = word\n            # Increment by 1 the number of words\n            self.n_words += 1\n        else:\n            self.word2count[word] += 1\n            \n    def save_to_file(self, filename):\n        ''' Save the Vocab object to a file'''\n        with open(filename,'wb') as f:\n            pickle.dump(self,f) \n\ndef load_vocab(filename):\n    ''' Load a Vocab instance from a file'''\n    with open(filename,'rb') as f:\n        v = pickle.load(f)\n    return v\n\ndef read_vocabs(text, summary, reverse=False):\n    print(\"Reading lines...\")\n    \n    # Split every line into pairs and normalize\n    pairs = [[text[i],summary[i]] for i in range(len(text))]\n\n    # Reverse pairs, make Lang instances\n    if reverse:\n        pairs = [list(reversed(p)) for p in pairs]\n        input_lang = Vocab(summary)\n        output_lang = Vocab(text)\n    else:\n        input_lang = Vocab(text)\n        output_lang = Vocab(summary)\n\n    return input_lang, output_lang, pairs\n\ndef prepare_data(lang1, lang2, reverse=False):\n    input_lang, output_lang, pairs = read_vocabs(lang1, lang2, reverse)\n    print(\"Read %s sentence pairs\" % len(pairs))\n    print(\"Counting words...\")\n    for pair in pairs:\n        input_lang.addSentence(pair[0])\n        output_lang.addSentence(pair[1])\n    print(\"Counted words:\")\n    print(input_lang.name, input_lang.n_words)\n    print(output_lang.name, output_lang.n_words)\n    return input_lang, output_lang, pairs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we need to build a vocabulary for each dataset, training and validation.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the vocabularies of the inout and output data and return the data in pairs of (source text, summary)\ninput_lang, output_lang, pairs = prepare_data( x, y , False)\nprint(random.choice(pairs))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"An important parameter we need to set is the maximum length of a sequence of text. We find out the max length in the sourfe texts and the summaries and set the max length to that value plus one.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"len_x_tr=[]\nlen_y_tr=[]\n# For every pair Text, summary on the training dataset\nfor i in pairs:\n    len_x_tr.append(len(i[0].split(' '))) # Get the count of words for the soure text\n    len_y_tr.append(len(i[1].split(' '))) # Get the count of words for the summary\n    \n# \nx_test = valid_dataset['text'].values\ny_test = valid_dataset['summary'].values\n\nlen_x_val=[]\nlen_y_val=[]\n# For every pair Text, summary\nfor i in range(len(x_test)):\n    len_x_val.append(len(x_test[i].split(' '))) # Get the count of words for the soure text\n    len_y_val.append(len(y_test[i].split(' '))) # Get the count of words for the summary\n\nprint('Max Length of Texts: ', max(len_x_tr), 'Max Length of Summaries: ',max(len_x_val))\n# Set the global variable MAX LENGTH\nMAX_LENGTH = max(max(len_x_tr), max(len_y_tr), max(len_x_val), max(len_y_val), )+1\nprint(MAX_LENGTH)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create the model\n\nFirst, we define the Encoder component of our Sequence-to-Sequence model. It will be comprised by an embedding layer and a GRU layer (Gate Recurrent Unit).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class EncoderRNN(nn.Module):\n    ''' Define an encoder in a seq2seq architecture'''\n    def __init__(self, input_size, hidden_size):\n        ''' Initialize tyhe encoder instance defining its parameters:\n            Input:\n                - input_size: the size of the vocabulary\n                - hidden:size: size of the hidden layer\n        '''\n        super(EncoderRNN, self).__init__()\n        # Set the hidden size\n        self.hidden_size = hidden_size\n        # Create the embedding layer of size (vocabulary length, hidden_size) \n        self.embedding = nn.Embedding(input_size, hidden_size)\n        # Create a GRU layer\n        self.gru = nn.GRU(hidden_size, hidden_size)\n\n    def forward(self, input, hidden):\n        ''' Run a Forward pass of the encoder to return outputs\n            Input:\n                Input: a tensor element (integer) representing the next word in the sentence\n                hidden: a tensor, the previous hidden state of the encoder\n        '''\n        # Get the embedding of the input\n        embedded = self.embedding(input).view(1, 1, -1)\n        output = embedded\n        \n        # Apply a forward step of the GRU returning the output features and\n        # the hidden state of the actual time step\n        output, hidden = self.gru(output, hidden)\n        \n        return output, hidden\n\n    def initHidden(self):\n        ''' Initialize the hidden state of the encoder, tensor of zeros'''\n        return torch.zeros(1, 1, self.hidden_size, device=device)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, create the decoder with attention component","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class AttnDecoderRNN(nn.Module):\n    ''' Define a decoder with atention in a seq2seq architecture'''\n    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n        ''' Initialize the decoder instance defining its parameters:\n            Input:\n                - hidden_size:size: size of the hidden layer (Hyperparameter)\n                - output_size: the size of the vocabulary of the output summary\n                - dropout_p: dropout probability to apply\n                - max_length: max length (number of words) of an output or summary\n        '''\n\n        super(AttnDecoderRNN, self).__init__()\n        # Set parameters of the decoder\n        self.hidden_size = hidden_size\n        self.output_size = output_size\n        self.dropout_p = dropout_p\n        self.max_length = max_length\n\n        #Create an embedding layer for the input (output vocabulary, hidden size)\n        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n        # Create some linear layers to build the attention mechanism\n        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n        # A dropout layer\n        self.dropout = nn.Dropout(self.dropout_p)\n        # A GRU layer\n        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n        # A Fully-connected layer\n        self.out = nn.Linear(self.hidden_size, self.output_size)\n\n    def forward(self, input, hidden, encoder_outputs):\n        ''' Run a Forward pass of the decoder to return outputs\n            Input:\n                Input: a tensor element (integer) representing the previous output of the decoder\n                hidden: a tensor, the previous hidden state of the decoder\n                Encoder outputs: a tensor, outputs of the encoder\n        '''\n        \n        #Get the embedding representation of the input\n        embedded = self.embedding(input).view(1, 1, -1)\n        # Apply dropout \n        embedded = self.dropout(embedded)\n        #Calculate the attention weights of the attention mechanism using the encoder states\n        #in previous time steps\n        attn_weights = F.softmax(\n            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n        \n        #Calculate the context vectors fo the attention mechanism using the attention weights\n        # and the encoder outputs\n        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n                                 encoder_outputs.unsqueeze(0))\n        output = torch.cat((embedded[0], attn_applied[0]), 1)\n        output = self.attn_combine(output).unsqueeze(0)\n        output = F.relu(output)\n        \n        # Apply a forward pass to the GRU layer of the decider using the output from the attention\n        # as input and the hidden state\n        output, hidden = self.gru(output, hidden)\n        output = F.log_softmax(self.out(output[0]), dim=1)\n        # return the output features, the hidden state and the attention weights\n        return output, hidden, attn_weights\n\n    def initHidden(self):\n        ''' Initialize the hidden state of the encoder, tensor of zeros'''\n        return torch.zeros(1, 1, self.hidden_size, device=device)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define the steps of the training process\n\nFirst, we create functions to help us to handle and transform the text input data to tensor datatype requiered to train","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def indexesFromSentence(lang, sentence):\n    ''' Transform a sentence in string format to a list of indexes or integers.\n            The model need to be feeded with numbers, not characters\n            Input:\n                - sentence: a string\n            Output:\n                - a list of integers, the representation of the sentence in the vector space.\n    '''\n    return [lang.word2index[word] for word in sentence.split(' ')]\n\n\ndef tensorFromSentence(lang, sentence):\n    ''' Transform a sentence in string format to tensor of indexes or integers.\n            Out pytorch model work with tensor objects\n            Input:\n                - sentence: a string\n            Output:\n                - a tensor of integers, the representation of the sentence in the vector space.\n    '''\n    indexes = indexesFromSentence(lang, sentence)\n    indexes.append(EOS_token)\n    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n\n\ndef tensorsFromPair(pair):\n    ''' Convert a pair of text data (source text, summary) to tensors\n        Input:\n        - pair: tuple of strings, the source text and its summary\n        Output:\n        - tuple of tensors, the input tensor and the outout one\n    '''\n    # Convert the source text to the input tensor\n    input_tensor = tensorFromSentence(input_lang, pair[0])\n    # Convert the summary to the output tensor\n    target_tensor = tensorFromSentence(output_lang, pair[1])\n    return (input_tensor, target_tensor)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will apply Teacher forcing, a method for quickly and efficiently training recurrent neural network models that use the ground truth from a prior time step as input, that is, using the actual or expected output from the training dataset at the current time step y(t) as input in the next time step X(t+1), rather than the output generated by the network \n\nFirst we define the probability of applying teacher forcing.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"teacher_forcing_ratio = 0.5","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This function execute a training step where we provide an input and target tensor and apply the algorithm on it. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n    ''' Run all the steps in the training phase of a batch of examples\n        Input:\n        - input_tensor: a tensor, vector representation of the input text\n        - target_tensor: a tensor, vector representation of the expect or labelled output or summary\n        - encoder: a Class Encoder object, the encoder\n        - decoder: a Class AttnDecoder object, the decoder\n        - encoder_optimizer: a torch optimizer, the optimizer of the encoder\n        - decoer_optimizer: a torch optimizer, the optimizer of the decoder\n        - criterion: a pytoch loss function\n        - max_length: an integer, maximun length of an output\n    '''\n    #Init the encoder hidden state\n    encoder_hidden = encoder.initHidden()\n    \n    # Reset the optimizer\n    encoder_optimizer.zero_grad()\n    decoder_optimizer.zero_grad()\n    # Set the length if the source text and the summary\n    input_length = input_tensor.size(0)\n    target_length = target_tensor.size(0)\n    # Create the initial encoder output, all zeros\n    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n\n    loss = 0\n    # For every token in the source text or inout\n    for ei in range(input_length):\n        # Forward pass of the encoder to get the encoder output and hidden state\n        encoder_output, encoder_hidden = encoder(\n            input_tensor[ei], encoder_hidden)\n        encoder_outputs[ei] = encoder_output[0, 0]\n        \n    # Set the initial decoder input as the SOS token\n    decoder_input = torch.tensor([[SOS_token]], device=device)\n    #Set the initial decoder hidden state equals to the last encoder hidden state\n    decoder_hidden = encoder_hidden\n\n    # Active teacher forcing with probability teacher_forcing_ratio \n    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n    if use_teacher_forcing:\n        # Teacher forcing: Feed the target as the next input\n        for di in range(target_length):\n            # Forward pass of the decoder returning the decoder output, hidden state and context vector\n            # of the attention mechanism\n            decoder_output, decoder_hidden, decoder_attention = decoder(\n                decoder_input, decoder_hidden, encoder_outputs)\n            # Increment the loss function by the loss of the decoder output in the actual time step\n            loss += criterion(decoder_output, target_tensor[di])\n            decoder_input = target_tensor[di]  # Teacher forcing\n\n    else:\n        # Without teacher forcing: use its own predictions as the next input\n        for di in range(target_length):\n            # Forward pass of the decoder returning the decoder output, hidden state and context vector\n            # of the attention mechanism\n            decoder_output, decoder_hidden, decoder_attention = decoder(\n                decoder_input, decoder_hidden, encoder_outputs)\n             # Select the decoder output with the highest probability\n            topv, topi = decoder_output.topk(1)\n            decoder_input = topi.squeeze().detach()  # detach from history as input\n            # Increment the loss function by the loss of the decoder output in the actual time step\n            loss += criterion(decoder_output, target_tensor[di])\n            # Stop training if the EOS token is returned\n            if decoder_input.item() == EOS_token:\n                break\n   # Apply the backward pass to calculate and propagate the loss\n    loss.backward()\n    # Apply a step of the optimizers\n    encoder_optimizer.step()\n    decoder_optimizer.step()\n    \n    # Return the final loss\n    return loss.item() / target_length","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some helpers function to show the progress and losses during training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nimport math\n\n\ndef asMinutes(s):\n    ''' Return the seconds, s, to a string in the format: Xm Ys'''\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\ndef timeSince(since, percent):\n    ''' Return '''\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n\ndef showPlot(points):\n    ''' Plot the points in a line graph to show a training metric'''\n    plt.figure()\n    fig, ax = plt.subplots()\n    # this locator puts ticks at regular intervals\n    loc = ticker.MultipleLocator(base=0.2)\n    ax.yaxis.set_major_locator(loc)\n    plt.plot(points)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The next function describes the training process, iterating over the number of epochs","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n    ''' Train a encoder-decoder model on the input x for n_iters iterations\n        Input:\n        - encoder: a Class Encoder object, the encoder\n        - decoder: a Class AttnDecoder object, the decoder\n        - x: array of strings, source texts of the training dataset\n        - y: array of strings, target texts or summaries of the training dataset\n        - vocab_input: a Vocab Class object, vocabulary of the source texts\n        - vocab_output: a Vocab Class object, vocabulary of the target texts\n        - n_iters: integer, number of iterations\n        - print_every: integer, print the progress every print_every iteration\n        - plot_every: integer, plot the losses every plot_every iteration\n        - learning_rate: float, learning rate\n    '''\n\n    print(\"Training....\")\n    # Get the current time\n    start = time.time()\n    # Initialize variables for progress tracking\n    plot_losses = []\n    print_loss_total = 0  # Reset every print_every\n    plot_loss_total = 0  # Reset every plot_every\n    # Create the optimizer for the encoder and the decoder\n    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n    # Extract the training set randomly for all the iterations\n    training_pairs = [tensorsFromPair(random.choice(pairs))\n                      for i in range(n_iters)]\n    # Set the function loss to apply\n    criterion = nn.NLLLoss()\n\n    for iter in range(1, n_iters + 1):\n        if iter% 1000 == 0:\n            print(iter,\"/\",n_iters + 1) # Plot progress\n            \n        # Get the next pair of source text and target to train on\n        training_pair = training_pairs[iter - 1]\n        input_tensor = training_pair[0]\n        target_tensor = training_pair[1]\n        # Train on the pair of data selected\n        loss = train(input_tensor, target_tensor, encoder,\n                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n        # Set the variable to plot the progress\n        print_loss_total += loss\n        plot_loss_total += loss\n\n        if iter % print_every == 0:\n            # Print the ETA and current loss\n            print_loss_avg = print_loss_total / print_every\n            print_loss_total = 0\n            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n                                         iter, iter / n_iters * 100, print_loss_avg))\n\n        if iter % plot_every == 0:\n            # Plot the current loss\n            plot_loss_avg = plot_loss_total / plot_every\n            plot_losses.append(plot_loss_avg)\n            plot_loss_total = 0\n\n    showPlot(plot_losses)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Evaluate or predict function","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(encoder, decoder, sentence, input_lang, output_lang, max_length=MAX_LENGTH):\n    ''' Function to predict the summary of the source text sentence with a max length\n        Input:\n        - encoder: a Class Encoder object, the encoder\n        - decoder: a Class AttnDecoder object, the decoder\n        - vocab_input: a Vocab Class object, vocabulary of the source texts\n        - vocab_output: a Vocab Class object, vocabulary of the target texts\n        - sentence: string, source text to predict\n\n    '''\n    with torch.no_grad():\n        # Get the tensor of the source text\n        input_tensor = tensorFromSentence(input_lang, sentence)\n        # Calculate the length of the source text\n        input_length = input_tensor.size()[0]\n        # Set the initial hidden state of the encoder\n        encoder_hidden = encoder.initHidden()\n        # Set the initial encoder outputs\n        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n        # For every word in the input\n        for ei in range(input_length):\n            # Forward pass of the encoder\n            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n                                                     encoder_hidden)\n            encoder_outputs[ei] += encoder_output[0, 0]\n        # Set the initial input of the decoder \n        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n        # Set the initial hidden state of the decoder to the hidden state of the decoder in the last time step\n        decoder_hidden = encoder_hidden\n\n        decoded_words = []\n        # Set the initial context vectors of the decoder to zeros\n        decoder_attentions = torch.zeros(max_length, max_length)\n        # For every word or step in the output sequence\n        for di in range(max_length):\n            # Forward pass of the decoder\n            decoder_output, decoder_hidden, decoder_attention = decoder(\n                decoder_input, decoder_hidden, encoder_outputs)\n            # Save the decoder attention vector of the step\n            decoder_attentions[di] = decoder_attention.data\n            # Get the element in the decoder output with the highest probability (the best output)\n            topv, topi = decoder_output.data.topk(1)\n            # If the token returned is EOS then finish\n            if topi.item() == EOS_token:\n                decoded_words.append('<EOS>')\n                break\n            else:\n                # Append the token in the summary returned by the decoder\n                decoded_words.append(output_lang.index2word[topi.item()])\n            # Set the decoder input to the output selected\n            decoder_input = topi.squeeze().detach()\n\n        return decoded_words, decoder_attentions[:di + 1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The next function will generate the predictions for a set of source texts to be evaluated","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_predictions(x_test, encoder, decoder, input_vocab, output_vocab, max_length, print_every=20):\n    ''' Generate the predicted summaries of the source texts on x_test\n        Input:\n        - x_test: list of strings, the source texts\n        - encoder: a Class Encoder object, the encoder\n        - decoder: a Class AttnDecoder object, the decoder\n        - input_vocab: a Vocab Class object, vocabulary of the source texts\n        - output_vocab: a Vocab Class object, vocabulary of the target texts\n        - max_length: integer, max length of the output summary\n        - print_every: integer, print progress every print_every iterations\n    '''\n    predicted_summaries = []\n    # Set a progress bar\n    #kbar = pkbar.Kbar(target=len(x_test), width=8)\n    # Para cada text or document in the validation dataset\n    for i,doc in enumerate(x_test):\n        # Predict the summary for the document\n        #pred_summ = predict(doc,vocab,params,batch_size=1)\n        pred_summ,_ = predict(encoder, decoder, doc, input_vocab, output_vocab, max_length)\n        predicted_summaries.append(' '.join(pred_summ[:-1]))\n        #predicted_summaries.append(' '.join(pred_summ))\n        \n        #if i%print_every==0:\n        #    kbar.update(i)\n            \n    # Set teh labeled summaries as the y_test variable, column summary of our dataset\n    return predicted_summaries\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluateRandomly(encoder, decoder, n=10):\n    for i in range(n):\n        pair = random.choice(pairs)\n        print('>', pair[0])\n        print('=', pair[1])\n        output_words, attentions = predict(encoder, decoder, pair[0])\n        output_sentence = ' '.join(output_words)\n        print('<', output_sentence)\n        print('')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training the model\n\nIt is time to train our model, setting the hidden size in 100, the iterations in 150000","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"hidden_size = 100\nencoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\nattn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.2).to(device)\n\ntrainIters(encoder1, attn_decoder1, 75000, print_every=5000)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Once the model is trained we will save it, we can use it in the future to make predictions. We need to save the encoder, the decoder and the input and output vocabularies.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(encoder1.state_dict(), './enc.w')\ntorch.save(attn_decoder1.state_dict(), './att.w')\n# Save the vocabularies\ninput_lang.save_to_file('input_vocab.pkl')\noutput_lang.save_to_file('output_vocab.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load the vocabularies, \n#input_vocab= load_vocab('input_vocab.pkl')\n#output_vocab= load_vocab('output_vocab.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Uncomment and execute if you want to show some results quickly\n#evaluateRandomly(encoder1, attn_decoder1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Evaluate the model\n\nWe predict the summary for every text in our validation dataset and then we can compare them to the targeted summary. We also calculate the Rouge metrics and visualize the results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test = valid_dataset['text'].values\ny_test = valid_dataset['summary'].values\n# Generate the predctions on the validation dataset\npredicted_summaries = generate_predictions(x_test, encoder1, attn_decoder1, input_lang, output_lang, MAX_LENGTH, 100)\n# Set teh labeled summaries as the y_test variable, column summary of our dataset\nlabeled_summaries = y_test\n#print(len(x_test), len(labeled_summaries), len(predicted_summaries))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Show some results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('\\n Pred: ',predicted_summaries[100],'\\n Target: ', labeled_summaries[100])\nprint('\\n Pred: ',predicted_summaries[200],'\\n Target: ', labeled_summaries[200])\nprint('\\n Pred: ',predicted_summaries[300],'\\n Target: ', labeled_summaries[300])\nprint('\\n Pred: ',predicted_summaries[400],'\\n Target: ', labeled_summaries[400])\nprint('\\n Pred: ',predicted_summaries[500],'\\n Target: ', labeled_summaries[500])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets evaluate with the ROUGE metric","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_textfile(filename, strings):\n    ''' Save the contect of a list of strings to a file called filename\n    \n        Input:\n           - filename: name of the file to save the strings\n           - strings: a list of string to save to disk\n    '''\n    \n    with open(filename, 'w') as f:\n        for item in strings:\n            #Remove any \\n in the string\n            item = remove_CTL(item)\n            f.write(\"%s\\n\" % item)\n\ndef eval_metrics(preds, targets, avg=True):\n    ''' Evaluate the ROUGE metrics ROUGE-2 and ROUGE-L for every pair predicted summary - target summary\n    \n        Input:\n           - preds: list of strings, predicted summaries\n           - targets: list of string, target summaries\n        Output:\n            - rouge2_f_metric: list of float, the Rouge-2 fscore for every predicted summary\n            - rougel_f_metric: list of float, the Rouge-L fscore for every predicted summary\n    '''\n    #Lets calculate the rouge metrics for every document\n    rouge = Rouge()\n    scores = rouge.get_scores(preds, targets, avg)\n    # Create the output variables\n    if avg:\n        rouge2_f_metric = scores['rouge-2']['f']\n        rouge2_p_metric = scores['rouge-2']['p']\n        rouge2_r_metric = scores['rouge-2']['r']\n        rougel_f_metric = scores['rouge-l']['f']\n        rougel_p_metric = scores['rouge-l']['p']\n        rougel_r_metric = scores['rouge-l']['r']\n    else:\n        rouge2_f_metric = [score['rouge-2']['f'] for score in scores]\n        rouge2_p_metric = [score['rouge-2']['p'] for score in scores]\n        rouge2_r_metric = [score['rouge-2']['r'] for score in scores]\n        rougel_f_metric = [score['rouge-l']['f'] for score in scores]\n        rougel_p_metric = [score['rouge-l']['p'] for score in scores]\n        rougel_r_metric = [score['rouge-l']['r'] for score in scores]\n\n       \n    \n    return rouge2_f_metric, rouge2_p_metric, rouge2_r_metric, rougel_f_metric, rougel_p_metric, rougel_r_metric","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we can calculate the Rouge-2 and Rouge-L metrics for the validation dataset ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate the Rouge-2 and Rouge-L metrics for the validation dataset\nr2_f, r2_p, r2_r, rl_f, rl_p, rl_r = eval_metrics(predicted_summaries, list(labeled_summaries), False)\nprint('Mean Rouge-2 FScore: ',np.mean(r2_f), 'Mean Rouge-L FScore: ',np.mean(rl_f))\n#Store the results on the dataframe\nvalid_dataset['pred_summary'] = predicted_summaries\nvalid_dataset['rouge2-f'] = r2_f\nvalid_dataset['rouge2-p'] = r2_p\nvalid_dataset['rouge2-r'] = r2_r\nvalid_dataset['rougel-f'] = rl_f\nvalid_dataset['rougel-p'] = rl_p\nvalid_dataset['rougel-r'] = rl_r","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_dataset.to_csv('results.csv', index=False)\nvalid_dataset.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualizing the results\n\nWe are going to plotting the distribution of the Rouge-2 and Rouge-L values in the training and validation datasets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot\nkwargs = dict(hist_kws={'alpha':.7}, kde_kws={'linewidth':2})\n# plot\nfig, axes = plt.subplots(1, 2, figsize=(10, 5), sharey=False, dpi=100)\nsns.distplot(valid_dataset['rouge2-f'] , color=\"dodgerblue\", ax=axes[0], axlabel='Rouge-2 Fscore')\nsns.distplot(valid_dataset['rougel-f'], color=\"deeppink\", ax=axes[1], axlabel='Rouge-L Fscore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}