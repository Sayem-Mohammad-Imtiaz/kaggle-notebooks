{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Pima people - Wikipedia\n\nThe Pima are a group of Native Americans living in an area consisting of what is now central and southern Arizona, as well as northwestern Mexico in the states of Sonora and Chihuahua.\n\nhttps://en.wikipedia.org/wiki/Pima_people"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/pima-indians-diabetes-database/diabetes.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* There are no missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* All of the available variables are numeric variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The target or the dependent variable here is **Outcome** which is binary i.e., 0 for the people who don't have diabetes and 1 for them who have diabetes.\n* Looking at the summarized view of all the features, we can see that the maximum values of some features are significantly higher compared to the median and also there is significant difference between the median and mean for the feature. This indicates the presence of outliers. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(df[\"Pregnancies\"], bins=50)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df[\"Pregnancies\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df[\"Pregnancies\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Pregnancies** column has a long tail on the right side i.e., right-skewed.\n* There are few rare cases present in the dataset where **Pregnancies** have been reported more than 10 times. We might need to look into more details for these outliers and how to treat them for generalization."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x=\"Pregnancies\", y=\"Outcome\", data=df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df[\"Pregnancies\"], hue=df[\"Outcome\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* While we see that Diabetes has been reported at all levels for the number of Pregnancies,  the number of Diabetes reported seems to be increasing when the number of Pregnancies is more than 6."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df[\"Glucose\"], bins=25)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### After going through some study on glucose levels - \n\n* Normal: < 110 mg/dL\n* Pre-diabetes: 110–125 mg/dL\n* Diabetes: ≥ 126 mg/dL\n\n* Also it is important to be noted that if the glucose level in the body reduces below 60mg/dl, the human can go unconscious. This state is called diabetic coma. Meaning coma caused by too less glucose level. This condition is considered to be serious."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(data=df, y=\"Glucose\", x=\"Outcome\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Looking at the above box-plot we do get the confirmation that the Pre-diabetes levels have been marked as 0.\n* Again there are cases of outliers clealy visible here which would need to be dealt with before creating ML model\n* There is small yet significant overlap the Glucose levels as for the Outcomes as 0 and 1."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df[\"BloodPressure\"], bins=25)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The normal Blood Pressure level is between 60-80\n* There are outliers on the lower sides"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(data=df, y=\"BloodPressure\", x=\"Outcome\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The cases of Diabetes have slightly higher blood pressure than those who don't have diabetes."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df[\"SkinThickness\"], bins=25)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(data=df, y=\"SkinThickness\", x=\"Outcome\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* A lot of the cases have a Skin Thickness as 0 and there are cases as well where it has been reported with higher values \n* Comparing Outcome and Skin Thickness, it seems the diabetes cases have a slightly higher skin thickness"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df[\"Insulin\"], bins=25)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(data=df, y=\"Insulin\", x=\"Outcome\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* As expected the cases which don't have diabetes, they have higher insulin present.\n* There are yet a lot cases where even though a high level of insulin is present yet have diabetes. This needs to be investigated further."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df[\"BMI\"], bins=25)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(data=df, y=\"BMI\", x=\"Outcome\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Majority of the data is centered with the BMI around 30-35 with few outliers in both the sides\n* The diabetes cases have slightly higher BMI"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df[\"DiabetesPedigreeFunction\"], bins=25)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(data=df, y=\"DiabetesPedigreeFunction\", x=\"Outcome\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df[\"Age\"], bins=25)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(data=df, y=\"Age\", x=\"Outcome\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* It is the elder people who have majorly been reported with diabetes"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.plotting.scatter_matrix(df, figsize=(15,15))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df[(df[\"Pregnancies\"]<=10) & (df[\"Glucose\"]>=60) & (df[\"BloodPressure\"]>=40) & (df[\"BloodPressure\"]<=120) &\n         (df[\"SkinThickness\"]<=60) & (df[\"Insulin\"]<=400) & (df[\"BMI\"]>=15) & (df[\"BMI\"]<=50)]\ndf1.shape, df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\nsns.heatmap(df1.corr(), annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_feats = [\"Pregnancies\",\"Glucose\",\"BMI\",\"Age\",\"Outcome\"]\n\ndf2 = df1[best_feats]\ndf2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.plotting.scatter_matrix(df2, figsize=(15,15))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df3 = df2.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df3[\"Age\"] = np.log(df3[\"Age\"])\ndf3[\"Pregnancies\"] = np.log(df3[\"Pregnancies\"]+1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df3.drop(\"Outcome\", axis=1).copy()\ny = df3[\"Outcome\"].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\nX.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df3[\"Outcome\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlog_reg = LogisticRegression()\nlog_reg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = log_reg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\nconfusion_matrix(y_test, pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score\n\nprecision_score(y_test, pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"recall_score(y_test, pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\n\nf1_score(y_test, pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\n\nroc_auc_score(y_test, pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\nsvm_clf = SVC()\nsvm_clf.fit(X_train,y_train)\npred = svm_clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test, pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Precision Score:\", precision_score(y_test, pred))\nprint(\"Recall Score:\", recall_score(y_test, pred))\nprint(\"F1 Score:\", f1_score(y_test, pred))\nprint(\"ROC AUC Score\", roc_auc_score(y_test, pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nknn_clf = KNeighborsClassifier()\nknn_clf.fit(X_train,y_train)\npred = knn_clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test, pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Precision Score:\", precision_score(y_test, pred))\nprint(\"Recall Score:\", recall_score(y_test, pred))\nprint(\"F1 Score:\", f1_score(y_test, pred))\nprint(\"ROC AUC Score\", roc_auc_score(y_test, pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Stratified Sampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\n\nsss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n\nfor train_index, test_index in sss.split(df3, df3[\"Outcome\"]):\n    train_set = df3.iloc[train_index]\n    test_set = df3.iloc[test_index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set[\"Outcome\"].mean(),test_set[\"Outcome\"].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train1 = train_set.drop(\"Outcome\", axis=1).copy()\nX_test1 = test_set.drop(\"Outcome\", axis=1).copy()\n\ny_train1 = train_set[\"Outcome\"].copy()\ny_test1 = test_set[\"Outcome\"].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nX_train1 = pd.DataFrame(scaler.fit_transform(X_train1), columns=X_train1.columns)\nX_train1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test1 = pd.DataFrame(scaler.fit_transform(X_test1), columns=X_test1.columns)\nX_test1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_reg1 = LogisticRegression()\nlog_reg1.fit(X_train1, y_train1)\npred1 = log_reg1.predict(X_test1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test1, pred1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Precision Score:\", precision_score(y_test1, pred1))\nprint(\"Recall Score:\", recall_score(y_test1, pred1))\nprint(\"F1 Score:\", f1_score(y_test1, pred1))\nprint(\"ROC AUC Score\", roc_auc_score(y_test1, pred1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svm_clf1 = SVC()\nsvm_clf1.fit(X_train1,y_train1)\npred1 = svm_clf1.predict(X_test1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test1, pred1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Precision Score:\", precision_score(y_test1, pred1))\nprint(\"Recall Score:\", recall_score(y_test1, pred1))\nprint(\"F1 Score:\", f1_score(y_test1, pred1))\nprint(\"ROC AUC Score\", roc_auc_score(y_test1, pred1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_clf1 = KNeighborsClassifier()\nknn_clf1.fit(X_train1,y_train1)\npred1 = knn_clf1.predict(X_test1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test1, pred1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Precision Score:\", precision_score(y_test1, pred1))\nprint(\"Recall Score:\", recall_score(y_test1, pred1))\nprint(\"F1 Score:\", f1_score(y_test1, pred1))\nprint(\"ROC AUC Score\", roc_auc_score(y_test1, pred1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### With Stratified Shuffle split, the performance of Logistic Regression improved significantly"},{"metadata":{},"cell_type":"markdown","source":"## Tree Based Algorithms"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df3.drop(\"Outcome\", axis=1).copy()\ny = df3[\"Outcome\"].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n\nfor train_index, test_index in sss.split(df3, df3[\"Outcome\"]):\n    train_set = df3.iloc[train_index]\n    test_set = df3.iloc[test_index]\n\nX_train2 = train_set.drop(\"Outcome\", axis=1).copy()\nX_test2 = test_set.drop(\"Outcome\", axis=1).copy()\n\ny_train2 = train_set[\"Outcome\"].copy()\ny_test2 = test_set[\"Outcome\"].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrf_clf = RandomForestClassifier()\nrf_clf.fit(X_train2, y_train2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred2 = rf_clf.predict(X_test2)\n\nconfusion_matrix(y_test2, pred2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Precision Score:\", precision_score(y_test2, pred2))\nprint(\"Recall Score:\", recall_score(y_test2, pred2))\nprint(\"F1 Score:\", f1_score(y_test2, pred2))\nprint(\"ROC AUC Score\", roc_auc_score(y_test2, pred2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\n\nlog_clf = LogisticRegression()\nrnd_clf = RandomForestClassifier()\nsvm_clf = SVC()\n\nvoting_clf = VotingClassifier(estimators=[('lr', log_clf),('rf', rnd_clf), ('svc', svm_clf)],voting='hard')\n\nvoting_clf.fit(X_train2, y_train2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\nfor clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n    clf.fit(X_train2, y_train2)\n    y_pred = clf.predict(X_test2)\n    print(clf.__class__.__name__, accuracy_score(y_test2, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_clf.fit(X_train2, y_train2)\npred3 = log_clf.predict(X_test2)\nconfusion_matrix(y_test2, pred3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Precision Score:\", precision_score(y_test2, pred3))\nprint(\"Recall Score:\", recall_score(y_test2, pred3))\nprint(\"F1 Score:\", f1_score(y_test2, pred3))\nprint(\"ROC AUC Score\", roc_auc_score(y_test2, pred3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred4 = voting_clf.predict(X_test2)\nconfusion_matrix(y_test2, pred4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Precision Score:\", precision_score(y_test2, pred4))\nprint(\"Recall Score:\", recall_score(y_test2, pred4))\nprint(\"F1 Score:\", f1_score(y_test2, pred4))\nprint(\"ROC AUC Score\", roc_auc_score(y_test2, pred4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion\n\n* We started with importing the dataset and exploring it to understand the data more closely.\n* As there were some outliers in the dataset, we decided to remove them for a creating a more generic model.\n* Because the data was a slight imbalanced, we tried with both Random Sampling and Stratified Sampling.\n* Models created - Logistic Regression, K-Nearest Neighbors, SVC, Random Forest and we also tried a custom ensemble model. Of all these models, we observed that it was Logistic Regression which performed the best."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}