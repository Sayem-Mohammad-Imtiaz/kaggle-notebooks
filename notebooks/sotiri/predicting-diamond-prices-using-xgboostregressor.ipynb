{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nimport xgboost as xgb\nfrom category_encoders.ordinal import OrdinalEncoder\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV\nfrom sklearn_pandas import DataFrameMapper\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ede6b88a1b7b4af078f967cccbee2ba2f91fa873"},"cell_type":"code","source":"#Get data:\nfile_path = '../input/diamonds.csv'\n\ndf = pd.read_csv(file_path,index_col =0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ee72662daab9eb78bb082a910c68eb8c365a320"},"cell_type":"code","source":"# Check for completness of dataset: No null entires!\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f80330faa4ed406dbadc2484496fe85e14ad200e"},"cell_type":"code","source":"# Print .head() to get a flavour of the dataset:\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7fe0c342784456c50499c68572e7faded61e7a5d"},"cell_type":"code","source":"# Count the types of cut: Ideal and premium cuts are most popular\nsns.countplot(df.cut)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ae5a9fc37a9061d1aa7a26fc9c507ee4ca1b35c2"},"cell_type":"code","source":"# In order to do any feature engineering before building the model\n# Its usually a good idea to see which attributes strongly correlated with Price\n# Correlation:\ndf_numeric = df.select_dtypes(exclude=['object'])\ndf_corr = df_numeric.corr()\nplt.figure(figsize=(10,10))\n#Heatmap:\nsns.set(font_scale=1.5)\nsns.heatmap(df_corr,center=0,cmap='YlGnBu',square=True, annot=True)\n\n#Carat is correlated the most, although x,y,z are not far behind.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3219b352698cc4fce5e86bbeb9521f2404413fdc"},"cell_type":"code","source":"sns.pairplot(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c6b9c73cd6c8db52682aef581aeb7abe0afddd33"},"cell_type":"code","source":"# Note: We want to maybe create new features such as ratio of carat to length\n# Ratio of length to width\n# See if any of the above also correlate with price\n# But before we can do that you may notice x,y,z suffer from zero values\n# We don't want to divide by zero!\nsns.jointplot(x='carat',y='price',data=df)\nsns.jointplot(x='x',y='price',data=df)\nsns.jointplot(x='x',y='y',data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59f566298a3f18b1d88160fae1cc30d1dbeb4d28"},"cell_type":"code","source":"# We have value where length=0,width=0,depth=0. Remove this before feature engineering otherwise we divide by 0 and get inf:\nprint((df.x == 0).any())\nprint((df.y == 0).any())\nprint((df.z == 0).any())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"58961dbb82d1965cc23940ec282fa21141fcfa81"},"cell_type":"code","source":"#Delete each row with this condition:\ndf = df[df['x']!= 0]\ndf = df[df['y']!= 0]\ndf = df[df['z']!= 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b368f823b4fb933bc1b784579ca662afa62d4a9"},"cell_type":"code","source":"# Feature engineering: Length to width ratio, carat/x,carat,y,carat/z\ndf = df.assign(length_width_ratio = round(df.x/df.y,2))\ndf = df.assign(carat_length_ratio = round(df.carat/df.x,2))\ndf = df.assign(carat_width_ratio = round(df.carat/df.y,2))\ndf = df.assign(carat_depth_ratio = round(df.carat/df.z,2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f19a058d18a425a38ba1150c519bdf91e27cdd1c"},"cell_type":"code","source":"# Now check updated correlations with price:\n# length to width ratio has little correlation but the resut are very highly correlated!\ndf_corr = df.corr()\ndf_corr['price']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"778e293c79d9ee3860a5c8ee4c156d2c1e98a720"},"cell_type":"code","source":"# Before we go anyfurther into preprocessing its good practice to reserve a holdout set for testing\n# We will return to this later!\ndiamond_train,diamond_test = train_test_split(df,test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a8628d0b3174d47a8534a48b69e8066a357cff81"},"cell_type":"code","source":"# Good idea now is to only work with our training data and start the preprocessing stage\n# X=features, y=target\nX,y = diamond_train.drop('price',axis=1),diamond_train.price\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"841c95c76912e737df9928998b24273009780c7a"},"cell_type":"code","source":"# This section we will attempt to use OrdinalEncoder() which can be customerised so that I can specify what each class in each attribute should be labeled as.\n# We will also standardize our numerical attributes before inputing into our model (standard ML practice).\n\n# List of dictionaries, first key should be the feature name, second key should be mapping.\n\nordinal_enc_mapping = [{'col':'cut','mapping': [('Fair',0),('Good',1),('Very Good',2),('Premium',3),('Ideal',4)]},\n                       {'col':'color','mapping': [('J',0),('I',1),('H',2),('G',3),('F',4),('E',5),('D',6)]},\n                       {'col':'clarity','mapping': [('I1',0),('SI2',1),('SI1',2),('VS2',3),('VS1',4),('VVS2',5),('VVS1',6),('IF',7)]}]\n\n# Seperate categorical columns from numerical:\ncategorical_columns = list(X.select_dtypes(include=['object']).columns)\nnumerical_columns = list(X.select_dtypes(exclude=['object']).columns)\n\n#Dataframemapper: Useful for applying transformation to specific columns of the dataframe.\n#numeric_mapper will apply transforms to the numeric columns selected above. First element in tuple is a list of columns to apply transformation to and second element is transformation.\nnumeric_mapper = DataFrameMapper([([numeric_feature], StandardScaler()) for numeric_feature in numerical_columns],\n                                sparse=False, df_out=True,input_df=True)\n\n\n#Apply feature union to both dataframe mapper and OrdinalEncoder:\n\nnumerical_categorical_union = FeatureUnion([('num_mapper',numeric_mapper),('oe',OrdinalEncoder(mapping=ordinal_enc_mapping,cols=categorical_columns))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"61b31bf03a4bd228d25de420f3a93750c4cf5ec8"},"cell_type":"code","source":"# Now we setup a Pipeline to run this badboy in! \n# Piece together into a pipeline: I have set the n_estimators high, rarely do we have an issue with overfitting on XGBoost if we keep the learning rate at a sufficient level.\nsteps = [('featureunion',numerical_categorical_union),\n         ('xgb_model',xgb.XGBRegressor(n_estimators=1000,subsample=0.3,max_depth=10,learning_rate=0.005,gamma=1.45))]\n\npipeline = Pipeline(steps)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"95339dcb90b9b0c57f0b4de22ed0bb573f01776f"},"cell_type":"code","source":"#cross validate: 3 folds\ncv = cross_val_score(pipeline,X,y,cv=3,verbose=1,scoring='r2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b78f879af7775124a2305906f42622781e8ee2bd"},"cell_type":"code","source":"#R2 score: Average of 3 folds\nprint(cv.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dd7220d01224bd75ccdc34baea9f4821cb92d30a"},"cell_type":"code","source":"# Now to the above performs well on the training data, lets check the test data with 3 folds:\nX_test,y_test = diamond_test.drop('price',axis=1),diamond_test.price\n\ncv_test = cross_val_score(pipeline,X_test,y_test,scoring='r2',cv=3)\n\n#R2 score:\nprint('R2 score:',cv_test.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cadb9eb1365f979438903c4a304e5dcb65a89050"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6a57a09d7cccde9e1a71b7209ca19c7420177b0b"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}