{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-26T13:46:17.441305Z","iopub.execute_input":"2021-05-26T13:46:17.441725Z","iopub.status.idle":"2021-05-26T13:46:17.463529Z","shell.execute_reply.started":"2021-05-26T13:46:17.44169Z","shell.execute_reply":"2021-05-26T13:46:17.461872Z"}}},{"cell_type":"code","source":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n#import requests\n#from bs4 import BeautifulSoup\nimport nltk\nnltk.download() ","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom collections import Counter\nimport urllib.request\nimport json\nfrom tqdm import tqdm\nimport collections\nimport matplotlib.pyplot as plt\n","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-05-27T12:08:53.745013Z","iopub.execute_input":"2021-05-27T12:08:53.745532Z","iopub.status.idle":"2021-05-27T12:08:53.75132Z","shell.execute_reply.started":"2021-05-27T12:08:53.745498Z","shell.execute_reply":"2021-05-27T12:08:53.750017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def my_parser(text):\n    tokens = word_tokenize(text)\n    words = [word for word in tokens if word.isalpha()]\n    stop_words = set(stopwords.words('english'))\n    words = [w for w in words if not w in stop_words]\n    porter = PorterStemmer()\n    stemmed = [porter.stem(word) for word in words]\n    return Counter(stemmed)\n   ","metadata":{"execution":{"iopub.status.busy":"2021-05-27T11:03:19.479912Z","iopub.execute_input":"2021-05-27T11:03:19.480275Z","iopub.status.idle":"2021-05-27T11:03:19.486763Z","shell.execute_reply.started":"2021-05-27T11:03:19.480245Z","shell.execute_reply":"2021-05-27T11:03:19.485953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nbigtext = []\npath = '/kaggle/input/CORD-19-research-challenge/document_parses/pdf_json'\njsons = os.listdir(path)\nfor i in tqdm(jsons):\n    with open(path + '/' + i, 'r') as file:\n        j = json.load(file)\n        study = j['abstract']\n        #print(j['metadata']['title'])\n        smalltext = []\n        if study:\n            for i in study:\n                smalltext.append(i['text'])\n            #print(smalltext)\n            bigtext.append(smalltext)\n\n           ","metadata":{"execution":{"iopub.status.busy":"2021-05-27T10:13:49.172457Z","iopub.execute_input":"2021-05-27T10:13:49.173119Z","iopub.status.idle":"2021-05-27T10:35:57.192922Z","shell.execute_reply.started":"2021-05-27T10:13:49.17306Z","shell.execute_reply":"2021-05-27T10:35:57.191969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"flat_list = [item for sublist in bigtext for item in sublist]\nstring = ' '.join([str(item) for item in flat_list])","metadata":{"execution":{"iopub.status.busy":"2021-05-27T11:08:20.124397Z","iopub.execute_input":"2021-05-27T11:08:20.124965Z","iopub.status.idle":"2021-05-27T11:08:21.419634Z","shell.execute_reply.started":"2021-05-27T11:08:20.124915Z","shell.execute_reply":"2021-05-27T11:08:21.418111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mydict = my_parser(string)\ndel mydict['the']\ndel mydict['We']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mydict2 = sorted(mydict.items(), key=lambda x: x[1], reverse = True)[:100]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(mydict2)","metadata":{"execution":{"iopub.status.busy":"2021-05-27T12:15:06.215795Z","iopub.execute_input":"2021-05-27T12:15:06.216366Z","iopub.status.idle":"2021-05-27T12:15:06.222646Z","shell.execute_reply.started":"2021-05-27T12:15:06.21633Z","shell.execute_reply":"2021-05-27T12:15:06.221853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wc = pd.DataFrame(mydict2, columns=['word', 'count'])","metadata":{"execution":{"iopub.status.busy":"2021-05-27T12:16:42.759621Z","iopub.execute_input":"2021-05-27T12:16:42.760316Z","iopub.status.idle":"2021-05-27T12:16:42.769101Z","shell.execute_reply.started":"2021-05-27T12:16:42.760257Z","shell.execute_reply":"2021-05-27T12:16:42.767557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(wc)","metadata":{"execution":{"iopub.status.busy":"2021-05-27T12:35:47.269656Z","iopub.execute_input":"2021-05-27T12:35:47.270134Z","iopub.status.idle":"2021-05-27T12:35:47.281644Z","shell.execute_reply.started":"2021-05-27T12:35:47.270093Z","shell.execute_reply":"2021-05-27T12:35:47.280149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(6, 15))\nax.barh( wc['word'], wc['count'],  align='center', linewidth = 0.2)\nax.set_yticks(wc['word'])\nbar_size = 0.25\npadding = 0.25\nax.set_xlabel('Counts')\nax.set_title('Words')\nax.invert_yaxis() \n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:00:22.885089Z","iopub.execute_input":"2021-05-27T13:00:22.885483Z","iopub.status.idle":"2021-05-27T13:00:24.238054Z","shell.execute_reply.started":"2021-05-27T13:00:22.885451Z","shell.execute_reply":"2021-05-27T13:00:24.236969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"На графике представлены 100 самых частотных слов из абстрактов статей по коронавирусу. \nВидим что большинство слов посвящено состоянию пацеинтов, их симптомам. \nТакже в этой состне есть слова связанные с распространением вируса в популяции","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:05:06.574067Z","iopub.execute_input":"2021-05-27T13:05:06.57448Z","iopub.status.idle":"2021-05-27T13:05:06.582905Z","shell.execute_reply.started":"2021-05-27T13:05:06.574447Z","shell.execute_reply":"2021-05-27T13:05:06.581027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}