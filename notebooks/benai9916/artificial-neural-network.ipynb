{"cells":[{"metadata":{},"cell_type":"markdown","source":"## About the data set\nWe have customer infromation which we got it from bank, and we have to predict base on customer credit score, salary etc whether customer will leave the bank in the comming years or will the cutomer stay and utilize the sevice of the bank","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Load Library","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\nimport matplotlib.pyplot as plt\n\nfrom tensorflow import keras","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Dataset","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"cust = pd.read_csv('../input/churn-for-bank-customers/churn.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print the first five rows of the data set\n\ncust.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print the shape of the dataset\n\ncust.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# few detail about data\n\ncust.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# statistical detail about data\n\ncust.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check for missing values\n\ncust.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Split the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# we wont take the first two columns (row id and customer id)\n\nx = cust.iloc[:, 3:13]\n\n# target variable\ny = cust.iloc[:, -1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Convert categorical column to numerical","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x.Gender = pd.factorize(x.Gender)[0]\n\nx.Geography = pd.factorize(x.Geography)[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train test split","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting the dataset into the Training set and Test set\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(x_train.shape, x_test.shape, y_train.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Scaling the dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sc = StandardScaler()\n\nx_train = sc.fit_transform(x_train)\nx_test = sc.fit_transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Atrifical Neural Network (ANN)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Import Deep Learning Libraries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, LeakyReLU, PReLU, ELU, Dropout","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialising the ANN\n\nclassify = Sequential()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding the input layer and the first hidden layer\n\nclassify.add(Dense(units = 6, kernel_initializer = 'he_uniform', activation ='relu', input_dim =10))\n\n# Adding the second hidden layer\n\nclassify.add(Dense(units = 6, kernel_initializer ='he_uniform' ,activation ='relu'))\n\n# Adding the output layer\n\nclassify.add(Dense(units = 1, kernel_initializer = 'glorot_uniform', activation = 'sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classify.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compiling the ANN\n\nclassify.compile(optimizer = 'adam', loss='binary_crossentropy', metrics='accuracy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting the ANN to the Training set\n\nmodel = classify.fit(x_train, y_train, validation_split=0.20, batch_size=10, epochs=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# list all data in histroy\n\nprint(model.history.keys())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# summarize history for accuracy\nplt.plot(model.history['accuracy'])\nplt.plot(model.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='lower right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# summarize history for loss\nplt.plot(model.history['loss'])\nplt.plot(model.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper right')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Making predictions and evaluating model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predict = classify.predict(x_test)\ny_predict = (y_predict > 0.5)\n\n\nprint(confusion_matrix(y_test, y_predict))\n\nprint('\\nAccuracy: ', accuracy_score(y_predict,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model using Logistic regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegressionCV\nfrom sklearn.metrics import accuracy_score\nlg = LogisticRegressionCV(cv=3)\n\nlg.fit(x_train, y_train)\n\np_predict_train = lg.predict(x_train)\n\np_predict_test = lg.predict(x_test)\n\nprint(accuracy_score(p_predict_train, y_train))\nprint(accuracy_score(p_predict_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Hyperparameter tuning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nfrom keras.models import Sequential\nfrom keras.layers import LeakyReLU, Activation, Dropout, Dense, Embedding, Flatten, BatchNormalization\nfrom keras.activations import relu, sigmoid","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model(layers, activation):\n    model = Sequential()\n    \n    for i, nodes in enumerate(layers):\n        if i==0:\n            model.add(Dense(nodes,input_dim=x_train.shape[1]))\n            model.add(Activation(activation))\n            model.add(Dropout(0.3))\n        else:\n            model.add(Dense(nodes))\n            model.add(Activation(activation))\n            model.add(Dropout(0.3))\n            \n    model.add(Dense(units = 1, kernel_initializer= 'glorot_uniform', activation = 'sigmoid'))\n    \n    model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n    \n    return model\n    \nmodel = KerasClassifier(build_fn=create_model, verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"layers = [(20,), (30, 20), (45, 30, 15)]\nactivations = ['sigmoid', 'relu']\n\nparam_grid = dict(layers=layers, activation=activations, batch_size = [128, 256], epochs=[100])\ngrid = GridSearchCV(estimator=model, param_grid=param_grid,cv=5)\n\ngrid_result = grid.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(grid_result.best_score_,grid_result.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}