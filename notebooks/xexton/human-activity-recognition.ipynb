{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Train dataset","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# reading the dataset\ntrain = pd.read_csv('../input/human-activity-recognition-with-smartphones/train.csv')\ntrain.head(10)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-17T17:51:14.030211Z","iopub.execute_input":"2021-07-17T17:51:14.030581Z","iopub.status.idle":"2021-07-17T17:51:14.924403Z","shell.execute_reply.started":"2021-07-17T17:51:14.03055Z","shell.execute_reply":"2021-07-17T17:51:14.923357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# shape of the dataset\ntrain.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-17T17:51:14.925744Z","iopub.execute_input":"2021-07-17T17:51:14.92603Z","iopub.status.idle":"2021-07-17T17:51:14.930893Z","shell.execute_reply.started":"2021-07-17T17:51:14.926006Z","shell.execute_reply":"2021-07-17T17:51:14.930063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test dataset","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv('../input/human-activity-recognition-with-smartphones/test.csv')\ntest.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T17:51:14.932678Z","iopub.execute_input":"2021-07-17T17:51:14.93307Z","iopub.status.idle":"2021-07-17T17:51:15.334719Z","shell.execute_reply.started":"2021-07-17T17:51:14.933034Z","shell.execute_reply":"2021-07-17T17:51:15.333879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#shape of test dataset\ntest.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-17T17:51:15.336176Z","iopub.execute_input":"2021-07-17T17:51:15.33646Z","iopub.status.idle":"2021-07-17T17:51:15.341826Z","shell.execute_reply.started":"2021-07-17T17:51:15.336434Z","shell.execute_reply":"2021-07-17T17:51:15.340982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"While predicting the result of our model we will not use test dataset","metadata":{}},{"cell_type":"markdown","source":"# Data Cleaning","metadata":{}},{"cell_type":"markdown","source":"## 1. Check for duplicates","metadata":{}},{"cell_type":"code","source":"#checking for duplicate values in train dataset- if there are any duplicate values we will remove them\nprint(\"Number of duplicate values in train dataset are\", train.duplicated().sum())\nprint(\"Number of duplicate values in test dataset are\", test.duplicated().sum()) ","metadata":{"execution":{"iopub.status.busy":"2021-07-17T17:51:15.343044Z","iopub.execute_input":"2021-07-17T17:51:15.343311Z","iopub.status.idle":"2021-07-17T17:51:16.081488Z","shell.execute_reply.started":"2021-07-17T17:51:15.343287Z","shell.execute_reply":"2021-07-17T17:51:16.080598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see that there are no duplicate values in train and test dataset","metadata":{}},{"cell_type":"markdown","source":"## 2. Check for null values","metadata":{}},{"cell_type":"code","source":"#checkng for null values - if there are any null values then we will remove them using simpleimputer with mean or median strategy\nprint(\"Number of null values in train dataset are \", train.isna().sum().sum())\nprint(\"Number of null values in test dataset are \", test.isna().sum().sum())","metadata":{"execution":{"iopub.status.busy":"2021-07-17T17:51:16.082681Z","iopub.execute_input":"2021-07-17T17:51:16.082954Z","iopub.status.idle":"2021-07-17T17:51:16.10653Z","shell.execute_reply.started":"2021-07-17T17:51:16.082927Z","shell.execute_reply":"2021-07-17T17:51:16.105618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see that there are no null values in train and test dataset","metadata":{}},{"cell_type":"markdown","source":"## 3. check for outliers","metadata":{}},{"cell_type":"markdown","source":"### train dataset","metadata":{}},{"cell_type":"code","source":"#checking for outliers, if there are any outliers we will remove then or we will use median() to fill them\n\n# 1. Identify the outliers with inter quntile range(IQR)\nq1 = train.quantile(0.10)\nq3 = train.quantile(0.90)\niqr = q3 - q1\n#printing the iqr score which will help us to detect outliers\nprint(iqr)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T17:51:16.107685Z","iopub.execute_input":"2021-07-17T17:51:16.107955Z","iopub.status.idle":"2021-07-17T17:51:16.260264Z","shell.execute_reply.started":"2021-07-17T17:51:16.107929Z","shell.execute_reply":"2021-07-17T17:51:16.259471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#2. printing the number of outliers\noutlier = ((train < (q1 - 1.5*iqr)) | (train > (q3 + 1.5*iqr))).values.sum()\nprint(\"number of outliers are \", outlier)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T17:51:16.262135Z","iopub.execute_input":"2021-07-17T17:51:16.262369Z","iopub.status.idle":"2021-07-17T17:51:16.48222Z","shell.execute_reply.started":"2021-07-17T17:51:16.262346Z","shell.execute_reply":"2021-07-17T17:51:16.481343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Ignore the error for now*\n\nWe can see that there are some outliers, and we will adjust them when we want to predict the result, which we won't do in this notebook","metadata":{}},{"cell_type":"markdown","source":"### test dataset","metadata":{}},{"cell_type":"code","source":"# 1. Identify the outliers with inter quntile range(IQR)\nq1 = test.quantile(0.10)\nq3 = test.quantile(0.90)\niqr = q3 - q1\n#printing the iqr score which will help us to detect outliers\nprint(iqr)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T17:51:16.483944Z","iopub.execute_input":"2021-07-17T17:51:16.484213Z","iopub.status.idle":"2021-07-17T17:51:16.546371Z","shell.execute_reply.started":"2021-07-17T17:51:16.484188Z","shell.execute_reply":"2021-07-17T17:51:16.545654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#2. printing the number of outliers\noutlier = ((test < (q1 - 1.5*iqr)) | (test > (q3 + 1.5*iqr))).values.sum()\nprint(\"number of outliers are \", outlier)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T17:51:16.547444Z","iopub.execute_input":"2021-07-17T17:51:16.547962Z","iopub.status.idle":"2021-07-17T17:51:16.747201Z","shell.execute_reply.started":"2021-07-17T17:51:16.547923Z","shell.execute_reply":"2021-07-17T17:51:16.746231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ignore the error for now\n\nWe can see that there are some outliers, and we will adjust them when we want to predict the result, which we won't do in this notebook","metadata":{}},{"cell_type":"markdown","source":"# Exploratory data analysis - EDA","metadata":{}},{"cell_type":"markdown","source":"## 1. description of dataset","metadata":{}},{"cell_type":"code","source":"#description of train dataset\ntrain.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T17:51:16.748595Z","iopub.execute_input":"2021-07-17T17:51:16.74915Z","iopub.status.idle":"2021-07-17T17:51:17.850235Z","shell.execute_reply.started":"2021-07-17T17:51:16.74911Z","shell.execute_reply":"2021-07-17T17:51:17.84929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we all already know, there are 7352 rows with 562 columns. With description method you can see mean, std, min, max, etc, values for each column","metadata":{}},{"cell_type":"code","source":"#description of test dataset\ntest.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T17:51:17.851622Z","iopub.execute_input":"2021-07-17T17:51:17.851964Z","iopub.status.idle":"2021-07-17T17:51:18.888371Z","shell.execute_reply.started":"2021-07-17T17:51:17.85193Z","shell.execute_reply":"2021-07-17T17:51:18.887622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we all already know, there are 2947 rows with 562 columns. With description method you can see mean, std, min, max, etc, values for each column","metadata":{}},{"cell_type":"markdown","source":"## 2. visualize user data","metadata":{}},{"cell_type":"code","source":"# visualizing the use user data in train\nplt.figure(figsize=(16,8))\nsns.countplot(x='subject', hue='Activity', data=train)\nplt.title(\"User data\", fontsize=20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T17:51:18.889444Z","iopub.execute_input":"2021-07-17T17:51:18.889687Z","iopub.status.idle":"2021-07-17T17:51:19.627798Z","shell.execute_reply.started":"2021-07-17T17:51:18.889664Z","shell.execute_reply":"2021-07-17T17:51:19.627013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Activity and subject data points","metadata":{}},{"cell_type":"code","source":"sns.countplot(x='Activity', data=train)\nplt.title(\"Activity data points\", fontsize=20)\nplt.xticks(rotation=90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T17:51:19.628883Z","iopub.execute_input":"2021-07-17T17:51:19.629141Z","iopub.status.idle":"2021-07-17T17:51:19.782701Z","shell.execute_reply.started":"2021-07-17T17:51:19.629118Z","shell.execute_reply":"2021-07-17T17:51:19.781721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 1400 data points in which lowest data point is walking downstairs. We can say that **walking downstairs** acitivity was **less performered** and highest data points for **Laying** activity, which was **mostly performed.**","metadata":{}},{"cell_type":"code","source":"sns.countplot(x='subject', data=train)\nplt.title(\"Subject data points\", fontsize=20)\nplt.xticks(rotation=90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T17:51:19.784329Z","iopub.execute_input":"2021-07-17T17:51:19.784752Z","iopub.status.idle":"2021-07-17T17:51:20.035673Z","shell.execute_reply.started":"2021-07-17T17:51:19.784711Z","shell.execute_reply":"2021-07-17T17:51:20.034836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From above data points we can say that most of the subjects performed a same amount of movement(activity). Though few subjects did more than others.","metadata":{}},{"cell_type":"markdown","source":"No need to check it for test dataset","metadata":{}},{"cell_type":"code","source":"test.Activity.unique()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T17:51:20.036805Z","iopub.execute_input":"2021-07-17T17:51:20.037106Z","iopub.status.idle":"2021-07-17T17:51:20.042827Z","shell.execute_reply.started":"2021-07-17T17:51:20.037068Z","shell.execute_reply":"2021-07-17T17:51:20.041945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Dropping some columns","metadata":{}},{"cell_type":"markdown","source":"Now we will drop **subject** column because it contains string values and we will drop **Activity** column because it is **dependent column.**","metadata":{}},{"cell_type":"code","source":"train_PCA = train.drop(['Activity', 'subject'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T17:51:20.044061Z","iopub.execute_input":"2021-07-17T17:51:20.044352Z","iopub.status.idle":"2021-07-17T17:51:20.062149Z","shell.execute_reply.started":"2021-07-17T17:51:20.044325Z","shell.execute_reply":"2021-07-17T17:51:20.061191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PCA","metadata":{}},{"cell_type":"markdown","source":"## 1. PCA projecton to 2D","metadata":{}},{"cell_type":"markdown","source":"We imported PCA from sklearn.decomposition. n_components = 2, because we wanted to convert our dataset into 2D array. ","metadata":{}},{"cell_type":"code","source":"def stand_data(x):\n    r,c=x.shape\n    sa=np.zeros(shape=(r,c))\n    temp=np.zeros(r)\n    for i in range (c):\n        mean=np.mean(x[:,i])\n        st=np.std(x[:,i])\n        temp=np.empty(0)\n        for j in  x[:,i] :\n            temp=np.append(temp,((j-mean)/st))\n        sa[:,i]=temp\n    return sa","metadata":{"execution":{"iopub.status.busy":"2021-07-17T17:51:20.063816Z","iopub.execute_input":"2021-07-17T17:51:20.064153Z","iopub.status.idle":"2021-07-17T17:51:20.072806Z","shell.execute_reply.started":"2021-07-17T17:51:20.064125Z","shell.execute_reply":"2021-07-17T17:51:20.072032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_PCA","metadata":{"execution":{"iopub.status.busy":"2021-07-17T17:51:20.074181Z","iopub.execute_input":"2021-07-17T17:51:20.074484Z","iopub.status.idle":"2021-07-17T17:51:20.113445Z","shell.execute_reply.started":"2021-07-17T17:51:20.07445Z","shell.execute_reply":"2021-07-17T17:51:20.112642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntraind=stand_data(train_PCA.values)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T17:51:20.114592Z","iopub.execute_input":"2021-07-17T17:51:20.114859Z","iopub.status.idle":"2021-07-17T17:52:05.717576Z","shell.execute_reply.started":"2021-07-17T17:51:20.114834Z","shell.execute_reply":"2021-07-17T17:52:05.716755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x=pd.DataFrame(traind)\nx.head","metadata":{"execution":{"iopub.status.busy":"2021-07-17T17:54:45.174386Z","iopub.execute_input":"2021-07-17T17:54:45.174939Z","iopub.status.idle":"2021-07-17T17:54:45.195834Z","shell.execute_reply.started":"2021-07-17T17:54:45.174908Z","shell.execute_reply":"2021-07-17T17:54:45.195164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"covar=np.cov(x.T)\ncovar.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-17T18:05:20.863685Z","iopub.execute_input":"2021-07-17T18:05:20.864003Z","iopub.status.idle":"2021-07-17T18:05:20.936391Z","shell.execute_reply.started":"2021-07-17T18:05:20.863976Z","shell.execute_reply":"2021-07-17T18:05:20.935273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eig_val,eig_vect=np.linalg.eig(covar)\nprint(\"Eigenvector: \\n\",eig_vect,\"\\n\")\nprint(\"Eigenvalues: \\n\", eig_val, \"\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-07-17T18:07:35.57548Z","iopub.execute_input":"2021-07-17T18:07:35.575829Z","iopub.status.idle":"2021-07-17T18:07:35.868911Z","shell.execute_reply.started":"2021-07-17T18:07:35.5758Z","shell.execute_reply":"2021-07-17T18:07:35.867921Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"variance_explained = []\ntemp=[]\nfor i in eig_val:\n     variance_explained.append((i/sum(eig_val))*100)\n        \nlen(variance_explained)\nfor i in range (10):\n    temp.append(variance_explained[i])\n    print(\"Pca:\",i,':',variance_explained[i],\"\\n\")\nprint(sum(temp))","metadata":{"execution":{"iopub.status.busy":"2021-07-17T18:50:23.82859Z","iopub.execute_input":"2021-07-17T18:50:23.828935Z","iopub.status.idle":"2021-07-17T18:50:23.955376Z","shell.execute_reply.started":"2021-07-17T18:50:23.828873Z","shell.execute_reply":"2021-07-17T18:50:23.954571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Storing 2D values in new dataframe","metadata":{}},{"cell_type":"markdown","source":"After storing our principalComponant into humanAcivity dataframe we added labels into the dataset. They will help us to visualize the 2D dataset","metadata":{}},{"cell_type":"markdown","source":"## 3. Visualize 2D Projection","metadata":{}},{"cell_type":"markdown","source":"* We can't seprate our activities.\n\n* Model will probably be confused, from where to seprate the dataset. ","metadata":{}},{"cell_type":"markdown","source":"## 4. Variance","metadata":{}},{"cell_type":"markdown","source":"By using the attribute **explained_variance_ratio_**, you can see that the first principal component contains 62.55% of the variance and the second principal component contains 4.91% of the variance. Together, the two components contain 6% of the information.","metadata":{}}]}