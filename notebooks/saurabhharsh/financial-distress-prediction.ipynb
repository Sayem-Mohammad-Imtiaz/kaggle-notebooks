{"cells":[{"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\n#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\ndf = pd.read_csv(\"../input/Financial Distress.csv\")\ndf.head()\n# Any results you write to the current directory are saved as output.","cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2410ea3d-9502-4dbf-b781-ecf60c802d5b","_uuid":"8d47f3fd23eee3a43e0a1759f692d518a51abfbe"}},{"outputs":[],"source":"print(df.Company.unique().shape) # 422 company numbers","cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"416b6c52-fba0-4194-9c38-a1205aa2ebdf","_uuid":"71239f65e413a6a97bb3e995de1ab31818c57679"}},{"source":"There are 422 company numbers in the dataframe with financial data given as short time series for each company. In this notebook the time information is ignored and every row is treated as an independent data point.\n\nExamine correlation of variables with Finacial Distress measurement: ","cell_type":"markdown","metadata":{"_cell_guid":"79c2ef0f-6b90-40ee-be4f-3966288b6b74","_uuid":"6504104960b77ab209510f3547f7d5ec507d9ba5"}},{"outputs":[],"source":"print(df.x80.unique().shape)\ncorrDf = df.drop(labels = ['Time','Company'], axis = 1).corr().abs()\ncorrDf.sort_values(by = 'Financial Distress', inplace=True, ascending = False)\ncorrColumns = corrDf.drop(labels=['x80']).index.values #[corrDf['Financial Distress'] > 0.01]\ncorrDf.head(n = 10)","cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c9446c3d-90b8-49a8-b43b-6171b1143028","_uuid":"2247df4be434dc9966a667fd07f3e6ff97f21bb8"}},{"source":"'x80' is dropped because it is a categorical variable with 37 distinct values. It needs to be one hot encoded to work with classifiers. Some more variables can be dropped and only the top few can be retained but right now the number of variables is manageable so we will take all of them. When 'x80' is encoded some of these can be dropped based on the correlation.","cell_type":"markdown","metadata":{"_cell_guid":"f1a5db59-5455-432d-b473-8c8c575c9d8b","_uuid":"c8ab43eddd13c37ee118296919ffe78aed5f4a2d"}},{"outputs":[],"source":"reducedDf = df[corrColumns]\nreducedDf.head()","cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3fccd230-a86c-4c03-b42c-ad3e934cc3af","_uuid":"084110bcffe1813bfff26546699fc3cc9bd5c07c"}},{"source":"reducedDf contains only Financial Distress measure and the features we will be working with.  Features should be scaled using standard scaler before using them for training or testing.","cell_type":"markdown","metadata":{"_cell_guid":"867560c6-1324-4e58-8caf-391e688da0c6","_uuid":"6c65ed389ee5ccac54d654b8c851823b533422c9"}},{"outputs":[],"source":"from sklearn.preprocessing import RobustScaler, StandardScaler\nscaler = StandardScaler()\ntrainArray = reducedDf.as_matrix()\nscaledData = trainArray\nscaledData[:,1:] = scaler.fit_transform(trainArray[:,1:])\n","cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"cb2323e2-e5de-49c0-9987-1ba8b6aa0c7c","_uuid":"532e5f805ce20ec00cc2591f77d4c0818c4e8ea1"}},{"source":"Examine imbalance in the dataset. Only ~5 % are distressed ","cell_type":"markdown","metadata":{"_cell_guid":"326e82bd-605e-4d2e-bf6e-6960b41b870d","_uuid":"4f9e3fe657841d00d4f5f9b9fb00f195122e1335"}},{"outputs":[],"source":"print(np.sum(scaledData[:,0] > -0.5)) # 3281 healthy\nprint(np.sum(scaledData[:,0] <= -0.5)) # 391 distressed cases\n","cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7685d186-f963-4481-90a1-ac39bdc6baec","_uuid":"396f72431a82cf652b34594f214309213526473f"}},{"source":"Plotting to see all features if distribution is good. Looks reasonable.","cell_type":"markdown","metadata":{"_cell_guid":"d391bc4d-24d6-40ce-a316-018fa54dd069","_uuid":"d7e85af71d0c332fd460f4fb7fa83688844fa540"}},{"outputs":[],"source":"import seaborn as sns\nsns.boxplot(data = scaledData[:,1:])","cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a3210eef-ab77-49ab-b443-497685f6d58b","_uuid":"21a81eb86736db06ac2f5b9991857f78bb0c976c"}},{"source":"Since the data is imabalanced we should focus on precision, recall and FScore rather than relying on accuracy.  \n\nPeform a linear regression to predict Financial Distress value and then predict if it is distressed or not using a threshold on the predicted distress metric.","cell_type":"markdown","metadata":{"_cell_guid":"3d4aa5de-9d48-46dd-a071-63f1480bc138","_uuid":"e300b77503e7978f2c4484e04a7f18922a72e614"}},{"outputs":[],"source":"from sklearn.linear_model import LinearRegression\nfrom sklearn import svm\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nimport matplotlib.pyplot as plt\n\nuniformData = scaledData\nX = uniformData[:,1:]\ny = uniformData[:,0]\ny_discrete = (uniformData[:,0] < -0.5).astype(int)\n\nmdl = LinearRegression()\n\nthresholds = np.arange(-1.5,-0.5,0.1) # Try some thresholds\nprecisions = np.zeros_like(thresholds)\nrecalls = np.zeros_like(thresholds)\nf1_scores = np.zeros_like(thresholds)\npredicted_metric = cross_val_predict(mdl, X, y, cv = 5)\nfig, ax = plt.subplots()\nfor i in range(len(thresholds)):\n    predicted = (predicted_metric < thresholds[i]).astype(int)\n    precisions[i] = precision_score(y_discrete, predicted)\n    recalls[i] = recall_score(y_discrete, predicted)\n    f1_scores[i] = f1_score(y_discrete, predicted)\n    plt.scatter(recalls[i], precisions[i])\n    ax.annotate('%0.3f' % (f1_scores[i]),(recalls[i], precisions[i]))\nplt.xlabel('Recall')    \nplt.ylabel('Precision')\n\n","cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5e516e3f-b30a-4a5e-8e61-021c3f8e9a0a","_uuid":"9f9b43253b85f1882a186246fcc3754d0c141b43"}},{"outputs":[],"source":"mdl = svm.SVR()\nthresholds = np.arange(-0.5,0.5,0.1) # Try some thresholds\nprecisions = np.zeros_like(thresholds)\nrecalls = np.zeros_like(thresholds)\nf1_scores = np.zeros_like(thresholds)\npredicted_metric = cross_val_predict(mdl, X, y, cv = 5)\nfig, ax = plt.subplots()\nfor i in range(len(thresholds)):\n    predicted = (predicted_metric < thresholds[i]).astype(int)\n    precisions[i] = precision_score(y_discrete, predicted)\n    recalls[i] = recall_score(y_discrete, predicted)\n    f1_scores[i] = f1_score(y_discrete, predicted)\n    plt.scatter(recalls[i], precisions[i])\n    ax.annotate('%0.3f' % (f1_scores[i]),(recalls[i], precisions[i]))\nplt.xlabel('Recall')    \nplt.ylabel('Precision')","cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b515f6a5-4c6f-4ed1-a1fa-e22cbee9e803","_uuid":"072f3870b2f54986c4ca345453dd3fa0adbad86c"}},{"source":"Linear model gives a best Fscore of 0.295 and SVR improves it to ~0.4. Now we turn to some classifiers to run this task as a pure classification job\n\nTo run the data through classifiers we should use StratifiedKFold because it ensures that the proportion of classes remains almost constant across splits. Also classifiers have a parameter named 'class_weight' which can be set to 'balanced' to weigh the observations by their support. \n","cell_type":"markdown","metadata":{"_cell_guid":"ec1fb258-8062-4753-a62d-55c7397a99aa","_uuid":"4edb1db03ad3ddb2c300f56538354c22428062b3"}},{"outputs":[],"source":"from sklearn.model_selection import StratifiedKFold","cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"db2bdc9f-81b5-47d3-8091-4d53109bd84c","_uuid":"eee0243b30f097e2e442a721eecf6268a91406f2"}},{"source":"Let's define a wrapper function which does the classification using StratifiedKFold CV and returns predicted probability for each observation. This function should also be able to plot the confusion matrix for different threshold levels.","cell_type":"markdown","metadata":{"_cell_guid":"6673c31e-e9d4-49d8-9126-a388b257238a","_uuid":"a678f58a02df58ac61bc1dbb6ca3c5db06b1ec4d"}},{"outputs":[],"source":"\nfrom sklearn.metrics import precision_recall_curve\nimport matplotlib.pyplot as plt\n\ndef cvClassifier(mdl, X, y, color, name, confMat = False, confMatNormalize = True):\n    skf = StratifiedKFold(n_splits = 5)\n    predicted_prob = np.zeros_like(y, dtype = float)\n    for train,test in skf.split(X, y):\n        mdl.fit(X[train,:],y[train])\n        y_prob = mdl.predict_proba(X[test,:])\n        predicted_prob[test] = y_prob[:,1] #The second class 1 from 0,1 is the one to be predicted\n    \n    precision, recall, thresholds = precision_recall_curve(y, predicted_prob)\n    plt.plot(recall, precision, color=color,label = name)\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.ylim([0.0, 1.05])\n    plt.xlim([0.0, 1.0])\n    plt.title('2-class Precision-Recall curve')\n    plt.legend()\n    \n    fscore = 2*(precision*recall)/(precision + recall)\n    maxFidx = np.nanargmax(fscore)\n    selP = precision[maxFidx]\n    selRecall = recall[maxFidx]\n    selThreshold = thresholds[maxFidx]\n\n    return predicted_prob, selP, selRecall, fscore[maxFidx], selThreshold","cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"ee3684e4-99ec-49e8-990a-1eae3b06b66b","_uuid":"e72de3f7e0c49543ae7b80d76c306193864dc26c"}},{"source":"Now we can try some classifier using the function defined above. We should use only classifiers with a class_weight parameter available since only they can compensate for the imbalance in the dataset. The selection criterion is to maximize F score. ","cell_type":"markdown","metadata":{"_cell_guid":"df789bd7-be45-4d8d-a9a8-8e9944393237","_uuid":"178b6e48ca138d53ba49e85be7a69b72843ec0e4"}},{"outputs":[],"source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y_discrete, test_size=0.3, stratify=y_discrete, random_state=42)\n\nmdl = LogisticRegression(class_weight = 'balanced')\nout1 = cvClassifier(mdl, X_train, y_train, 'y','Logit')\n\nmdl = svm.SVC(kernel = 'linear', C=0.025, class_weight = 'balanced', probability = True)\nout2 = cvClassifier(mdl, X_train, y_train, 'b','LinearSVC')\n\nmdl = RandomForestClassifier(class_weight = 'balanced', n_estimators=1000)\nout3 = cvClassifier(mdl, X_train, y_train, 'r','RandomForest')\n\nmdl = svm.SVC(C=0.5, class_weight = 'balanced', probability = True)\nout4 = cvClassifier(mdl, X_train, y_train, 'g','RBFSVC')","cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"07742935-dfb6-4197-a1a9-a7840849a47c","_uuid":"f36cd0b61263cfb5d33837d4f10b3fa4a75b23b8"}},{"source":"All the classifiers are performing very closely. If the FScore numbers don't vary by a lot we should use the simplest model (Logit or LinearSVC).\n\nWe can now examine the best Fscores from different models and the precision recall associated with the scores.","cell_type":"markdown","metadata":{"_cell_guid":"1a64d87b-8fe9-41a7-9ea3-7a0bcc0678ef","_uuid":"029303c80432765545926cf2609fc6c39c48b58f"}},{"outputs":[],"source":"results = [out1, out2, out3, out4]\nmdlNames = ['Logit','LinearSVC','RF','RBFSVC']\nfig, ax = plt.subplots()\nfor i in range(len(results)):\n    ax.scatter(results[i][2],results[i][1])\n    ax.annotate('%s %0.4f' % (mdlNames[i], results[i][3]),(results[i][2],results[i][1]))\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.ylim([0.3, 0.5])\nplt.xlim([0.35, 0.65])","cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b11a7b16-dd04-48e9-b5df-499a004123ad","_uuid":"52acc2399622c13d7c3a6db31915b1515d680b6f"}},{"source":"LinearSVC has the highest F score and at the highest recall value. For this problem it's good to have a model with a better recall.","cell_type":"markdown","metadata":{"_cell_guid":"4e4819d1-e7df-4e94-9574-e977a67d3cff","_uuid":"06849604b648ca435d204c7328b9a0284fcfaf9d"}},{"outputs":[],"source":"threshold = out2[4]\ny_pred = (out2[0] > threshold).astype(int)\nfrom sklearn.metrics import accuracy_score\nacc = accuracy_score(y_train, y_pred)\nprint('Accuracy %0.2f' % (acc))\nprint('Threshold %0.3f' % (threshold))","cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"73389563-83c9-4448-aad8-8b3124a1e3c9","_uuid":"8045a78a599350991ff0bd89778e261d438ac9e1"}},{"source":"Now we can try the LinearSVC model with the hold out test set.","cell_type":"markdown","metadata":{}},{"outputs":[],"source":"mdl = svm.SVC(kernel = 'linear', C=0.025, class_weight = 'balanced', probability = True)\nout2 = cvClassifier(mdl, X_train, y_train, 'b','LinearSVC')\n\ny_testp = (mdl.predict_proba(X_test)[:,1] > threshold).astype(int)\nacc = accuracy_score(y_test, y_testp)\nprint('Accuracy %0.2f' % (acc))\nprint('Precision %0.2f' % (precision_score(y_test,y_testp)))\nprint('Recall %0.2f' % (recall_score(y_test,y_testp)))","cell_type":"code","execution_count":null,"metadata":{}}],"nbformat":4,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","file_extension":".py","version":"3.6.4","mimetype":"text/x-python","pygments_lexer":"ipython3","nbconvert_exporter":"python"}},"nbformat_minor":1}