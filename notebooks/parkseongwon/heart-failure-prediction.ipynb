{"cells":[{"metadata":{},"cell_type":"markdown","source":"Used Dataset: Heart Failure Prediction\n\nScaling method: Standard Scaler, MinMax Scaler, Robust Scaler\n\nClassifier model: GaussianNB, Logistic Regression, Decision Tree, SVM\n\nEvaluation method: Confusion Matrix, ROC curve\n\n1. Data Analysis Process step:\n0. Import Library\n1. Dataset Load\n2. Dataset Scaling\n3. Split the Dataset\n4. Build a model and train the model\n5. Evaluation\n\nFirst of all, Import the library that we will use."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Import the library\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score, precision_score, precision_recall_curve\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_curve, roc_auc_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then load the dataset."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"code","source":"# Load the dataset\ndef load_dataset():\n    df = pd.read_csv(\"../input/heart-failure-clinical-data/heart_failure_clinical_records_dataset.csv\")\n    return df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Scale the dataset with 3 method: standard, minmax, robust.\n\nIn this case, only numeric attribute have to be scaled.\n\nSo, categorical attribute will be inserted in scaled dataframe."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scale the numeric attribute using standard scaler\ndef standard_scaling(df, scaling_list):\n    standard_model = StandardScaler().fit(df[scaling_list])\n    standard_df = standard_model.transform(df[scaling_list])\n    standard_df = pd.DataFrame(standard_df)\n    standard_df.columns = scaling_list\n    standard_df.insert(1, 'anaemia', df['anaemia'])\n    standard_df.insert(3, 'diabetes', df['diabetes'])\n    standard_df.insert(5, 'high_blood_pressure', df['high_blood_pressure'])\n    standard_df.insert(9, 'sex', df['sex'])\n    standard_df.insert(10, 'smoking', df['smoking'])\n    standard_df.insert(12, 'DEATH_EVENT', df['DEATH_EVENT'])\n    return standard_df\n\n# Scale the numeric attribute using minmax scaler\ndef minmax_scaling(df, scaling_list):\n    minmax_model = MinMaxScaler().fit(df[scaling_list])\n    minmax_df = minmax_model.transform(df[scaling_list])\n    minmax_df = pd.DataFrame(minmax_df)\n    minmax_df.columns = scaling_list\n    minmax_df.insert(1, 'anaemia', df['anaemia'])\n    minmax_df.insert(3, 'diabetes', df['diabetes'])\n    minmax_df.insert(5, 'high_blood_pressure', df['high_blood_pressure'])\n    minmax_df.insert(9, 'sex', df['sex'])\n    minmax_df.insert(10, 'smoking', df['smoking'])\n    minmax_df.insert(12, 'DEATH_EVENT', df['DEATH_EVENT'])\n    return minmax_df\n\n# Scale the numeric attribute using robust scaler\ndef robust_scaling(df, scaling_list):\n    robust_model = RobustScaler().fit(df[scaling_list])\n    robust_df = robust_model.transform(df[scaling_list])\n    robust_df = pd.DataFrame(robust_df)\n    robust_df.columns = scaling_list\n    robust_df.insert(1, 'anaemia', df['anaemia'])\n    robust_df.insert(3, 'diabetes', df['diabetes'])\n    robust_df.insert(5, 'high_blood_pressure', df['high_blood_pressure'])\n    robust_df.insert(9, 'sex', df['sex'])\n    robust_df.insert(10, 'smoking', df['smoking'])\n    robust_df.insert(12, 'DEATH_EVENT', df['DEATH_EVENT'])\n    return robust_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Split the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the dataset to the target attribute and variable attribute\ndef split_dataset(df):\n    X = df.drop(columns = [\"DEATH_EVENT\"], axis = 1)\n    y = df[\"DEATH_EVENT\"]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size=0.2)\n    return X_train, X_test, y_train, y_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Build the classifier model: Gaussian NB, Logistic Regression, Decision Tree, SVM.\n\nAll parameters are determined by GridSearchCV."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build a gaussian nb model\ndef gaussian_model(X_train, X_test, y_train, y_test):\n    gaussian_classifier = GaussianNB()\n    parameters = {'var_smoothing' : np.logspace(0, -9, num=200)}\n    gaussian_grid_search = GridSearchCV(estimator = gaussian_classifier, param_grid = parameters, scoring = 'accuracy')\n    gaussian_grid_search.fit(X_train, y_train)\n    best_parameter = gaussian_grid_search.best_params_\n    best_score = round(gaussian_grid_search.best_score_, 4)\n    print('Gaussian NB Best Parameter: {}'.format(best_parameter))\n    print('Gaussian NB Best Score: {}\\n'.format(best_score))\n    return best_parameter, best_score\n\n# Build a logistic regression model\ndef logistic_model(X_train, X_test, y_train, y_test):\n    logistic_classifier = LogisticRegression()\n    parameters = {'C': [0.01, 0.1, 1.0, 10.0], 'max_iter': [1000, 10000, 100000]}\n    logistic_grid_search = GridSearchCV(estimator = logistic_classifier, param_grid = parameters, scoring = 'accuracy')\n    logistic_grid_search.fit(X_train, y_train)\n    best_parameter = logistic_grid_search.best_params_\n    best_score = round(logistic_grid_search.best_score_, 4)\n    print('Logistic Regression Best Parameter: {}'.format(best_parameter))\n    print('Logistic Regression Best Score: {}\\n'.format(best_score))\n    return best_parameter, best_score\n\n# Build a decision tree model\ndef decision_model(X_train, X_test, y_train, y_test):\n    decision_classifier = DecisionTreeClassifier()\n    parameters = {'criterion': ['gini', 'entropy'], 'max_depth': [3, 10, 15, 30, 50, 100]}\n    decision_grid_search = GridSearchCV(estimator = decision_classifier, param_grid = parameters, scoring = 'accuracy')\n    decision_grid_search.fit(X_train, y_train)\n    best_parameter = decision_grid_search.best_params_\n    best_score = round(decision_grid_search.best_score_, 4)\n    print('Decision Tree Best Parameter: {}'.format(best_parameter))\n    print('Decision Tree Best Score: {}\\n'.format(best_score))\n    return best_parameter, best_score\n\n# Build a svm model\ndef svm_model(X_train, X_test, y_train, y_test):\n    svm_classifier = SVC()\n    parameters = {'C': [0.1, 1.0, 10.0], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': [0.01, 0.1, 1.0, 10.0]}\n    svm_grid_search = GridSearchCV(estimator = svm_classifier, param_grid = parameters, scoring = 'accuracy')\n    svm_grid_search.fit(X_train, y_train)\n    best_parameter = svm_grid_search.best_params_\n    best_score = round(svm_grid_search.best_score_, 4)\n    print('SVM Best Parameter: {}'.format(best_parameter))\n    print('SVM Best Score: {}\\n'.format(best_score))\n    return best_parameter, best_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visualize and evaluate the result. (Highest score top 3)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize the confusion matrix\ndef visual_confusion_roc(scaler, model, params, score, X_train, X_test, y_train, y_test):\n    if(model == 'GaussianNB'):\n        classifier = GaussianNB(var_smoothing = params['var_smoothing'])\n        classifier.fit(X_train, y_train)\n        y_predict = classifier.predict(X_test)\n        y_pred_proba = classifier.predict_proba(X_test)\n        y_predict_proba = y_pred_proba[:, 1]\n    elif (model == 'Logistic Regression'):\n        classifier = LogisticRegression(C = params['C'], max_iter = params['max_iter'])\n        classifier.fit(X_train, y_train)\n        y_predict = classifier.predict(X_test)\n        y_pred_proba = classifier.predict_proba(X_test)\n        y_predict_proba = y_pred_proba[:, 1]\n    elif (model == 'Decision Tree'):\n        classifier = DecisionTreeClassifier(criterion = params['criterion'], max_depth = params['max_depth'])\n        classifier.fit(X_train, y_train)\n        y_predict = classifier.predict(X_test)\n        y_pred_proba = classifier.predict_proba(X_test)\n        y_predict_proba = y_pred_proba[:, 1]\n    elif (model == 'SVM') :\n        classifier = SVC(C = params['C'], kernel = params['kernel'], gamma = params['gamma'], probability=True)\n        classifier.fit(X_train, y_train)\n        y_predict = classifier.predict(X_test)\n        y_pred_proba = classifier.predict_proba(X_test)\n        y_predict_proba = y_pred_proba[:, 1]\n    else :\n        print('ERROR:: Invalid Model Input')\n    matrix = confusion_matrix(y_test, y_predict)\n    acc_score = metrics.accuracy_score(y_test, y_predict)\t\n    rec_score = metrics.recall_score(y_test, y_predict)\t\n    pre_score = metrics.precision_score(y_test, y_predict)\t\n    f1s_score = metrics.f1_score(y_test, y_predict)\n    print(\"* Accuracy: {}\".format(round(acc_score, 4)))\n    print(\"* Precision: {}\".format(round(pre_score, 4)))\n    print(\"* Recall: {}\".format(round(rec_score, 4)))\n    print(\"* F1 score: {}\".format(round(f1s_score, 4)))\n    sns.heatmap(matrix, annot=True, linewidth=0.7, linecolor='black', fmt='g', cmap=\"BuPu\")\n    plt.title('{0} {1} Confusion Matrix (score: {2})'.format(scaler, model, score))\n    plt.xlabel('Y predict')\n    plt.ylabel('Y test')\n    plt.show()\n    plt.clf()\n    fpr, tpr, _ = roc_curve(y_test, y_predict_proba)\n    plt.plot([0, 1], [0, 1], linestyle='--')\n    plt.plot(fpr, tpr, label = 'ANN')\n    plt.xlabel('fpr')\n    plt.ylabel('tpr')\n    plt.title('{0} {1} ROC curve (score: {2})'.format(scaler, model, score))\n    plt.show()\n    plt.clf()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And finally main function."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Main Function\nif __name__ == \"__main__\":\n    scaling_list = ['age', 'creatinine_phosphokinase', 'ejection_fraction', 'platelets', 'serum_creatinine', 'serum_sodium', 'time']\n    non_scaling_list = ['anaemia', 'diabetes', 'high_blood_pressure', 'sex','smoking', 'DEATH_EVENT']\n    classifier_model_list = ['GaussianNB', 'Logistic Regression', 'Decision Tree', 'SVM']\n    scaler_list = ['Standard Scaler', 'MinMax Scaler', 'Robust Scaler']\n    total_model_list = []\n    total_score_list = []\n    total_param_list = []\n    standard_score_list = []\n    standard_param_list = []\n    minmax_score_list = []\n    minmax_param_list = []\n    robust_score_list = []\n    robust_param_list = []\n\n    # Load the dataset\n    df = load_dataset()\n\n    # Scale the numeric attributes\n    standard_df = standard_scaling(df, scaling_list) \n    minmax_df = minmax_scaling(df, scaling_list) \n    robust_df = robust_scaling(df, scaling_list) \n\n    # Split dataset to the test and train dataset\n    sX_train, sX_test, sy_train, sy_test = split_dataset(standard_df)\n    mX_train, mX_test, my_train, my_test = split_dataset(minmax_df)\n    rX_train, rX_test, ry_train, ry_test = split_dataset(robust_df)\n\n    # Used dataset - Standard Scaler\n    print('\\n======================= Standard Scaler =======================')\n    stand_gaussian_best_param, stand_gaussian_best_score = gaussian_model(sX_train, sX_test, sy_train, sy_test)\n    standard_param_list.append(stand_gaussian_best_param)\n    standard_score_list.append(stand_gaussian_best_score)\n    stand_logistic_best_param, stand_logistic_best_score = logistic_model(sX_train, sX_test, sy_train, sy_test)\n    standard_param_list.append(stand_logistic_best_param)\n    standard_score_list.append(stand_logistic_best_score)\n    stand_decision_best_param, stand_decision_best_score = decision_model(sX_train, sX_test, sy_train, sy_test)\n    standard_param_list.append(stand_decision_best_param)\n    standard_score_list.append(stand_decision_best_score)\n    stand_svm_best_param, stand_svm_best_score = svm_model(sX_train, sX_test, sy_train, sy_test)\n    standard_param_list.append(stand_svm_best_param)\n    standard_score_list.append(stand_svm_best_score)\n    standard_max_index = standard_score_list.index(max(standard_score_list))\n    print(\"Scaling Method: Standard Scaler\\nBest Model: {0}\\nBest Parameters: {1}\\nBest Score: {2}\\n\"\n    .format(classifier_model_list[standard_max_index], standard_param_list[standard_max_index], standard_score_list[standard_max_index]))\n    total_model_list.append(classifier_model_list[standard_max_index])\n    total_param_list.append(standard_param_list[standard_max_index])\n    total_score_list.append(standard_score_list[standard_max_index])\n\n    # Used dataset - MinMax Scaler\n    print('\\n======================= MinMax Scaler =======================')\n    minmax_gaussian_best_param, minmax_gaussian_best_score = gaussian_model(mX_train, mX_test, my_train, my_test)\n    minmax_param_list.append(minmax_gaussian_best_param)\n    minmax_score_list.append(minmax_gaussian_best_score)\n    minmax_logistic_best_param, minmax_logistic_best_score = logistic_model(mX_train, mX_test, my_train, my_test)\n    minmax_param_list.append(minmax_logistic_best_param)\n    minmax_score_list.append(minmax_logistic_best_score)\n    minmax_decision_best_param, minmax_decision_best_score = decision_model(mX_train, mX_test, my_train, my_test)\n    minmax_param_list.append(minmax_decision_best_param)\n    minmax_score_list.append(minmax_decision_best_score)\n    minmax_svm_best_param, minmax_svm_best_score = svm_model(mX_train, mX_test, my_train, my_test)\n    minmax_param_list.append(minmax_svm_best_param)\n    minmax_score_list.append(minmax_svm_best_score)\n    minmax_max_index = minmax_score_list.index(max(minmax_score_list))\n    print(\"Scaling Method: MinMax Scaler\\nBest Model: {0}\\nBest Parameters: {1}\\nBest Score: {2}\\n\"\n    .format(classifier_model_list[minmax_max_index], minmax_param_list[minmax_max_index], minmax_score_list[minmax_max_index]))\n    total_model_list.append(classifier_model_list[minmax_max_index])\n    total_param_list.append(minmax_param_list[minmax_max_index])\n    total_score_list.append(minmax_score_list[minmax_max_index])\n\n    # Used dataset - Robust Scaler\n    print('\\n======================= Robust Scaler =======================')\n    robust_gaussian_best_param, robust_gaussian_best_score = gaussian_model(rX_train, rX_test, ry_train, ry_test)\n    robust_param_list.append(robust_gaussian_best_param)\n    robust_score_list.append(robust_gaussian_best_score)\n    robust_logistic_best_param, robust_logistic_best_score = logistic_model(rX_train, rX_test, ry_train, ry_test)\n    robust_param_list.append(robust_logistic_best_param)\n    robust_score_list.append(robust_logistic_best_score)\n    robust_decision_best_param, robust_decision_best_score = decision_model(rX_train, rX_test, ry_train, ry_test)\n    robust_param_list.append(robust_decision_best_param)\n    robust_score_list.append(robust_decision_best_score)\n    robust_svm_best_param, robust_svm_best_score = svm_model(rX_train, rX_test, ry_train, ry_test)\n    robust_param_list.append(robust_svm_best_param)\n    robust_score_list.append(robust_svm_best_score)\n    robust_max_index = robust_score_list.index(max(robust_score_list))\n    print(\"Scaling Method: Robust Scaler\\nBest Model: {0}\\nBest Parameters: {1}\\nBest Score: {2}\"\n    .format(classifier_model_list[robust_max_index], robust_param_list[robust_max_index], robust_score_list[robust_max_index]))\n    total_model_list.append(classifier_model_list[robust_max_index])\n    total_param_list.append(robust_param_list[robust_max_index])\n    total_score_list.append(robust_score_list[robust_max_index])\n\n    print('\\n======================= Summary =======================')\n    total_max_index = total_score_list.index(max(total_score_list))\n    print(\"Scaling Method: {0}\\nBest Model: {1}\\nBest Parameters: {2}\\nBest Score: {3}\"\n    .format(scaler_list[total_max_index], total_model_list[total_max_index], total_param_list[total_max_index], total_score_list[total_max_index]))\n\n    for i in range(0, 3):\n        if i == 0 :\n            print('\\n================== Standard Scaler Evaluation ==================')\n            visual_confusion_roc(scaler_list[i], total_model_list[i], total_param_list[i], total_score_list[i], sX_train, sX_test, sy_train, sy_test)\n        elif i == 1 :\n            print('\\n================== MinMax Scaler Evaluation ==================')\n            visual_confusion_roc(scaler_list[i], total_model_list[i], total_param_list[i], total_score_list[i], mX_train, mX_test, my_train, my_test)\n        elif i == 2 :\n            print('\\n================== Robust Scaler Evaluation ==================')\n            visual_confusion_roc(scaler_list[i], total_model_list[i], total_param_list[i], total_score_list[i], rX_train, rX_test, ry_train, ry_test)\n        else :\n            print('Out of Range!')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}