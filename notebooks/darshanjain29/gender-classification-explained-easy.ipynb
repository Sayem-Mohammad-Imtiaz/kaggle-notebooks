{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dataframe = pd.read_csv(\"/kaggle/input/gender-classification/Transformed Data Set - Sheet1.csv\")\ndataframe.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's first rename the column names and remove bla","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframe.rename(columns={'Favorite Color' :'FavoriteColor', 'Favorite Music Genre':'FavoriteMusicGenre', \n                          'Favorite Beverage':'FavoriteBeverage', 'Favorite Soft Drink':'FavoriteSoftDrink'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we see that all the columns are of type object, so we will have to bring them all in type numeric. We will use Label Encoding Technique.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n#Method 1 when we have all the columns as type object\nfrom sklearn.preprocessing import LabelEncoder\ndataframe.apply(LabelEncoder().fit_transform)\n'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Method 2 - when we have mixed type columns. Then fetch the list of column names of type object type programmatically  and then Label Encode them","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#Fetch features of type Object\nobjFeatures = dataframe.select_dtypes(include=\"object\").columns\n\n#Iterate a loop for features of type object\nfrom sklearn import preprocessing\nle = preprocessing.LabelEncoder()\n\nfor feat in objFeatures:\n    dataframe[feat] = le.fit_transform(dataframe[feat].astype(str))\n    \ndataframe.info()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.countplot('FavoriteColor', hue='Gender', data=dataframe, palette='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframe.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = dataframe.drop(['Gender'], axis = 1)\ny = dataframe.Gender","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import confusion_matrix\n\ndef clf_scores(clf, y_predicted):\n    # Accuracy\n    acc_train = clf.score(X_train, y_train)*100\n    acc_test = clf.score(X_test, y_test)*100\n    \n    roc = roc_auc_score(y_test, y_predicted)*100 \n    tn, fp, fn, tp = confusion_matrix(y_test, y_predicted).ravel()\n    cm = confusion_matrix(y_test, y_predicted)\n    correct = tp + tn\n    incorrect = fp + fn\n    \n    return acc_train, acc_test, roc, correct, incorrect, cm\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#1. Logistic regression\n\nfrom sklearn.linear_model import LogisticRegression\nclf_lr = LogisticRegression()\nclf_lr.fit(X_train, y_train)\n\nY_pred_lr = clf_lr.predict(X_test)\nprint(clf_scores(clf_lr, Y_pred_lr))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#2. KNN\n\nfrom sklearn.neighbors import KNeighborsClassifier\nclf_knn = KNeighborsClassifier(n_neighbors=3)\nclf_knn.fit(X_train, y_train)\n\nY_pred_knn = clf_knn.predict(X_test)\nprint(clf_scores(clf_knn, Y_pred_knn))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#3. Naive Bayes\n\nfrom sklearn.naive_bayes import GaussianNB\nclf_gnb = GaussianNB()\nclf_gnb.fit(X_train, y_train)\n\nY_pred_gnb = clf_gnb.predict(X_test)\nprint(clf_scores(clf_gnb, Y_pred_gnb))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#4. SVM \nfrom sklearn.svm import SVC\n\nclf_svm = SVC()\nclf_svm.fit(X_train, y_train)\n\nY_pred_svm = clf_svm.predict(X_test)\nprint(clf_scores(clf_svm, Y_pred_svm))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#5. Decision tree\nfrom sklearn.tree import DecisionTreeClassifier\n\nclf_dt = DecisionTreeClassifier(random_state=0)\nclf_dt.fit(X_train, y_train)\nclf_dt.fit(X_train, y_train)\n\nY_pred_dt = clf_dt.predict(X_test)\nprint(clf_scores(clf_dt, Y_pred_dt))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#6. Radom forest classifier\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nclf_rfc = RandomForestClassifier(max_depth=10, random_state=42)\nclf_rfc.fit(X_train, y_train)\n\nY_pred_rfc = clf_rfc.predict(X_test)\nprint(clf_scores(clf_rfc, Y_pred_rfc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#7. Gradient boosting classifier\n\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nclf_gbc = GradientBoostingClassifier(random_state=42)\nclf_gbc.fit(X_train, y_train)\n\nY_pred_gbc = clf_gbc.predict(X_test)\nprint(clf_scores(clf_gbc, Y_pred_gbc))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}