{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport tensorflow_addons as tfa\n\nimport matplotlib.pyplot as plt\nimport re\n\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-04T10:58:24.646916Z","iopub.execute_input":"2021-09-04T10:58:24.647278Z","iopub.status.idle":"2021-09-04T10:58:24.663011Z","shell.execute_reply.started":"2021-09-04T10:58:24.647245Z","shell.execute_reply":"2021-09-04T10:58:24.66197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE_NO_CROP = 128  # Size of image before cropping\nIMAGE_SIZE = 64  # Shapes of input image\nBATCH_SIZE = 64  # Batch size\nDATA_PATH = \"/kaggle/input/celeba-dataset/img_align_celeba\"\nRANDOM_SEED = 42\n\nZ_DIM = 128  # Dimension of face's manifold\nGENERATOR_DENSE_SIZE = 512\nOUTPUT_CHANNELS = 3\n\ntf.random.set_seed(RANDOM_SEED)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T10:58:24.66537Z","iopub.execute_input":"2021-09-04T10:58:24.665796Z","iopub.status.idle":"2021-09-04T10:58:24.672716Z","shell.execute_reply.started":"2021-09-04T10:58:24.665717Z","shell.execute_reply":"2021-09-04T10:58:24.671737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Checking available GPUs","metadata":{}},{"cell_type":"code","source":"print(tf.config.experimental.list_physical_devices(\"GPU\"))\nprint(tf.test.gpu_device_name())","metadata":{"execution":{"iopub.status.busy":"2021-09-04T10:58:24.675116Z","iopub.execute_input":"2021-09-04T10:58:24.675462Z","iopub.status.idle":"2021-09-04T10:58:24.690678Z","shell.execute_reply.started":"2021-09-04T10:58:24.675427Z","shell.execute_reply":"2021-09-04T10:58:24.689611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare dataset\n\nHere we will check and prepare our data. We need the faces only. Images in the dataset are centered on eyes, so we will crop faces utilizing that fact.\n\nI've found caching is extremely useful in this task. The whole dataset can be put into memory if you have >12GB RAM. Prefetching will also help us to utilize resources better.\n\nSometimes image_dataset_from_directory is slow as fuck. Also Kaggle won't let us to cache everything in memory and will kill the kernel during the training, that's frustrating.\n\nNevertheless training on the whole dataset will take some time (first epoch with BATCH_SIZE=64 takes ~1800 seconds to finish with GPU accelerator here, ~1300 seconds for BATCH_SIZE=512, after caching it's ~300 seconds per epoch).","metadata":{}},{"cell_type":"code","source":"num_images = len(os.listdir(os.path.join(DATA_PATH, \"img_align_celeba\")))\nprint(f\"Num images: {num_images}\")","metadata":{"execution":{"iopub.status.busy":"2021-09-04T10:58:24.692881Z","iopub.execute_input":"2021-09-04T10:58:24.693951Z","iopub.status.idle":"2021-09-04T10:58:24.846131Z","shell.execute_reply.started":"2021-09-04T10:58:24.693913Z","shell.execute_reply":"2021-09-04T10:58:24.845106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"celeb_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n    DATA_PATH,\n    label_mode=None,\n    color_mode=\"rgb\",\n    batch_size=BATCH_SIZE,\n    image_size=(IMAGE_SIZE_NO_CROP, IMAGE_SIZE_NO_CROP),\n    seed=RANDOM_SEED,\n)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T10:58:24.84834Z","iopub.execute_input":"2021-09-04T10:58:24.849372Z","iopub.status.idle":"2021-09-04T10:58:30.114416Z","shell.execute_reply.started":"2021-09-04T10:58:24.849331Z","shell.execute_reply":"2021-09-04T10:58:30.113633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CACHE_FILE = \"cache\"\n\ndef crop_face(image):\n    height, width = image.shape[1], image.shape[2]\n\n    offset_height = int(height * 0.35)\n    offset_width = int(height * 0.27)\n\n    image = tf.image.crop_to_bounding_box(\n        image, offset_height, offset_width, int(width * 0.45), int(height * 0.45)\n    )\n\n    return image\n\n\ndef process(image):\n    #     images are centered on eyes, we will crop faces utilizing that fact\n#     image = crop_face(image)\n#     image = tf.image.resize(image, [IMAGE_SIZE, IMAGE_SIZE], preserve_aspect_ratio=True)\n    image = tf.cast((image - 127.5) / 127.5, tf.float32)\n    return image\n\n\nceleb_dataset = (\n    celeb_dataset\n    .map(process)\n    .unbatch()\n    .shuffle(1024)\n    .repeat()\n    .batch(BATCH_SIZE, drop_remainder=True)\n    .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n#         .cache(filename=CACHE_FILE)\n)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T10:58:30.115955Z","iopub.execute_input":"2021-09-04T10:58:30.116345Z","iopub.status.idle":"2021-09-04T10:58:30.150264Z","shell.execute_reply.started":"2021-09-04T10:58:30.116307Z","shell.execute_reply":"2021-09-04T10:58:30.149255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_samples(ds, row, col):\n    ds_iter = iter(ds)\n    plt.figure(figsize=(15, int(15*row/col)))\n    for j in range(row*col):\n        example_sample = next(ds_iter)\n        plt.subplot(row,col,j+1)\n        plt.axis('off')\n        plt.imshow(example_sample * 0.5 + 0.5)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-04T11:17:04.663646Z","iopub.execute_input":"2021-09-04T11:17:04.664014Z","iopub.status.idle":"2021-09-04T11:17:04.67049Z","shell.execute_reply.started":"2021-09-04T11:17:04.663982Z","shell.execute_reply":"2021-09-04T11:17:04.669475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_samples(celeb_dataset.unbatch(), 4, 6)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T11:17:06.353636Z","iopub.execute_input":"2021-09-04T11:17:06.353976Z","iopub.status.idle":"2021-09-04T11:17:08.301317Z","shell.execute_reply.started":"2021-09-04T11:17:06.353948Z","shell.execute_reply":"2021-09-04T11:17:08.300013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generator","metadata":{}},{"cell_type":"code","source":"def down_sample(filters, size, apply_instancenorm=True):\n    initializer = tf.random_normal_initializer(0., 0.02)\n    gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n\n    layer = keras.Sequential()\n    layer.add(layers.Conv2D(filters, size, strides=2, padding='same', kernel_initializer=initializer, use_bias=False))\n\n    if apply_instancenorm:\n        layer.add(tfa.layers.InstanceNormalization(gamma_initializer=gamma_init))\n\n    layer.add(layers.LeakyReLU())\n\n    return layer\n\ndef up_sample(filters, size, apply_dropout=False):\n    initializer = tf.random_normal_initializer(0., 0.02)\n    gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n\n    layer = keras.Sequential()\n    layer.add(layers.Conv2DTranspose(filters, size, strides=2, padding='same', kernel_initializer=initializer,use_bias=False))\n    layer.add(tfa.layers.InstanceNormalization(gamma_initializer=gamma_init))\n\n    if apply_dropout:\n        layer.add(layers.Dropout(0.5))\n\n    layer.add(layers.ReLU())\n\n    return layer","metadata":{"execution":{"iopub.status.busy":"2021-09-04T11:17:18.622774Z","iopub.execute_input":"2021-09-04T11:17:18.623087Z","iopub.status.idle":"2021-09-04T11:17:18.631759Z","shell.execute_reply.started":"2021-09-04T11:17:18.623058Z","shell.execute_reply":"2021-09-04T11:17:18.63069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Generator():\n    inputs = layers.Input(shape=(Z_DIM, ))\n\n    up_stack = [\n        layers.Dense(4 * 4 * GENERATOR_DENSE_SIZE, use_bias=False),\n        layers.BatchNormalization(),\n        layers.LeakyReLU(),\n        layers.Reshape((4, 4, GENERATOR_DENSE_SIZE)),# (size, 4, 4, 512)\n        up_sample(512, 4, apply_dropout=True),       # (size, 8, 8, 512)\n        up_sample(256, 4, apply_dropout=True),       # (size, 16, 16, 256)\n        up_sample(128, 4),                           # (size, 32, 32, 128)\n        up_sample(64, 4),                            # (size, 64, 64, 64)\n    ]\n    \n    initializer = tf.random_normal_initializer(0., 0.02)\n    last = layers.Conv2DTranspose(3, 4, strides=2, padding='same', kernel_initializer=initializer, activation='tanh') \n    # (size, 128, 128, 3)\n\n    x = inputs\n\n    # Upsampling and establishing the skip connections\n    for up in up_stack:\n        x = up(x)\n\n    x = last(x)\n\n    return keras.Model(inputs=inputs, outputs=x)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T11:17:18.664476Z","iopub.execute_input":"2021-09-04T11:17:18.664739Z","iopub.status.idle":"2021-09-04T11:17:18.671917Z","shell.execute_reply.started":"2021-09-04T11:17:18.664714Z","shell.execute_reply":"2021-09-04T11:17:18.670946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Headless discriminator (shared part)","metadata":{}},{"cell_type":"code","source":"def Discriminator():\n    initializer = tf.random_normal_initializer(0., 0.02)\n    gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n    \n    inp = layers.Input(shape=[128, 128, 3], name='input_image')\n    x = inp\n    \n    down1 = down_sample(64, 4, False)(x)       # (size, 64, 64, 64)\n    down2 = down_sample(128, 4)(down1)         # (size, 32, 32, 128)\n    down3 = down_sample(256, 4)(down2)         # (size, 16, 16, 256)\n\n    zero_pad1 = layers.ZeroPadding2D()(down3) # (size, 18, 18, 256)\n    conv = layers.Conv2D(512, 4, strides=1, kernel_initializer=initializer, use_bias=False)(zero_pad1) # (size, 15, 15, 512)\n\n    norm1 = tfa.layers.InstanceNormalization(gamma_initializer=gamma_init)(conv)\n    leaky_relu = layers.LeakyReLU()(norm1)\n    zero_pad2 = layers.ZeroPadding2D()(leaky_relu) # (size, 17, 17, 512)\n\n    return tf.keras.Model(inputs=inp, outputs=zero_pad2)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T11:17:18.673972Z","iopub.execute_input":"2021-09-04T11:17:18.675066Z","iopub.status.idle":"2021-09-04T11:17:18.684849Z","shell.execute_reply.started":"2021-09-04T11:17:18.67503Z","shell.execute_reply":"2021-09-04T11:17:18.683988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Head for two-objective discriminator","metadata":{}},{"cell_type":"code","source":"def DHead():\n    initializer = tf.random_normal_initializer(0., 0.02)\n    \n    inp = layers.Input(shape=[17, 17, 512], name='input_image')\n    x = inp\n    \n    last = layers.Conv2D(1, 4, strides=1, kernel_initializer=initializer)(x) # (size, 14, 14, 1)\n\n    return tf.keras.Model(inputs=inp, outputs=last)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T11:17:18.717225Z","iopub.execute_input":"2021-09-04T11:17:18.718076Z","iopub.status.idle":"2021-09-04T11:17:18.724212Z","shell.execute_reply.started":"2021-09-04T11:17:18.71804Z","shell.execute_reply":"2021-09-04T11:17:18.723272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator = Generator() \ndiscriminator = Discriminator() # differentiates real images and generated images\ndHead1 = DHead() # Head for BCE\ndHead2 = DHead() # Head for hinge loss","metadata":{"execution":{"iopub.status.busy":"2021-09-04T11:17:18.806054Z","iopub.execute_input":"2021-09-04T11:17:18.806319Z","iopub.status.idle":"2021-09-04T11:17:19.744066Z","shell.execute_reply.started":"2021-09-04T11:17:18.806295Z","shell.execute_reply":"2021-09-04T11:17:19.743249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DCGAN with 2-objective discriminator","metadata":{}},{"cell_type":"code","source":"class DCGan(tf.keras.Model):\n    def __init__(\n        self,\n        generator,\n        discriminator,\n        dhead1,        \n        dhead2\n    ):\n        super(DCGan, self).__init__()\n        self.gen = generator\n        self.disc = discriminator\n        self.dhead1 = dhead1\n        self.dhead2 = dhead2\n        \n    def compile(\n        self,\n        gen_optimizer,\n        disc_optimizer,\n        gen_loss_fn1,\n        gen_loss_fn2,\n        disc_loss_fn1,\n        disc_loss_fn2,\n        aug_fn\n    ):\n        super(DCGan, self).compile()\n        self.gen_optimizer = gen_optimizer\n        self.disc_optimizer = disc_optimizer\n        self.gen_loss_fn1 = gen_loss_fn1\n        self.gen_loss_fn2 = gen_loss_fn2\n        self.disc_loss_fn1 = disc_loss_fn1\n        self.disc_loss_fn2 = disc_loss_fn2\n        self.aug_fn = aug_fn\n\n        self.step_num = 0\n        \n    def train_step(self, real_image):\n        batch_size = tf.shape(real_image)[0]\n        noise = tf.random.uniform([batch_size, Z_DIM])\n        \n        with tf.GradientTape(persistent=True) as tape:\n        \n            # generates fake images from generator\n            fake_image = self.gen(noise, training=True)\n\n            # Diffaugment\n            both_image = tf.concat([real_image, fake_image], axis=0)            \n            \n            aug_image = self.aug_fn(both_image)\n            \n            aug_real_image = aug_image[:batch_size]\n            aug_fake_image = aug_image[batch_size:]\n            \n            \n            # two-objective discriminator\n            disc_fake_image1 = self.dhead1(self.disc(aug_fake_image, training=True), training=True)\n            disc_real_image1 = self.dhead1(self.disc(aug_real_image, training=True), training=True)\n            disc_fake_image2 = self.dhead2(self.disc(aug_fake_image, training=True), training=True)\n            disc_real_image2 = self.dhead2(self.disc(aug_real_image, training=True), training=True)\n\n            gen_loss1 = self.gen_loss_fn1(disc_fake_image1) \n            head_loss1 = self.disc_loss_fn1(disc_real_image1, disc_fake_image1)\n            gen_loss2 = self.gen_loss_fn2(disc_fake_image2)\n            head_loss2 = self.disc_loss_fn2(disc_real_image2, disc_fake_image2)\n\n            total_gen_loss = (gen_loss1 + gen_loss2) * 0.4\n            total_disc_loss = head_loss1 + head_loss2\n\n        # Calculate the gradients for generator and discriminator\n        generator_gradients = tape.gradient(total_gen_loss, \n                                            self.gen.trainable_variables)\n\n        discriminator_gradients = tape.gradient(total_disc_loss, \n                                                self.disc.trainable_variables)\n        \n\n        # Heads gradients\n        head_gradients1 = tape.gradient(head_loss1, \n                                        self.dhead1.trainable_variables)\n\n        self.disc_optimizer.apply_gradients(zip(head_gradients1,\n                                                  self.dhead1.trainable_variables))       \n\n        head_gradients2 = tape.gradient(head_loss2, \n                                        self.dhead2.trainable_variables)\n        self.disc_optimizer.apply_gradients(zip(head_gradients2, \n                                                  self.dhead2.trainable_variables))     \n        \n        \n        \n        # Apply the gradients to the optimizer\n        self.gen_optimizer.apply_gradients(zip(generator_gradients,\n                                                 self.gen.trainable_variables))\n\n        self.disc_optimizer.apply_gradients(zip(discriminator_gradients, \n                                                self.disc.trainable_variables))\n        \n        return {\n            \"head_loss1\": head_loss1, \n            \"head_loss2\": head_loss2, \n            \"disc_real_image\": disc_real_image1, \n            \"disc_fake_image\": disc_fake_image1, \n            \"disc_real_image2\": disc_real_image2, \n            \"disc_fake_image2\": disc_fake_image2, \n            \"gen_loss\": total_gen_loss, \n            \"disc_loss\": total_disc_loss\n            }\n","metadata":{"execution":{"iopub.status.busy":"2021-09-04T11:17:19.745607Z","iopub.execute_input":"2021-09-04T11:17:19.746067Z","iopub.status.idle":"2021-09-04T11:17:19.766675Z","shell.execute_reply.started":"2021-09-04T11:17:19.746029Z","shell.execute_reply":"2021-09-04T11:17:19.765439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def discriminator_loss1(real, generated):\n    real_loss = tf.math.maximum(tf.zeros_like(real), tf.ones_like(real) - real)\n\n    generated_loss = tf.math.maximum(tf.zeros_like(generated), generated + tf.ones_like(generated))\n\n    total_disc_loss = real_loss + generated_loss\n\n    return tf.reduce_mean(total_disc_loss * 0.5)\n\ndef discriminator_loss2(real, generated):\n    generated_loss = tf.keras.losses.BinaryCrossentropy(\n        from_logits=True, \n        reduction=tf.keras.losses.Reduction.NONE, \n        label_smoothing=0.05)(tf.ones_like(generated), generated)\n    real_loss = tf.keras.losses.BinaryCrossentropy(\n        from_logits=True, \n        reduction=tf.keras.losses.Reduction.NONE, \n        label_smoothing=0.05)(tf.zeros_like(real), real)\n    total_disc_loss = real_loss + generated_loss\n\n    return tf.reduce_mean(total_disc_loss * 0.5)\n\ndef generator_loss1(generated):\n    return  tf.reduce_mean(-generated)\n\ndef generator_loss2(generated):\n    return tf.reduce_mean(tf.keras.losses.BinaryCrossentropy(\n        from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(tf.zeros_like(generated), generated))","metadata":{"execution":{"iopub.status.busy":"2021-09-04T11:17:19.769092Z","iopub.execute_input":"2021-09-04T11:17:19.769484Z","iopub.status.idle":"2021-09-04T11:17:19.782399Z","shell.execute_reply.started":"2021-09-04T11:17:19.769445Z","shell.execute_reply":"2021-09-04T11:17:19.781286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Differentiable Augmentation for Data-Efficient GAN Training\n# Shengyu Zhao, Zhijian Liu, Ji Lin, Jun-Yan Zhu, and Song Han\n# https://arxiv.org/pdf/2006.10738\n# from https://github.com/mit-han-lab/data-efficient-gans/blob/master/DiffAugment_tf.py\n\n\ndef DiffAugment(x, policy='', channels_first=False):\n    if policy:\n        if channels_first:\n            x = tf.transpose(x, [0, 2, 3, 1])\n        for p in policy.split(','):\n            for f in AUGMENT_FNS[p]:\n                x = f(x)\n        if channels_first:\n            x = tf.transpose(x, [0, 3, 1, 2])\n    return x\n\n\ndef rand_brightness(x):\n    magnitude = tf.random.uniform([tf.shape(x)[0], 1, 1, 1]) - 0.5\n    x = x + magnitude\n    return x\n\n\ndef rand_saturation(x):\n    magnitude = tf.random.uniform([tf.shape(x)[0], 1, 1, 1]) * 2\n    x_mean = tf.reduce_sum(x, axis=3, keepdims=True) * 0.3333333333333333333\n    x = (x - x_mean) * magnitude + x_mean\n    return x\n\n\ndef rand_contrast(x):\n    magnitude = tf.random.uniform([tf.shape(x)[0], 1, 1, 1]) + 0.5\n    x_mean = tf.reduce_sum(x, axis=[1, 2, 3], keepdims=True) * 5.086e-6\n    x = (x - x_mean) * magnitude + x_mean\n    return x\n\ndef rand_translation(x, ratio=0.125):\n    batch_size = tf.shape(x)[0]\n    image_size = tf.shape(x)[1:3]\n    shift = tf.cast(tf.cast(image_size, tf.float32) * ratio + 0.5, tf.int32)\n    translation_x = tf.random.uniform([batch_size, 1], -shift[0], shift[0] + 1, dtype=tf.int32)\n    translation_y = tf.random.uniform([batch_size, 1], -shift[1], shift[1] + 1, dtype=tf.int32)\n    grid_x = tf.clip_by_value(tf.expand_dims(tf.range(image_size[0], dtype=tf.int32), 0) + translation_x + 1, 0, image_size[0] + 1)\n    grid_y = tf.clip_by_value(tf.expand_dims(tf.range(image_size[1], dtype=tf.int32), 0) + translation_y + 1, 0, image_size[1] + 1)\n    x = tf.gather_nd(tf.pad(x, [[0, 0], [1, 1], [0, 0], [0, 0]]), tf.expand_dims(grid_x, -1), batch_dims=1)\n    x = tf.transpose(tf.gather_nd(tf.pad(tf.transpose(x, [0, 2, 1, 3]), [[0, 0], [1, 1], [0, 0], [0, 0]]), tf.expand_dims(grid_y, -1), batch_dims=1), [0, 2, 1, 3])\n    return x\n\n\ndef rand_cutout(x, ratio=0.5):\n    batch_size = tf.shape(x)[0]\n    image_size = tf.shape(x)[1:3]\n    cutout_size = tf.cast(tf.cast(image_size, tf.float32) * ratio + 0.5, tf.int32)\n    offset_x = tf.random.uniform([tf.shape(x)[0], 1, 1], maxval=image_size[0] + (1 - cutout_size[0] % 2), dtype=tf.int32)\n    offset_y = tf.random.uniform([tf.shape(x)[0], 1, 1], maxval=image_size[1] + (1 - cutout_size[1] % 2), dtype=tf.int32)\n    grid_batch, grid_x, grid_y = tf.meshgrid(tf.range(batch_size, dtype=tf.int32), tf.range(cutout_size[0], dtype=tf.int32), tf.range(cutout_size[1], dtype=tf.int32), indexing='ij')\n    cutout_grid = tf.stack([grid_batch, grid_x + offset_x - cutout_size[0] // 2, grid_y + offset_y - cutout_size[1] // 2], axis=-1)\n    mask_shape = tf.stack([batch_size, image_size[0], image_size[1]])\n    cutout_grid = tf.maximum(cutout_grid, 0)\n    cutout_grid = tf.minimum(cutout_grid, tf.reshape(mask_shape - 1, [1, 1, 1, 3]))\n    mask = tf.maximum(1 - tf.scatter_nd(cutout_grid, tf.ones([batch_size, cutout_size[0], cutout_size[1]], dtype=tf.float32), mask_shape), 0)\n    x = x * tf.expand_dims(mask, axis=3)\n    return x\n\n\nAUGMENT_FNS = {\n    'color': [rand_brightness, rand_saturation, rand_contrast],\n    'translation': [rand_translation],\n    'cutout': [rand_cutout],\n}\ndef aug_fn(image):\n    return DiffAugment(image,\"color,translation,cutout\")","metadata":{"execution":{"iopub.status.busy":"2021-09-04T11:17:19.784775Z","iopub.execute_input":"2021-09-04T11:17:19.785195Z","iopub.status.idle":"2021-09-04T11:17:19.819429Z","shell.execute_reply.started":"2021-09-04T11:17:19.78513Z","shell.execute_reply":"2021-09-04T11:17:19.818527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T11:17:19.821217Z","iopub.execute_input":"2021-09-04T11:17:19.821625Z","iopub.status.idle":"2021-09-04T11:17:19.832687Z","shell.execute_reply.started":"2021-09-04T11:17:19.82159Z","shell.execute_reply":"2021-09-04T11:17:19.831682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"EPOCHS = 30\nNUM_SAMPLES_TO_GENERATE = 8\nNUM_CHECKPOINT = 10\n\n\n# You will reuse this seed overtime (so it's easier)\n# to visualize progress in the animated GIF)\nseed = tf.random.uniform([NUM_SAMPLES_TO_GENERATE, Z_DIM])","metadata":{"execution":{"iopub.status.busy":"2021-09-04T11:17:19.834497Z","iopub.execute_input":"2021-09-04T11:17:19.834927Z","iopub.status.idle":"2021-09-04T11:17:19.842292Z","shell.execute_reply.started":"2021-09-04T11:17:19.834893Z","shell.execute_reply":"2021-09-04T11:17:19.841422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_and_save_images(model, epoch, test_input):\n    # Notice `training` is set to False.\n    # This is so all layers run in inference mode (batchnorm).\n    predictions = model(test_input, training=False)\n\n    fig = plt.figure(figsize=(8, 4), constrained_layout=True)\n\n    for i in range(predictions.shape[0]):\n        plt.subplot(2, 4, i + 1)\n        plt.imshow((predictions[i].numpy() * 127.5 + 127.5).astype(\"uint8\"))\n        plt.axis(\"off\")\n\n    plt.savefig(\"image_at_epoch_{:04d}.png\".format(epoch))\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-04T11:17:19.844046Z","iopub.execute_input":"2021-09-04T11:17:19.845023Z","iopub.status.idle":"2021-09-04T11:17:19.853437Z","shell.execute_reply.started":"2021-09-04T11:17:19.844986Z","shell.execute_reply":"2021-09-04T11:17:19.852366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CheckpointCallback(tf.keras.callbacks.Callback):\n    def __init__(self, manager):\n        super(CheckpointCallback, self).__init__()\n        self.manager = manager\n\n    def on_epoch_end(self, epoch, logs=None):\n        self.manager.save()\n        \nclass SampleTestCallback(tf.keras.callbacks.Callback):\n    def __init__(self, test_sample, num_epoch):\n        super(SampleTestCallback, self).__init__()\n        self.test_sample = test_sample\n        self.num_epoch = num_epoch\n\n    def on_epoch_end(self, epoch, logs=None):\n        if epoch % self.num_epoch == 0:\n            generate_and_save_images(self.model.gen, epoch, self.test_sample)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T11:17:19.856347Z","iopub.execute_input":"2021-09-04T11:17:19.857407Z","iopub.status.idle":"2021-09-04T11:17:19.866794Z","shell.execute_reply.started":"2021-09-04T11:17:19.857371Z","shell.execute_reply":"2021-09-04T11:17:19.865794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dc_gan_model = DCGan(\n        generator, discriminator, dHead1,  dHead2\n    )","metadata":{"execution":{"iopub.status.busy":"2021-09-04T11:17:19.868622Z","iopub.execute_input":"2021-09-04T11:17:19.869538Z","iopub.status.idle":"2021-09-04T11:17:19.881445Z","shell.execute_reply.started":"2021-09-04T11:17:19.86948Z","shell.execute_reply":"2021-09-04T11:17:19.880452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dc_gan_model.compile(\n    gen_optimizer = generator_optimizer,\n    disc_optimizer = discriminator_optimizer,\n    gen_loss_fn1 = generator_loss1,\n    gen_loss_fn2 = generator_loss2,\n    disc_loss_fn1 = discriminator_loss1,\n    disc_loss_fn2 = discriminator_loss2,\n    aug_fn = aug_fn ,\n)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T11:17:19.883249Z","iopub.execute_input":"2021-09-04T11:17:19.884037Z","iopub.status.idle":"2021-09-04T11:17:19.9062Z","shell.execute_reply.started":"2021-09-04T11:17:19.884002Z","shell.execute_reply":"2021-09-04T11:17:19.905404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_path = \"./\"\nckpt = tf.train.Checkpoint(\n    generator_optimizer=generator_optimizer,\n    discriminator_optimizer=discriminator_optimizer,\n    generator=dc_gan_model.gen,\n    discriminator=dc_gan_model.disc,\n    dhead1=dc_gan_model.dhead1,\n    dhead2=dc_gan_model.dhead2\n)\nckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=3)\n\n# if a checkpoint exists, restore the latest checkpoint.\nif ckpt_manager.latest_checkpoint:\n    ckpt.restore(ckpt_manager.latest_checkpoint)\n    print ('Latest checkpoint restored!!')","metadata":{"execution":{"iopub.status.busy":"2021-09-04T11:17:19.907555Z","iopub.execute_input":"2021-09-04T11:17:19.908311Z","iopub.status.idle":"2021-09-04T11:17:19.91582Z","shell.execute_reply.started":"2021-09-04T11:17:19.908276Z","shell.execute_reply":"2021-09-04T11:17:19.914923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_cb = CheckpointCallback(ckpt_manager)\ntest_cb = SampleTestCallback(seed, 1)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T11:17:19.917706Z","iopub.execute_input":"2021-09-04T11:17:19.918735Z","iopub.status.idle":"2021-09-04T11:17:19.928013Z","shell.execute_reply.started":"2021-09-04T11:17:19.918671Z","shell.execute_reply":"2021-09-04T11:17:19.927127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dc_gan_model.fit(celeb_dataset, epochs=EPOCHS, steps_per_epoch=3165, callbacks=[checkpoint_cb, test_cb])","metadata":{"execution":{"iopub.status.busy":"2021-09-04T11:17:19.929716Z","iopub.execute_input":"2021-09-04T11:17:19.930831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}