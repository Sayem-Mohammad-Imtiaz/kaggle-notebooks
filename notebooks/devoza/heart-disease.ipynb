{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Heart Disease Prediction\n\nIn this machine learning project, I have collected the dataset from Kaggle (https://www.kaggle.com/ronitf/heart-disease-uci) and I will be using Machine Learning to predict whether any person is suffering from heart disease","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib import rcParams\nfrom matplotlib.cm import rainbow\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2021-08-11T16:05:58.722932Z","iopub.execute_input":"2021-08-11T16:05:58.72339Z","iopub.status.idle":"2021-08-11T16:05:58.739752Z","shell.execute_reply.started":"2021-08-11T16:05:58.723356Z","shell.execute_reply":"2021-08-11T16:05:58.738233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/heart-disease-uci/heart.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-11T16:05:58.741771Z","iopub.execute_input":"2021-08-11T16:05:58.74225Z","iopub.status.idle":"2021-08-11T16:05:58.760607Z","shell.execute_reply.started":"2021-08-11T16:05:58.742204Z","shell.execute_reply":"2021-08-11T16:05:58.75959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-08-11T16:05:58.762159Z","iopub.execute_input":"2021-08-11T16:05:58.762634Z","iopub.status.idle":"2021-08-11T16:05:58.781404Z","shell.execute_reply.started":"2021-08-11T16:05:58.762599Z","shell.execute_reply":"2021-08-11T16:05:58.780389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-08-11T16:05:58.782665Z","iopub.execute_input":"2021-08-11T16:05:58.782979Z","iopub.status.idle":"2021-08-11T16:05:58.847734Z","shell.execute_reply.started":"2021-08-11T16:05:58.782949Z","shell.execute_reply":"2021-08-11T16:05:58.846665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Selection","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\n#get correlations of each features in dataset\ncorrmat = df.corr()\ntop_corr_features = corrmat.index\nplt.figure(figsize=(20,20))\n#plot heat map\ng=sns.heatmap(df[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")","metadata":{"execution":{"iopub.status.busy":"2021-08-11T16:05:58.849935Z","iopub.execute_input":"2021-08-11T16:05:58.850309Z","iopub.status.idle":"2021-08-11T16:06:00.481137Z","shell.execute_reply.started":"2021-08-11T16:05:58.850277Z","shell.execute_reply":"2021-08-11T16:06:00.479975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.hist()","metadata":{"execution":{"iopub.status.busy":"2021-08-11T16:06:00.482786Z","iopub.execute_input":"2021-08-11T16:06:00.48316Z","iopub.status.idle":"2021-08-11T16:06:02.782386Z","shell.execute_reply.started":"2021-08-11T16:06:00.483125Z","shell.execute_reply":"2021-08-11T16:06:02.780967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It's always a good practice to work with a dataset where the target classes are of approximately equal size. Thus, let's check for the same.","metadata":{}},{"cell_type":"code","source":"sns.set_style('whitegrid')\nsns.countplot(x='target',data=df,palette='RdBu_r')","metadata":{"execution":{"iopub.status.busy":"2021-08-11T16:06:02.784336Z","iopub.execute_input":"2021-08-11T16:06:02.784864Z","iopub.status.idle":"2021-08-11T16:06:02.958744Z","shell.execute_reply.started":"2021-08-11T16:06:02.784783Z","shell.execute_reply":"2021-08-11T16:06:02.957804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Processing\n\nAfter exploring the dataset, I observed that I need to convert some categorical variables into dummy variables and scale all the values before training the Machine Learning models.\nFirst, I'll use the `get_dummies` method to create dummy columns for categorical variables.","metadata":{}},{"cell_type":"code","source":"dataset = pd.get_dummies(df, columns = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal'])","metadata":{"execution":{"iopub.status.busy":"2021-08-11T16:06:02.960204Z","iopub.execute_input":"2021-08-11T16:06:02.960527Z","iopub.status.idle":"2021-08-11T16:06:02.976058Z","shell.execute_reply.started":"2021-08-11T16:06:02.960496Z","shell.execute_reply":"2021-08-11T16:06:02.974942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nstandardScaler = StandardScaler()\ncolumns_to_scale = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\ndataset[columns_to_scale] = standardScaler.fit_transform(dataset[columns_to_scale])","metadata":{"execution":{"iopub.status.busy":"2021-08-11T16:06:02.977875Z","iopub.execute_input":"2021-08-11T16:06:02.97825Z","iopub.status.idle":"2021-08-11T16:06:02.995458Z","shell.execute_reply.started":"2021-08-11T16:06:02.978201Z","shell.execute_reply":"2021-08-11T16:06:02.994306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-11T16:06:02.998645Z","iopub.execute_input":"2021-08-11T16:06:02.999256Z","iopub.status.idle":"2021-08-11T16:06:03.028251Z","shell.execute_reply.started":"2021-08-11T16:06:02.999215Z","shell.execute_reply":"2021-08-11T16:06:03.027004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = dataset['target']\nX = dataset.drop(['target'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T16:06:03.029764Z","iopub.execute_input":"2021-08-11T16:06:03.030199Z","iopub.status.idle":"2021-08-11T16:06:03.046315Z","shell.execute_reply.started":"2021-08-11T16:06:03.030167Z","shell.execute_reply":"2021-08-11T16:06:03.045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random Forest Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.model_selection import cross_val_score","metadata":{"execution":{"iopub.status.busy":"2021-08-11T16:06:03.048021Z","iopub.execute_input":"2021-08-11T16:06:03.048679Z","iopub.status.idle":"2021-08-11T16:06:03.062124Z","shell.execute_reply.started":"2021-08-11T16:06:03.048629Z","shell.execute_reply":"2021-08-11T16:06:03.060985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = RandomForestClassifier(n_estimators=50)\ntrain_X, val_X, train_y, val_y = train_test_split(X, y,test_size=0.2,random_state=100)\nmodel.fit(train_X, train_y)\npred = model.predict(val_X)\nac = accuracy_score(val_y,pred)\nprint(ac)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T16:11:35.941231Z","iopub.execute_input":"2021-08-11T16:11:35.941609Z","iopub.status.idle":"2021-08-11T16:11:36.067684Z","shell.execute_reply.started":"2021-08-11T16:11:35.941574Z","shell.execute_reply":"2021-08-11T16:11:36.066339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"randomforest_classifier= RandomForestClassifier(n_estimators=100)\nscore=cross_val_score(randomforest_classifier,X,y,cv=10)\nprint(score)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T16:15:11.89139Z","iopub.execute_input":"2021-08-11T16:15:11.891762Z","iopub.status.idle":"2021-08-11T16:15:14.055432Z","shell.execute_reply.started":"2021-08-11T16:15:11.891732Z","shell.execute_reply":"2021-08-11T16:15:14.054326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score.mean()","metadata":{"execution":{"iopub.status.busy":"2021-08-11T16:07:00.686141Z","iopub.execute_input":"2021-08-11T16:07:00.686765Z","iopub.status.idle":"2021-08-11T16:07:00.6934Z","shell.execute_reply.started":"2021-08-11T16:07:00.686716Z","shell.execute_reply":"2021-08-11T16:07:00.692106Z"},"trusted":true},"execution_count":null,"outputs":[]}]}