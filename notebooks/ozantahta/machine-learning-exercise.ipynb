{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/biomechanical-features-of-orthopedic-patients/column_3C_weka.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.plot(subplots=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"class\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns[data.isnull().any()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"normal = data[data[\"class\"]==\"Normal\"]\nnormal","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Linear Regression\ny = normal.iloc[:,0].values.reshape(-1,1)\nx = normal.iloc[:,1].values.reshape(-1,1)\n\n# import library\nfrom sklearn.linear_model import LinearRegression\n\nlinear_regression = LinearRegression()\nlinear_regression.fit(x,y)\n\nb0 = linear_regression.intercept_\nb1 = linear_regression.coef_\n\ny_head = linear_regression.predict(x)\n\nprint(\"Predict 40: \",linear_regression.predict([[40]]))\n\nplt.figure(figsize=(9,9))\nplt.scatter(x,y,color = \"green\")\nplt.plot(x,y_head,color = \"red\")\nplt.xlabel(\"Pelvic Tilt\")\nplt.ylabel(\"Pelvic Incidence\")\nplt.show()\nfrom sklearn.metrics import r2_score\nprint(\"r2_score: \",r2_score(y,y_head))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import dataframe\nx1 = normal.loc[:,[\"pelvic_tilt\",\"lumbar_lordosis_angle\"]].values\n\n# Multiple Linear Regression\nmultiple_linear_reg = LinearRegression()\nmultiple_linear_reg.fit(x1,y)\n\n\n\n\nprint(\"Multiple Predict (pelvic_incidence) -> 40 and (lumbar_lordosis_angle) -> 26 [pelvic_tilt]:\",multiple_linear_reg.predict(np.array([[40,26]])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"first_filter = normal[\"pelvic_incidence\"] > 38\nsecond_filter = normal[\"pelvic_incidence\"] < 41\nthird_filter = normal[\"lumbar_lordosis_angle\"] < 40\nfourth_filter = normal[\"lumbar_lordosis_angle\"] > 10\nnormal[first_filter & second_filter & third_filter & fourth_filter]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x2 = normal.loc[:,[\"lumbar_lordosis_angle\"]].values\n\nlinear_reg2 = LinearRegression()\nlinear_reg2.fit(x2,y)\n\ny2_head = linear_reg2.predict(x2)\n\nplt.figure(figsize = (9,9))\nplt.scatter(x,y,color = \"purple\",label = \"pelvic_incidence\")\nplt.scatter(x2,y,color = \"yellow\",label = \"lumbar_lordosis_angle\")\nplt.plot(x,y_head,color = \"red\",label = \"pelvic_incidence_label\")\nplt.plot(x2,y2_head,color = \"red\",label = \"lumbar_lordosis_angle_label\")\nplt.legend()\nplt.show()\nfrom sklearn.metrics import r2_score\nprint(\"r2_score: \",r2_score(y,y2_head))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"normal_sort = normal.sort_values(by = \"pelvic_tilt\")\nnormal_sort","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = normal_sort.iloc[:,0].values.reshape(-1,1)\nx = normal_sort.iloc[:,1].values.reshape(-1,1)\n\n\nlinear_reg3 = LinearRegression()\nlinear_reg3.fit(x,y)\ny_head3 = linear_reg3.predict(x)\nplt.figure(figsize = (7,7))\nplt.scatter(x,y)\nplt.plot(x,y_head3,color=\"red\")\n\nfrom sklearn.preprocessing import PolynomialFeatures\n\npoly_reg = PolynomialFeatures(degree = 3)\nx_poly = poly_reg.fit_transform(x)\n\nlinear_reg4 = LinearRegression()\nlinear_reg4.fit(x_poly,y)\ny_head4 = linear_reg4.predict(x_poly)\nplt.plot(x,y_head4,color = \"yellow\")\nplt.xlabel(\"Pelvic Tilt\")\nplt.ylabel(\"Pelvic Incidence\")\nprint(linear_reg4.predict(poly_reg.fit_transform([[40]])))\nfrom sklearn.metrics import r2_score\nprint(\"r2_score: \",r2_score(y,y_head4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decision Tree\ny = normal_sort.iloc[:,0].values.reshape(-1,1)\nx = normal_sort.iloc[:,1].values.reshape(-1,1)\n\nfrom sklearn.tree import DecisionTreeRegressor\ntree_reg = DecisionTreeRegressor()\ntree_reg.fit(x,y)\n\narange = np.arange(min(x),max(x),0.01).reshape(-1,1)\ny_head5 = tree_reg.predict(arange)\n\nplt.figure(figsize = (9,9))\nplt.scatter(x,y,color=\"blue\")\nplt.plot(arange,y_head5,color = \"red\")\nplt.xlabel(\"Pelvic Tilt\")\nplt.ylabel(\"Pelvic Incidence\")\nprint(tree_reg.predict([[40]]))\nplt.show()\n\nfrom sklearn.metrics import r2_score\ny_head_other = tree_reg.predict(x)\nprint(\"r2_score: \",r2_score(y,y_head_other))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Forest\ny = normal_sort.iloc[:,0].values.reshape(-1,1)\nx = normal_sort.iloc[:,1].values.reshape(-1,1)\n\nfrom sklearn.ensemble import RandomForestRegressor\n\nrandom_forest = RandomForestRegressor(n_estimators=300, random_state = 42 ,max_depth= 30)\nrandom_forest.fit(x,y)\nprint(random_forest.predict([[40]]))\nx_ = np.arange(min(x),max(x),0.01).reshape(-1,1)\ny_head6 = random_forest.predict(x_)\nplt.figure(figsize=(9,9))\nplt.scatter(x,y,color=\"green\")\nplt.plot(x_,y_head6,color=\"red\")\nplt.show()\n\nfrom sklearn.metrics import r2_score\ny_head_other1 = random_forest.predict(x)\nprint(\"r2_score\",r2_score(y,y_head_other1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(\"class\",data=data)\nprint(data[\"class\"].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(data[\"class\"].value_counts().index,data[\"class\"].value_counts().values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"color_list = []\nfor i in data[\"class\"]:\n    if i == \"Hernia\":\n        color_list.append(\"blue\")\n    elif i == \"Normal\":\n        color_list.append(\"green\")\n    else:\n        color_list.append(\"red\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(color_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.plotting.scatter_matrix(data.iloc[:,data.columns!=\"class\"],\n                           figsize=(15,15),\n                            marker = \"-*-\",\n                            c = color_list,\n                            diagonal = \"hist\",\n                            s = 20,\n                            grid = True,\n                            alpha = 0.5, edgecolor = \"black\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_data = data.copy()\nnew_data.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_data[\"class\"] = [1 if i == \"Spondylolisthesis\" or i == \"Hernia\" else 0 for i in new_data[\"class\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_data[\"class\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_data = new_data.iloc[:,new_data.columns!=\"class\"].values\ny = new_data.loc[:,[\"class\"]].values\n\nx = (x_data-np.min(x_data))/(np.max(x_data)-np.min(x_data))\n\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3, random_state=1)\n\nfrom sklearn.neighbors import KNeighborsClassifier\narange = np.arange(1,30)\n\naccuracy_values = []\nfor i in arange:\n    KNN = KNeighborsClassifier(n_neighbors=i)\n    KNN.fit(x_train, y_train)\n    accuracy_values.append(KNN.score(x_test,y_test))\n    \nplt.figure(figsize = (9,9))\nplt.plot(arange,accuracy_values,color = \"blue\",label = \"Accuracy\")\nplt.show()\n\nprint(\"Maximum Accuracy Index: \",accuracy_values.index(max(accuracy_values)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(9,9))\nplt.scatter(new_data[new_data[\"class\"] == 1][\"pelvic_incidence\"].values,new_data[new_data[\"class\"] == 1][\"pelvic_radius\"].values,color = \"red\",label = \"BAD\")\nplt.scatter(new_data[new_data[\"class\"] == 0][\"pelvic_incidence\"].values,new_data[new_data[\"class\"] == 0][\"pelvic_radius\"].values,color = \"green\",label = \"GOOD\")\nplt.xlabel(\"pelvic_incidence\")\nplt.ylabel(\"pelvic_radius\")\nplt.legend()\nplt.show()\n\nfrom sklearn.neighbors import KNeighborsClassifier\nKNN = KNeighborsClassifier(n_neighbors=accuracy_values.index(max(accuracy_values))) # of course 12\nKNN.fit(x,y)\nprint(\"Accuracy Score: \", KNN.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_ = new_data[\"pelvic_incidence\"].values.reshape(-1,1)\ny_ = new_data[\"pelvic_radius\"].values.reshape(-1,1)\n\n\nfrom sklearn.ensemble import RandomForestRegressor\nrandom_for = RandomForestRegressor(n_estimators=100,random_state=42)\nrandom_for.fit(x_,y_)\ny_head = random_for.predict(x_)\n\ngrid = np.arange(min(x_),max(x_),0.01).reshape(-1,1)\n\nplt.figure(figsize=(9,9))\nplt.scatter(new_data[new_data[\"class\"] == 1][\"pelvic_incidence\"].values,new_data[new_data[\"class\"] == 1][\"pelvic_radius\"].values,color = \"red\",label = \"BAD\")\nplt.scatter(new_data[new_data[\"class\"] == 0][\"pelvic_incidence\"].values,new_data[new_data[\"class\"] == 0][\"pelvic_radius\"].values,color = \"green\",label = \"GOOD\")\nplt.plot(grid,random_for.predict(grid))\nplt.xlabel(\"pelvic_incidence\")\nplt.ylabel(\"pelvic_radius\")\nplt.legend()\nplt.show()\n\nfrom sklearn.metrics import r2_score\nprint(\"R^2 Score: \",r2_score(y_,random_for.predict(x_)))\n\nfrom sklearn.metrics import mean_squared_error\nprint('mean_squared_error: ',mean_squared_error(y_,random_for.predict(x_)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_data[new_data[\"class\"] == 1][\"pelvic_incidence\"].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.sample(6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = new_data[\"pelvic_incidence\"].values.reshape(-1,1)\ny = new_data[\"lumbar_lordosis_angle\"].values.reshape(-1,1)\n\nfrom sklearn.linear_model import LinearRegression\nlinear_reg = LinearRegression()\nlinear_reg.fit(x,y)\ny_head = linear_reg.predict(x)\n\n\nplt.figure(figsize = (8,8))\nplt.scatter(new_data[new_data[\"class\"] == 1][\"pelvic_incidence\"],new_data[new_data[\"class\"] == 1][\"lumbar_lordosis_angle\"],color=\"red\",label = \"BAD\")\nplt.scatter(new_data[new_data[\"class\"] == 0][\"pelvic_incidence\"],new_data[new_data[\"class\"] == 0][\"lumbar_lordosis_angle\"],color=\"green\",label = \"GOOD\")\nplt.plot(x,y_head,color=\"blue\",label = \"Linear Regression\")\nplt.xlabel(\"pelvic_incidence\")\nplt.ylabel(\"lumbar_lordosis_angle\")\nplt.legend()\nplt.show()\n\nfrom sklearn.metrics import r2_score\nprint(r2_score(y,y_head))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_data.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cross Validation\nfrom sklearn.model_selection import cross_val_score\nreg = LinearRegression()\nk = 5\ncv_result = cross_val_score(reg,x,y,cv = k)\nprint(\"CV Scores\",cv_result)\nprint(\"CV Scores Average: \",np.mean(cv_result))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ridge\nfrom sklearn.linear_model import Ridge\nx_train,x_test,y_train,y_test = train_test_split(x,y,random_state = 2, test_size = 0.3)\nridge = Ridge(alpha = 0.1, normalize = True)\nridge.fit(x_train,y_train)\nridge_predict = ridge.predict(x_test)\nprint('Ridge score: ',ridge.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(x_test,y_test)\nplt.plot(x_test,ridge.predict(x_test),color=\"red\")\nprint(ridge.intercept_)\nprint(ridge.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sse_values = []\nslope = np.linspace(-0.2,2,len(y_test))\nintercept = 11.29623421\nfor i in range(len(y_test)):\n    sse = (y_test.ravel()[i] - (intercept + slope[i]* x_test.ravel()[i]))\n    sse_values.append(sse**2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sse_values1 = []\nslope = np.linspace(-0.2,2,len(y_test))\nintercept = 11.29623421\nfor i in range(len(y_test)):\n    sse = (y_test.ravel()[i] - (intercept + slope[i]* x_test.ravel()[i]))**2 + (100 + (slope[i])**2)\n    sse_values1.append(sse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sse_values2 = []\nslope = np.linspace(-0.2,2,len(y_test))\nintercept = 11.29623421\nfor i in range(len(y_test)):\n    sse = (y_test.ravel()[i] - (intercept + slope[i]* x_test.ravel()[i]))**2 + (500 + (slope[i])**2)\n    sse_values2.append(sse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sse_values3 = []\nslope = np.linspace(-0.2,2,len(y_test))\nintercept = 11.29623421\nfor i in range(len(y_test)):\n    sse = (y_test.ravel()[i] - (intercept + slope[i]* x_test.ravel()[i]))**2 + (1000 + (slope[i])**2)\n    sse_values3.append(sse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sse_values4 = []\nslope = np.linspace(-0.2,2,len(y_test))\nintercept = 11.29623421\nfor i in range(len(y_test)):\n    sse = (y_test.ravel()[i] - (intercept + slope[i]* x_test.ravel()[i]))**2 + (2000 + (slope[i])**2)\n    sse_values4.append(sse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(sse_values4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(y_test)):\n    print(slope[i],sse_values[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aralık = np.arange(0,100,10)\nnew1 = []\nother = []\nother1 = []\nother2 = []\nother3 = []\nother4 = []\nfor i in aralık:\n    new1.append(slope[i])\n    other.append(sse_values[i])\n    other1.append(sse_values1[i])\n    other2.append(sse_values2[i])\n    other3.append(sse_values3[i])\n    other4.append(sse_values4[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (9,9))\nplt.plot(new1,other,color=\"green\",label=\"lambda: 0\")\nplt.plot(new1,other1,color=\"red\",label=\"lambda: 1\")\nplt.plot(new1,other2,color=\"blue\",label=\"lambda: 5\")\nplt.plot(new1,other3,color=\"orange\",label=\"lambda: 10\")\nplt.plot(new1,other4,color=\"yellow\",label=\"lambda: 20\")\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}