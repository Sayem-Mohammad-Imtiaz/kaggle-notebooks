{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Imports"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport cv2\nimport os \nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, cohen_kappa_score\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.utils import to_categorical","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Enviroment variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"path = \"../input/ocular-disease-recognition-odir5k\"\ndatafr = pd.read_csv(os.path.join(path, \"full_df.csv\"))\n# Image size\nROW = 224\nCOL = 224\n\n# Images file names\nfile_names = []\n\n# Loaded data\ntraining_images = []\nflags = []\n\n# Features\ngrayscaled_images = []\ninverted_images = []\nthresholded_images = []\ngray_histogram_of_images = []\nRGB_histogram_of_images = []\nconny_edged_images = []\nlaplacian_edged_images = []\nx_edged_images = []\ny_edged_images = []\n\nthreshold_mean = []\nthreshold_median = []\nthreshold_std_dev = []\n\nconny_mean = []\nconny_median = []\nconny_std_dev = []","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Filtering Cataract & Healthy eyes from others"},{"metadata":{"trusted":true},"cell_type":"code","source":"cutter = 0\ndivision = 1 # Increase to decrease number of images to load .. faster outputing for testing\nfile_names.clear()\nflags.clear()\nfor label, flag, file_name in zip(datafr[\"Left-Diagnostic Keywords\"], datafr[\"C\"], datafr[\"Left-Fundus\"]):\n    if((\"cataract\" in label) and (flag == 1)):\n        file_names.append(file_name)\n        flags.append(1)\n    elif((\"normal fundus\" in label) and (flag == 0)):\n        if(cutter%division == 0):\n            file_names.append(file_name)\n            flags.append(0)\n        cutter = cutter + 1\n\ncutter = 0\nfor label, flag, file_name in zip(datafr[\"Right-Diagnostic Keywords\"], datafr[\"C\"], datafr[\"Right-Fundus\"]):\n    if((\"cataract\" in label) and (flag == 1)):\n        file_names.append(file_name)\n        flags.append(1)\n    elif((\"normal fundus\" in label) and (flag == 0)):\n        if(cutter%division == 0):\n            file_names.append(file_name)\n            flags.append(0)\n        cutter = cutter + 1\n\nprint(\"Data Length =\",len(file_names), \"files\", len(flags), \"flags\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cataract Ratio"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.bar([0,1], [len([i for i in flags if i == 1]), len([i for i in flags if i == 0])], color = ['r', 'g'])\nplt.xticks([0, 1], ['Cataract', 'Normal'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading Images"},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"training_images.clear()\nfor idx, image_name in enumerate(file_names):\n    image = cv2.imread(os.path.join(path,\"preprocessed_images\",image_name))\n    try:\n        image = cv2.resize(image, (ROW, COL))\n        image = cv2.normalize(image, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype =cv2.CV_8U)\n        training_images.append(image)\n    except:\n        del flags[idx]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Images Sample"},{"metadata":{"trusted":true},"cell_type":"code","source":"def showSamples(images, gray = False):\n    figure, axes = plt.subplots(2, 2)\n    axes[0, 0].title.set_text(\"Cataract\")\n    axes[0, 1].title.set_text(\"Normal\")\n    \n    axes[0, 0].axis('off')\n    axes[0, 1].axis('off')\n    axes[1, 0].axis('off')\n    axes[1, 1].axis('off')\n    \n    axes[0, 0].imshow(images[0],cmap='gray') if gray else axes[0, 0].imshow(cv2.cvtColor(images[0], cv2.COLOR_BGR2RGB))\n    axes[0, 1].imshow(images[2],cmap='gray') if gray else axes[0, 1].imshow(cv2.cvtColor(images[2], cv2.COLOR_BGR2RGB))\n    axes[1, 0].imshow(images[17],cmap='gray') if gray else axes[1, 0].imshow(cv2.cvtColor(images[17], cv2.COLOR_BGR2RGB))\n    axes[1, 1].imshow(images[12],cmap='gray') if gray else axes[1, 1].imshow(cv2.cvtColor(images[12], cv2.COLOR_BGR2RGB))\n    plt.show()\n\nprint(np.array(training_images).shape)\nprint(training_images[1961].dtype)\nshowSamples(training_images)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Extraction"},{"metadata":{},"cell_type":"markdown","source":"## F1 Grayscale"},{"metadata":{"trusted":true},"cell_type":"code","source":"grayscaled_images.clear()\nfor idx, image in enumerate(training_images):\n    gray_image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n    gray_image = cv2.normalize(src=gray_image, dst=None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n    grayscaled_images.append(gray_image)\n\nshowSamples(grayscaled_images, True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## F2 Threshold"},{"metadata":{"trusted":true},"cell_type":"code","source":"thresholded_images.clear()\nfor idx, image in enumerate(grayscaled_images):\n    ret, image = cv2.threshold(image,127,255,cv2.THRESH_TOZERO_INV)\n    thresholded_images.append(image)\n\nshowSamples(thresholded_images, True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## F4 Grayscale Histogram"},{"metadata":{"trusted":true},"cell_type":"code","source":"gray_histogram_of_images.clear()\nfor idx, image in enumerate(grayscaled_images):\n    image_histogram = cv2.equalizeHist(image)\n    gray_histogram_of_images.append(image_histogram)\n\nshowSamples(gray_histogram_of_images, True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## F5 RGB Histogram"},{"metadata":{"trusted":true},"cell_type":"code","source":"RGB_histogram_of_images.clear()\nfor idx, image in enumerate(training_images):\n    R, G, B = cv2.split(image)\n    image_histogram_R = cv2.equalizeHist(R)\n    image_histogram_G = cv2.equalizeHist(G)\n    image_histogram_B = cv2.equalizeHist(B)\n    image_histogram = cv2.merge((image_histogram_R, image_histogram_G, image_histogram_B))\n    RGB_histogram_of_images.append(image_histogram)\n\nshowSamples(RGB_histogram_of_images)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## F3 Conny Edge detection"},{"metadata":{"trusted":true},"cell_type":"code","source":"conny_edged_images.clear()\nfor idx, image in enumerate(training_images):\n    image = cv2.Canny(image,30,200)\n    conny_edged_images.append(image)\n\nshowSamples(conny_edged_images, True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## F6 X Edges"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_edged_images.clear()\nfor idx, image in enumerate(grayscaled_images):\n    sobelx = cv2.Sobel(image,cv2.CV_64F,1,0,ksize=5)\n    x_edged_images.append(sobelx)\n\nshowSamples(x_edged_images, True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## F7 Y Edges"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_edged_images.clear()\nfor idx, image in enumerate(grayscaled_images):\n    sobely = cv2.Sobel(image,cv2.CV_64F,0,1,ksize=5)  \n    y_edged_images.append(sobely)\n\nshowSamples(y_edged_images, True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## F8 Laplacian Edges"},{"metadata":{"trusted":true},"cell_type":"code","source":"laplacian_edged_images.clear()\nfor idx, image in enumerate(grayscaled_images):\n    lap_image = cv2.Laplacian(image, cv2.CV_64F)\n    laplacian_edged_images.append(lap_image)\n\nshowSamples(laplacian_edged_images, True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## F9 Mean, Median, Mode, Standard Deviation of ***Threshold***"},{"metadata":{"trusted":true},"cell_type":"code","source":"threshold_mean.clear()\nthreshold_median.clear()\nthreshold_std_dev.clear()\n\nfor idx, image in enumerate(thresholded_images):\n    mean = np.mean(image)\n    median = np.median(image)\n    std_dev = np.std(image)\n    \n    threshold_mean.append(mean)\n    threshold_median.append(median)\n    threshold_std_dev.append(std_dev)\n\nprint(threshold_mean[0], threshold_mean[2])\nprint(threshold_median[0], threshold_median[2])\nprint(threshold_std_dev[0], threshold_std_dev[2])\nprint()\nprint(threshold_mean[17], threshold_mean[12])\nprint(threshold_median[17], threshold_median[12])\nprint(threshold_std_dev[17], threshold_std_dev[12])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## F9 Mean, Median, Mode, Standard Deviation of ***Conny***"},{"metadata":{"trusted":true},"cell_type":"code","source":"conny_mean.clear()\nconny_median.clear()\nconny_std_dev.clear()\n\nfor idx, image in enumerate(conny_edged_images):\n    mean = np.mean(image)\n    median = np.median(image)\n    std_dev = np.std(image)\n    \n    conny_mean.append(mean)\n    conny_median.append(median)\n    conny_std_dev.append(std_dev)\n\nprint(conny_mean[0], conny_mean[2])\nprint(conny_median[0], conny_median[2])\nprint(conny_std_dev[0], conny_std_dev[2])\nprint()\nprint(conny_mean[17], conny_mean[12])\nprint(conny_median[17], conny_median[12])\nprint(conny_std_dev[17], conny_std_dev[12])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Formating the data for Machine Learning"},{"metadata":{"trusted":true},"cell_type":"code","source":"training_features = np.vstack((threshold_mean,threshold_median,threshold_std_dev,conny_mean,conny_median,conny_std_dev)).T\n\nimage_train, image_test, flag_train, flag_test = train_test_split(training_features, np.asarray(flags), test_size=0.3, random_state=1)\n\nstdSc = StandardScaler()\nimage_train = stdSc.fit_transform(image_train)\nimage_test = stdSc.transform(image_test)\n\nimage_train = np.asarray(image_train).astype('float32')\nflag_train = np.asarray(flag_train).astype('float32')\n\nimage_test = np.asarray(image_test).astype('float32')\nflag_test = np.asarray(flag_test).astype('float32')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building, Training & Testing the NN Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = Sequential()\n\nlayer_info = Dense(activation='relu', input_dim=6, units=6)\nclassifier.add(layer_info)\n\nlayer_info = Dense(activation='relu', units=4)\nclassifier.add(layer_info)\n\nlayer_info = Dense(activation='sigmoid',units=1)\nclassifier.add(layer_info)\n\nclassifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nclassifier.fit(image_train, flag_train, batch_size=50, epochs=50)\n\nflag_prediction = classifier.predict(image_test).round()\n\ntn, fp, fn, tp = confusion_matrix(flag_test, flag_prediction).ravel()\n\nprint(\"True Negative =\",tn)\nprint(\"False Positive =\",fp)\nprint(\"False Negative =\",fn)\nprint(\"True Positive =\",tp)\n\n\nprint(confusion_matrix(flag_test, flag_prediction))\nprint(accuracy_score(flag_test, flag_prediction)*100)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}