{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reading data set"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/deepnlp/Sheet_1.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some variable having NaN values and not important in further analysis.Removing such variable from data using simple drop command."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_data=df.drop([\"Unnamed: 3\",\"Unnamed: 4\",\"Unnamed: 5\",\"Unnamed: 6\",\"Unnamed: 7\"],axis=\"columns\")\ndf_data.count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Word Cloud"},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS \nimport matplotlib.pyplot as plt\ntext_df = \" \".join(review for review in df_data.response_text)\nwordcloud = WordCloud(background_color=\"red\").generate(text_df)\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Word frequency Counter plot**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import defaultdict\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom yellowbrick.text import FreqDistVisualizer\nvectorizer = CountVectorizer(stop_words='english')\ndocs       = vectorizer.fit_transform(text for text in df_data['response_text'])\nfeatures   = vectorizer.get_feature_names()\n\nvisualizer = FreqDistVisualizer(\n    features=features, size=(1080, 720)\n)\nvisualizer.fit(docs)\nvisualizer.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Obervation\n    Word like \n1.     friend\n2.     help\n3.     talk\n4.     going\n are repeated more then other words.\n    "},{"metadata":{},"cell_type":"markdown","source":"In each and every observation stopword are present and that are not importanat of our point of view.\" from nltk.corpus import stopwords \" Library help us to remove stopwords from our data."},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nfrom nltk.corpus import stopwords\nstops = stopwords.words('english')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I am using here Stemmer to strim word.Also we can use Tokenizer or Lemmatizer.Some time stemmer strim word but word like \"GO\",\"Went\",\"Going\" are back to their root meaning.In such case we use Lemmatizer.\nTokenizer split sentence into seperate word.Stemmer remove \"ed\",\"tion\",\"Ing\" etc in short it try to word should be in it's root meaning by removing this word."},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.stem.porter import PorterStemmer\ncorpus = []\nfor i in range(0, 80):\n    response_text = re.sub('[^a-zA-Z]', ' ', df_data['response_text'][i])\n    response_text = response_text.lower()\n    response_text = response_text.split()\n    ps = PorterStemmer()\n    response_text = [ps.stem(word) for word in response_text if not word in set(stops)]\n    response_text = ' '.join(response_text)\n    corpus.append(response_text)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating data frame of important word from every observation.If some word are reated in any obervaton this feature data frame count it's frequency."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(max_features = 1000)\nX = cv.fit_transform(corpus).toarray()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importing response variable from original data frame."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_response = df_data.iloc[:, 1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"But this reponse variable in categorical form i.e.flagged and not_flagged.While doing operation we have need to convert it into binary form.Using Numpy we can convert it into binary."},{"metadata":{"trusted":true},"cell_type":"code","source":"y=np.where(y_response==\"flagged\",0,1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train test split.Response variable is binary that why I use stratify=y."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split \nX_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.4, \n                                                    random_state=1,\n                                                    stratify=y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model build using random forest algorithm.Because it gives me best accuracy than other algorithm."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nmodel_rf = RandomForestClassifier(random_state=1211,\n                                  n_estimators=500,oob_score=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_rf.fit( X_train , y_train )\ny_pred_probarf = model_rf.predict_proba(X_test)[:,1]\nfrom sklearn.metrics import roc_auc_score\nroc_auc_score(y_test,y_pred_probarf)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}