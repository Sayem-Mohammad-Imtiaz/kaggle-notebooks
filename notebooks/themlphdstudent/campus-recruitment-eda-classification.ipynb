{"cells":[{"metadata":{},"cell_type":"markdown","source":"<font color='blue' size='9.5'><b><i>\n    Campus Recruitment: EDA and Classification</b></i>\n</font>\n\n<font size='2'>Durgesh Samariya | The ML PhD Student</font>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"![]()\n<center>\n    <img src='https://d8it4huxumps7.cloudfront.net/bites/wp-content/banners/2020/7/5f02f3ca4efab_campus_recruitment_process_heres_everything_you_need_to_know.png?d=700x400'>\n    <font size='1'> Source: https://d8it4huxumps7.cloudfront.net/bites/wp-content/banners/2020/7/5f02f3ca4efab_campus_recruitment_process_heres_everything_you_need_to_know.png?d=700x400 </font>\n</center>\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<font color='red' size='5'>\n    <center>\n        Please Upvote my kernel if you like my work.\n    </center>\n</font>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id=\"top\"></a>\n## Table of Content\n\n* [1. Summary](#1)\n* [2. Loading and Exploring Data](#2)\n    - [2.1 Loading libraries required and reading the data into Python DataFrame](#2.1)\n    - [2.2 Data size and structure](#2.2)\n* [3. Exploring features and relation with target class](#4)\n    - [3.1. Target Class; Status](#4.1)\n    - [3.2. Gender](#4.2)\n    - [3.3. SSC Percentage](#4.3)\n    - [3.4. SSC Board](#4.4)\n    - [3.5. HSC Percentage](#4.5)\n    - [3.6. HSC Board](#4.6)\n    - [3.7. HSC Specialization](#4.7)\n    - [3.8. Degree Percentage](#4.8)\n    - [3.9. Degree Type](#4.9)\n    - [3.10. Work Experience](#4.10)\n    - [3.11. Employment Test Percentage](#4.11)\n    - [3.12. MBA Specialization](#4.12)\n    - [3.13. MBA Percentage](#4.13)\n    - [3.14. Most Important Factor; Salary](#4.14)\n    - [3.15. Correlation between features](#4.15)\n* [4. Feature mapping and generation](#5)\n    - [4.1. Additional feature generation](#5.1)\n* [5. Model Prediction](#6)\n    - [5.1. Train and Test Split](#6.1)\n    - [5.2. KNN Classification](#6.2)\n    - [5.3. Decision Tree Classification](#6.3)\n    - [5.4. Support Vector Machine](#6.4)\n    - [5.5. Random Forest](#6.5)\n    - [5.6. Gaussian Naive Bayes](#6.6)\n    - [5.7. Stochastic Gradient Descent](#6.7)\n    - [5.8. Linear SVC](#6.8)\n    - [5.9. Best Performing Model](#6.9)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id='#1'></a>\n<font color=\"darkslateblue\" size=+2.5><b>1. Summary</b></font>\n\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Go to TOC</a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<font size=3>Campus placement or campus recruiting is a program conducted within universities or other educational institutions to provide jobs to students nearing completion of their studies. </font>\n<center>\n    <img src='https://annamacharyagroup.org/wp-content/uploads/2018/05/Tip-for-campus-placements-2-05-2018.jpg'>\n    <text size=2> Source: https://annamacharyagroup.org/wp-content/uploads/2018/05/Tip-for-campus-placements-2-05-2018.jpg</text>\n</center>\n<hr>\n\n<font size=5>Problem Statement:</font>\n\nXYZ University wants to build machine learning model to know whethere student will get placed or not. So that they can provide special attention and help them to get job. Given dataset can be trated as classification or regression problem. In this project, I am going to focus on classification problem, where task is to find whethere candidate will placed or not. This is binary classification problem.\n\nIn this project, I used following classification algorithms.\n- KNN Classification\n- Decision Tree Classification\n- Support Vector Machine\n- Random Forest\n- Gaussian Naive Bayes\n- Stochastic Gradient Descent\n- Linear SVC","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id='#2'></a>\n<font color=\"darkslateblue\" size=+2.5><b>2. Loading and Exploring Data</b></font>\n\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Go to TOC</a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id='#2.1'></a>\n<font color=\"darkslateblue\" size=3.5><b>2.1. Loading libraries required and reading the data into Python DataFrame</b></font>","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# data visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# machine learning\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn import preprocessing\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# setting color for all graphs\ncolors = ['#e79c2a','#d54062', '#ebdc87', '#ffa36c']\nsns.set_palette(sns.color_palette(colors))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/factors-affecting-campus-placement/Placement_Data_Full_Class.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='#2.2'></a>\n<font color=\"darkslateblue\" size=3.5><b>2.2. Data size and Structure</b></font>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's have look at example samples.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Features in data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('='*50)\nprint(\"Columns in data\")\nprint('='*50)\nprint(data.columns.values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's have look at each column information.\n\n* sl_no : Serial Number\n\n* gender : Candidate gender --> Male='M',Female='F'\n\n* ssc_p : SSC (10th) Percentage\n\n* ssc_b : SSC Board of Education --> Central (or) Others\n\n* hsc_p : HSC (12th) percentage\n\n* hsc_b : HSC Board of Education --> Central/ Others\n\n* hsc_s : Specialization in HSC\n\n* degree_p : Degree Percentage\n\n* degree_t : Under Graduation (Degree type)- Field of degree education\n\n* workex : Work Experience\n\n* etest_p : Employability test percentage ( conducted by college)\n\n* specialisation : Post Graduation(MBA)- Specialization\n\n* mba_p : MBA percentage\n\n* status : Status of placement- Placed/Not placed\n\n* salary : Salary offered by corporate to candidates","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('='*20)\nprint(\"Data shape\")\nprint('='*20)\nprint(data.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have only 215 samples in our dataset. I hope this is enough to train models.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('='*50)\nprint(\"\\nDescribe data\\n\")\nprint('='*50) \nprint(data.describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('='*50)\nprint(\"\\nData Information\\n\")\nprint('='*50) \nprint(data.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As it is clear that we don't need sl_no in training model or in EDA. Thus I am dropping sl_no column. Rest of them I will keep as it is. After performing EDA I will drop other if needed.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(['sl_no'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='#4'></a>\n<font color=\"darkslateblue\" size=+2.5><b>3. Exploring important features</b></font>\n\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Go to TOC</a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id='#4.1'></a>\n<font color=\"darkslateblue\" size=3.5><b>3.1. The Class Variable; Status</b></font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot('status', data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='#4.2'></a>\n<font color=\"darkslateblue\" size=3.5><b>3.2. Gender</b></font>\n\nLet's check whethere gender affect on placement.\n- Out of 215 candidates, 139 are male and 76 are female.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['gender'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(data.groupby(['gender','status'])['status'].count())\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='gender', hue='status', data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Male have high chances of getting placed compared to females.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id='#4.3'></a>\n<font color=\"darkslateblue\" size=3.5><b>3.3. SSC Percentage</b></font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(data['ssc_p'], kde=False)\nplt.title('Distribution of SSC Percentage')\nplt.xlabel('SSC %')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(y='ssc_p', x='status', data=data)\nplt.xlabel('Employment Status')\nplt.ylabel('SSC %')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Students who are place have higer percentage in SSC.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id='#4.4'></a>\n<font color=\"darkslateblue\" size=3.5><b>3.4. SSC Board</b></font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['ssc_b'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(data.groupby(['ssc_b','status'])['status'].count())\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='ssc_b', hue='status', data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above analysis I can say that, SSC board is not important to recruiters when it come to hiring candidates.\nSo I am not going to use this feature while training model.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id='#4.5'></a>\n<font color=\"darkslateblue\" size=3.5><b>3.5. HSC Percentage </b></font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(data['hsc_p'], kde=False)\nplt.title('Distribution of SSC Percentage')\nplt.xlabel('HSC %')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(y='hsc_p', x='status', data=data)\nplt.xlabel('Employment Status')\nplt.ylabel('HSC %')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"HSC percentage are important features. As all placed students have higher percentages.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id='#4.6'></a>\n<font color=\"darkslateblue\" size=3.5><b>3.6. HSC Board</b></font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['hsc_b'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(data.groupby(['hsc_b','status'])['status'].count())\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='hsc_b', hue='status', data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above analysis I can say that, SSC board is not important to recruiters when it come to hiring candidates.\nSo I am not going to use this feature while training model.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id='#4.7'></a>\n<font color=\"darkslateblue\" size=3.5><b>3.7. HSC Specialisation</b></font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['hsc_s'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(data.groupby(['hsc_s','status'])['status'].count())\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='hsc_s', hue='status', data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='#4.8'></a>\n<font color=\"darkslateblue\" size=3.5><b>3.8. Degree Percentage</b></font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(data['degree_p'], kde=False)\nplt.title('Distribution of Degree Percentage')\nplt.xlabel('Degree %')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(y='degree_p', x='status', data=data)\nplt.xlabel('Employment Status')\nplt.ylabel('Degree %')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Like SSC and HSC percentages, Degree Percentages are also impotant factor to get placed.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id='#4.9'></a>\n<font color=\"darkslateblue\" size=3.5><b>3.9. Degree Type</b></font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['degree_t'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(data.groupby(['degree_t','status'])['status'].count())\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='degree_t', hue='status', data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='#4.10'></a>\n<font color=\"darkslateblue\" size=3.5><b>3.10. Work Experience</b></font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['workex'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(data.groupby(['workex','status'])['status'].count())\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='workex', hue='status', data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is clear that candidate with work experience have higher chance of getting placed.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id='#4.11'></a>\n<font color=\"darkslateblue\" size=3.5><b>3.11. Employment Test Percentage</b></font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(data['etest_p'], kde=False)\nplt.title('Distribution of MBA Percentage')\nplt.xlabel('Employment Test %')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(y='etest_p', x='status', data=data)\nplt.xlabel('Employment Status')\nplt.ylabel('Employment Test %')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='#4.12'></a>\n<font color=\"darkslateblue\" size=3.5><b>3.12. MBA Specialization</b></font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['specialisation'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(data.groupby(['specialisation','status'])['status'].count())\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='specialisation', hue='status', data=data)\nplt.xlabel('MBA Specialization')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='#4.13'></a>\n<font color=\"darkslateblue\" size=3.5><b>3.13. MBA Percentage</b></font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(data['mba_p'], kde=False)\nplt.title('Distribution of MBA Percentage')\nplt.xlabel('MBA %')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(y='mba_p', x='status', data=data)\nplt.xlabel('Employment Status')\nplt.ylabel('MBA %')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='#4.14'></a>\n<font color=\"darkslateblue\" size=3.5><b>3.14. Most Important Factor; Salary</b></font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(data['salary'], kde=False)\nplt.title('Distribution of Salary')\nplt.xlabel('Salary')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(y='salary', x='status', data=data)\nplt.xlabel('Employment Status')\nplt.ylabel('Salary')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is obvious, we dont have salary details of Un-Placed candidate. Salary feature alone is enough to classify the placement status of candidate (if salary > 0 then placed else not placed). However, if we want to use only salary feature then we dont need machine learning for that, by looking only we can do that. So I am going to drop this column while performing classification model training.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id='#4.15'></a>\n<font color=\"darkslateblue\" size=3.5><b>3.15. Correlation between features</b></font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data=data[['ssc_p','hsc_p','degree_p', 'etest_p','mba_p','salary', 'status']], hue=\"status\", diag_kind='hist')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='#5'></a>\n<font color=\"darkslateblue\" size=+2.5><b>4. Feature mapping and generation</b></font>\n\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Go to TOC</a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's drop all unwanted columns as menstioned in above section.\n- SSC Board\n- HSC Board\n- HSC Specialisation\n- Degree Type\n- Salart","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(['ssc_b','hsc_b', 'hsc_s', 'degree_t', 'salary'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's map categorical feature to numeric one.\nCategorical features:\n- Gender : Gender feature have male and female values. I am going to map 0 for male and 1 for female.\n- Work Experience : Work Experience feature have Yes and No values. I am going to map 0 for No and 1 for Yes.\n- Status : Status feature have Not Placed and Placed values. Again for this features I am mapping 0 for not placed and 1 for placed values.\n- Specialisation : Specialisation feature have two values Mkt&HR and Mkt&Fin. I am going to map 0 to Mkt&HR and 1 to Mkt&Fin.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"gender\"] = data.gender.map({\"M\":0,\"F\":1})\ndata[\"workex\"] = data.workex.map({\"No\":0, \"Yes\":1})\ndata[\"status\"] = data.status.map({\"Not Placed\":0, \"Placed\":1})\ndata[\"specialisation\"] = data.specialisation.map({\"Mkt&HR\":0, \"Mkt&Fin\":1})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='#5.1'></a>\n<font color=\"darkslateblue\" size=3.5><b>4.1. Additional feature generation</b></font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def new_features(df):\n    df['hsc_to_ssc'] = df['hsc_p'] / df['ssc_p']\n    df['degree_to_hsc'] = df['degree_p'] / df['hsc_p']\n    df['degree_to_ssc'] = df['degree_p'] / df['ssc_p']\n    df['mba_to_degree'] = df['mba_p'] / df['degree_p']\n    df['mba_to_etest'] = df['mba_p'] / df['etest_p']\n        \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = new_features(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='#6'></a>\n<font color=\"darkslateblue\" size=+2.5><b>5. Model Prediction</b></font>\n\n<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Go to TOC</a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Now our data is ready to prepare model to predict solution. There is plenty of predictive algorithm out there to try. In this project, I am going to use classification and regression algorithms.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id='#6.1'></a>\n<font color=\"darkslateblue\" size=3.5><b>5.1. Train and Test Split</b></font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Seperating Features and Target\nX = data.copy().drop('status', axis=1)\ny = data['status']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# scale each features\nX_scaled = preprocessing.scale(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Train Test Split\nX_train, X_test, Y_train, Y_test = train_test_split(X_scaled, y, test_size=0.3)\nX_train.shape, Y_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='#6.2'></a>\n<font color=\"darkslateblue\" size=3.5><b>5.2. KNN Classification</b></font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# k-nearest neighbor\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\nknn_Y_pred = knn.predict(X_test)\nknn_accuracy = knn.score(X_test, Y_test)\nknn_accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating confusion matrix heatmap\n\nconf_mat = confusion_matrix(Y_test, knn_Y_pred)\nfig = plt.figure(figsize=(10,7))\ngroup_names = ['True Neg','False Pos','False Neg','True Pos']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                conf_mat.flatten()]\nlabels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_names,group_counts)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(conf_mat, annot=labels, annot_kws={\"size\": 16}, fmt='')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting precision, recall and f1-score via classification report\n\nprint(classification_report(Y_test, knn_Y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='#6.3'></a>\n<font color=\"darkslateblue\" size=3.5><b>5.3. Decision Tree Classification</b></font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decision Tree\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\ndecision_tree_Y_pred = decision_tree.predict(X_test)\ndecision_tree_accuracy = decision_tree.score(X_test, Y_test)\ndecision_tree_accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating confusion matrix heatmap\n\nconf_mat = confusion_matrix(Y_test, decision_tree_Y_pred)\nfig = plt.figure(figsize=(10,7))\ngroup_names = ['True Neg','False Pos','False Neg','True Pos']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                conf_mat.flatten()]\nlabels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_names,group_counts)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(conf_mat, annot=labels, annot_kws={\"size\": 16}, fmt='')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting precision, recall and f1-score via classification report\n\nprint(classification_report(Y_test, decision_tree_Y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='#6.4'></a>\n<font color=\"darkslateblue\" size=3.5><b>5.4. Support Vector Machine</b></font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Support Vector Machine\nsvc = SVC()\nsvc.fit(X_train, Y_train)\nsvm_Y_pred = svc.predict(X_test)\nsvc_accuracy = svc.score(X_test, Y_test)\nsvc_accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating confusion matrix heatmap\n\nconf_mat = confusion_matrix(Y_test, svm_Y_pred)\nfig = plt.figure(figsize=(10,7))\ngroup_names = ['True Neg','False Pos','False Neg','True Pos']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                conf_mat.flatten()]\nlabels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_names,group_counts)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(conf_mat, annot=labels, annot_kws={\"size\": 16}, fmt='')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting precision, recall and f1-score via classification report\n\nprint(classification_report(Y_test, svm_Y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='#6.5'></a>\n<font color=\"darkslateblue\" size=3.5><b>5.5. Random Forest</b></font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Forest\n\nrandom_forest = RandomForestClassifier(n_estimators=1000)\nrandom_forest.fit(X_train, Y_train)\nrandom_forest_Y_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nrandom_forest_accuracy = random_forest.score(X_test, Y_test)\nrandom_forest_accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating confusion matrix heatmap\n\nconf_mat = confusion_matrix(Y_test, random_forest_Y_pred)\nfig = plt.figure(figsize=(10,7))\ngroup_names = ['True Neg','False Pos','False Neg','True Pos']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                conf_mat.flatten()]\nlabels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_names,group_counts)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(conf_mat, annot=labels, annot_kws={\"size\": 16}, fmt='')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting precision, recall and f1-score via classification report\n\nprint(classification_report(Y_test, random_forest_Y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='#6.6'></a>\n<font color=\"darkslateblue\" size=3.5><b>5.6. Gaussian Naive Bayes</b></font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(X_train, Y_train)\ngaussian_Y_pred = gaussian.predict(X_test)\ngaussian_accuracy = gaussian.score(X_test, Y_test)\ngaussian_accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating confusion matrix heatmap\n\nconf_mat = confusion_matrix(Y_test, gaussian_Y_pred)\nfig = plt.figure(figsize=(10,7))\ngroup_names = ['True Neg','False Pos','False Neg','True Pos']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                conf_mat.flatten()]\nlabels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_names,group_counts)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(conf_mat, annot=labels, annot_kws={\"size\": 16}, fmt='')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting precision, recall and f1-score via classification report\n\nprint(classification_report(Y_test, gaussian_Y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='#6.7'></a>\n<font color=\"darkslateblue\" size=3.5><b>5.7. Stochastic Gradient Descent</b></font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stochastic Gradient Descent\n\nsgd = SGDClassifier()\nsgd.fit(X_train, Y_train)\nsgd_Y_pred = sgd.predict(X_test)\nsgd_accuracy = sgd.score(X_test, Y_test)\nsgd_accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating confusion matrix heatmap\n\nconf_mat = confusion_matrix(Y_test, sgd_Y_pred)\nfig = plt.figure(figsize=(10,7))\ngroup_names = ['True Neg','False Pos','False Neg','True Pos']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                conf_mat.flatten()]\nlabels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_names,group_counts)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(conf_mat, annot=labels, annot_kws={\"size\": 16}, fmt='')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting precision, recall and f1-score via classification report\n\nprint(classification_report(Y_test, sgd_Y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='#6.8'></a>\n<font color=\"darkslateblue\" size=3.5><b>5.8. Linear SVC</b></font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Linear SVC\n\nlinear_svc = LinearSVC()\nlinear_svc.fit(X_train, Y_train)\nlinear_svc_Y_pred = linear_svc.predict(X_test)\nlinear_svc_accuracy = linear_svc.score(X_test, Y_test)\nlinear_svc_accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating confusion matrix heatmap\n\nconf_mat = confusion_matrix(Y_test, linear_svc_Y_pred)\nfig = plt.figure(figsize=(10,7))\ngroup_names = ['True Neg','False Pos','False Neg','True Pos']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                conf_mat.flatten()]\nlabels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_names,group_counts)]\nlabels = np.asarray(labels).reshape(2,2)\nsns.heatmap(conf_mat, annot=labels, annot_kws={\"size\": 16}, fmt='')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting precision, recall and f1-score via classification report\n\nprint(classification_report(Y_test, linear_svc_Y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='#6.9'></a>\n<font color=\"darkslateblue\" size=3.5><b>5.9. Best Performing Model</b></font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Linear SVC', 'Decision Tree','Random Forest', 'Stochastic Gradient Descent', 'Gaussian Naive Bayes'],\n    'Score': [svc_accuracy, knn_accuracy, linear_svc_accuracy, decision_tree_accuracy, random_forest_accuracy, sgd_accuracy, gaussian_accuracy]})\nmodels.sort_values(by='Score', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font color='red' size=5>\n    <center>\n        I hope you enjoyed this kernel, Please don't forget to appreciate me with an Upvote. :)\n    </center>\n</font>","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}