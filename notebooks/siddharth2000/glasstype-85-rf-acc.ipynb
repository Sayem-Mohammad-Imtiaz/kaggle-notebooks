{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Credits - https://www.kaggle.com/tolgahancepel/glass-classification-analysis-with-eda**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Attribute Information:\n\n1. Id number: 1 to 214 (removed from CSV file)\n2. RI: refractive index\n3. Na: Sodium (unit measurement: weight percent in corresponding oxide, as are attributes 4-10)\n4. Mg: Magnesium\n5. Al: Aluminum\n6. Si: Silicon\n7. K: Potassium\n8. Ca: Calcium\n9. Ba: Barium\n10. Fe: Iron\n11. Type of glass: (class attribute)\n\n-- 1 buildingwindowsfloatprocessed -- 2 buildingwindowsnonfloatprocessed -- 3 vehiclewindowsfloatprocessed\n-- 4 vehiclewindowsnonfloatprocessed (none in this database)\n-- 5 containers\n-- 6 tableware\n-- 7 headlamps","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/glass/glass.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df['Type'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['RI'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = df.columns[:-1].tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in features:\n    sns.distplot(df[feature], kde=False)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in features:\n    sns.boxplot(df[feature])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in features:\n    sns.violinplot(x = 'Type', y = feature, data=df)\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = df.corr()\nplt.figure(figsize=(12,12))\nsns.heatmap(corr, cbar = True,  square = True, annot=True, fmt= '.2f',annot_kws={'size': 15},\n            alpha = 0.7,   cmap= 'coolwarm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\ndef outlier_hunt(df):\n    \"\"\"\n    Takes a dataframe df of features and returns a list of the indices\n    corresponding to the observations containing more than 2 outliers. \n    \"\"\"\n    outlier_indices = []\n    \n    # iterate over features(columns)\n    for col in df.columns.tolist():\n        # 1st quartile (25%)\n        Q1 = np.percentile(df[col], 25)\n        \n        # 3rd quartile (75%)\n        Q3 = np.percentile(df[col],75)\n        \n        # Interquartile rrange (IQR)\n        IQR = Q3 - Q1\n        \n        # outlier step\n        outlier_step = 1.5 * IQR\n        \n        # Determine a list of indices of outliers for feature col\n        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n        \n        # append the found outlier indices for col to the list of outlier indices \n        outlier_indices.extend(outlier_list_col)\n        \n    # select observations containing more than 2 outliers\n    outlier_indices = Counter(outlier_indices)        \n    multiple_outliers = list( k for k, v in outlier_indices.items() if v > 2 )\n    \n    return multiple_outliers   \n\nprint('The dataset contains %d observations with more than 2 outliers' %(len(outlier_hunt(df[features]))))   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outlier_indices = outlier_hunt(df[features])\ndf = df.drop(outlier_indices).reset_index(drop=True)\nprint(df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in features:\n    sns.boxplot(x = 'Type', y = feature, data=df)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop('Type', axis=1).values\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df['Type'].values.reshape(-1,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42, stratify = y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting Logistic Regression to the Training set\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\n\nclassifier_lr = LogisticRegression()\nsteps = [\n    ('scalar', StandardScaler()),\n    ('model', LogisticRegression())\n]\n\nlr_pipe = Pipeline(steps)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = { 'model__C' : [1,10,100,1000,10000],\n               'model__fit_intercept' : [True],\n               'model__multi_class' : ['auto'],\n               'model__tol' : [0.0001],\n               'model__solver' : ['newton-cg', 'lbfgs', 'sag', 'saga'],\n               'model__n_jobs' : [-1],\n               'model__max_iter' : [5000],\n               'model__random_state': [42] \n}\nclassifier_lr = GridSearchCV(lr_pipe, parameters, iid=False, cv = 3)\nclassifier_lr = classifier_lr.fit(X_train, y_train.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\ny_pred_lr_train = classifier_lr.predict(X_train)\naccuracy_lr_train = accuracy_score(y_train, y_pred_lr_train)\nprint(\"Training set: \", accuracy_lr_train)\n\ny_pred_lr_test = classifier_lr.predict(X_test)\naccuracy_lr_test = accuracy_score(y_test, y_pred_lr_test)\nprint(\"Test set: \", accuracy_lr_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nsns.heatmap(confusion_matrix(y_test, y_pred_lr_test), annot=True, cmap = 'viridis', fmt='.0f')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint( classification_report(y_test, y_pred_lr_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting classifier to the Training set\nfrom sklearn.neighbors import KNeighborsClassifier\nclassifier_knn = KNeighborsClassifier()\nsteps = [\n    ('scalar', StandardScaler()),\n    ('model', KNeighborsClassifier())\n]\nknn_pipe = Pipeline(steps)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = { 'model__algorithm' : ['brute', 'kdtree'],\n               'model__metric' : ['minkowski'],\n               'model__p' : [1],\n               'model__n_neighbors' : [3,5,11,19],\n               'model__weights' : ['uniform', 'distance'],\n               'model__n_jobs' : [-1]\n}\nclassifier_knn = GridSearchCV(knn_pipe, parameters, iid=False, cv = 3)\nclassifier_knn = classifier_knn.fit(X_train, y_train.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_knn_train = classifier_knn.predict(X_train)\naccuracy_knn_train = accuracy_score(y_train, y_pred_knn_train)\nprint(\"Training set: \", accuracy_knn_train)\n\ny_pred_knn_test = classifier_knn.predict(X_test)\naccuracy_knn_test = accuracy_score(y_test, y_pred_knn_test)\nprint(\"Test set: \", accuracy_knn_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(confusion_matrix(y_test, y_pred_knn_test), annot=True, cmap = 'viridis', fmt='.0f')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint( classification_report(y_test, y_pred_lr_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting classifier to the Training set\nfrom sklearn.svm import SVC\nclassifier_svm_kernel = SVC()\nsteps = [\n    ('scalar', StandardScaler()),\n    ('model', SVC())\n]\nsvm_kernel_pipe = Pipeline(steps)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = { 'model__kernel' : ['rbf', 'poly', 'sigmoid'],\n               'model__C' : [1,10, 50, 100,1000,10000],\n               'model__gamma' : [0.001, 0.01, 0.1, 1, 'scale'],\n               'model__random_state' : [42],\n               'model__degree' : [1,2,3]\n}\nclassifier_svm_kernel = GridSearchCV(svm_kernel_pipe, parameters, iid=False, cv = 3)\nclassifier_svm_kernel = classifier_svm_kernel.fit(X_train, y_train.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier_svm_kernel.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_svm_kernel_train = classifier_svm_kernel.predict(X_train)\naccuracy_svm_kernel_train = accuracy_score(y_train, y_pred_svm_kernel_train)\nprint(\"Training set: \", accuracy_svm_kernel_train)\n\ny_pred_svm_kernel_test = classifier_svm_kernel.predict(X_test)\naccuracy_svm_kernel_test = accuracy_score(y_test, y_pred_svm_kernel_test)\nprint(\"Test set: \", accuracy_svm_kernel_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nsns.heatmap(confusion_matrix(y_test, y_pred_svm_kernel_test), annot=True, cmap = 'viridis', fmt='.0f')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint( classification_report(y_test, y_pred_svm_kernel_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting classifier to the Training set\nfrom sklearn.tree import DecisionTreeClassifier\nclassifier_dt = DecisionTreeClassifier()\n\nsteps = [\n    ('scalar', StandardScaler()),\n    ('model', DecisionTreeClassifier())\n]\ndt_pipe = Pipeline(steps)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Applying Grid Search to find the best model and the best parameters\nparameters = [ { \"model__max_depth\": np.arange(1,21),\n                 \"model__min_samples_leaf\": [1, 5, 10, 20, 50, 100],\n                 \"model__min_samples_split\": np.arange(2, 11),\n                 \"model__criterion\": [\"gini\"],\n                 \"model__random_state\" : [42]}\n            ]\nclassifier_dt = GridSearchCV(estimator = dt_pipe,\n                           param_grid  = parameters,\n                           cv = 3,\n                           iid = False,\n                           n_jobs = -1)\nclassifier_dt = classifier_dt.fit(X_train, y_train.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_dt_train = classifier_dt.predict(X_train)\naccuracy_dt_train = accuracy_score(y_train, y_pred_dt_train)\nprint(\"Training set: \", accuracy_dt_train)\n\ny_pred_dt_test = classifier_dt.predict(X_test)\naccuracy_dt_test = accuracy_score(y_test, y_pred_dt_test)\nprint(\"Test set: \", accuracy_dt_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nsns.heatmap(confusion_matrix(y_test, y_pred_dt_test), annot=True, cmap = 'viridis', fmt='.0f')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint( classification_report(y_test, y_pred_dt_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting Random Forest Classification to the Training set\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\nclassifier_rf = RandomForestClassifier()\n\nsteps = [\n    ('scalar', StandardScaler()),\n    ('model', RandomForestClassifier())\n]\nrf_pipe = Pipeline(steps)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters =  { \"model__n_estimators\": [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)],\n                \"model__max_features\": [\"auto\", \"sqrt\"],\n                \"model__max_depth\": np.linspace(10, 110, num = 11),\n                \"model__min_samples_split\": [2, 5, 10],\n                \"model__min_samples_leaf\": [1, 2, 4],\n                \"model__bootstrap\": [True, False],\n                \"model__criterion\": [\"gini\"],\n                \"model__random_state\" : [42] }\n            \nclassifier_rf = RandomizedSearchCV(estimator = rf_pipe,\n                                  param_distributions = parameters,\n                                  n_iter = 100,\n                                  cv = 3,\n                                  random_state=42,\n                                  verbose = 4,\n                                  n_jobs = -1)\nclassifier_rf = classifier_rf.fit(X_train, y_train.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_rf_train = classifier_rf.predict(X_train)\naccuracy_rf_train = accuracy_score(y_train, y_pred_rf_train)\nprint(\"Training set: \", accuracy_rf_train)\n\ny_pred_rf_test = classifier_rf.predict(X_test)\naccuracy_rf_test = accuracy_score(y_test, y_pred_rf_test)\nprint(\"Test set: \", accuracy_rf_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nsns.heatmap(confusion_matrix(y_test, y_pred_rf_test), annot=True, cmap = 'viridis', fmt='.0f')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nfrom scipy.stats import uniform, randint\n\nxgb_model = xgb.XGBClassifier()\n\nparams = {\n    \"colsample_bytree\": uniform(0.7, 0.3),\n    \"gamma\": uniform(0, 0.5),\n    \"learning_rate\": uniform(0.03, 0.3), # default 0.1 \n    \"max_depth\": randint(2, 6), # default 3\n    \"n_estimators\": randint(100, 150), # default 100\n    \"subsample\": uniform(0.6, 0.4)\n}\n\nsearch = RandomizedSearchCV(xgb_model, param_distributions=params, random_state=42, n_iter=200, cv=3, verbose=1, n_jobs=1, return_train_score=True)\n\nsearch.fit(X_train, y_train.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_xgb_train = search.predict(X_train)\naccuracy_xgb_train = accuracy_score(y_train, y_pred_xgb_train)\nprint(\"Training set: \", accuracy_xgb_train)\n\ny_pred_xgb_test = search.predict(X_test)\naccuracy_xgb_test = accuracy_score(y_test, y_pred_xgb_test)\nprint(\"Test set: \", accuracy_xgb_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nsns.heatmap(confusion_matrix(y_test, y_pred_xgb_test), annot=True, cmap = 'viridis', fmt='.0f')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred_xgb_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = [('Logistic Regression', accuracy_lr_train, accuracy_lr_test),\n          ('KNN', accuracy_knn_train, accuracy_knn_test),\n          ('SVM (Kernel)', accuracy_svm_kernel_train, accuracy_svm_kernel_test),\n          ('Decision Tree Classification', accuracy_dt_train, accuracy_dt_test),\n          ('Random Forest Classification', accuracy_rf_train, accuracy_rf_test),\n          ('XG Boost Classification', accuracy_xgb_train, accuracy_xgb_test),\n         ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = pd.DataFrame(data = models, columns=['Model', 'Training Accuracy', 'Test Accuracy'])\npredict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(2,1, figsize=(14,10))\n\npredict.sort_values(by=['Training Accuracy'], ascending=False, inplace=True)\n\nsns.barplot(x='Training Accuracy', y='Model', data = predict, palette='Blues_d', ax = axes[0])\n#axes[0].set(xlabel='Region', ylabel='Charges')\naxes[0].set_xlabel('Training Accuracy', size=16)\naxes[0].set_ylabel('Model')\naxes[0].set_xlim(0,1.0)\naxes[0].set_xticks(np.arange(0, 1.1, 0.1))\n\npredict.sort_values(by=['Test Accuracy'], ascending=False, inplace=True)\n\nsns.barplot(x='Test Accuracy', y='Model', data = predict, palette='Greens_d', ax = axes[1])\n#axes[0].set(xlabel='Region', ylabel='Charges')\naxes[1].set_xlabel('Test Accuracy', size=16)\naxes[1].set_ylabel('Model')\naxes[1].set_xlim(0,1.0)\naxes[1].set_xticks(np.arange(0, 1.1, 0.1))\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Do not forget to upvote and comment if you have any queries**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}