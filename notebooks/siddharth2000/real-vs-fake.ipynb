{"cells":[{"metadata":{},"cell_type":"markdown","source":"Credits - **https://www.kaggle.com/sreshta140/is-it-authentic-or-not/notebook**","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.offline as pyoff\nimport plotly.graph_objs as go\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import classification_report","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"true = pd.read_csv('../input/fake-and-real-news-dataset/True.csv')\nfake = pd.read_csv('../input/fake-and-real-news-dataset/Fake.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"true.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fake.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"true.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fake.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"true['Target'] = 0\nfake['Target'] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([true, fake])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"patternDel = \"http\"\nfilter1 = df['date'].str.contains(patternDel)\n\ndf = df[~filter1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pattern = \"Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec\"\nfilter2 = df['date'].str.contains(pattern)\n\ndf = df[filter2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['date'] = pd.to_datetime(df['date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.countplot(df['subject'], hue='Target', data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Highly imbalanced representation which might create problems later**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"copy = df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"copy = copy.sort_values(by = ['date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"copy = copy.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"copy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"copy1 = copy[copy['Target'] == 1]\ncopy1 = copy1.groupby(['date'])['Target'].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"copy1 = pd.DataFrame(copy1)\ncopy1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"copy0 = copy[copy['Target'] == 0]\ncopy0 = copy0.groupby(['date'])['Target'].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"copy0 = pd.DataFrame(copy0)\ncopy0.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_data = [\n    go.Scatter(\n        x=copy0.index,\n        y=copy0['Target'],\n        name='True',\n        #x_axis=\"OTI\",\n        #y_axis=\"time\",\n    ),\n    go.Scatter(\n        x=copy1.index,\n        y=copy1['Target'],\n        name='Fake'\n    )\n    \n]\nplot_layout = go.Layout(\n        title='Day-wise',\n        yaxis_title='Count',\n        xaxis_title='Time',\n        plot_bgcolor='rgba(0,0,0,0)'\n    )\nfig = go.Figure(data=plot_data, layout=plot_layout)\npyoff.iplot(fig)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can safely say that data is highly representative of the real scenario. \n1. Emergence of fake news before US 2016 Elections\n2. Huge amount of tweets on 9/Nov 2016 - Trump's Victory\n3. 7th April 2017 - US missile attack on Syria","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud,STOPWORDS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (20,20))\nwc = WordCloud(min_font_size = 3,  max_words = 3000 , width = 1600 , height = 800 , stopwords = STOPWORDS).generate((\" \".join(df_[df_.target == 1].news)))\nplt.imshow(wc,interpolation = 'bilinear')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (20,20))\nwc = WordCloud(min_font_size = 3,  max_words = 3000 , width = 1600 , height = 800 , stopwords = STOPWORDS).generate((\" \".join(df_[df_.target == 0].news)))\nplt.imshow(wc,interpolation = 'bilinear')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import stopwords\nfrom nltk.util import ngrams\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom collections import defaultdict\nfrom collections import  Counter\nplt.style.use('ggplot')\nstop=set(stopwords.words('english'))\nimport re\nfrom nltk.tokenize import word_tokenize\nimport gensim\nimport string","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom wordcloud import WordCloud,STOPWORDS\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize,sent_tokenize\nfrom bs4 import BeautifulSoup\nimport re,string,unicodedata\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score,plot_confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom string import punctuation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_['news'] = df['text'] + df['title'] + df['subject']\ndf_['target'] = df['Target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf_.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cleaner(phrase):\n    phrase = re.sub(r\"won't\", \"will not\", phrase)\n    phrase = re.sub(r\"can't\", 'can not', phrase)\n  \n  # general\n    phrase = re.sub(r\"n\\'t\",\" not\", phrase)\n    phrase = re.sub(r\"\\'re'\",\" are\", phrase)\n    phrase = re.sub(r\"\\'s\",\" is\", phrase)\n    phrase = re.sub(r\"\\'ll\",\" will\", phrase)\n    phrase = re.sub(r\"\\'d\",\" would\", phrase)\n    phrase = re.sub(r\"\\'t\",\" not\", phrase)\n    phrase = re.sub(r\"\\'ve\",\" have\", phrase)\n    phrase = re.sub(r\"\\'m\",\" am\", phrase)\n    \n    return phrase","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from bs4 import BeautifulSoup\nfrom tqdm import tqdm\nimport re\n\nimport nltk\nnltk.download('stopwords')\n\nfrom nltk.corpus import stopwords","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stop = set(stopwords.words('english'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cleaned_text = []\n\nfor sentance in tqdm(df_['news'].values):\n    sentance = str(sentance)\n    sentance = re.sub(r\"http\\S+\", \"\", sentance)\n    sentance = BeautifulSoup(sentance, 'lxml').get_text()\n    sentance = cleaner(sentance)\n    sentance = re.sub(r'[?|!|\\'|\"|#|+]', r'', sentance)\n    sentance = re.sub(\"\\S*\\d\\S*\", \"\", sentance).strip()\n    sentance = re.sub('[^A-Za-z]+', ' ', sentance)\n    sentance = ' '.join(e.lower() for e in sentance.split() if e.lower() not in stop)\n    cleaned_text.append(sentance.strip())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_['news'] = cleaned_text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gensim\nimport nltk","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = []\ntokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\nfor par in df_['news'].values:\n    tmp = []\n    sentences = nltk.sent_tokenize(par)\n    for sent in sentences:\n        sent = sent.lower()\n        tokens = tokenizer.tokenize(sent)\n        filtered_words = [w.strip() for w in tokens if w not in stop and len(w) > 1]\n        tmp.extend(filtered_words)\n    X.append(tmp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"w2v_model = gensim.models.Word2Vec(sentences=X, size=150, window=5, min_count=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"w2v_model.wv.most_similar(positive = 'trump')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"w2v_model.wv.most_similar('hillary')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"w2v_model.wv.similarity('donaldtrump', 'hillaryclinton')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"w2v_model.wv.similarity('donaldtrump', 'mikepence')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"w2v_model.wv.doesnt_match(['trump', 'hillary', 'sanders'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"w2v_model.wv.doesnt_match(['donaldtrump', 'hillary', 'mikepence'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Perfecto**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"w2v_model.wv.most_similar(positive = ['woman','trump'], negative=['hillary'], topn=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"w2v_model.wv.most_similar(positive = ['hillary','trump'], negative=['mikepence'], topn=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ohh My Gawd **'Hillary and her friends at FOX'**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"w2v_model.wv.most_similar(positive = ['hillary','trump'], negative=['america'], topn=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Basket of Deplorables***","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Modelling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_['news']\ny = df_['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_Train, X_test, y_Train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_cross, y_train, y_cross = train_test_split(X_Train, y_Train, test_size=0.1, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf_idf=TfidfVectorizer(min_df=5,use_idf=True,ngram_range=(1,2))\ntf_idf.fit(X_train)\nTrain_TFIDF = tf_idf.transform(X_train)\nCrossVal_TFIDF = tf_idf.transform(X_cross)\nTest_TFIDF= tf_idf.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Multinomial naive Bayes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"alpha_set=[0.0001,0.001,0.01,0.1,1,10,100,1000]\n\nTrain_AUC_TFIDF = []\nCrossVal_AUC_TFIDF = []\n\n\nfor i in alpha_set:\n    naive_b=MultinomialNB(alpha=i)\n    naive_b.fit(Train_TFIDF, y_train)\n    Train_y_pred =  naive_b.predict(Train_TFIDF)\n    Train_AUC_TFIDF.append(roc_auc_score(y_train,Train_y_pred))\n    CrossVal_y_pred =  naive_b.predict(CrossVal_TFIDF)\n    CrossVal_AUC_TFIDF.append(roc_auc_score(y_cross,CrossVal_y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Alpha_set=[]\nfor i in range(len(alpha_set)):\n    Alpha_set.append(np.math.log(alpha_set[i]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(Alpha_set, Train_AUC_TFIDF, label='Train AUC')\nplt.scatter(Alpha_set, Train_AUC_TFIDF)\nplt.plot(Alpha_set, CrossVal_AUC_TFIDF, label='CrossVal AUC')\nplt.scatter(Alpha_set, CrossVal_AUC_TFIDF)\nplt.legend()\nplt.xlabel(\"alpha : hyperparameter\")\nplt.ylabel(\"AUC\")\nplt.title(\"ERROR PLOTS\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimal_alpha=alpha_set[CrossVal_AUC_TFIDF.index(max(CrossVal_AUC_TFIDF))]\nprint(optimal_alpha)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Classifier2 = MultinomialNB(alpha=optimal_alpha)\nClassifier2.fit(Train_TFIDF, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"Accuracy on Train is: \", accuracy_score(y_train,Classifier2.predict(Train_TFIDF)))\n\nprint (\"Accuracy on Test is: \", accuracy_score(y_test,Classifier2.predict(Test_TFIDF)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nprint(metrics.classification_report(y_test,Classifier2.predict(Test_TFIDF)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(Classifier2, Test_TFIDF, y_test ,display_labels=['0','1'],cmap=\"Blues\",values_format = '')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Logistic Regression**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"c=[0.0001,0.001,0.01,0.1,1,10,100,1000]\nTrain_AUC_TFIDF = []\nCrossVal_AUC_TFIDF = []\nfor i in c:\n    logreg = LogisticRegression(C=i,penalty='l2')\n    logreg.fit(Train_TFIDF, y_train)\n    Train_y_pred =  logreg.predict(Train_TFIDF)\n    Train_AUC_TFIDF.append(roc_auc_score(y_train ,Train_y_pred))\n    CrossVal_y_pred =  logreg.predict(CrossVal_TFIDF)\n    CrossVal_AUC_TFIDF.append(roc_auc_score(y_cross,CrossVal_y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"C=[]\nfor i in range(len(c)):\n    C.append(np.math.log(c[i]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(C, Train_AUC_TFIDF, label='Train AUC')\nplt.scatter(C, Train_AUC_TFIDF)\nplt.plot(C, CrossVal_AUC_TFIDF, label='CrossVal AUC')\nplt.scatter(C, CrossVal_AUC_TFIDF)\nplt.legend()\nplt.xlabel(\"lambda : hyperparameter\")\nplt.ylabel(\"AUC\")\nplt.title(\"ERROR PLOTS\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimal_inverse_lambda=c[CrossVal_AUC_TFIDF.index(max(CrossVal_AUC_TFIDF))]\nprint(pow(optimal_inverse_lambda,-1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Classifier=LogisticRegression(C=optimal_inverse_lambda,penalty='l2')\nClassifier.fit(Train_TFIDF, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"Accuracy is: \", accuracy_score(y_test,Classifier.predict(Test_TFIDF)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nprint(metrics.classification_report(y_test,Classifier.predict(Test_TFIDF)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(Classifier, Test_TFIDF, y_test ,display_labels=['0','1'],cmap=\"Blues\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. **Logistic Regression using L2 Penalty turns out to be the winner with an accuracy of more than 99.6%**\n2. **Multinomial Naive Bayes also did a commendable job with the classification**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**When I first tried, I didn't include the 'subject' column and the model performed similar for MNB model, but the Logistic Regression Model could only achieve an accuracy of 90%. I guess the model suffers from overfitting due to the 'subject' feature**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We had already seen that the presence of 'Subject' was highly inconsistent, the subjects were very target specific which might the reason for overfitting. \n**I would prefer the Naive Bayes model without the 'Subject' feature as a perfect model.**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Please upvote and comment","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}