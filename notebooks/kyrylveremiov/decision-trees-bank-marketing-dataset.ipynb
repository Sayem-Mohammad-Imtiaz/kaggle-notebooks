{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df= pd.read_csv('../input/bank-marketing-dataset/bank.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Полное описание**: \nhttps://www.researchgate.net/figure/Bank-marketing-data-set-descriptions_tbl1_283761844\nПояснение некоторых признаков:\npoutcome: результат предыдущей маркетинговой кампании (категориальный: «неудача», «несуществующий», «успех»)\nprevious: количество контактов, выполненных до этой кампании для этого клиента (числовое значение)\ncampaign: количество контактов, выполненных во время этой кампании для этого клиента (числовое, включая последний контакт)\n\nЦелевая переменная: \nduration: клиент подписался на срочный вклад? (бинарный: «yes», «no»)\n\n\nЗадача классификации: вероятность, что данный клиент может взять срочный депозит"},{"metadata":{"trusted":true},"cell_type":"code","source":"def outliers_indices(feature):\n    mid = df[feature].mean()\n    sigma = df[feature].std()\n    return df[(df[feature] < mid - 3*sigma) | (df[feature] > mid + 3*sigma)].index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wrong_dur=outliers_indices('duration')\nwrong_bal=outliers_indices('balance')\nout=set(wrong_bal|wrong_dur)\nlen(out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(out, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ddf= df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['deposit']=df['deposit'].map({'no': 0,'yes': 1})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Перевод в минуты\ndf['duration']=df['duration']/60","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['default']=df['default'].map({'no':0,'yes':1})\ndf['housing']=df['housing'].map({'no':0,'yes':1})\ndf['loan']=df['loan'].map({'no':0,'yes':1})\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dummy df\nddf = pd.get_dummies(df, columns=['job', 'education', 'marital', 'contact', 'poutcome', 'month'])\n\nddf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ddf.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX=ddf.drop('deposit',axis=1)\ny=ddf['deposit']\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ntree = DecisionTreeClassifier(random_state=2019)\ntree.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree.score(X_valid, y_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\ny_pred = tree.predict(X_valid)\naccuracy_score(y_valid, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**max_depth**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\ntree = DecisionTreeClassifier()\ntree_params_max_depth = {'max_depth': np.arange(2, 15)}\ntree_grid = GridSearchCV(tree, tree_params_max_depth, cv=kf, scoring='accuracy')\ntree_grid.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_grid_cv_results_max_depth=tree_grid.cv_results_\ntree_grid.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_grid.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_tree = DecisionTreeClassifier(max_depth=9)\ny_pred =best_tree.fit(X_train, y_train).predict(X_valid)\naccuracy_score(y_valid, y_pred)\n# best_tree.score(X_valid, y_valid)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**min_samples_split**"},{"metadata":{"trusted":true},"cell_type":"code","source":"tree = DecisionTreeClassifier(max_depth=9)\ntree_params_min_samples_split = {'min_samples_split': np.arange(2, 150)}\ntree_grid = GridSearchCV(tree, tree_params_min_samples_split, cv=kf, scoring='accuracy')\ntree_grid.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_grid_cv_results_min_samples_split=tree_grid.cv_results_\ntree_grid.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_grid.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_tree = DecisionTreeClassifier(max_depth=9,min_samples_split=96)\ny_pred =best_tree.fit(X_train, y_train).predict(X_valid)\naccuracy_score(y_valid, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"min_samples_leaf"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV\ntree = DecisionTreeClassifier(min_samples_split=96,max_depth=9)\ntree_params_min_samples_leaf = {'min_samples_leaf': np.arange(1, 50)}\ntree_grid = GridSearchCV(tree, tree_params_min_samples_leaf, cv=kf, scoring='accuracy')\ntree_grid.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_grid_cv_results_min_samples_leaf=tree_grid.cv_results_\ntree_grid.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_grid.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_tree = DecisionTreeClassifier(max_depth=9, min_samples_split=96, min_samples_leaf=5)\ny_pred =best_tree.fit(X_train, y_train).predict(X_valid)\naccuracy_score(y_valid, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**max_features**"},{"metadata":{"trusted":true},"cell_type":"code","source":"kf = KFold(n_splits=5, shuffle=True, random_state=42)\ntree = DecisionTreeClassifier(min_samples_split=96,max_depth=9, min_samples_leaf=5)\ntree_params_max_features = {'max_features': np.arange(1, X.shape[1])}\ntree_grid = GridSearchCV(tree, tree_params_max_features, cv=kf, scoring='accuracy') \ntree_grid.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_grid_cv_results_max_features=tree_grid.cv_results_\ntree_grid.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_grid.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_tree = DecisionTreeClassifier(min_samples_split=96,max_depth=9, min_samples_leaf=5, max_features=43)\ny_pred =best_tree.fit(X_train, y_train).predict(X_valid)\naccuracy_score(y_valid, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfig, ax = plt.subplots(nrows=1, ncols=4, sharey=True,figsize=(20, 5))\n\nax[0].plot(tree_params_max_depth['max_depth'], tree_grid_cv_results_max_depth['mean_test_score'])\nax[0].set_xlabel('max_depth')\nax[0].set_ylabel('Mean accuracy on test set')\n\nax[1].plot(tree_params_min_samples_split['min_samples_split'], tree_grid_cv_results_min_samples_split['mean_test_score'])\nax[1].set_xlabel('min_samples_split')\nax[1].set_ylabel('Mean accuracy on test set')\n\nax[2].plot(tree_params_min_samples_leaf['min_samples_leaf'], tree_grid_cv_results_min_samples_leaf['mean_test_score'])\nax[2].set_xlabel('min_samples_leaf')\nax[2].set_ylabel('Mean accuracy on test set')\n\nax[3].plot(tree_params_max_features['max_features'], tree_grid_cv_results_max_features['mean_test_score'])\nax[3].set_xlabel('max_features')\nax[3].set_ylabel('Mean accuracy on test set')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Проверим, не требуют ли изменения параметры, подобранные вначале после подбора остальных"},{"metadata":{"trusted":true},"cell_type":"code","source":"kf = KFold(n_splits=5, shuffle=True, random_state=42)\ntree = DecisionTreeClassifier(min_samples_split=96,max_depth=9, min_samples_leaf=5, max_features=43)\ntree_params_max_depth = {'max_depth': np.arange(2, 15)}\ntree_grid = GridSearchCV(tree, tree_params_max_depth, cv=kf, scoring='accuracy')\ntree_grid.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_grid.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_grid.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(tree_grid.cv_results_).T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Коррекция незначительная"},{"metadata":{},"cell_type":"markdown","source":"Лучшая модель:"},{"metadata":{"trusted":true},"cell_type":"code","source":"best_tree = DecisionTreeClassifier(min_samples_split=96,max_depth=10, min_samples_leaf=5, max_features=43)\ny_pred =best_tree.fit(X_train, y_train).predict(X_valid)\naccuracy_score(y_valid, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Графическое изображение полученного дерева"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import export_graphviz\n\nexport_graphviz(best_tree, out_file='best_tree.dot', feature_names=X.columns)\nprint(open('best_tree.dot').read())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Сделано с помощью https://dreampuf.github.io/GraphvizOnline/ \n\n[Картинка](https://drive.google.com/file/d/1GYizXOC9K3MscGKf2PW6EzoqI3kRx1Na/view?usp=sharing) слишком большого размера, Kaggle не позволяет сохранять. "},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfeatures = {'f'+str(i+1):name for (i, name) in zip(range(len(ddf.columns)), ddf.columns)}\n\n# Важность признаков\n\nimportances = best_tree.feature_importances_\n\nindices = np.argsort(importances)[::-1]\n# Plot the feature importancies of the tree\nnum_to_plot = 10\nfeature_indices = [ind+1 for ind in indices[:num_to_plot]]\n\n# Print the feature ranking\nprint(\"Feature ranking:\")\n\nfor f in range(num_to_plot):\n    print(f+1, features[\"f\"+str(feature_indices[f])], importances[indices[f]])\n\nplt.figure(figsize=(15,5))\nplt.title(\"Feature importances\")\nbars = plt.bar(range(num_to_plot), \n               importances[indices[:num_to_plot]],\n               color=([str(i/float(num_to_plot+1)) for i in range(num_to_plot)]),\n               align=\"center\")\nticks = plt.xticks(range(num_to_plot), \n                   feature_indices)\nplt.xlim([-1, num_to_plot])\nplt.legend(bars, [u''.join(features[\"f\"+str(i)]) for i in feature_indices]);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"В итоге лучшей оказалась модель построенная с такими параметрами: min_samples_split=85,max_depth=9, min_samples_leaf=14, max_features=33. Работает с точностью 82%. Самым влиятельным из гиперпараметров оказался max_depth- его корректировка привела к улучшению сразу на 5%. Самый влиятельный из признаков: duration, продолжительность разговора."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn. preprocessing import LabelEncoder\n\nddf=df.copy()\nle = LabelEncoder()\nle.fit(df.job)\nddf['job']=le.transform(df.job)\n\nle = LabelEncoder()\nle.fit(df.education)\nddf['education']=le.transform(df.education)\n\nle = LabelEncoder()\nle.fit(df.marital)\nddf['marital']=le.transform(df.marital)\n\nle = LabelEncoder()\nle.fit(df.contact)\nddf['contact']=le.transform(df.contact)\n\nle = LabelEncoder()\nle.fit(df.poutcome)\nddf['poutcome']=le.transform(df.poutcome)\n\nle = LabelEncoder()\nle.fit(df.month)\nddf['month']=le.transform(df.month)\n\nddf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ddf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX=ddf.drop('deposit',axis=1)\ny=ddf['deposit']\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier()\nrf.fit(X_train, y_train)\ny_pred = rf.predict(X_valid)\n\naccuracy_score(y_valid, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# GridSearchCV\nkf = KFold(n_splits=5, shuffle=True, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**n_estimators**"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier()\nrf_params_n_estimators = {'n_estimators': np.arange(25, 450, 50)}\n# rf_params_n_estimators\nrf_grid = GridSearchCV(rf, rf_params_n_estimators, cv=kf, scoring='accuracy')\nrf_grid.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_grid_cv_results_n_estimators=rf_grid.cv_results_\nrf_grid.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_grid.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(rf_grid.cv_results_).T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Увеличение количества решающих деревьев в лесу может приводить к улучшению результата, однако это улучшение при увеличении параметров становятся всё незначительнее (ассимптотически, результат приближается ~85%), а время вычисления заметно возрастает. Поэтому можно выбрать оптимальный вариант не максимальным значением."},{"metadata":{"trusted":true},"cell_type":"code","source":"best_rf = RandomForestClassifier(n_estimators=125)\ny_pred =best_rf.fit(X_train, y_train).predict(X_valid)\naccuracy_score(y_valid, y_pred)\n# best_rf.score(X_valid, y_valid)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**max_depth**"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators=125)\nrf_params_max_depth = {'max_depth': np.arange(2, 15)}\nrf_grid = GridSearchCV(rf, rf_params_max_depth, cv=kf, scoring='accuracy')\nrf_grid.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_grid_cv_results_max_depth=rf_grid.cv_results_\nrf_grid.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_grid.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(rf_grid.cv_results_).T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ситуация аналогична с параметраметром n_estimators."},{"metadata":{"trusted":true},"cell_type":"code","source":"best_rf = RandomForestClassifier(n_estimators=125, max_depth=14)\ny_pred =best_rf.fit(X_train, y_train).predict(X_valid)\naccuracy_score(y_valid, y_pred)\n# best_rf.score(X_valid, y_valid)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**min_samples_split**"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators=125,max_depth=14)\nrf_params_min_samples_split = {'min_samples_split': np.arange(2, 20)}\nrf_grid = GridSearchCV(rf, rf_params_min_samples_split, cv=kf, scoring='accuracy')\nrf_grid.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_grid_cv_results_min_samples_split=rf_grid.cv_results_\nrf_grid.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_grid.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(rf_grid.cv_results_).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_rf = RandomForestClassifier(n_estimators=125, max_depth=14,min_samples_split=12)\ny_pred =best_rf.fit(X_train, y_train).predict(X_valid)\naccuracy_score(y_valid, y_pred)\n# best_rf.score(X_valid, y_valid)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**min_samples_leaf**"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators=125,max_depth=14,min_samples_split=12)\nrf_params_min_samples_leaf = {'min_samples_leaf': np.arange(1, 50)}\nrf_grid = GridSearchCV(rf, rf_params_min_samples_leaf, cv=kf, scoring='accuracy')\nrf_grid.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_grid_cv_results_min_samples_leaf=rf_grid.cv_results_\nrf_grid.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_grid.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(rf_grid.cv_results_).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_rf = RandomForestClassifier(n_estimators=125, max_depth=14,min_samples_split=12,min_samples_leaf=4)\ny_pred =best_rf.fit(X_train, y_train).predict(X_valid)\naccuracy_score(y_valid, y_pred)\n# best_rf.score(X_valid, y_valid)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**max_features**"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators=125, max_depth=14,min_samples_split=12,min_samples_leaf=4)\nrf_params_max_features = {'max_features': np.arange(2, X.shape[1])}\nrf_grid = GridSearchCV(rf, rf_params_max_features, cv=kf, scoring='accuracy')\nrf_grid.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_grid_cv_results_max_features=rf_grid.cv_results_\nrf_grid.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_grid.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(rf_grid.cv_results_).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_rf = RandomForestClassifier(n_estimators=125, max_depth=14,min_samples_split=5,min_samples_leaf=4,max_features=14)\ny_pred =best_rf.fit(X_train, y_train).predict(X_valid)\naccuracy_score(y_valid, y_pred)\n# best_rf.score(X_valid, y_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfig, ax = plt.subplots(nrows=1, ncols=5, sharey=True,figsize=(25, 5))\n\nax[0].plot(rf_params_max_depth['max_depth'], rf_grid_cv_results_max_depth['mean_test_score'])\nax[0].set_xlabel('max_depth')\nax[0].set_ylabel('Mean accuracy on test set')\n\nax[1].plot(rf_params_min_samples_split['min_samples_split'], rf_grid_cv_results_min_samples_split['mean_test_score'])\nax[1].set_xlabel('min_samples_split')\nax[1].set_ylabel('Mean accuracy on test set')\n\nax[2].plot(rf_params_min_samples_leaf['min_samples_leaf'], rf_grid_cv_results_min_samples_leaf['mean_test_score'])\nax[2].set_xlabel('min_samples_leaf')\nax[2].set_ylabel('Mean accuracy on test set')\n\nax[3].plot(rf_params_max_features['max_features'], rf_grid_cv_results_max_features['mean_test_score'])\nax[3].set_xlabel('max_features')\nax[3].set_ylabel('Mean accuracy on test set')\n\nax[4].plot(rf_params_n_estimators['n_estimators'], rf_grid_cv_results_n_estimators['mean_test_score'])\nax[4].set_xlabel('n_estimators')\nax[4].set_ylabel('Mean accuracy on test set')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfeatures = {'f'+str(i+1):name for (i, name) in zip(range(len(ddf.columns)), ddf.columns)}\n\n# Важность признаков\n\nimportances = best_rf.feature_importances_\n\nindices = np.argsort(importances)[::-1]\n# Plot the feature importancies of the forest\nnum_to_plot = 10\nfeature_indices = [ind+1 for ind in indices[:num_to_plot]]\n\n# Print the feature ranking\nprint(\"Feature ranking:\")\n\nfor f in range(num_to_plot):\n    print(f+1, features[\"f\"+str(feature_indices[f])], importances[indices[f]])\n\nplt.figure(figsize=(15,5))\nplt.title(\"Feature importances\")\nbars = plt.bar(range(num_to_plot), \n               importances[indices[:num_to_plot]],\n               color=([str(i/float(num_to_plot+1)) for i in range(num_to_plot)]),\n               align=\"center\")\nticks = plt.xticks(range(num_to_plot), \n                   feature_indices)\nplt.xlim([-1, num_to_plot])\nplt.legend(bars, [u''.join(features[\"f\"+str(i)]) for i in feature_indices]);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[Метод ближайших соседей](https://www.kaggle.com/kyrylveremiov/knn-bank-marketing-dataset) в лучшей конфигурации давал 70% точности. Дерево решений с оптимальным набором гиперпараметров- уже 82%. То есть модель основанная на деревьеях решений намного лучше подходит для данной задачи (Что можно объяснить наличием большого колическтва категориальных данных в data frame). Модель основанная на алгоритме случайного леса дала лучшие результаты (на 2%). И дерево решений, и случайный лес выявивили, что наиболее влиятельным является признак duration- продолжительность разговора.\n\nИтог: Из рассмотренных моделей для данного датасета самым оптимальным оказался лес деревьев решений с гиперпараметрами: \nn_estimators=125, max_depth=14,min_samples_split=5,min_samples_leaf=4,max_features=14"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}