{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Problem","execution_count":null},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"\nŞirketi terk edecek müşterileri tahmin edebilecek bir makine öğrenmesi modeli geliştirebilir misiniz?\n\nAmaç bir bankanın müşterilerinin bankayı terk etme ya da terk etmeme durumunun tahmin edilmesidir.\n\nMüşteri terkini tanımlayan olay müşterinin banka hesabını kapatmasıdır.\n\nVeri Seti Hikayesi:\n\n10000 gözlemden ve 12 değişkenden oluşmaktadır.\nBağımsız değişkenler müşterilere ilişkin bilgiler barındırmaktadır.\nBağımlı değişken müşteri terk durumunu ifade etmektedir.\nDeğişkenler:\n\nSurname : Soy isim\nCreditScore : Kredi skoru\nGeography : Ülke (Germany/France/Spain)\nGender : Cinsiyet (Female/Male)\nAge : Yaş\nTenure : Kaç yıllık müşteri\nBalance : Bakiye\nNumOfProducts : Kullanılan banka ürünü\nHasCrCard : Kredi kartı durumu (0=No,1=Yes)\nIsActiveMember : Aktif üyelik durumu (0=No,1=Yes)\nEstimatedSalary : Tahmini maaş\nExited : Terk mi değil mi? (0=No,1=Yes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Understanding","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.linear_model import LogisticRegression  \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier \nfrom sklearn.ensemble import RandomForestClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score, GridSearchCV,train_test_split,cross_val_score\nimport itertools\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.neighbors import LocalOutlierFactor # çok değişkenli aykırı gözlem incelemesi\nfrom sklearn.preprocessing import scale,StandardScaler, MinMaxScaler,Normalizer,RobustScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import  accuracy_score, f1_score, precision_score,confusion_matrix, recall_score, roc_auc_score\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) \nwarnings.filterwarnings(\"ignore\", category=FutureWarning) \nwarnings.filterwarnings(\"ignore\", category=UserWarning) \n\n%config InlineBackend.figure_format = 'retina'\n\n# to display all columns and rows:\npd.set_option('display.max_columns', None); pd.set_option('display.max_rows', None);\ndf = pd.read_csv(\"../input/churn-for-bank-customers/churn.csv\" , index_col=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1.Data Preprocessing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Exited\"].value_counts()*100/len(df)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nlabels = 'Exited', 'Retained'\nsizes = [df.Exited[df['Exited']==1].count(), df.Exited[df['Exited']==0].count()]\nexplode = (0, 0.1)\nfig1, ax1 = plt.subplots(figsize=(10, 8))\nax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n        shadow=True, startangle=90)\nax1.axis('equal')\nplt.title(\"Proportion of customer churned and retained\", size = 20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axarr = plt.subplots(2, 2, figsize=(20, 12))\nsns.countplot(x='Geography', hue = 'Exited',data = df, ax=axarr[0][0])\nsns.countplot(x='Gender', hue = 'Exited',data = df, ax=axarr[0][1])\nsns.countplot(x='HasCrCard', hue = 'Exited',data = df, ax=axarr[1][0])\nsns.countplot(x='IsActiveMember', hue = 'Exited',data = df, ax=axarr[1][1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop([ \"CustomerId\", \"Surname\" ], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.pairplot(df, hue = \"Exited\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# burada bağımlı değişkeni, \"Exited\" u yukarıdaki gibi satıra ve sütüna koymadan gösterdik. yani \"Exited\" gösterip boş göstermedi\n# regresyon eğrilerin icin kind argumanini kullaniyorum \n# burada sdf dataframindeki [\"Age\", \"Balance\",\"Tenure\",\"EstimatedSalary\",\"CreditScore\"] değişkenleri seçtik.\nsns.pairplot(df, vars = [\"Age\", \"Balance\",\"Tenure\",\"EstimatedSalary\",\"CreditScore\"], \n             hue = \"Exited\",\n            kind = \"reg\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1.1 one hot encoding","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.get_dummies(df, columns = {\"Gender\", \"Geography\"})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1.2 outliers","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in df:\n    \n    Q1 = df[feature].quantile(0.05)\n    Q3 = df[feature].quantile(0.95)\n    IQR = Q3-Q1\n    lower = Q1- 1.5*IQR\n    upper = Q3 + 1.5*IQR\n    \n    if df[(df[feature] > upper)].any(axis=None):\n        print(feature,\"yes\")\n    else:\n        print(feature, \"no\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=df.NumOfProducts);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Q1 = df[\"NumOfProducts\"].quantile(0.05)\nQ3 = df[\"NumOfProducts\"].quantile(0.95)\nIQR = Q3-Q1\nupper = Q3 + 1.5*IQR\nupper","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df[\"NumOfProducts\"] > upper]\ndf.loc[df[\"NumOfProducts\"] > upper, \"NumOfProducts\"] = upper","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(\"Exited\" ).agg({\"CreditScore\":\"mean\" , \"Tenure\":\"mean\" ,\"Balance\":\"mean\",  } ).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. FEATURE ENGINEERING","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"ÖN BILGI :\n\nKredi ya da kredi kartı vermek için bankanın belirlediği alt sınır bankadan bankaya, almak istediğiniz tutara ve gelir durumunuza göre değişse bile Findeks kredi notu aralıklarının anlamı şöyle:\n\nKredi Notu\n\n0 - 699  = Risk Grubu\n\n700 - 1099 = En riskli\n\n1100 - 1499 = Orta riskli\n\n1500 - 1699 = Az riskli\n\n1700 - 1900 = Iyi\n\n1500 - 1900 = Çok İyi","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"CreditScore\"].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"CreditScore\"].min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sonuc olarak verimizde max ve min kredi skoru 350 ve 850 arsinda degisiyor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def CreditScore(kredi_skoru):\n    \n    if 300<= kredi_skoru < 500:\n        return \"Cok riskli\"\n    elif 500<=kredi_skoru < 700:\n        return \"Riskli\"\n    elif  700<= kredi_skoru < 800:\n        return \"Iyi\"\n    elif  800<=  kredi_skoru < 850:\n        return \"Cok iyi\"\n    elif  850 <= kredi_skoru: \n        return \"Harika\"\n    elif 300 > kredi_skoru :\n        return \"Berbat\"\n    \ndf['New_CreditScore_status'] = df['CreditScore'].apply(CreditScore)\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #bakiye maas orani","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['New_BalanceSalaryRate'] = df.Balance/df.EstimatedSalary\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#OneHotEncoding yeni degisken icin yapmam lazim","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df =pd.get_dummies(df, columns = [\"New_CreditScore_status\"], drop_first = True, dummy_na = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.New_CreditScore_status_nan.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop([ \"New_CreditScore_status_nan\" ], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df[\"Exited\"]\nX = df.drop([\"Exited\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3.Standardization","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"scaled_cols=StandardScaler().fit_transform(X)\nscaled_cols=pd.DataFrame(scaled_cols, columns=X.columns)\nscaled_cols.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4.Modeling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tum modellerin train validasyon skorları\n\nmodels = []\nmodels.append(('LR', LogisticRegression()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('RF', RandomForestClassifier()))\nmodels.append(('SVM', SVC(gamma='auto')))\nmodels.append(('XGB', GradientBoostingClassifier()))\n\n# evaluate each model in turn\nresults = []\nnames = []\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 12345)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nresults = []\nnames = []\n\nfor name, model in models:\n    \n        kfold = KFold(n_splits = 10, random_state = 12345)\n        cv_results = cross_val_score(model, X_train, y_train, cv = kfold, scoring= \"accuracy\")\n        results.append(cv_results)\n        names.append(name)\n        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n        print(msg)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for name, model in models:\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n        acc = accuracy_score(y_test, y_pred)\n        msg = \"%s: (%f)\" % (name, acc)\n        print(msg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4.1 Model Tuning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4.1.1 Model Installation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"#  RandomForest","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_model = RandomForestClassifier(random_state = 12345).fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = rf_model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"cross_val_score : \", cross_val_score(rf_model, X_train, y_train, cv = 10).mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# RandomForest Tuning","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_params = {\"max_depth\": [5,8,10,None],\n            \"max_features\": [2,5,10,15,17],\n            \"n_estimators\": [100,200, 500, 1000],\n            \"min_samples_split\": [2,5,10,20,30]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_cv_model = RandomizedSearchCV(estimator= rf_model, param_distributions = rf_params, n_iter=50, cv=10, scoring='accuracy', n_jobs=-1, verbose=2).fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_cv_model.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_tuned = RandomForestClassifier(**rf_cv_model.best_params_).fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = rf_tuned.predict(X_test)\n\nprint(\"cross_val_score : \", cross_val_score(rf_tuned, X_train, y_train, scoring='accuracy', cv = 10, n_jobs=-1, verbose=2).mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nprint('RandomForest model accuracy score: {0:0.2f}'. format(accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# XGB","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb = XGBClassifier().fit(X_train,y_train)\ny_pred = xgb.predict(X_test)\n\nprint(\"cross_val_score : \", cross_val_score(xgb, X_train, y_train, cv = 10).mean())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# XGB Tuning ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_params = {\"learning_rate\": [0.1,0.01,0.5],\n             \"max_depth\": [2,3,4,5,8],\n             \"n_estimators\": [100,200,500,1000],\n             \"colsample_bytree\": [0.4,0.7,1]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_rsc = RandomizedSearchCV(estimator=xgb, param_distributions=xgb_params, n_iter=50, cv=10, scoring='accuracy', n_jobs=-1, verbose=2).fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_rsc.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_tuned = XGBClassifier(**xgb_rsc.best_params_).fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = xgb_tuned.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"cross_val_score : \", cross_val_score(xgb_tuned, X_train, y_train, cv = 10).mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nprint('XGBoost model accuracy score: {0:0.2f}'. format(accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. FEATURE IMPORTANCE","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 5.1   XGB","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nImportance = pd.DataFrame({'Importance':xgb_tuned.feature_importances_*100},\n                          index = X_train.columns)\nImportance.sort_values(by = 'Importance',\n                       axis = 0,\n                       ascending = True).plot(kind = 'barh',\n                                              color = 'r', )\nplt.xlabel('Variable Importance')\nplt.gca().legend_ = None","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5.2 RandomForest","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Importance = pd.DataFrame({'Importance':rf_tuned.feature_importances_*100},\n                          index = X_train.columns)\nImportance.sort_values(by = 'Importance',\n                       axis = 0,\n                       ascending = True).plot(kind = 'barh',\n                                              color = 'r', )\nplt.xlabel('Variable Importance')\nplt.gca().legend_ = None","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6.Confusion Matrix","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import rc,rcParams\ndef plot_confusion_matrix(cm, classes,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n\n    plt.rcParams.update({'font.size': 19})\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title,fontdict={'size':'16'})\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45,fontsize=13,color=\"blue\")\n    plt.yticks(tick_marks, classes,fontsize=12,color=\"blue\")\n    rc('font', weight='bold')\n    fmt = '.1f'\n    thresh = cm.max()\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"red\")\n\n    plt.ylabel('True label',fontdict={'size':'16'})\n    plt.xlabel('Predicted label',fontdict={'size':'16'})\n    plt.tight_layout()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cfm = confusion_matrix(y_test, y_pred=y_pred)\nplot_confusion_matrix(cfm, classes=['Non Exited','Exited'],\n                      title='Churn Confusion matrix')\ntn, fp, fn, tp = cfm.ravel()\nprint(\"True Negatives: \",tn)\nprint(\"False Positives: \",fp)\nprint(\"False Negatives: \",fn)\nprint(\"True Positives: \",tp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7.Reporting","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#  Churn veri seti input edildi.\n\n#  1. Veri analizi veri ön isleme yapildi.\n#    * Aykiri gözlem yapildi\n#    * One hot encoding yapildi\n\n#  2.Feature Enginering yapildi\n\n#  3.Standardization\n\n#  4.Alti  tane  Model ayni anda kuruldu ve en iyi modelllrin RandomForest  ve XGB oldugu saptandi. \n\n#  4.1.RandomForest ve XGB modeli  tun edildi ve en iyi sonuc amaclandi.\n\n#  5.Degisken onem siralarina bakildi bu iki modelde.\n\n#  6.Model sonucu: sonuc sayilari yazdirilarak görselestirildi.       ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}