{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Basic Done Right"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.read_csv('../input/insurance.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#convert columns to catgorical columns\n#Not needed \n#data['sex']=pd.Categorical(data['sex'])\n#data['region']=pd.Categorical(data['region'])\n#data['smoker']=pd.Categorical(data['smoker'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create new column based on healthiness\n\n#data=data.drop(columns='healthy')\ndata['healthy'] =np.nan","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fun(bmi_str):\n    if (bmi_str >=18.5 and bmi_str <= 24.9) :\n        return 1\n    else:\n        return 0\n\ndata['healthy']=data['bmi'].apply(fun)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#only if its in object format it can be processed using one hot encoding\ndata['healthy']=data['healthy'].astype(object)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Checking normality and correlation"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(data['age'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(data['bmi'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(data['children'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.value_counts(data['smoker'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(y='charges',x='smoker',data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Explaining ANOVA - not used in the code"},{"metadata":{"trusted":true},"cell_type":"code","source":"#This tab is not used. Anova is used while comaring \n\ndata_smoker=data[data['smoker']=='yes']\ndata_no_smoker=data[data['smoker']=='no']\ndata_smoker=(data_smoker['charges']).astype(int)\ndata_no_smoker=(data_no_smoker['charges']).astype(int)\n\n\nplt.figure(figsize=(10,5))\nplt.subplot(1,2,1)\nsns.distplot(data_smoker)\nplt.subplot(1,2,2)\nsns.distplot(data_no_smoker)\n\n#these are independent columns,\nfrom scipy.stats import mannwhitneyu\nz_statistic,p_value=mannwhitneyu(data_no_smoker,data_smoker)\nprint(z_statistic,p_value)\n\n#Since p<0.05 ,null hyp is rejected. Thus both columns are from different population(Different mean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.value_counts(data['sex'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(y='charges',x='sex',data=data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#This tab is not used. Anova is used while comaring \n\ndata_male=data[data['sex']=='male']\ndata_female=data[data['sex']=='female']\ndata_male=(data_male['charges']).astype(int)\ndata_female=(data_female['charges']).astype(int)\n\n\nplt.figure(figsize=(10,5))\nplt.subplot(1,2,1)\nsns.distplot(data_male)\nplt.subplot(1,2,2)\nsns.distplot(data_female)\n\n#these are independent columns,\nfrom scipy.stats import mannwhitneyu,ttest_ind\nz_statistic,p_value=mannwhitneyu(data_male,data_female)\nz_statistic_ttest,p_value_ttest=mannwhitneyu(data_male,data_female)\nprint(z_statistic,p_value)\nprint(z_statistic_ttest,p_value_ttest)\n\n#Since p>0.05 ,null hyp is accepted. Thus both columns are from same population(same mean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.value_counts(data['region'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(y='charges',x='region',data=data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#This tab is not used. Anova is used while comaring \n\ndata_reg1=data[data['region']=='southeast']\ndata_reg2=data[data['region']=='southwest']\ndata_reg3=data[data['region']=='northwest']\ndata_reg4=data[data['region']=='northeast']\ndata_reg1=(data_reg1['charges']).astype(int)\ndata_reg2=(data_reg2['charges']).astype(int)\ndata_reg3=(data_reg3['charges']).astype(int)\ndata_reg4=(data_reg4['charges']).astype(int)\n\n\nplt.figure(figsize=(10,5))\nplt.subplot(2,2,1)\nsns.distplot(data_reg1)\nplt.subplot(2,2,2)\nsns.distplot(data_reg2)\nplt.subplot(2,2,3)\nsns.distplot(data_reg3)\nplt.subplot(2,2,4)\nsns.distplot(data_reg4)\n\n#these are independent columns,Following ANOVA - since there are more than 2 categories(columns)\nfrom statsmodels.formula.api import ols \nfrom statsmodels.stats.anova import anova_lm\nfrom statsmodels.stats.multicomp import pairwise_tukeyhsd, MultiComparison\n\nformula = 'charges ~ C(region)'\nmodel = ols(formula, data).fit()\naov_table = anova_lm(model)\nprint(aov_table)\n\n\n#Since p<0.05 ,null hyp is rejected. So we must use multi comparison(Refer one way anova- golf exapmle)\n\nmc = MultiComparison(data['charges'], data['region'])\nresult = mc.tukeyhsd()\n \nprint(result)\nprint(mc.groupsunique)\n\n#for all other case except last one - 0 is in between lower and upper bound values. So accept null hyp(mean is equal) \n#for those and reject for last case. \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.value_counts(data['healthy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(y='charges',x='healthy',data=data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(y='charges',x='children',data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Chi Square Testing"},{"metadata":{"trusted":true},"cell_type":"code","source":"#find correlation in case of categorical data\n\nfrom scipy.stats import chisquare,chi2_contingency\n\nprint(chisquare(data[\"sex\"].value_counts()))\nprint(chisquare(data[\"smoker\"].value_counts()))\nprint(chisquare(data[\"region\"].value_counts()))\nprint(chisquare(data[\"healthy\"].value_counts()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Goodness of Fit Test between 2 categorical variables\n\n# H0: The two categorical variables are independent\n# Ha: The two categorical variables are dependent\n\n# Creating contingency table\ncont = pd.crosstab(data[\"sex\"],\n                   data[\"smoker\"])\n\nprint(cont)\nprint(chi2_contingency(cont))\n\n#The p-value 0.006 < 0.05 hence we conclude that the 2 categorical variables are dependent","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cont = pd.crosstab(data[\"smoker\"],\n                   data[\"region\"])\n\nprint(cont)\nprint(chi2_contingency(cont))\n\n#The p-value 0.06 > 0.05 hence we conclude that the 2 categorical variables are independent","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cont = pd.crosstab(data[\"smoker\"],\n                   data[\"healthy\"])\n\nprint(cont)\nprint(chi2_contingency(cont))\n\n#The p-value 0.46 > 0.05 hence we conclude that the 2 categorical variables are independent","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cont = pd.crosstab(data[\"sex\"],\n                   data[\"healthy\"])\n\nprint(cont)\nprint(chi2_contingency(cont))\n\n#The p-value 0.40 > 0.05 hence we conclude that the 2 categorical variables are independent","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correlation=data.corr()\ncorrelation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert categorical variable into dummy/indicator variables. As many columns will be created as distinct values\n# This is also kown as one hot coding. The column names will be America, Europe and Asia... with one hot coding\n# Like feature scaling\n\n#Replace 1 and 0 with values in healthy column\ndata['healthy'] = data['healthy'].replace({0:'not_healthy', 1:'healthy'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#one hot coding\ndata=pd.get_dummies(data,columns=['sex','smoker','region','healthy'],drop_first='True')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"#PREPROCESSING DATA - Standardization and training data split\n\nfrom sklearn import preprocessing\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\nX=data.drop(columns='charges')\ny=data['charges']\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.5,random_state=1)\n\n# Create the Scaler object\nscaler = preprocessing.StandardScaler()\n\n#feature scaling in dependent and independent columns\nX_train=scaler.fit_transform(X_train)\nX_test=scaler.transform(X_test)\n\n        #Gets some error\n#y_train=scaler.fit_transform(y_train)\n#y_test=scaler.transform(y_test)\n\nlinear_reg=LinearRegression()\nlinear_reg.fit(X_train,y_train)\n\nlinear_reg.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Linear Regression - 2 types"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using SKLEARN  - Without Standardized\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\nX=data.drop(columns='charges')\ny=data['charges']\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.5,random_state=1)\nlinear_reg=LinearRegression()\nlinear_reg.fit(X_train,y_train)\n\nlinear_reg.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using OLS method\n\nfrom statsmodels.formula.api import ols   \n\nformula='charges ~ healthy_not_healthy +  smoker_yes + sex_male + children + age + bmi'\nmodel=ols(formula,data).fit()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Polynomial Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Polynomial regression\n\n\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn import linear_model\n\nX1=data.drop(columns='charges')\ny1=data['charges']\n\nX_poly_train,X_poly_test,y_poly_train,y_poly_test=train_test_split(X1,y1,test_size=0.25,random_state=1)\n\npoly = PolynomialFeatures(degree=2, interaction_only=True)\n\nX1_poly_train=poly.fit_transform(X_poly_train)\nX1_poly_test=poly.fit_transform(X_poly_test)\n\nlin=linear_model.LinearRegression()\nlin.fit(X1_poly_train,y_poly_train)\n\ny_pred=lin.predict(X1_poly_test)\n\nlin.score(X1_poly_test,y_poly_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thus by using this we get higher value."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":1}