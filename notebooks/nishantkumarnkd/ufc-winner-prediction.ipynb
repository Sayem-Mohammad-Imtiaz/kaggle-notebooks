{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfights = pd.read_csv('../input/ufcdata/data.csv')\nfights\n#to find missing values\nfights.isnull().sum()\n#retain only  those columns or features having at least 4800 non na values \nfights.dropna(thresh=4800,inplace=True,axis=1)\n#filling missing values\nfights.fillna({'B_Height_cms':fights['B_Height_cms'].median(),\n               'B_Weight_lbs':fights['B_Weight_lbs'].median(),\n                'R_Reach_cms':fights['R_Reach_cms'].median(),\n                'R_Weight_lbs':fights['R_Weight_lbs'].median(),\n                 'B_age':fights['B_age'].median(),\n                'R_age':fights['R_age'].median(),\n                 'R_Height_cms':fights['R_Height_cms'].median()},inplace=True)\nimport scipy.stats\ncrosstab = pd.crosstab(fights['Winner'],fights['R_Stance'])\nchi = scipy.stats.chi2_contingency(crosstab)\nchi\n#R_stance should be dropped as it has no correlation with the output\nfights.drop(columns=['B_Stance','R_Stance'],inplace=True)\n\n# as herb dean is the most popular and more frequently occur in the referee column\nimport numpy as np\nfights['Referee']= fights['Referee'].replace(np.NaN , 'Herb Dean')\nfights\n\nfrom sklearn.model_selection import train_test_split\ny = fights['Winner']\nfights.drop(columns='Winner',inplace=True)\n\nX_train,X_test,y_train,y_test = train_test_split(fights,y,test_size=0.3,random_state=42)\n\n#label encoding the categorical columns present in our train data\nfrom sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\n\nfor col in X_train.columns.values:\n\n       if X_train[col].dtypes=='object':\n            data=X_train[col].append(X_train[col])\n            le.fit(data.values)\n            X_train[col]=le.fit_transform(X_train[col])\n            \n#label encoding the categorical columns present in our test data\nfrom sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\n\nfor col in X_test.columns.values:\n\n       if X_test[col].dtypes=='object':\n            data=X_test[col].append(X_test[col])\n            le.fit(data.values)\n            X_test[col]=le.transform(X_test[col])\n\n# scaling our data to normalize the influence of all the features with respect to the output\nfrom sklearn.preprocessing import MinMaxScaler\nminmaxscaling = MinMaxScaler()\nX_train_scaled = minmaxscaling.fit_transform(X_train)\nX_test_scaled = minmaxscaling.transform(X_test)\n\nfrom sklearn.metrics import confusion_matrix,balanced_accuracy_score,accuracy_score,classification_report\n\n\n#using adaptive boosting technique\nfrom sklearn.ensemble import AdaBoostClassifier\nada = AdaBoostClassifier(n_estimators=130,learning_rate=.65)\nada.fit(X_train_scaled,y_train)\npredicted_ada = ada.predict(X_test_scaled)\npredicted_ada\n\n#checking score\naccuracy_score(y_test,predicted_ada)*100\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}