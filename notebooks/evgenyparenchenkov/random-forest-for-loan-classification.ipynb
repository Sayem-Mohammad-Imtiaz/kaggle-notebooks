{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook provides a baseline loan applications classifier based on Scikit-Learn's Random Forest. It doesn't include complex feature engineering, but provides high F1 and ROC AUC score on 5-fold cross-validation.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import cross_validate, StratifiedKFold\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import roc_auc_score, f1_score, make_scorer\n\nimport hashlib","metadata":{"execution":{"iopub.status.busy":"2021-09-12T16:53:56.464759Z","iopub.execute_input":"2021-09-12T16:53:56.465647Z","iopub.status.idle":"2021-09-12T16:53:57.47246Z","shell.execute_reply.started":"2021-09-12T16:53:56.465522Z","shell.execute_reply":"2021-09-12T16:53:57.471658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set path for project files\nfpath = ('../input/should-this-loan-be-approved-or-denied/')","metadata":{"execution":{"iopub.status.busy":"2021-09-12T16:55:22.286855Z","iopub.execute_input":"2021-09-12T16:55:22.287693Z","iopub.status.idle":"2021-09-12T16:55:22.292261Z","shell.execute_reply.started":"2021-09-12T16:55:22.28763Z","shell.execute_reply":"2021-09-12T16:55:22.291486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's read CSV and take a look at our data\n# We drop unique ID and borrower's organization name right away as they are useless or even noisy as features;\n# Also we drop ChgOffDate, ChgOffPrinGr because they can directly tell us that the loan is charged-off\n# 'ApprovalDate', 'ApprovalFY', 'DisbursementDate' are dropped to make the model time-independent\ndata = pd.read_csv(fpath + 'SBAnational.csv').drop(columns=['LoanNr_ChkDgt', 'Name', 'ChgOffDate', 'ChgOffPrinGr',\n                                                            'ApprovalDate', 'ApprovalFY', 'DisbursementDate'])\nlen_data = len(data)\ndata","metadata":{"execution":{"iopub.status.busy":"2021-09-12T16:55:23.559471Z","iopub.execute_input":"2021-09-12T16:55:23.560308Z","iopub.status.idle":"2021-09-12T16:55:29.5106Z","shell.execute_reply.started":"2021-09-12T16:55:23.560258Z","shell.execute_reply":"2021-09-12T16:55:29.509696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's convert the strings styled as '$XXXX.XX' to float values\nmoney_cols = ['DisbursementGross', 'BalanceGross', 'GrAppv', 'SBA_Appv']\n\nfor col in money_cols:\n  data[col] = [float(val[1:].replace(',', '')) for val in data[col].values]","metadata":{"execution":{"iopub.status.busy":"2021-09-12T16:56:03.483928Z","iopub.execute_input":"2021-09-12T16:56:03.484589Z","iopub.status.idle":"2021-09-12T16:56:06.5486Z","shell.execute_reply.started":"2021-09-12T16:56:03.484548Z","shell.execute_reply":"2021-09-12T16:56:06.547668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's check our data for missing values and fill NAs with mode\nfor col in data.drop(columns=['MIS_Status']).columns:\n  if data[col].isna().any():\n    data[col] = data[col].fillna(data[col].mode().iloc[0])","metadata":{"execution":{"iopub.status.busy":"2021-09-12T16:56:11.9893Z","iopub.execute_input":"2021-09-12T16:56:11.989873Z","iopub.status.idle":"2021-09-12T16:56:14.230254Z","shell.execute_reply.started":"2021-09-12T16:56:11.989809Z","shell.execute_reply":"2021-09-12T16:56:14.229263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We have many columns with Object dtype; let's apply one hot encoding\n# (if the number of unique values is relatively small)\n# or hashing if there are many uniques\n# The only exception is MIS_Status (our target) variable: it is 'PIF' if the loan is returned\n# and 'CHGOFF' if the borrower had a debt\ncols_to_drop = []\n\nfor col in data.drop(columns=['MIS_Status']).columns:\n  if data[col].dtype == 'object':\n    print(f'Column {col} has {data[col].nunique()} values among {len_data}')\n\n    if data[col].nunique() < 25:\n      print(f'One-hot encoding of {col}')\n      one_hot_cols = pd.get_dummies(data[col])\n      for ohc in one_hot_cols.columns:\n        data[col + '_' + ohc] = one_hot_cols[ohc]\n    else:\n      print(f'Hashing of {col}')\n      data[col + '_hash'] = data[col].apply(lambda row: int(hashlib.sha1((col + \"_\" + str(row)).encode('utf-8')).hexdigest(), 16) % len_data)\n\n    cols_to_drop.append(col)","metadata":{"execution":{"iopub.status.busy":"2021-09-12T16:56:19.754918Z","iopub.execute_input":"2021-09-12T16:56:19.755895Z","iopub.status.idle":"2021-09-12T16:56:30.02123Z","shell.execute_reply.started":"2021-09-12T16:56:19.755844Z","shell.execute_reply":"2021-09-12T16:56:30.020618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converting target variable from string to binary\ndata = data.drop(columns=cols_to_drop)\n\ndata['Defaulted'] = [1 if app == 'CHGOFF' else 0 for app in data.MIS_Status.values]\ndata = data.drop(columns=['MIS_Status'])","metadata":{"execution":{"iopub.status.busy":"2021-09-12T16:56:30.071074Z","iopub.execute_input":"2021-09-12T16:56:30.071849Z","iopub.status.idle":"2021-09-12T16:56:30.845342Z","shell.execute_reply.started":"2021-09-12T16:56:30.071816Z","shell.execute_reply":"2021-09-12T16:56:30.844591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Finally, our data looks like this:\ndata","metadata":{"execution":{"iopub.status.busy":"2021-09-12T16:56:50.258383Z","iopub.execute_input":"2021-09-12T16:56:50.259198Z","iopub.status.idle":"2021-09-12T16:56:50.383893Z","shell.execute_reply.started":"2021-09-12T16:56:50.259122Z","shell.execute_reply":"2021-09-12T16:56:50.383275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The dataset is quite imbalanced: the amount of non-defaulted loans is 5x of that of defaulted ones\nprint(data.Defaulted.value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-09-12T17:15:07.985768Z","iopub.execute_input":"2021-09-12T17:15:07.98611Z","iopub.status.idle":"2021-09-12T17:15:07.998382Z","shell.execute_reply.started":"2021-09-12T17:15:07.986073Z","shell.execute_reply":"2021-09-12T17:15:07.997671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's fit and cross-validate a balanced random forest; first, divide the data to X and Y...\nX = data.drop(columns=['Defaulted'])\nY = data.Defaulted","metadata":{"execution":{"iopub.status.busy":"2021-09-12T16:57:05.825859Z","iopub.execute_input":"2021-09-12T16:57:05.82648Z","iopub.status.idle":"2021-09-12T16:57:05.882655Z","shell.execute_reply.started":"2021-09-12T16:57:05.82644Z","shell.execute_reply":"2021-09-12T16:57:05.882014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ...and apply stratified 5-fold validation\nrfc = RandomForestClassifier(class_weight='balanced', random_state=42)\nf1_scorer = make_scorer(f1_score)\nauc_scorer = make_scorer(roc_auc_score)\ncross_validate(rfc, X, Y, cv=StratifiedKFold(random_state=42, shuffle=True), scoring=['f1_weighted', 'roc_auc'],\n               n_jobs=-1, verbose=10)","metadata":{"execution":{"iopub.status.busy":"2021-09-12T16:57:12.111673Z","iopub.execute_input":"2021-09-12T16:57:12.112505Z","iopub.status.idle":"2021-09-12T17:05:04.014781Z","shell.execute_reply.started":"2021-09-12T16:57:12.11246Z","shell.execute_reply":"2021-09-12T17:05:04.01407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see, this model provides average F1 of 0.94 and average ROC AUC of 0.97, which is close to 1 and, thus, efficient to detect potentially risky loan applications. To improve the baseline solution, we can:\n- dive deeper into the problem and create new informative features;\n- apply more sophisticated methods, such as boosting or deep learning;\n- try to use oversampling techniques.\n\nThanks for your attention :)","metadata":{}}]}