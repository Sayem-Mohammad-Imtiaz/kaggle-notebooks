{"cells":[{"cell_type":"markdown","metadata":{},"source":"# How To Compute Notebook Rankings\n\nThis notebook attempts to recompute the notebook ranking points for all users.\n\nKaggle is pretty open about how the voting system works, see this from the [progression](https://www.kaggle.com/progression) guide:\n\n___________________________\n\n\n<div style=\"background:#f0f0f0; padding: 1em;\">\n\n<h3>Points</h3>\n\n<p>While tiers and medals are permanent representations of a data scientist’s achievements, points are designed to decay over time. This keeps Kaggle’s rankings contemporary and competitive. All points awarded decay in a consistent way using the formula below:</p>\n\n$$e^{-t/500}$$\n\nIn this formula, t is the number of days elapsed since the point was awarded. \n\n\n<h3>Notebook Medals</h3>\n\nNotebook Medals are awarded to popular notebooks, as measured by the number of upvotes a notebook receives. Not all upvotes count towards medals: self-votes, votes by novices, and votes on old posts are excluded from medal calculation.\n\n<ul>\n<li>Bronze : 5 Votes\n<li>Silver : 20 Votes\n<li>Gold : 50 Votes\n<ul>\n\n</div>\n\n___________________________\n\n\nWe will see in the notebook that \"self-votes, votes by novices\" also do not apply to the ranking points.\nThere is a 0.97 correlation between my computation of points and Kaggle's own published calculation - whilst most users match very well, intriguingly, some users are WAY off.\nKaggle seems to have boosted the points for some users and taken points away from others.\n\n\n***Why?***\n\n\n## Contents\n\n * [Vote Counts](#Vote-Counts)\n * [V1: Sum of Votes](#V1:-Sum-of-Votes)\n * [V2: Exclude Self Votes and Novices](#V2:-Exclude-Self-Votes-and-Novices)\n * [V3: Add Time Decay](#V3:-Add-Time-Decay)\n * [Comparing Estimate to True Points: Plotly](#Comparing-Estimate-to-True-Points:-Plotly)\n * [Comparing Ranks of Estimated Points: Plotly](#Comparing-Ranks-of-Estimated-Points:-Plotly)\n * [Users With Fewer Points Than Expected](#Users-With-Fewer-Points-Than-Expected)\n * [Users With More Points Than Expected](#Users-With-More-Points-Than-Expected)\n * [Conclusions](#Conclusions)\n"},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":"from jt_mk_utils import *"},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":"import os, sys, re, time\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport seaborn as sns\nfrom IPython.display import HTML, Image, display\nfrom sklearn import linear_model\n\nTIER_COLORS = np.asarray([\"green\", \"blue\", \"purple\", \"orange\", \"gold\", \"black\"])\nTIERS = np.asarray([\"Novice\", \"Contributor\", \"Expert\", \"Master\", \"GrandMaster\", \"Staff\"])"},{"cell_type":"code","execution_count":3,"metadata":{"_kg_hide-input":true},"outputs":[],"source":"plt.rc('figure', figsize=(15, 9))\nplt.rc('font', size=14)\nplt.style.use('bmh')"},{"cell_type":"code","execution_count":4,"metadata":{"_kg_hide-input":true},"outputs":[],"source":"plt.rc('figure', figsize=(15, 9))\nplt.rc('font', size=14)\n\ndef plt_log_scales():\n    plt.yscale('symlog')\n    plt.xscale('symlog')\n    plt.ylim(10)\n    plt.xlim(10)"},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":"kernels = read_kernels(index_col=0)\nkernels.shape"},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":"votes = read_kernel_votes(index_col=0)\nvotes.shape"},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":"ver = read_kernel_versions(\n    usecols=['Id', 'ScriptId', 'AuthorUserId']).set_index('Id')\nver.shape"},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":"votes = votes.join(ver, on='KernelVersionId', how='inner')\nvotes.count()"},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":"UIDS = set(votes.AuthorUserId) | set(votes.UserId)\nusers = read_users(filter=('Id', UIDS)).set_index('Id')\nusers.shape"},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":"votes = votes.join(users[['PerformanceTier']], on='UserId') # UserId is ID of voter"},{"cell_type":"markdown","metadata":{},"source":"# Vote Counts\n\nSince 2020 votes have averaged around 2000 per day"},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":"votes['VoteDate'].value_counts().sort_index().plot()\nplt.title('Notebook Votes');"},{"cell_type":"markdown","metadata":{},"source":"\n***Unfortunately*** : Novices (Tier 0) are the only tier whose votes *do not count for the points/rankings* yet by some way are the largest class of voters!!"},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":"votes['PerformanceTier'].dropna().astype(int).hist()\nplt.title('Voter Tiers');"},{"cell_type":"markdown","metadata":{},"source":"\n### Notebook rankings and points are supposed to be in UserAchievements.csv, however:\n\n[Bug: Users missing from UserAchievements](https://www.kaggle.com/kaggle/meta-kaggle/discussion/181048)\n\n... so I am using a [Kaggle Notebook User Rankings dataset](https://www.kaggle.com/jtrotman/kaggle-notebook-user-rankings) with a saved version of the rankings from the website."},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":"path = '/kaggle/input/kaggle-notebook-user-rankings/NotebookRankings.csv'\n\nuser_achievements = pd.read_csv(\n    path,\n    index_col='UserId',\n    dtype={'Points': 'int'},\n    parse_dates=['RegisterDate'])\nuser_achievements['NotebookCount'] = kernels.AuthorUserId.value_counts()\nuser_achievements.count()"},{"cell_type":"markdown","metadata":{},"source":"# V1: Sum of Votes"},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":"votes['weight'] = 1"},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":"user_achievements['VoteCount'] = votes.groupby('AuthorUserId')['weight'].sum()"},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":"user_achievements[['Points', 'VoteCount']].corr()"},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":"title = 'Top Kaggle Notebook Authors'\nuser_achievements.plot.scatter('VoteCount', 'Points', title=title);\nplt_log_scales();"},{"cell_type":"markdown","metadata":{},"source":"# V2: Exclude Self Votes and Novices"},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":"invalid_vote_index = ((votes.UserId == votes.AuthorUserId) |\n                      (votes.PerformanceTier == 0))\nvotes.loc[invalid_vote_index, 'weight'] = 0"},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":"user_achievements['VoteCount2'] = votes.groupby('AuthorUserId')['weight'].sum()"},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":"user_achievements[['Points', 'VoteCount', 'VoteCount2']].corr()"},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":"user_achievements.plot.scatter('VoteCount2', 'Points', title=title);\nplt_log_scales();"},{"cell_type":"markdown","metadata":{},"source":"# V3: Add Time Decay"},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":"age = votes.VoteDate - votes.VoteDate.max()\nage.describe()"},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":"votes.loc[~invalid_vote_index, 'weight'] = np.exp(age.dt.days / 500)"},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":"votes['weight'].describe()  # max weight is 1, many still 0"},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":"votes['weight'].hist(bins=50, color='g')\nplt.title('Distribution of Notebook Vote \"Weights\"');"},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":"user_achievements['PointsEstimate'] = votes.groupby('AuthorUserId')['weight'].sum()\nuser_achievements['PointsEstimate'] = user_achievements['PointsEstimate'].fillna(1).round(0).astype(int)"},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":"user_achievements[['Points', 'VoteCount', 'VoteCount2', 'PointsEstimate']].corr().style"},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":"user_achievements.plot.scatter('PointsEstimate', 'Points', title=title);\nplt_log_scales();"},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":"df = user_achievements.copy() # join(users.drop(['DisplayName', 'UserName'], 1))"},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":"df['RegisterDateText'] = df.RegisterDate.dt.strftime('%a %-d %B %Y')"},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":"df['TierName'] = TIERS[df.Tier]"},{"cell_type":"markdown","metadata":{},"source":"# Comparing Estimate to True Points: Plotly\n\nWho are the outliers above? Hover to see.\n\nTop tip: click or double-click on the TierName values in the legend to turn points on or off"},{"cell_type":"code","execution_count":32,"metadata":{"_kg_hide-input":true},"outputs":[],"source":"px.scatter(df,\n           'PointsEstimate',\n           'Points',\n           color='TierName',\n           log_x=True,\n           log_y=True,\n           hover_name='DisplayName',\n           hover_data=[\n               'CurrentRanking', 'NotebookCount', 'TotalGold', 'TotalSilver',\n               'TotalBronze', 'UserName', 'RegisterDateText'\n           ],\n           title=title)"},{"cell_type":"markdown","metadata":{},"source":"# Comparing Ranks of Estimated Points: Plotly\n\nPoints are only used to determine a ranking so the effect of a mismatch is actually best shown on a rank vs rank plot.\n\nThose under the line have been demoted, those over the line promoted/boosted.\n"},{"cell_type":"code","execution_count":33,"metadata":{"_kg_hide-input":true},"outputs":[],"source":"df['PointsEstimateRatio'] = df.eval('Points/PointsEstimate')\ndf['PointsEstimateDiff'] = df.eval('Points-PointsEstimate')\ndf['EstimatedRank'] = df.PointsEstimate.rank(ascending=False)\ndf['EstimatedRankDiff'] = df['CurrentRanking'] - df['EstimatedRank']\n\npx.scatter(df,\n           'CurrentRanking',\n           'EstimatedRank',\n           color='TierName',\n           hover_name='DisplayName',\n           hover_data=[\n               'UserName', 'RegisterDateText',\n               'CurrentRanking', #'HighestRanking',\n               'NotebookCount',\n               'TotalGold', 'TotalSilver', 'TotalBronze',\n               'Points', 'PointsEstimate'\n           ],\n           title=title)"},{"cell_type":"code","execution_count":34,"metadata":{"_kg_hide-input":true},"outputs":[],"source":"SHOW = ['User', 'Points', 'PointsEstimate', 'PointsEstimateRatio', 'PointsEstimateDiff']\nBC = '#c0c0c0'\n\n# f'HighestRanking: {r.HighestRanking}\\n'\ndef user_name_link(r):\n    return (f'<a href=\"https://www.kaggle.com/{r.UserName}\" '\n            f' title=\"UserName: {r.UserName}\\n'\n            f'Tier: {TIERS[r.Tier]}\\n'\n            f'RegisterDate: {r.RegisterDate.date()}\\n'\n            f'CurrentRanking: {r.CurrentRanking:.0f}\\n'\n            f'EstimatedRank: {r.EstimatedRank:.0f}\\n'\n            f'EstimatedRankDiff: {r.EstimatedRankDiff:.0f}\\n'\n            f'NotebookCount: {r.NotebookCount:.0f}\\n'\n            f'TotalGold: {r.TotalGold}\\n'\n            f'TotalSilver: {r.TotalSilver}\\n'\n            f'TotalBronze: {r.TotalBronze}\\n'\n            f'VoteCount: {r.VoteCount:.0f}\">'\n            f'{r.DisplayName}</a>')\n\ndef fmt_df(df):\n    df = df.assign(User=df.apply(user_name_link, 1))\n    return df\n\ndef show_df(df):\n    return df[SHOW].set_index('User').style.bar(color=BC, width=85).format({'PointsEstimateRatio': lambda v: f'{v:.3f}'})"},{"cell_type":"markdown","metadata":{},"source":"# Users With Fewer Points Than Expected"},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":"show_df(fmt_df(df.sort_values('PointsEstimateDiff', ascending=True).head(100)))"},{"cell_type":"markdown","metadata":{},"source":"# Users With More Points Than Expected\n\nPossible reasons?\n - The top 3-4 are ex Kaggle staff, maybe the time-decay on their votes was reset when they left?\n - A few have a lot of collaborators on their notebooks(?)\n"},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":"show_df(fmt_df(df.sort_values('PointsEstimateDiff', ascending=False).head(100)))"},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":"# save a snapshot of the source dataset with our extra computations\nuser_achievements.to_csv('NotebookRankings.csv', float_format='%.0f')"},{"cell_type":"markdown","metadata":{},"source":"# Conclusions\n\nAs I said in the intro: Kaggle is pretty open about how the voting system works.\nHowever there is clearly an adjustment layer that means some votes count for less.\n\nI will not try to reverse engineer that system, but we can see the results of it above.\nInformally, I have noticed some effects:\n\n - ***Too much reciprocation*** *A votes for B, then B votes for A*\n - ***Too fast*** *A votes for B say 30 times in just a few minutes (check the KernelVotes.csv for evidence that this happens a lot!)*\n - ***Lack of voter diversity*** *A has 7 votes on 5 Notebooks but always the same 7 users &rarr; No Bronze!*\n \n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":4}