{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Reconnaissance de chiffres manuscrits : MNIST","metadata":{}},{"cell_type":"markdown","source":"## Librairies et fonctions utiles","metadata":{}},{"cell_type":"code","source":"# Pandas : librairie de manipulation de données\n# NumPy : librairie de calcul scientifique\n# MatPlotLib : librairie de visualisation et graphiques\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import metrics\nfrom sklearn import preprocessing\nfrom sklearn import model_selection\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score,auc, accuracy_score\n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nfrom sklearn.model_selection import train_test_split\n\nfrom IPython.core.display import HTML # permet d'afficher du code html dans jupyter","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Le dataset de chiffres manuscrits MNIST","metadata":{}},{"cell_type":"markdown","source":"On charge le dataset MNIST :","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"../input/mnist-in-csv/mnist_test.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On a 785 colonnes :\n* une colonne 'label' identifiant le chiffre  \n* et 784 colonnes de pixels (image de 28x28 pixels \"aplatie\")","metadata":{}},{"cell_type":"code","source":"df.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On crée la cible y (colonne 'label') :","metadata":{}},{"cell_type":"code","source":"y = df['label']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"et les caractéristiques X :","metadata":{}},{"cell_type":"code","source":"X = df.drop(['label'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On sépare les ensembles d'apprentissage et de test :","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On peut maintenant appliquer les méthodes de machine learning, mais auparavant on va visualiser les images","metadata":{}},{"cell_type":"markdown","source":"## Visualisation des images MNIST","metadata":{}},{"cell_type":"markdown","source":"Pour visualiser les images, on va convertir une ligne de 784 pixels en une matrice 28x28  \nIl faut en premier transformer le dataframe X en un tableau :","metadata":{}},{"cell_type":"code","source":"X1 = np.array(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On affiche la première ligne :","metadata":{}},{"cell_type":"code","source":"print(X1[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On applique la méthode **reshape** pour convertir cette ligne de 784 éléments en une matrice 28x28 :","metadata":{}},{"cell_type":"code","source":"image = X1[0].reshape(28,28)\nprint(image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On peut maintenant afficher cette matrice :","metadata":{}},{"cell_type":"code","source":"plt.imshow(image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"en niveaux de gris, sans graduation des axes, et avec le label comme titre :","metadata":{}},{"cell_type":"code","source":"plt.imshow(image, cmap=\"gray_r\")\nplt.axis('off')\nplt.title(y[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On redimensionne toutes les lignes :","metadata":{}},{"cell_type":"code","source":"n_samples = len(df.index)\nimages = X1.reshape(n_samples,28,28)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On affiche les 50 premiers :","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,20))\nfor i in range(0,49) :\n    plt.subplot(10,5,i+1)\n    plt.axis('off')\n    plt.imshow(images[i], cmap=\"gray_r\")\n    plt.title(y[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Machine learning","metadata":{}},{"cell_type":"code","source":"## Machine learning\ndata_train = df.sample(frac=0.8, random_state=1)          # 80% des données avec frac=0.8\ndata_test = df.drop(data_train.index)   \n\nX_train = data_train.drop(['label'], axis=1)\ny_train = data_train['label']\nX_test = data_test.drop(['label'], axis=1)\ny_test = data_test['label']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Appliquer des méthodes de machine learning et évaluer les résultats (accuracy, matrice de confusion, ...)","metadata":{}},{"cell_type":"code","source":"#Arbre de décision\n\nfrom sklearn import tree\ndtc = tree.DecisionTreeClassifier()\ndtc.fit(X_train,y_train)\ny_dtc = dtc.predict(X_test)\nprint(accuracy_score(y_test, y_dtc))\n\n#matrice de confusion\nfrom sklearn.metrics import accuracy_score, confusion_matrix\ncm = confusion_matrix(y_test, y_rf)\nprint(cm)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import ensemble\nrf = ensemble.RandomForestClassifier()\nrf.fit(X_train, y_train)\ny_rf = rf.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_score = accuracy_score(y_test, y_rf)\nprint(rf_score)\n\n#Affichage de la matrice de confusion:\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix\ncm = confusion_matrix(y_test, y_rf)\nprint(cm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Vous pouvez également si vous le souhaitez tester l'algorithme XGBoost, souvent très efficace :  \nhttps://datascientest.com/xgboost-grand-gagnant-des-competitions-machine-learning-algorithme  \nhttps://medium.com/sfu-cspmp/xgboost-a-deep-dive-into-boosting-f06c9c41349","metadata":{}},{"cell_type":"code","source":"import xgboost as XGB\nxgb  = XGB.XGBClassifier()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport xgboost as xgb\nfrom sklearn.datasets import load_boston\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import explained_variance_score\n\n# Linear Base Learner\ndf = pd.read_csv(\"../input/mnist-in-csv/mnist_test.csv\")\ny = df['label']\nX = df.drop(['label'], axis=1)\n\n# Train and test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n\n# Convert the training and testing sets into DMatrixes\ntrain = xgb.DMatrix(data=X_train, label=y_train)\ntest = xgb.DMatrix(data=X_test, label=y_test)\n\n# Parameters with booster as gblinear for Linear base learner\nparams = {\"booster\": \"gblinear\", \"objective\": \"reg:squarederror\"}\n\n# Train the model: xg_reg\nxg_reg = xgb.train(params=params, dtrain=train, num_boost_round=5)\n\n# Making predictions\npredictions = xg_reg.predict(test)\nprint(\"explained variance:\",explained_variance_score(predictions, y_test))\n\n\n# Computing RMSE\nprint(\"RMSE: %f\" % (np.sqrt(mean_squared_error(y_test, predictions))))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import xgboost as xgb\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import explained_variance_score\n\n# KC House Data\ndf = pd.read_csv(\"../input/mnist-in-csv/mnist_test.csv\")\ny = df['label']\nX = df.drop(['label'], axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n\n# Fitting XGB regressor model and default base learner is Decision Tree\nxgb_reg = xgb.XGBRegressor(objective=\"reg:squarederror\", n_estimators=75, subsample=0.75, max_depth=7)\nxgb_reg.fit(X_train, y_train)\n\n# Making Predictions\npredictions = xgb_reg.predict(X_test)\n\n# Variance_score\nprint((explained_variance_score(predictions, y_test)))\nprint(\"RMSE: %f\" % (np.sqrt(mean_squared_error(y_test, predictions))))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Matrice de confusion\nfrom sklearn.metrics import accuracy_score, confusion_matrix\ncm = confusion_matrix(predictions,y_test)\nprint(cm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}