{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nimport math\nimport random\nfrom collections import Counter, defaultdict\n\n#import nltk\nfrom nltk.corpus import stopwords, movie_reviews","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/pfizer-vaccine-tweets/vaccination_tweets.csv')\npd.to_datetime(df['date'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.date.value_counts().sort_index()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df.text[0].split(' ')[0]\nall_words = []\nhashtags_in_text = []\n\nstop = stopwords.words('english')\n\nfor i in df.text[:500]:\n    for j in i.split(' '):\n        if j.lower() not in stop:\n            if '#' not in j and 'https' not in j:\n                all_words.append(j.lower())\n            elif '#' in j:\n                hashtags_in_text.append(j)\n        \nall_words_dict = Counter(all_words)\nhashtags_in_text_dict = Counter(hashtags_in_text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_words_dict.most_common(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hashtags_in_text_dict.most_common(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Word cloud","metadata":{}},{"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS\nimport matplotlib.pyplot as plt\nfrom PIL import Image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def text_size(total):\n    return 30 + ((total / 200) * 40)\n\nmost_common = []\nstr_common = ''\nstopwords = set(STOPWORDS)\n\nfor word, value in all_words_dict.most_common(40):\n    most_common.append(word)\n\nstr_common += ' '.join(most_common)\n\nplt.figure(figsize = (15, 8), facecolor = None)\n\n\nwordcloud = WordCloud(width = 800, height = 800, \n                    background_color ='white',\n                    stopwords = stopwords,\n                    min_font_size = 10, mode=\"RGBA\").generate(str_common)\nplt.imshow(wordcloud)\nplt.axis(\"off\") \nplt.tight_layout(pad = 0)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def text_size(total):\n    return 30 + ((total / 200) * 40)\n\nmost_common = []\nstr_common = ''\nstopwords = set(STOPWORDS)\n\nfor word, value in hashtags_in_text_dict.most_common(40):\n    most_common.append(word)\n\nstr_common += ' '.join(most_common)\n\nplt.figure(figsize = (15, 8), facecolor = None)\n\nwordcloud = WordCloud(width = 800, height = 800, \n                    background_color ='white',\n                    stopwords = stopwords,\n                    min_font_size = 10, mode=\"RGBA\").generate(str_common)\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\") \nplt.tight_layout(pad = 0)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Naive Bayes","metadata":{}},{"cell_type":"code","source":"df.head(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.text.values[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tweet = df['text'][0].lower()\nall_words = re.findall(\"[a-z0-9']+\", tweet)\nall_words","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, j in zip(df.text.values, df.user_verified.values):\n    print(i, j)\n    break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Naive Bayes","metadata":{}},{"cell_type":"markdown","source":"I use Naive Bayes theorem to find out whether a tweet is from a verified account or not. The following is the algorithm.","metadata":{}},{"cell_type":"markdown","source":"****-------------------------- UNDER CONSTRUCTION ---------------------------****","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"def tokenize(tweet):\n    tweet = tweet.lower()\n    all_words = re.findall(\"[a-z0-9']+\", tweet)\n    return set(all_words)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def count_UV(training_set):\n    counts = defaultdict(lambda: [0, 0])\n    for tweet, is_verified in training_set:\n        for word in tokenize(tweet):\n            if is_verified:\n                counts[word][0] += 1\n            else:\n                counts[word][1] += 1\n    return counts","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def word_probs(total_verified, total_non_verified, counts, k = 1.0):\n    probs = []\n    for word, (verified, not_verified) in counts.items():\n        verified_prob = (k + verified) / (2 * k + total_verified)\n        not_verified_prob = (k + not_verified) / (2 * k + total_non_verified)\n        probs.append((word, verified_prob, not_verified_prob))\n    return probs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def verified_prob(probs, tweet):\n    tweet_words = tokenize(tweet)\n    log_prob_if_verified = 0.0\n    log_prob_if_not_verified = 0.0\n    \n    for word, prob_if_verified, prob_if_not_verified in probs:\n        if word in tweet_words:\n            log_prob_if_verified += math.log(prob_if_verified)\n            log_prob_if_not_verified += math.log(prob_if_not_verified)\n        else:\n            log_prob_if_verified += math.log(1.0 - prob_if_verified)\n            log_prob_if_not_verified += math.log(1.0 - prob_if_not_verified)\n            \n    prob_if_verified = math.exp(log_prob_if_verified)\n    prob_if_not_verified = math.exp(log_prob_if_not_verified)\n    return prob_if_verified / (prob_if_verified + prob_if_not_verified)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class NaiveBayesClassifier:\n    \n    def __init__(self, k=0.5):\n        self.k = k\n        self.word_probs = []\n        \n    def train(self, training_set):\n        num_verified = len([is_verified\n                            for message, is_verified in training_set\n                            if is_verified])\n        num_non_verified = len(training_set) - num_verified\n        \n        word_counts = count_UV(training_set)\n        self.word_probs = verified_prob(word_counts)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}