{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"import pandas as pd\nframingham = pd.read_csv(\"../input/heart-disease-prediction-using-logistic-regression/framingham.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"framingham.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"dataframe.shape is to check the rows and columns of the dataset, to know that we took the correct dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"framingham.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"problem statement:\nHere the TenYearCHD (Ten year risk of coronary hear disease) is our prediction variable (Y) as Ten year cardio Heart disease, we need to predict in 10 years the patient gonna have the heart diesease, with his current medical records.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"framingham.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Basic Packages:\nimport statsmodels.api as sm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"framingham.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"framingham.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are some missing values.\nCheck the number of records having null values."},{"metadata":{"trusted":true},"cell_type":"code","source":"framingham.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=framingham.dropna()\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"na=framingham.shape[0]-df.shape[0]\nna_percentage= (na/framingham.shape[0])*100\nna_percentage","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If i go with dropna, totally I drop 13.732%.\nAs a thumb rule, we can drop 10 to 15% records. so i dropped it"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.rename(columns={'male':'gender'},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Strongly correlated features are: from this correlation matrix we cannot make the decision of correlation.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\npd.crosstab(df['gender'],df['TenYearCHD']).plot.bar(stacked=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x='TenYearCHD',y='age',hue='gender',kind='box',data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Statistical Test:\n# gender vs disease - 2 sample propotion test\n# age vs disease - 2 sample t test\n# education vs disaease - chi-sq\n# current smoker - 2 sample propotion test \n# cigsperday - 2 sample t test\n# BPMeds vs disease - 2 sample propotion test\n# prevalentStroke, prevalentHyp, diabetes, totChol,sysBP, diaBP, BMI - 2 sample propotion test.\n\nX=df.drop('TenYearCHD',axis=1)\nY=df['TenYearCHD']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape,Y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tools import add_constant as add_constant\ndf_constant=add_constant(df)\ndf_constant.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols=df_constant.columns[:-1]\nmodel=sm.Logit(df.TenYearCHD,df_constant[cols]) # ('y~x',df)\nresult=model.fit()\nresult.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Variables not passing test: Education, Current Smoker, BPMeds, prevelentStroke, prevelentHyp, diabetes, diaBP, BMI, heartRate based on p-value >0.05 higher probability being null hypothesis is True. so reject it.\nFinally, we are buliding the model with 6 features which are passing the statistical tests."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_final=df[['gender','age','cigsPerDay','totChol','sysBP','glucose']]\nX_final.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nmodel=LogisticRegression()\nXtrain,Xtest,Ytrain,Ytest=train_test_split(X_final,Y,test_size=0.30,random_state=2)\nmodel.fit(Xtrain,Ytrain)\ny_pred=model.predict(Xtest)\nacc=metrics.accuracy_score(Ytest,y_pred)\ncm=metrics.confusion_matrix(Ytest,y_pred)\nprint('Overall Accuracy=',acc*100)\nprint('Confusion Matrix=\\n',cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tpr=cm[1,1]/cm[1,:].sum()# Sensitivity\nprint(tpr)\nprint('Senstivity error (%) =',(1-tpr)*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tnr=cm[0,0]/cm[0,:].sum() #Specivicity\ntnr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.round(model.coef_,4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, the totChol co-eff value is very low, so the contribution of that particular variable is very less. So, it is the good cholestrol value. Basically, the cholestrol value is highly varying the the caronary heart disease the classification.\nSo, this dataset cant be treated using the Logistic regression(), we need to use Random Forest or Decision tree to classify this problem."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}