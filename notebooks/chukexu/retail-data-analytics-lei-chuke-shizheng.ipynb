{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Retail Sales Forescast Project by Shizheng Hou, Chuke Xu and Lei","metadata":{}},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"markdown","source":"## Import needed packages","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nfrom sklearn import linear_model\nfrom sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\nfrom sklearn.model_selection import cross_validate","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Read and Import data","metadata":{}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sales = pd.read_csv('/kaggle/input/retaildataset/sales data-set.csv', parse_dates=[\"Date\"])\ndf_stores = pd.read_csv('/kaggle/input/retaildataset/stores data-set.csv')\ndf_features = pd.read_csv('/kaggle/input/retaildataset/Features data set.csv', parse_dates=[\"Date\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sales.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_stores.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_features.tail()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Merge data","metadata":{}},{"cell_type":"code","source":"df = df_sales.merge(df_stores).merge(df_features)\ndf.tail()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = df.sample(frac=0.8, random_state=123)\ntrain_data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = df[~df.index.isin(train_data.index)]\ntest_data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tranform date to 3 columns","metadata":{}},{"cell_type":"code","source":"train_data[\"Month\"] = train_data.Date.dt.month\ntrain_data[\"Year\"] = train_data.Date.dt.year\ntrain_data[\"Week\"] = train_data.Date.dt.weekofyear\ntrain_data[\"Day\"] = train_data.Date.dt.dayofyear\ntrain_data.drop(['Date'],axis=1,inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data frame information","metadata":{}},{"cell_type":"code","source":"train_data.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Number of Nulls for each Feature","metadata":{}},{"cell_type":"code","source":"train_data.isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Replace all missing value with zero","metadata":{}},{"cell_type":"code","source":"lst = ['MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5']\nfor column in lst:\n    train_data[column].fillna((train_data[column].mean()), inplace=True)\ntrain_data.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Encoding","metadata":{}},{"cell_type":"code","source":"m = pd.get_dummies(train_data[\"Type\"])\nm = m.rename(columns={\"A\": \"TypeA\", \"B\": \"TypeB\", \"C\": \"TypeC\"})\n\ntrain_data = pd.concat([train_data, m], axis = 1)\ntrain_data.drop(\"Type\", axis = 1, inplace = True)\n\nm = pd.get_dummies(train_data[\"IsHoliday\"])\nm = m.rename(columns={False: \"Not Holiday\", True: \"Holiday\"})\n\ntrain_data = pd.concat([train_data, m], axis = 1)\ntrain_data.drop(\"IsHoliday\", axis = 1, inplace = True)\n\nm = pd.get_dummies(train_data[\"Store\"])\nm = m.rename(columns=lambda x: 'Store' + str(x))\n\ntrain_data = pd.concat([train_data, m], axis = 1)\ntrain_data.drop(\"Store\", axis = 1, inplace = True)\n\nm = pd.get_dummies(train_data[\"Dept\"])\nm = m.rename(columns=lambda x: 'Dept' + str(x))\n\ntrain_data = pd.concat([train_data, m], axis = 1)\ntrain_data.drop(\"Dept\", axis = 1, inplace = True)\n\nm = pd.get_dummies(train_data[\"Week\"])\nm = m.rename(columns=lambda x: 'Week' + str(x))\n\ntrain_data = pd.concat([train_data, m], axis = 1)\ntrain_data.drop(\"Week\", axis = 1, inplace = True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data[\"Month\"] = test_data.Date.dt.month\ntest_data[\"Year\"] = test_data.Date.dt.year\ntest_data[\"Week\"] = test_data.Date.dt.weekofyear\ntest_data[\"Day\"] = test_data.Date.dt.dayofyear\ntest_data.drop(['Date'],axis=1,inplace=True)\n\nlst = ['MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5']\nfor column in lst:\n    test_data[column].fillna(0, inplace=True)\n\ns = pd.get_dummies(test_data[\"Type\"])\ns = s.rename(columns={\"A\": \"TypeA\", \"B\": \"TypeB\", \"C\": \"TypeC\"})\n\ntest_data = pd.concat([test_data, s], axis = 1)\ntest_data.drop(\"Type\", axis = 1, inplace = True)\n\nm = pd.get_dummies(test_data[\"IsHoliday\"])\nm = m.rename(columns={False: \"Not Holiday\", True: \"Holiday\"})\n\ntest_data = pd.concat([test_data, m], axis = 1)\ntest_data.drop(\"IsHoliday\", axis = 1, inplace = True)\n\nm = pd.get_dummies(test_data[\"Store\"])\nm = m.rename(columns=lambda x: 'Store' + str(x))\n\ntest_data = pd.concat([test_data, m], axis = 1)\ntest_data.drop(\"Store\", axis = 1, inplace = True)\n\nm = pd.get_dummies(test_data[\"Dept\"])\nm = m.rename(columns=lambda x: 'Dept' + str(x))\n\ntest_data = pd.concat([test_data, m], axis = 1)\ntest_data.drop(\"Dept\", axis = 1, inplace = True)\n\nm = pd.get_dummies(test_data[\"Week\"])\nm = m.rename(columns=lambda x: 'Week' + str(x))\n\ntest_data = pd.concat([test_data, m], axis = 1)\ntest_data.drop(\"Week\", axis = 1, inplace = True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Normalization","metadata":{}},{"cell_type":"code","source":"df_weekly_sales = train_data['Weekly_Sales']\ntrain_data = train_data / train_data.max()\ntrain_data['Weekly_Sales'] = df_weekly_sales","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_weekly_sales = test_data['Weekly_Sales']\ntest_data = test_data / test_data.max()\ntest_data['Weekly_Sales'] = test_weekly_sales","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split X and y","metadata":{}},{"cell_type":"code","source":"X = train_data.drop('Weekly_Sales', axis=1)\ny = train_data['Weekly_Sales']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = test_data.drop('Weekly_Sales', axis=1)\ny_test = test_data['Weekly_Sales']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## (PCA)","metadata":{}},{"cell_type":"code","source":"# from sklearn.decomposition import PCA\n\n# train_data_drop = train_data.drop('Weekly_Sales', axis=1)\n\n# pca = PCA(100)\n# pca_train_data = pca.fit_transform(train_data_drop)\n\n# plt.plot(np.cumsum(pca.explained_variance_ratio_))\n# plt.xlabel('number of components')\n# plt.ylabel('cumulative explained variance')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Heat Map","metadata":{}},{"cell_type":"code","source":"# sns.set(rc={'figure.figsize':(20,18)})\n# sns.heatmap(df.corr(), center = 0, annot = True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## (Standardization)","metadata":{}},{"cell_type":"code","source":"# from sklearn import preprocessing\n# scaler = preprocessing.StandardScaler()\n\n# scaler_list = ['Weekly_Sales', 'Size', 'Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment', 'Month', 'Year', 'Day']\n\n# scaler_data = train_data[scaler_list]\n# scaler_data = pd.DataFrame(scaler.fit_transform(scaler_data))\n\n# train_data.drop(scaler_list, axis=1, inplace=True).reset_index(inplace=True)\n\n# # train_data = pd.concat([scaler_data, train_data], ignore_index=True, axis=1)\n\n# # train_data = pd.DataFrame(scaler.fit_transform(X))\n# # train_data['Weekly_Sales'] = df_weekly_sales","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Cross Validation","metadata":{}},{"cell_type":"code","source":"# from sklearn import linear_model\n# from sklearn.model_selection import cross_validate\n# from sklearn.metrics import make_scorer\n# from sklearn.metrics import confusion_matrix\n# import lightgbm as lgb","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X = np.array(train_data.drop('Weekly_Sales', axis=1))\n# y = np.array(train_data[\"Weekly_Sales\"])\n# my_model = lgb.LGBMRegressor(objective='regression', num_leaves=150, max_depth = 14, learning_rate=0.5, n_estimators=2000, reg_alpha=0.5)\n# cv_results = cross_validate(my_model, X, y, scoring = \"r2\", cv = 10)\n# sorted(cv_results.keys())\n# cv_results['test_score']","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission 0: Linear regression","metadata":{}},{"cell_type":"markdown","source":"## OLS Regression","metadata":{}},{"cell_type":"code","source":"import statsmodels.api as sm\nimport statsmodels.formula.api as smf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reg_ols = sm.OLS(y, X)\nest = reg_ols.fit()\nest.summary()  ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = est.predict(X)\n\nr_2 = r2_score(y, y_pred)\nrmse = mean_squared_error(y, y_pred, squared=False)\nmae = mean_absolute_error(y, y_pred)\n\nprint(\"R squared:\", r_2)\nprint(\"RMSE:\", rmse)\nprint(\"MAE:\", mae)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_pred = est.predict(X_test)\n\nr_2 = r2_score(y_test, y_test_pred)\nrmse = mean_squared_error(y_test, y_test_pred, squared=False)\nmae = mean_absolute_error(y_test, y_test_pred)\n\nprint(\"R squared:\", r_2)\nprint(\"RMSE:\", rmse)\nprint(\"MAE:\", mae)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission 1: Lasso, Ridge and Polynomial regression","metadata":{}},{"cell_type":"markdown","source":"## Lasso regression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import Lasso","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reg_lasso = Lasso().fit(X,y)\n\ny_pred = reg_lasso.predict(X)\n\nr_2 = reg_lasso.score(X, y)\nrmse = mean_squared_error(y, y_pred, squared=False)\nmae = mean_absolute_error(y, y_pred)\n\nprint(\"R squared:\", r_2)\nprint(\"RMSE:\", rmse)\nprint(\"MAE:\", mae)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_pred = reg_lasso.predict(X_test)\n\nr2_test = reg_lasso.score(X_test, y_test)\nrmse_test = mean_squared_error(y_test, y_test_pred, squared=False)\nmae_test = mean_absolute_error(y_test, y_test_pred)\n\nprint(\"R squared:\", r2_test)\nprint(\"RMSE:\", rmse_test)\nprint(\"MAE:\", mae_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ridge regression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import Ridge","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reg_ridge = Ridge().fit(X,y)\n\ny_pred = reg_ridge.predict(X)\n\nr_2 = reg_ridge.score(X, y)\nrmse = mean_squared_error(y, y_pred, squared=False)\nmae = mean_absolute_error(y, y_pred)\n\nprint(\"R squared:\", r_2)\nprint(\"RMSE:\", rmse)\nprint(\"MAE:\", mae)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_pred = reg_ridge.predict(X_test)\n\nr_2 = reg_ridge.score(X_test, y_test)\nrmse = mean_squared_error(y_test, y_test_pred, squared=False)\nmae = mean_absolute_error(y_test, y_test_pred)\n\nprint(\"R squared:\", r_2)\nprint(\"RMSE:\", rmse)\nprint(\"MAE:\", mae)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Polynomial regression","metadata":{}},{"cell_type":"code","source":"# from sklearn.preprocessing import PolynomialFeatures\n# from sklearn import linear_model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# poly = PolynomialFeatures(degree=2)\n# X = poly.fit_transform(X)\n\n# clf = linear_model.LinearRegression().fit(X, y)\n# clf.score(X, y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission 2: GBDT, XGBoost and LightBGM","metadata":{}},{"cell_type":"markdown","source":"## Gradient Boosting Decision Tree","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reg_gbdt = GradientBoostingRegressor().fit(X,y)\n\ny_pred = reg_gbdt.predict(X)\n\nr_2 = reg_gbdt.score(X, y)\nrmse = mean_squared_error(y, y_pred, squared=False)\nmae = mean_absolute_error(y, y_pred)\n\nprint(\"R squared:\", r_2)\nprint(\"RMSE:\", rmse)\nprint(\"MAE:\", mae)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_pred = reg_gbdt.predict(X_test)\n\nr_2 = reg_gbdt.score(X_test, y_test)\nrmse = mean_squared_error(y_test, y_test_pred, squared=False)\nmae = mean_absolute_error(y_test, y_test_pred)\n\nprint(\"R squared:\", r_2)\nprint(\"RMSE:\", rmse)\nprint(\"MAE:\", mae)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## XGBoost","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBRegressor","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reg_xgb = XGBRegressor(objective='reg:squarederror', n_estimators=2000)\nreg_xgb = reg_xgb.fit(X,y)\n\ny_pred = reg_xgb.predict(X)\n\nr2 = reg_xgb.score(X, y)\nrmse = mean_squared_error(y, y_pred, squared=False)\nmae = mean_absolute_error(y, y_pred)\n\nprint(\"R squared:\", r_2)\nprint(\"RMSE:\", rmse)\nprint(\"MAE:\", mae)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_pred = reg_xgb.predict(X_test)\n\nr2_test = reg_xgb.score(X_test, y_test)\nrmse_test = mean_squared_error(y_test, y_test_pred, squared=False)\nmae_test = mean_absolute_error(y_test, y_test_pred)\n\nprint(\"R squared:\", r2_test)\nprint(\"RMSE:\", rmse_test)\nprint(\"MAE:\", mae_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## LightGBM","metadata":{}},{"cell_type":"code","source":"import lightgbm as lgb","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reg_lgb = lgb.LGBMRegressor(objective='regression', num_leaves=60, max_depth = 9, learning_rate=0.5, n_estimators=2000, reg_alpha=0.6, subsample=0.6, colsample_bytree = 0.8, scale_pos_weight = 5)\nreg_lgb.fit(X, y, verbose=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = reg_lgb.predict(X)\n\nr_2 = reg_lgb.score(X, y)\nrmse = mean_squared_error(y, y_pred, squared=False)\nmae = mean_absolute_error(y, y_pred)\n\nprint(\"R squared:\", r_2)\nprint(\"RMSE:\", rmse)\nprint(\"MAE:\", mae)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_pred = reg_lgb.predict(X_test)\n\nr2_test = reg_lgb.score(X_test, y_test)\nrmse_test = mean_squared_error(y_test, y_test_pred, squared=False)\nmae_test = mean_absolute_error(y_test, y_test_pred)\n\nprint(\"R squared:\", r2_test)\nprint(\"RMSE:\", rmse_test)\nprint(\"MAE:\", mae_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission 3: Neural Network","metadata":{}},{"cell_type":"code","source":"def build_model():\n  model = keras.Sequential([\n    layers.Dense(256, activation='relu', input_shape=[len(X.keys())]),\n    layers.Dense(128, activation='relu'),\n    layers.Dense(64, activation='relu'),\n    layers.Dense(32, activation='relu'),\n    layers.Dense(1)\n  ])\n\n  optimizer = tf.keras.optimizers.RMSprop(0.001)\n\n  model.compile(loss='mse',\n                optimizer=optimizer,\n                metrics=['mae', 'mse'])\n  return model\n\nmodel = build_model()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_stats = train_data.describe()\ntrain_stats.pop(\"Weekly_Sales\")\ntrain_stats = train_stats.transpose()\ntrain_stats","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def norm(x):\n  return (x - train_stats['mean']) / train_stats['std']\n  \nnorm_X = norm(X)\nnorm_X_test = norm(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PrintDot(keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs):\n    if epoch % 100 == 0: print('')\n    print('.', end='')\n\nEPOCHS = 200\n\nhistory = model.fit(\n  norm_X, y,\n  epochs=EPOCHS, validation_split = 0.2, verbose=0,\n  callbacks=[PrintDot()])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist = pd.DataFrame(history.history)\nhist['epoch'] = history.epoch\nhist.tail()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_history(history):\n  hist = pd.DataFrame(history.history)\n  hist['epoch'] = history.epoch\n\n  plt.figure()\n  plt.xlabel('Epoch')\n  plt.ylabel('Mean Abs Error [Weekly_Sales]')\n  plt.plot(hist['epoch'], hist['mae'],\n           label='Train Error')\n  plt.plot(hist['epoch'], hist['val_mae'],\n           label = 'Val Error')\n  plt.ylim([0,3000])\n  plt.legend()\n\n  plt.figure()\n  plt.xlabel('Epoch')\n  plt.ylabel('Mean Square Error [Weekly_Sales]')\n  plt.plot(hist['epoch'], hist['mse'],\n           label='Train Error')\n  plt.plot(hist['epoch'], hist['val_mse'],\n           label = 'Val Error')\n#   plt.ylim([0,3000])\n  plt.legend()\n  plt.show()\n\n\nplot_history(history)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(norm_X)\n\nr_2 = r2_score(y, y_pred)\nrmse = mean_squared_error(y, y_pred, squared=False)\nmae = mean_absolute_error(y, y_pred)\n\nprint(\"R squared:\", r_2)\nprint(\"RMSE:\", rmse)\nprint(\"MAE:\", mae)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_pred = model.predict(norm_X_test)\n\nr2_test = r2_score(y_test, y_test_pred)\nrmse_test = mean_squared_error(y_test, y_test_pred, squared=False)\nmae_test = mean_absolute_error(y_test, y_test_pred)\n\nprint(\"R squared:\", r2_test)\nprint(\"RMSE:\", rmse_test)\nprint(\"MAE:\", mae_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission 4: Split train dataset and train two models (using LightGBM)","metadata":{}},{"cell_type":"code","source":"outliers_data = train_data[train_data[\"Weekly_Sales\"] >= 40000]\nnormal_data = train_data[train_data[\"Weekly_Sales\"] < 40000]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Outliers data","metadata":{}},{"cell_type":"code","source":"X = outliers_data.drop('Weekly_Sales', axis=1)\ny = outliers_data['Weekly_Sales']\nmodel_outliers = lgb.LGBMRegressor(objective='regression', num_leaves=140, max_depth = 15, learning_rate=0.5, n_estimators=2000, reg_alpha=0.6)\nmodel_outliers.fit(X, y, verbose=False)","metadata":{"tags":["outputPrepend"]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model_outliers.predict(X)\n\nr_2 = model_outliers.score(X, y)\nrmse = mean_squared_error(y, y_pred, squared=False)\nmae = mean_absolute_error(y, y_pred)\nprint(\"R squared:\", r_2)\nprint(\"RMSE:\", rmse)\nprint(\"MAE:\", mae)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Normal data","metadata":{}},{"cell_type":"code","source":"X = normal_data.drop('Weekly_Sales', axis=1)\ny = normal_data['Weekly_Sales']\nmodel_normal = lgb.LGBMRegressor(objective='regression', num_leaves=140, max_depth = 15, learning_rate=0.5, n_estimators=2000, reg_alpha=0.6)\nmodel_normal.fit(X, y, verbose=False)","metadata":{"tags":["outputPrepend"]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model_normal.predict(X)\n\nr_2 = model_normal.score(X, y)\nrmse = mean_squared_error(y, y_pred, squared=False)\nmae = mean_absolute_error(y, y_pred)\n\nprint(\"R squared:\", r_2)\nprint(\"RMSE:\", rmse)\nprint(\"MAE:\", mae)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## KNN to split test data","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier\n\nmodel = NearestNeighbors(algorithm = \"brute\", n_neighbors = 5)\nmodel.fit(train_data.drop('Weekly_Sales', axis=1))\n\nX_test = X_test.reset_index(drop=True)\ny_test = y_test.reset_index(drop=True)\n\nindices = model.kneighbors(X_test, 3, return_distance=False)\n\ny_test = pd.DataFrame(y_test)\nX_test['label'] = [0]*len(X_test)\ny_test['label'] = [0]*len(y_test)\nfor i,index_list in enumerate(indices):\n    count = 0\n    for index in index_list:\n        if train_data['Weekly_Sales'].iloc[index] >= 40000:\n            count += 1\n    if count > 1:\n        X_test['label'].iloc[i] = 1\n        y_test['label'].iloc[i] = 1\n\nX_test_normal = X_test[X_test['label'] == 0]\nX_test_outlier = X_test[X_test['label'] == 1]\ny_test_normal = y_test[y_test['label'] == 0]\ny_test_outlier = y_test[y_test['label'] == 1]\n\ny_test_normal = y_test_normal.drop('label', axis = 1)\ny_test_outlier = y_test_outlier.drop('label', axis = 1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict on two test dataset using two models","metadata":{}},{"cell_type":"code","source":"y_test_normal_pred = model_normal.predict(X_test_normal.drop('label', axis=1))\n\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom math import sqrt\nr2_test = r2_score(y_test_normal, y_test_normal_pred)\nrmse_test = sqrt(mean_squared_error(y_test_normal, y_test_normal_pred))\nmae_test = mean_absolute_error(y_test_normal, y_test_normal_pred)\n\nprint(\"R squared:\", r2_test)\nprint(\"RMSE:\", rmse_test)\nprint(\"MAE:\", mae_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_outlier_pred = model_outliers.predict(X_test_outlier.drop('label', axis=1))\n\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom math import sqrt\nr2_test = r2_score(y_test_outlier, y_test_outlier_pred)\nrmse_test = sqrt(mean_squared_error(y_test_outlier, y_test_outlier_pred))\nmae_test = mean_absolute_error(y_test_outlier, y_test_outlier_pred)\n\nprint(\"R squared:\", r2_test)\nprint(\"RMSE:\", rmse_test)\nprint(\"MAE:\", mae_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Overall performance in whole test dataset","metadata":{}},{"cell_type":"code","source":"overall_y_test_pred = y_test_normal_pred.tolist() + y_test_outlier_pred.tolist()\noverall_y_test = y_test_normal['Weekly_Sales'].tolist() + y_test_outlier['Weekly_Sales'].tolist()\n\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom math import sqrt\nr2_test = r2_score(overall_y_test, overall_y_test_pred)\nrmse_test = sqrt(mean_squared_error(overall_y_test, overall_y_test_pred))\nmae_test = mean_absolute_error(overall_y_test, overall_y_test_pred)\n\nprint(\"R squared:\", r2_test)\nprint(\"RMSE:\", rmse_test)\nprint(\"MAE:\", mae_test)","metadata":{},"execution_count":null,"outputs":[]}]}