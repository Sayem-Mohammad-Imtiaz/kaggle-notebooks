{"cells":[{"metadata":{"_cell_guid":"1be39542-723c-4424-82fc-073a425287f9","_uuid":"2069027e814059d61dd25521ae9975a3936b3c77","trusted":true},"cell_type":"code","source":"#Here are some standard libraries that are loaded when you \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # visualize satellite images\nfrom skimage.io import imshow # visualize satellite images\n\nfrom keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout # components of network\nfrom keras.models import Sequential # type of model","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3ba61d1b-50c6-4151-bad6-193c246cbe7b","_uuid":"2a5212bba975e1ab50c852c1678a7d5092f6c8ff"},"cell_type":"markdown","source":"## Get Input Data\nThe input data was encoded into CSV files. The X_test_sat4.csv flattened the images that were 28 x 28 x 4 that were taken from space. The first three channels are the standard red, green, and blue channels in normal images. The 4th is a near-infrared band. We are using the smaller test set because the training set is too big.\nAfter extracting the data from the csv files, we can reshape it into the original images. Then, we can see the images before we train on them.\nThe second file we are loading are the labels for each image. They can be one of 4: barren land, trees, grassland and other. Each row in the file looks like this [1,0,0,0], where only one of the 4 value is 1. If it is one, then it is that class respective to the order I showed above. If it was the above values, the image is a picture of barren land. If it was [0,1,0,0], then it would be trees. If it was [0,0,1,0], then it would be grassland and so on.","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"ac43537d-f364-4787-ae7c-a63e5cc09796","_uuid":"e3f5f23d9f2fcb63dd2aaaefcf540f8e8464f2f5","trusted":true},"cell_type":"code","source":"x_train_set_fpath = '../input/X_test_sat4.csv'\ny_train_set_fpath = '../input/y_test_sat4.csv'\nprint ('Loading Training Data')\nX_train = pd.read_csv(x_train_set_fpath)\nprint ('Loaded 28 x 28 x 4 images')\nY_train = pd.read_csv(y_train_set_fpath)\nprint ('Loaded labels')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1740250f-16b0-49d8-8995-81bc9dd6817c","_uuid":"4e9d5d6eb6acabd9a6fcce08d946db81fe66d54c"},"cell_type":"markdown","source":"## The values are in a pandas(data library) DataFrame. We need them as a numpy array\nYou can convert pandas dataframes to numpy arrays like this:","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"49f81e61-3f44-424a-b52e-5bce9c3fe8d9","_uuid":"330103a9ca501213a114ba9b2eb6f582dbd0868a","trusted":true},"cell_type":"code","source":"X_train = X_train.as_matrix()\nY_train = Y_train.as_matrix()\nprint ('We have',X_train.shape[0],'examples and each example is a list of',X_train.shape[1],'numbers with',Y_train.shape[1],'possible classifications.')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"37b1fd7f-a50d-43ff-9fec-a7481070526d","_uuid":"ad647b29aed3964d08fa9b2896e1ca3552a1585c","trusted":true},"cell_type":"code","source":"#First we have to reshape each of them from a list of numbers to a 28*28*4 image.\nX_train_img = X_train.reshape([99999,28,28,4]).astype(float)\nprint (X_train_img.shape)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e60e1429-3caf-4849-b10d-f52c5cddf946","_uuid":"5ab368469e2efc8218271017acc8cf16ce8708d3","trusted":true},"cell_type":"code","source":"#Let's take a look at one image. Keep in mind the channels are R,G,B, and I(Infrared)\nix = 54643#Type a number between 0 and 99,999 inclusive\nimshow(np.squeeze(X_train_img[ix,:,:,0:3]).astype(float)) #Only seeing the RGB channels\nplt.show()\n#Tells what the image is\nif Y_train[ix,0] == 1:\n    print ('Barren Land')\nelif Y_train[ix,1] == 1:\n    print ('Trees')\nelif Y_train[ix,2] == 1:\n    print ('Grassland')\nelse:\n    print ('Other')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f9c66bc1-c551-49cd-94f8-95b81cfc621b","_uuid":"91e31516cd56c3337ec20463f0fc5379b9af8ccc"},"cell_type":"markdown","source":"## Let's now define our model\nThere are 2 different types of models we can choose from: A 'vanilla' artificial neural network we have been learning about, and a special Convolutional Neural Network we will learn about, which is very, very good at image recognition. For now we will use the simpler, vanilla artificial neural network. The network will only have one layer: the output one. This network will not be expected to be very powerful, and pretty slow.","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"dfab20ea-4eb9-46f7-9d58-685504c4de1c","_uuid":"1a3de30500dca883eb201eedf5128a4d8a814582","collapsed":true,"trusted":true},"cell_type":"code","source":"model = Sequential([\n    Dense(4, input_shape=(3136,), activation='softmax')\n])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1a4d5b57-67e4-42b5-9f5c-092ff97d0fb5","_uuid":"2733d81eb89d365cc2ae8afa4d360567c9a3a31a"},"cell_type":"markdown","source":"Now that we have the data and model ready, there is one more thing we have to do. In neural networks, it is very important we normalize training data. This means we make the mean 0, and the standard deviation 1 for the best results. However, dividing the image by 255 is good enough. We will just divide the array by 255:","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"4710e101-3b95-4de4-a04e-be01b7232648","_uuid":"e50083560adc106107e2b529dcb0047e6e6a049a","collapsed":true,"trusted":true},"cell_type":"code","source":"X_train = X_train/255","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"fe1570f0-7433-4add-95e8-b1414295224f","_uuid":"22fcd2e5359bd354b302e2346b772e45fbc42de9"},"cell_type":"markdown","source":"## Now lets fit our model to the training data","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"6399bc5c-db83-4ef6-bd21-0f619e968652","_uuid":"118d5746e7d95b50c07be26eb5b52c1e98ff0484","trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()\nmodel.fit(X_train,Y_train,batch_size=32, epochs=5, verbose=1, validation_split=0.01)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0a801207-e880-44da-8d93-8accc67cf1ee","_uuid":"4c19bf83d352d6293ae4b84e776ba1cc715a5058"},"cell_type":"markdown","source":"Lets try to see what the model can do on a few images. Let's first get the predictions:","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"a8f55044-c699-4384-ac65-251c65f9b693","_uuid":"0544479619f951004c87482f724a0fd5264a7e43","trusted":true},"cell_type":"code","source":"preds = model.predict(X_train_img[-1000:].reshape(1000, 28*28*4), verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"91a021d3-783c-4ce3-9d5b-049cb0a26d49","_uuid":"9ae1abcea1ebba5ced63074543cf2456e24a8d10","trusted":true},"cell_type":"code","source":"ix = 20 #Type a number between 0 and 999 inclusive\nimshow(np.squeeze(X_train_img[99999-(1000-ix),:,:,0:3]).astype(float)*255) #Only seeing the RGB channels\nplt.show()\n#Tells what the image is\nprint ('Prediction:\\n{:.1f}% probability barren land,\\n{:.1f}% probability trees,\\n{:.1f}% probability grassland,\\n{:.1f}% probability other\\n'.format(preds[ix,0]*100,preds[ix,1]*100,preds[ix,2]*100,preds[ix,3]*100))\n\nprint ('Ground Truth: ',end='')\nif Y_train[99999-(1000-ix),0] == 1:\n    print ('Barren Land')\nelif Y_train[99999-(1000-ix),1] == 1:\n    print ('Trees')\nelif Y_train[99999-(1000-ix),2] == 1:\n    print ('Grassland')\nelse:\n    print ('Other')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4fb21730-eaeb-4093-9512-1900029e35c4","_uuid":"fbd1d6897d0950a77f8d726d83c4fa20fb117f1d"},"cell_type":"markdown","source":"Ehh. 72% accuracy is pretty bad. Here's a model that can do lot better(there is some error):","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"3aacc217-ae98-40ae-bcf0-f6ab62a02e5d","_uuid":"8e349afd350ea313a3566a0e474e5d052523848c","trusted":true},"cell_type":"code","source":"model = Sequential([\n    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28,28,4)),\n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D(pool_size=(2, 2)),\n    Dropout(0.25),\n    Flatten(),\n    Dense(32, activation='relu'),\n    Dropout(0.5),\n    Dense(4, activation='softmax')\n])\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()\nmodel.fit(X_train_img,Y_train,batch_size=32, epochs=5, verbose=1, validation_split=0.01)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d537e7c2-35a1-4111-9886-643eeb72b988","_uuid":"66e745eca3497ebf4c95eaec665e8e9eb1ec4eee"},"cell_type":"markdown","source":"That should take a good 20-25 minutes to train. There are definitely going to be better, faster architectures you could use, but this network is much better at image recognition, then the other type. OR it should be, but it is not, and i am working on it=)","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"352776e4-98fe-45eb-b294-ae6d4a337dbb","_uuid":"8fa5be47af1cf78a33b356f26208424f940742c7","collapsed":true,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}