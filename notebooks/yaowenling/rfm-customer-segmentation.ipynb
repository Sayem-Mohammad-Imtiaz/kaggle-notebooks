{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Intro into RFM Framework\n\nRFM framework is a method used to determine customer value by looking at the following three dimensions:\n* Recency: when is the last time the user takes an action (e.g., login, place an order)?Â \n* Frequency: how many times does the user take this action?\n* Monetary value: what is the sum of monetary value from this user throughout his/her lifetime?\n\nWhen used properly, RFM becomes a powerful tool to identify the most valuable customer (MVC) of a business. Based on the output from this model, we are able to develop customized CRM strategies for different customer segments. With this post, I want to share the Kaggle notebook from an RFM segmentation analysis plus some tips that I found useful in the application of the model output.","metadata":{}},{"cell_type":"code","source":"# Load the dataset and have a peek into first rows\ndata = pd.read_csv(\"/kaggle/input/ecommerce-data/data.csv\")\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the basic info of the dataset: size, variables, data types\ndata.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Note that we have some missing values in column \"Description\" and \"CustomerID\".\n# Since our goal is to create a customer segmentation using the RFM framework, we need \n# drop rows with missing customer ID and description.\ndata = data.dropna()\ndata.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert column \"InvoiceDate\" to datetime\nfrom datetime import datetime\ndata[\"InvoiceDate\"] = data[\"InvoiceDate\"].apply(lambda x: x.split(' ')[0])\ndata[\"InvoiceDate\"].head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"InvoiceDate\"] = data[\"InvoiceDate\"].apply(lambda x: datetime.strptime(x, '%m/%d/%Y'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the dataset info after conversion\ndata.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a new variable OrderValue = Quanity * UnitPrice\ndata[\"OrderValue\"] = data[\"Quantity\"] * data[\"UnitPrice\"]\ndata[[\"Quantity\", \"UnitPrice\", \"OrderValue\"]].head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Aggregate at customer level\ncustomer_data = pd.DataFrame(data.pivot_table(index=\"CustomerID\", \n                                              values=[\"InvoiceDate\", \"OrderValue\"], \n                                              aggfunc={\"InvoiceDate\": [min, max, pd.Series.nunique], \"OrderValue\": sum}))\ncustomer_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"customer_data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Rename columns\ncustomer_data.columns = [\"LastInvoiceDate\", \"FirstInvoiceDate\", \"Frequency\", \"MonetaryValue\"]\ncustomer_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n# Create column \"FirstInvoceMonth\" to look at customer intake\ncustomer_data[\"FirstInvoiceMonth\"] = customer_data[\"FirstInvoiceDate\"].apply(lambda x: x.replace(day=1))\ncustomer_data.groupby([\"FirstInvoiceMonth\"]).count()[\"FirstInvoiceDate\"].plot(kind=\"bar\")\nplt.title(\"Monthly Customer Intakes\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate recency, relative recency and relative frequency\n# Take the maximum invoice date as today\ntoday = customer_data[\"LastInvoiceDate\"].max()\ntoday","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate recency: the interval (days) between the last transation day and today\ncustomer_data[\"Recency\"] = (today - customer_data[\"LastInvoiceDate\"]) / np.timedelta64(1, 'D')\ncustomer_data[\"Recency\"].hist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate customer lifetime: the interval (days) between the first transation day and today\ncustomer_data[\"Lifetime\"] = (today - customer_data[\"FirstInvoiceDate\"]) / np.timedelta64(1, 'D')\ncustomer_data[\"Lifetime\"].hist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"customer_data[\"Lifetime\"].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the relative recency: recency / customer lifetime\n# Note: this is to normalise the fact that newer customers have lower lifetime and thus lower recency\n# by nature.\ncustomer_data[\"RelRecency\"] = 1 - customer_data[\"Recency\"] / customer_data[\"Lifetime\"]\ncustomer_data[\"RelRecency\"].hist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"customer_data[\"Recency\"].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"customer_data[\"RelRecency\"].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sum(customer_data[\"RelRecency\"]==0) / len(customer_data)\n# This shows that 31% customers only had one transactions.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the relative frequency: frequency / customer lifetime\n# Note: this is to normalise the fact that newer customers have lower lifetime and thus lower frequency\n# by nature.\ncustomer_data[\"RelFrequency\"] = customer_data[\"Frequency\"] / customer_data[\"Lifetime\"]\ncustomer_data[\"RelFrequency\"].apply(lambda x: np.isinf(x)).value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Found a record with inifinity value, we need to remove it\ncustomer_data[customer_data[\"RelFrequency\"].apply(lambda x: np.isinf(x))]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"customer_data = customer_data[customer_data[\"RelFrequency\"].apply(lambda x: np.isinf(x))==False]\ncustomer_data[\"RelFrequency\"].hist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"customer_data[\"RelFrequency\"].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the relative monetary value: monetary value / customer lifetime\n# Note: this is to normalise the fact that newer customers have lower lifetime and thus lower frequency\n# by nature.\ncustomer_data[\"MonetaryValue\"].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"customer_data[\"MonetaryValue\"].hist()\n# There are some outliers in terms of monetary value.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.percentile(customer_data[\"MonetaryValue\"], 99)\n# The 99.5% percentile of monetary value is 33.4K, i.e., 0.5% * 4K = 20 customers have value higher than 33.4K.\n# We should exclude these outliers from our analysis.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"customer_data = customer_data[customer_data[\"MonetaryValue\"]<=np.percentile(customer_data[\"MonetaryValue\"], 99)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(customer_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(customer_data[customer_data[\"MonetaryValue\"]<0])\n# 43 customers have negative transation value because of the returns.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"customer_data[customer_data[\"MonetaryValue\"]<0].head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[data[\"CustomerID\"]==12454]\n# Some customers have a negative sum of order value. This is because they have returns.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"customer_data[\"RelMonetaryValue\"] = customer_data[\"MonetaryValue\"] / customer_data[\"Lifetime\"]\ncustomer_data[\"RelMonetaryValue\"].hist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"customer_data[\"RelMonetaryValue\"].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create RFM buckets using absolute values","metadata":{}},{"cell_type":"code","source":"# Create RFM buckets using absolute values\n# For this analysis, we take the medians and 75% quartiles of relative recency, relative frequency and relative monetary value and use them for\n# 4 bins for each variable. We label those bins as 1, 2, 3 and 4 and use them as the scores for R, F and M respectively.\n# We then create \n# By doing so we end up with 10 clusters ()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"customer_data['RecencyScore'] = pd.cut(customer_data[\"Recency\"], \n                                       bins=[-1, \n                                             np.percentile(customer_data[\"Recency\"], 25), \n                                             np.percentile(customer_data[\"Recency\"], 50), \n                                             np.percentile(customer_data[\"Recency\"], 75), \n                                             customer_data[\"Recency\"].max()], \n                                       labels=[4, 3, 2, 1]).astype(\"int\")\ncustomer_data[\"RecencyScore\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"customer_data[\"FrequencyScore\"] = pd.cut(customer_data[\"Frequency\"], \n                                       bins=[-1, \n                                             np.percentile(customer_data[\"Frequency\"], 25), \n                                             np.percentile(customer_data[\"Frequency\"], 50), \n                                             np.percentile(customer_data[\"Frequency\"], 75), \n                                             customer_data[\"Frequency\"].max()], \n                                       labels=[1, 2, 3, 4]).astype(\"int\")\ncustomer_data[\"FrequencyScore\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"customer_data[\"MonetaryScore\"] = pd.cut(customer_data[\"MonetaryValue\"], \n                                       bins=[customer_data[\"MonetaryValue\"].min()-1, \n                                             np.percentile(customer_data[\"MonetaryValue\"], 25),\n                                             np.percentile(customer_data[\"MonetaryValue\"], 50), \n                                             np.percentile(customer_data[\"MonetaryValue\"], 75), \n                                             customer_data[\"MonetaryValue\"].max()], \n                                       labels=[1, 2, 3, 4]).astype(\"int\")\ncustomer_data[\"MonetaryScore\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"customer_data[\"RFM\"] = customer_data[\"RecencyScore\"] + customer_data[\"FrequencyScore\"] + customer_data[\"MonetaryScore\"]\ncustomer_data[\"RFM\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfm_abs = pd.DataFrame(customer_data.pivot_table(index=[\"RFM\"], \n                                    values=[\"Recency\", \"Frequency\", \"MonetaryValue\", \"Lifetime\"], \n                                    aggfunc={\"Recency\": [np.min, np.median, np.max], \n                                             \"Frequency\": [np.min, np.median, np.max], \n                                             \"MonetaryValue\": [np.min, np.median, np.max], \n                                             \"Lifetime\": [np.min, np.median, np.max, \"count\"]}))\nrfm_abs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see, the groups have very different median days of lifetime. This suggests potential bias associated with customer sign up date.","metadata":{}},{"cell_type":"markdown","source":"# Create RFM buckets using relative values","metadata":{}},{"cell_type":"code","source":"# Create RFM buckets using relative values\n# For this analysis, we take the medians and 75% quartiles of relative recency, relative frequency and relative monetary value and use them for\n# 4 bins for each variable. We label those bins as 1, 2, 3 and 4 and use them as the scores for R, F and M respectively.\n# We then create \n# By doing so we end up with 10 clusters ()\ncustomer_data[\"RecencyScore\"] = pd.cut(customer_data[\"RelRecency\"], \n                                       bins=[-1, \n                                             np.percentile(customer_data[\"RelRecency\"], 25), \n                                             np.percentile(customer_data[\"RelRecency\"], 50), \n                                             np.percentile(customer_data[\"RelRecency\"], 75), \n                                             customer_data[\"RelRecency\"].max()], \n                                       labels=[1, 2, 3, 4]).astype(\"int\")\ncustomer_data[\"RecencyScore\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"customer_data[\"FrequencyScore\"] = pd.cut(customer_data[\"RelFrequency\"], \n                                       bins=[-1, \n                                             np.percentile(customer_data[\"RelFrequency\"], 25), \n                                             np.percentile(customer_data[\"RelFrequency\"], 50), \n                                             np.percentile(customer_data[\"RelFrequency\"], 75), \n                                             customer_data[\"RelFrequency\"].max()], \n                                       labels=[1, 2, 3, 4]).astype(\"int\")\ncustomer_data[\"FrequencyScore\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"customer_data[\"MonetaryScore\"] = pd.cut(customer_data[\"RelMonetaryValue\"], \n                                       bins=[customer_data[\"RelMonetaryValue\"].min()-1, \n                                             np.percentile(customer_data[\"RelMonetaryValue\"], 25),\n                                             np.percentile(customer_data[\"RelMonetaryValue\"], 50), \n                                             np.percentile(customer_data[\"RelMonetaryValue\"], 75), \n                                             customer_data[\"RelMonetaryValue\"].max()], \n                                       labels=[1, 2, 3, 4]).astype(\"int\")\ncustomer_data[\"MonetaryScore\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"customer_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"customer_data[\"RFM\"] = customer_data[\"RecencyScore\"] + customer_data[\"FrequencyScore\"] + customer_data[\"MonetaryScore\"]\ncustomer_data[\"RFM\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfm_rel = pd.DataFrame(customer_data.pivot_table(index=[\"RFM\"], \n                                    values=[\"Recency\", \"Frequency\", \"MonetaryValue\", \"Lifetime\"], \n                                    aggfunc={\"Recency\": [np.min, np.median, np.max], \n                                             \"Frequency\": [np.min, np.median, np.max], \n                                             \"MonetaryValue\": [np.min, np.median, np.max], \n                                             \"Lifetime\": [np.min, np.median, np.max, \"count\"]}))\nrfm_rel\n# Note that the median lifetime is rather constant across clusters. This is a good news - our segmentation is not biased by the lifetime\n# of the customers.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(nrows=2, ncols=1)\nfig.suptitle('Median Lifetime of RFM Segments (Absolute vs Relative)')\nrfm_abs[\"Lifetime\"][\"median\"].plot(ax=axes[0], kind=\"bar\")\nrfm_rel[\"Lifetime\"][\"median\"].plot(ax=axes[1], kind=\"bar\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualise segments using 3D plot\nx = customer_data[\"RelRecency\"]\ny = customer_data[\"RelFrequency\"]\nz = (customer_data[\"RelMonetaryValue\"] - customer_data[\"RelMonetaryValue\"].min()) / customer_data[\"RelMonetaryValue\"].max()\nc = customer_data[\"RFM\"]\nfig = plt.figure(figsize=(10, 8))\nax = fig.add_subplot(111, projection='3d')\nax.scatter(xs=x, ys=y, zs=z, c=c, s=30, alpha=0.5)\nax.set_title(\"RFM Visualisation\")\nax.set_xlabel(\"Relative Recency\")\nax.set_ylabel(\"Relative Frequency\")\nax.set_zlabel(\"Relative Monetary Value (with Min-Max Standardisation)\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(nrows=3, ncols=1, sharex=True, sharey=True, figsize=(5, 15))\nfig.suptitle('Correlation between R, F and M')\n\naxs[0].scatter(x, y, alpha=0.5)\naxs[0].set_title(\"Relative Recency (x) vs Relative Frequency (y)\")\n\naxs[1].scatter(y, z, alpha=0.5)\naxs[1].set_title(\"Relative Frequency (x) vs Relative Monetary Value (y)\")\n\naxs[2].scatter(x, z, alpha=0.5)\naxs[2].set_title(\"Relative Recency (x) vs Relative Monetary Value (y)\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = customer_data[\"RecencyScore\"]\ny = customer_data[\"FrequencyScore\"]\nz = customer_data[\"MonetaryScore\"]\nc = customer_data[\"RFM\"]\nfig = plt.figure(figsize=(10, 8))\nax = fig.add_subplot(111, projection='3d')\nax.scatter(xs=x, ys=y, zs=z, c=c, s=30, alpha=0.5)\nax.set_title(\"RFM Visualisation\")\nax.set_xlabel(\"Recency Score\")\nax.set_ylabel(\"Frequency Score\")\nax.set_zlabel(\"Monetary Score\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generate simple criteria for labelling","metadata":{}},{"cell_type":"code","source":"# From these statistics we can generate some heuristic business rules to simplify our segmentation.\n# For example, RFM score 3 and 4 can be combined, because these two groups tend to have only one transaction.\n# Create new columns with our learnings\ncustomer_data.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfm_rel","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"customer_data[\"last_order_within_l60d\"] = customer_data[\"Recency\"]<60 # Had transactions in the last 60 days\ncustomer_data[\"more_than_two_orders\"] = customer_data[\"Frequency\"]>2 # Logged in more than twice\ncustomer_data[\"value_higher_than_2k\"] = customer_data[\"MonetaryValue\"]>2000 # Sum of value higher than 2K\ncustomer_data.groupby([\"last_order_within_l60d\", \"more_than_two_orders\", \"value_higher_than_2k\"]).count()[\"Lifetime\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conditions = [\n    (customer_data[\"last_order_within_l60d\"]==True)&(customer_data[\"more_than_two_orders\"]==True)&(customer_data[\"value_higher_than_2k\"]==True),\n    (customer_data[\"last_order_within_l60d\"]==True)&(customer_data[\"more_than_two_orders\"]==True)&(customer_data[\"value_higher_than_2k\"]==False),\n    (customer_data[\"last_order_within_l60d\"]==True)&(customer_data[\"more_than_two_orders\"]==False),\n    (customer_data[\"last_order_within_l60d\"]==False)&(customer_data[\"more_than_two_orders\"]==True),\n    (customer_data[\"last_order_within_l60d\"]==False)&(customer_data[\"more_than_two_orders\"]==False)\n]\nmappings = [\"01. high engagement & high value\", \n            \"02. high engagement & low value\", \n            \"03. recent and low frequency\", \n            \"04. old and high frequency\", \n            \"05. low engagement & low value\"]\ncustomer_data['FinalRFM'] = np.select(conditions, mappings, default=\"Others\")\ncustomer_data['FinalRFM'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"customer_data.pivot_table(index=[\"FinalRFM\"], \n                          values=[\"Recency\", \"Frequency\", \"MonetaryValue\", \"Lifetime\"], \n                          aggfunc={\"Recency\": [np.min, np.median, np.max], \n                                   \"Frequency\": [np.min, np.median, np.max], \n                                   \"MonetaryValue\": [np.min, np.median, np.max], \n                                   \"Lifetime\": [np.min, np.median, np.max, \"count\"]})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Bonus: calculate the percentage of new, active, inactive and return users in each month","metadata":{}},{"cell_type":"code","source":"# Calculate the number of new users, inactive users, return users and active users in each month\n# Definition:\n# New users: those who made their first purchase in the current month\n# Active users: those who made purchases in the previous month and in the current month\n# Inactive users: those who made purchases in previous months, but not in the current month\n# Return users: those who made purchases before the previous month, not in the previous month and made purchases agian in the current month\ndata[\"InvoiceMonth\"] = data[\"InvoiceDate\"].apply(lambda x: x.replace(day=1))\ndata[\"InvoiceMonth\"] = data[\"InvoiceMonth\"].apply(lambda x: x.strftime(\"%Y-%m-%d\"))\nuser_month_pivot = data.pivot_table(index=[\"CustomerID\"], \n                                    columns=[\"InvoiceMonth\"], \n                                    values=[\"InvoiceNo\"], \n                                    aggfunc=\"count\", \n                                    fill_value=0)\nuser_month_pivot.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replace count of invoices with 1\nuser_month_pivot = user_month_pivot.applymap(lambda x: 1 if x>0 else 0)\nuser_month_pivot.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the number of columns\nlen((user_month_pivot).columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define functions to get user status\ndef user_status(data):\n    status = []\n    for i in range(13):\n    # If the user has no purchase in the current month\n        if data[i] == 0:\n            # If the user has made purchases before\n            if len(status) > 0:\n                # If the user is unregistered in the previous month\n                if status[i-1] == \"unreg\":\n                # The the user is also unregistered this month\n                    status.append(\"unreg\")\n                # Otherwise the user is an active user, i.e., he/she already registered\n                else:\n                    status.append(\"inactive\")\n            # Otherwise the user is not registered in the current month, i.e., he/she has never made any purchases\n            else:\n                status.append(\"unreg\")\n        else:\n            # This is the first purchase of the user\n            if len(status) == 0:\n                status.append(\"new\")\n            else:\n                if status[i-1] == \"inactive\":\n                    status.append(\"return\")\n                elif status[i-1] == \"unreg\":\n                    status.append(\"new\")\n                else:\n                    status.append(\"active\")\n    return status","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"user_month_status = pd.DataFrame(user_month_pivot.apply(lambda x: pd.Series(user_status(x)), axis=1))\nuser_month_status.columns = user_month_pivot.columns\nuser_month_status.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"month_status_pivot = pd.DataFrame(user_month_status.replace(\"unreg\", np.NaN).apply(lambda x: pd.value_counts(x)))\nmonth_status_pivot.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"month_status_pivot = month_status_pivot.fillna(0).T\nmonth_status_pivot.reset_index(inplace=True)\nmonth_status_pivot.set_index(\"InvoiceMonth\", inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = month_status_pivot.plot.area(figsize = (12,6))\nplt.title(\"Number of Users by Status in each month\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}